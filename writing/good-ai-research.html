<!DOCTYPE html>
<html lang="en">

<head>
  <link rel="stylesheet" href="/css/site.css" />
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
  <meta charset="utf-8" />

  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">

  <meta name="description" content="Some scattered thoughts about what
makes a good computer science, AI or ML research paper." />
  <meta name="keywords" content="research taste" />
  <title>What makes for good AI research?</title>
  
</head>

<body>
  <aside class="sidebar">
    <div id="sidebar">
      <img src="/images/me3.jpg" />
      <p>Sam Stevens</p>
    </div>
  </aside>
  <main>
    <header>
      <h1>Sam Stevens</h1>
      <p>
        [<a href="/">Home</a>]
        [<a href="/writing">Writing</a>]
        [<a href="/research">Research</a>]
        [<a href="/contact">Contact</a>]
        [<a href="/cv.pdf">CV</a>]
      </p>
    </header>
    <article>
      <!-- Must be unindented to prevent code indentation being broken -->
<h1 id="what-makes-a-cs-paper-worth-reading-and-why-i-had-to-ask">What
Makes a CS Paper Worth Reading? (And Why I Had to Ask)</h1>
<p>My ecology co&#x2011;author asked me a deceptively simple question:</p>
<blockquote>
<p><em>&#x201C;Why isn&#x2019;t our automated&#x2011;trait&#x2011;measurement idea an interesting CS
paper? What even is a fundamentally good CS/ML paper?&#x201D;</em></p>
</blockquote>
<p>Cue existential crisis. I rifled through the papers that
<strong>actually</strong> fire me up and reverse&#x2011;engineered why I cite
them.</p>
<h2 id="a-punchthrough-framing">A Punch&#x2011;Through Framing</h2>
<p>Good research punctures the status quo with a <strong>new
lens</strong>:</p>
<ul>
<li><strong>ImageNet</strong> reframed vision progress as single&#x2011;number
scaling: classification accuracy here, win everywhere else.<br />
</li>
<li><strong>ARC-AGI</strong> reframed intelligence as
<em>skill&#x2011;acquisition efficiency</em> instead of dataset
memorisation.</li>
</ul>
<p>If the problem statement feels instantly obvious in hindsight, that&#x2019;s
the trick. Does the abstract define a task/metric that makes today&#x2019;s
SOTA look silly? No? Move on.</p>
<h2 id="one-decisive-experiment-or-benchmark">One Decisive Experiment
(or Benchmark)</h2>
<p>A single, clean test that forces consensus beats a zoo of partial
results. Scaling&#x2011;law papers plotted <strong>loss vs compute</strong> and
everyone&#x2019;s jaw dropped.<br />
Can I name the killer figure before reading Section 4? If I can&#x2019;t, the
evidence probably isn&#x2019;t decisive.</p>
<h2 id="universal-regularity">Universal Regularity</h2>
<p>Find a law, trend or invariance that survives across models, data,
and scaling.</p>
<ul>
<li>Neural scaling laws.<br />
</li>
<li>SSL &#x2265; CLIP when data is controlled.</li>
</ul>
<p>Regularities turn one&#x2011;off hacks into field guides. Would the claim
still matter if we doubled the model size, swapped datasets, and trained
another month?</p>
<h2 id="clarity-intuition">Clarity &amp; Intuition</h2>
<p>A paper that <em>feels</em> inevitable is more reusable. Matryoshka
SAEs can be summarized as &#x201C;training on prefixes reduces feature
absorption.&#x201D; Six words, memorable fix. Can I explain the core idea on a
whiteboard in 30 seconds without squinting at the PDF?</p>
<h2 id="future-leverage">Future Leverage</h2>
<p>Results that age gracefully: scale, hardware, modalities, or theory
can grow and the insight still holds.</p>
<hr />
<h2 id="whats-not-enough">What&#x2019;s <em>Not</em> Enough</h2>
<ul>
<li>Architectural tweaks chasing +0.5 mAP with bigger GPUs.<br />
</li>
<li>Re&#x2011;implementations that add zero framing (useful, yes; citable,
no).<br />
</li>
<li>Benches that duplicate existing task structure&#x2014;no new failure mode,
no cross&#x2011;task correlation.<br />
</li>
<li>Theory disconnected from anomalies practitioners care about.</li>
</ul>
<hr />
<h2 id="why-this-came-up">Why This Came Up</h2>
<p>I kept insisting that automated beetle&#x2011;trait measurement wasn&#x2019;t AI
research, but I lacked a mental checklist. Pinning down these six
ingredients clarifies the bar:</p>
<p><em>If a project can&#x2019;t articulate its punch&#x2011;through framing
<strong>and</strong> sketch the decisive experiment that proves it, it&#x2019;s
probably a neat application, not a CS contribution.</em></p>
<p>Now when my co&#x2011;author asks &#x201C;is this CS&#x2011;worthy?&#x201D; I can run the smell
tests above instead of shrugging.</p>
<hr />
<h3 id="tldr">TL;DR</h3>
<blockquote>
<p><strong>Novel framing + decisive evidence + universal reach =
indispensable paper.</strong><br />
Everything else is garnish (useful garnish, but garnish).</p>
</blockquote>
<p>Back to chasing that punch&#x2011;through idea&#x2014;maybe diagnostic&#x2011;trait
discovery <em>is</em> exciting, but only if we can design the benchmark
that exposes a blind spot ImageNet never touched.</p>
      <hr />
      <p>[<a href="/links" data-no-instant>Links</a>] [<a href="https://github.com/samuelstevens/personal-website">Source</a>]</p>
      <p>Sam Stevens, 2024</p>
    </article>
  </main>
  <script src="/js/instantclick.min.js" data-no-instant></script>
  <script data-no-instant>
    InstantClick.init();
  </script>
  <style>
    
  </style>
</body>

</html>
