<!DOCTYPE html>
<html lang="en">

<head>
  <link rel="stylesheet" href="/css/site.css" />
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
  <meta charset="utf-8" />

  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">

  <meta name="description" content="All papers I was a part of." />
  <meta name="keywords" content="research, ai, machine
learning, papers, publications" />
  <title>All My Papers</title>
  
</head>

<body>
  <aside class="sidebar">
    <div id="sidebar">
      <img src="/images/me3.jpg" />
      <p>Sam Stevens</p>
    </div>
  </aside>
  <main>
    <header>
      <h1>Sam Stevens</h1>
      <p>
        [<a href="/">Home</a>]
        [<a href="/writing">Writing</a>]
        [<a href="/research">Research</a>]
        [<a href="/microblog">Blog</a>]
        [<a href="/contact">Contact</a>]
        [<a href="/cv.pdf">CV</a>]
      </p>
    </header>
    <article>
      <!-- Must be unindented to prevent code indentation being broken -->
<h1 id="research-papers">Research Papers</h1>
<p>Organized by date. I bolded myself as an author for clarity. <a
href="https://scholar.google.com/citations?user=uR-A0LAAAAAJ&amp;hl=en">Google
Scholar</a> might be more up-to-date if you are looking for very recent
work.</p>
<p><strong>Towards Open-Ended Visual Scientific Discovery with Sparse
Autoencoders</strong> <br/> <strong>Samuel Stevens</strong>, Jacob
Beattie, Tanya Berger-Wolf, Yu Su <em>(arXiv Preprint)</em> [<a
href="https://arxiv.org/abs/2511.17735">paper</a>] [<a
href="https://github.com/OSU-NLP-Group/saev">code</a>]</p>
<p><strong>BioBench: A Blueprint to Move Beyond ImageNet for Scientific
ML Benchmarks</strong> <br/> <strong>Samuel Stevens</strong> <em>(Third
Workshop for Imageomics at NeurIPS 2025)</em> [<a
href="https://arxiv.org/abs/2511.16315">paper</a>] [<a
href="https://samuelstevens.me/biobench/">website</a>] [<a
href="https://github.com/samuelstevens/biobench">code</a>]</p>
<p><strong>BioCLIP 2: Emergent Properties from Scaling Hierarchical
Contrastive Learning</strong> <br/> Jianyang Gu, <strong>Samuel
Stevens</strong>, Elizabeth G Campolongo, Matthew J Thompson, Net Zhang,
Jiaman Wu, Andrei Kopanev, Zheda Mai, Alexander E. White, James Balhoff,
Wasila Dahdul, Daniel Rubenstein, Hilmar Lapp, Tanya Berger-Wolf,
Wei-Lun Chao, Yu Su <em>(NeurIPS 2025, <span
style="color: var(--secondary-color)"><strong>Spotlight</strong></span>)</em>
[<a href="https://arxiv.org/abs/2505.23883">paper</a>] [<a
href="https://imageomics.github.io/bioclip-2/">website</a>] [<a
href="https://huggingface.co/spaces/imageomics/bioclip-2-demo">demo</a>]</p>
<p><strong>Optimizing image capture for computer vision-powered
taxonomic identification and trait recognition of biodiversity
specimens</strong> <br/> Alyson East, Elizabeth G. Campolongo, Luke
Meyers, S. M. Rayeed, <strong>Samuel Stevens</strong>, Iuliia
Zarubiieva, Isadora E. Fluck, Jennifer C. Giron, Maximiliane Jousse,
Scott Lowe, Kayla I. Perry, Isabelle Betancourt, Noah Charney, Evan
Donoso, Nathan Fox, Kim J. Landsbergen, Ekaterina Nepovinnykh, Michelle
Ramirez, Parkash Singh, Khum Thapa-Magar, Matthew Thompson, Evan Waite,
Tanya Berger-Wolf, Hilmar Lapp, Paula Mabee, Charles Stewart, Graham
Taylor, Sydne Record <em>(Methods in Ecology and Evolution)</em> [<a
href="https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.70140">paper</a>]</p>
<p><strong>Mind the (Data) Gap: Evaluating Vision Systems in Small Data
Applications</strong> <br/> <strong>Samuel Stevens</strong>, S M Rayeed,
Jenna Kline <em>(Third Workshop for Imageomics at NeurIPS 2025)</em> [<a
href="https://arxiv.org/abs/2504.06486">paper</a>]</p>
<p><strong>Interpretable and Testable Vision Features via Sparse
Autoencoders</strong> <br/> <strong>Samuel Stevens</strong>, Wei-Lun
Chao, Tanya Berger-Wolf, Yu Su <em>(arXiv Preprint)</em> [<a
href="https://arxiv.org/abs/2502.06755">paper</a>] [<a
href="https://osu-nlp-group.github.io/saev/">website</a>] [<a
href="https://osu-nlp-group.github.io/saev/#demos">demos</a>] [<a
href="https://huggingface.co/collections/osunlp/sae-v-67ab8c4fdf179d117db28195">models</a>]</p>
<p><strong>The Cool and the Cruel: Separating Hard Parts of LWE
Secrets</strong> <br/> Niklas Nolte, Mohamed Malhou, Emily Wenger,
<strong>Samuel Stevens</strong>, Cathy Li, Fran&#xE7;ois Charton, Kristin
Lauter <em>International Conference on Cryptology in Africa
(AFRICACRYPT)</em> [<a
href="https://arxiv.org/pdf/2403.10328">paper</a>] [<a
href="https://github.com/facebookresearch/LWE-benchmarking">code</a>]</p>
<p><strong>Salsa Fresca: Angular Embeddings and Pre-Training for ML
Attacks on Learning with Errors</strong> <br/> <strong>Samuel
Stevens</strong>, Emily Wenger, Cathy Yuanchen Li, Niklas Nolte, Eshika
Saxena, Francois Charton, and Kristin Lauter <em>(TMLR 2025)</em> [<a
href="https://openreview.net/pdf?id=w4nd5695sq">paper</a>] [<a
href="https://openreview.net/forum?id=w4nd5695sq">OpenReview</a>]</p>
<p><strong>BioCLIP: A Vision Foundation Model for the Tree of
Life</strong> <br/> <strong>Samuel Stevens</strong>*, Jiaman Wu*,
Matthew J Thompson, Elizabeth G Campolongo, Chan Hee Song, David Edward
Carlyn, Li Dong, Wasila M Dahdul, Charles Stewart, Tanya Berger-Wolf,
Wei-Lun Chao, Yu Su (* equal contribution) <em>(CVPR 2024, <span
style="color: var(--secondary-color)"><strong>Best Student
Paper</strong></span>)</em> [<a
href="https://arxiv.org/abs/2311.18803">paper</a>] [<a
href="https://imageomics.github.io/bioclip/">website</a>] [<a
href="https://huggingface.co/spaces/imageomics/bioclip-demo">demo</a>]</p>
<p><strong>MMMU: A Massive Multi-Discipline Multimodal Understanding and
Reasoning Benchmark for Expert AGI</strong> <br/> Xiang Yue, Yuansheng
Ni, Kai Zhang, Tianyu Zheng, Ruoqi Liu, Ge Zhang, <strong>Samuel
Stevens</strong>, Dongfu Jiang, Weiming Ren, Yuxuan Sun, Cong Wei, Botao
Yu, Ruibin Yuan, Renliang Sun, Ming Yin, Boyuan Zheng, Zhenzhu Yang,
Yibo Liu, Wenhao Huang, Huan Sun, Yu Su, Wenhu Chen <em>(CVPR 2024,
<span style="color: var(--secondary-color)"><strong>Best Paper
Finalist</strong></span>)</em> [<a
href="https://arxiv.org/abs/2311.16502">paper</a>] [<a
href="https://mmmu-benchmark.github.io/">website</a>]</p>
<p><strong>A Simple Interpretable Transformer for Fine-Grained Image
Classification and Analysis</strong> <br/> Dipanjyoti Paul, Arpita
Chowdhury, Xinqi Xiong, Feng-Ju Chang, David Carlyn, <strong>Samuel
Stevens</strong>, Kaiya Provost, Anuj Karpatne, Bryan Carstens, Daniel
Rubenstein, Charles Stewart, Tanya Berger-Wolf, Yu Su, Wei-Lun Chao
<em>(ICLR 2024)</em> [<a
href="https://arxiv.org/abs/2311.04157">paper</a>] [<a
href="https://github.com/Imageomics/INTR">code</a>]</p>
<p><strong>A Framework for Autonomic Computing for In Situ
Imageomics</strong> <br/> Jenna Kline, Christopher Stewart, Tanya
Berger-Wolf, Michelle Ramirez, <strong>Samuel Stevens</strong>, Reshma
Ramesh Babu, Namrata Banerji, Alec Sheets, Sowbaranika Balasubramaniam,
Elizabeth Campolongo, Matthew Thompson, Charles V Stewart, Maksim
Kholiavchenko, Daniel I Rubenstein, Nina Van Tiel, Jackson Miliko
<em>(IEEE International Conference on Autonomic Computing and
Self-Organizing Systems)</em> [<a
href="https://ieeexplore.ieee.org/abstract/document/10336017">paper</a>]</p>
<p><strong>Roll Up Your Sleeves: Working with a Collaborative and
Engaging Task-Oriented Dialogue System</strong> <br/> Lingbo Mo, Shijie
Chen, Ziru Chen, Xiang Deng, Ashley Lewis, Sunit Singh, <strong>Samuel
Stevens</strong>, Chang-You Tai, Zhen Wang, Xiang Yue, Tianshu Zhang, Yu
Su, Huan Sun <em>(24th Meeting of the Special Interest Group on
Discourse and Dialogue, SIGDIAL 2023)</em> [<a
href="https://aclanthology.org/2023.sigdial-1.19.pdf">paper</a>]</p>
<p><strong>Mind2Web: Towards a Generalist Agent for the Web</strong>
<br/> Xiang Deng, Yu Gu, Boyuan Zheng, Shijie Chen, <strong>Samuel
Stevens</strong>, Boshi Wang, Huan Sun, Yu Su <em>(NeurIPS 2023, <span
style="color: var(--secondary-color)"><strong>Spotlight</strong></span>)</em>
[<a href="https://arxiv.org/abs/2306.06070">paper</a>] [<a
href="https://osu-nlp-group.github.io/Mind2Web">website</a>]</p>
<p><strong>Memorization for Good: Encryption with Autoregressive
Language Models</strong> <br/> <strong>Samuel Stevens</strong>, Yu Su.
<em>(Arxiv Preprint)</em> [<a
href="https://arxiv.org/abs/2305.10445">paper</a>] [<a
href="/research/encryption">website</a>]</p>
<p><strong>arXivEdits: Understanding the human revision process in
scientific writing</strong> <br/> Chao Jiang, Wu Xu, <strong>Samuel
Stevens</strong> <em>(EMNLP 2022)</em> [<a
href="https://arxiv.org/abs/2210.15067">paper</a>] [<a
href="https://github.com/chaojiang06/arXivEdits">code+data</a>]</p>
<p><strong>Bootstrapping a User-Centered Task-Oriented Dialogue
System</strong> <br/> Shijie Chen, Ziru Chen, Xiang Deng, Ash Lewis,
Lingbo Mo, <strong>Samuel Stevens</strong>, Zhen Wang, Xiang Yue,
Tianshu Zhang, Yu Su, Huan Sun. <em>(Alexa Prize TaskBot Challenge
Proceedings 2022)</em> [<a
href="https://arxiv.org/abs/2207.05223">paper</a>] [<a
href="https://sunlab-osu.github.io/tacobot/">website</a>]</p>
<p><strong>An Investigation of Language Model Interpretability via
Sentence Editing</strong> <br/> <strong>Samuel Stevens</strong>, Yu Su.
<em>(EMNLP BlackboxNLP 2021.)</em> [<a
href="https://arxiv.org/abs/2011.14039">paper</a>] [<a
href="https://github.com/samuelstevens/sentence-editing-interpretability">code</a>]</p>
<p><strong>SalsaBot: Towards a Robust and Generalizable Embodied
Agent</strong> <br/> Chan Hee Song, Jiaman Wu, Ju-Seung Byeon, Zexin Xu,
Vardaan Pahuja, Goonmeet Bajaj, <strong>Samuel Stevens</strong>, Ziru
Chen, Yu Su <em>(short paper at Embodied AI Workshop at CVPR 2023, long
paper in Alexa Prize SimBot Challenge Proceedings 2023)</em> [<a
href="https://embodied-ai.org/papers/2023/10.pdf">short paper</a>] [<a
href="https://assets.amazon.science/ea/b7/0895f4e0468680903efcfd67e795/salsabot-report-1.pdf">long
paper</a>]</p>
      <hr />
      <p>[<a href="/links" data-no-instant>Links</a>] [<a href="https://github.com/samuelstevens/personal-website">Source</a>]</p>
      <p>Sam Stevens, 2024</p>
    </article>
  </main>
  <script src="/js/instantclick.min.js" data-no-instant></script>
  <script data-no-instant>
    InstantClick.init();
  </script>
  <style>
    
  </style>
</body>

</html>
