<!DOCTYPE html>
<html lang="en">

<head>
  <link rel="stylesheet" href="/css/site.css" />
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
  <meta charset="utf-8" />

  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">

  <meta name="description" content="Applying AI to science in 2025." />
  <meta name="keywords" content="" />
  <title>AI for Science</title>
  
</head>

<body>
  <aside class="sidebar">
    <div id="sidebar">
      <img src="/images/me3.jpg" />
      <p>Sam Stevens</p>
    </div>
  </aside>
  <main>
    <header>
      <h1>Sam Stevens</h1>
      <p>
        [<a href="/">Home</a>]
        [<a href="/writing">Writing</a>]
        [<a href="/research">Research</a>]
        [<a href="/microblog">Blog</a>]
        [<a href="/contact">Contact</a>]
        [<a href="/cv.pdf">CV</a>]
      </p>
    </header>
    <article>
      <!-- Must be unindented to prevent code indentation being broken -->
<h1 id="ai-for-science">AI for Science</h1>
<p>My mentor <a
href="https://scholar.google.com/citations?user=Hq28JM0AAAAJ">Tanya
Berger-Wolf</a> thinks about science in terms of 4 steps:</p>
<ol type="1">
<li>Question</li>
<li>Data</li>
<li>Hypothesis</li>
<li>Answer</li>
</ol>
<p>AI can assist with some of these steps. Certainly, if you correctly
frame a question, AI can help you annotate or process data. Currently, I
think AI systems are unable to form hypotheses.<a href="#fn1"
class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>
Statistical tests, AI coding assistants, and other tools can assist you
in the &#x201C;hypothesis&#x201D; to &#x201C;answer&#x201D; step.</p>
<p>However, Tanya argues that asking questions is still a fundamentally
human challenge. Based on some (as of yet hypothetical) conversations
with</p>
<p><strong>An AI system to help scientists write expert-level empirical
software</strong> uses LLMs to do grad student search: try lots of
different ideas, their implementations, and hyperparameter tuning, on
verifiable tasks.</p>
<p><strong>Accelerating scientific discoveries through data-driven
innovations</strong> (Patterns special collection)</p>
<blockquote>
<p>By framing protein structure prediction as a recurring community
benchmark with standardized evaluation metrics, CASP identified the key
computational bottleneck and created a venue for sustained
methodological innovation. This groundwork ultimately enabled
breakthroughs such as AlphaFold, but <strong>the critical contribution
was the clear problem formulation and consistent evaluation regime that
mobilized an entire research community.</strong></p>
</blockquote>
<p><em>(Emphasis mine)</em></p>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>Google&#x2019;s <a
href="https://arxiv.org/abs/2502.18864">Co-Scientist</a> system
supposedly can do this, but it has been mired in controversy.<a
href="#fnref1" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
</ol>
</section>
      <hr />
      <p>[<a href="/links" data-no-instant>Links</a>] [<a href="https://github.com/samuelstevens/personal-website">Source</a>]</p>
      <p>Sam Stevens, 2024</p>
    </article>
  </main>
  <script src="/js/instantclick.min.js" data-no-instant></script>
  <script data-no-instant>
    InstantClick.init();
  </script>
  <style>
    
  </style>
</body>

</html>
