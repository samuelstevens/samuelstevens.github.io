
<rss version="2.0">
  <channel>
    <title>
      Reading List
    </title>
    <link>
      https://samuelstevens.me/readinglist.xml
    </link>
    <description>
      My personal reading list
    </description>
    <language>
      en-us
    </language>
    <pubDate>
      Sat, 6 Feb 2021 19:10:25 UT
    </pubDate>
    <lastBuildDate>
      Sat, 6 Feb 2021 19:10:25 UT
    </lastBuildDate>
    <docs>
      https://cyber.harvard.edu/rss/rss.html
    </docs>
    <generator>
      samuelstevens/racket-rss
    </generator>
    <managingEditor>
      samuel.robert.stevens@gmail.com
    </managingEditor>
    <webMaster>
      samuel.robert.stevens@gmail.com
    </webMaster>
    <item>
      <title>
        
      </title>
      <link>
        https://www.executeprogram.com/
      </link>
      <description>
        &lt;a href="https://www.executeprogram.com/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:18:12 UT
      </pubDate>
      <guid>
        https://www.executeprogram.com/
      </guid>
    </item>
    <item>
      <title>
        Markov Chains
      </title>
      <link>
        https://setosa.io/blog/2014/07/26/markov-chains/index.html
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;
&lt;p&gt;Markov chains, named after &lt;a href="https://en.wikipedia.org/wiki/Andrey_Markov"&gt;Andrey Markov&lt;/a&gt;, are mathematical systems that hop from one "state" (a situation or set of values) to another. For example, if you made a Markov chain model of a baby's behavior, you might include "playing," "eating", "sleeping," and "crying" as states, which together with other behaviors could form a 'state space': a list of all possible states. In addition, on top of the state space, a Markov chain tells you the probabilitiy of hopping, or "transitioning," from one state to any other state---e.g., the chance that a baby currently playing will fall asleep in the next five minutes without crying first.&lt;/p&gt;

&lt;p&gt;A simple, two-state Markov chain is shown below.&lt;/p&gt;



&lt;p&gt;With two states (A and B) in our state space, there are 4 possible transitions (not 2, because a state can transition back into itself). If we're at 'A' we could transition to 'B' or stay at 'A'. If we're at 'B' we could transition to 'A' or stay at 'B'. In this two state diagram, the probability of
transitioning from any state to any other state is 0.5.&lt;/p&gt;

&lt;p&gt;Of course, real modelers don't always draw out Markov chain diagrams. Instead they use a "transition matrix" to tally the transition probabilities. Every state in the state space is included once as a row and again as a column, and each cell in the matrix tells you the probability of transitioning from its row's state to its column's state. So, in the matrix, the cells do the same job that the arrows do in the diagram.&lt;/p&gt;



&lt;p&gt;If the state space adds one state, we add one row and one column, adding one cell to every existing column and row. This means the number of cells grows quadratically as we add states to our Markov chain. Thus, a transition matrix comes in handy pretty quickly, unless you want to draw a jungle gym Markov chain diagram.&lt;/p&gt;

&lt;p&gt;One use of Markov chains is to include real-world phenomena in computer simulations. For example, we might want to check how frequently a new dam will overflow, which depends on the number of rainy days in a row. To build this model, we start out with the following pattern of rainy (R) and sunny (S) days:&lt;/p&gt;



&lt;p&gt;One way to simulate this weather would be to just say "Half of the days are rainy. Therefore, every day in our simulation will have a fifty percent chance of rain." This rule would generate the following sequence in simulation:&lt;/p&gt;



&lt;p&gt;Did you notice how the above sequence doesn't look quite like the original? The second sequence seems to jump around, while the first one (the real data) seems to have a "stickyness". In the real data, if it's sunny (S) one day, then the next day is also much more likely to be sunny.&lt;/p&gt;

&lt;p&gt;We can minic this "stickyness" with a two-state Markov chain. When the Markov chain is in state "R", it has a 0.9 probability of staying put and a 0.1 chance of leaving for the "S" state. Likewise, "S" state has 0.9 probability of staying put and a 0.1 chance of transitioning to the "R" state.&lt;/p&gt;



&lt;p&gt;In the hands of metereologists, ecologists, computer scientists, financial engineers and other people who need to model big phenomena, Markov chains can get to be quite large and powerful. For example, the algorithm Google uses to determine the order of search results, called &lt;a href="https://en.wikipedia.org/wiki/PageRank"&gt;PageRank&lt;/a&gt;, is a type of Markov chain.&lt;/p&gt;



&lt;p&gt;Above, we've included a Markov chain "playground", where you can make your own Markov chains by messing around with a transition matrix. Here's a few to work from as an example: &lt;a&gt;ex1&lt;/a&gt;, &lt;a&gt;ex2&lt;/a&gt;, &lt;a&gt;ex3&lt;/a&gt; or generate one &lt;a&gt;randomly&lt;/a&gt;. The transition matrix text will turn red if the provided matrix isn't a valid transition matrix. The rows of the transition matrix must total to 1. There also has to be the same number of rows as columns.&lt;/p&gt;

&lt;p&gt;You can also access a fullscreen version at &lt;a href="https://setosa.io/markov/index.html"&gt;setosa.io/markov&lt;/a&gt;&lt;/p&gt;



&lt;/div&gt;&lt;/div&gt;&lt;a href="https://setosa.io/blog/2014/07/26/markov-chains/index.html"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:18:48 UT
      </pubDate>
      <guid>
        https://setosa.io/blog/2014/07/26/markov-chains/index.html
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://www.lesswrong.com/posts/FCXCXigp7byv2dM8D/how-to-make-billions-of-dollars-reducing-loneliness
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;&lt;h2 id="Loneliness_Is_a_Big_Problem"&gt;Loneliness Is a Big Problem&lt;/h2&gt;
&lt;p&gt;On Facebook, my friend Tyler &lt;a href="https://www.facebook.com/tyleralterman/posts/10214636828938815"&gt;writes&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Lately, I've been having an alarming amount of conversations arise about the burdens of loneliness, alienation, rootlessness, and a lack of belonging that many of my peers feel, especially in the Bay Area. I feel it too. Everyone has a gazillion friends and events to attend. But there's a palpable lack of social fabric. I worry that this atomization is becoming a world-wide phenomenon – that we might be some of the first generations without the sort of community that it's in &lt;em&gt;human nature&lt;/em&gt; to rely on.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;And that the result is a worsening epidemic of mental illness...&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Without the framework of a uniting religion, ethnicity, or purpose, it's hard to get people to truly commit to a given community. Especially when it's so easy to swipe left and opt for things that offer the fleeting &lt;em&gt;feeling&lt;/em&gt; of community without being the real thing: the parties, the once-a-month lecture series, the Facebook threads, the workshops, the New Age ceremonies. We often use these as "community porn" – they're easier than the real thing and they satisfy enough of the craving. But they don't make you whole.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;I've had some thoughts about experiments to try. But then I think about how hard it is (especially in this geographic area) to get people to show up to something on at least a weekly basis. Even if it's for something really great. I see many great attempts at community slowly peter out.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href="https://today.yougov.com/topics/lifestyle/articles-reports/2019/07/30/loneliness-friendship-new-friends-poll-survey"&gt;Young people are lonely&lt;/a&gt;.  &lt;a href="https://www.washingtonpost.com/national/health-science/theres-a-serious-problem-plaguing-some-older-people-loneliness/2019/04/05/338aac8e-5648-11e9-8ef3-fbd41a2ce4d5_story.html"&gt;Old people are lonely&lt;/a&gt;.
&lt;a href="https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1000316"&gt;Loneliness is bad for your health&lt;/a&gt;.  It's bad for &lt;a href="https://www.ft.com/content/89f16688-fb15-11e7-a492-2c9be7f3120a"&gt;society's&lt;/a&gt; &lt;a href="https://www.nytimes.com/2018/11/23/opinion/loneliness-political-polarization.html"&gt;health&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Having a smartphone that keeps you entertained all day, and enough money to live by yourself, might sound like first world problems.  But they are likely contributors to loneliness.  And as developing countries get richer, they'll start having first world problems too.  So I think addressing loneliness could be very high-leverage for the world.&lt;/p&gt;
&lt;p&gt;People are starting businesses to address loneliness: you can pay someone to &lt;a href="https://www.kcrw.com/news/shows/greater-la/have-a-friend-call-you-regularly-for-a-fee/effective-cure-for-loneliness-pay-a-monthly-fee-to-rent-a-friend"&gt;call you periodically&lt;/a&gt; or &lt;a href="https://www.latimes.com/local/lanow/la-me-city-beat-people-walker-loneliness-20190516-story.html"&gt;take you for a walk&lt;/a&gt;.  But I'd argue these services are a band-aid in the same sense that parties, workshops, and ceremonies are.  They don't solve the underlying problem: You're still alone by default instead of together by default.&lt;/p&gt;
&lt;h2 id="Roommates_Could_Be_a_Great_Solution"&gt;Roommates Could Be a Great Solution&lt;/h2&gt;
&lt;p&gt;Sociologists &lt;a href="https://www.nytimes.com/2012/07/15/fashion/the-challenge-of-making-friends-as-an-adult.html"&gt;think&lt;/a&gt; there are three conditions necessary for making friends: proximity; repeated, unplanned interactions; and a setting that encourages people to let their guard down and confide in each other.  These conditions tend to be present during college for many people, but not afterwards.&lt;/p&gt;
&lt;p&gt;Why do people find it easier to make friends in college?  Maybe it's because college students don't usually live alone.&lt;/p&gt;
&lt;p&gt;Going to events doesn't work because (a) you don't typically get repeated interactions with the same person and (b) events take place at a scheduled time.  Which may or may not be a time you're feeling lonely.&lt;/p&gt;
&lt;p&gt;If you have a lot of roommates, all you have to do is step outside your room and find someone to chat with.  No transportation CO2 emissions needed.  But more important, you know your roommates are always gonna be around.&lt;/p&gt;
&lt;h2 id="But_I_Already_Have_Roommates"&gt;But I Already Have Roommates&lt;/h2&gt;
&lt;p&gt;Even if you already have roommates, I think there's a good chance your roommate situation is under-optimized.  Given that you spend so much time with them, there's a lot of value in living with people you really connect with.  (Finding great coworkers makes sense for similar reasons.)&lt;/p&gt;
&lt;p&gt;The layout of your house and the number of roommates you have can also make a big difference.  I used to have friends living in a 4-bedroom place where all the bedrooms opened directly into a single large common area.  If anyone else was outside their room, you'd immediately know it and have an opportunity for interaction.  Later I lived in an 8-bedroom place which felt far lonelier, even with every room occupied.  The house was laid out so it was easy to go about your day without ever running into a fellow roommate.  I also lived in a house with over 50 bedrooms for a while, which was wild &amp;amp; a lot of fun.&lt;/p&gt;
&lt;h2 id="But_I_Don_t_Want_Roommates"&gt;But I Don't Want Roommates&lt;/h2&gt;
&lt;p&gt;One reason you might not want roommates is because you're worried you might have conflicting preferences for what living together should be like.  For example, my philosophy towards dirty dishes is to let them pile up on the counter and periodically stuff them all in the dishwasher, to be as time-efficient as possible.  Surprisingly, some people dislike this approach.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.roomiematch.com/"&gt;RoomieMatch.com&lt;/a&gt; is a website which tries to solve the roommate compatibility problem.  You create a profile by answering questions about dishes, food in the fridge, housecleaning, social events, noise, overnight guests, shared household items, walking around in your underwear, TV, etc.  In addition, there are questions to help predict how you well you will connect as people.&lt;/p&gt;
&lt;h2 id="You_Could_Make_a_Lot_of_Money"&gt;You Could Make a Lot of Money&lt;/h2&gt;
&lt;p&gt;RoomieMatch has two search options: free and cheap.  Cheap costs $20/year.&lt;/p&gt;
&lt;p&gt;The problem with RoomieMatch is they're leaving a massive amount of money on the table.&lt;/p&gt;
&lt;p&gt;A few years ago, a friend of mine was jobless &amp;amp; struggling financially.  He was living in a 4-bedroom house at the time, and he was the primary contact with the landlord.  My friend took responsibility for vetting folks from Craigslist in order to fill the remaining rooms in the house.  He found that folks from Craigslist were willing to pay enough rent for the remaining 3 rooms that he was able to live rent-free until he found a job.&lt;/p&gt;
&lt;p&gt;I acknowledge this is murky ethical territory, and I'm not condoning my friend's actions.  (I don't believe anyone ever found out or got upset, for whatever that's worth.)  The point I'm trying to make is that property management is way more lucrative than roommate matching.  RoomieMatch makes $20 per user per year at best.  My friend was making $100+ per user per &lt;em&gt;month&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;What I'm suggesting is that you take the &lt;a href="https://a16z.com/2015/01/22/the-full-stack-startup/"&gt;full-stack startup&lt;/a&gt; playbook which has been successful in Silicon Valley recently, and apply it to online roommate matching + property management.&lt;/p&gt;
&lt;p&gt;The extreme full-stack approach is to own your own properties.  Apparently the US has a &lt;a href="https://www.wsj.com/articles/a-growing-problem-in-real-estate-too-many-too-big-houses-11553181782"&gt;surplus of big houses&lt;/a&gt; right now.&lt;/p&gt;
&lt;p&gt;There are already &lt;a href="https://techcrunch.com/2018/05/19/shared-housing-startups-are-taking-off/"&gt;players in this space&lt;/a&gt; such as &lt;a href="https://www.roam.co/"&gt;Roam&lt;/a&gt; which are proving that people will pay for community.  (As if people paying extra to live in hip cities like SF &amp;amp; NYC didn't prove that already.  BTW, I found that the &lt;a href="https://forum.effectivealtruism.org/posts/sigun924gsxN4oZq2/the-case-for-the-ea-hotel"&gt;awesome community&lt;/a&gt; at the &lt;a href="https://slatestarcodex.com/2018/08/20/practically-a-book-review-ea-hotel/"&gt;Athena Hotel&lt;/a&gt; more than made up for the fact that it's in a non-hip city.)  Anyway, I think existing players are mostly pursuing the extreme full-stack option.  I actually think this is the wrong play.  You want to be a marketplace, like Airbnb (valued at over $30 billion).  The more people who are using &lt;em&gt;your&lt;/em&gt; tool, the finer-grained roommate matching services you can provide.  It's hard to achieve massive scale if you have to own every property.  You want to be playing matchmaker for individuals with common interests who all happen to be looking for rooms around the same time, plus landlords with empty houses.  Maybe you'll want to undercut RoomieMatch, and provide free matching services for people who live in their properties, in order to achieve the necessary scale.  (RoomieMatch's existing scale is impressive by the way--I quickly got 100+ active, vetted matches in a midsize US city when I tried the tool.  If you have the money you might want to just buy it.)&lt;/p&gt;
&lt;p&gt;So instead of buying properties, maybe you just want to contact people selling large homes &amp;amp; see if you can convince them to let you manage their property.&lt;/p&gt;
&lt;p&gt;Note that this is a good company to start if a recession happens, since people who currently live alone will be thinking about how to save on rent.&lt;/p&gt;
&lt;h2 id="This_Could_Be_Really_Great"&gt;This Could Be Really Great&lt;/h2&gt;
&lt;p&gt;Most roommate search tools, like Craigslist, don't make it easy to figure out if a future roommate is someone you'd actually want to live with.  Imagine reaching a scale where you could match people based on factors like:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;They love to play board games, or pool, or Super Smash Bros.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;They want a compost pile and a garden in their backyard.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;One has a pet, and the other likes animals but isn't yet ready to make a lifetime commitment.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;They want a squat rack in the basement to save time &amp;amp; money going to the gym.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;They want to continue partying like college students after graduation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;They want to be part of an intentional community devoted to mutual improvement and life optimization, or spirituality, or whatever.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;They want to &lt;a href="https://www.lesswrong.com/posts/4esQ684vtR9zcjHgW/i-want-to-live-in-a-baugruppe"&gt;share childcare responsibilities&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;They're all fans of the same sports team.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;They enjoy reading and discussing the same genre of novels, or watching the same movies.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;They're musicians looking for people to jam with.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;They want to live near hiking trails and go on group hikes together.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;They want to do independent study of the same topic.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;They're trying to eat a healthier diet.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;They just moved to a new city and want friends they can explore the city with.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;They have the same unusual work schedule.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;One needs a caretaker, and the other wants to make extra money.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;They like the idea of having a couch or two listed on &lt;a href="https://www.couchsurfing.com/"&gt;CouchSurfing&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;One knows a language the other wants to learn.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;They work close together in the same expensive metropolitan area and want save on housing.  So they live in the outskirts of the city and commute together every day using the diamond lane.  One drives and the other pays for gas.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I also see opportunities to reduce friction in the current roommate matching process:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Automatically find times when everyone is available for a meet &amp;amp; greet video call.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Let people take virtual tours of the houses on offer to minimize driving.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;No need to worry about breaking a lease if someone moves to a different house in your company's network.  Let people try out a few communities &amp;amp; see what works for them.  Use machine learning to improve your matching as you gather more data.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Provide external mediation in the event of roommate disputes, and have a reputation system to encourage good behavior.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You aren't providing &lt;em&gt;housing&lt;/em&gt; as a service (like Airbnb), or &lt;em&gt;companionship&lt;/em&gt; as a service (like the people-walking startup).  You're providing &lt;em&gt;community&lt;/em&gt; as a service.  You could even organize mixers across your houses.&lt;/p&gt;
&lt;h2 id="Conclusion"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Technology has been blamed for the loneliness epidemic, but I think we can use technology to cure the loneliness epidemic as well.&lt;/p&gt;
&lt;p&gt;I'm too busy being obsessed with machine learning to start any company which isn't mostly about that.  But I think this is a product the world needs, and I want you to build it.  I encourage you to sign the &lt;a href="https://founderspledge.com/"&gt;Founders Pledge&lt;/a&gt; and donate the money to &lt;a href="https://www.effectivealtruism.org/"&gt;effective charities&lt;/a&gt; in case you actually end up making billions of dollars as a result of reading this.&lt;/p&gt;
&lt;p&gt;I apologize if you found the tone of this post overly sales-y.  My goal was to light a spark in the right person.  (Feel free to steal phrases from this post when pitching investors!)&lt;/p&gt;
&lt;p&gt;Some folks in the rationalist community might be a little underwhelmed by this idea, since people in the rationalist community have been living together in group houses for a long time.  The thing is, finding roommates by connecting based on mutual interests via the internet is still kind of weird in the eyes of the general public.  As Paul Graham &lt;a href="http://www.paulgraham.com/startupideas.html"&gt;put it&lt;/a&gt;: "Live in the future, then build what's missing."  The existence of so many lonely people proves that this option is still missing for most people.&lt;/p&gt;
&lt;p&gt;Anyway, if you're interested in building/investing in this, please comment below, or send me a private message via my &lt;a href="https://www.lesswrong.com/users/john_maxwell"&gt;user page&lt;/a&gt; with the country you're in and I'll put you in contact with others who message me.  (Edit: I might be slow to reply, sorry)&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Cross-posted from the &lt;a href="https://forum.effectivealtruism.org/posts/YNnG86WS8z8aYdBES/how-to-make-billions-of-dollars-reducing-loneliness"&gt;Effective Altruism Forum&lt;/a&gt;.  See also discussion on &lt;a href="https://news.ycombinator.com/item?id=20847752"&gt;Hacker News&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;&lt;a href="https://www.lesswrong.com/posts/FCXCXigp7byv2dM8D/how-to-make-billions-of-dollars-reducing-loneliness"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:22:01 UT
      </pubDate>
      <guid>
        https://www.lesswrong.com/posts/FCXCXigp7byv2dM8D/how-to-make-billions-of-dollars-reducing-loneliness
      </guid>
    </item>
    <item>
      <title>
        Understanding SAT by Implementing a Simple SAT Solver in Python
      </title>
      <link>
        https://sahandsaba.com/understanding-sat-by-implementing-a-simple-sat-solver-in-python.html
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;section id="content"&gt;
    &lt;header&gt;
        &lt;h2&gt;
            &lt;span&gt;Understanding SAT by Implementing a Simple SAT Solver in Python&lt;/span&gt;
        &lt;/h2&gt;
    &lt;/header&gt;

    

    &lt;div id="article-content"&gt;
      &lt;div id="introduction"&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;SAT is short for "satisfiability". Chances are you have heard of it or one of
its variants like 3-SAT in passing, especially in discussions of complexity and
NP-completeness. In this post, we will go into details of what it is all about,
why it is of such importance from both a theoretical and practical perspective,
and how to approach solving it by developing a simple Python SAT solver.  By
the end of this post, we will have a working SAT solver with a command-line
interface. The code for it is on GitHub: &lt;a href="https://github.com/sahands/simple-sat"&gt;https://github.com/sahands/simple-sat&lt;/a&gt;. Feel free to fork and contribute
improvements. Of course, our implementation will not be anywhere close to more
complicated SAT solvers implemented in C or C++, such as &lt;a href="https://github.com/niklasso/minisat"&gt;miniSAT&lt;/a&gt;. The focus here is on simplicity since
the code is to be an introduction to SAT and SAT solvers.&lt;/p&gt;
&lt;p&gt;Sections marked with &lt;sup&gt;*&lt;/sup&gt; are more theoretical and not required for
understanding the algorithm we will use. On the other hand, the rest of the
introduction section below can be skipped if you already know the problem
definition and relevant technical terms.&lt;/p&gt;
&lt;div id="non-technical-definitions-example"&gt;
&lt;h3&gt;Non-Technical Definitions &amp;amp; Example&lt;/h3&gt;
&lt;p&gt;Before we start with the definitions, you might be asking why SAT is written in
all capitals if it is not an acronym.  Well, great question. SAT happens to
fall under what are called &lt;em&gt;decision problems&lt;/em&gt; in computer science. What that
means is that the answer to a particular instance of the problem is either
"yes" or "no". Decision problems are often simply identified with the set of
inputs for which the answer is "yes", and that set is given a capitalized name.
For example, SAT is the set of all satisfiable CNF expressions, and PRIMES is
the set of all prime numbers (the decision problem in the latter is that of
primality; i.e. given the binary representation of number &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

, decide if
it is a prime or not). To go on a bit of a tangent, this is also the reason
that the title of the paper that introduced the AKS primality test (&lt;a href="https://www.cse.iitk.ac.in/users/manindra/algebra/primality_v6.pdf"&gt;"PRIMES is
in P"&lt;/a&gt;) is
not a silly grammar mistake; PRIMES is a set and the paper shows that it is in
P, which is the set of decision problems solvable in polynomial-time. This
naming style, as far as I know, is mainly due to Garey and Johnson's classic
&lt;a href="https://en.wikipedia.org/wiki/Computers_and_Intractability:_A_Guide_to_the_Theory_of_NP-Completeness"&gt;textbook on complexity theory&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;So, back to SAT. So far we mentioned that SAT is a decision problem, and
something about mysterious sounding "CNF expressions". Now, if you happen to
know your Boolean logic and already know all about satisfiability and CNF
expressions, then feel free to skip ahead to next section. The rest of this
section assumes no prior knowledge of logic. Like many other interesting
problems, there are a variety of ways of describing SAT, some more technical
and some less. Here I will provide a very non-technical description of the
problem that nonetheless is an accurate description.&lt;/p&gt;
&lt;p&gt;Assume you are in charge of elections in a society. Elections in this society
work as follows: there are &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 candidates, and any number of them, from
&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;0&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 (nobody) to &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 (everybody) can be elected as the result of the
elections. Each voter provides a list of candidates they want elected and
candidates they want not elected. For example, if we call the candidates A, B
and C, then one vote might be "A, B, not C". We say a voter will be &lt;em&gt;satisfied&lt;/em&gt;
with the results of the election if at least one of his/her preferences is met.
For example, the voter with the "A, B, not C" vote will be satisfied if either
A or B is elected, or if C is not elected. To be clear, that voter will be
happy even if nobody is elected (anarchy!) because one of the preferences is
"not C" which is met if we do not pick anyone. It's also possible to receive an
empty vote. We take this to mean that the voter will not be satisfied
regardless of who is elected.&lt;/p&gt;
&lt;p&gt;You are given all the votes, and your job is to determine if all the voters can
be satisfied or not, and if yes, provide at least one possible pick of
candidates that would satisfy everybody.&lt;/p&gt;
&lt;p&gt;We assume that each candidate is represented by a unique identifier that will
be a string in the input. For the votes, we will write just the string
representing candidate &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;x&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 to indicate the voter wants the candidate
elected, and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;∼&lt;/mo&gt;&lt;mrow&gt;&lt;/mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;\sim{}x&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 to indicate the voter wants &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;x&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 not elected.&lt;/p&gt;
&lt;p&gt;Let's look at an example. Assume the list of votes is given as follows, one per
line:&lt;/p&gt;

&lt;p&gt;Then choosing to elect just candidates &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;/mrow&gt;A&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;/mrow&gt;C&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 but not
&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;/mrow&gt;B&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 will satisfy all the voters. Take a moment to convince yourself that
no other choice of candidates (there are a total of &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/msup&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;8&lt;/mn&gt;&lt;/mrow&gt;2^3 = 8&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;


possibilities) can satisfy everyone. It is easy to see that in general
the search-space is of size &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/msup&gt;&lt;/mrow&gt;2^n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 where &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 is the number of
candidates.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="technical-terminology"&gt;
&lt;h3&gt;Technical Terminology&lt;/h3&gt;
&lt;p&gt;Now that the problem makes sense, let's define the technical
vocabulary. First, what we called "candidates" are called &lt;em&gt;variables&lt;/em&gt;. The
variables in the above example are &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;/mrow&gt;A&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

, &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;/mrow&gt;B&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;/mrow&gt;C&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

. A
variable can be assigned true or false. A &lt;em&gt;literal&lt;/em&gt; is a variable or its
negation. For example &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;/mrow&gt;A&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;∼&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;/mrow&gt;\sim A&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 are literals.  Literals
without the &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;∼&lt;/mo&gt;&lt;/mrow&gt;\sim&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 are called positive, pure, or unnegated literals.
Literals with &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;∼&lt;/mo&gt;&lt;/mrow&gt;\sim&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 are called negated literals. A set of literals is
called a &lt;em&gt;clause&lt;/em&gt;. An &lt;em&gt;assignment&lt;/em&gt; is a mapping of variables to true or false.
For example, the assignment that satisfied the clauses in the previous example
was given by &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;/mrow&gt;A = true&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

, &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;/mrow&gt;B = false&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;/mrow&gt;C = true&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

. A clause
is &lt;em&gt;satisfied&lt;/em&gt; by an assignment if at least one of its unnegated literals is
assigned true by the assignment, or one of its negated literals is assigned
false in the assignment.  It is customary, in logic notation, to separate the
literals in a clause using the &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;∨&lt;/mo&gt;&lt;/mrow&gt;\vee&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 symbol, read "or". For example, the
first clause above is written as &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;∨&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mtext&gt;&amp;nbsp;&lt;/mtext&gt;&lt;mo&gt;∨&lt;/mo&gt;&lt;mo&gt;∼&lt;/mo&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;/mrow&gt;A \vee B ~ \vee \sim C&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 in mathematical
notation.&lt;/p&gt;
&lt;p&gt;So SAT can be summarized as follows: given a list of clauses, determine if
there exists an assignment that satisfies all of them simultaneously.&lt;/p&gt;
&lt;p&gt;It is also worthy of mention that there is a variation of SAT called 3-SAT with
the restriction that each clause consists of at most 3 (distinct) literals.
It can be shown with relative ease that SAT is in fact reducible to 3-SAT.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="a-simple-sat-solver-in-python"&gt;
&lt;h2&gt;A Simple SAT Solver In Python&lt;/h2&gt;
&lt;p&gt;Even though SAT is NP-complete and therefore no known polynomial-time algorithm
for it is (yet) known, many improvements over the basic backtracking algorithms
have been made over the last few decades. However, here we will look at one of
the most basic yet relatively efficient algorithms for solving SAT. The encoding
and the algorithm are based on Knuth's SAT0W program which you can download
from his &lt;a href="https://www-cs-faculty.stanford.edu/~uno/programs.html"&gt;programs page&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The algorithm is a watch-list based backtracking algorithm. What makes the
watch-list based algorithms particularly simple, as we will see, is that very
little (practically nothing) needs to be done to "undo" steps taken when we
need to backtrack.&lt;/p&gt;
&lt;div id="parsing-encoding-the-input"&gt;
&lt;h3&gt;Parsing &amp;amp; Encoding The Input&lt;/h3&gt;
&lt;p&gt;Before we can approach solving a SAT instance, we need to be able to represent
the instance in memory. Let's remember that a SAT instance is a set of clauses,
and each clause is a set of literals. Finally, a literal is a variable that is
either negated or not. Of course, we can just store the instance as a list of
clauses, with each clause being a list of strings that are the literals. The
problem with this approach is that we will not be able to quickly look up
variables, and checking to see if a literal is negated or not, and negating it
if not, would be rather slow string operations.&lt;/p&gt;
&lt;p&gt;Instead, we will first assign a unique number, starting from &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;0&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 and
counting up, to each variable as we encounter them, using a dictionary to keep
track of the mapping. So variables will be encoded as numbers &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;0&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 to
&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;n-1&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 where &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 is the number of variables.  Then for an unnegated
literal with variable encoded as number &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;x&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 we will encode the literal as
&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;2x&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

, and the negated one will be &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;2x + 1&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

. Then a clause will
simply be a list of numbers that are the encoded literals, and&lt;/p&gt;
&lt;p&gt;Let's look at an example first. For this, let's see how the code that we will
look at in a minute behaves:&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span&gt;from&lt;/span&gt; &lt;span&gt;satinstance&lt;/span&gt; &lt;span&gt;import&lt;/span&gt; &lt;span&gt;SATInstance&lt;/span&gt;
&lt;span&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span&gt;s&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;SATInstance&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;
&lt;span&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span&gt;s&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;parse_and_add_clause&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;'A B ~C'&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
&lt;span&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span&gt;s&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;variables&lt;/span&gt;
&lt;span&gt;['A', 'B', 'C']&lt;/span&gt;
&lt;span&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span&gt;s&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;variable_table&lt;/span&gt;
&lt;span&gt;{'A': 0, 'C': 2, 'B': 1}&lt;/span&gt;
&lt;span&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span&gt;s&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;clauses&lt;/span&gt;
&lt;span&gt;[(0, 2, 5)]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;So as you see, the clause &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;∨&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mo&gt;∨&lt;/mo&gt;&lt;mo&gt;∼&lt;/mo&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;/mrow&gt;A \vee B \vee \sim C&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 is encoded as the tuple
&lt;tt&gt;(0, 2, 5)&lt;/tt&gt; since variable &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;/mrow&gt;A&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 is assigned number &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;0&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

, and hence
literal &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;/mrow&gt;A&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 is &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo&gt;⋅&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;2 \cdot 0 =0&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

. On the other hand, &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;∼&lt;/mo&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;/mrow&gt;\sim C&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 is
encoded as &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;5&lt;/mn&gt;&lt;/mrow&gt;5&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 since &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;/mrow&gt;C&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 is assigned &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mrow&gt;2&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 and hence
&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;∼&lt;/mo&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;/mrow&gt;\sim C&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 is encoded as &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo&gt;⋅&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;5&lt;/mn&gt;&lt;/mrow&gt;2 \cdot 2 + 1 = 5&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

.&lt;/p&gt;
&lt;p&gt;Why the funny encoding, you ask? Because it has a few advantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;we can keep track of variables by keeping a list of length &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

, and of
literals by keeping a list of length &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;2n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

,&lt;/li&gt;
&lt;li&gt;checking to see if a literal is negated or not is simple: just do a bit-wise
AND with &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;1&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

, that is &lt;tt&gt;x &amp;amp; 1 == 0&lt;/tt&gt;,&lt;/li&gt;
&lt;li&gt;looking up the variable in a literal is a matter of dividing by two, which is
the same as a bit-wise shift to the right, that is &lt;tt&gt;v = x &amp;gt;&amp;gt; 1&lt;/tt&gt;,&lt;/li&gt;
&lt;li&gt;switching a literal from negated to unnegated and back can be done by doing a
bit-wise XOR with the number one, that is &lt;tt&gt;negate(x) = x ^ 1&lt;/tt&gt;,&lt;/li&gt;
&lt;li&gt;and finally going from a variable to a literal can be done by doing a
bit-wise shift to the right (and a bit-wise OR with 1 if negated), that is
&lt;tt&gt;x = v &amp;lt;&amp;lt; 1&lt;/tt&gt; or &lt;tt&gt;x = v &amp;lt;&amp;lt; 1 | 1&lt;/tt&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Notice that all of the above can be done using bit-wise operations which are
generally very fast to do. And since these operations will be happening an
exponential number of times, we will take any performance boost we can get.&lt;/p&gt;
&lt;p&gt;With this, we are ready to write the code that takes care of reading an input
file and encoding the clauses. Here it is:&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;SATInstance&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;object&lt;/span&gt;&lt;span&gt;):&lt;/span&gt;
    &lt;span&gt;def&lt;/span&gt; &lt;span&gt;parse_and_add_clause&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;self&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;line&lt;/span&gt;&lt;span&gt;):&lt;/span&gt;
        &lt;span&gt;clause&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;[]&lt;/span&gt;
        &lt;span&gt;for&lt;/span&gt; &lt;span&gt;literal&lt;/span&gt; &lt;span&gt;in&lt;/span&gt; &lt;span&gt;line&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;split&lt;/span&gt;&lt;span&gt;():&lt;/span&gt;
            &lt;span&gt;negated&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;1&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;literal&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;startswith&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;'~'&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;else&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;
            &lt;span&gt;variable&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;literal&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;negated&lt;/span&gt;&lt;span&gt;:]&lt;/span&gt;
            &lt;span&gt;if&lt;/span&gt; &lt;span&gt;variable&lt;/span&gt; &lt;span&gt;not&lt;/span&gt; &lt;span&gt;in&lt;/span&gt; &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;variable_table&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;
                &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;variable_table&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;variable&lt;/span&gt;&lt;span&gt;]&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;len&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;variables&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
                &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;variables&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;variable&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
            &lt;span&gt;encoded_literal&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;variable_table&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;variable&lt;/span&gt;&lt;span&gt;]&lt;/span&gt; &lt;span&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span&gt;1&lt;/span&gt; &lt;span&gt;|&lt;/span&gt; &lt;span&gt;negated&lt;/span&gt;
            &lt;span&gt;clause&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;encoded_literal&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
        &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;clauses&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;tuple&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;set&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;clause&lt;/span&gt;&lt;span&gt;)))&lt;/span&gt;

    &lt;span&gt;def&lt;/span&gt; &lt;span&gt;__init__&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;self&lt;/span&gt;&lt;span&gt;):&lt;/span&gt;
        &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;variables&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;[]&lt;/span&gt;
        &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;variable_table&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;dict&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;
        &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;clauses&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;[]&lt;/span&gt;

    &lt;span&gt;@classmethod&lt;/span&gt;
    &lt;span&gt;def&lt;/span&gt; &lt;span&gt;from_file&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;cls&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;file&lt;/span&gt;&lt;span&gt;):&lt;/span&gt;
        &lt;span&gt;instance&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;cls&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;
        &lt;span&gt;for&lt;/span&gt; &lt;span&gt;line&lt;/span&gt; &lt;span&gt;in&lt;/span&gt; &lt;span&gt;file&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;
            &lt;span&gt;line&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;line&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;strip&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;
            &lt;span&gt;if&lt;/span&gt; &lt;span&gt;len&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;line&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;0&lt;/span&gt; &lt;span&gt;and&lt;/span&gt; &lt;span&gt;not&lt;/span&gt; &lt;span&gt;line&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;startswith&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;'#'&lt;/span&gt;&lt;span&gt;):&lt;/span&gt;
                &lt;span&gt;instance&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;parse_and_add_clause&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;line&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
        &lt;span&gt;return&lt;/span&gt; &lt;span&gt;instance&lt;/span&gt;

    &lt;span&gt;def&lt;/span&gt; &lt;span&gt;literal_to_string&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;self&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;literal&lt;/span&gt;&lt;span&gt;):&lt;/span&gt;
        &lt;span&gt;s&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'~'&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;literal&lt;/span&gt; &lt;span&gt;&amp;amp;&lt;/span&gt; &lt;span&gt;1&lt;/span&gt; &lt;span&gt;else&lt;/span&gt; &lt;span&gt;''&lt;/span&gt;
        &lt;span&gt;return&lt;/span&gt; &lt;span&gt;s&lt;/span&gt; &lt;span&gt;+&lt;/span&gt; &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;variables&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;literal&lt;/span&gt; &lt;span&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;]&lt;/span&gt;

    &lt;span&gt;def&lt;/span&gt; &lt;span&gt;clause_to_string&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;self&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;clause&lt;/span&gt;&lt;span&gt;):&lt;/span&gt;
        &lt;span&gt;return&lt;/span&gt; &lt;span&gt;' '&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;join&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;literal_to_string&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;l&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;for&lt;/span&gt; &lt;span&gt;l&lt;/span&gt; &lt;span&gt;in&lt;/span&gt; &lt;span&gt;clause&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;

    &lt;span&gt;def&lt;/span&gt; &lt;span&gt;assignment_to_string&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;self&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;assignment&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;brief&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;False&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;starting_with&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;''&lt;/span&gt;&lt;span&gt;):&lt;/span&gt;
        &lt;span&gt;literals&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;[]&lt;/span&gt;
        &lt;span&gt;for&lt;/span&gt; &lt;span&gt;a&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;v&lt;/span&gt; &lt;span&gt;in&lt;/span&gt; &lt;span&gt;((&lt;/span&gt;&lt;span&gt;a&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;v&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;for&lt;/span&gt; &lt;span&gt;a&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;v&lt;/span&gt; &lt;span&gt;in&lt;/span&gt; &lt;span&gt;zip&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;assignment&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;variables&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
                     &lt;span&gt;if&lt;/span&gt; &lt;span&gt;v&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;startswith&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;starting_with&lt;/span&gt;&lt;span&gt;)):&lt;/span&gt;
            &lt;span&gt;if&lt;/span&gt; &lt;span&gt;a&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;0&lt;/span&gt; &lt;span&gt;and&lt;/span&gt; &lt;span&gt;not&lt;/span&gt; &lt;span&gt;brief&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;
                &lt;span&gt;literals&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;'~'&lt;/span&gt; &lt;span&gt;+&lt;/span&gt; &lt;span&gt;v&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
            &lt;span&gt;elif&lt;/span&gt; &lt;span&gt;a&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;
                &lt;span&gt;literals&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;v&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
        &lt;span&gt;return&lt;/span&gt; &lt;span&gt;' '&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;join&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;literals&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As you can see, we also include methods here to decode variables, literals,
clauses, and assignments. These are used for outputting logging messages as
well as the final solutions.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="keeping-track-of-the-assignment"&gt;
&lt;h3&gt;Keeping Track Of The Assignment&lt;/h3&gt;
&lt;p&gt;Our algorithm will be a backtracking algorithm, in which we will assign true or
false to all the variables, starting from variable &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;0&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 and going in order to
variable &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;n-1&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

. Of course, the basic search space is of size &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/msup&gt;&lt;/mrow&gt;2^n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 but by
pruning, we will not explore the whole space (usually anyway). The assignment
will be kept as a list of length &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

, with item at index &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/mrow&gt;i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 being
&lt;tt&gt;None&lt;/tt&gt; if neither true or false has been assigned variable &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/mrow&gt;i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

, and
&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;0&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 (false) or &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;1&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 (true) otherwise, depending on the assignment.
When we backtrack, we set the corresponding item in the assignment list back to
&lt;tt&gt;None&lt;/tt&gt; to indicate it is no longer assigned.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="watch-lists"&gt;
&lt;h3&gt;Watch-lists&lt;/h3&gt;
&lt;p&gt;Now that we have the encoding in place, and know how to keep track of the
assignment, let's look at the key idea of our algorithm. For each clause to be
satisfied, it needs to have at least one of its literals satisfied. As such, we
can make each clause &lt;em&gt;watch&lt;/em&gt; one of its literals, and ensure that the following
invariant is maintained throughout our algorithm:&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;Invariant&lt;/dt&gt;
&lt;dd&gt;All watched literals are either not assigned yet, or they have been
assigned true.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;We then proceed to assign true or false to variables, starting from &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;0&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 to
&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;n-1&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

. If we successfully assign true or false to every variable while
maintaining the above variant, then we have an assignment that satisfies every
clause.&lt;/p&gt;
&lt;p&gt;To maintain this invariant, any time we assign true or false to a variable, we
ensure to update the watch-list accordingly. To do this efficiently, we need to
keep a list of clauses that are currently watching a given literal. This is
done in the code below using a list of length &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;2n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 of double-ended queue
(&lt;tt&gt;collections.deque&lt;/tt&gt;), with each clause initially watching the first literal in
it. The function below takes care of this setting up of the watch-list:&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;def&lt;/span&gt; &lt;span&gt;setup_watchlist&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;instance&lt;/span&gt;&lt;span&gt;):&lt;/span&gt;
    &lt;span&gt;watchlist&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;deque&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;for&lt;/span&gt; &lt;span&gt;__&lt;/span&gt; &lt;span&gt;in&lt;/span&gt; &lt;span&gt;range&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; &lt;span&gt;len&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;instance&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;variables&lt;/span&gt;&lt;span&gt;))]&lt;/span&gt;
    &lt;span&gt;for&lt;/span&gt; &lt;span&gt;clause&lt;/span&gt; &lt;span&gt;in&lt;/span&gt; &lt;span&gt;instance&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;clauses&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;
        &lt;span&gt;# Make the clause watch its first literal&lt;/span&gt;
        &lt;span&gt;watchlist&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;clause&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;]]&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;clause&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;watchlist&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Why double-ended queues instead of just a list? Short answer is that after
experimenting, I found out that double-ended queues provided the best
performance.&lt;/p&gt;
&lt;p&gt;Back to the algorithm, whenever we assign true to a variable &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;x&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 we must
make clauses watching &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;∼&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;\sim x&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 watch something else. And
similarly, whenever we assign false to a variable &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;x&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 we make clauses watching
&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;x&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 watch something else. If we can not make a clause watch something, which
happens when all the other literals in a clause have already been assigned
false, then we know that the current assignment contradicts the clause, and we
stop and backtrack. We only need one clause to be contradicted to know not to
go any further. As such, the heart of our algorithm will be where we update the
watch-list after an assignment has been made. The Python function below, which
is in (&lt;tt&gt;watchlist.py&lt;/tt&gt;), implements this part of the algorithm:&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;def&lt;/span&gt; &lt;span&gt;update_watchlist&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;instance&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
                     &lt;span&gt;watchlist&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
                     &lt;span&gt;false_literal&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
                     &lt;span&gt;assignment&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
                     &lt;span&gt;verbose&lt;/span&gt;&lt;span&gt;):&lt;/span&gt;
    &lt;span&gt;"""&lt;/span&gt;
&lt;span&gt;    Updates the watch list after literal 'false_literal' was just assigned&lt;/span&gt;
&lt;span&gt;    False, by making any clause watching false_literal watch something else.&lt;/span&gt;
&lt;span&gt;    Returns False it is impossible to do so, meaning a clause is contradicted&lt;/span&gt;
&lt;span&gt;    by the current assignment.&lt;/span&gt;
&lt;span&gt;    """&lt;/span&gt;
    &lt;span&gt;while&lt;/span&gt; &lt;span&gt;watchlist&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;false_literal&lt;/span&gt;&lt;span&gt;]:&lt;/span&gt;
        &lt;span&gt;clause&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;watchlist&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;false_literal&lt;/span&gt;&lt;span&gt;][&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;]&lt;/span&gt;
        &lt;span&gt;found_alternative&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;False&lt;/span&gt;
        &lt;span&gt;for&lt;/span&gt; &lt;span&gt;alternative&lt;/span&gt; &lt;span&gt;in&lt;/span&gt; &lt;span&gt;clause&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;
            &lt;span&gt;v&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;alternative&lt;/span&gt; &lt;span&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;
            &lt;span&gt;a&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;alternative&lt;/span&gt; &lt;span&gt;&amp;amp;&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;
            &lt;span&gt;if&lt;/span&gt; &lt;span&gt;assignment&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;v&lt;/span&gt;&lt;span&gt;]&lt;/span&gt; &lt;span&gt;is&lt;/span&gt; &lt;span&gt;None&lt;/span&gt; &lt;span&gt;or&lt;/span&gt; &lt;span&gt;assignment&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;v&lt;/span&gt;&lt;span&gt;]&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;a&lt;/span&gt; &lt;span&gt;^&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;
                &lt;span&gt;found_alternative&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;True&lt;/span&gt;
                &lt;span&gt;del&lt;/span&gt; &lt;span&gt;watchlist&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;false_literal&lt;/span&gt;&lt;span&gt;][&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;]&lt;/span&gt;
                &lt;span&gt;watchlist&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;alternative&lt;/span&gt;&lt;span&gt;]&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;clause&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
                &lt;span&gt;break&lt;/span&gt;

        &lt;span&gt;if&lt;/span&gt; &lt;span&gt;not&lt;/span&gt; &lt;span&gt;found_alternative&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;
            &lt;span&gt;if&lt;/span&gt; &lt;span&gt;verbose&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;
                &lt;span&gt;dump_watchlist&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;instance&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;watchlist&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
                &lt;span&gt;print&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;'Current assignment: {}'&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;format&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;
                      &lt;span&gt;instance&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;assignment_to_string&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;assignment&lt;/span&gt;&lt;span&gt;)),&lt;/span&gt;
                      &lt;span&gt;file&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;stderr&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
                &lt;span&gt;print&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;'Clause {} contradicted.'&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;format&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;
                      &lt;span&gt;instance&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;clause_to_string&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;clause&lt;/span&gt;&lt;span&gt;)),&lt;/span&gt;
                      &lt;span&gt;file&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;stderr&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
            &lt;span&gt;return&lt;/span&gt; &lt;span&gt;False&lt;/span&gt;
    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;True&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;So why the watch-list based approach? The main reason is the simplicity it
affords us. Since during a backtracking step, assignments only go from &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;0&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 or
&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;1&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 to &lt;tt&gt;None&lt;/tt&gt;, the watch-list does not need to be updated at all to maintain
the invariant. This means the backtracking step will simply be changing the
assignment of a variable back to &lt;tt&gt;None&lt;/tt&gt; and that's it.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="putting-it-all-together"&gt;
&lt;h3&gt;Putting It All Together&lt;/h3&gt;
&lt;p&gt;We are now ready to put it all together to get a simple recursive algorithm for
solving SAT. The steps are simple: try assigning &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;0&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 to variable
&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;/mrow&gt;d&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

, update the watch-list, if successful, move on to variable
&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;d+1&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

. If not successful, try assigning &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;1&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 to variable &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;/mrow&gt;d&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;


and update the watch-list and continue to variable &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;d+1&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

. If neither
succeed, assign &lt;tt&gt;None&lt;/tt&gt; to variable &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;/mrow&gt;d&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 and backtrack. Here is the code:&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;def&lt;/span&gt; &lt;span&gt;solve&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;instance&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;watchlist&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;assignment&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;d&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;verbose&lt;/span&gt;&lt;span&gt;):&lt;/span&gt;
    &lt;span&gt;"""&lt;/span&gt;
&lt;span&gt;    Recursively solve SAT by assigning to variables d, d+1, ..., n-1. Assumes&lt;/span&gt;
&lt;span&gt;    variables 0, ..., d-1 are assigned so far. A generator for all the&lt;/span&gt;
&lt;span&gt;    satisfying assignments is returned.&lt;/span&gt;
&lt;span&gt;    """&lt;/span&gt;
    &lt;span&gt;if&lt;/span&gt; &lt;span&gt;d&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;len&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;instance&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;variables&lt;/span&gt;&lt;span&gt;):&lt;/span&gt;
        &lt;span&gt;yield&lt;/span&gt; &lt;span&gt;assignment&lt;/span&gt;
        &lt;span&gt;return&lt;/span&gt;

    &lt;span&gt;for&lt;/span&gt; &lt;span&gt;a&lt;/span&gt; &lt;span&gt;in&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;]:&lt;/span&gt;
        &lt;span&gt;if&lt;/span&gt; &lt;span&gt;verbose&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;
            &lt;span&gt;print&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;'Trying {} = {}'&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;format&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;instance&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;variables&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;d&lt;/span&gt;&lt;span&gt;],&lt;/span&gt; &lt;span&gt;a&lt;/span&gt;&lt;span&gt;),&lt;/span&gt;
                  &lt;span&gt;file&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;stderr&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
        &lt;span&gt;assignment&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;d&lt;/span&gt;&lt;span&gt;]&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;a&lt;/span&gt;
        &lt;span&gt;if&lt;/span&gt; &lt;span&gt;update_watchlist&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;instance&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
                            &lt;span&gt;watchlist&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
                            &lt;span&gt;(&lt;/span&gt;&lt;span&gt;d&lt;/span&gt; &lt;span&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;|&lt;/span&gt; &lt;span&gt;a&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
                            &lt;span&gt;assignment&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
                            &lt;span&gt;verbose&lt;/span&gt;&lt;span&gt;):&lt;/span&gt;
            &lt;span&gt;for&lt;/span&gt; &lt;span&gt;a&lt;/span&gt; &lt;span&gt;in&lt;/span&gt; &lt;span&gt;solve&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;instance&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;watchlist&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;assignment&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;d&lt;/span&gt; &lt;span&gt;+&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;verbose&lt;/span&gt;&lt;span&gt;):&lt;/span&gt;
                &lt;span&gt;yield&lt;/span&gt; &lt;span&gt;a&lt;/span&gt;

    &lt;span&gt;assignment&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;d&lt;/span&gt;&lt;span&gt;]&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;None&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div id="making-it-iterative"&gt;
&lt;h3&gt;Making It Iterative &lt;sup&gt;*&lt;/sup&gt;&lt;/h3&gt;
&lt;p&gt;For fun, let's see if we can implement the above algorithm without recursion.
This is in fact how Knuth implements the algorithm. (He seems to dislike
recursion, see for example &lt;a href="https://www.quora.com/Stanford-University/What-is-it-like-to-be-in-a-class-taught-by-Donald-Knuth"&gt;this story on Quora&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;The basic idea here is to manually keep track of the current state of the
backtrack tree. When we use recursion, the state is kept implicitly using the
stack and which instruction is executing in each of the function calls. In the
iterative case, we will store the state using &lt;tt&gt;d&lt;/tt&gt; which is the current depth
of the backtrack tree we are currently in, and also the variable we are to
assign to currently, and the &lt;tt&gt;state&lt;/tt&gt; list which keeps track of which
assignments for each variable have been tried so far. Here is the code:&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;def&lt;/span&gt; &lt;span&gt;solve&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;instance&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;watchlist&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;assignment&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;d&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;verbose&lt;/span&gt;&lt;span&gt;):&lt;/span&gt;
    &lt;span&gt;"""&lt;/span&gt;
&lt;span&gt;    Iteratively solve SAT by assigning to variables d, d+1, ..., n-1. Assumes&lt;/span&gt;
&lt;span&gt;    variables 0, ..., d-1 are assigned so far. A generator for all the&lt;/span&gt;
&lt;span&gt;    satisfying assignments is returned.&lt;/span&gt;
&lt;span&gt;    """&lt;/span&gt;

    &lt;span&gt;# The state list wil keep track of what values for which variables&lt;/span&gt;
    &lt;span&gt;# we have tried so far. A value of 0 means nothing has been tried yet,&lt;/span&gt;
    &lt;span&gt;# a value of 1 means False has been tried but not True, 2 means True but&lt;/span&gt;
    &lt;span&gt;# not False, and 3 means both have been tried.&lt;/span&gt;
    &lt;span&gt;n&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;len&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;instance&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;variables&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
    &lt;span&gt;state&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;]&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; &lt;span&gt;n&lt;/span&gt;

    &lt;span&gt;while&lt;/span&gt; &lt;span&gt;True&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;
        &lt;span&gt;if&lt;/span&gt; &lt;span&gt;d&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;n&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;
            &lt;span&gt;yield&lt;/span&gt; &lt;span&gt;assignment&lt;/span&gt;
            &lt;span&gt;d&lt;/span&gt; &lt;span&gt;-=&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;
            &lt;span&gt;continue&lt;/span&gt;
        &lt;span&gt;# Let's try assigning a value to v. Here would be the place to insert&lt;/span&gt;
        &lt;span&gt;# heuristics of which value to try first.&lt;/span&gt;
        &lt;span&gt;tried_something&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;False&lt;/span&gt;
        &lt;span&gt;for&lt;/span&gt; &lt;span&gt;a&lt;/span&gt; &lt;span&gt;in&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;]:&lt;/span&gt;
            &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;state&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;d&lt;/span&gt;&lt;span&gt;]&lt;/span&gt; &lt;span&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span&gt;a&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;&amp;amp;&lt;/span&gt; &lt;span&gt;1&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;
                &lt;span&gt;if&lt;/span&gt; &lt;span&gt;verbose&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;
                    &lt;span&gt;print&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;'Trying {} = {}'&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;format&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;instance&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;variables&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;d&lt;/span&gt;&lt;span&gt;],&lt;/span&gt; &lt;span&gt;a&lt;/span&gt;&lt;span&gt;),&lt;/span&gt;
                          &lt;span&gt;file&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;stderr&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
                &lt;span&gt;tried_something&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;True&lt;/span&gt;
                &lt;span&gt;# Set the bit indicating a has been tried for d&lt;/span&gt;
                &lt;span&gt;state&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;d&lt;/span&gt;&lt;span&gt;]&lt;/span&gt; &lt;span&gt;|=&lt;/span&gt; &lt;span&gt;1&lt;/span&gt; &lt;span&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span&gt;a&lt;/span&gt;
                &lt;span&gt;assignment&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;d&lt;/span&gt;&lt;span&gt;]&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;a&lt;/span&gt;
                &lt;span&gt;if&lt;/span&gt; &lt;span&gt;not&lt;/span&gt; &lt;span&gt;update_watchlist&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;instance&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;watchlist&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
                                        &lt;span&gt;d&lt;/span&gt; &lt;span&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span&gt;1&lt;/span&gt; &lt;span&gt;|&lt;/span&gt; &lt;span&gt;a&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
                                        &lt;span&gt;assignment&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
                                        &lt;span&gt;verbose&lt;/span&gt;&lt;span&gt;):&lt;/span&gt;
                    &lt;span&gt;assignment&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;d&lt;/span&gt;&lt;span&gt;]&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;None&lt;/span&gt;
                &lt;span&gt;else&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;
                    &lt;span&gt;d&lt;/span&gt; &lt;span&gt;+=&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;
                    &lt;span&gt;break&lt;/span&gt;

        &lt;span&gt;if&lt;/span&gt; &lt;span&gt;not&lt;/span&gt; &lt;span&gt;tried_something&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;
            &lt;span&gt;if&lt;/span&gt; &lt;span&gt;d&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;
                &lt;span&gt;# Can't backtrack further. No solutions.&lt;/span&gt;
                &lt;span&gt;return&lt;/span&gt;
            &lt;span&gt;else&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;
                &lt;span&gt;# Backtrack&lt;/span&gt;
                &lt;span&gt;state&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;d&lt;/span&gt;&lt;span&gt;]&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;
                &lt;span&gt;assignment&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;d&lt;/span&gt;&lt;span&gt;]&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;None&lt;/span&gt;
                &lt;span&gt;d&lt;/span&gt; &lt;span&gt;-=&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="theoretical-and-practical-significance"&gt;
&lt;h2&gt;Theoretical and Practical Significance &lt;sup&gt;*&lt;/sup&gt;&lt;/h2&gt;
&lt;p&gt;All right, so SAT is a cool problem, sure; possibly even useful. But why is
it given so much importance? The short answer is that many other problems,
often "difficult" problems, can be reduced to SAT. Let's consider an example
first, and then look at Stephen Cook's result that established SAT as the first
NP-complete problem, to get a sense of both practical applications of SAT, and
its theoretical importance.&lt;/p&gt;
&lt;div id="four-colouring"&gt;
&lt;h3&gt;Four Colouring &lt;sup&gt;*&lt;/sup&gt;&lt;/h3&gt;
&lt;p&gt;You might have heard of the "four colour theorem". In simplest terms, it states
that the regions in any map can be coloured using at most four colours
such that no two neighbouring regions are coloured the same. See the &lt;a href="https://en.wikipedia.org/wiki/Four_colour_theorem"&gt;Wikipedia
page&lt;/a&gt; on it for more
details.&lt;/p&gt;
&lt;p&gt;This lends itself to a simple decision problem: given a map, is it possible to
colour it using 4 or less colours such that no two neighbouring regions are
the same colour? The four colour theorem is then true if and only if the answer
to this decision problem is always true (provided the input map meets the
requirements of a planar graph, a detail we are not too concerned with here).
As input, we will take the number of regions &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

, and assume the regions
are labelled using numbers &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;1&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 to &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

, and a list of neighbouring
regions of the form &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;{&lt;/mo&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo separator="true"&gt;,&lt;/mo&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;mo&gt;}&lt;/mo&gt;&lt;/mrow&gt;\{i, j\}&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 with &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;̸&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/mrow&gt;i \ne j&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

, indicating regions
&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/mrow&gt;i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/mrow&gt;j&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 are neighbours. Let us use colours red (R), blue (B),
green (G), and yellow (Y) to colour the regions. Our variables are going to be
&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;R_i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

, &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;B_i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

, &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;G&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;G_i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;Y_i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

, for &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;1 \le i \le
n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

, indicating that region &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/mrow&gt;i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 is coloured red, blue, green, or yellow,
respectively.&lt;/p&gt;
&lt;p&gt;Next, we need to construct the right set of clauses such that if all of
them are satisfied, then we have a proper colouring of the map. Specifically, we
need every region to be coloured, and we need no two neighbouring regions to be
the same colour. First, let us construct the clauses that will make sure every
region has one and only one colour assigned to it. For this, we need to make sure
only one of &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;R_i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

, &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;B_i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

, &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;G&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;G_i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 or &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;Y_i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 is picked for
our assignment at a time. We can express this in terms of  &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;/mrow&gt;K&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 clauses for
each region &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/mrow&gt;i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

. First, we add &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;∨&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;∨&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;G&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;∨&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;R_i \vee B_i \vee G_i \vee Y_i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 as
a clause, which ensures that region &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/mrow&gt;i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 gets at least one colour assigned
to it. Then for pair of colours, say &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;/mrow&gt;R&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;/mrow&gt;B&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

, we add the clause
&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;∼&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;∨&lt;/mo&gt;&lt;mo&gt;∼&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;\sim R_i \vee \sim B_i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 which basically says "not both of &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;R_i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;


and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;B_i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 can be picked at the same time", effectively making sure that
exactly one colour is assigned to each region. Finally, for any two
neighbouring regions, say &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/mrow&gt;i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/mrow&gt;j&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

, and each colour, say
&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;/mrow&gt;R&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

, we add the clause &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;∼&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;∨&lt;/mo&gt;&lt;mo&gt;∼&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;\sim R_i \vee \sim R_j&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 which says not both
of &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/mrow&gt;i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/mrow&gt;j&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 can be coloured red.&lt;/p&gt;
&lt;p&gt;Let's look at a very simple example. Suppose our map has only two regions,
regions &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;1&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mrow&gt;2&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 and that they are neighbours. Then our SAT
input would be:&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;# Assign at least one colour to region 1&lt;/span&gt;
R1 B1 G1 Y1

&lt;span&gt;# But no more than one colour&lt;/span&gt;
~R1 ~B1
~R1 ~G1
~R1 ~Y1
~B1 ~G1
~B1 ~Y1
~G1 ~Y1

&lt;span&gt;# Similarly for region 2&lt;/span&gt;
R2 B2 G2 Y2
~R2 ~B2
~R2 ~G2
~R2 ~Y2
~B2 ~G2
~B2 ~Y2
~G2 ~Y2

&lt;span&gt;# Make sure regions 1 and 2 are not coloured the same since they are neighbours&lt;/span&gt;
~R1 ~R2
~B1 ~B2
~G1 ~G2
~Y1 ~Y2
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Running this through our SAT solver gives:&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ python sat.py --brief --all &amp;lt; tests/colouring/01.in
Y1 G2
Y1 B2
Y1 R2
G1 Y2
G1 B2
G1 R2
B1 Y2
B1 G2
B1 R2
R1 Y2
R1 G2
R1 B2
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As you can see, there are many possible solutions, since in such a simple case
we have a valid colouring as long as we assign a different colour to each
region, which can be done in &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;mo&gt;⋅&lt;/mo&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;12&lt;/mn&gt;&lt;/mrow&gt;4 \cdot 3 = 12&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 ways, corresponding
precisely to the &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;12&lt;/mn&gt;&lt;/mrow&gt;12&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 solutions given by our SAT solver.&lt;/p&gt;
&lt;p&gt;In the next section, we see that a much broader set of problems can be reduced
to SAT.&lt;/p&gt;
&lt;p&gt;In general, the decision problem of the above example is known as graph
colouring, or GT4 in Garey-Johnson's naming, where given a graph and a number
&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/mrow&gt;k&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 the decision problem is to determine if a &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/mrow&gt;k&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

-colouring for the
graph exists.  In the above, we had &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;4.&lt;/mn&gt;&lt;/mrow&gt;k=4.&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 In this more general
definition, with &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 regions, our reduction to SAT involves introducing
&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;⋅&lt;/mo&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;k\cdot n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 variables and&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;⋅&lt;/mo&gt;&lt;mrow&gt;&lt;mo fence="true"&gt;(&lt;/mo&gt;&lt;mfrac linethickness="0px"&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mfrac&gt;&lt;mo fence="true"&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;⋅&lt;/mo&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;/mrow&gt;
1 + n \cdot \binom{k}{2} + k \cdot e
&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;clauses, where &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;/mrow&gt;e&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 is the number of edges.  Since &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;e = O(n^2)&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 (in
fact, &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;e = O(n)&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 for planar graphs), the number of variables and clauses
in our construction above are polynomials in &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/mrow&gt;k&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

.  Hence we
have a polynomial-time reduction to SAT.  The significance of this is discussed
further in the next section.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="np-completeness-of-sat"&gt;
&lt;h3&gt;NP-Completeness Of SAT &lt;sup&gt;*&lt;/sup&gt;&lt;/h3&gt;
&lt;p&gt;In previous section we saw how a problem regarding colouring of regions in a
map can be reduced to SAT. This can be further generalized to much larger class
of problems: any decision problem that can be decided in polynomial time using
a non-deterministic Turing machine can be reduced in polynomial time to
SAT. This was first proved in Stephen Cook's paper &lt;a href="http://4mhz.de/cook.html"&gt;"The Complexity of
Theorem-Proving Procedures"&lt;/a&gt;, which is the paper
that introduced the famous P = NP question as well. Let's go over the basic
idea in the paper very briefly here. If you are interested in more details,
make sure you have a look at the paper, as it is rather short and a pleasure to
read.&lt;/p&gt;
&lt;p&gt;But before we go into detail, let us take a moment to discuss why it is of such
importance. First, nobody has yet come up with an efficient (polynomial time)
algorithm to solve SAT in its generality. (SAT with some restrictions, e.g.
2-SAT, can be solved efficiently though.) Showing that a problem can be reduced
to SAT means that if we find an efficient algorithm for SAT then we have found
an efficient algorithm for that problem as well. For example, if we find a
polynomial-time algorithm for SAT then we immediately have a polynomial-time
algorithm for the graph colouring problem given above.&lt;/p&gt;
&lt;p&gt;Now, the class of decision problems that can be solved in polynomial-time using
a non-deterministic Turing machine is known as NP (which stands for
Non-deterministic Polynomial). This is a very large class of problems, since
Turing machines are one of the most general computational models we have, and
even though we are limited to polynomial-time Turing machines, the fact that
the Turing machine does not have to be deterministic allows us much more
freedom. Some examples of problems that are in NP are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;all problems in P, e.g. determining if a number is prime or not (PRIMES), and
decision versions of shortest path, network flow, etc.,&lt;/li&gt;
&lt;li&gt;integer factorization,&lt;/li&gt;
&lt;li&gt;graph colouring,&lt;/li&gt;
&lt;li&gt;SAT,&lt;/li&gt;
&lt;li&gt;and all NP-complete problems (see &lt;a href="https://en.wikipedia.org/wiki/List_of_NP-complete_problems"&gt;here&lt;/a&gt; for a rather
large list of examples).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A problem is said to be NP-complete if it, in addition to being in NP, also has
the property that any other problem in NP can be reduced to it in
polynomial-time. Cook's paper proved SAT to be NP-complete. In fact, since that
paper introduced the concept of NP-completeness, SAT was the first problem
to be proved NP-complete. Since then, many other problems have been shown to be
NP-complete, often by showing that SAT (or 3-SAT) can be reduced in
polynomial-time to those problems (converse of what we proved earlier for
graph colouring).&lt;/p&gt;
&lt;p&gt;Now, as promised, let's briefly look at why SAT is NP-complete. For this, we
need to know more precisely what a Turing machine is. Unfortunately, this would
involve a bit more detail than I want to include in this section. So instead, I
am going to show that if a problem can be solved using a finite-state machine
(FSM) then it be reduced in polynomial-time to SAT. The case for Turing
machines, which are a generalizations of finite-state machines (Turing machines
are basically FSM's with the addition of a tape that they can read from and
write to), is quite similar, just more complicated. I encourage you to read
Cook's original paper for details of the proof with Turing machines.&lt;/p&gt;
&lt;p&gt;First, let's define what an FSM is. In simplest terms, an FSM is a program that
has a finite number of states, and that when fed an input character, moves to
another state (or possibly stays in the same state) based on a fixed set of
rules.  Also, some states are taken as "accepting" states. Given an input
string, we feed the string character by character into the FSM, and if at the
end the FSM is in an accepting state, the answer to our decision problem is
yes. If not, the answer is no.&lt;/p&gt;
&lt;p&gt;The below code shows how an FSM could can be implemented in Python. Note that
in this implementation, we are forced to have a &lt;em&gt;deterministic&lt;/em&gt; FSM. Let's
ignore this detail for now though. This particular example implements an FSM
that accepts input strings that contain an even number of ones.&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;from&lt;/span&gt; &lt;span&gt;__future__&lt;/span&gt; &lt;span&gt;import&lt;/span&gt; &lt;span&gt;print_function&lt;/span&gt;


&lt;span&gt;def&lt;/span&gt; &lt;span&gt;even_ones&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;s&lt;/span&gt;&lt;span&gt;):&lt;/span&gt;
    &lt;span&gt;# Two states:&lt;/span&gt;
    &lt;span&gt;# - 0 (even number of ones seen so far)&lt;/span&gt;
    &lt;span&gt;# - 1 (odd number of ones seen so far)&lt;/span&gt;
    &lt;span&gt;rules&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;{(&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;'0'&lt;/span&gt;&lt;span&gt;):&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
             &lt;span&gt;(&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;'1'&lt;/span&gt;&lt;span&gt;):&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
             &lt;span&gt;(&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;'0'&lt;/span&gt;&lt;span&gt;):&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
             &lt;span&gt;(&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;'1'&lt;/span&gt;&lt;span&gt;):&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;}&lt;/span&gt;
    &lt;span&gt;# There are 0 (which is an even number) ones in the empty&lt;/span&gt;
    &lt;span&gt;# string so we start with state = 0.&lt;/span&gt;
    &lt;span&gt;state&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;
    &lt;span&gt;for&lt;/span&gt; &lt;span&gt;c&lt;/span&gt; &lt;span&gt;in&lt;/span&gt; &lt;span&gt;s&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;
        &lt;span&gt;state&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;rules&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;state&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;c&lt;/span&gt;&lt;span&gt;]&lt;/span&gt;
    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;state&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;


&lt;span&gt;# Example usage:&lt;/span&gt;
&lt;span&gt;s&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;"001100110"&lt;/span&gt;
&lt;span&gt;print&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;'Output for {} = {}'&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;format&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;s&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;even_ones&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;s&lt;/span&gt;&lt;span&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;So the core of an FSM is a list of rules of the form &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mo separator="true"&gt;,&lt;/mo&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;→&lt;/mo&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/mrow&gt;(S, c) \rightarrow
T&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 which says if the FSM is in state &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;/mrow&gt;S&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 and receives input character
&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;/mrow&gt;c&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 then it goes to state &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/mrow&gt;T&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

. If for any unique pair of &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mo separator="true"&gt;,&lt;/mo&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;(S,
c)&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 there is only one rule &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mo separator="true"&gt;,&lt;/mo&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;→&lt;/mo&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/mrow&gt;(S, c) \rightarrow T&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 then the FSM is said to
be deterministic. This is because the FSM will never need to make a "choice" as
to which of the rules to apply. With non-deterministic FSM's, the definition of
acceptance needs to be modified a bit: if &lt;em&gt;any&lt;/em&gt; set of choices of rules would
get us to an accepting state given an input then the input is said to be
accepted. It is a well-established result in Automata theory that deterministic
and non-deterministic FSM's are computationally equally powerful, because any
non-deterministic FSM can be translated to an equivalent deterministic one by
the &lt;a href="https://en.wikipedia.org/wiki/Powerset_construction"&gt;"powerset construction" method&lt;/a&gt;. The equivalent
deterministic FSM might have an exponentially larger number of states compared
to the non-deterministic one, however.&lt;/p&gt;
&lt;p&gt;It is also well-known that FSM's can solve a class of problems known as
"regular" problems. What this means, in very simple terms, is that if you can
write a regular expression that would accept the "yes" instances of your
decision problem, then you can solve the problem using an FSM. In fact, regular
expressions are often implemented using FSM-like structures. The "compile"
phase of using regular expression is precisely when the regular expression
engine builds the FSM-like structure from your regular expression. (Exercise:
Find a regular expression that accepts the above language, namely binary
strings with an even number of ones.)&lt;/p&gt;
&lt;p&gt;All right, so let's say a decision problem can be solved using an FSM with states
numbered &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;1&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 to &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

. For simplicity, let's assume that our input
will be binary (character set is &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;{&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo separator="true"&gt;,&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;}&lt;/mo&gt;&lt;/mrow&gt;\{0, 1\}&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

). Suppose the FSM has
&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/mrow&gt;k&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 rules given by &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo separator="true"&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;→&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;(S_i, c_i) \rightarrow T_i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

, for &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/mrow&gt;1 \le i
\le k&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

. And assume the input characters are given by &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;/mrow&gt;s_1&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 to
&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;s_m&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

. So our input is of length &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mrow&gt;m&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

. Finally, assume that the
initial state is &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;1&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 and accepting states are &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;/mrow&gt;a_1&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 to &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;a_q&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

,
where &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;/mrow&gt;q&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 is the number of accepting states.&lt;/p&gt;
&lt;p&gt;Following Cook's footsteps, we will introduce the following variables for our
SAT reduction:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;P_t&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 which is true iff &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;s_t = 1&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

,&lt;/li&gt;
&lt;li&gt;and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msubsup&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msubsup&gt;&lt;/mrow&gt;Q^i_t&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 which is true iff the FSM is in state &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/mrow&gt;i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 after input
character &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;s_t&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 has been fed into the FSM, for &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;&amp;lt;&lt;/mo&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;1 \le i &amp;lt; j \le
n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mrow&gt;0 \le t \le m&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

. We will take &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;t=0&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 to be the starting step,
before anything has been fed into the FSM.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With these definitions, we proceed to translate the question of whether the
input is accepted by the FSM into an instance of SAT. The goal is to produce a
set of clauses that are satisfiable iff the FSM ends in an accepting state
given the particular input. The clauses that will accomplish this are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;P_t&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 for &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mrow&gt;0 \le t \le m&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 such that &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;s_t = 1&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 and
&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;∼&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;\sim P_t&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 for all other &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mrow&gt;1 \le t \le m&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

. These will be the first
&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mrow&gt;m&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 clauses, each consisting of a single literal.&lt;/li&gt;
&lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msubsup&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/msub&gt;&lt;/msubsup&gt;&lt;/mrow&gt;Q^{a_j}_{m}&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 for &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;/mrow&gt;1 \le j \le q&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

. This says that after the last
character is fed into the FSM, we want to be in one of the accepting states.&lt;/li&gt;
&lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;∼&lt;/mo&gt;&lt;msubsup&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msubsup&gt;&lt;mo&gt;∨&lt;/mo&gt;&lt;mo&gt;∼&lt;/mo&gt;&lt;msubsup&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/msubsup&gt;&lt;/mrow&gt;\sim Q^i_t \vee \sim Q^j_t&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 for any &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;&amp;lt;&lt;/mo&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;1 \le i &amp;lt; j \le n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 and
&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mrow&gt;1 \le t \le m&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

, which effectively says that the FSM can not be in both
states &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/mrow&gt;i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/mrow&gt;j&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 at step &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;t&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

.  Collectively, these
clauses will ensure that the FSM is not in more than one state at a time.&lt;/li&gt;
&lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msubsup&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msubsup&gt;&lt;mo&gt;∨&lt;/mo&gt;&lt;mo&gt;…&lt;/mo&gt;&lt;mo&gt;∨&lt;/mo&gt;&lt;msubsup&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/msubsup&gt;&lt;/mrow&gt;Q^1_t \vee \ldots \vee Q^n_t&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 for &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mrow&gt;1 \le t \le m&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

. This says
that the FSM needs to be in at least one state at any step. Together with the
last set of clauses, we ensure that the FSM is in exactly one state at any
step.&lt;/li&gt;
&lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;∼&lt;/mo&gt;&lt;msubsup&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;msub&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/msubsup&gt;&lt;mo&gt;∨&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;∨&lt;/mo&gt;&lt;msubsup&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/msubsup&gt;&lt;/mrow&gt;\sim Q^{S_i}_{t-1} \vee P_t \vee Q^{T_i}_{t}&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 for all rules &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo separator="true"&gt;,&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;→&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;(S_i,
0) \rightarrow T_i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;∼&lt;/mo&gt;&lt;msubsup&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;msub&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/msubsup&gt;&lt;mo&gt;∨&lt;/mo&gt;&lt;mo&gt;∼&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;∨&lt;/mo&gt;&lt;msubsup&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/msubsup&gt;&lt;/mrow&gt;\sim Q^{S_i}_{t-1} \vee \sim P_t \vee
Q^{T_i}_{t}&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 for all rules &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo separator="true"&gt;,&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;→&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;(S_i, 1) \rightarrow T_i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

, for
&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mrow&gt;1 \le t \le m&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

. These clauses are logically equivalent to
"&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msubsup&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;msub&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/msubsup&gt;&lt;/mrow&gt;Q^{S_i}_{t-1}&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;P_t&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 implies &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msubsup&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/msubsup&gt;&lt;/mrow&gt;Q^{T_i}_{t}&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

" which is
equivalent to &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo separator="true"&gt;,&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;→&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;(S_i, 1) \rightarrow T_i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

.  In other words, they ensure
proper transition between states based on the input.&lt;/li&gt;
&lt;li&gt;Finally, we want to start in the initial state so we add the
clause &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msubsup&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msubsup&gt;&lt;/mrow&gt;Q^1_0&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let's see this in action for the above FSM which accepts strings with an even
number of ones in them. First, we have two states, so &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mrow&gt;n=2&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

. Let's build the
SAT instance to handle inputs of length &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;t&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

. Also note that we can leave out the
first set of clauses (the &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;P_t&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;∼&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;\sim P_t&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 ones), in which case any SAT
assignment will give us some accepted input. Which means we can list all the
strings accepted by the FSM by looking at all the satisfying assignments of the
above set of clauses.&lt;/p&gt;
&lt;p&gt;Here is an example for &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/mrow&gt;t=3&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

. In this input &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msubsup&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msubsup&gt;&lt;/mrow&gt;Q^i_t&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 is written as
&lt;cite&gt;Qi-t&lt;/cite&gt;.  The states are also labelled &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;0&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;1&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 instead of
&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;1&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 to &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 in the above.&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;# No more than one state at each step&lt;/span&gt;
~Q0-0 ~Q1-0
~Q0-1 ~Q1-1
~Q0-2 ~Q1-2
~Q0-3 ~Q1-3

&lt;span&gt;# At least one state in each step&lt;/span&gt;
Q0-0 Q1-0
Q0-1 Q1-1
Q0-2 Q1-2
Q0-3 Q1-3

&lt;span&gt;# Add the rules&lt;/span&gt;
&lt;span&gt;# (EVEN, 1) -&amp;gt; ODD&lt;/span&gt;
~Q0-0  ~P1   Q1-1
~Q0-1  ~P2   Q1-2
~Q0-2  ~P3   Q1-3

&lt;span&gt;# (ODD, 1) -&amp;gt; EVEN&lt;/span&gt;
~Q1-0  ~P1   Q0-1
~Q1-1  ~P2   Q0-2
~Q1-2  ~P3   Q0-3

&lt;span&gt;# (EVEN, 0) -&amp;gt; EVEN&lt;/span&gt;
~Q0-0   P1   Q0-1
~Q0-1   P2   Q0-2
~Q0-2   P3   Q0-3

&lt;span&gt;# (ODD, 0) -&amp;gt; ODD&lt;/span&gt;
~Q1-0   P1   Q1-1
~Q1-1   P2   Q1-2
~Q1-2   P3   Q1-3

&lt;span&gt;# Start in state 0&lt;/span&gt;
Q0-0
&lt;span&gt;# End in an accepting state&lt;/span&gt;
Q0-3
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Let's see the output of running a SAT solver on this, and another file for
&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/mrow&gt;t=3&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;/mrow&gt;t=4&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

:&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ python sat.py --all --starting_with P --brief &amp;lt; tests/fsm/even-ones-3.in

P1 P3
P1 P2
P2 P3
$ python sat.py --all --starting_with P --brief &amp;lt; tests/fsm/even-ones-4.in

P1 P4
P1 P3
P1 P2 P3 P4
P1 P2
P2 P4
P2 P3
P3 P4
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As expected, all the possible ways of picking a subset of &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;{&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo separator="true"&gt;,&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo separator="true"&gt;,&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;mo&gt;}&lt;/mo&gt;&lt;/mrow&gt;\{P1, P2, P3
\}&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

 with an even number of elements in them are listed above, and similarly for
&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;{&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo separator="true"&gt;,&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo separator="true"&gt;,&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;mo separator="true"&gt;,&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;mo&gt;}&lt;/mo&gt;&lt;/mrow&gt;\{P1, P2, P3, P4 \}&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;

, although not necessarily in any meaningful order.
(Notice that the empty lines are the empty subsets, which also have even
numbers of ones.)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;


    &lt;/div&gt;




        

&lt;/section&gt;






&lt;/div&gt;&lt;a href="https://sahandsaba.com/understanding-sat-by-implementing-a-simple-sat-solver-in-python.html"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:22:09 UT
      </pubDate>
      <guid>
        https://sahandsaba.com/understanding-sat-by-implementing-a-simple-sat-solver-in-python.html
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://ferd.ca/clever-functional-design.html
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;article&gt;
        
            &lt;span&gt;2019/08/24&lt;/span&gt;
        
        &lt;h2&gt;Clever Functional Design&lt;/h2&gt;
        

&lt;p&gt;One of the best bits of software design I recall participating in was something done a few years ago at Heroku. It's been long enough since then that I feel comfortable boasting about it here. It's one small piece of data-centred functional design, where thinking a bit harder about the problem at hand greatly simplified what would have been a more straightforward and obvious implementation choice in a mutable language.&lt;/p&gt;

&lt;h3&gt;The Feature&lt;/h3&gt;


&lt;p&gt;Heroku's routing stack had one very interesting feature it provided to all users: a router log. The router log contains fields such as the overall request time, the time it took to send the request, the time it took to send the body, &lt;a href="https://devcenter.heroku.com/articles/error-codes"&gt;heroku-specific error codes&lt;/a&gt; and so on. They're broader categories of interesting time span.&lt;/p&gt;

&lt;p&gt;At the same time, Heroku engineers had internal logs for all the requests for which users had public logs. These internal logs contained more detailed information that more often made sense to display during specific debugging activities. They included information such as time spent parsing headers from the client, time to first response packet (calculating what would essentially be the time after which the whole request was sent, but before which the back-end application would respond), POSIX statuses detected by the proxy on socket issues, and so on.&lt;/p&gt;

&lt;p&gt;During more intricate debugging, other values could be required from the logs, but adding them would need code changes. This information was maintained in what was essentially a monolithic proxy that contained both the business logic (what logs to create, which servers to route to, and so on) and the proxying logic (how to shuttle HTTP from point A to point B).&lt;/p&gt;

&lt;p&gt;At some point during my Heroku days, we rewrote the entire routing stack to clearly divide the business concerns (routing and features for Heroku apps) and the proxying logic. The idea was to clean up deeply intertwined code, &lt;a href="https://devcenter.heroku.com/articles/http-routing"&gt;clarify and properly specify the proxying behaviour&lt;/a&gt;, and allow to reason about and change what we offered to customers without having to know all the innards of HTTP proxying logic to do so. This divide was successful, and eventually allowed us to open source the proxying logic: since it was no longer business related and was commodity infrastructure, &lt;a href="https://github.com/heroku/vegur"&gt;vegur&lt;/a&gt; became public.&lt;/p&gt;

&lt;p&gt;This division came with a few challenges though, and one of them was with the logs: how were we to take a Heroku feature, such as the router logs we had, with their own specific needs that could change according to business requirements, and bake them into a generic proxy library, where all the interesting measurements and samplings were to take place?&lt;/p&gt;

&lt;h3&gt;The Straightforward Design&lt;/h3&gt;


&lt;p&gt;The approach we took in the original router was to just take all the samples as we needed them, mostly as spans. You essentially just intersperse the logging and observational needs with the actual business end of the code, and do what you must.&lt;/p&gt;

&lt;p&gt;One straightforward way to do this is with timestamps and might look something like this:&lt;/p&gt;

&lt;div&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;T1&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;stamp&lt;/span&gt;&lt;span&gt;(),&lt;/span&gt;
&lt;span&gt;do_something&lt;/span&gt;&lt;span&gt;(),&lt;/span&gt;
&lt;span&gt;T2&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;stamp&lt;/span&gt;&lt;span&gt;(),&lt;/span&gt;
&lt;span&gt;report_duration&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"some label"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;T2&lt;/span&gt;&lt;span&gt;-&lt;/span&gt;&lt;span&gt;T1&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You take a timestamp, do the thing, take a second timestamp, and report the difference as the duration of the operation. Eventually you get tired of doing this, and you might wrap them up in a helper that takes a closure (or wraps some object in OO design) and hides the reporting:&lt;/p&gt;

&lt;div&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;with_timestamp&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"some label"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;fun&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&amp;gt;&lt;/span&gt; &lt;span&gt;do_something&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;end&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Both approaches work fine. The latter offers slightly more encapsulation, and also prevents having overlapping timestamps where two measurements intersect. The logic is always set at the call-site, and things can be a bit tricky with error handling, but that's generally how you do it. The same kind of approach is still rather broadly used in &lt;a href="https://opensource.com/article/18/9/distributed-tracing-microservices-world"&gt;distributed tracing&lt;/a&gt; with the addition of a &lt;em&gt;context&lt;/em&gt;, which lets you define some lineage or nesting of operations:&lt;/p&gt;

&lt;div&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;%% approach 1&lt;/span&gt;
&lt;span&gt;Ctx&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;new_span&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"some label"&lt;/span&gt;&lt;span&gt;),&lt;/span&gt;
&lt;span&gt;T1&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;stamp&lt;/span&gt;&lt;span&gt;(),&lt;/span&gt;
&lt;span&gt;NewCtx&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;do_something&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Ctx&lt;/span&gt;&lt;span&gt;),&lt;/span&gt;
&lt;span&gt;T2&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;stamp&lt;/span&gt;&lt;span&gt;(),&lt;/span&gt;
&lt;span&gt;close_span&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;NewCtx&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;

&lt;span&gt;%% approach 2&lt;/span&gt;
&lt;span&gt;with_span&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"some_label"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;fun&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Ctx&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&amp;gt;&lt;/span&gt; &lt;span&gt;do_something&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Ctx&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;end&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Of course if you've got mutability going on and some global scope available, you'll cheat a bit and hide the span context within the program's state differently.&lt;/p&gt;

&lt;p&gt;In any case, the old approach was based on these kinds of mechanism. When time came to split them up into their business and general parts, the tools used for logging needed to be decoupled as well. The general and straightforward approach to that is to do it through dependency injection. Our new approaches might now look something like this:&lt;/p&gt;

&lt;div&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;f&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Logger&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&amp;gt;&lt;/span&gt;
    &lt;span&gt;T1&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;stamp&lt;/span&gt;&lt;span&gt;(),&lt;/span&gt;
    &lt;span&gt;do_something&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Logger&lt;/span&gt;&lt;span&gt;),&lt;/span&gt;
    &lt;span&gt;T2&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;stamp&lt;/span&gt;&lt;span&gt;(),&lt;/span&gt;
    &lt;span&gt;Logger&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"some label"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;T2&lt;/span&gt;&lt;span&gt;-&lt;/span&gt;&lt;span&gt;T1&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Kind of similarly to passing the context or a span in the distributed tracing approach, you now parametrize each contract of dependent functions to take some contextual cues that explain how to do things.  It would have become a bit cumbersome to do it through all involved components of a proxying library, but it would have been possible to do it, and even more easily with tool or IDE support.&lt;/p&gt;

&lt;p&gt;This, however, was the road we decided not to take.&lt;/p&gt;

&lt;h3&gt;The Weakness of the Straightforward Approach&lt;/h3&gt;


&lt;p&gt;The problem with the dependency injection approach, aside from its cumbersomeness, is that it did not sufficiently decouple what was a business concern from what was a generic library. Sure, we would hide and abstract away the tools chosen—which logging or tracing library would be used—but in no way would it really de-couple the design.&lt;/p&gt;

&lt;p&gt;It would be tricky, for example, to properly track the concerns of "public user logs" and "internal engineer logs". The biggest design issue was something we uncovered by simply asking ourselves this question: if some other project were to use this library, would &lt;em&gt;their&lt;/em&gt; reporting need to change every time Heroku decided to log new metrics?&lt;/p&gt;

&lt;p&gt;Sure, the implementation could be independent. But the straightforward design only de-coupled the technical dependencies and which code was used. It did not get rid of the logical coupling that still existed between Heroku's business logic and the proxy's need to just shuttle HTTP. If we went with that approach, there was still a very deep dependency between both code bases. Heroku would unsurprisingly rely on the proxy, but it &lt;em&gt;felt&lt;/em&gt; weird that the proxy's instrumentation would have to be defined by the Heroku product requirements.&lt;/p&gt;

&lt;p&gt;Another slightly less important issue came from implementation details. I mention it not because it was a huge blocker to logical decoupling, but because this implementation detail ended up providing the key to the nicer design. The Vegur proxy had been written to use &lt;a href="https://stackoverflow.com/a/51376869/35344"&gt;&lt;code&gt;passive&lt;/code&gt; TCP sockets&lt;/a&gt; used in a blocking mode, because those were faster back in the day (implementation changes and optimizations within the BEAM VM have since then made this unnecessary). This, and other earlier design choices, made it so the proxy itself had 3 major moving parts:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;an HTTP server parsing module, which would listen to incoming requests from the public Internet and parse them&lt;/li&gt;
&lt;li&gt;an HTTP client parsing module, which would forward the traffic to a customer's back-end and listen to the responses&lt;/li&gt;
&lt;li&gt;an inner loop that would use both the client and server bits and would handle the data transfer across both of them as a bridge.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This meant that some concerns we had in terms of metrics would sometimes reside all within one bit of code (i.e. the time it takes to parse headers is self-contained to any of the components), but sometimes it would cross boundaries. For example, knowing the time it took to parse the request body required taking measurements in the HTTP server, but which could be intertwined with operations taking place both in the inner loop and the HTTP client. It had no clear structural hierarchy.&lt;/p&gt;

&lt;p&gt;Worse, some debugging scenarios required taking some measurements that started in the HTTP server, and finished in the HTTP client. That made it particularly difficult to localize and isolate concerns well, and the overall requirements of Heroku's reporting risked having a huge impact on the structure of the proxy.&lt;/p&gt;

&lt;p&gt;Dependency injection would not be enough to fix this, we needed to think about the problem differently.&lt;/p&gt;

&lt;h3&gt;A Functional Design&lt;/h3&gt;


&lt;p&gt;Even in today's modern distributed tracing ecosystem, the design of most tracing libraries is deeply centered on the concept of a span: a pre-defined point A to point B period of time, which is written and instrumented as such in the code.&lt;/p&gt;

&lt;p&gt;The big &lt;em&gt;Eureka!&lt;/em&gt; moment for our approach in Vegur was in realizing that what when debugging, what we care about is picking arbitrary points on a timeline. Spans let you represent things a bit like this:&lt;/p&gt;
&lt;pre&gt;|------------------- Request --------------------|
 |--- Header Parsing ---|-- Body parsing --| ...
     |-- Cookie --|
        | ... |
&lt;/pre&gt;
&lt;p&gt;Those are contiguous subdivisions of the whole timeline. What we wanted, instead, was a flat timeline on which we could pick arbitrary intervals:&lt;/p&gt;
&lt;pre&gt;request start                                          end of request
|                                                       |
| start header parsing                                  |
| |                first packet sent           ...      |
| |                |                             |      |
|-x--x--x------x---x----x------------------x-----x---...|
     |  |      |        |                  |
     |  |     ...      start body parsing  |
     | end cookie                     end body parsing
 start cookie
&lt;/pre&gt;
&lt;p&gt;All these things happen in a continuum. The divisions of what we wanted to report were not structural to this timeline, they were views or selections of various points of interests, and a measurement between them. The "first packet sent" event is something that could be useful to multiple metrics:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;time between the first packet received and the first packet sent ("how long we took to process the headers"&lt;/li&gt;
&lt;li&gt;time between header parsing being done and sending the first packet ("how long we took to make a routing decision")&lt;/li&gt;
&lt;li&gt;time between the first packet sent and the last header packet sent ("time to send the request headers")&lt;/li&gt;
&lt;li&gt;time between the first packet sent and the last request packet sent ("time to send the full request")&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;and so on. Being able to report on all of these was context-dependent for the consumer, meaning that's usually a business concern. But the proxying library itself only cared about specific arbitrary points we thought could be useful to its technical users.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;That&lt;/em&gt; distinction and approach as a timeline was the pivotal point we needed in the design. What the proxying library needed to do was not provide all the metrics and spans Heroku expected. What it needed to provide was the list of all important points on a timeline, whether they represented a singular event, or a duration. It would then be up to the consumer to report things however they wanted, whenever they wanted.&lt;/p&gt;

&lt;p&gt;The flat timeline was particularly interesting for this because it is easily representable as an immutable data structure. If all you have is a bunch of local &lt;em&gt;monotonic&lt;/em&gt; timestamps, all you need to do is maintain a local data structure that maintains sequences of labelled points in time: &lt;code&gt;[{Label1, T1}, {Label2, T2}, ...]&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Since timestamps are generally sortable locally—you need some fancy cheats to make it work in a distributed setting—then all the local timelines between the HTTP client, server, and inner loop modules could be maintained independently, but merged reliably: just sort by timestamp.&lt;/p&gt;
&lt;pre&gt;|-x----------------x---------------------------------...|

  |--x--x------x--------x------------------|

                   |—---------------------------x---...|

         |               |             |
         v               v             v

|-x--x--x------x---x----x------------------x----x----...|
&lt;/pre&gt;
&lt;p&gt;This would let us write one generic well-defined data structure, use it wherever and whenever we needed it, and just merge them near the end of each timeline. No need to coordinate context-passing around, just a fetch and a merge once per item.&lt;/p&gt;

&lt;p&gt;Then, the business end of code in Heroku's router could ask for that timeline once the request was ready to be logged, get one well-known data structure, and do as many selections for as many debugging reports as it required. If you wanted to send 15 logs out of there, it did not matter to the proxy library. Just analyze the timeline, generate what you need, and that's it.&lt;/p&gt;

&lt;p&gt;Interestingly, since the final data structure could be represented easily in the base types of the language, Heroku's router was able to create its own compatible timeline that itself could be cast and merged with the proxy's timeline, without having them actually share the implementation (which would also have been fine). This would later let us augment the proxying logs with all the routing and business decisions for all kinds of debugging purposes (how much time would we spend queued to find an available back-end to route to?). This turned into app-specific routing flags that could allow to do deeper introspection of routing logic for specific applications, at nearly no overhead in code.&lt;/p&gt;

&lt;h3&gt;Lesson Learned&lt;/h3&gt;


&lt;p&gt;The approach itself here is mildly interesting. It has some intriguing implications in the context of designing implementations of distributed tracing libraries. The implementation is so straightforward in Vegur that I didn't spend the time to describe it here.&lt;/p&gt;

&lt;p&gt;The true bigger lesson here is in systems design. It relates to functional, immutable, and declarative approaches to structuring communication flows.&lt;/p&gt;

&lt;p&gt;The straightforward answer to our decoupling issue was to respond to the technical concern: just make it so the dependency does not know about the libraries used by its parent. I think it would have strictly speaking solved the most blocking problem in getting the code to build.  This would have been easy to do, and the only thing that made it annoying was the fact we were using a functional programming language with no mutable data structures nor global shared context. But satisfying the compiler is not enough to make for good design. This approach would have made it hard to get maintainable code given implementation details, and did not remove any logical coupling.&lt;/p&gt;

&lt;p&gt;Rather than dismissing this challenge as "a bad fit for functional programming", it is what led to a better solution: re-think the data structure, gain better insights in the distinction between &lt;em&gt;how the data is produced&lt;/em&gt; and &lt;em&gt;how the data is consumed&lt;/em&gt;. Take that separation, and make it explicit. Build around it. Turn it into a data contract. This, in turn, lets you more transparently change either ends. You might need to add new measurement points in the producer-side when the consumer needs it, but the properly declared abstraction makes it so the other consumers will not be effected by the change.&lt;/p&gt;

&lt;p&gt;The end result was a purely functional data structure that was mergeable, testable, and in line with functional design, but that's just a technical aspect of the result: it was the structural constraint of already being in an immutable context that prompted the cleaner design. Most challenges of working in a functional, declarative, or immutable language are not necessarily due to the language itself. They come from being thrown in a context where easier shortcuts are not as practical as we are used for them to be, and having to re-think both our problem and our solutions.&lt;/p&gt;

    &lt;/article&gt;&lt;/div&gt;&lt;a href="https://ferd.ca/clever-functional-design.html"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:22:15 UT
      </pubDate>
      <guid>
        https://ferd.ca/clever-functional-design.html
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://blog.scaleway.com/2019/building-a-machine-reading-comprehension-system-using-the-latest-advances-in-deep-learning-for-nlp/
      </link>
      <description>
        &lt;a href="https://blog.scaleway.com/2019/building-a-machine-reading-comprehension-system-using-the-latest-advances-in-deep-learning-for-nlp/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:22:26 UT
      </pubDate>
      <guid>
        https://blog.scaleway.com/2019/building-a-machine-reading-comprehension-system-using-the-latest-advances-in-deep-learning-for-nlp/
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://blog.regehr.org/archives/1687
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div id="content"&gt;
		&lt;main id="main"&gt;

			
&lt;article id="post-1687"&gt;
		
	
	&lt;div&gt;
		&lt;p&gt;Fuzzing is sort of a superpower for locating vulnerabilities and other software defects, but it is often used to find problems baked deeply into already-deployed code. Fuzzing should be done earlier, and moreover developers should spend some effort making their code more amenable to being fuzzed. &lt;/p&gt;
&lt;p&gt;This post is a non-comprehensive, non-orthogonal list of ways that you can write code that fuzzes better. Throughout, I’ll use “fuzzer” to refer to basically any kind of randomized test-case generator, whether mutation-based (afl, libFuzzer, etc.) or generative (jsfunfuzz, Csmith, etc.). Not all advice will apply to every situation, but a lot of it is sound software engineering advice in general. I’ve bold-faced a few points that I think are particularly important.&lt;/p&gt;
&lt;h2&gt;Invest in Oracles&lt;/h2&gt;
&lt;p&gt;A test oracle decides whether a test case triggered a bug or not. By default, the only oracle available to a fuzzer like afl is provided by the OS’s page protection mechanism. In other words, it detects only crashes. We can do much better than this.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://blog.regehr.org/archives/1091"&gt;Assertions&lt;/a&gt; and their compiler-inserted friends — sanitizer checks — are another excellent kind of oracle. You should fuzz using as many of these checks as possible. Beyond these easy oracles, many more possibilities exist, such as: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;function-inverse pairs: does a parse-print loop, compress-decompress loop, encrypt-decrypt loop, or similar, work as expected?
&lt;/li&gt;&lt;li&gt;differential: do two different implementations, or modes of the same implementation, show the same behavior?
&lt;/li&gt;&lt;li&gt;metamorphic: does the system show the same behavior when a test case is modified in a semantics-preserving way, such as adding a layer of parentheses to an expression?
&lt;/li&gt;&lt;li&gt;resource: does the system consume a reasonable amount of time, memory, etc. when processing an input?
&lt;/li&gt;&lt;li&gt;domain specific: for example, is a lossily-compressed image sufficiently visually similar to its uncompressed version?
&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Strong oracles are worth their weight in gold, since they tend to find application-level logic errors rather than the lower-level bugs that are typically caught by looking for things like array bounds violations.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I &lt;a href="https://blog.regehr.org/archives/856"&gt;wrote a bit more about this topic&lt;/a&gt; a few years ago. Finally, a twitter user suggested “If you’re testing a parser, poke at the object it returns, don’t just check if it parses.” This is good advice.&lt;/p&gt;
&lt;h2&gt;Interpose on I/O and State&lt;/h2&gt;
&lt;p&gt;Stateless code is easier to fuzz. Beyond that, you will want APIs for taking control of state and for interposing on I/O. For example, if your program asks the OS for the number of cores, the current date, or the amount of disk space remaining, you should provide a documented method for setting these values. It’s not that we necessarily want to randomly change the number of cores, but rather that we might want to fuzz our code when set to single-core mode and then separately fuzz it in 128-core mode. Important special cases of taking control of state and I/O include making it easy to reset the state (to support persistent-mode fuzzing) and avoiding hidden inputs that lead to non-deterministic execution. &lt;strong&gt;We want as much determinism as possible while fuzzing our code.&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;Avoid or Control Fuzzer Blockers&lt;/h2&gt;
&lt;p&gt;Fuzzer blockers are things that make fuzzing gratuitously difficult. The canonical fuzzer blocker is a checksum included somewhere in the input: the random changes made to the input by a mutation-based fuzzer will tend to cause the checksum to not validate, resulting in very poor code coverage. There are basically two solutions. First, turn off checksum validation in builds intended for fuzzing. Second, have the fuzzer generate inputs with valid checksums. A generation-based fuzzer will have this built in; with a mutation-based fuzzer we would write a little utility to patch up the test case with a valid checksum after it is generated and before it is passed to the program being fuzzed. &lt;a href="https://github.com/mirrorer/afl/blob/master/experimental/post_library/post_library.so.c"&gt;afl has support for this&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Beyond checksums, hard-to-satisfy validity properties over the input can be a serious problem. For example, if you are fuzzing a compiler for a strongly typed programming language, blind mutation of compiler inputs may not result in valid compiler inputs very often. I like to think of validity constraints as being either soft (invalid inputs waste time, but are otherwise harmless) or hard (the system behaves arbitrarily when processing an invalid input, so they must be avoided for fuzzing to work at all). When we fuzz a C++ compiler to look for wrong code bugs, we face a hard validity constraint because compiler inputs that have UB will look like wrong code bugs. There is no simple, general-purpose solution to this kind of problem, but rather a family of techniques for explicitly taking validity properties into account. The most obvious solution — but often not the right one — is to write a new generational fuzzer. The problem is that if you do this, you cannot take advantage of modern coverage-driven fuzzing techniques, which are amazing. To fit into a coverage-driven fuzzing framework you have a couple of options. First, write a custom mutator that respects your validity constraints. &lt;strong&gt;Second, &lt;a href="https://github.com/google/fuzzer-test-suite/blob/master/tutorial/structure-aware-fuzzing.md"&gt;structure-aware fuzzing&lt;/a&gt;, which basically means taking the mutated data from the fuzzer and translating it into something like what the program being fuzzed expects to see.&lt;/strong&gt; There’s a lot of research left to be done in making coverage-driven fuzzers work well in the presence of validity constraints without requiring a lot of manual effort. There are some significant subtleties here, maybe I’ll go into them another time. Putting something like a SAT solver into the fuzzer is not, generally speaking, the answer here, first because some validity constraints like checksums are specifically difficult for solvers, and second because some validity constraints (such as UB-freedom in a C++ program) are implicit and cannot be inferred, even in principle, by looking at the system being fuzzed.&lt;/p&gt;
&lt;p&gt;A lot of code in a typical system cannot be fuzzed effectively by feeding input to public APIs because access is blocked by other code in the system. For example, if you use a custom memory allocator or hash table implementation, then fuzzing at the application level probably does not result in especially effective fuzzing of the allocator or hash table. These kinds of APIs should be exposed to direct fuzzing. &lt;strong&gt;There is a strong synergy between unit testing and fuzzing: if one of these is possible and desirable, then the other one probably is too. You typically want to do both.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Sanitizers and fuzzers often require tweaks or even significant changes to the build process. To make this easier, keep the build process as clean and simple as possible. Make it easy to switch out the compiler and modify the compiler options. Depend on specific tools (and versions of tools) as little as possible. Routinely build and test your code with multiple compilers. Document special build system requirements.&lt;/p&gt;
&lt;p&gt;Finally, some fuzzer blockers are sort of silly and easy to avoid. If your code leaks memory or terminates its process with a deep call stack, it will be painful to test using a persistent-mode fuzzer, so don’t do these things. Avoid handling SIGSEGV or, if you really must do this, have a way to disable the handler for fuzzer builds. If your code is not compatible with ASan or UBSan, then these extremely useful oracles are harder to use. In particular, if your code uses a custom memory allocator you should consider turning it off for fuzzer builds, or else &lt;a href="https://github.com/google/sanitizers/wiki/AddressSanitizerManualPoisoning"&gt;adapting it to work with ASan&lt;/a&gt;, or else you’ll miss important bugs.&lt;/p&gt;
&lt;h2&gt;Unblock Coverage-Driven Fuzzers&lt;/h2&gt;
&lt;p&gt;Because coverage-driven fuzzers refocus their effort to try to hit uncovered branches, they can be blocked in certain specific ways. For example, if a coverage-driven fuzzer is presented with too many uncoverable branches, it can spend so much time on them that it becomes less likely to hit more interesting branches elsewhere in the program. For example, one time I compared afl’s coverage on a program compiled with and without UBSan, and found that (in whatever time limit I used) it covered quite a lot less of the sanitized program, compared to the unsanitized build. On the other hand, we definitely want our fuzzer to look for sanitizer failures.  My advice is to fuzz both sanitized and unsanitized builds of your program. I don’t know how to budget fuzzing resources for these different activities and don’t know of any principled work on that problem. It may not matter that much, since fuzzing is all about overkill.&lt;/p&gt;
&lt;p&gt;Sometimes your program will call branchy, already-heavily-fuzzed code early in its execution. For example, you might decompress or decrypt input before processing it. This is likely to distract the coverage-driven fuzzer, causing it to spend a lot of time trying to fuzz the crypto or compression library. If you don’t want to do this, provide a way to disable crypto or compression during fuzzing.&lt;/p&gt;
&lt;p&gt;Any interpreter in your program is likely to make life difficult for a coverage-driven fuzzer, since the relevant program paths are now encoded in the data being interpreted, which is generally opaque to the fuzzer. If you want maximum mileage out of coverage-driven fuzzers, you may want to try to avoid writing interpreters, or at least keep them extremely simple. An obvious way to deal with embedded interpreters — which someone must have thought of and tried, but I don’t have any pointers — would be to have an API for teaching the fuzzer how to see coverage of the language being interpreted.&lt;/p&gt;
&lt;h2&gt;Enable High Fuzzing Throughput&lt;/h2&gt;
&lt;p&gt;Fuzzing is most effective when throughput is very high; this seems particularly the case for feedback-driven fuzzers that may take a while to learn how to hit difficult coverage targets. An easy throughput hack is to make it possible to disable slow code (detailed logging, for example) when it is not germane to the fuzzing task. Similarly, interposing on I/O can help us avoid speed hacks such as running the fuzzer in a ramdisk.&lt;/p&gt;
&lt;h2&gt;“But I Want Fuzzing My Code to be Harder, Not Easier”&lt;/h2&gt;
&lt;p&gt;I don’t have a lot of sympathy for this point of view. Instead of aiming for security through obscurity, we would do better to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;fuzz early and thoroughly, eliminating fuzzable defects before releasing code into the wild
&lt;/li&gt;&lt;li&gt;write code in a programming language with as strong of a type system as we are willing to tolerate — this will statically eliminate classes of bad program behaviors, for example by stopping us from putting the wrong kind of thing into a hashmap
&lt;/li&gt;&lt;li&gt;aggressively use assertions and sanitizers to get dynamic checking for properties that the type system can’t enforce statically
&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;Anti-fuzzing techniques are a thing, but I don’t think it represents a useful kind of progress towards better software. &lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Randomized testing is incredibly powerful and there’s no point avoiding it: if you don’t fuzz your code, someone else will. This piece has described some ways for you, the software developer, to make fuzzing work better. Of course there are plenty of other aspects, such as choosing a good corpus and writing a good fuzzer driver, that are not covered here.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Acknowledgments:&lt;/b&gt; Pascal Cuoq and Alex Groce provided feedback on a draft of this piece, and it also benefited from suggestions I received on Twitter. You can &lt;a href="https://twitter.com/johnregehr/status/1154888675810934784"&gt;read the conversation here&lt;/a&gt;; it contains some suggestions and nuances that I did not manage to capture.&lt;/p&gt;
	&lt;/div&gt;

	

				
&lt;/article&gt;

	


		&lt;/main&gt;
	&lt;/div&gt;&lt;/div&gt;&lt;a href="https://blog.regehr.org/archives/1687"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:24:29 UT
      </pubDate>
      <guid>
        https://blog.regehr.org/archives/1687
      </guid>
    </item>
    <item>
      <title>
        Full Page Reload
      </title>
      <link>
        https://spectrum.ieee.org/the-institute/ieee-member-news/educational-resources-that-get-students-up-to-speed-on-advanced-manufacturing-and-programming-languages
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;header id="header"&gt;
		&lt;div id="ieee-metanav"&gt;
				&lt;ul&gt;
					&lt;li&gt;&lt;a href="https://spectrum.ieee.org/static/enhance-your-spectrum-experience-become-an-ieee-member"&gt;Join IEEE&lt;/a&gt;&lt;/li&gt;
					&lt;li&gt;|&lt;/li&gt;
					&lt;li&gt;&lt;a href="http://www.ieee.org/"&gt;IEEE.org&lt;/a&gt;&lt;/li&gt;
					&lt;li&gt;|&lt;/li&gt;
					&lt;li&gt;&lt;a href="http://ieeexplore.ieee.org/"&gt;IEEE &lt;em&gt;Xplore&lt;/em&gt; Digital Library&lt;/a&gt;&lt;/li&gt;
					&lt;li&gt;|&lt;/li&gt;
					&lt;li&gt;&lt;a href="http://standards.ieee.org/"&gt;IEEE Standards&lt;/a&gt;&lt;/li&gt;
					&lt;li&gt;|&lt;/li&gt;
					&lt;li&gt;&lt;a href="https://spectrum.ieee.org/"&gt;&lt;span&gt;IEEE Spectrum&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
					&lt;li&gt;|&lt;/li&gt;
					&lt;li&gt;&lt;a href="http://www.ieee.org/sitemap"&gt;More Sites&lt;/a&gt;&lt;/li&gt;
					
				&lt;/ul&gt;

				&lt;div&gt;
				&lt;ul&gt;
					
					
					
						
							
							
								
									
										&lt;li&gt;&lt;a href="https://www.ieee.org/profile/public/createwebaccount/showCreateAccount.html?ShowMGAMarkeatbilityOptIn=true&amp;amp;sourceCode=spectrum&amp;amp;signinurl=https://spectrum.ieee.org/user/login&amp;amp;url=https://spectrum.ieee.org/the-institute/ieee-member-news/educational-resources-that-get-students-up-to-speed-on-advanced-manufacturing-and-programming-languages&amp;amp;autoSignin=Y&amp;amp;car=IEEE-Spectrum"&gt;Create
											Account&lt;/a&gt;&lt;/li&gt;
									
											
								
								&lt;li&gt;|&lt;/li&gt;
								
									
									&lt;li&gt;&lt;a href="https://spectrum.ieee.org/user/login"&gt;Sign In&lt;/a&gt;&lt;/li&gt;
									
									
									
							
							
						
					
					&lt;/ul&gt;
				&lt;/div&gt;
		&lt;/div&gt;

    &lt;/header&gt;         




			

 
	

	




 





	
	
	
	

 
 
 



	






			


&lt;/div&gt;&lt;a href="https://spectrum.ieee.org/the-institute/ieee-member-news/educational-resources-that-get-students-up-to-speed-on-advanced-manufacturing-and-programming-languages"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:27:19 UT
      </pubDate>
      <guid>
        https://spectrum.ieee.org/the-institute/ieee-member-news/educational-resources-that-get-students-up-to-speed-on-advanced-manufacturing-and-programming-languages
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://blog.plaid.com/how-we-reduced-deployment-times-by-95/
      </link>
      <description>
        &lt;a href="https://blog.plaid.com/how-we-reduced-deployment-times-by-95/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:27:27 UT
      </pubDate>
      <guid>
        https://blog.plaid.com/how-we-reduced-deployment-times-by-95/
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://www.reifyworks.com/writing/2019-08-26-a-most-software-companies
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div id="wrapper"&gt;

      


      &lt;main id="main"&gt;
        
        &lt;div&gt;
                  &lt;p&gt;One of the most important skills to build as a marketer is &lt;em&gt;follow through&lt;/em&gt;. In marketing that means taking every opportunity to gather data in order to &lt;em&gt;understand&lt;/em&gt; your users and &lt;em&gt;improve&lt;/em&gt; your process.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Understanding your users doesn’t end when they purchase your product.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;One deficiency we’ve consistently seen inside companies small and large alike is that they don’t have ready access to information about what users are doing with their product. Marketers are incentivized to instrument the hell of out lead generation and a section of the funnel, sales religiously updates CRMs to track prospects and potential revenue expansion opportunities, but noone is tying it all together by looking to information that &lt;em&gt;you own&lt;/em&gt; about what users are doing with your product.&lt;/p&gt;

&lt;p&gt;The reason why this is so important to get right early is that it will deeply inform decisions that you’ll need to make later on … if you’re around that long. Decisions about pricing and packaging, feature development, marketing spending, hiring, strategic investment of all sorts, etc., are more intelligently made when they’re backed by data that is enriched by how &lt;em&gt;users are actually using your product.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;There are myriad technical approaches to gathering the data necessary for this method, but an ideal setup should contain the following, regardless of how it is implemented:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A “User table” which rolls up all useful usage information into one easy to query data source. You likely have some version of this powering either a homegrown “admin dashboard” or feeding into one or more external systems.&lt;/li&gt;
  &lt;li&gt;A time-bounded data source which is amenable to more complex queries, including historical queries, and can be used to generate reports. Amazon Redshift is a popular solution for this component.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Here’s an example row:&lt;/p&gt;

&lt;table id="usertable"&gt;
  &lt;tbody&gt;&lt;tr&gt;
    &lt;th&gt;ID&lt;/th&gt;
    &lt;th&gt;name&lt;/th&gt;
    &lt;th&gt;score&lt;/th&gt;
    &lt;th&gt;feature1&lt;/th&gt;
    &lt;th&gt;feature2&lt;/th&gt;
    &lt;th&gt;plan&lt;/th&gt;
    &lt;th&gt;monthly&lt;/th&gt;
    &lt;th&gt;seats&lt;/th&gt;
    &lt;th&gt;last_seen&lt;/th&gt;
    &lt;th&gt;user_since&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;1&lt;/td&gt;
    &lt;td&gt;Reify&lt;/td&gt;
    &lt;td&gt;87&lt;/td&gt;
    &lt;td&gt;1&lt;/td&gt;
    &lt;td&gt;0&lt;/td&gt;
    &lt;td&gt;small&lt;/td&gt;
    &lt;td&gt;99&lt;/td&gt;
    &lt;td&gt;3&lt;/td&gt;
    &lt;td&gt;019-08-29&lt;/td&gt;
    &lt;td&gt;019-01-02&lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;



&lt;p&gt;Maintaining and curating this date over time will allow you to answer crucial questions about your trial users, customes, ex-customers, and so on. Recording and maintaining this data is &lt;em&gt;so simple&lt;/em&gt; that it’s becoming table stakes for good marketers – don’t get left behind.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bonus Implementation Tips&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Track feature usage in your user table with columns denoting whether or not a user has or has not used this feature&lt;/li&gt;
  &lt;li&gt;Associate plan and payment information with your user table rows so that you can easily segment your user data by important revenue based facets&lt;/li&gt;
  &lt;li&gt;Create an “engagement metric” number which takes core features of your product into account and rolls them up into a 0-100 score that can be tracked over time.&lt;/li&gt;
  &lt;li&gt;Use the data in your users table to power all kinds of interesting customer communication. Want to communicate with users who have or haven’t used a specific feature and ask them why? Now you can. Want to segment trial users into those who haven’t used that one killer feature and those who have? Go for it.&lt;/li&gt;
&lt;/ul&gt;


                  &lt;hr&gt;
                  &lt;br&gt;
                &lt;/div&gt;

      &lt;/main&gt;

      
    &lt;/div&gt;&lt;/div&gt;&lt;a href="https://www.reifyworks.com/writing/2019-08-26-a-most-software-companies"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:27:34 UT
      </pubDate>
      <guid>
        https://www.reifyworks.com/writing/2019-08-26-a-most-software-companies
      </guid>
    </item>
    <item>
      <title>
        How Gerald Ratner lost $10B in 10 seconds
      </title>
      <link>
        https://thehustle.co/gerald-ratners-billion-dollar-speech
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;
&lt;p&gt;&lt;span&gt;When Gerald Ratner took the stage before 6k high-powered businesspeople, journalists, and dignitaries at London’s Royal Albert Hall in April 1991, he had no idea his speech would be a professional death sentence.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;His incredible success had led him to this moment. He’d inherited a struggling chain of jewelry stores and turned it into a £1B enterprise in less than a decade. He’d flipped an elitist industry on its head by making earrings and rings for the working class. And in the process, he’d built his company, Ratners Group, into the UK’s &lt;/span&gt;&lt;a href="https://www.nytimes.com/1987/07/04/business/company-news-ratners-group-buying-sterling.html"&gt;&lt;span&gt;biggest&lt;/span&gt;&lt;/a&gt;&lt;span&gt;, and most recognizable, jewelry chain.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;But in a matter of seconds on that fateful night in April, a few jokes would destroy it all.&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;The rise of a populist jeweler&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;Gerald Ratner joined his father’s small, fledgling jewelry business in 1965, at the age of 15, after being expelled from grammar school for “being too stupid.” He spent his youth cleaning up the shop, running errands, and getting to know the “grass roots of the business.” &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;When he inherited the company, Ratners Group (AKA “Ratners”), in 1984, it consisted of 120 bland, traditional storefronts, and was posting annual losses of £350k (US$459k).&lt;/span&gt;&lt;/p&gt;
&lt;figure aria-describedby="caption-attachment-9728" id="attachment_9728"&gt;&lt;img data-sizes="(max-width: 600px) 100vw, 600px" data-src="https://thehustle.co/wp-content/uploads/2018/08/ratners-store.jpg" data-srcset="https://thehustle.co/wp-content/uploads/2018/08/ratners-store.jpg 600w, https://thehustle.co/wp-content/uploads/2018/08/ratners-store-300x225.jpg 300w" height="100%" width="2500" alt="" loading="lazy" src="https://thehustle.co/wp-content/uploads/2018/08/ratners-store.jpg" srcset="https://thehustle.co/wp-content/uploads/2018/08/ratners-store.jpg 600w, https://thehustle.co/wp-content/uploads/2018/08/ratners-store-300x225.jpg 300w"&gt;&lt;figcaption id="caption-attachment-9728"&gt;A Ratners jewelry store in 1991, complete with garish advertisements (via Getty Images)&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;&lt;span&gt;In his youth, Ratner had learned a valuable lesson by observing London’s street shops: the &lt;/span&gt;&lt;a href="http://www.todayifoundout.com/index.php/2014/04/speech-cost-nearly-billion-dollars/"&gt;&lt;span&gt;vendors&lt;/span&gt;&lt;/a&gt;&lt;span&gt; who “yelled the loudest and had the most garish, eye-catching displays” landed the most sales. He decided to employ the same strategy at Ratners.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Within months, all Ratners locations were plastered with vibrant orange and red posters with all-caps pitches like “LAST CHANCE — MEGA RED STAR SALE!” and “SALE SALE SALE: HALF PRICE!” Everything in the window was clearly marked with a price tag.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Prior to the 1980s, jewelry had largely been elitist. The average item cost over £300 (about US$950 in today’s dollars) — and jewelers thrived on an aura of exclusivity and prestige.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Ratner made a decision to market his chain toward a wider working class demographic, offering earrings, bracelets, and rings for an average price of just £20, and as low as £1. “I put the earrings and chains in the front of the window and diamond rings at the back, and played pop music,” he later told the &lt;/span&gt;&lt;a href="https://www.ft.com/content/b138e81a-29cd-11e3-9bc6-00144feab7de"&gt;&lt;i&gt;&lt;span&gt;Financial Times&lt;/span&gt;&lt;/i&gt;&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;This approach came at a cost: other jewelers (and the press) constantly berated Ratners for selling “cheap” and “tacky” products.&lt;/span&gt;&lt;/p&gt;
&lt;figure aria-describedby="caption-attachment-9729" id="attachment_9729"&gt;&lt;img data-sizes="(max-width: 600px) 100vw, 600px" data-src="https://thehustle.co/wp-content/uploads/2018/08/ratner-pose-1.jpg" data-srcset="https://thehustle.co/wp-content/uploads/2018/08/ratner-pose-1.jpg 600w, https://thehustle.co/wp-content/uploads/2018/08/ratner-pose-1-300x244.jpg 300w" height="100%" width="2500" alt="" loading="lazy" src="https://thehustle.co/wp-content/uploads/2018/08/ratner-pose-1.jpg" srcset="https://thehustle.co/wp-content/uploads/2018/08/ratner-pose-1.jpg 600w, https://thehustle.co/wp-content/uploads/2018/08/ratner-pose-1-300x244.jpg 300w"&gt;&lt;figcaption id="caption-attachment-9729"&gt;Top: Ratner surveying his goods; Bottom: Ratner proudly displaying his wares shortly after he took over as CEO of Ratners Group (via The Telegraph)&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;&lt;span&gt;But Ratner’s strategy paid off: by 1990, he grew Ratners from 120 to more than 2k stores, captured 50% of the UK’s jewelry market, and had annual sales of £1.2B (US$1.57B) — £125m of which was profit. They bought up competing chains like Jared and Kay Jewelers.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;In quick order, Ratners became a household name and the great democratizer of a previously stuffy industry.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;“[I] just felt [I] could not fail,” &lt;/span&gt;&lt;a href="https://www.ft.com/content/b138e81a-29cd-11e3-9bc6-00144feab7de"&gt;&lt;span&gt;said&lt;/span&gt;&lt;/a&gt;&lt;span&gt; Ratner. Until, of course, he did.&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;The speech that broke the businessman’s back&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;In 1991, Ratner’s success earned him an invitation to speak at the prestigious &lt;/span&gt;&lt;a href="https://en.wikipedia.org/wiki/Institute_of_Directors"&gt;&lt;span&gt;Institute of Directors&lt;/span&gt;&lt;/a&gt;&lt;span&gt; annual convention.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Leading up to his speech, Ratner passed a draft by a public speaking consultant, and was given some advice: “I think you should put in a couple of jokes,” the man &lt;/span&gt;&lt;a href="https://www.thejc.com/business/features/interview-gerald-ratner-1.1929"&gt;&lt;span&gt;told him&lt;/span&gt;&lt;/a&gt;&lt;span&gt;. “People like your jokes.” Unfortunately, Ratner took it to an extreme.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;On the night of April 23, 1991, Ratner began his speech (&lt;/span&gt;&lt;a href="https://www.youtube.com/watch?v=Nj9BZz71yQE"&gt;&lt;span&gt;in full here&lt;/span&gt;&lt;/a&gt;&lt;span&gt;) innocently enough, harping on the event’s thematic values of quality, choice, and prosperity. Then, about 3 minutes in, he dropped several brutally honest jokes.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;“Ratners doesn’t represent prosperity — and come to think of it, it has very little to do with quality as well,” he began. “We do cut-glass sherry decanters complete with six glasses on a silver-plated tray that your butler can serve you drinks on, all for £4.95. People say, ‘How can you sell this for such a low price?’ I say, because it’s total crap.”&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Then, several minutes later, just for good measure: “We even sell a pair of [gold] earrings for under £1,” he said. “Some people say, ‘That’s cheaper than a prawn sandwich!’…I have to say, the sandwich will probably last longer than the earrings.”&lt;/span&gt;&lt;/p&gt;
&lt;figure aria-describedby="caption-attachment-9730" id="attachment_9730"&gt;&lt;img data-sizes="(max-width: 600px) 100vw, 600px" data-src="https://thehustle.co/wp-content/uploads/2018/08/ratnerspeech.jpg" data-srcset="https://thehustle.co/wp-content/uploads/2018/08/ratnerspeech.jpg 600w, https://thehustle.co/wp-content/uploads/2018/08/ratnerspeech-300x219.jpg 300w" height="100%" width="2500" alt="" loading="lazy" src="https://thehustle.co/wp-content/uploads/2018/08/ratnerspeech.jpg" srcset="https://thehustle.co/wp-content/uploads/2018/08/ratnerspeech.jpg 600w, https://thehustle.co/wp-content/uploads/2018/08/ratnerspeech-300x219.jpg 300w"&gt;&lt;figcaption id="caption-attachment-9730"&gt;Gerald Ratner’s ill-fated jokes (&lt;a href="https://thehustle.co/"&gt;The Hustle&lt;/a&gt;)&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;&lt;span&gt;The next morning, Ratner awoke to terrifying news: his comments had made national headlines to the effect of: “JEWELRY CEO CALLS HIS OWN PRODUCTS ‘CRAP.’” The &lt;/span&gt;&lt;i&gt;&lt;span&gt;Sunday Times&lt;/span&gt;&lt;/i&gt;&lt;span&gt; dubbed him “Gerald Crapner” — a nickname that caught on with disgruntled ex-customers.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Initially, Ratner tried to play it off by featuring special in-store promotions that put a “humorous twist” on his remarks — but within a few weeks, it was clear that what he’d said had taken an irreparable toll on his business.&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;The downfall &lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;Within a few days of the speech, Ratners Group shares dropped by £500 million (US$1.8B today); by the end of 1991, its stock &lt;/span&gt;&lt;a href="https://timesmachine.nytimes.com/timesmachine/1991/12/08/307091.html?action=click&amp;amp;contentCollection=Archives&amp;amp;module=LedeAsset&amp;amp;region=ArchiveBody&amp;amp;pgtype=article&amp;amp;pageNumber=202"&gt;&lt;span&gt;was down 80%&lt;/span&gt;&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;One-time enthusiastic customers boycotted the brand and Ratners, which was quickly losing sales volume, was forced to close down hundreds of stores and lay off a hefty percentage of its 25k-person workforce.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;The company claimed there had been a “shift in consumer spending habits,” and that the &lt;/span&gt;&lt;a href="https://www.telegraph.co.uk/finance/9891085/From-the-archive-Ratner-says-recession-to-blame-for-17.7m-loss-not-controversial-comments.html"&gt;&lt;span&gt;ongoing recession&lt;/span&gt;&lt;/a&gt;&lt;span&gt; had finally caught up to its bottom line. But stock charts show the company suffered clear consequences from Ratner’s speech.&lt;/span&gt;&lt;/p&gt;
&lt;figure aria-describedby="caption-attachment-9731" id="attachment_9731"&gt;&lt;img data-sizes="(max-width: 600px) 100vw, 600px" data-src="https://thehustle.co/wp-content/uploads/2018/08/ratners-share.jpg" data-srcset="https://thehustle.co/wp-content/uploads/2018/08/ratners-share.jpg 600w, https://thehustle.co/wp-content/uploads/2018/08/ratners-share-300x219.jpg 300w" height="100%" width="2500" alt="" loading="lazy" src="https://thehustle.co/wp-content/uploads/2018/08/ratners-share.jpg" srcset="https://thehustle.co/wp-content/uploads/2018/08/ratners-share.jpg 600w, https://thehustle.co/wp-content/uploads/2018/08/ratners-share-300x219.jpg 300w"&gt;&lt;figcaption id="caption-attachment-9731"&gt;Ratners stock declined by as much as 80% within 10 months of Ratner’s comments (Zachary Crockett/The Hustle)&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;&lt;span&gt;In November of 1992, Ratner was let go as CEO of Ratners Group. The day he left, he sold his shares for “pittance” to pay off the £1B (US$1.3B) he owed the bank, and walked away with nothing.&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;The Ratner effect&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;In an age where tweet-happy CEOs are empowered with large digital audiences they can instantly broadcast to, Ratner’s story is a worthy parable.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Today, the phrase “Doing a Ratner” is British &lt;/span&gt;&lt;a href="https://www.theguardian.com/business/2009/mar/07/gerald-ratner-interview"&gt;&lt;span&gt;parlance&lt;/span&gt;&lt;/a&gt;&lt;span&gt; for any time someone says something stupid that undermines his or her own product or customers — something that tends to play out more often than it should.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;We’ve seen many similarly high-profile stumbles in recent years:&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.telegraph.co.uk/news/2017/08/02/helen-mirren-admits-loreal-moisturiser-probably-does-f/"&gt;&lt;span&gt;Helen Mirren&lt;/span&gt;&lt;/a&gt;&lt;span&gt;, actress and paid brand ambassador of L’Oreal, said that using the company’s products “probably does f*ck all.”&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.theguardian.com/politics/2003/oct/17/uk.creditcards"&gt;&lt;span&gt;Matt Barrett&lt;/span&gt;&lt;/a&gt;&lt;span&gt;, ex-CEO of Barclays, insinuated that customers shouldn’t use the bank’s credit card products because they could “pile up debts.”&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.theguardian.com/business/nils-pratley-on-finance/2011/nov/15/john-pluthero-cww-ceo-quits"&gt;&lt;span&gt;John Pluthero&lt;/span&gt;&lt;/a&gt;&lt;span&gt;, then-CEO of the telecom giant Cable &amp;amp; Wireless, sent out a memo calling his company an “underperforming business in a crappy industry.”&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://business.time.com/2012/09/11/thats-some-quirky-marketing-strategy-ceo-calls-his-customers-idiots/"&gt;&lt;span&gt;Michael O’Leary&lt;/span&gt;&lt;/a&gt;&lt;span&gt;, CEO of Ryanair, called his passengers “idiots;” on another occasion, he said customers who ask for a refund should “f**k off.”&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mashable.com/2015/10/08/lululemon-ceo-apologizes/"&gt;&lt;span&gt;Chip Wilson&lt;/span&gt;&lt;/a&gt;&lt;span&gt;, founder of lululemon, told customers his products “don’t work for certain women’s bodies.”&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span&gt;A &lt;/span&gt;&lt;a href="https://hbr.org/2016/06/we-studied-38-incidents-of-ceo-bad-behavior-and-measured-their-consequences"&gt;&lt;span&gt;Harvard Business School study&lt;/span&gt;&lt;/a&gt;&lt;span&gt; that analyzed instances of CEO misbehavior between 200 and 2015 found that the average comment (or action) resulted in 250 negative news stories (some of which were cited up to 5 years later), and a 3.1% decline in company stock price.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Though not true “Doing a Ratner” situations, we’ve also seen a number of business leaders say incredibly stupid things in a very public way, with very real financial consequences: twice this year, Tesla stock has fallen 4-5% after &lt;/span&gt;&lt;a href="https://www.cnbc.com/2018/07/16/tesla-sinks-after-elon-musk-tweets-again.html"&gt;&lt;span&gt;Elon Musk&lt;/span&gt;&lt;/a&gt;&lt;span&gt; spoke — once in &lt;/span&gt;&lt;a href="https://markets.businessinsider.com/news/stocks/tesla-stock-price-is-falling-after-elon-musk-jokes-about-the-company-going-bankrupt-2018-4-1020247710"&gt;&lt;span&gt;April&lt;/span&gt;&lt;/a&gt;&lt;span&gt;, when he joked about going “bankrupt,” and again in &lt;/span&gt;&lt;a href="https://www.cnbc.com/2018/07/16/tesla-sinks-after-elon-musk-tweets-again.html"&gt;&lt;span&gt;July&lt;/span&gt;&lt;/a&gt;&lt;span&gt;, when he called a Thai cave rescuer a “pedo guy.”&lt;/span&gt;&lt;/p&gt;
&lt;figure aria-describedby="caption-attachment-9732" id="attachment_9732"&gt;&lt;img data-sizes="(max-width: 600px) 100vw, 600px" data-src="https://thehustle.co/wp-content/uploads/2018/08/share-musk.jpg" data-srcset="https://thehustle.co/wp-content/uploads/2018/08/share-musk.jpg 600w, https://thehustle.co/wp-content/uploads/2018/08/share-musk-300x165.jpg 300w" height="100%" width="2500" alt="" loading="lazy" src="https://thehustle.co/wp-content/uploads/2018/08/share-musk.jpg" srcset="https://thehustle.co/wp-content/uploads/2018/08/share-musk.jpg 600w, https://thehustle.co/wp-content/uploads/2018/08/share-musk-300x165.jpg 300w"&gt;&lt;figcaption id="caption-attachment-9732"&gt;Elon Musk (right) has drawn comparisons to Gerald Ratner in recent years, in part for his constant barrage of controversial tweets that impact Tesla’s stock (via Daily Express, SpaceX)&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;&lt;span&gt;As for Ratner?&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;After losing everything, he toiled in misery for years — but he eventually made an improbable comeback. In 1997, he took out a £155k (US$203k) loan on his house, built up a health club business, and sold it for £3.9m (US$5.1m). He then used the profits to start an online jewelry company. (The Ratners Group rebranded as &lt;/span&gt;&lt;a href="https://en.wikipedia.org/wiki/Signet_Jewelers"&gt;&lt;span&gt;Signet&lt;/span&gt;&lt;/a&gt;&lt;span&gt; in 1993; today, it is the largest diamond retailer in the world.)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;But Ratner is unlikely to ever live down his ill-timed remarks nearly 3 decades ago.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;‘It doesn’t seem to matter that in the ‘80s I was Britain’s largest jeweler, with over 50% of the UK market,” he &lt;/span&gt;&lt;a href="http://www.thisismoney.co.uk/money/markets/article-2371730/GERALD-RATNER-INTERVIEW-How-I-cut-cr-p--The-return-UKs-biggest-online-jeweller.html"&gt;&lt;span&gt;told&lt;/span&gt;&lt;/a&gt; &lt;i&gt;&lt;span&gt;This Is Money&lt;/span&gt;&lt;/i&gt;&lt;span&gt;.&lt;/span&gt; &lt;span&gt;“My obituary will be all about being a disaster.”&lt;/span&gt;&lt;/p&gt;

 &lt;/div&gt;&lt;/div&gt;&lt;a href="https://thehustle.co/gerald-ratners-billion-dollar-speech"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:28:17 UT
      </pubDate>
      <guid>
        https://thehustle.co/gerald-ratners-billion-dollar-speech
      </guid>
    </item>
    <item>
      <title>
        App-pocalypse Now
      </title>
      <link>
        https://blog.codinghorror.com/app-pocalypse-now/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;section&gt;
                &lt;p&gt;
I'm getting pretty sick of being nagged to install your damn apps.
&lt;/p&gt;
&lt;p&gt;
&lt;img height="279" width="669" src="https://blog.codinghorror.com/content/images/uploads/2014/02/6a0120a85dcdae970b01a3fcc4a231970b-pi.jpg" title="This-website-has-an-ipad-app" alt="This-website-has-an-ipad-app"&gt;&lt;br&gt;
&lt;/p&gt;
&lt;p&gt;
XKCD helpfully &lt;a href="http://xkcd.com/1174/"&gt;translates&lt;/a&gt;:
&lt;/p&gt;
&lt;p&gt;
&lt;a href="http://xkcd.com/1174/"&gt;&lt;img height="318" width="474" src="https://blog.codinghorror.com/content/images/uploads/2014/02/6a0120a85dcdae970b01a73d7faa6b970d-pi.png" title="Xkcd-download-our-app" alt="Xkcd-download-our-app"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;
Yeah, there are &lt;a href="https://developer.apple.com/library/ios/documentation/AppleApplications/Reference/SafariWebContent/PromotingAppswithAppBanners/PromotingAppswithAppBanners.html"&gt;smart app banners&lt;/a&gt;, which are marginally less annoying, but it's amazing how quickly we went from "Cool! Phone apps that &lt;a href="http://www.codinghorror.com/blog/2009/06/the-iphone-software-revolution.html"&gt;finally don't suck!&lt;/a&gt;" to this sad, eye rolling, oh-great-of-&lt;i&gt;course&lt;/i&gt;-you-have-an-app-too state of affairs.
&lt;/p&gt;
&lt;blockquote lang="en"&gt;&lt;p&gt;"Would you like to install our free app?!?" is the new "It looks like you're writing a letter!"&lt;/p&gt;— Jeff Atwood (@codinghorror) &lt;a href="https://twitter.com/codinghorror/statuses/288918388141617152"&gt;January 9, 2013&lt;/a&gt;&lt;/blockquote&gt;


&lt;p&gt;
Four years, give or take a few months, if you were counting. So what happened?
&lt;/p&gt;
&lt;h2&gt;Millions of pointless apps&lt;/h2&gt;
&lt;p&gt;Your platform now has a &lt;i&gt;million&lt;/i&gt; apps? Amazing! Wonderful! What they don't tell you is that 99% of them are awful junk that nobody would ever want.
&lt;/p&gt;
&lt;p&gt;
Let's start with the basics. How do you know which apps you need? How do you get them installed? How do you keep them updated? How many apps can you reasonably keep track of on a phone? On a tablet? Just the home screen? A few screens? A dozen screens? When you have millions of apps out there, this rapidly becomes less of a "slap a few icons on the page" problem and more of a search problem like the greater web. My son's iPad has more than 10 pages of apps now, we don't even bother with the pretense of scrolling through pages of icons, we just go straight to search every time.
&lt;/p&gt;
&lt;p&gt;
&lt;a href="http://solveforinteresting.com/facebooks-rocks-and-hard-places/"&gt;&lt;img height="251" width="610" src="https://blog.codinghorror.com/content/images/uploads/2014/02/6a0120a85dcdae970b01a73d7fadee970d-pi.jpg" title="Walledgarden-cover" alt="Walledgarden-cover"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;
The more apps out there, the more the app stores are clogged with mediocre junk, the more the overall noise level keeps going up, which leads directly to this profligate nagging. Companies keep asking &lt;i&gt;how can we get people to find and install our amazing app&lt;/i&gt; instead of the one question they really should have asked.
&lt;/p&gt;
&lt;p&gt;
&lt;i&gt;Why the hell are we building an app in the first place?&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;
I want to know who exactly is going to all the trouble of installing the McDonalds app on their device instead of simply visiting the McDonalds website in the browser as needed. What problem does that app solve for &lt;a href="http://aht.seriouseats.com/archives/2010/05/the-burger-lab-how-to-make-perfect-mcdonalds-style-french-fries.html"&gt;french fry enthusiasts&lt;/a&gt; that it needs to be permanently installed on your device? Why are they &lt;a href="http://slickdeals.net/f/5437442-free-mcdonald-s-sandwich-with-app"&gt;giving away free Big Macs&lt;/a&gt; just to get people to install this thing?
&lt;/p&gt;
&lt;h2&gt;Fragmentation into parallel and incompatible app worlds&lt;/h2&gt;
&lt;p&gt;It was so much easier when iOS was totally dominant and the iPhone was the only player. Before the iPad and tablets. Before Android got decent in 4.0 and Google standardized the Play store. Now there are, at minimum, &lt;i&gt;four&lt;/i&gt; radically different mobile platforms that every serious app player has to support:
&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Android phone
&lt;/li&gt;&lt;li&gt;iOS phone
&lt;/li&gt;&lt;li&gt;iOS tablet
&lt;/li&gt;&lt;li&gt;Android tablet
&lt;/li&gt;&lt;/ol&gt;
&lt;p&gt;(For extra credit: how many of these are actually "mobile"?)&lt;/p&gt;
&lt;p&gt;
Unless you're careful to build equivalent apps in all those places, it's like having multiple parallel Internets. "No, sorry, it's not available on that Internet, only the iOS phone Internet." Or even worse, only on the United States iOS phone Internet.&lt;/p&gt;
&lt;p&gt;
If you're feeling generous, we should technically include Windows 8 and Windows Phone in here too. All with different screen dimensions, development stacks, UI guidelines, and usage patterns. Oh and by the way, that's assuming no other players emerge as serious contenders in the computing device market. &lt;i&gt;Ever.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;At the point where you find yourself praying for a duopoly as one of the better possible outcomes, that's … not a good sign.&lt;/p&gt;
&lt;h2&gt;Paying for apps became a race to the bottom&lt;/h2&gt;
&lt;p&gt;Buying an app is the modern &lt;a href="http://www.codinghorror.com/blog/2006/12/today-is-support-your-favorite-small-software-vendor-day.html"&gt;Support Your Favorite Small Software Vendor Day&lt;/a&gt;. I was always fine with dropping ten or twenty bucks on software I loved. I'm a software engineer by profession; apps are cheaper so I can buy even more of them.&lt;/p&gt;
&lt;p&gt;Have you ever noticed that the people complaining about apps that cost $3.99 are the same people dropping five bucks on a cup of fancy coffee without batting an eyelash? Me too, and &lt;a href="http://www.joshlehman.com/thoughts/stop-using-the-cup-of-coffee-vs-0-99-cent-app-analogy/"&gt;I'm with the coffee people&lt;/a&gt;. $3.99 for your app? &lt;i&gt;Outraaageous!&lt;/i&gt;&lt;/p&gt;
&lt;blockquote&gt;
Now, contrast this with your app, Mr. Developer. I don’t know you from Adam. You’re pitching digital Instant Refresher Juice 1.0 to me in the form of a new app. The return I’m going to get is questionable at best. I already have 30 apps on my phone, some of them very good. Do I need another one? I don’t use the 30 I have. The experience I’m going to get from adding one more app is not trustable. I’m assured of nothing. Last week I bought an app for 99 cents and it was terrible. I used it once, for 15 seconds. I could be shoving $1 straight down the toilet again for all I know. Your app, good sir, is a total gamble. Sure, it’s only a $1 gamble… but it’s a gamble and that fact matters more than any price you might place on it.
&lt;/blockquote&gt;
&lt;p&gt;For some reason I don't completely understand, mobile app review systems are frequently of questionable value, so all you really have to go on are the screenshots and a bit of text provided by the developer.&lt;/p&gt;
&lt;p&gt;Imagine you bought your coffee, only to open the lid and find it was only half full, or that it wasn't coffee at all but lemonade. If only 1 in 5 cups of coffee you bought actually contained coffee, a $3.99 price for that coffee starts to seem &lt;a href="http://struct.ca/2010/how-to-price-your-game/"&gt;unreasonably high&lt;/a&gt;. &lt;b&gt;When you buy an app, you don't really know what you're going to get.&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;Turns out, the precious resource here isn't the money after all. &lt;i&gt;It's your time.&lt;/i&gt; In a world of millions of apps, free is the correct and only price for most apps except those rare few of extreme, easily demonstrable value – probably from well known brands of websites you already use daily. So hey, everything is &lt;i&gt;free!&lt;/i&gt; Awesome! Right? Well…
&lt;/p&gt;&lt;h2&gt;When apps are free, you're the product&lt;/h2&gt;
&lt;p&gt;I know, I know, I'm sick of this trite phrase too. But if the market is emphatically proving that free is the only sustainable model for apps, then this is the new reality we have to acknowledge.&lt;/p&gt;
&lt;p&gt;
&lt;a href="http://geekandpoke.typepad.com/geekandpoke/2010/12/the-free-model.html"&gt;&lt;img height="454" width="521" src="https://blog.codinghorror.com/content/images/uploads/2014/02/6a0120a85dcdae970b01a3fcc55683970b-800wi.png" title="Geek-and-poke-pigs-free" alt="Geek-and-poke-pigs-free"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;Nothing terrifies me more than an app with no moral conscience in the desperate pursuit of revenue that has full access to everything on my phone: contacts, address book, pictures, email, auth tokens, you name it. I'm not excited by the prospect of installing an app on my phone these days. It's more like a vague sense of impending dread, with my finger shakily hovering over the uninstall button the whole time. All I can think is &lt;b&gt;what shitty thing is this "free" app going to do to me so they can satisfy their investors?&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;For the sake of argument, let's say the app is free, and the developers are ethical, so you trust that they won't do anything sketchy with the personal information on your device to make ends meet. Great!  But they still have to make a living, don't they? Which means doing anything &lt;i&gt;useful&lt;/i&gt; in the app requires buying three "optional" add-ons that cost $2.99 each. Or there are special fees for performing certain actions. Isn't this stuff you would want to know before installing the app? You betcha. Maybe the app is properly tagged as "offering in-app purchases" but &lt;b&gt;the entire burden of discovering exactly what "in-app purchases" means, and how much the app will ultimately cost you, is placed completely on your shoulders.&lt;/b&gt; You, the poor, bedraggled user.
&lt;/p&gt;
&lt;h2&gt;The app user experience is wildly inconsistent&lt;/h2&gt;
&lt;p&gt;Have you ever tried actually &lt;i&gt;using&lt;/i&gt; the Amazon app on iOS, Android, and Windows? iOS does the best, mostly because it's been an app platform for longer than the others, but even there, the Amazon app is a frustrating morass of missing and incomplete functions from the website. Sure, maybe you don't need the full breadth of Amazon functions on your phone, though that's debatable on a tablet. But natural web conveniences like opening links in new tabs, sharing links, the back button, searching within the page, and zooming in and out are available inconsistently, if at all.
&lt;/p&gt;
&lt;p&gt;The minute you begin switching between platforms – say you use an iOS tablet and an Android phone and a Windows 8 touch laptop, like I do – you'll find there are &lt;i&gt;massive&lt;/i&gt; differences between the Amazon apps (and the eBay apps, and the Netflix apps, and the..) on these different platforms. At some point, you just get fed up with all the inconsistencies and oddities and quirks and say to hell with these apps, &lt;b&gt;can I please just use the website instead?&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;
Now, if your website is an awful calcified throwback to 2003, like eBay, then the &lt;a href="http://www.codinghorror.com/blog/2012/04/will-apps-kill-websites.html"&gt;mobile apps can be a valuable opportunity to reinvent your user interface&lt;/a&gt; without alienating all your existing users. If there's one thing I love about tablet and phone design it's that their small screens and touch interfaces force people to &lt;a href="http://www.codinghorror.com/blog/2006/03/in-pursuit-of-simplicity.html"&gt;think simpler&lt;/a&gt;. This is a good thing. But if you don't eventually take those improvements home to the mothership, you're creating two totally different and incompatible UIs for doing the same things.
&lt;/p&gt;
&lt;p&gt;It seems like a fool's errand to dump millions of dollars of development time into these radically different, siloed app platforms when Amazon could have spent it improving their website and making that experience scale a bit better to every device out there.
&lt;/p&gt;
&lt;h2&gt;The World Wide App&lt;/h2&gt;
&lt;p&gt;But that's not an option, because apparently &lt;a href="https://twitter.com/rabois/status/406519032624320512"&gt;the web is dead&lt;/a&gt;, and mobile apps are the future. I'm doing my best to resist a sudden uncontrollable urge to use my Ledge Finder app to find the nearest ledge to jump from right now.&lt;/p&gt;
&lt;p&gt;The tablet and phone app ecosystem is slowly, painstakingly reinventing everything I hated about the computer software industry before the web blew it all up. Even fans &lt;a href="http://parislemon.com/post/77357979234/a-new-glue-for-a-new-kingdom"&gt;are concerned&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
I’m waiting for something that will unify the world of apps and make manually going to an App Store to find a new app as weird as typing in a URL to find a new website. My bet is that this won’t be Facebook. Instead, I would not bet against some young upstart, perhaps one inspired upon reading about a $19 billion deal, to go heads-down and come up with something crazy.
&lt;/blockquote&gt;
&lt;p&gt;
I'll have more to say about this soon, but I expect there to be an explosion of new computing devices all over the world in the next few decades, not a contraction. Sometimes the craziest solution is the one that's been right there in front of you the whole time.
&lt;/p&gt;


            &lt;/section&gt;&lt;/div&gt;&lt;a href="https://blog.codinghorror.com/app-pocalypse-now/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:28:28 UT
      </pubDate>
      <guid>
        https://blog.codinghorror.com/app-pocalypse-now/
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://howistart.org/posts/erlang/1/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;span&gt;b&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;c&lt;/span&gt;&lt;span&gt;().&lt;/span&gt;

&lt;span&gt;c&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;done&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;
&lt;p&gt;Of course, there’s going to be more data in our case.&lt;/p&gt;
&lt;h2 id="the-prototype"&gt;The Prototype&lt;/h2&gt;
&lt;p&gt;Our glorious application will be called ‘muumuu’. Whenever I don’t exactly know
where I’m going, I decide to prototype stuff. And here I stress the importance
of &lt;em&gt;prototype&lt;/em&gt;. Despite this fact, it will often end up being in production, but
yeah – that’s to be avoided.&lt;/p&gt;
&lt;p&gt;I decide to start with the basic stuff to prototype, state transitions. I go for
them in a fairly simple manner, top-down:&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;code data-lang="erlang"&gt;&lt;span&gt;-&lt;/span&gt;&lt;span&gt;module&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;muumuu_fsm&lt;/span&gt;&lt;span&gt;).&lt;/span&gt;
&lt;span&gt;-&lt;/span&gt;&lt;span&gt;export&lt;/span&gt;&lt;span&gt;([&lt;/span&gt;&lt;span&gt;start&lt;/span&gt;&lt;span&gt;/&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;]).&lt;/span&gt;

&lt;span&gt;-&lt;/span&gt;&lt;span&gt;define&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;MAX_NO_VENT&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;5&lt;/span&gt;&lt;span&gt;).&lt;/span&gt;

&lt;span&gt;start&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;    %% S&lt;/span&gt;&lt;span&gt;eed&lt;/span&gt; &lt;span&gt;PRNG&lt;/span&gt;
    &lt;span&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span&gt;A&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;32&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;B&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;32&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;C&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;32&lt;/span&gt;&lt;span&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;crypto&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;rand_bytes&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;&lt;span&gt;),&lt;/span&gt;
    &lt;span&gt;random&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;seed&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;A&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;B&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;C&lt;/span&gt;&lt;span&gt;),&lt;/span&gt;
    &lt;span&gt;wait_any_key&lt;/span&gt;&lt;span&gt;().&lt;/span&gt;


&lt;span&gt;%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
&lt;/span&gt;&lt;span&gt;%%% States and Transitions %%%
&lt;/span&gt;&lt;span&gt;%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;wait_any_key&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;io&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;get_line&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"To Start, Press Any Key.&lt;/span&gt;&lt;span&gt;\n&lt;/span&gt;&lt;span&gt;&amp;gt; "&lt;/span&gt;&lt;span&gt;),&lt;/span&gt;
    &lt;span&gt;first_core_check&lt;/span&gt;&lt;span&gt;().&lt;/span&gt;

&lt;span&gt;first_core_check&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;case&lt;/span&gt; &lt;span&gt;option&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"Check core temperature?"&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;of&lt;/span&gt;
        &lt;span&gt;yes&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;core_temperature&lt;/span&gt;&lt;span&gt;();&lt;/span&gt;
        &lt;span&gt;no&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;noop&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;
    &lt;span&gt;end&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
    &lt;span&gt;first_gas_vent&lt;/span&gt;&lt;span&gt;().&lt;/span&gt;

&lt;span&gt;first_gas_vent&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;case&lt;/span&gt; &lt;span&gt;option&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"Vent radioactive gas?"&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;of&lt;/span&gt;
        &lt;span&gt;yes&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;blow_crops_away&lt;/span&gt;&lt;span&gt;();&lt;/span&gt;
        &lt;span&gt;no&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;venting_prevents_explosions&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;
    &lt;span&gt;end&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
    &lt;span&gt;wait_for_command&lt;/span&gt;&lt;span&gt;().&lt;/span&gt;

&lt;span&gt;wait_for_command&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;case&lt;/span&gt; &lt;span&gt;wait_cmd&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;10000&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;of&lt;/span&gt;
        &lt;span&gt;timeout&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;            {O&lt;/span&gt;&lt;span&gt;pt&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Yes&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;No&lt;/span&gt;&lt;span&gt;}&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;random_option&lt;/span&gt;&lt;span&gt;(),&lt;/span&gt;
            &lt;span&gt;case&lt;/span&gt; &lt;span&gt;option&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Opt&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;of&lt;/span&gt;
                &lt;span&gt;yes&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; Y&lt;/span&gt;&lt;span&gt;es&lt;/span&gt;&lt;span&gt;();&lt;/span&gt;
                &lt;span&gt;no&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; N&lt;/span&gt;&lt;span&gt;o&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;
            &lt;span&gt;end&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
        &lt;span&gt;Cmd&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;            &lt;/span&gt;&lt;span&gt;case&lt;/span&gt; &lt;span&gt;match_option&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Cmd&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;of&lt;/span&gt;
                &lt;span&gt;{_,&lt;/span&gt; &lt;span&gt;Yes&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;_}&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; Y&lt;/span&gt;&lt;span&gt;es&lt;/span&gt;&lt;span&gt;();&lt;/span&gt;
                &lt;span&gt;_&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;noop&lt;/span&gt;
            &lt;span&gt;end&lt;/span&gt;
    &lt;span&gt;end&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
    &lt;span&gt;wait_for_command&lt;/span&gt;&lt;span&gt;().&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In this bit of code, we can see our 4 main states:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;wait_any_key&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;first_core_check&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;first_gas_event&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;wait_for_command&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The rest of the code is more or less going to be events and input management to
check the transitions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;printing questions and getting responses (&lt;code&gt;option/1&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;eventually waiting for a command (&lt;code&gt;wait_cmd/1&lt;/code&gt; and &lt;code&gt;match_option/1&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;or, if it takes too long, generate an option randomly (&lt;code&gt;random_option/1&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can look at the code, find whatever you want about it disgusting. So that’s
the general idea I want in the code. Time to add all that option management
stuff:&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;code data-lang="erlang"&gt;&lt;span&gt;%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
&lt;/span&gt;&lt;span&gt;%%% Options and Response Handling %%%
&lt;/span&gt;&lt;span&gt;%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;option&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Prompt&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;show_option&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Prompt&lt;/span&gt;&lt;span&gt;),&lt;/span&gt;
    &lt;span&gt;Data&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;io&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;get_line&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;""&lt;/span&gt;&lt;span&gt;),&lt;/span&gt;
    &lt;span&gt;case&lt;/span&gt; &lt;span&gt;iolist_to_binary&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Data&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;of&lt;/span&gt;
        &lt;span&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span&gt;"Y"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;_&lt;/span&gt;&lt;span&gt;/&lt;/span&gt;&lt;span&gt;binary&lt;/span&gt;&lt;span&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;yes&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span&gt;"y"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;_&lt;/span&gt;&lt;span&gt;/&lt;/span&gt;&lt;span&gt;binary&lt;/span&gt;&lt;span&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;yes&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span&gt;"N"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;_&lt;/span&gt;&lt;span&gt;/&lt;/span&gt;&lt;span&gt;binary&lt;/span&gt;&lt;span&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;no&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span&gt;"n"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;_&lt;/span&gt;&lt;span&gt;/&lt;/span&gt;&lt;span&gt;binary&lt;/span&gt;&lt;span&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;no&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
        &lt;span&gt;_&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;ambiguous&lt;/span&gt;
    &lt;span&gt;end&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;

&lt;span&gt;show_option&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Str&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;io&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;format&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"&lt;/span&gt;&lt;span&gt;~s&lt;/span&gt;&lt;span&gt; (Y/N)&lt;/span&gt;&lt;span&gt;~n&lt;/span&gt;&lt;span&gt;&amp;gt; "&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;Str&lt;/span&gt;&lt;span&gt;]).&lt;/span&gt;

&lt;span&gt;wait_cmd&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Timeout&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;    P&lt;/span&gt;&lt;span&gt;arent&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;self&lt;/span&gt;&lt;span&gt;(),&lt;/span&gt;
    &lt;span&gt;Pid&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;spawn&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;fun&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; P&lt;/span&gt;&lt;span&gt;arent&lt;/span&gt; &lt;span&gt;!&lt;/span&gt; &lt;span&gt;io&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;get_line&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;""&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;end&lt;/span&gt;&lt;span&gt;),&lt;/span&gt;
    &lt;span&gt;receive&lt;/span&gt;
        &lt;span&gt;Data&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; D&lt;/span&gt;&lt;span&gt;ata&lt;/span&gt;
    &lt;span&gt;after&lt;/span&gt; &lt;span&gt;Timeout&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;        &lt;/span&gt;&lt;span&gt;exit&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Pid&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;kill&lt;/span&gt;&lt;span&gt;),&lt;/span&gt;
        &lt;span&gt;timeout&lt;/span&gt;
    &lt;span&gt;end&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;

&lt;span&gt;random_option&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;    P&lt;/span&gt;&lt;span&gt;os&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;random&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;uniform&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;tuple_size&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;opts&lt;/span&gt;&lt;span&gt;())),&lt;/span&gt;
    &lt;span&gt;{_,&lt;/span&gt; &lt;span&gt;Val&lt;/span&gt;&lt;span&gt;}&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;element&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Pos&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;opts&lt;/span&gt;&lt;span&gt;()),&lt;/span&gt;
    &lt;span&gt;Val&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;

&lt;span&gt;match_option&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Data&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;case&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;Vals&lt;/span&gt; &lt;span&gt;||&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;Pattern&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Vals&lt;/span&gt;&lt;span&gt;}&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;-&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;tuple_to_list&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;opts&lt;/span&gt;&lt;span&gt;()),&lt;/span&gt;
                  &lt;span&gt;nomatch&lt;/span&gt; &lt;span&gt;=/=&lt;/span&gt; &lt;span&gt;re&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;run&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Data&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Pattern&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;caseless&lt;/span&gt;&lt;span&gt;])]&lt;/span&gt; &lt;span&gt;of&lt;/span&gt;
        &lt;span&gt;[&lt;/span&gt;&lt;span&gt;Opt&lt;/span&gt;&lt;span&gt;|_]&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; O&lt;/span&gt;&lt;span&gt;pt&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
        &lt;span&gt;[]&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;invalid_opt&lt;/span&gt;
    &lt;span&gt;end&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Cool. Not fantastic looking yet. Basically, an option will only fetch a line of
text entered by the user, look at the first response, and return what it is.
Showing the options just wraps things up so they look like a prompt.&lt;/p&gt;
&lt;p&gt;Interestingly enough, the command has to be waited for in a different process.
The problem with this it that Erlang’s standard library doesn’t support a
timeout mode for &lt;code&gt;io&lt;/code&gt; operations, which would tell us “wait 10 seconds for
input or quit”. Therefore, there is a need to move this to a process.&lt;/p&gt;
&lt;p&gt;The rest relies on an elusive &lt;code&gt;opts()&lt;/code&gt; function that apparently returns all
questions and options offered to the user:&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;code data-lang="erlang"&gt;&lt;span&gt;%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
&lt;/span&gt;&lt;span&gt;%%% Defining Options/Events %%%
&lt;/span&gt;&lt;span&gt;%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;opts&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;    {{"(&lt;/span&gt;&lt;span&gt;check&lt;/span&gt;&lt;span&gt;|&lt;/span&gt;&lt;span&gt;core&lt;/span&gt;&lt;span&gt;|&lt;/span&gt;&lt;span&gt;temp&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;",
&lt;/span&gt;&lt;span&gt;      {"&lt;/span&gt;&lt;span&gt;Check&lt;/span&gt; &lt;span&gt;core&lt;/span&gt; &lt;span&gt;temperature&lt;/span&gt;&lt;span&gt;?&lt;/span&gt;&lt;span&gt;",
&lt;/span&gt;&lt;span&gt;       fun core_temperature/0,
&lt;/span&gt;&lt;span&gt;       fun noop/0}},
&lt;/span&gt;&lt;span&gt;     {"&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;vent&lt;/span&gt;&lt;span&gt;|&lt;/span&gt;&lt;span&gt;rad&lt;/span&gt;&lt;span&gt;|&lt;/span&gt;&lt;span&gt;gas&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;",
&lt;/span&gt;&lt;span&gt;      {"&lt;/span&gt;&lt;span&gt;Vent&lt;/span&gt; &lt;span&gt;radioactive&lt;/span&gt; &lt;span&gt;gas&lt;/span&gt;&lt;span&gt;?&lt;/span&gt;&lt;span&gt;",
&lt;/span&gt;&lt;span&gt;       fun vent_gas/0,
&lt;/span&gt;&lt;span&gt;       fun no_venting/0}},
&lt;/span&gt;&lt;span&gt;     {"&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;sound&lt;/span&gt;&lt;span&gt;|&lt;/span&gt;&lt;span&gt;alert&lt;/span&gt;&lt;span&gt;|&lt;/span&gt;&lt;span&gt;horn&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;",
&lt;/span&gt;&lt;span&gt;      {"&lt;/span&gt;&lt;span&gt;Sound&lt;/span&gt; &lt;span&gt;alertness&lt;/span&gt; &lt;span&gt;horn&lt;/span&gt;&lt;span&gt;?&lt;/span&gt;&lt;span&gt;",
&lt;/span&gt;&lt;span&gt;       fun sound_horn/0,
&lt;/span&gt;&lt;span&gt;       fun noop/0}},
&lt;/span&gt;&lt;span&gt;     {"&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;calc&lt;/span&gt;&lt;span&gt;|&lt;/span&gt;&lt;span&gt;duct&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;",
&lt;/span&gt;&lt;span&gt;      {"&lt;/span&gt;&lt;span&gt;Decalcify&lt;/span&gt; &lt;span&gt;calcium&lt;/span&gt; &lt;span&gt;ducts&lt;/span&gt;&lt;span&gt;?&lt;/span&gt;&lt;span&gt;",
&lt;/span&gt;&lt;span&gt;       fun noop/0,
&lt;/span&gt;&lt;span&gt;       fun noop/0}}}.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This basically is a tuple (I use a tuple because it makes random selection with
a fixed position more efficient) of all questions, positive and negative
response and consequences, paired up with a regular expression that represents
fuzzy matching – for example, someone typing it &lt;code&gt;check temperature&lt;/code&gt; should
match &lt;code&gt;Check core temperature?&lt;/code&gt; as a question, and return both options. The
code back in &lt;code&gt;wait_for_command/0&lt;/code&gt; will only execute the &lt;code&gt;core_temperature/0&lt;/code&gt;
function.&lt;/p&gt;
&lt;p&gt;Finally, all actions and consequences can be implemented:&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;code data-lang="erlang"&gt;&lt;span&gt;noop&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;ok&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;

&lt;span&gt;venting_prevents_explosions&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;case&lt;/span&gt; &lt;span&gt;option&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"Venting prevents explosion."&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;of&lt;/span&gt;
        &lt;span&gt;yes&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;blow_crops_away&lt;/span&gt;&lt;span&gt;();&lt;/span&gt;
        &lt;span&gt;no&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;noop&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;
    &lt;span&gt;end&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;

&lt;span&gt;core_temperature&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;io&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;format&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"Core temperature normal.&lt;/span&gt;&lt;span&gt;~n&lt;/span&gt;&lt;span&gt;"&lt;/span&gt;&lt;span&gt;).&lt;/span&gt;

&lt;span&gt;blow_crops_away&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;io&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;format&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"*Gas blows away corn crop*&lt;/span&gt;&lt;span&gt;~n&lt;/span&gt;&lt;span&gt;"&lt;/span&gt;&lt;span&gt;).&lt;/span&gt;

&lt;span&gt;sound_horn&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;io&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;format&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"*horn sounds in the distance*&lt;/span&gt;&lt;span&gt;~n&lt;/span&gt;&lt;span&gt;"&lt;/span&gt;&lt;span&gt;).&lt;/span&gt;

&lt;span&gt;pressure_too_high&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;io&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;format&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"Pressure too high. Tank must be shut down manually.&lt;/span&gt;&lt;span&gt;~n&lt;/span&gt;&lt;span&gt;"&lt;/span&gt;&lt;span&gt;).&lt;/span&gt;

&lt;span&gt;vent_gas&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;    %% A&lt;/span&gt;&lt;span&gt;fter&lt;/span&gt; &lt;span&gt;?&lt;/span&gt;&lt;span&gt;MAX_NO_VENT&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;pressure&lt;/span&gt; &lt;span&gt;has&lt;/span&gt; &lt;span&gt;to&lt;/span&gt; &lt;span&gt;be&lt;/span&gt; &lt;span&gt;shut&lt;/span&gt; &lt;span&gt;down&lt;/span&gt;
    &lt;span&gt;%% manually -- unsupported in this here program!
&lt;/span&gt;&lt;span&gt;&lt;/span&gt;    &lt;span&gt;case&lt;/span&gt; &lt;span&gt;get&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;missed&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;of&lt;/span&gt;
        &lt;span&gt;?&lt;/span&gt;&lt;span&gt;MAX_NO_VENT&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;            &lt;/span&gt;&lt;span&gt;pressure_too_high&lt;/span&gt;&lt;span&gt;();&lt;/span&gt;
        &lt;span&gt;_&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;            &lt;/span&gt;&lt;span&gt;put&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;missed&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;),&lt;/span&gt;
            &lt;span&gt;blow_crops_away&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;
    &lt;span&gt;end&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;

&lt;span&gt;no_venting&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;case&lt;/span&gt; &lt;span&gt;get&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;missed&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;of&lt;/span&gt;
        &lt;span&gt;undefined&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;put&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;missed&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
        &lt;span&gt;N&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;put&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;missed&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;N&lt;/span&gt;&lt;span&gt;+&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
    &lt;span&gt;end&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Here the two last functions implement the special last requirement: after
denying venting too many times, the valve must be disabled manually.&lt;/p&gt;
&lt;p&gt;Here we use a dirty ugly counter for prototyping’s sake. In fact I had
forgotten about that requirement at the time and just bolted it on that way.
The prototype helped figure that requirement out, and the final version can now
be designed with this in mind.&lt;/p&gt;
&lt;p&gt;You can run the code and try it from a shell:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;λ → erlc src/muumuu_fsm.erl &amp;amp;&amp;amp; erl -s muumuu_fsm -noshell
To Start, Press Any Key.
&amp;gt; .
Check core temperature? (Y/N)
&amp;gt; N
Vent radioactive gas? (Y/N)
&amp;gt; No
Venting prevents explosion. (Y/N)
&amp;gt; yes
*Gas blows away corn crop*
Sound alertness horn? (Y/N)
&amp;gt; Y
*horn sounds in the distance*
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That works. Using &lt;code&gt;-s &amp;lt;module&amp;gt;&lt;/code&gt; runs the &lt;code&gt;start/0&lt;/code&gt; function from that module,
and using &lt;code&gt;-noshell&lt;/code&gt; makes it so that the Erlang VM won’t fight with all the
&lt;code&gt;io&lt;/code&gt; calls I’m doing for user input ownership.&lt;/p&gt;
&lt;p&gt;Sadly, the implementation is kind of ugly and shouldn’t go in production.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://howistart.org/posts/erlang/1/images/muumuu.gif"&gt;&lt;/p&gt;
&lt;h2 id="making-it-a-library"&gt;Making it a library&lt;/h2&gt;
&lt;p&gt;There are two ways to make something reach production: distributing yourself, or
distributing it as a library other Erlang developers can use.&lt;/p&gt;
&lt;p&gt;The latter can be a prerequisite for the former, so we’re going to start there.
By default, everyone using Erlang in the open source community uses &lt;a href="http://learnyousomeerlang.com/building-otp-applications"&gt;OTP
applications&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;OTP is kind of often treated as a super advanced topic, so what I’m gonna show
here is how to take any non-OTP compliant code and turn it into an OTP
application. Fun fun.&lt;/p&gt;
&lt;p&gt;First, the directory structure:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;src/
  - muumuu_fsm.erl
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That’s all you need in terms of structure if you have rebar3 installed in your
system.&lt;/p&gt;
&lt;p&gt;Add a file in &lt;code&gt;src/&lt;/code&gt; called &lt;code&gt;muumuu.app.src&lt;/code&gt;. This file is basically
telling Erlang (and rebar3) what the library is:&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;code data-lang="erlang"&gt;&lt;span&gt;{&lt;/span&gt;&lt;span&gt;application&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;muumuu&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;
  &lt;span&gt;{&lt;/span&gt;&lt;span&gt;description&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;"Too fat to go to the power plant app"&lt;/span&gt;&lt;span&gt;},&lt;/span&gt;
  &lt;span&gt;{&lt;/span&gt;&lt;span&gt;vsn&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;"0.1.0"&lt;/span&gt;&lt;span&gt;},&lt;/span&gt;
  &lt;span&gt;{&lt;/span&gt;&lt;span&gt;registered&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[]},&lt;/span&gt;
  &lt;span&gt;{&lt;/span&gt;&lt;span&gt;applications&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;kernel&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;stdlib&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;crypto&lt;/span&gt;&lt;span&gt;]},&lt;/span&gt;
  &lt;span&gt;{&lt;/span&gt;&lt;span&gt;mod&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;muumuu_app&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[]}},&lt;/span&gt;
  &lt;span&gt;{&lt;/span&gt;&lt;span&gt;env&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[]}&lt;/span&gt;
&lt;span&gt;]}.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The &lt;code&gt;registered&lt;/code&gt; entry specifies what processes are going to be globally
registered on the node. In this case, none. The &lt;code&gt;applications&lt;/code&gt; tuple is a list
of all applications we depend on. All applications depend on both &lt;code&gt;kernel&lt;/code&gt; and
&lt;code&gt;stdlib&lt;/code&gt;. These entries have to always be in there. On the other hand, &lt;code&gt;crypto&lt;/code&gt;
is optional to most apps, but we need it because we use it to seed our
pseudo-random number generator in &lt;code&gt;start/0&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;env&lt;/code&gt; tuple can contain &lt;a href="http://erlang.org/doc/man/app.html"&gt;configuration
values&lt;/a&gt;, but we need none right now.&lt;/p&gt;
&lt;p&gt;The other option considered here is &lt;code&gt;mod&lt;/code&gt;. If your library requires no process
to be started and you’re just shipping code around, you’re done. In our case
however, we’re starting a process (or we want to), and therefore we specify an
application module named &lt;code&gt;muumuu_app&lt;/code&gt;. This module is also in &lt;code&gt;src/&lt;/code&gt;:&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;code data-lang="erlang"&gt;&lt;span&gt;-&lt;/span&gt;&lt;span&gt;module&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;muumuu_app&lt;/span&gt;&lt;span&gt;).&lt;/span&gt;
&lt;span&gt;-&lt;/span&gt;&lt;span&gt;behaviour&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;application&lt;/span&gt;&lt;span&gt;).&lt;/span&gt;
&lt;span&gt;-&lt;/span&gt;&lt;span&gt;export&lt;/span&gt;&lt;span&gt;([&lt;/span&gt;&lt;span&gt;start&lt;/span&gt;&lt;span&gt;/&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;stop&lt;/span&gt;&lt;span&gt;/&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;]).&lt;/span&gt;

&lt;span&gt;start&lt;/span&gt;&lt;span&gt;(_&lt;/span&gt;&lt;span&gt;Type&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;_&lt;/span&gt;&lt;span&gt;Args&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;muumuu_sup&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;start_link&lt;/span&gt;&lt;span&gt;().&lt;/span&gt;

&lt;span&gt;stop&lt;/span&gt;&lt;span&gt;(_)&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;ok&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;That module is basically giving callbacks to the Erlang VM. See it a bit as the
&lt;code&gt;main&lt;/code&gt; function in C, except you also have to provide a &lt;code&gt;stop&lt;/code&gt; function that
will clean up once the process exits. In this case we need nothing.&lt;/p&gt;
&lt;p&gt;What’s the &lt;code&gt;muumuu_sup&lt;/code&gt; module? That’s the final step to be glued in OTP. OTP
has a concept called
&lt;a href="http://learnyousomeerlang.com/supervisors"&gt;&lt;code&gt;supervisors&lt;/code&gt;&lt;/a&gt;. Supervisors are in
charge of checking OTP-compliant processes, to start them, stop them, and
&lt;a href="http://ferd.ca/it-s-about-the-guarantees.html"&gt;provide guarantees regarding their
state&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Unfortunately, our process isn’t OTP-compliant. The guys at Ericsson have long
ago hit that problem and developed a &lt;a href="http://www.erlang.org/doc/man/supervisor_bridge.html"&gt;supervisor
bridge&lt;/a&gt;, which basically
acts as a wrapper. This is what we could use if I were not the kind of person
to want my OTP processes done correctly everywhere.&lt;/p&gt;
&lt;p&gt;For the time being, I’ll stick with a regular supervisor and will rewrite the
FSM right after:&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;code data-lang="erlang"&gt;&lt;span&gt;-&lt;/span&gt;&lt;span&gt;module&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;muumuu_sup&lt;/span&gt;&lt;span&gt;).&lt;/span&gt;
&lt;span&gt;-&lt;/span&gt;&lt;span&gt;behaviour&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;supervisor&lt;/span&gt;&lt;span&gt;).&lt;/span&gt;

&lt;span&gt;-&lt;/span&gt;&lt;span&gt;export&lt;/span&gt;&lt;span&gt;([&lt;/span&gt;&lt;span&gt;start_link&lt;/span&gt;&lt;span&gt;/&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;]).&lt;/span&gt;
&lt;span&gt;-&lt;/span&gt;&lt;span&gt;export&lt;/span&gt;&lt;span&gt;([&lt;/span&gt;&lt;span&gt;init&lt;/span&gt;&lt;span&gt;/&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;]).&lt;/span&gt;

&lt;span&gt;start_link&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;supervisor&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;start_link&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;?&lt;/span&gt;&lt;span&gt;MODULE&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[]).&lt;/span&gt;

&lt;span&gt;init&lt;/span&gt;&lt;span&gt;([])&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;    {&lt;/span&gt;&lt;span&gt;ok&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;{{&lt;/span&gt;&lt;span&gt;one_for_one&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;5&lt;/span&gt;&lt;span&gt;},&lt;/span&gt;
          &lt;span&gt;[{&lt;/span&gt;&lt;span&gt;console&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
            &lt;span&gt;{&lt;/span&gt;&lt;span&gt;muumuu_fsm&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;start_link&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[]},&lt;/span&gt;
            &lt;span&gt;permanent&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;5000&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;worker&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;muumuu_fsm&lt;/span&gt;&lt;span&gt;]}]}}.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will start &lt;code&gt;muumuu_fsm&lt;/code&gt; as a permanent worker that can die once every 5
seconds before the entire system crashes. I don’t have a good way to pick
frequencies, but 1 in 5 seconds sounds like something reasonable for someone to
mash keys in ways bad enough it causes errors.&lt;/p&gt;
&lt;p&gt;So then comes the rewrite from prototype to
&lt;a href="http://learnyousomeerlang.com/finite-state-machines"&gt;&lt;code&gt;gen_fsm&lt;/code&gt;&lt;/a&gt;. This is stuff
that has been covered in multiple tutorials before, so I’m going to skip most
of it. You can instead look at books and docs for &lt;code&gt;gen_fsm&lt;/code&gt;, follow along the
final module,
&lt;a href="https://github.com/ferd/howistart-erlang1-code/blob/master/library/src/muumuu_fsm.erl"&gt;muumuu_fsm.erl&lt;/a&gt;,
and see for yourself.&lt;/p&gt;
&lt;p&gt;The biggest changes there, outside of providing the &lt;code&gt;gen_fsm&lt;/code&gt; callbacks
required by the OTP behavior, are related to the general information flow.
Rather than being really direct sequences of functions doing whatever they
want, the OTP version of the module becomes a lot more declarative.&lt;/p&gt;
&lt;p&gt;We no longer enter a state function, ask a question, and wait for the response
within the same context. The logic has moved so that an event in a state (say
&lt;code&gt;first_gas_vent&lt;/code&gt;) causes a question to be asked before transitioning to the
state that will handle that response.&lt;/p&gt;
&lt;p&gt;This doesn’t make the code particulalry harder to read, just different:&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;code data-lang="erlang"&gt;&lt;span&gt;init&lt;/span&gt;&lt;span&gt;([])&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;    &amp;lt;&amp;lt;A:32, B:32, C:32&amp;gt;&amp;gt; = &lt;/span&gt;&lt;span&gt;crypto&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;rand_bytes&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;&lt;span&gt;),&lt;/span&gt;
    &lt;span&gt;random&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;seed&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;A&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;B&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;C&lt;/span&gt;&lt;span&gt;),&lt;/span&gt;
    &lt;span&gt;{&lt;/span&gt;&lt;span&gt;ok&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;wait_any_key&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;prompt&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;wait_any_key&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;#state&lt;/span&gt;&lt;span&gt;{})}.&lt;/span&gt;

&lt;span&gt;%% [...]
&lt;/span&gt;&lt;span&gt;&lt;/span&gt;
&lt;span&gt;wait_any_key&lt;/span&gt;&lt;span&gt;(_,&lt;/span&gt; &lt;span&gt;State&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;    {&lt;/span&gt;&lt;span&gt;next_state&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;first_core_check&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;prompt&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;first_core_check&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;State&lt;/span&gt;&lt;span&gt;)}.&lt;/span&gt;

&lt;span&gt;first_core_check&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;no&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;State&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;    {&lt;/span&gt;&lt;span&gt;next_state&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;first_gas_vent&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;prompt&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;first_gas_vent&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;State&lt;/span&gt;&lt;span&gt;)};&lt;/span&gt;
&lt;span&gt;first_core_check&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;yes&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;State&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;show_core_temperature&lt;/span&gt;&lt;span&gt;(),&lt;/span&gt;
    &lt;span&gt;{&lt;/span&gt;&lt;span&gt;next_state&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;first_gas_vent&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;prompt&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;first_gas_vent&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;State&lt;/span&gt;&lt;span&gt;)}.&lt;/span&gt;

&lt;span&gt;first_gas_vent&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;no&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;State&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;    S&lt;/span&gt;&lt;span&gt;tateName&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;venting_prevents_explosions&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
    &lt;span&gt;{&lt;/span&gt;&lt;span&gt;next_state&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;StateName&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;prompt&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;StateName&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;State&lt;/span&gt;&lt;span&gt;)};&lt;/span&gt;
&lt;span&gt;first_gas_vent&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;yes&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;State&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;show_blow_crops_away&lt;/span&gt;&lt;span&gt;(),&lt;/span&gt;
    &lt;span&gt;{&lt;/span&gt;&lt;span&gt;next_state&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;wait_for_command&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;prompt&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;wait_for_command&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;State&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;10000&lt;/span&gt;&lt;span&gt;}.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This form, along with the experience gained in the prototype, allows for
simpler state management via the &lt;code&gt;State&lt;/code&gt; variable, which allows us to be more
transparent about our usage of venting limits, for example. We also instantly
benefit from everything OTP gives us in terms of transparency: tracing,
logging, statistics, and so on (see &lt;a href="http://www.erlang.org/doc/man/sys.html"&gt;the &lt;code&gt;sys&lt;/code&gt;
module&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;With that code in place, we can compile and run the entire application:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;λ → rebar3 compile
===&amp;gt; Verifying dependencies...
===&amp;gt; Compiling muumuu
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With this compiled we can run it, with a funky command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;λ →  erl -env ERL_LIBS _build/default/lib -eval 'application:ensure_all_started(muumuu).' -noshell
To Start, Press Any Key.
&amp;gt; any
Check core temperature? (Y/N)
&amp;gt; y
Core temperature normal.
Vent radioactive gas? (Y/N)
&amp;gt; y
*Gas blows away corn crop*
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That’s kind of an ugly command to run the app, but the app is now something
other people can use to pull it within their own systems.&lt;/p&gt;
&lt;p&gt;In order to run it ourselves and actually ship it to customers, we will need to
build a release. In any other case, though, you may want to &lt;a href="http://www.rebar3.org/v3.0/docs/publishing-packages"&gt;publish your
library as a Hex package&lt;/a&gt;
with the help of the &lt;a href="http://www.rebar3.org/v3.0/docs/using-available-plugins#hex-package-management"&gt;proper rebar3 plugin&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://howistart.org/posts/erlang/1/images/y-y-y.gif"&gt;&lt;/p&gt;
&lt;h2 id="releases"&gt;Releases&lt;/h2&gt;
&lt;p&gt;The directory structure we’ve been using was for an application and turns out
looking like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;src/
ebin/
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;At the simplest level. A release is basically a group of applications put
together. For this reason, we’ll change the directory structure a bit:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;apps/
    - muumuu/
        - src/
        - ebin/
rebar.config
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;All applications you need will go into &lt;code&gt;apps/&lt;/code&gt;. Here I just moved &lt;code&gt;src/&lt;/code&gt; to
&lt;code&gt;apps/muumuu/&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The rebar.config file looks like this:&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;code data-lang="erlang"&gt;&lt;span&gt;{&lt;/span&gt;&lt;span&gt;relx&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;
    &lt;span&gt;{&lt;/span&gt;&lt;span&gt;release&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;muumuu&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;"1.0.0"&lt;/span&gt;&lt;span&gt;},&lt;/span&gt;
     &lt;span&gt;%% list of apps to include
&lt;/span&gt;&lt;span&gt;&lt;/span&gt;     &lt;span&gt;[&lt;/span&gt;&lt;span&gt;muumuu&lt;/span&gt;&lt;span&gt;]},&lt;/span&gt;

    &lt;span&gt;%% Don't ship an Erlang VM by default
&lt;/span&gt;&lt;span&gt;&lt;/span&gt;    &lt;span&gt;{&lt;/span&gt;&lt;span&gt;include_erts&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;false&lt;/span&gt;&lt;span&gt;}&lt;/span&gt;
&lt;span&gt;]}.&lt;/span&gt;

&lt;span&gt;{&lt;/span&gt;&lt;span&gt;profiles&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;
    &lt;span&gt;%% called as `rebar3 as prod &amp;lt;command&amp;gt;`
&lt;/span&gt;&lt;span&gt;&lt;/span&gt;    &lt;span&gt;{&lt;/span&gt;&lt;span&gt;prod&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;
        &lt;span&gt;{&lt;/span&gt;&lt;span&gt;relx&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt; &lt;span&gt;% override relx specifically
&lt;/span&gt;&lt;span&gt;&lt;/span&gt;          &lt;span&gt;{&lt;/span&gt;&lt;span&gt;include_src&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;false&lt;/span&gt;&lt;span&gt;},&lt;/span&gt; &lt;span&gt;% don't include source code
&lt;/span&gt;&lt;span&gt;&lt;/span&gt;          &lt;span&gt;{&lt;/span&gt;&lt;span&gt;include_erts&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;true&lt;/span&gt;&lt;span&gt;}&lt;/span&gt;  &lt;span&gt;% include the VM in the release
&lt;/span&gt;&lt;span&gt;&lt;/span&gt;        &lt;span&gt;]}&lt;/span&gt;
    &lt;span&gt;]}&lt;/span&gt;
&lt;span&gt;]}.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This basically just tells rebar3 what the release-building tool it includes
(relx) should do to give us our release. The release will only include our
custom Erlang code, and use the currently installed Erlang VM to run things
rather than installing a fully self-contianed program. Then the magic happens:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;λ → rebar3 release
===&amp;gt; Verifying dependencies...
===&amp;gt; Compiling muumuu
===&amp;gt; Starting relx build process ...
===&amp;gt; Resolving OTP Applications from directories:
          /Users/ferd/code/self/howistart-erlang1-code/release/_build/default/lib
          /Users/ferd/code/self/howistart-erlang1-code/release/apps
          /Users/ferd/.kerl/builds/17.4/release_17.4/lib
===&amp;gt; Resolved muumuu-1.0.0
===&amp;gt; release successfully created!
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And a release is born! To run it:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;λ → ./_build/default/rel/muumuu/bin/muumuu -noshell
To Start, Press Any Key.
&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Pretty cool. This can now be shipped and distributed to people.&lt;/p&gt;
&lt;p&gt;I want to make the release a bit fancier though. As you’ve just seen, we still
need to put the &lt;code&gt;-noshell&lt;/code&gt; by hand, which is totally unacceptable.&lt;/p&gt;
&lt;p&gt;To fix this, add a &lt;code&gt;config/&lt;/code&gt; repository, and I open the &lt;code&gt;vm.args&lt;/code&gt; file in vim in
there:&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;code data-lang="bash"&gt;&lt;span&gt;# only show the programmed prompt&lt;/span&gt;
-noshell

&lt;span&gt;# for remote access &amp;amp; debugging&lt;/span&gt;
-name &lt;a data-cfemail="abc5dec8dec7cad9f4dbc7cac5dfeb9a999c859b859b859a" href="https://howistart.org/cdn-cgi/l/email-protection"&gt;[email&amp;nbsp;protected]&lt;/a&gt;

&lt;span&gt;# not needed&lt;/span&gt;
-smp disable
+A &lt;span&gt;1&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Arguments in there I merged into one. A good practice for any Erlang system is
to give it a name, which will let you connect to it while it’s running. In this
case I could go in and debug the console as the user is maintaining the
powerplant.&lt;/p&gt;
&lt;p&gt;The last arguments (&lt;code&gt;-smp disable +A 1&lt;/code&gt;) are basically optimizations for this
very app: they remove Erlang parallelism (I’m running a single active process
for the thing, so why bother?) and removes the number of asynchronous threads
for IO to a single one (for the same reason – one active process, why
bother?).&lt;/p&gt;
&lt;p&gt;In more serious apps, tweaking your VM options can be worthwhile, but outside of
this text’s scope.&lt;/p&gt;
&lt;p&gt;The rebar3 config file needs an update too:&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;code data-lang="erlang"&gt;&lt;span&gt;{&lt;/span&gt;&lt;span&gt;relx&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;
    &lt;span&gt;{&lt;/span&gt;&lt;span&gt;release&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;muumuu&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;"1.0.0"&lt;/span&gt;&lt;span&gt;},&lt;/span&gt;
     &lt;span&gt;%% list of apps to include
&lt;/span&gt;&lt;span&gt;&lt;/span&gt;     &lt;span&gt;[&lt;/span&gt;&lt;span&gt;muumuu&lt;/span&gt;&lt;span&gt;]},&lt;/span&gt;

    &lt;span&gt;%% Don't ship an Erlang VM by default
&lt;/span&gt;&lt;span&gt;&lt;/span&gt;    &lt;span&gt;{&lt;/span&gt;&lt;span&gt;include_erts&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;false&lt;/span&gt;&lt;span&gt;},&lt;/span&gt;

    &lt;span&gt;{&lt;/span&gt;&lt;span&gt;vm_args&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;"./config/vm.args"&lt;/span&gt;&lt;span&gt;}&lt;/span&gt;
&lt;span&gt;]}.&lt;/span&gt;

&lt;span&gt;{&lt;/span&gt;&lt;span&gt;profiles&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;
    &lt;span&gt;%% called as `rebar3 as prod &amp;lt;command&amp;gt;`
&lt;/span&gt;&lt;span&gt;&lt;/span&gt;    &lt;span&gt;{&lt;/span&gt;&lt;span&gt;prod&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;
        &lt;span&gt;{&lt;/span&gt;&lt;span&gt;relx&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt; &lt;span&gt;% override relx specifically
&lt;/span&gt;&lt;span&gt;&lt;/span&gt;          &lt;span&gt;{&lt;/span&gt;&lt;span&gt;include_src&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;false&lt;/span&gt;&lt;span&gt;},&lt;/span&gt; &lt;span&gt;% don't include source code
&lt;/span&gt;&lt;span&gt;&lt;/span&gt;          &lt;span&gt;{&lt;/span&gt;&lt;span&gt;include_erts&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;true&lt;/span&gt;&lt;span&gt;}&lt;/span&gt;  &lt;span&gt;% include the VM in the release
&lt;/span&gt;&lt;span&gt;&lt;/span&gt;        &lt;span&gt;]}&lt;/span&gt;
    &lt;span&gt;]}&lt;/span&gt;
&lt;span&gt;]}.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The last line above the profiles is the new one. Compile again and the
arguments should implicitly be passed to the node:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;λ → rebar3 release
===&amp;gt; Verifying dependencies...
===&amp;gt; Compiling muumuu
===&amp;gt; Starting relx build process ...
===&amp;gt; Resolving OTP Applications from directories:
          /Users/ferd/code/self/howistart-erlang1-code/release/_build/default/lib
          /Users/ferd/code/self/howistart-erlang1-code/release/apps
          /Users/ferd/.kerl/builds/17.4/release_17.4/lib
          /Users/ferd/code/self/howistart-erlang1-code/release/_build/default/rel
===&amp;gt; Resolved muumuu-1.0.0
===&amp;gt; release successfully created!
λ → ./_build/default/rel/muumuu/bin/muumuu
To Start, Press Any Key.
&amp;gt; &amp;lt;Tab&amp;gt;
Check core temperature? (Y/N)
&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Cool, everything works. I now have a binary executable I can link to from
anywhere in the system and will require no magical arguments to work!&lt;/p&gt;
&lt;h2 id="tests"&gt;Tests&lt;/h2&gt;
&lt;p&gt;As much as I like to try and get testing done ahead of time – it’s the only
time it’s not super terrible and crappy – I often end up adding it after the
fact when I know I’ll have to maintain it.&lt;/p&gt;
&lt;p&gt;For this, each app should have its tests, so I’ll have to add a &lt;code&gt;test/&lt;/code&gt;
directory in &lt;code&gt;apps/muumuu/&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;My tool of choice is &lt;a href="http://learnyousomeerlang.com/common-test-for-uncommon-tests"&gt;Common
Test&lt;/a&gt;, which
while it is kind of full of annoying overheads for unit testing and is mostly
useless for shell output (you gotta deal with HTML files), it scales fairly
well for integration and system tests.&lt;/p&gt;
&lt;p&gt;The test suite in there is going to be &lt;code&gt;muumuu_SUITE.erl&lt;/code&gt;:&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;code data-lang="erlang"&gt;&lt;span&gt;-&lt;/span&gt;&lt;span&gt;module&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;muumuu_SUITE&lt;/span&gt;&lt;span&gt;).&lt;/span&gt;
&lt;span&gt;-&lt;/span&gt;&lt;span&gt;include_lib&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"common_test/include/ct.hrl"&lt;/span&gt;&lt;span&gt;).&lt;/span&gt;
&lt;span&gt;-&lt;/span&gt;&lt;span&gt;compile&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;export_all&lt;/span&gt;&lt;span&gt;).&lt;/span&gt;

&lt;span&gt;%% Copy/pasting from the suite
&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;-&lt;/span&gt;&lt;span&gt;record&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;state&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;no_vent_count&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
                &lt;span&gt;pid&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
                &lt;span&gt;yes&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
                &lt;span&gt;no&lt;/span&gt;&lt;span&gt;}).&lt;/span&gt;

&lt;span&gt;all&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;    [&lt;/span&gt;&lt;span&gt;demo_session&lt;/span&gt;&lt;span&gt;].&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;So at first I’m just gonna make one run-through test. Testing &lt;code&gt;muumuu&lt;/code&gt; is going
to be hard because it’s purely a side-effectful application.&lt;/p&gt;
&lt;p&gt;Before going further, I’ll say that the trick to getting this working is to use
&lt;code&gt;meck&lt;/code&gt;, which is pretty much the best code-mocking application around.&lt;/p&gt;
&lt;p&gt;Adding &lt;code&gt;meck&lt;/code&gt; can be done by declaring &lt;code&gt;rebar.config&lt;/code&gt; dependencies:&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;code data-lang="erlang"&gt;&lt;span&gt;{&lt;/span&gt;&lt;span&gt;profiles&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;
    &lt;span&gt;{&lt;/span&gt;&lt;span&gt;test&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;
        &lt;span&gt;{&lt;/span&gt;&lt;span&gt;deps&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;
          &lt;span&gt;{&lt;/span&gt;&lt;span&gt;meck&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;"0.8.2"&lt;/span&gt;&lt;span&gt;}&lt;/span&gt;
        &lt;span&gt;]}&lt;/span&gt;
    &lt;span&gt;]},&lt;/span&gt;
    &lt;span&gt;%% called as `rebar3 as prod &amp;lt;command&amp;gt;`
&lt;/span&gt;&lt;span&gt;&lt;/span&gt;    &lt;span&gt;{&lt;/span&gt;&lt;span&gt;prod&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;
        &lt;span&gt;...&lt;/span&gt;
    &lt;span&gt;]}&lt;/span&gt;
  &lt;span&gt;]}&lt;/span&gt;
&lt;span&gt;]}.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note that rather than having a top-level &lt;code&gt;deps&lt;/code&gt; entry as we usually would, we
define this one to be into the &lt;code&gt;test&lt;/code&gt; profile. This will allow the dependency
to only be fetched and used when running tests, and to avoid bundling it when
shipping the application.&lt;/p&gt;
&lt;p&gt;Rebar3 pulls stuff from a package repository for this one (&lt;a href="http://www.rebar3.org/v3.0/docs/dependencies"&gt;github
dependencies&lt;/a&gt; are also an
option). Rebar3 will add it to a lock file when it fetches and compiles it
later.&lt;/p&gt;
&lt;p&gt;Now back to &lt;code&gt;muumuu_SUITE&lt;/code&gt;. Time to set up the state:&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;code data-lang="erlang"&gt;&lt;span&gt;init_per_testcase&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;demo_session&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Config&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;mock_io&lt;/span&gt;&lt;span&gt;(),&lt;/span&gt;
    &lt;span&gt;{&lt;/span&gt;&lt;span&gt;ok&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Pid&lt;/span&gt;&lt;span&gt;}&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;muumuu_fsm&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;start_link&lt;/span&gt;&lt;span&gt;(),&lt;/span&gt;
    &lt;span&gt;[{&lt;/span&gt;&lt;span&gt;pid&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Pid&lt;/span&gt;&lt;span&gt;}&lt;/span&gt; &lt;span&gt;|&lt;/span&gt; &lt;span&gt;Config&lt;/span&gt;&lt;span&gt;].&lt;/span&gt;

&lt;span&gt;end_per_testcase&lt;/span&gt;&lt;span&gt;(_,&lt;/span&gt; &lt;span&gt;Config&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;meck&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;unload&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;io&lt;/span&gt;&lt;span&gt;),&lt;/span&gt;
    &lt;span&gt;Pid&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;?&lt;/span&gt;&lt;span&gt;config&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;pid&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Config&lt;/span&gt;&lt;span&gt;),&lt;/span&gt;
    &lt;span&gt;unlink&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Pid&lt;/span&gt;&lt;span&gt;),&lt;/span&gt;
    &lt;span&gt;exit&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Pid&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;shutdown&lt;/span&gt;&lt;span&gt;),&lt;/span&gt;
    &lt;span&gt;wait_for_death&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Pid&lt;/span&gt;&lt;span&gt;).&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Mocking the &lt;code&gt;io&lt;/code&gt; system is a fun way to basically take it and make it return
messages we can look at. That all takes place in &lt;code&gt;mock_io()&lt;/code&gt;, and after that’s
in place, we start a &lt;code&gt;muumuu&lt;/code&gt; instance directly (no application needed):&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;code data-lang="erlang"&gt;&lt;span&gt;mock_io&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;    %% F&lt;/span&gt;&lt;span&gt;or&lt;/span&gt; &lt;span&gt;this&lt;/span&gt; &lt;span&gt;one&lt;/span&gt; &lt;span&gt;we&lt;/span&gt; &lt;span&gt;mock&lt;/span&gt; &lt;span&gt;the&lt;/span&gt; &lt;span&gt;IO&lt;/span&gt; &lt;span&gt;system&lt;/span&gt; &lt;span&gt;so&lt;/span&gt; &lt;span&gt;that&lt;/span&gt; &lt;span&gt;instead&lt;/span&gt; &lt;span&gt;of&lt;/span&gt;
    &lt;span&gt;%% printing messages and getting input to and from the user,
&lt;/span&gt;&lt;span&gt;&lt;/span&gt;    &lt;span&gt;%% we instead have a message-passing interface that will
&lt;/span&gt;&lt;span&gt;&lt;/span&gt;    &lt;span&gt;%% be inspectable.
&lt;/span&gt;&lt;span&gt;&lt;/span&gt;    &lt;span&gt;%%
&lt;/span&gt;&lt;span&gt;&lt;/span&gt;    &lt;span&gt;%% Note that because the `io` module is pre-compiled by the
&lt;/span&gt;&lt;span&gt;&lt;/span&gt;    &lt;span&gt;%% VM, we have to 'unstick' it first, and be careful to keep
&lt;/span&gt;&lt;span&gt;&lt;/span&gt;    &lt;span&gt;%% it mocked as little as possible.
&lt;/span&gt;&lt;span&gt;&lt;/span&gt;    &lt;span&gt;Parent&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;self&lt;/span&gt;&lt;span&gt;(),&lt;/span&gt;
    &lt;span&gt;code&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;unstick_dir&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;filename&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;dirname&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;code&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;where_is_file&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"io.beam"&lt;/span&gt;&lt;span&gt;))),&lt;/span&gt;
    &lt;span&gt;meck&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;io&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;passthrough&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;no_link&lt;/span&gt;&lt;span&gt;]),&lt;/span&gt;
    &lt;span&gt;meck&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;expect&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;io&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;format&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;fun&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Str&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;        P&lt;/span&gt;&lt;span&gt;arent&lt;/span&gt; &lt;span&gt;!&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;out&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Str&lt;/span&gt;&lt;span&gt;},&lt;/span&gt;
        &lt;span&gt;ok&lt;/span&gt;
    &lt;span&gt;end&lt;/span&gt;&lt;span&gt;),&lt;/span&gt;
    &lt;span&gt;meck&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;expect&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;io&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;format&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;fun&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Str&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Args&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;        P&lt;/span&gt;&lt;span&gt;arent&lt;/span&gt; &lt;span&gt;!&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;out&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;io_lib&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;format&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Str&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;Args&lt;/span&gt;&lt;span&gt;)},&lt;/span&gt;
        &lt;span&gt;ok&lt;/span&gt;
    &lt;span&gt;end&lt;/span&gt;&lt;span&gt;),&lt;/span&gt;
    &lt;span&gt;meck&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;expect&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;io&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;get_line&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;fun&lt;/span&gt;&lt;span&gt;(_&lt;/span&gt;&lt;span&gt;Prompt&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;        P&lt;/span&gt;&lt;span&gt;arent&lt;/span&gt; &lt;span&gt;!&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;in&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;self&lt;/span&gt;&lt;span&gt;()},&lt;/span&gt;
        &lt;span&gt;receive&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;Parent&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;In&lt;/span&gt;&lt;span&gt;}&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; I&lt;/span&gt;&lt;span&gt;n&lt;/span&gt; &lt;span&gt;end&lt;/span&gt;
    &lt;span&gt;end&lt;/span&gt;&lt;span&gt;).&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Ugly. The first step is unstickying the directory for Erlang code. Most modules
don’t require that, only those in Erlang’s standard library. Unstickying allows
to load new versions of code at run time, which &lt;code&gt;meck&lt;/code&gt; dynamically does.&lt;/p&gt;
&lt;p&gt;Here what I’m doing is mocking the functions &lt;code&gt;io:format/1&lt;/code&gt;, &lt;code&gt;io:format/2&lt;/code&gt; and
&lt;code&gt;io:get_line/1&lt;/code&gt; to send messages of the form &lt;code&gt;{in, Msg}&lt;/code&gt; and &lt;code&gt;{out, Msg}&lt;/code&gt; from
input and output, respectively. &lt;code&gt;meck:unload(io)&lt;/code&gt; will undo that.&lt;/p&gt;
&lt;p&gt;We also had the &lt;code&gt;wait_for_death/1&lt;/code&gt; call. I’m using these &lt;em&gt;everywhere&lt;/em&gt; in tests.
Timers are the enemy of good concurrent testing, and if you rely on a
&lt;code&gt;timer:sleep(1000)&lt;/code&gt; of some sort to make sure everything is clean, you’re doing
it wrong.&lt;/p&gt;
&lt;p&gt;Here the function polls to return ASAP, with a tiny sleep to not heat up your
room too much via the CPU:&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;code data-lang="erlang"&gt;&lt;span&gt;wait_for_death&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Pid&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;case&lt;/span&gt; &lt;span&gt;is_process_alive&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Pid&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;of&lt;/span&gt;
        &lt;span&gt;true&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;            &lt;/span&gt;&lt;span&gt;timer&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;sleep&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;&lt;span&gt;),&lt;/span&gt;
            &lt;span&gt;wait_for_death&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Pid&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
        &lt;span&gt;false&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;            &lt;/span&gt;&lt;span&gt;ok&lt;/span&gt;
    &lt;span&gt;end&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;With this done, I can start planning more for the test. This here is something I
always want to write a library for, and maybe some day I will, but right now I
re-do that crap by hand every time:&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;code data-lang="erlang"&gt;&lt;span&gt;%%%%%%%%%%%%%%%%%%
&lt;/span&gt;&lt;span&gt;%%% TEST CASES %%%
&lt;/span&gt;&lt;span&gt;%%%%%%%%%%%%%%%%%%
&lt;/span&gt;&lt;span&gt;&lt;/span&gt;
&lt;span&gt;%% Pressing a given key through the message-passing interface
&lt;/span&gt;&lt;span&gt;%% will yield expected output. There should be a prompt waiting
&lt;/span&gt;&lt;span&gt;%% for a key.
&lt;/span&gt;&lt;span&gt;%% All states can be cycled through using only Y/N answers.
&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;demo_session&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Config&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;    P&lt;/span&gt;&lt;span&gt;id&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;?&lt;/span&gt;&lt;span&gt;config&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;pid&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Config&lt;/span&gt;&lt;span&gt;),&lt;/span&gt;
    &lt;span&gt;out&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"press.*any.*key.*&amp;gt;"&lt;/span&gt;&lt;span&gt;),&lt;/span&gt;
    &lt;span&gt;in&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"&amp;lt;tab&amp;gt;"&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;% the characters shouldn't matter
&lt;/span&gt;&lt;span&gt;&lt;/span&gt;    &lt;span&gt;out&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"check.*core.*temp.*&amp;gt;"&lt;/span&gt;&lt;span&gt;),&lt;/span&gt;
    &lt;span&gt;in&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"Y"&lt;/span&gt;&lt;span&gt;),&lt;/span&gt;
    &lt;span&gt;out&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"temperature.*normal"&lt;/span&gt;&lt;span&gt;),&lt;/span&gt;
    &lt;span&gt;out&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"vent.*radioactive.*gas.*&amp;gt;"&lt;/span&gt;&lt;span&gt;),&lt;/span&gt;
    &lt;span&gt;in&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"no"&lt;/span&gt;&lt;span&gt;),&lt;/span&gt;
    &lt;span&gt;out&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"venting.*prevents.*explosion.*&amp;gt;"&lt;/span&gt;&lt;span&gt;),&lt;/span&gt;
    &lt;span&gt;in&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"yES"&lt;/span&gt;&lt;span&gt;),&lt;/span&gt;
    &lt;span&gt;out&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"gas.*blows.*crop.*"&lt;/span&gt;&lt;span&gt;),&lt;/span&gt;
    &lt;span&gt;gen_fsm&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;send_event&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Pid&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;timeout&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;% force a timeout faster
&lt;/span&gt;&lt;span&gt;&lt;/span&gt;    &lt;span&gt;out&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;".*Y/N.*&amp;gt;"&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;% some question
&lt;/span&gt;&lt;span&gt;&lt;/span&gt;    &lt;span&gt;in&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"No"&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;% who cares
&lt;/span&gt;&lt;span&gt;&lt;/span&gt;    &lt;span&gt;in&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"vent gAs"&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;% force a command
&lt;/span&gt;&lt;span&gt;&lt;/span&gt;    &lt;span&gt;out&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"gas.*blows.*crop.*"&lt;/span&gt;&lt;span&gt;).&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I basically just write the test the way I want it to look like. I will start
expecting messages that will match the regex &lt;code&gt;"press.*any.*key.*&amp;gt;"&lt;/code&gt; being
output, after which I’ll insert &lt;code&gt;&amp;lt;tab&amp;gt;&lt;/code&gt;. Rinse and repeat.&lt;/p&gt;
&lt;p&gt;Here, my desire is pretty much to turn the interactions I’d write in the shell
into a bunch of function calls and matches.&lt;/p&gt;
&lt;p&gt;That’s why I planned having a message-passing interface. I can now write
functions to wrap that functionality:&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;code data-lang="erlang"&gt;&lt;span&gt;%%%%%%%%%%%%%%%
&lt;/span&gt;&lt;span&gt;%%% HELPERS %%%
&lt;/span&gt;&lt;span&gt;%%%%%%%%%%%%%%%
&lt;/span&gt;&lt;span&gt;&lt;/span&gt;
&lt;span&gt;in&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Input&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;receive&lt;/span&gt;
        &lt;span&gt;{&lt;/span&gt;&lt;span&gt;in&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Pid&lt;/span&gt;&lt;span&gt;}&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; P&lt;/span&gt;&lt;span&gt;id&lt;/span&gt; &lt;span&gt;!&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;self&lt;/span&gt;&lt;span&gt;(),&lt;/span&gt; &lt;span&gt;Input&lt;/span&gt;&lt;span&gt;}&lt;/span&gt;
    &lt;span&gt;after&lt;/span&gt; &lt;span&gt;1000&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;        &lt;/span&gt;&lt;span&gt;ct&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;pal&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"MBOX: &lt;/span&gt;&lt;span&gt;~p&lt;/span&gt;&lt;span&gt;"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;process_info&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;self&lt;/span&gt;&lt;span&gt;(),&lt;/span&gt; &lt;span&gt;messages&lt;/span&gt;&lt;span&gt;)]),&lt;/span&gt;
        &lt;span&gt;error&lt;/span&gt;&lt;span&gt;({&lt;/span&gt;&lt;span&gt;too_long&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;in&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Input&lt;/span&gt;&lt;span&gt;}})&lt;/span&gt;
    &lt;span&gt;end&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If we look back into the mocked function, the mocked function sends us &lt;code&gt;{in,
ProcessThatWaitsForInput}&lt;/code&gt;. We take the &lt;code&gt;Input&lt;/code&gt; argument, and send it back to
the mocked function (which runs in its own process).&lt;/p&gt;
&lt;p&gt;If we never receive the &lt;code&gt;in&lt;/code&gt; message, we crash, but printing the debugging
information. Interestingly here the function I use is &lt;code&gt;ct:pal&lt;/code&gt;. It works exactly
like &lt;code&gt;io:format&lt;/code&gt;, except:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;It outputs to both the shell and HTML logs for Common Test&lt;/li&gt;
&lt;li&gt;It’s not gonna be used in production systems and it’s surely never going to
be mocked (unlike &lt;code&gt;io&lt;/code&gt;).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The &lt;code&gt;out/1&lt;/code&gt; helper is slightly more complex:&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;code data-lang="erlang"&gt;&lt;span&gt;%% fuzzily match the input string, waiting 1s at most
&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;out&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Expected&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;receive&lt;/span&gt;
        &lt;span&gt;{&lt;/span&gt;&lt;span&gt;out&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Prompt&lt;/span&gt;&lt;span&gt;}&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;            &lt;/span&gt;&lt;span&gt;ct&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;pal&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"Expected: &lt;/span&gt;&lt;span&gt;~p~n&lt;/span&gt;&lt;span&gt;Prompt: &lt;/span&gt;&lt;span&gt;~p&lt;/span&gt;&lt;span&gt;"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;Expected&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Prompt&lt;/span&gt;&lt;span&gt;]),&lt;/span&gt;
            &lt;span&gt;{&lt;/span&gt;&lt;span&gt;match&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;_}&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;re&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;run&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Prompt&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Expected&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;dotall&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;caseless&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;global&lt;/span&gt;&lt;span&gt;])&lt;/span&gt;
    &lt;span&gt;after&lt;/span&gt; &lt;span&gt;1000&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt;
&lt;/span&gt;&lt;span&gt;        &lt;/span&gt;&lt;span&gt;ct&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;pal&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"MBOX: &lt;/span&gt;&lt;span&gt;~p&lt;/span&gt;&lt;span&gt;"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;process_info&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;self&lt;/span&gt;&lt;span&gt;(),&lt;/span&gt; &lt;span&gt;messages&lt;/span&gt;&lt;span&gt;)]),&lt;/span&gt;
        &lt;span&gt;error&lt;/span&gt;&lt;span&gt;({&lt;/span&gt;&lt;span&gt;too_long&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;out&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Expected&lt;/span&gt;&lt;span&gt;}})&lt;/span&gt;
    &lt;span&gt;end&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;That one makes an assertion on a regular expression with &lt;code&gt;re:run/3&lt;/code&gt;, and the
rest is similar to what we did in &lt;code&gt;in/1&lt;/code&gt;. We receive the output, match it, and
that’s it.&lt;/p&gt;
&lt;p&gt;And there we go, we can run the tests:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;λ → rebar3 ct
→ rebar3 ct
===&amp;gt; Verifying dependencies...
===&amp;gt; Fetching meck ({pkg,&amp;lt;&amp;lt;"meck"&amp;gt;&amp;gt;,&amp;lt;&amp;lt;"0.8.2"&amp;gt;&amp;gt;})
===&amp;gt; Compiling meck
===&amp;gt; Compiling muumuu
===&amp;gt; Running Common Test suites...

&amp;lt;test output omitted&amp;gt;

All 1 tests passed.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After this, I check in the rebar lock files into version control, and I go do
something else because I’m pretty much done. You can see all the &lt;a href="https://github.com/ferd/howistart-erlang1-code"&gt;code
here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://howistart.org/posts/erlang/1/images/outdoors.gif"&gt;&lt;/p&gt;








&lt;/div&gt;&lt;a href="https://howistart.org/posts/erlang/1/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:29:55 UT
      </pubDate>
      <guid>
        https://howistart.org/posts/erlang/1/
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://www.drmaciver.com/2016/10/some-things-that-might-help-you-write-better-software/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;

&lt;nav&gt;
&lt;h3&gt;Post navigation&lt;/h3&gt;
&lt;span&gt;&lt;a rel="prev" href="https://www.drmaciver.com/2016/10/giving-up-on-giving-up-on-caffeine/"&gt;&lt;span&gt;←&lt;/span&gt; Giving up on giving up on caffeine&lt;/a&gt;&lt;/span&gt;
&lt;span&gt;&lt;a rel="next" href="https://www.drmaciver.com/2016/10/underestimating-the-inductive-step/"&gt;Underestimating the inductive step &lt;span&gt;→&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;
&lt;/nav&gt;













&lt;/div&gt;&lt;a href="https://www.drmaciver.com/2016/10/some-things-that-might-help-you-write-better-software/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:31:01 UT
      </pubDate>
      <guid>
        https://www.drmaciver.com/2016/10/some-things-that-might-help-you-write-better-software/
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://blog.gregbrockman.com/how-i-became-a-machine-learning-practitioner
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;article id="u5TReR2cWsQifoMYSHMtAg"&gt;
	&lt;time datetime="2019-07-30"&gt;July 30, 2019&lt;/time&gt;
  &lt;h2&gt;
    &lt;a href="https://blog.gregbrockman.com/how-i-became-a-machine-learning-practitioner"&gt;How I became a machine learning practitioner&lt;/a&gt;
  &lt;/h2&gt;
	&lt;p&gt;For the first three years of OpenAI, I dreamed of becoming a machine learning expert but made little progress towards that goal. Over the past nine months, I’ve finally made the transition to being a machine learning practitioner. It was hard but not impossible, and I think most people who are good programmers and know (or are willing to learn) the &lt;a href="https://www.deeplearningbook.org/"&gt;math&lt;/a&gt; can do it too. There are many online courses to &lt;a href="https://course.fast.ai/"&gt;self-study&lt;/a&gt; &lt;a href="https://github.com/openai/spinningup"&gt;the&lt;/a&gt; &lt;a href="http://cs231n.stanford.edu/"&gt;technical&lt;/a&gt; &lt;a href="http://rll.berkeley.edu/deeprlcoursesp17/"&gt;side&lt;/a&gt;, and what turned out to be my biggest blocker was a mental barrier — getting ok with being a &lt;a href="https://www.goodreads.com/quotes/309485-nobody-tells-this-to-people-who-are-beginners-i-wish"&gt;beginner&lt;/a&gt; again.&lt;/p&gt;

&lt;p&gt;&lt;img alt="gdb-ml1.png" src="https://svbtleusercontent.com/dvwQxNxkr6FKLVsDTBoqwm0xspap_small.png"&gt; &lt;em&gt;Studying machine learning during the 2018 holiday season.&lt;/em&gt;&lt;/p&gt;
&lt;h2 id="early-days_1"&gt;Early days &lt;a href="#early-days_1"&gt;#&lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;A founding principle of OpenAI is that we value research and engineering equally&amp;nbsp;—&amp;nbsp;our goal is to build working systems that solve previously impossible tasks, so we need both. (In fact, our team is comprised of 25% people primarily using software skills, 25% primarily using machine learning skills, and 50% doing a hybrid of the two.) So from day one of OpenAI, my software skills were always &lt;a href="https://blog.gregbrockman.com/define-cto-openai#gym_1"&gt;in demand&lt;/a&gt;, and I kept procrastinating on picking up the machine learning skills I wanted.&lt;/p&gt;

&lt;p&gt;After helping build &lt;a href="https://openai.com/blog/openai-gym-beta/"&gt;OpenAI Gym&lt;/a&gt;, I was called to work on &lt;a href="https://openai.com/blog/universe/"&gt;Universe&lt;/a&gt;. And as Universe was winding down, we decided to start working on &lt;a href="https://openai.com/five/#timeline"&gt;Dota&lt;/a&gt; — and we needed someone to turn the game into a reinforcement learning environment before any machine learning could begin.&lt;/p&gt;
&lt;h2 id="dota_1"&gt;Dota &lt;a href="#dota_1"&gt;#&lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Turning such a complex game into a research environment without source code access was &lt;a href="https://www.youtube.com/watch?v=UdIPveR__jw"&gt;awesome&lt;/a&gt; &lt;a href="https://openai.com/blog/more-on-dota-2/#infrastructure"&gt;work&lt;/a&gt;, and the team’s excitement every time I overcame a new obstacle was deeply validating. I figured out how to break out of the game’s Lua sandbox, &lt;a href="https://stackoverflow.com/a/426260"&gt;LD_PRELOAD&lt;/a&gt; in a Go GRPC server to programmatically control the game, incrementally dump the whole game state into a Protobuf, and build a Python library and abstractions with future compatibility for the many different multiagent configurations we might want to use.&lt;/p&gt;

&lt;p&gt;But I felt half blind. At &lt;a href="https://blog.gregbrockman.com/figuring-out-the-cto-role-at-stripe"&gt;Stripe&lt;/a&gt;, though I gravitated towards infrastructure solutions, I could make changes anywhere in the stack since I knew the product code intimately. In Dota, I was constrained to looking at all problems through a software lens, which sometimes meant I tried to solve hard problems that could be avoided by just doing the machine learning slightly differently.&lt;/p&gt;

&lt;p&gt;I wanted to be like my teammates Jakub Pachocki and Szymon Sidor, who had made the core breakthrough that powered our Dota bot. They had questioned the common wisdom within OpenAI that reinforcement algorithms didn’t scale. They wrote a distributed reinforcement learning framework called Rapid and scaled it exponentially every two weeks or so, and we never hit a wall with it. I wanted to be able to make critical contributions like that which combined software and machine learning skills.&lt;/p&gt;

&lt;p&gt;&lt;img alt="jakub-szymon-gdb.jpg" src="https://svbtleusercontent.com/pKEBrnXKw7dzHBrccoTvZF0xspap_small.jpg"&gt; &lt;em&gt;Szymon on the left; Jakub on the right.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In July 2017, it looked like I might have my chance. The software infrastructure was stable, and I began work on a machine learning project. My goal was to use behavioral cloning to teach a neural network from human training data. But I wasn’t quite prepared for just how much I would feel like a beginner.&lt;/p&gt;

&lt;p&gt;I kept being frustrated by small workflow details which made me uncertain if I was making progress, such as not being certain which code a given experiment had used or realizing I needed to compare against a result from last week that I hadn’t properly archived. To make things worse, I kept discovering small bugs that had been corrupting my results the whole time.&lt;/p&gt;

&lt;p&gt;I didn’t feel confident in my work, but to make it worse, other people did. People would mention how how hard behavioral cloning from human data is. I always made sure to correct them by pointing out that I was a newbie, and this probably said more about my abilities than the problem.&lt;/p&gt;

&lt;p&gt;It all briefly felt worth it when my code made it into the bot, as Jie Tang used it as the starting point for creep blocking which he then fine-tuned with reinforcement learning. But soon Jie figured out how to get better results without using my code, and I had nothing to show for my efforts.&lt;/p&gt;

&lt;p&gt;I never tried machine learning on the Dota project again.&lt;/p&gt;
&lt;h2 id="time-out_1"&gt;Time out &lt;a href="#time-out_1"&gt;#&lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;After we lost two games in The International in 2018, most observers thought we’d &lt;a href="https://twitter.com/polynoamial/status/1032988066967965696"&gt;topped out&lt;/a&gt; what our approach could do. But we knew from our metrics that we were right on the edge of success and mostly needed more training. This meant the demands on my time had relented, and in November 2018, I felt I had an opening to take a gamble with three months of my time.&lt;/p&gt;

&lt;p&gt;&lt;img alt="ti-elevator.png" src="https://svbtleusercontent.com/xeofo3DevLKYRqsiq7D5yR0xspap_small.png"&gt; &lt;em&gt;Team members in high spirits after losing our first game at The International.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;I learn best when I have something specific in mind to build. I decided to try building a chatbot. I started self-studying the curriculum we developed for our &lt;a href="https://openai.com/blog/openai-fellows/"&gt;Fellows&lt;/a&gt; program, selecting only the NLP-relevant modules. For example, I wrote and trained an LSTM language model and then a Transformer-based one. I also read up on topics like &lt;a href="https://colah.github.io/posts/2015-09-Visual-Information/"&gt;information theory&lt;/a&gt; and read many papers, poring over each line until I fully absorbed it.&lt;/p&gt;

&lt;p&gt;It was slow going, but this time I expected it. I didn’t experience flow state. I was reminded of how I’d felt when I just started programming, and I kept thinking of how many years it had taken to achieve a feeling of mastery. I honestly wasn’t confident that I would ever become good at machine learning. But I kept pushing because… well, honestly because I didn’t want to be constrained to only understanding one part of my projects. I wanted to see the whole picture clearly.&lt;/p&gt;

&lt;p&gt;My personal life was also an important factor in keeping me going. I’d begun a relationship with someone who made me feel it was ok if I failed. I spent our first holiday season together beating my head against the machine learning wall, but she was there with me no matter how many planned activities it meant skipping.&lt;/p&gt;

&lt;p&gt;One important conceptual step was overcoming a barrier I’d been too timid to do with Dota: make substantive changes to someone else’s machine learning code. I fine-tuned &lt;a href="https://github.com/openai/finetune-transformer-lm"&gt;GPT-1&lt;/a&gt; on chat datasets I’d found, and made a small change to add my own naive sampling code. But it became so painfully slow as I tried to generate longer messages that my frustration overwhelmed my fear, and I implemented GPU caching — a change which touched the entire model.&lt;/p&gt;

&lt;p&gt;I had to try a few times, throwing out my changes as they exceeded the complexity I could hold in my head. By the time I got it working a few days later, I realized I’d learned something that I would have previously thought impossible: I now understood how the whole model was put together, down to small stylistic details like how the codebase elegantly handles TensorFlow variable scopes.&lt;/p&gt;

&lt;p&gt;After three months of self-study, I felt ready to work on an actual project. This was also the first point where I felt I could benefit from the many experts we have at OpenAI, and I was delighted when Jakub and my co-founder Ilya Sutskever agreed to advise me.&lt;/p&gt;

&lt;p&gt;&lt;img alt="ilya.png" src="https://svbtleusercontent.com/4EsPtaedTxAUj3GCBLBvNe0xspap_small.png"&gt; &lt;em&gt;Ilya singing karaoke at our company offsite.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;We started to get very exciting results, and Jakub and Szymon joined the project full-time. I feel proud every time I see a commit from them in the machine learning codebase I’d started.&lt;/p&gt;

&lt;p&gt;I’m starting to feel competent, though I haven’t yet achieved mastery. I’m seeing this reflected in the number of hours I can motivate myself to spend focused on doing machine learning work — I’m now around 75% of the number of coding hours from where I’ve &lt;a href="https://twitter.com/sama/status/792898456650076160?lang=en"&gt;been historically&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;But for the first time, I feel that I’m on trajectory. At first, I was overwhelmed by the seemingly endless stream of new machine learning concepts. Within the first six months, I realized that I could make progress without constantly learning entirely new primitives. I still need to get more experience with many skills, such as initializing a network or setting a learning rate schedule, but now the work feels incremental rather than potentially impossible.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;From our Fellows and Scholars programs, I’d known that software engineers with solid fundamentals in linear algebra and probability can become machine learning engineers with just a few months of self study. But somehow I’d convinced myself that I was the exception and couldn’t learn. But I was wrong — even embedded in the middle of OpenAI, I couldn’t make the transition because I was unwilling to become a beginner again.&lt;/p&gt;

&lt;p&gt;You’re probably not an exception either. If you’d like to become a deep learning practitioner, you can. You need to give yourself the space and time to fail. If you learn from enough failures, you’ll succeed —&amp;nbsp;and it’ll probably take much less time than you expect.&lt;/p&gt;

&lt;p&gt;At some point, it does become important to surround yourself by existing experts. And that is one place where I’m incredibly lucky. If you’re a great software engineer who reaches that point, keep in mind there’s a way you can be surrounded by the same people as I am — &lt;a href="https://openai.com/jobs/"&gt;apply&lt;/a&gt; to OpenAI!&lt;/p&gt;



  &lt;figure id="kudo_u5TReR2cWsQifoMYSHMtAg"&gt;
    &lt;a href="#kudo"&gt;
      
    &lt;/a&gt;
    &lt;p&gt;1,074&lt;/p&gt;
    &lt;p&gt;Kudos&lt;/p&gt;
  &lt;/figure&gt;
  &lt;figure id="kudo_side_u5TReR2cWsQifoMYSHMtAg"&gt;
    &lt;a href="#kudo"&gt;
      
    &lt;/a&gt;
    &lt;p&gt;1,074&lt;/p&gt;
    &lt;p&gt;Kudos&lt;/p&gt;
  &lt;/figure&gt;
&lt;/article&gt;&lt;/div&gt;&lt;a href="https://blog.gregbrockman.com/how-i-became-a-machine-learning-practitioner"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:31:08 UT
      </pubDate>
      <guid>
        https://blog.gregbrockman.com/how-i-became-a-machine-learning-practitioner
      </guid>
    </item>
    <item>
      <title>
        The Coming Automation of Propaganda - War on the Rocks
      </title>
      <link>
        https://warontherocks.com/2019/08/the-coming-automation-of-propaganda/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div id="post-20662"&gt;

&lt;p&gt;If you want a vision of the future, imagine a thousand bots screaming from a human face – forever (apologies to George Orwell). As U.S.&amp;nbsp;policymakers remain indecisive over how to prevent a repeat of the 2016 election interference, the threat is looming ever more ominous on the horizon.&amp;nbsp;The public has unfortunately settled on the term&amp;nbsp;“bots”&amp;nbsp;to describe the social media manipulation activities of foreign actors,&amp;nbsp;invoking an image of neat rows of metal automatons hunched over keyboards, when in reality&amp;nbsp;&lt;a href="https://intelligence.house.gov/social-media-content/"&gt;live humans&lt;/a&gt; are methodically at work. While the 2016 election&amp;nbsp;mythologized the power of these influence-actors, such work is slow, costly, and labor-intensive. Humans must manually create and manage accounts, hand-write posts and comments, and spend countless hours reading content online to&amp;nbsp;&lt;a href="https://faculty.washington.edu/kstarbi/BLM-IRA-Camera-Ready.pdf"&gt;signal-boost particular narratives&lt;/a&gt;. However, recent advances in artificial intelligence (AI) may soon enable the automation of much of this work, massively amplifying the disruptive potential of online influence operations.&lt;/p&gt;
&lt;p&gt;This emerging threat draws its power from vulnerabilities&amp;nbsp;in our society: an unaware public, an underprepared legal system, and social media companies not sufficiently concerned with their exploitability by malign actors. Addressing these vulnerabilities requires immediate attention from lawmakers to inform the public, address legal blind spots, and hold social media companies to account.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Characterizing the Threat&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;What the American public has called AI, for lack of a better term, is better thought of as a cluster of emerging technologies capable of constructing convincing false realities. In line with the&amp;nbsp;&lt;a href="https://intelligence.house.gov/news/documentsingle.aspx?DocumentID=657"&gt;terms policymakers use&lt;/a&gt;, we will refer to the falsified media (pictures, audio, and video) these technologies generate as “deepfakes,” though we also suggest a new term, “machine persona,” to refer to AI that mimics the behavior of live users in the service of driving narratives.&lt;/p&gt;
&lt;p&gt;Improvements in AI bots, up to this point, have mostly manifested in relatively harmless areas like customer service. But these thus far modest improvements build upon breakthroughs in speech recognition and generation that are &lt;a href="https://www.theatlantic.com/technology/archive/2018/05/humans-acting-like-robots-vs-robots-acting-like-humans/559955/"&gt;nothing short of profound&lt;/a&gt;.&lt;/p&gt;



&lt;p&gt;OpenAI,&amp;nbsp;a project Elon Musk founded, made headlines this year for its GPT-2, a&amp;nbsp;&lt;a href="https://openai.com/blog/better-language-models/"&gt;text generation language model&lt;/a&gt;&amp;nbsp;the organization deemed “&lt;a href="https://slate.com/technology/2019/02/openai-gpt2-text-generating-algorithm-ai-dangerous.html"&gt;too dangerous to release.&lt;/a&gt;” This framing was perhaps an exaggeration, but OpenAI’s work was impressive nonetheless. Testers gave the algorithm 40GB of seed text from links aggregated across the Internet, which it studied with the aid of a&amp;nbsp;&lt;a href="https://blogs.nvidia.com/blog/2016/08/15/first-ai-supercomputer-openai-elon-musk-deep-learning/"&gt;supercomputer&lt;/a&gt;, producing a lightweight output that a&amp;nbsp;&lt;a href="https://github.com/openai/gpt-2"&gt;regular desktop could run&lt;/a&gt;. OpenAI released a toned-down version of the algorithm to the public, but the products the organization revealed of the full version were remarkable. Though OpenAI&amp;nbsp;&lt;a href="https://openai.com/blog/better-language-models/#sample1"&gt;admits to taking a few tries to get a good sample&lt;/a&gt;, given the first line of Orwell’s 1984, “It was a bright cold day in April, and the clocks were striking thirteen,” it eventually&amp;nbsp;&lt;a href="https://www.theguardian.com/technology/2019/feb/14/elon-musk-backed-ai-writes-convincing-news-fiction"&gt;produced a coherent opening&lt;/a&gt;&amp;nbsp;to a near-future novel set in Seattle. With an opening line about the discovery of unicorns in the Andes, an article GPT-2 produced wouldn’t look at all out of place in a pop-science website. That is, apart from the subject. The “&lt;a href="https://openai.com/blog/better-language-models/#sample2"&gt;fake news&lt;/a&gt;” applications require little imagination. &lt;a href="https://www.foreignaffairs.com/articles/2019-08-02/not-your-fathers-bots"&gt;One study&lt;/a&gt; explored this exact scenario, showing that GPT-2 was able to generate foreign policy news that subjects rated on average only marginally less credible than the &lt;em&gt;New York Times&lt;/em&gt; seed text.&lt;/p&gt;
&lt;p&gt;These developments aren’t mere science projects either, but beneficiaries of market forces. Companies have used natural language processing (NLP) and generalized text generation to automate a growing share of the customer service and information technology workforce, cutting labor costs and freeing skilled labor from menial tasks.&amp;nbsp;Advances in text generation have greatly benefited &lt;a href="https://automatedinsights.com/customer-stories/associated-press/"&gt;journalism in particular&lt;/a&gt;, driving media companies to invest in generating ever more believable content. However, NLP is just one facet of the AI revolution.&lt;/p&gt;
&lt;p&gt;Advancements in image recognition and generation can now produce faces that are almost entirely &lt;a href="https://thispersondoesnotexist.com/"&gt;indistinguishable from those of real humans&lt;/a&gt;. Intelligence organizations have already used this technology to&amp;nbsp;&lt;a href="https://www.apnews.com/bc2f19097a4c4fffaa00de6770b8a60d"&gt;solicit unwitting contacts&lt;/a&gt;&amp;nbsp;through social media. The same underlying technologies have also led to a recent spike in deepfake videos, now letting anyone with&amp;nbsp;&lt;a href="https://github.com/iperov/DeepFaceLab"&gt;at-home software&lt;/a&gt; blend real footage almost seamlessly with &lt;a href="https://www.youtube.com/watch?v=bPhUhypV27w"&gt;generated content&lt;/a&gt;.&amp;nbsp;And you don’t have to take our word for it,&amp;nbsp;&lt;a href="https://www.youtube.com/watch?v=cQ54GDm1eL0"&gt;trust former president Barack Obama&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;AI technology also has less flashy, but no less substantial applications in influencing what users see online. Social media platforms work by identifying trending content and boosting it into the feeds of other users. While the case varies from platform to platform, these trend algorithms tend to be a function of ‘likes,’ ‘retweets,’ or ‘upvotes’ over time, but they weight early interaction most strongly. This means that a small,&amp;nbsp;&lt;a href="https://www.forbes.com/sites/jaymcgregor/2016/12/14/how-we-bought-reddit-for-200/#5fd60b7544a8"&gt;concentrated burst of interaction&lt;/a&gt;&amp;nbsp;at the birth of new content is often&amp;nbsp;&lt;a href="https://summercon.org/presentations.html#rain-drop-drop-top"&gt;all that is necessary&lt;/a&gt;&amp;nbsp;to send it trending, pushing it into the feeds of thousands of legitimate users.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Understanding the Impact&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To appreciate the threat at the intersection of deepfakes and machine personas, consider your daily diet of online information. You probably know enough to avoid following small, suspicious accounts on Twitter or browsing links to sites of which you’ve never heard. You probably don’t accept Facebook friend requests from people you’ve never met and generally stay out of the seedier parts of Reddit. However, the Internet is an ecosystem built for virality. A disruption somewhere can have &lt;a href="https://arxiv.org/abs/1805.12512"&gt;impacts almost anywhere&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Imagine an influence-actor posts a&amp;nbsp;&lt;a href="https://www.vice.com/en_us/article/ywyxex/deepfake-of-mark-zuckerberg-facebook-fake-video-policy"&gt;deepfake video&lt;/a&gt;&amp;nbsp;of the NYPD beating a young minority man to death in an alley. The alley in the background is real. The faces of the police doing the beating are real. The face of the man beaten to death is real, taken from a list of missing persons. The video need only be dropped in a forum somewhere for the Internet to do the rest. Machine personas can then set about controlling the dialogue, goading opposition, reinforcing extremists, and generally shaping the conversation in the most confrontational direction possible. In popular forums such as Reddit, they automatically identify and &lt;a href="https://www.forbes.com/sites/jaymcgregor/2016/12/14/how-we-bought-reddit-for-200/#5fd60b7544a8"&gt;signal-boost comments&lt;/a&gt; about the incident that threaten violence against the police and government. Users claiming the footage is deepfaked are targeted by these same machine personas with downvotes and accusations of supporting a cover up. The omnipresent machine personas fake a public consensus and make dissenters feel they are an unwelcome minority. Posts about the incident reach the front page of Reddit where real users pick up and&amp;nbsp;&lt;a href="http://ide.mit.edu/sites/default/files/publications/2017%20IDE%20Research%20Brief%20False%20News.pdf"&gt;spread the “news” across Facebook and Twitter&lt;/a&gt;, reaching an audience of millions in just a few hours.&lt;/p&gt;
&lt;p&gt;As the NYPD struggles to evaluate the video and debunk it, an operative &lt;a href="https://medium.com/huia/live-deep-fakes-you-can-now-change-your-face-to-someone-elses-in-real-time-video-applications-a4727e06612f"&gt;assuming the identity&lt;/a&gt;&amp;nbsp;of a concerned NYPD officer sends a&amp;nbsp;&lt;a href="https://www.vice.com/en_us/article/3k7mgn/baidu-deep-voice-software-can-clone-anyones-voice-with-just-37-seconds-of-audio"&gt;deepfake audio file&lt;/a&gt; to a major U.S. news publication. The file contains the supervisor of the framed officers engaging in a racial epithet-laden rant about the alleged cover-up. The deceived news organization vouches for its credibility, lending its authority to the outrage. Machine personas &lt;a href="https://towardsdatascience.com/automated-text-classification-using-machine-learning-3df4f4f9570b"&gt;automatically identify&lt;/a&gt;&amp;nbsp;and signal-boost tweets and comments advocating for&amp;nbsp;&lt;a href="https://thehill.com/policy/technology/358025-thousands-attended-protest-organized-by-russians-on-facebook"&gt;protest marches&lt;/a&gt;. In the following days, a video surfaces on&amp;nbsp;&lt;a href="https://www.amazon.com/Kill-All-Normies-Culture-Alt-Right/dp/1785355430"&gt;4chan&lt;/a&gt;&amp;nbsp;of immigrants kidnapping and sexually assaulting a young girl, though nobody in the video actually exists to undermine its authenticity. Machine personas then begin advocating on 4chan and 8chan for&amp;nbsp;&lt;a href="https://www.thedailybeast.com/new-zealand-shooting-who-was-ebba-akerlund-whose-death-mosque-shooter-used-as-pretext-for-revenge"&gt;acts of revenge&lt;/a&gt;&amp;nbsp;against the planned protesters, who the machine personas label politically responsible for advocating pro-immigration policies.&lt;/p&gt;
&lt;p&gt;Whether a malicious group would engage in such an overtly provocative act or merely&amp;nbsp;&lt;a href="https://www.theguardian.com/world/2018/dec/24/race-russian-election-interference-senate-reports"&gt;patiently stoke the same resentments&lt;/a&gt;&amp;nbsp;is debatable. The danger is that these technologies exist now. Though they may only be prototypes, it is ill-advised to bet against technological progress. In a world where the above scenario is possible, curating your social media contacts is insufficient to insulate yourself from the effects of malign actors. If you are American, you also may have imagined Russia behind this fictional attack, but we ask you to think more broadly. While the resources of a state actor made possible the interference into the 2016 U.S. presidential campaign, AI technologies could put this power into the hands of minor state or even non-state actors.&amp;nbsp;In fact, nothing about this vignette couldn’t be done by a talented lone wolf&amp;nbsp;lacking any intelligence footprint whatsoever.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Countering the Effects&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;There are no easy solutions&amp;nbsp;to the informational challenges&amp;nbsp;AI presents.&amp;nbsp;Each challenge warrants a deeper discussion than we can deliver&amp;nbsp;here, and many of these challenges will have consequences that will require considerable reflection. Rather than proposing solutions in a vacuum, this conversation is best framed in terms of&amp;nbsp;the&amp;nbsp;vulnerabilities that any solution would need to address.&lt;/p&gt;
&lt;p&gt;The first vulnerability is a lack of public&amp;nbsp;awareness or skepticism towards content that users view online. A concerted effort should be made by U.S. legislators and Silicon Valley to bring public attention to AI-enabled disinformation. The June 13&amp;nbsp;&lt;a href="https://www.c-span.org/video/?461679-1/house-intelligence-committee-hearing-deepfake-videos"&gt;congressional hearing&lt;/a&gt;&amp;nbsp;on AI-enabled influence operations was an important first step, and it is encouraging to hear bipartisan consensus on the threat. However, awareness has limitations. The public is fortunate that deepfakes and text generators still have a somewhat identifiable “&lt;a href="https://www.lexalytics.com/lexablog/deepfakes-explained-what-why-how-to-spot"&gt;off” quality&lt;/a&gt;&amp;nbsp;to them. Yet the technology is unlikely to plateau here.&amp;nbsp;&lt;a href="https://engineering.purdue.edu/~dgueraco/content/deepfake.pdf"&gt;Technical solutions&lt;/a&gt;&amp;nbsp;also&amp;nbsp;exist in identifying machine-generated content. However, there is no inherent quality of “realness” to a real image that more sophisticated software couldn’t eventually recreate. In a world where malign actors can generate pixel-by-pixel accurate content in the comfort of their own basements,&amp;nbsp;distinguishing fake content from a grainy cell phone video could conceivably become&amp;nbsp;impossible. Everyone should already have an untrusting eye turned towards what they see online, but we ourselves can’t claim to always abide by this virtue. Still, the public should be continuously confronted with the ease with which&amp;nbsp;machine personas will soon be manufacturing provocative and disgusting content. To mitigate this vulnerability, our first impulse when we see members of a different political persuasion engaging in outrageous behavior should not be to share it, but to question its veracity.&lt;/p&gt;
&lt;p&gt;The second vulnerability is a legal system with numerous blind spots that lawmakers should close. Reddit is the third-most-popular social media site on the Internet, &lt;a href="https://www.digitaltrends.com/computing/reddit-more-popular-than-facebook-in-2018/"&gt;surpassing Facebook&lt;/a&gt; among American Internet users. It is also shockingly vulnerable, requiring only an e-mail address to register an account. Consequently, anyone could theoretically register an unlimited number of accounts and, being careful not to stand out to system administrators,&amp;nbsp;&lt;a href="https://www.forbes.com/sites/jaymcgregor/2016/12/14/how-we-bought-reddit-for-200/#5fd60b7544a8"&gt;effectively control conversations&lt;/a&gt;&amp;nbsp;on whatever topics they want. This is no hypothetical — you can pay for&amp;nbsp;&lt;a href="https://reddit-marketing.pro/"&gt;this service&lt;/a&gt;&amp;nbsp;right now. (Please don’t.) It’s hard to imagine a real-life analogy, but would Americans defend the right of the local felon to march on city hall with a thousand androids masquerading as fellow citizens? This drives to the heart of an&amp;nbsp;&lt;a href="https://www.city-journal.org/html/platform-or-publisher-15888.html"&gt;ongoing legal debate&lt;/a&gt;&amp;nbsp;on what exactly social media is and how regulators should treat it. However, to accept the status quo is to accept that such behavior is no more serious than a terms of service violation. This unsettled status that regards social media as no more than the footprint of its company is insufficient to capture the scope and impact that users who abuse social platforms have on American society.&lt;/p&gt;
&lt;p&gt;The third vulnerability is online anonymity. While we absolutely do not advocate for de-anonymizing the Internet, it is now so influential over American society that legislators should not leave regulation to social media platforms alone. Congress should put more pressure on social media companies to ensure their users are, at a minimum, who they say they are. That said, it is still important to remember that anonymity is both a bug and a feature, and not something regulators should crush out of hand. The Internet’s capacity to act as a platform for dissidents is not something lawmakers should root out, though any attempts are &lt;a href="https://tempophone.com/"&gt;likely to fail anyway&lt;/a&gt;. Still, wherever a microphone appears before a crowd online, there should be no question that malicious actors will seek to place themselves before it. When they can do so with anonymity, tracing the origins of deepfaked media and rooting them out becomes a nearly impossible task. There is a middle ground between anarchy and government-issued Facebook accounts. That middle ground likely involves a far better vetting process for account creation at major sites. A modified&amp;nbsp;&lt;a href="https://www.ics.uci.edu/~kobsa/papers/2003-TOIT-kobsa.pdf"&gt;pseudonymity&amp;nbsp;&lt;/a&gt;system is one possibility, whereby a third party cryptographically verifies an individual can hold an account, then ties the account to that identity without disclosing the name of the holder. This is also not without its faults, both technical and otherwise, not least of which is who the third party should be.&amp;nbsp;Though the government is one clear answer, for a public so enamored with conspiracy theories, Americans shouldn’t expect federally managed Internet identity tracking to be popular with any demographic except federal officials. Platforms also&amp;nbsp;come and go,&amp;nbsp;meaning that companies and regulators would have to continuously renegotiate such a solution. The&amp;nbsp;&lt;a href="https://www.cfr.org/blog/preventing-balkanization-internet"&gt;Internet is&amp;nbsp;also&amp;nbsp;international&lt;/a&gt;&amp;nbsp;— forcing sites to navigate the myriad of requirements various states impose on them. However, no solution needs to be 100% effective. Nor could it, in the face of well-resourced state actors. It should only make reaching&amp;nbsp;&lt;a href="https://fs.blog/2017/07/critical-mass/"&gt;critical mass&lt;/a&gt;&amp;nbsp;in public spaces prohibitively expensive.&lt;/p&gt;
&lt;p&gt;Every solution will be painful. Consequently, we don’t expect that regulators will take any significant steps in the directions outlined above until the effects of machine personas become undeniable. It is the responsibility of both the U.S. government and Silicon Valley to ensure that the American public is aware of this threat so that policymakers have the necessary political capital to take action. The public should also be prepared for the possibility that malign actors will put their thumbs on the scale to the&amp;nbsp;&lt;a href="https://www.dw.com/en/frances-yellow-vests-and-the-russian-trolls-that-encourage-them/a-46753388"&gt;benefit of one political entity&lt;/a&gt;&amp;nbsp;over another, so they should have a united voice in rejecting anti-democratic interference. The Internet may already be past the era of speculation about the problem and in the age of persistent machine interference. To protect both it and democracy, the American public needs to begin these conversations in earnest.&lt;/p&gt;



&lt;p&gt;&lt;em&gt;Capt. Frank Adkins and Capt. Shawn Hibbard are both active duty Air Force cyber officers and graduates of the U.S. Air Force Academy. They’ve worked at Cyber Command in various positions as operators, red teamers, and planners on the leading edge of the U.S. cyber mission. Capt. Adkins received his Master’s in computer science from Northeastern University with a focus in cyber vulnerability assessment, and Capt. Hibbard received his in strategic intelligence from the National Intelligence University, studying the strategic implications of next-generation supercomputing technology. The views expressed are those of the authors and do not necessarily reflect the official policy or position of the U.S. Air Force, Cyber Command, or the U.S. government.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Image: &lt;a href="https://www.flickr.com/photos/dcarlbom/3468358859"&gt;Daniel Carlbom&lt;/a&gt; and &lt;a href="https://pixabay.com/illustrations/matrix-code-data-networking-1735640/"&gt;Johnny Lindner&lt;/a&gt;, adapted by War on the Rocks&lt;/p&gt;


        
    &lt;/div&gt;&lt;/div&gt;&lt;a href="https://warontherocks.com/2019/08/the-coming-automation-of-propaganda/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:31:16 UT
      </pubDate>
      <guid>
        https://warontherocks.com/2019/08/the-coming-automation-of-propaganda/
      </guid>
    </item>
    <item>
      <title>
        Every productivity thought I&amp;#39;ve ever had, as concisely as possible - Alexey Guzey
      </title>
      <link>
        https://guzey.com/productivity/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;article&gt;
      &lt;h2&gt;Every productivity thought I've ever had, as concisely as possible&lt;/h2&gt;
      
              &lt;span&gt;
          created: &lt;i&gt;&lt;time&gt;2018-08-07&lt;/time&gt;;&lt;/i&gt; modified: &lt;i&gt;&lt;time&gt;2020-06-15&lt;/time&gt;&lt;/i&gt;

        &lt;/span&gt;
        
      


      

      &lt;p&gt;See discussion on &lt;a href="https://news.ycombinator.com/item?id=20737304"&gt;Hacker News&lt;/a&gt; (&lt;a href="https://perma.cc/LJN5-EVQ4"&gt;a&lt;/a&gt;) (610 points, 156 comments)&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;I combed through several years of my private notes and through everything I published on productivity before and tried to summarize all of it in this post.&lt;/p&gt;
&lt;h2 id="if-youre-unproductive-right-now"&gt;If you’re unproductive right now&lt;/h2&gt;
&lt;p&gt;Here’s what you should do if you’ve been procrastinating for an entire day:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Accept that you won’t do anything today and try not to get angry at yourself&lt;/li&gt;
&lt;li&gt;Set the alarm for the time you will be preparing to go to bed today&lt;/li&gt;
&lt;li&gt;No, really. Do it. It will take 20 seconds&lt;/li&gt;
&lt;li&gt;Procrastinate for the rest of the day&lt;/li&gt;
&lt;li&gt;When the alarm rings, put your laptop and everything you need for work in your backpack&lt;/li&gt;
&lt;li&gt;When you wake up, try to not check social media, email or anything else. Do not take anything out of your backpack&lt;/li&gt;
&lt;li&gt;Get dressed, take your stuff, and go to a library, cafe, whatever else where you either
&lt;ul&gt;
&lt;li&gt;never been to&lt;/li&gt;
&lt;li&gt;have been to but never procrastinated within the last 6 months&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;While getting to that place, figure out what you want to be doing today&lt;/li&gt;
&lt;li&gt;Do it&lt;/li&gt;
&lt;li&gt;Return home in the evening. Don’t take anything (especially your laptop) out of your backpack. Repeat steps 6-10&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="every-productivity-system-stops-working-eventually-and-theres-nothing-you-can-do-about-it"&gt;Every productivity system stops working eventually and there’s nothing you can do about it&lt;/h2&gt;
&lt;p&gt;You’ve most likely tried the pomodoro technique. You set the timer for 25 minutes, then take a 5 minute break, then set the timer for 25 minutes again, then at some point you take a longer break and so on. I predict that pomodoro technique eventually broke down for the following reasons:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;you stopped adhering strictly to 5 minute breaks and they started turning into 6-7-10-15-20-or-more minute breaks&lt;/li&gt;
&lt;li&gt;you’ve gained an aversion towards 25 minute timers, even while remembering that you should set them, and started finding excuses like “oh this task is too short”, “oh i don’t need a pomo right now”, “i will wait till round time (:00 or :30) and start the pomo then” and these excuses started happening more and more frequently&lt;/li&gt;
&lt;li&gt;you started to outright forget about pomodoros, instead just doing your stuff the old way and once in a while realizing that you should’ve been running a pomodoro&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;It seems that every productivity trick / system stops working in exactly the same way I described above. Most productivity tricks develop aversion around them. All of them lose salience.&lt;/p&gt;
&lt;p&gt;The only way to avoid encountering problems with productivity is to make the stuff you want to be doing in the long-term to be the most exciting stuff you can do at any moment in time, which is perhaps possible if you, e.g. work at a startup, but is untenable in almost every situation.&lt;/p&gt;
&lt;h2 id="context-intentionality-as-the-key-difference-between-home-and-every-other-place-on-planet-earth"&gt;Context intentionality as the key difference between home and every other place on planet earth&lt;/h2&gt;
&lt;p&gt;You never wake up at work having forgotten to fill out to dos for the day and feeling slightly depressed.&lt;/p&gt;
&lt;p&gt;However awesome you feel you are, this &lt;em&gt;does&lt;/em&gt; occasionally happen at home.&lt;/p&gt;
&lt;p&gt;Home is the default place. Home lacks intentionality, which means that sometimes you will feel that “I need to do something” rather than “I will do something something specific right now”. As Kaj Sotala puts it: &lt;a href="https://www.facebook.com/Xuenay/posts/10153513535798662"&gt;“I’m starting to suspect that I may have MASSIVELY underestimated the negative motivational impact of not having a clear sense of one’s next action in a project. …"&lt;/a&gt; (&lt;a href="https://perma.cc/H7QD-9CDH"&gt;a&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Having no clear idea what to do next increases the probability that you won’t feel like following all the rules you came up with massively. The only solution I know is to avoid working from home as much as you can.&lt;/p&gt;
&lt;p&gt;If you aren’t working from home, your workplace should be at least a couple of minutes away (better: an hour away), so that you would not fall into the same trap with it and &lt;em&gt;always&lt;/em&gt; had the time to think on what specifically you’re going to do once there. &lt;label for="sn-2"&gt;
&lt;/label&gt;

&lt;span&gt;
This is also why designating a special room at home as an “office” is probably a bad idea: you will frequently enter it on autopilot, without intentionality. 
&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Thus, even if you can work at home, you probably shouldn’t. I personally try leave home as early as possible, go to the university, and return home as late as possible.&lt;/p&gt;
&lt;p&gt;A trick to aid leaving home and going to work someplace else is to try explicitly forbidding doing anything productive at home. This way, you can no longer tell yourself you’ll start working “soon” and then proceed to waste the entire day procrastinating.&lt;/p&gt;
&lt;h2 id="interlude-eliminate-the-distractions-is-the-worst-productivity-advice-ive-ever-seen"&gt;Interlude: “eliminate the distractions” is the worst productivity advice I’ve ever seen&lt;/h2&gt;
&lt;p&gt;With my present system, YouTube, reddit, agar.io, etc. are always just two clicks away, but it doesn’t seem to matter at all. And yet, when I had StayFocusd installed with Nuclear Option turned on (forbidding to visit any sites that aren’t on the white list), I picked up Windows Minesweeper and Solitaire, would often literally bang on the keyboard staring at the monitor wanting to scream and eventually found out a way to uninstall StayFocusd even when I purposely made it — as I thought — impossible to do so.&lt;/p&gt;
&lt;p&gt;The very fact that your to do list feels ughy means you’re doing something wrong. The very fact that you need to fight the urges to procrastinate means you’re doing it wrong. The utility function itself is warped in fucked up contexts.&lt;/p&gt;

&lt;h2 id="how-i-work-and-rest-how-my-system-is-different-from-all-the-others-and-why-i-like-it-so-much"&gt;How I work and rest, how my system is different from all the others, and why I like it so much&lt;/h2&gt;
&lt;p&gt;For the last several years, &lt;em&gt;all&lt;/em&gt; &lt;label for="sn-3"&gt;
&lt;/label&gt;

&lt;span&gt;
Did I hear somebody say “preference for routine”?
&lt;/span&gt; my working time has been structured as follows:&lt;/p&gt;
&lt;figure&gt;
    &lt;img src="https://guzey.com/pomos.png"&gt; 
&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;work for 25 minutes from :05 to :30&lt;/li&gt;
&lt;li&gt;take a 5 minute break from :30 to :35&lt;/li&gt;
&lt;li&gt;work for 25 minutes from :35 to :00&lt;/li&gt;
&lt;li&gt;take a 5 minute break from :00 to :05&lt;/li&gt;
&lt;li&gt;every three hours (at 12-3-6-9) the :05-:30 work cycle is substituted for a break, which lasts 35 minutes.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For example&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;work: 9:35-10:00&lt;/li&gt;
&lt;li&gt;break: 10:00-10:05&lt;/li&gt;
&lt;li&gt;work: 10:05-10:30&lt;/li&gt;
&lt;li&gt;break: 10:30-10:35&lt;/li&gt;
&lt;li&gt;work: 10:35-11:00&lt;/li&gt;
&lt;li&gt;break: 11:00-11:05&lt;/li&gt;
&lt;li&gt;work: 11:05-11:30&lt;/li&gt;
&lt;li&gt;break: 11:30-11:35&lt;/li&gt;
&lt;li&gt;work: 11:35-12:00&lt;/li&gt;
&lt;li&gt;break: 12:00-12:35&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It’s important for me my clock shows seconds, therefore I could know the start/end of pomos/breaks precisely, instead of constantly trying to guess them. On Windows I use &lt;a href="https://github.com/White-Tiger/T-Clock"&gt;T-Clock&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;But didn’t I just write that every productivity system breaks down eventually? Yep, this one breaks down as well. However, I found that this arrangement:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;prolongs the period during which the system works.&lt;/li&gt;
&lt;li&gt;provides me with 625 minutes of work, interspersed with 275 minutes of breaks (provided my workday is 15 hours). This ratio of work / breaks means that I
&lt;ul&gt;
&lt;li&gt;have a relatively easy time convincing myself to put off impulsive things (because the maximum waiting time is less than 2.5 hours — until the next long break)&lt;/li&gt;
&lt;li&gt;don’t burn out, since such a large portion of my day is specifically dedicated to doing pleasurable, rewarding in the short-term stuff&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;is impossible to forget. Frequently, we simply forget about productivity tricks. Once whole life is built around one, it becomes pretty difficult to forget about it.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You may say, “but isn’t this basically Pomodoro Technique TM?” Kind of. There are several important differences.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;I don’t care about doing only full pomodoros: suppose, I got home at 20:15. Do I dick around and wait till 20:35 to start a pomo? No. 20:15 is time during which I’m working, so I get to work, and then round this pomo up or down , depending on the circumstances.&lt;/li&gt;
&lt;li&gt;I don’t care about pomos being “distraction-free”: suppose, I got distracted in the middle of a pomo. Do I start over? No, I just get back to work, and round this pomo up or down, depending on the circumstances.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The fact that I &lt;em&gt;never&lt;/em&gt; have to think “do I work right now or do I take a break right now?” removes most of the friction of the pomodoro technique and means I no longer have to &lt;em&gt;actively&lt;/em&gt; think about starting pomodoros. &lt;label for="sn-4"&gt;
&lt;/label&gt;

&lt;span&gt;
Complice’s &lt;a href="https://complice.co/room/lesswrong"&gt;LessWrong Study Hall&lt;/a&gt; served as an inspiration for me. 
&lt;/span&gt; Given these modifications, it seems that I was able to make my system somewhat of a natural equilibrium.&lt;/p&gt;
&lt;p&gt;Some additional rules / heuristics that I follow:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;if I’m in the flow and don’t notice that it’s a break right now, then I skip it. This happens regularly to short breaks; occasionally, e.g. if I’m writing a really exciting post, to long breaks&lt;/li&gt;
&lt;li&gt;I usually divide the stuff I work on in 3 hour chunks. For example, my today’s to do list is:
&lt;ul&gt;
&lt;li&gt;-9 work on the most exciting thing about site&lt;/li&gt;
&lt;li&gt;9-12 productivity post&lt;/li&gt;
&lt;li&gt;12-13:30 &lt;a href="https://guzey.com/personal/college"&gt;retrospective on college post&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;13:30-15 clean up OneNote&lt;/li&gt;
&lt;li&gt;15-18 data post&lt;/li&gt;
&lt;li&gt;18-21 clean up incoming information&lt;/li&gt;
&lt;li&gt;21- figure out site’s todos&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;if I’m obsessed with something, e.g. very exciting research, I usually fill the entire day with it&lt;/li&gt;
&lt;li&gt;if I finish my task in the middle of a pomo, then I move on to the next task immediately&lt;/li&gt;
&lt;li&gt;if I decide that I don’t want to finish the pomo on the task I planned, e.g. after realizing that the textbook I picked is bad, I try to finish the pomo doing as similar to the original task as possible, e.g. starting to read another textbook on the topic&lt;/li&gt;
&lt;li&gt;if I have a thought pop up in my head during a pomo, I write it down to an “Incoming.md” file always open in Notepad. I clean this file up during the breaks and on Sunday&lt;/li&gt;
&lt;li&gt;during the short breaks I’m only allowed non-distractive stuff, i.e. social media, email, most of reddit, slack are  prohibited &lt;strong&gt;but&lt;/strong&gt;
&lt;ol&gt;
&lt;li&gt;if I have an ongoing conversation with someone, then during the next short break I’m allowed to check if the person wrote anything and reply to them
&lt;ol&gt;
&lt;li&gt;if I think the conversation does not wait, then set the phone timer for 5 minutes, and open the conversation then&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;if I need to open a specific email conversation, I go to &lt;a href="https://mail.google.com/mail/u/0/#search/NAMELASTNAMEORTOPIC,"&gt;https://mail.google.com/mail/u/0/#search/NAMELASTNAMEORTOPIC,&lt;/a&gt; which, along with &lt;a href="https://chrome.google.com/webstore/detail/unread-message-count-hide/jpcbhpcbhlmpnifidfhkomaaeifhiklk"&gt;hidden number of unread messages&lt;/a&gt;, means I don’t get distracted&lt;/li&gt;
&lt;li&gt;if I need to open my email inbox, I think if I can wait till the long break
&lt;ol&gt;
&lt;li&gt;if I can’t, set the phone timer for 5 minutes, and open email then&lt;/li&gt;
&lt;li&gt;if I can, open the “Incoming.md” file and write the thing I want to check there, so I don’t forget about it&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;if I need to open Twitter / FB for some reason
&lt;ol&gt;
&lt;li&gt;open it incognito, so that I don’t see my timeline, notifications, and DMs&lt;/li&gt;
&lt;li&gt;if I need to use my account, e.g. to tweet something or to write someone
&lt;ol&gt;
&lt;li&gt;write the tweet down and wait till the long break&lt;/li&gt;
&lt;li&gt;set the phone timer for 5 minutes, and open Twitter then&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Chrome
&lt;ol&gt;
&lt;li&gt;if I need to open a webpage for something, I’m only allowed to get one page away from what is immediately needed for the task, e.g. I’m writing this post and I want to see what Wikipedia writes about GTD, so I’m allowed to go to GTD, then from GTD to David Allen (and to any other page linked at GTD) but I’m not allowed to open any pages from David Allen. This is the exploration / exploitation tradeoff I enjoy&lt;/li&gt;
&lt;li&gt;if I’m researching something, I’m only allowed to open one page at a time, e.g. when I’m doing a literature review, I open the page, read it, close it, and then open the next one. This prevents me from accumulating a unread tabs too fast&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;if I have an ongoing real-time conversation with someone during the long break, I can continue it&lt;/li&gt;
&lt;li&gt;if I’m chatting with someone IRL and I need to open social media because of this, e.g. to send the person I’m chatting with a tweet, I’m allowed to open social media anytime, but only for that specific thing&lt;/li&gt;
&lt;li&gt;if I want to listen to a music, 5 minute timer (because music is somewhat distracting and starting listening to it impulsively is dangerous)&lt;/li&gt;
&lt;li&gt;If I just published a post, I can check social media whenever for the next 6 hours.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I have similar rules for all the other stuff, key being that I must either ensure that I don’t get distracted (incognito) or to make sure I’m not doing anything impulsive (5 minute timer, other person as a trigger). If I don’t follow this, it may be impossible to distinguish between opening, e.g. Twitter because I really needed it or because I really wanted to check my notifications. And if I can’t distinguish between these two, then the simplest explanation is the impulsive one, which means that I’m losing control. Which is really, really bad.&lt;/p&gt;
&lt;p&gt;My model of the brain is the following: if it believes that you will do as you planned to do, it will occasionally probe you with impulses, but nothing major, and you will be able to do what your “system 2” &lt;label for="sn-5"&gt;
&lt;/label&gt;

&lt;span&gt;
Where system 1 is “fast” and system 2 is “slow”. 
&lt;/span&gt; wants to do. But if you start to give in to these impulses, the brain increases their power and their frequency, and naturally, you start to give in more and more, right until the point when you do nothing but what your impulsive brain wants you to do in the moment.&lt;/p&gt;
&lt;p&gt;Note that being aware of doing something on impulse doesn’t magically remove the adverse consequences of the action on rules you’re breaking, i.e. being aware of breaking a rule does not make it ok to break it.&lt;/p&gt;
&lt;h2 id="rules-are-about-exceptions"&gt;Rules are about exceptions&lt;/h2&gt;
&lt;p&gt;Why the hell does my “some additional rules” list look like the table of contents for War and Peace? Why don’t I just say “distractive stuff allowed only during long breaks”? Because &lt;em&gt;rules are about exceptions&lt;/em&gt;. Exceptions are inevitable. Sometimes I will have to open a social network or check email during pomos. If I didn’t have exceptions explicitly written down, then I would break my rules, thereby decreasing their future strength. &lt;label for="sn-6"&gt;
&lt;/label&gt;

&lt;span&gt;
I wrote up a formal model of this process in my &lt;a href="https://guzey.com/files/bachelors-thesis/guzey-commitments.pdf"&gt;Bachelor’s thesis&lt;/a&gt;. 
&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Still, it’s impossible to write down &lt;em&gt;all&lt;/em&gt; exceptions, which means that sometimes I still break my rules and sometimes the rules break down completely. Thus, I need a way to reinstitute them.&lt;/p&gt;
&lt;h2 id="interlude-guilt"&gt;Interlude: guilt&lt;/h2&gt;
&lt;p&gt;When a rule / productivity system breaks and you start wasting your time, don’t take it too personally and try not to blame yourself. The only thing you can do now is write your observations down, think about how to improve them for the future, and then try to implement them.&lt;/p&gt;
&lt;h2 id="rules-stopped-working-what-next"&gt;Rules stopped working. What next?&lt;/h2&gt;
&lt;p&gt;First of all, an important qualification: rules don’t just stop working. They stop working in specific contexts, e.g. if you go to a novel location, you will find that the old patterns of behavior — whether productive or destructive — are much weakened there. This suggests a natural solution to the problem of reinstating broken rules: go to an unexplored coffee shop or library and work there until the new location breaks down.&lt;label for="sn-7"&gt;
&lt;/label&gt;

&lt;span&gt;
Often, people work in libraries and coffee shops precisely for this reason — because these locations allow to create a &lt;a href="https://twitter.com/The_Lagrangian/status/670332250089762816"&gt;novel self-pattern&lt;/a&gt; specifically for them. 
&lt;/span&gt; The problem with this is that if there are too many possible locations, there’s no incentive to maintain the rules structure in them, so they break down too fast.&lt;/p&gt;
&lt;p&gt;I found that I have 3-4 places in town I especially like and rotate my work between those in which rules work at the moment (the rule following ability seems to reset naturally within several days-weeks-months for each location). I have one specific place in which the rules are extra strict, meaning, upon entering this place I turn off mobile internet on the phone and can only turn it on after a 5 minute timer.&lt;/p&gt;
&lt;p&gt;Pro tip: you don’t usually go from 0 procrastination to 100 in an instant. If you learn to recognize when you’re at 20 and switch the location preemptively you will save yourself a lot of time.&lt;/p&gt;
&lt;p&gt;Physical place is not the only context that can be broken. For example, if you have trouble playing games on your phone everywhere, buying a new one and committing not to play any games on it from the very start can work very well (at least for some time).&lt;/p&gt;
&lt;h2 id="bullshit-test-for-the-previous-section"&gt;Bullshit test for the previous section&lt;/h2&gt;
&lt;p&gt;The previous section is exceptional in that you can test whether what I wrote there is bullshit rather easily (this is basically the same thing as in the beginning of this post):&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Think of a task you’re currently putting off, even though you shouldn’t.&lt;/li&gt;
&lt;li&gt;Open Google Maps and find a particular coffee shop/library/etc. you’ve never been to.&lt;/li&gt;
&lt;li&gt;Go to that place strongly committing to only doing the particular thing you decided to do there and not get distracted either physically or mentally on other things. This means as little chatting with people as possible; no checking email (unless it’s absolutely needed); no checking social media; not doing anything at all that is not directly related to the task at hand. Basically, maintaining the rule structure similar to the one I described in the beginning of the post.&lt;/li&gt;
&lt;li&gt;Notice how easy or difficult the task was to work on and how easy or difficult it was to not let yourself be distracted, compared to your usual environment.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;My prediction&lt;/strong&gt;: however off-putting and ughy the task is, there’s going to be close to none difficulty in concentrating on it and there will be no other issues that usually prevent you from accomplishing it.&lt;/p&gt;
&lt;h2 id="break-rules-sometimes"&gt;Break rules sometimes&lt;/h2&gt;
&lt;p&gt;Adhere to anything religiously enough and you start to forget why you decided on doing it in the first place. &lt;label for="sn-8"&gt;
&lt;/label&gt;

&lt;span&gt;
With rules turning into &lt;a href="https://en.m.wikipedia.org/wiki/Wikipedia:Chesterton%27s_fence"&gt;Chesterton’s fences&lt;/a&gt;. 
&lt;/span&gt;  Stoics suggest negative visualization and occasional intentional deprivation of things we take for granted, e.g. living off bread and milk for a few days; I suggest to occasionally forget all the rules you have for a while and see what happens. This will happen naturally at some rate, due to rules being gradually broken, but sometimes it might be worthwhile to explicitly let yourself not be bound by any rules designed to enhance productivity and see how it pans out. It seems that this kind of experience may serve as a sort of a springboard for the future.&lt;/p&gt;
&lt;p&gt;For example, a couple of times per year I clear out several days, during which I play Civilization 5 for 16-18 hours a day. At some point, I become so nauseated and frustrated by the game that I naturally just can’t play it anymore. The realization of just how easily I just sent like 50 hours of my life down the drain helps to gain the perspective on a lot of stuff, including why I avoid video games so scrupulously at all other times.&lt;/p&gt;
&lt;p&gt;Note that spending a day procrastinating / playing video games is equivalent to reading a book for an hour every day for two weeks.&lt;/p&gt;
&lt;h2 id="a-couple-more-tips"&gt;A couple more tips&lt;/h2&gt;
&lt;h3 id="how-to-not-forget-about-productivity-tricks"&gt;How to not forget about productivity tricks?&lt;/h3&gt;
&lt;p&gt;You can literally just add a reminder a week / a month in the future which asks if the new productivity trick is used and, if not, why. I use &lt;a href="http://www.amazingmarvin.com/"&gt;Amazing Marvin&lt;/a&gt; as my todo list and add the reminders there.&lt;/p&gt;

&lt;h3 id="podcasts-and-audiobooks"&gt;Podcasts and audiobooks&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://grognor.blogspot.com/2016/12/the-lifehack.html"&gt;If you think you can’t listen to podcasts and audiobooks, you’re probably wrong. Just speed them up and you’ll be able to concentrate on them just fine.&lt;/a&gt; You probably have at least 30-60 minutes of downtime every day available for audio content. That’s basically a free hour a day to read a book. The other possibility is that you’ve just tried to listen to a wrong book and gave up too early! I found that about half the books I can’t listen and need to actually read.&lt;/p&gt;
&lt;p&gt;The way to highlight books while listening to them is to catch an identifying phrase near the segment you want to return to, write it down to a special file, and after having finished the book, open the written version of the book and find all the highlights there, using the identifying phrases.&lt;/p&gt;
&lt;p&gt;See my audio content apps recommendations and headphones recommendations in my &lt;a href="https://guzey.com/tools-gear"&gt;Tools / Gear&lt;/a&gt; post.&lt;/p&gt;

&lt;h3 id="browser-tab-management"&gt;Browser tab management&lt;/h3&gt;
&lt;p&gt;Tabs have a tendency to blow up. However, there’s a natural upper limit for how much the can blow up, since at some point they overflow and you no longer have access to the rightmost tabs. This is so frustrating that we can naturally turn this to our advantage. So, create two soft rules: &lt;label for="sn-10"&gt;
&lt;/label&gt;

&lt;span&gt;
à la &lt;a href="https://en.m.wikipedia.org/wiki/FIFO_and_LIFO_accounting"&gt;FIFO&lt;/a&gt;. 
&lt;/span&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;only close tabs from the left-hand side&lt;/li&gt;
&lt;li&gt;only open tabs in the end (but can close just opened tabs).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;These rules are pretty easy to maintain (since you can still do anything you need while following them) but they’re really frustrating to abide by, which creates a really good incentive to clean tabs up. The equilibrium is to have about 50-80 tabs (depending on the size of your monitor), just about to overflow. Note that you might need a lot of RAM (like 16gb) for this to work.&lt;/p&gt;
&lt;h3 id="figuring-out-the-core-issues-behind-procrastination"&gt;Figuring out the core issues behind procrastination&lt;/h3&gt;
&lt;p&gt;I will quote &lt;a href="https://www.facebook.com/marco.vega.925"&gt;Marco Vega&lt;/a&gt; of &lt;a href="https://sapien.co/"&gt;Sapien&lt;/a&gt; here:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;99% of the time procrastination is not about you being lazy or lacking work-ethic. Your body/brain is sending your some important information about the tasks at hand, and it’s important that you listen to those signals empathetically.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;For example,&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;A - &lt;strong&gt;The task requirements and goals might not be clear enough&lt;/strong&gt;. If you are trying to get yourself to “plan for a project” or “write a book” then it’s hard to identify the next actionable items. Put some time aside to figure out what physical things you can do to move the project forward. Try break down the larger tasks into the smallest pieces possible. The goal of the project might need identifying, or the requirements fleshed out from a supervisor.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;B - &lt;strong&gt;The task might exceed your current competency&lt;/strong&gt;. Sometimes we know what we have to do, but don’t know how to do it, and then we become avoidant rather than admitting this. In this case, it’s worth figuring out what you do know how to do and what you don’t know how to do, and be honest with that. Then slowly ask for help or read up on the things you don’t know.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;C - &lt;strong&gt;The tasks might really not be worth it&lt;/strong&gt;. Sometimes you are assigned tasks that don’t actually help you achieve your long-term goals, and so your brain demotivate you from doing them. Maybe the payoff is low, maybe you don’t learn anything new from them, or maybe a colleague you don’t like will gain credit for the tasks, or maybe you just wont be rewarded or appreciated for getting the tasks done.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;As a general rule of thumb. If you notice yourself procrastinating, don’t beat yourself up about it. Just notice the behaviour and put some time aside to have an honest conversation with yourself for why you might be unconsciously avoiding these tasks. There is no shame here. It’s very difficult to move forward without self-empathy and self-understanding. ‘Pushing yourself’ is OK in small doses, but if you make it a habit, you are increasing your chances of burnout!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id="task-order"&gt;Task order&lt;/h3&gt;
&lt;p&gt;If you just have a bunch of things to do for the day, try using &lt;a href="https://random.org/"&gt;random.org&lt;/a&gt; to decide on the order of your tasks. This both&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;doesn’t allow you to just do the easiest tasks first&lt;/li&gt;
&lt;li&gt;makes the very act of choosing the next task pretty exciting&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="help-me-make-this-post-better"&gt;Help me make this post better!&lt;/h2&gt;
&lt;p&gt;If you’ve read to this point, I would guess you enjoyed the post. If you decide to try any of the tricks I describe — do let me know, so that I check back with you in 1, 3, and 12 months and see if this post is actually helpful in the long-term.&lt;/p&gt;
&lt;h2 id="acknowledgements"&gt;Acknowledgements&lt;/h2&gt;
&lt;p&gt;Thanks to &lt;a href="https://vk.com/ansty57"&gt;Anastasia Kuptsova&lt;/a&gt; for many helpful comments.&lt;/p&gt;
&lt;h2 id="also-see"&gt;Also see&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://blog.samaltman.com/productivity"&gt;Productivity&lt;/a&gt; by Sam Altman&lt;/p&gt;
&lt;h2 id="bibliography"&gt;Bibliography&lt;/h2&gt;
&lt;p&gt;Many people influenced my thinking on productivity. In particular, I should note:&lt;/p&gt;
&lt;p&gt;Scott Adams' &lt;a href="https://amzn.to/2B1qf4W"&gt;How to Fail at Almost Everything and Still Win Big&lt;/a&gt; (probably the most important book I’ve ever read)&lt;/p&gt;
&lt;p&gt;Scott Alexander’s &lt;a href="http://slatestarcodex.com/2013/06/30/the-lottery-of-fascinations/"&gt;The Lottery of Fascinations&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;David Allen’s &lt;a href="https://amzn.to/2KEJYHm"&gt;Getting Things Done&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Tiago Forte’s &lt;a href="http://www.ribbonfarm.com/2016/03/24/the-holy-grail-of-self-improvement/"&gt;The Holy Grail of Self-Improvement&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Malcolm Ocean’s &lt;a href="http://malcolmocean.com/2016/03/face-personality-upgrade-ritual/"&gt;A ritual to upgrade my Face&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Roko’s &lt;a href="https://wiki.lesswrong.com/wiki/Ugh_field"&gt;Ugh fields&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Adam Strandberg’s &lt;a href="http://the-lagrangian.blogspot.com/2015/10/time-depletion.html"&gt;Time Depletion&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Between ages fourteen and sixteen I read a lot of &lt;a href="https://scotthyoung.com/"&gt;Scott H Young&lt;/a&gt; and &lt;a href="http://tynan.com/"&gt;Tynan&lt;/a&gt; and some &lt;a href="https://www.stevepavlina.com/"&gt;Steve Pavlina&lt;/a&gt;, so although I don’t remember almost anything they wrote, I’m pretty sure there are some traces of their ideas in me.&lt;/p&gt;
&lt;h3 id="stuff-with-similar-thoughts-i-discovered-while-writing-this-post"&gt;Stuff with similar thoughts I discovered while writing this post&lt;/h3&gt;
&lt;p&gt;Peter Hurford’s &lt;a href="https://www.lesswrong.com/posts/JTHe5oGvdj6T73o4o/how-i-am-productive"&gt;How I Am Productive&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Scott Alexander’s &lt;a href="https://www.lesswrong.com/posts/NjzBrtvDS4jXi5Krp/applied-picoeconomics"&gt;Applied Picoeconomics&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Eliezer Yudkowsky’s &lt;a href="https://www.lesswrong.com/posts/FHukyfMagq4HrBYNt/willpower-hax-487-execute-by-default"&gt;Execute by Default&lt;/a&gt;&lt;/p&gt;

    &lt;/article&gt;&lt;/div&gt;&lt;a href="https://guzey.com/productivity/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:31:28 UT
      </pubDate>
      <guid>
        https://guzey.com/productivity/
      </guid>
    </item>
    <item>
      <title>
        Deep Learning Illustrated: Building Natural Language Processing Models &amp;#8211; Data Science Blog by Domino
      </title>
      <link>
        https://blog.dominodatalab.com/deep-learning-illustrated-building-natural-language-processing-models/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt; 
     &lt;p&gt;&lt;em&gt;&lt;small&gt;Many thanks to Addison-Wesley Professional for providing the permissions to excerpt “Natural Language Processing” from the book, &lt;a href="http://www.informit.com/store/deep-learning-illustrated-a-visual-interactive-guide-9780135116692?utm_source=Referral&amp;amp;utm_medium=DominoLabs&amp;amp;utm_campaign=Krohn&amp;amp;utm_term=DLBook"&gt;Deep Learning Illustrated&lt;/a&gt; by &lt;a href="https://www.linkedin.com/in/jonkrohn/"&gt;Krohn&lt;/a&gt;, &lt;a href="https://www.linkedin.com/in/grantbey/"&gt;Beyleveld&lt;/a&gt;, and &lt;a href="https://twitter.com/aglaebassens"&gt;Bassens&lt;/a&gt;. The excerpt covers how to create word vectors and utilize them as an input into a deep learning model. A complementary &lt;a href="https://try.dominodatalab.com/u/domino-andrealowe/Natural-Language-Processing/overview"&gt;Domino project is available&lt;/a&gt;.&lt;small&gt;&lt;/small&gt;&lt;/small&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;While the field of computational linguistics, or Natural Language Processing (NLP), has been around for decades, the increased interest in and use of deep learning models has &lt;a href="https://arxiv.org/pdf/1807.10854.pdf"&gt;also propelled applications of NLP forward&lt;/a&gt; within industry. Data scientists and researchers require an extensive array of techniques, packages, and tools to accelerate core work flow tasks including prepping, processing, and analyzing data. Utilizing NLP helps researchers and data scientists complete core tasks faster. As &lt;a href="https://www.dominodatalab.com/?utm_source=blog&amp;amp;utm_campaign=referral&amp;amp;utm_medium=logo&amp;amp;utm_content="&gt;Domino&lt;/a&gt; is committed to accelerating data science work flows, we reached out to Addison-Wesley Professional (AWP) for permissions to excerpt the extensive “Natural Language Processing” chapter from the book, &lt;em&gt;&lt;a href="http://www.informit.com/store/deep-learning-illustrated-a-visual-interactive-guide-9780135116692?utm_source=Referral&amp;amp;utm_medium=DominoLabs&amp;amp;utm_campaign=Krohn&amp;amp;utm_term=DLBook"&gt;Deep Learning Illustrated&lt;/a&gt;.&lt;/em&gt; We appreciate &lt;a href="http://www.informit.com/imprint/series_detail.aspx?ser=4255387"&gt;AWP Pearson&lt;/a&gt; for providing the permissions to excerpt the work and enabling us to provide a complementary &lt;a href="https://try.dominodatalab.com/u/domino-andrealowe/Natural-Language-Processing/overview"&gt;Domino project&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img sizes="(max-width: 947px) 100vw, 947px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/NLP-Workspace.png 979w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/NLP-Workspace-300x139.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/NLP-Workspace-768x357.png 768w" height="440" width="947" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/NLP-Workspace.png" loading="lazy"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img sizes="(max-width: 950px) 100vw, 950px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/NLP-files.png 1084w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/NLP-files-300x92.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/NLP-files-768x237.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/NLP-files-1024x316.png 1024w" height="293" width="950" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/NLP-files.png" loading="lazy"&gt;&lt;/p&gt;
&lt;h2&gt;Chapter Introduction: Natural Language Processing&lt;/h2&gt;
&lt;p&gt;In Chapter 2 [&lt;a href="http://www.informit.com/store/deep-learning-illustrated-a-visual-interactive-guide-9780135116692?utm_source=Referral&amp;amp;utm_medium=DominoLabs&amp;amp;utm_campaign=Krohn&amp;amp;utm_term=DLBook"&gt;in the book&lt;/a&gt;], we introduced computational representations of language, particularly highlighting word vectors as a potent approach for quantitatively capturing word meaning. In the present chapter [excerpt], we cover code that will enable you to create your own word vectors as well as to provide them as an input into a deep learning model.&lt;/p&gt;
&lt;p&gt;The natural language processing models you build in this chapter will incorporate neural network layers we’ve applied already: dense layers from Chapters 5 through 9 [&lt;a href="http://www.informit.com/store/deep-learning-illustrated-a-visual-interactive-guide-9780135116692?utm_source=Referral&amp;amp;utm_medium=DominoLabs&amp;amp;utm_campaign=Krohn&amp;amp;utm_term=DLBook"&gt;in the book&lt;/a&gt;], and convolutional layers from Chapter 10 [&lt;a href="http://www.informit.com/store/deep-learning-illustrated-a-visual-interactive-guide-9780135116692?utm_source=Referral&amp;amp;utm_medium=DominoLabs&amp;amp;utm_campaign=Krohn&amp;amp;utm_term=DLBook"&gt;in the book&lt;/a&gt;]. Our NLP models will also incorporate new layer types—ones from the family of recurrent neural networks. RNNs natively handle information that occurs in sequences such as natural language, but they can, in fact, handle any sequential data—such as financial time series or temperatures at a given geographic location—so they’re quite versatile. The chapter concludes with a section on deep learning networks that process data via multiple parallel streams—a concept that dramatically widens the scope for creativity when you design your model architectures and, as you’ll see, can also improve model accuracy.&lt;/p&gt;
&lt;h2&gt;Preprocessing Natural Language Data&lt;/h2&gt;
&lt;p&gt;There are steps you can take to preprocess natural language data such that the modeling you carry out downstream may be more accurate. Common natural language preprocessing options include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Tokenization:&lt;/em&gt; This is the splitting of a document (e.g., a book) into a list of discrete elements of language (e.g., words), which we call &lt;em&gt;tokens&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Converting all characters to &lt;em&gt;lowercase&lt;/em&gt;. A capitalized word at the beginning of a sentence (e.g., &lt;em&gt;She&lt;/em&gt;) has the same meaning as when it’s used later in a sentence (&lt;em&gt;She&lt;/em&gt;). By converting all characters in a corpus to lowercase, we disregard any use of capitalization.&lt;/li&gt;
&lt;li&gt;Removing &lt;em&gt;stop words:&lt;/em&gt; These are frequently occurring words that tend to contain relatively little distinctive meaning, such as &lt;em&gt;the&lt;/em&gt;, &lt;em&gt;at,&lt;/em&gt; &lt;em&gt;which&lt;/em&gt;, and &lt;em&gt;of&lt;/em&gt;. There is no universal consensus on the precise list of stop words, but depending on your application it may be sensible to ensure that certain words are (or aren’t!) considered to be stop words. For example, in this chapter, we’ll build a model to classify movie reviews as positive or negative. Some lists of stop words include negations like &lt;em&gt;didn’t&lt;/em&gt;, &lt;em&gt;isn’t&lt;/em&gt;, and &lt;em&gt;wouldn’t&lt;/em&gt; that might be critical for our model to identify the sentiment of a movie review, so these words probably shouldn’t be removed.&lt;/li&gt;
&lt;li&gt;Removing &lt;em&gt;punctuation&lt;/em&gt;: Punctuation marks generally don’t add much value to a natural language model and so are often removed.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Stemming:&lt;/em&gt; Stemming is the truncation of words down to their stem. For example, the words house and housing both have the stem hous. With smaller datasets in particular, stemming can be productive because it pools words with similar meanings into a single token. There will be more examples of this stemmed token’s con- text, enabling techniques like word2vec or GloVe to more accurately identify an appropriate location for the token in word-vector space (see Figures 2.5 and 2.6) [&lt;a href="http://www.informit.com/store/deep-learning-illustrated-a-visual-interactive-guide-9780135116692?utm_source=Referral&amp;amp;utm_medium=DominoLabs&amp;amp;utm_campaign=Krohn&amp;amp;utm_term=DLBook"&gt;in the book]&lt;/a&gt;. [Note: Lemmatization, a more sophisticated alternative to stemming, requires the use of a reference vocabulary. For our purposes in this book, stemming is a sufficient approach for considering multiple related words as a single token.]&lt;/li&gt;
&lt;li&gt;Handling &lt;em&gt;n-grams&lt;/em&gt;: Some words commonly co-occur in such a way that the combination of words is better suited to being considered a single concept than several separate concepts. As examples, &lt;em&gt;New York&lt;/em&gt; is a &lt;em&gt;bigram&lt;/em&gt; (an&lt;em&gt; n&lt;/em&gt;-gram of length two), and &lt;em&gt;New York City&lt;/em&gt; is a &lt;em&gt;trigram&lt;/em&gt; (an &lt;em&gt;n&lt;/em&gt;-gram of length three). When chained together, the words &lt;em&gt;new,&lt;/em&gt; &lt;em&gt;york&lt;/em&gt;, and&lt;em&gt; city&lt;/em&gt; have a specific meaning that might be better captured by a single token (and therefore a single location in word-vector space) than three separate ones.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Depending on the particular task that we’ve designed our model for, as well as the dataset that we’re feeding into it, we may use all, some, or none of these data preprocessing steps. As you consider applying any preprocessing step to your particular problem, you can use your intuition to weigh whether it might ultimately be valuable to your downstream task. We’ve already mentioned some examples of this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Stemming may be helpful for a small corpus but unhelpful for a large one.&lt;/li&gt;
&lt;li&gt;Likewise, converting all characters to lowercase is likely to be helpful when you’re working with a small corpus, but, in a larger corpus that has many more examples of individual uses of words, the distinction of, &lt;em&gt;say&lt;/em&gt;, &lt;em&gt;general&lt;/em&gt; (an adjective meaning “widespread”) versus &lt;em&gt;General&lt;/em&gt; (a noun meaning the commander of an army) may be valuable.&lt;/li&gt;
&lt;li&gt;Removing punctuation would not be an advantage in all cases. Consider, for example, if you were building a question-answering algorithm, which could use question marks to help it identify questions.&lt;/li&gt;
&lt;li&gt;Negations may be helpful as stop words for some classifiers but probably not for a sentiment classifier, for example. Which words you include in your list of stop words could be crucial to your particular application, so be careful with this one. In many instances, it will be best to remove only a limited number of stop words.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you’re unsure whether a given preprocessing step may be helpful or not, you can investigate the situation empirically by incorporating the step and observing whether it impacts the accuracy of your deep learning model downstream. As a general rule, the larger a corpus becomes, the fewer preprocessing steps that will be helpful. With a small corpus, you’re likely to be concerned about encountering words that are rare or that are outside the vocabulary of your training dataset. By pooling several rare words into a single common token, you’ll be more likely to train a model effectively on the meaning of the group of related words. As the corpus becomes larger, however, rare words and out-of-vocabulary words become less and less of an issue. With a very large corpus, then, it is likely to be helpful to &lt;em&gt;avoid&lt;/em&gt; pooling several words into a single common token. That’s because there will be enough instances of even the less-frequently-occurring words to effectively model their unique meaning as well as to model the relatively subtle nuances between related words (that might otherwise have been pooled together).&lt;/p&gt;
&lt;p&gt;To provide practical examples of these preprocessing steps in action, we invite you to check out our &lt;em&gt;Natural Language Preprocessing&lt;/em&gt; Jupyter notebook [or the &lt;a href="https://try.dominodatalab.com/u/domino-andrealowe/Natural-Language-Processing/overview"&gt;complementary Domino project&lt;/a&gt;].&lt;/p&gt;
&lt;p&gt;It begins by loading a number of dependencies:&lt;/p&gt;
&lt;pre title=""&gt;import nltk
from nltk import word_tokenize, sent_tokenize 
from nltk.corpus import stopwords
from nltk.stem.porter import * 
nltk.download('gutenberg') 
nltk.download('punkt') 
nltk.download('stopwords')

import string

import gensim
from gensim.models.phrases import Phraser, Phrases 
from gensim.models.word2vec import Word2Vec

from sklearn.manifold import TSNE

import pandas as pd
from bokeh.io import output_notebook, output_file 
from bokeh.plotting import show, figure 
%matplotlib inline

&lt;/pre&gt;
&lt;p&gt;Most of these dependencies are from &lt;code&gt;nltk&lt;/code&gt; (the Natural Language Toolkit) and gensim (another natural language library for Python). We explain our use of each individual dependency when we apply it in the example code that follows.&lt;/p&gt;
&lt;h2&gt;Tokenization&lt;/h2&gt;
&lt;p&gt;The dataset we used in this notebook is a small corpus of out-of-copyright books from Project Gutenberg. [Note: Named after the printing-press inventor Johannes Gutenberg, Project Gutenberg is a source of tens of thousands of electronic books. These books are classic works of literature from across the globe whose copyright has now expired, making them freely available. See &lt;a href="https://www.gutenberg.org/"&gt;gutenberg.org&lt;/a&gt;.]&lt;/p&gt;
&lt;p&gt;This corpus is available within nltk so it can be easily loaded using this code:&lt;/p&gt;
&lt;pre title=""&gt;from nltk.corpus import gutenberg

&lt;/pre&gt;
&lt;p&gt;This wee corpus consists of a mere 18 literary works, including Jane Austen’s Emma, Lewis Carroll’s Alice in Wonderland, and three plays by a little-known fellow named William Shakespeare. (Execute &lt;code&gt;gutenberg.fileids()&lt;/code&gt; to print the names of all 18 documents.) By running &lt;code&gt;len(gutenberg.words())&lt;/code&gt;, you can see that the corpus comes out to 2.6 million words—a manageable quantity that means you’ll be able to run all of the code examples in this section on a laptop.&lt;/p&gt;
&lt;p&gt;To tokenize the corpus into a list of sentences, one option is to use nltk’s &lt;code&gt;sent_tokenize()&lt;/code&gt; method:&lt;/p&gt;
&lt;pre title=""&gt;gberg_sent_tokens = sent_tokenize(gutenberg.raw()

&lt;/pre&gt;
&lt;p&gt;Accessing the first element of the resulting list by running &lt;code&gt;gberg_sent_tokens[0]&lt;/code&gt;, you can see that the first book in the Project Gutenberg corpus is Emma, because this first element contains the book’s title page, chapter markers, and first sentence, all (erroneously) blended together with newline characters (\n):&lt;/p&gt;
&lt;pre&gt;'[Emma by Jane Austen 1816]\n\nVOLUME I\n\nCHAPTER I\n\n\nEmma Wood-
house, handsome, clever, and rich, with a comfortable home\nand happy
disposition, seemed to unite some of the best blessings\nof existence;
and had lived nearly twenty-one years in the world\nwith very little to
distress or vex her.'&lt;/pre&gt;
&lt;p&gt;A stand-alone sentence is found in the second element, which you can view by executing &lt;code&gt;gberg_sent_tokens[1]&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;"She was the youngest of the two daughters of a most affectionate,
\nindulgent father; and had, in consequence of her sister's marriage,\nbeen 
mistress of his house from a very early period."&lt;/pre&gt;
&lt;p&gt;You can further tokenize this sentence down to the word level using nltk’s &lt;code&gt;word_tokenize()&lt;/code&gt; method&lt;/p&gt;
&lt;pre title=""&gt;word_tokenize(gberg_sent_tokens[1])

&lt;/pre&gt;
&lt;p&gt;This prints a list of words with all whitespace, including newline characters, stripped out (see Figure 11.1). The word &lt;em&gt;father&lt;/em&gt;, for example, is the 15th word in the second sentence, as you can see by running this line of code:&lt;/p&gt;
&lt;pre title=""&gt;word_tokenize(gberg_sent_tokens[1])[14]

&lt;/pre&gt;
&lt;p&gt;Although the &lt;code&gt;sent_tokenize()&lt;/code&gt; and &lt;code&gt;word_tokenize()&lt;/code&gt; methods may come in handy for working with your own natural language data, with this Project Gutenberg corpus, you can instead conveniently employ its built-in &lt;code&gt;sents()&lt;/code&gt; method to achieve the same aims in a single step:&lt;/p&gt;
&lt;pre title=""&gt;gberg_sents = gutenberg.sents()

&lt;/pre&gt;
&lt;p&gt;This command produces &lt;code&gt;gberg_sents&lt;/code&gt;, a tokenized list of lists. The higher-level list consists of individual sentences, and each sentence contains a lower-level list of words within it. Appropriately, the &lt;code&gt;sents()&lt;/code&gt; method also separates the title page and chapter markers into their own individual elements, as you can observe with a call to &lt;code&gt;gberg_sents[0:2]:&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;     [['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']'],
     ['VOLUME', 'I'],
     ['CHAPTER', 'I']]

&lt;/pre&gt;
&lt;p&gt;Because of this, the first actual sentence of &lt;em&gt;Emma&lt;/em&gt; is now on its own as the fourth element of &lt;code&gt;gberg_sents&lt;/code&gt;, and so to access the 15th word (father) in the second actual sentence, we now use &lt;code&gt;gberg_sents[4][14]&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;Converting All Characters to Lowercase&lt;/h2&gt;
&lt;p&gt;For the remaining natural language preprocessing steps, we begin by applying them iteratively to a single sentence. As we wrap up the section later on, we’ll apply the steps across the entire 18-document corpus.&lt;/p&gt;
&lt;p&gt;Looking back at Figure 11.1, we see that this sentence begins with the capitalized word &lt;em&gt;She&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img sizes="(max-width: 790px) 100vw, 790px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_1.png 1160w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_1-300x272.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_1-768x696.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_1-1024x929.png 1024w" height="716" width="790" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_1.png" loading="lazy"&gt;&lt;/p&gt;
&lt;p&gt;If we’d like to disregard capitalization so that this word is considered to be identical to &lt;em&gt;she&lt;/em&gt;, then we can use the Python &lt;code&gt;lower()&lt;/code&gt; method from the &lt;code&gt;string&lt;/code&gt; library, as shown in Example 11.1.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example 11.1 Converting a sentence to lowercase&lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;[w.lower() for w in gberg_sents[4]]
&lt;/pre&gt;
&lt;p&gt;This line returns the same list as in Figure 11.1 with the exception that the first element in the list is now she instead of &lt;code&gt;She&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;Removing Stop Words and Punctuation&lt;/h2&gt;
&lt;p&gt;Another potential inconvenience with the sentence in Figure 11.1 is that it’s littered with both stop words and punctuation. To handle these, let’s use the &lt;code&gt;+&lt;/code&gt; operator to concatenate together nltk’s list of English stop words with the &lt;code&gt;string&lt;/code&gt; library’s list of punctuation marks:&lt;/p&gt;
&lt;pre title=""&gt;stpwrds = stopwords.words('english') + list(string.punctuation)

&lt;/pre&gt;
&lt;p&gt;If you examine the &lt;code&gt;stpwrds&lt;/code&gt; list that you’ve created, you’ll see that it contains many common words that often don’t contain much particular meaning, such as &lt;em&gt;a&lt;/em&gt;, &lt;em&gt;an&lt;/em&gt;, and &lt;em&gt;the&lt;/em&gt;. [Note These three particular words are called &lt;em&gt;articles&lt;/em&gt;, or &lt;em&gt;determiners&lt;/em&gt;. However, it also contains words like not and other negative words that could be critical if we were building a sentiment classifier, such as in the sentence, “This film was not good.”]&lt;/p&gt;
&lt;p&gt;In any event, to remove all of the elements of stpwrds from a sentence we could use a &lt;a href="http://bit.ly/listComp"&gt;list comprehension &lt;/a&gt;as we do in Example 11.2, which incorporates the lowercasing we used in Example 11.1.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example 11.2 Removing stop words and punctuation with a list comprehension&lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;[w.lower() for w in gberg_sents[4] if w.lower() not in stpwrds]

&lt;/pre&gt;
&lt;p&gt;Relative to Figure 11.1, running this line of code returns a much shorter list that now contains only words that each tend to convey a fair bit of meaning:&lt;/p&gt;
&lt;pre&gt;               ['youngest',
               'two',
               'daughters',
               'affectionate',
               'indulgent',
               'father',
               'consequence',
               'sister',
               'marriage',
               'mistress',
               'house',
               'early',
               'period']
&lt;/pre&gt;
&lt;h2&gt;Stemming&lt;/h2&gt;
&lt;p&gt;To stem words, you can use the Porter algorithm [Note: Porter, M. F. (1980). An algorithm for suffix stripping. Program, 14, 130–7.] provided by nltk. To do this, you create an instance of a &lt;code&gt;PorterStemmer()&lt;/code&gt; object and then add its &lt;code&gt;stem() method&lt;/code&gt; to the list comprehension you began in Example 11.2, as shown in Example 11.3.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example 11.3 Adding word stemming to our list comprehension&lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;[stemmer.stem(w.lower()) for w in gberg_sents[4]
if w.lower() not in stpwrds]

&lt;/pre&gt;
&lt;p&gt;This outputs the following:&lt;/p&gt;
&lt;pre&gt;     ['youngest',
      'two',
      'daughter',
      'affection',
      'indulg',
      'father',
      'consequ',
      'sister',
      'marriag',
      'mistress',
      'hous',
      'earli',
      'period']
&lt;/pre&gt;
&lt;p&gt;This is similar to our previous output of the sentence except that many of the words have been stemmed:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;em&gt;daughters&lt;/em&gt; to &lt;em&gt;daughter&lt;/em&gt; (allowing the plural and singular terms to be treated identically)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;house&lt;/em&gt; to &lt;em&gt;hous&lt;/em&gt; (allowing related words like &lt;em&gt;house&lt;/em&gt; and &lt;em&gt;housing&lt;/em&gt; to be treated as the same)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;early&lt;/em&gt; to &lt;em&gt;earli&lt;/em&gt; (allowing differing tenses such as &lt;em&gt;early&lt;/em&gt;, &lt;em&gt;earlier&lt;/em&gt;, and &lt;em&gt;earliest&lt;/em&gt; to be treated as the same)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;These stemming examples may be advantageous with a corpus as small as ours, because there are relatively few examples of any given word. By pooling similar words together, we obtain more occurrences of the pooled version, and so it may be assigned to a more accurate location in vector space (Figure 2.6). With a very large corpus, however, where you have many more examples of rarer words, there might be an advantage to treating plural and singular variations on a word differently, treating related words as unique, and retaining multiple tenses; the nuances could prove to convey valuable meaning.&lt;/p&gt;
&lt;h2&gt;Handling &lt;em&gt;n&lt;/em&gt;-grams&lt;/h2&gt;
&lt;p&gt;To treat a bigram like &lt;em&gt;New York&lt;/em&gt; as a single token instead of two, we can use the &lt;code&gt;Phrases()&lt;/code&gt; and &lt;code&gt;Phraser()&lt;/code&gt; methods from the gensim library. As demonstrated in Example 11.4, we use them in this way:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;Phrases()&lt;/code&gt; to train a “detector” to identify how often any given pair of words occurs together in our corpus (the technical term for this is &lt;em&gt;bigram collocation&lt;/em&gt;) relative to how often each word in the pair occurs by itself&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Phraser()&lt;/code&gt;&lt;span&gt; to take the bigram collocations detected by the &lt;code&gt;Phrases()&lt;/code&gt; object and then use this information to create an object that can efficiently be passed over our corpus, converting all bigram collocations from two consecutive tokens into a single token&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Example 11.4 Detecting collocated bigrams&lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;phrases = Phrases(gberg_sents)
bigram = Phraser(phrases)

&lt;/pre&gt;
&lt;p&gt;By running &lt;code&gt;bigram.phrasegrams&lt;/code&gt;, we output a dictionary of the count and &lt;em&gt;score&lt;/em&gt; of each bigram. The topmost lines of this dictionary are provided in Figure 11.2.&lt;/p&gt;
&lt;p&gt;Each bigram in Figure 11.2 has a count and a score associated with it. The bigram &lt;em&gt;two daughters&lt;/em&gt;, for example, occurs a mere 19 times across our Gutenberg corpus. This bigram has a fairly low score (12.0), meaning the terms &lt;em&gt;two&lt;/em&gt; and &lt;em&gt;daughters&lt;/em&gt; do not occur together very frequently relative to how often they occur apart. In contrast, the bigram Miss Taylor occurs more often (48 times), and the terms &lt;em&gt;Miss&lt;/em&gt; and &lt;em&gt;Taylor&lt;/em&gt; occur much more frequently together relative to how often they occur on their own (score of 453.8).&lt;/p&gt;
&lt;p&gt;&lt;img sizes="(max-width: 635px) 100vw, 635px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_2.png 1002w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_2-300x189.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_2-768x484.png 768w" height="401" width="635" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_2.png" loading="lazy"&gt;Scanning over the bigrams in Figure 11.2, notice that they are marred by capitalized words and punctuation marks. We’ll resolve those issues in the next section, but in the meantime let’s explore how the &lt;code&gt;bigram&lt;/code&gt; object we’ve created can be used to convert bigrams from two consecutive tokens into one. Let’s tokenize a short sentence by using the &lt;code&gt;split()&lt;/code&gt; method on a string of characters wherever there’s a space, as follows:&lt;/p&gt;
&lt;pre title=""&gt;tokenized_sentence = "Jon lives in New York City".split()

&lt;/pre&gt;
&lt;p&gt;If we print &lt;code&gt;tokenized_sentence&lt;/code&gt;, we output a list of unigrams only: &lt;code&gt;['Jon', 'lives', 'in', 'New', 'York', 'City']&lt;/code&gt;. If, however, we pass the list through our gensim bigram object by using &lt;code&gt;bigram[tokenized_sentence]&lt;/code&gt;, the list then contains the bigram &lt;em&gt;New York&lt;/em&gt;: &lt;code&gt;['Jon', 'lives', 'in', 'New_York', 'City']&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;After you’ve identified bigrams across your corpus by running it through the bigram object, 
you can detect trigrams (such as &lt;em&gt;New York Cit&lt;/em&gt;y) by passing this new, bigram-filled corpus 
through the &lt;code&gt;Phrases()&lt;/code&gt; and &lt;code&gt;Phraser()&lt;/code&gt; methods. This could be repeated again to identify 4-grams (and then again to identify 5-grams, and so on); however, there are diminishing returns from this. Bigrams (or at most trigrams) should suffice for the majority of applications. By the way, if you go ahead and detect trigrams with the Project Gutenberg corpus, &lt;em&gt;New York City&lt;/em&gt; is unlikely to be detected. Our corpus of classic literature doesn’t mention it often enough.&lt;/pre&gt;
&lt;h2&gt;Preprocessing the Full Corpus&lt;/h2&gt;
&lt;p&gt;Having run through some examples of preprocessing steps on individual sentences, we now compose some code to preprocess the entire Project Gutenberg corpus. This will also enable us to collocate bigrams on a cleaned-up corpus that no longer contains capital letters or punctuation.&lt;/p&gt;
&lt;p&gt;Later on in this chapter, we’ll use a corpus of film reviews that was curated by Andrew Maas and his colleagues at Stanford University to predict the sentiment of the reviews with NLP models. [Note: Maas, A., et al. (2011). Learning word vectors for sentiment analysis. Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, 142–50.] During their data preprocessing steps, Maas and his coworkers decided to leave in stop words because they are “indicative of sentiment.” [Note: This is in line with our thinking, as we mentioned earlier in the chapter.] They also decided not to stem words because they felt their corpus was sufficiently large that their word-vector-based NLP model “learns similar representations of words of the same stem when the data suggest it.” Said another way, words that have a similar meaning should find their way to a similar location in word-vector space (Figure 2.6) [&lt;a href="http://www.informit.com/store/deep-learning-illustrated-a-visual-interactive-guide-9780135116692?utm_source=Referral&amp;amp;utm_medium=DominoLabs&amp;amp;utm_campaign=Krohn&amp;amp;utm_term=DLBook"&gt;in the book&lt;/a&gt;] during model training.&lt;/p&gt;
&lt;p&gt;Following their lead, we’ll also forgo stop-word removal and stemming when preprocessing the Project Gutenberg corpus, as in Example 11.5.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example 11.5 Removing capitalization and punctuation from Project Gutenberg corpus&lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;lower_sents = []
for s in gberg_sents:
    lower_sents.append([w.lower() for w in s if w.lower() 
                        not in list(string.punctuation)])

&lt;/pre&gt;
&lt;p&gt;In this example, we begin with an empty list we call &lt;code&gt;lower_sents&lt;/code&gt;, and then we append preprocessed sentences to it using a for loop. [Note: If you’re preprocessing a large corpus, we’d recommend using optimizable and parallelizable functional program- ming techniques in place of our simple (and therefore simple-to-follow) for loop.] For preprocessing each sentence within the loop, we used a variation on the list comprehension from Example 11.2, in this case removing only punctuation marks while converting all characters to lowercase.&lt;/p&gt;
&lt;p&gt;With punctuation and capitals removed, we can set about detecting collocated bigrams across the corpus afresh:&lt;/p&gt;
&lt;pre title=""&gt;lower_bigram = Phraser(Phrases(lower_sents))

&lt;/pre&gt;
&lt;p&gt;Relative to Example 11.4, this time we created our gensim lower_bigram object in a single line by chaining the &lt;code&gt;Phrases()&lt;/code&gt; and &lt;code&gt;Phraser()&lt;/code&gt; methods together. The top of the output of a call to &lt;code&gt;lower_bigram.phrasegrams&lt;/code&gt; is provided in Figure 11.3: Comparing these bigrams with those from Figure 11.2, we do indeed observe that they are all in lowercase (e.g., &lt;em&gt;miss taylor&lt;/em&gt;) and bigrams that included punctuation marks are nowhere to be seen.&lt;/p&gt;
&lt;p&gt;&lt;img sizes="(max-width: 653px) 100vw, 653px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_3.png 1028w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_3-300x193.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_3-768x493.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_3-1024x657.png 1024w" height="420" width="653" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_3.png" loading="lazy"&gt;&lt;/p&gt;
&lt;p&gt;Examining the results in Figure 11.3 further, however, it appears that the default minimum thresholds for both count and score are far too liberal. That is, word pairs like &lt;em&gt;two daughters&lt;/em&gt; and &lt;em&gt;her sister&lt;/em&gt; should not be considered bigrams. To attain bigrams that we thought were more sensible, we experimented with more conservative count and score thresholds by increasing them by powers of 2. Following this approach, we were generally satisfied by setting the optional &lt;code&gt;Phrases()&lt;/code&gt; arguments to a &lt;em&gt;min(imum) count&lt;/em&gt; of 32 and to a score &lt;em&gt;threshold&lt;/em&gt; of 64, as shown in Example 11.6.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example 11.6 Detecting collocated bigrams with more conservative thresholds&lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;lower_bigram = Phraser(Phrases(lower_sents,
                               min_count=32, threshold=64))

&lt;/pre&gt;
&lt;p&gt;Although it’s not perfect, [Note: These are statistical approximations, of course!] because there are still a few questionable bigrams like &lt;em&gt;great deal&lt;/em&gt; and &lt;em&gt;few minutes&lt;/em&gt;, the output from a call to &lt;code&gt;lower_bigram.phrasegrams&lt;/code&gt; is now largely defensible, as shown in Figure 11.4.&lt;/p&gt;
&lt;p&gt;&lt;img sizes="(max-width: 738px) 100vw, 738px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_4.png 1062w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_4-300x166.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_4-768x425.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_4-1024x567.png 1024w" height="408" width="738" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_4.png" loading="lazy"&gt;&lt;/p&gt;

&lt;p&gt;Armed with our well-appointed &lt;code&gt;lower_bigram&lt;/code&gt; object from Example 11.6, we can at last use a for loop to iteratively append for ourselves a corpus of cleaned-up sentences, as in Example 11.7.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example 11.7 Creating a “clean” corpus that includes bigrams&lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;clean_sents = []
for s in lower_sents:
    clean_sents.append(lower_bigram[s])

&lt;/pre&gt;
&lt;p&gt;&lt;img sizes="(max-width: 808px) 100vw, 808px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_5.png 1074w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_5-300x212.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_5-768x542.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_5-1024x723.png 1024w" height="570" width="808" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_5.png" loading="lazy"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img sizes="(max-width: 710px) 100vw, 710px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_6.png 1070w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_6-300x133.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_6-768x342.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_6-1024x456.png 1024w" height="316" width="710" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_6.png" loading="lazy"&gt;&lt;/p&gt;
&lt;h2&gt;Creating Word Embeddings with word2vec&lt;/h2&gt;
&lt;p&gt;With the cleaned corpus of natural language clean_sents now available to us, we are well positioned to embed words from the corpus into word-vector space (Figure 2.6). As you’ll see in this section, such word embeddings can be produced with a single line of code. This single line of code, however, should not be executed blindly, and it has quite a few optional arguments to consider carefully. Given this, we’ll cover the essential theory behind word vectors before delving into example code.&lt;/p&gt;
&lt;h2&gt;The Essential Theory Behind word2vec&lt;/h2&gt;
&lt;p&gt;In Chapter 2, we provided an intuitive understanding of what word vectors are. We also discussed the underlying idea that because you can “know a word by the company it keeps” then a given word’s meaning can be well represented as the average of the words that tend to occur around it. word2vec is an unsupervised learning technique—that is, it is applied to a corpus of natural language without making use of any labels that may or may not happen to exist for the corpus. This means that any dataset of natural language could be appropriate as an input to word2vec. [Note: Mikolov, T., et al. (2013). Efficient estimation of word representations in vector space. arXiv:1301.3781]&lt;/p&gt;
&lt;p&gt;When running word2vec, you can choose between two underlying model architectures—&lt;em&gt;skip-gram &lt;/em&gt;(SG) or continuous bag of words (CBOW; pronounced see-bo)— either of which will typically produce roughly comparable results despite maximizing probabilities from “opposite” perspectives. To make sense of this, reconsider our toy-sized corpus from Figure 2.5:&lt;/p&gt;
&lt;pre&gt;        you shall know a word by the company it keeps&lt;/pre&gt;
&lt;p&gt;In it, we are considering word to be the &lt;em&gt;target&lt;/em&gt; word, and the three words to the right of it as well as the three words to the left of it are considered to be context words. (This corresponds to a window size of three words—one of the primary hyperparameters we must take into account when applying word2vec.) With the SG architecture, context words are predicted given the target word. [Note: In more technical machine learning terms, the cost function of the skip-gram architecture is to maximize the log probability of any possible context word from a corpus given the current target word.] With CBOW, it is the inverse: The target word is predicted based on the context words. [Note: Again, in technical ML jargon, the cost function for CBOW is maximizing the log probability of any possible target word from a corpus given the current context words. ]&lt;/p&gt;
&lt;p&gt;To understand word2vec more concretely, let’s focus on the CBOW architecture in greater detail (although we equally could have focused on SG instead). With CBOW, the target word is predicted to be the average of all the context words considered &lt;em&gt;jointly&lt;/em&gt;. “Jointly” means “all at once”: The particular position of context words isn’t taken into consideration, nor whether the context word occurs before or after the target word. That the CBOW architecture has this attribute is right there in the “bag of words” part of its name:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We take all the context words within the windows to the right and the left of the target word.&lt;/li&gt;
&lt;li&gt;We (figuratively!) throw all of these context words into a bag. If it helps you remember that the sequence of words is irrelevant, you can even imagine shaking up the bag.&lt;/li&gt;
&lt;li&gt;We calculate the average of all the context words contained in the bag, using this average to estimate what the target word could be.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;If we were concerned about syntax—the grammar of language (see Figure 2.9 for 
a refresher on the elements of natural language)—then word order would matter. 
But because with word2vec we’re concerned only with semantics—the &lt;em&gt;meaning&lt;/em&gt; of 
words— it turns out that the order of context words is, on average, irrelevant.&lt;/pre&gt;
&lt;p&gt;Having considered the intuitiveness of the “BOW” component of the CBOW moniker, let’s also consider the “continuous” part of it: The target word and context word windows slide &lt;em&gt;continuously&lt;/em&gt; one word at a time from the first word of the corpus all the way through to the final word. At each position along the way, the target word is estimated given the context words. Via stochastic gradient descent, the location of words within vector space can be shifted, and thereby these target-word estimates can gradually be improved.&lt;/p&gt;
&lt;p&gt;&lt;img sizes="(max-width: 841px) 100vw, 841px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_1.png 1102w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_1-300x85.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_1-768x219.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_1-1024x292.png 1024w" height="240" width="841" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_1.png" loading="lazy"&gt;&lt;/p&gt;
&lt;p&gt;In practice, and as summarized in Table 11.1, the SG architecture is a better choice when you’re working with a small corpus. It represents rare words in word-vector space well. In contrast, CBOW is much more computationally efficient, so it is the better option when you’re working with a very large corpus. Relative to SG, CBOW also represents frequently occurring words slightly better. [Note: Regardless of whether you use the SG or CBOW architecture, an additional option you have while running word2vec is the training method. For this, you have two different options: &lt;em&gt;hierarchical softmax&lt;/em&gt; and &lt;em&gt;negative sampling&lt;/em&gt;. The former involves normalization and is better suited to rare words. The latter, on the other hand, forgoes normalization, making it better suited to common words and low-dimensional word-vector spaces. For our purposes in this book, the differences between these two training methods are insignificant and we don’t cover them further.]&lt;/p&gt;
&lt;pre&gt;Although word2vec is comfortably the most widely used approach for embedding words 
from a corpus of natural language into vector space, it is by no means the only approach. 
A major alternative to word2vec is GloVe—global vectors for word representation—which was 
introduced by the prominent natural language researchers Jeffrey Pennington, Richard Socher, 
and Christopher Manning. [Note: 15. Pennington, J., et al. (2014). GloVe: Global vectors 
for word representations. &lt;em&gt;Proceedings of the Conference on Empirical Methods in 
Natural Language Processing&lt;/em&gt;.] At the time—in 2014—the three were colleagues working 
together at Stanford University.

GloVe and word2vec differ in their underlying methodology: word2vec uses predictive models, 
while GloVe is count based. Ultimately, both approaches tend to pro- duce vector-space 
embeddings that perform similarly in downstream NLP applications, with some research 
suggesting that word2vec may provide modestly better results in select cases. One potential 
advantage of GloVe is that it was designed to be parallelized over multiple processors 
or even multiple machines, so it might be a good option if you’re looking to create a 
word-vector space with many unique words and a very large corpus.

The contemporary leading alternative to both word2vec and GloVe is fastText. 
[Note: The open-source fastText library is available at fasttext.cc. Joulin, A., 
et al. (2016). Bag of tricks for efficient text classification. arXiv: 1607.01759.
 Bojanowski, P., et al. (2016). Enriching word vectors with subword information. 
arXiv: 1607.04606. Note that the lead author of the landmark word2vec paper, 
Tomas Mikolov, is the final author of both of these landmark fastText papers.] 
This approach was developed by researchers at Facebook. A major benefit of fastText 
is that it operates on a subword level—its “word” vectors are actually subcomponents 
of words. This enables fastText to work around some of the issues related to rare words 
and out-of-vocabulary words addressed in the preprocessing section at the outset of 
this chapter.&lt;/pre&gt;
&lt;h2&gt;Evaluating Word Vectors&lt;/h2&gt;
&lt;p&gt;However you create your word vectors—be it with word2vec or an alternative approach—there are two broad perspectives you can consider when evaluating the quality of word vectors: &lt;em&gt;intrinsic&lt;/em&gt; and &lt;em&gt;extrinsic&lt;/em&gt; evaluations.&lt;/p&gt;
&lt;p&gt;Extrinsic evaluations involve assessing the performance of your word vectors within whatever your downstream NLP application of interest is—your sentiment-analysis classifier, say, or perhaps your named-entity recognition tool. Although extrinsic evaluations can take longer to carry out because they require you to carry out all of your downstream processing steps—including perhaps training a computationally intensive deep learning model—you can be confident that it’s worthwhile to retain a change to your word vectors if they relate to an appreciable improvement in the accuracy of your NLP application.&lt;/p&gt;
&lt;p&gt;In contrast, intrinsic evaluations involve assessing the performance of your word vectors not on your final NLP application, but rather on some specific intermediate sub- task. One common such task is assessing whether your word vectors correspond well to arithmetical analogies like those shown in Figure 2.7. For example, if you start at the word-vector location for king, subtract &lt;code&gt;man&lt;/code&gt;, and &lt;code&gt;add woman&lt;/code&gt;, do you end up near the word-vector location for queen? [Note: A test set of 19,500 such analogies was developed by Tomas Mikolov and his colleagues in their 2013 word2vec paper. This test set is available at &lt;a href="http://download.tensorflow.org/data/questions-words.txt"&gt;download.tensorflow.org/data/questions-words.txt&lt;/a&gt;.]&lt;/p&gt;
&lt;p&gt;Relative to extrinsic evaluations, intrinsic tests are quick. They may also help you better understand (and therefore troubleshoot) intermediate steps within your broader NLP process. The limitation of intrinsic evaluations, however, is that they may not ultimately lead to improvements in the accuracy of your NLP application downstream unless you’ve identified a reliable, quantifiable relationship between performance on the intermediate test and your NLP application.&lt;/p&gt;
&lt;h2&gt;Running word2vec&lt;/h2&gt;
&lt;p&gt;As mentioned earlier, and as shown in Example 11.8, word2vec can be run in a single line of code—albeit with quite a few arguments.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example 11.8 Running word2vec&lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;       model = Word2Vec(sentences=clean_sents, size=64,
                        sg=1, window=10, iter=5,
                        min_count=10, workers=4)

&lt;/pre&gt;
&lt;p&gt;Here’s a breakdown of each of the arguments we passed into the Word2Vec() method&lt;br&gt;
from the gensim library:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;sentences&lt;/code&gt;: Pass in a list of lists like clean_sents as a corpus. Elements in the higher-level list are sentences, whereas elements in the lower-level list can be word- level tokens.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;size&lt;/code&gt;: The number of dimensions in the word-vector space that will result from running word2vec. This is a hyperparameter that can be varied and evaluated extrinsically or intrinsically. Like other hyperparameters in this book, there is a Goldilocks sweet spot. You can home in on an optimal value by specifying, say, 32 dimensions and varying this value by powers of 2. Doubling the number of dimensions will double the computational complexity of your downstream deep learning model, but if doing this results in markedly higher model accuracy then this extrinsic evaluation suggests that the extra complexity could be worthwhile. On the other hand, halving the number of dimensions halves computational complexity downstream: If this can be done without appreciably decreasing your NLP model’s accuracy, then it should be. By performing a handful of intrinsic inspections (which we’ll go over shortly), we found 64 dimensions to provide more sensible word vectors than 32 dimensions for this particular case. Doubling this figure to 128, however, provided no noticeable improvement.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sg&lt;/code&gt;: Set to 1 to choose the skip-gram architecture, or leave at the 0 default to choose CBOW. As summarized in Table 11.1, SG is generally better suited to small datasets like our Gutenberg corpus.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;window&lt;/code&gt;: For SG, a window size of 10 (for a total of 20 context words) is a good bet, so we set this hyperparameter to 10. If we were using CBOW, then a window size of 5 (for a total of 10 context words) could be near the optimal value. In either case, this hyperparameter can be experimented with and evaluated extrinsically or intrinsically. Small adjustments to this hyperparameter may not be perceptibly impactful, however.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;iter&lt;/code&gt;: By default, the gensim &lt;code&gt;Word2Vec()&lt;/code&gt; method iterates over the corpus fed into it (i.e., slides over all of the words) five times. Multiple iterations of word2vec is analogous to multiple epochs of training a deep learning model. With a small corpus like ours, the word vectors improve over several iterations. With a very large corpus, on the other hand, it might be cripplingly computationally expensive to run even two iterations—and, because there are so many examples of words in a very large corpus anyway, the word vectors might not be any better.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;min_count&lt;/code&gt;: This is the minimum number of times a word must occur across the corpus in order to fit it into word-vector space. If a given target word occurs only once or a few times, there are a limited number of examples of its contextual words to consider, and so its location in word-vector space may not be reliable. Because of this, a minimum count of about 10 is often reasonable. The higher the count, the smaller the vocabulary of words that will be available to your downstream NLP task. This is yet another hyperparameter that can be tuned, with extrinsic evaluations likely being more illuminating than intrinsic ones because the size of the vocabulary you have to work with could make a considerable impact on your downstream NLP application.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;workers&lt;/code&gt;: This is the number of processing cores you’d like to dedicate to training. If the CPU on your machine has, say, eight cores, then eight is the largest number of parallel worker threads you can have. In this case, if you choose to use fewer than eight cores, you’re leaving compute resources available for other tasks.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In our GitHub repository, we saved our model using the save() method of word2vec objects:&lt;/p&gt;
&lt;pre title=""&gt;model.save('clean_gutenberg_model.w2v')

&lt;/pre&gt;
&lt;p&gt;Instead of running word2vec yourself, then, you’re welcome to load up our word vectors&lt;br&gt;
using this code:&lt;/p&gt;
&lt;pre title=""&gt;model = gensim.models.Word2Vec.load('clean_gutenberg_model.w2v')

&lt;/pre&gt;
&lt;p&gt;If you do choose the word vectors we created, then the following examples will produce the same outputs. [Note: Every time word2vec is run, the initial locations of every word of the vocabulary within word-vector space are assigned randomly. Because of this, the same data and arguments provided to &lt;em&gt;Word2Vec()&lt;/em&gt; will nevertheless produce unique word vectors every time, but the semantic relationships should be similar.] We can see the size of our vocabulary by calling &lt;code&gt;len(model.wv.vocab)&lt;/code&gt;. This tells us that there are 10,329 words (well, more specifically, tokens) that occur at least 10 times within our clean_sents corpus. [Note: Vocabulary size is equal to the number of tokens from our corpus that had occurred at least 10 times, because we set &lt;code&gt;min_count=10&lt;/code&gt; when calling &lt;code&gt;Word2Vec()&lt;/code&gt; in Example 11.8.] One of the words in our vocabulary is dog. As shown in Figure 11.6, we can output its location in 64-dimensional word-vector space by running &lt;code&gt;model.wv['dog']&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img sizes="(max-width: 793px) 100vw, 793px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_6-1.png 1070w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_6-1-300x133.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_6-1-768x342.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_6-1-1024x456.png 1024w" height="353" width="793" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_6-1.png" loading="lazy"&gt;&lt;/p&gt;
&lt;p&gt;As a rudimentary intrinsic evaluation of the quality of our word vectors, we can use the most_similar() method to confirm that words with similar meanings are found in similar locations within our word-vector space. [Note: Technically speaking, the similarity between two given words is computed here by calculating the cosine similarity.] For example, to output the three words that are most similar to father in our word-vector space, we can run this code:&lt;/p&gt;
&lt;pre title=""&gt;model.wv.most_similar('father', topn=3) 

&lt;/pre&gt;
&lt;p&gt;This outputs the following:&lt;/p&gt;
&lt;pre title=""&gt;              [('mother', 0.8257375359535217),
               ('brother', 0.7275018692016602),
               ('sister', 0.7177823781967163)]
&lt;/pre&gt;
&lt;p&gt;This output indicates that &lt;em&gt;mother&lt;/em&gt;,&lt;em&gt; brother&lt;/em&gt;, and &lt;em&gt;sister&lt;/em&gt; are the most similar words to father in our word-vector space. In other words, within our 64-dimensional space, the word that is closest. [Note: That is, has the shortest Euclidean distance in that 64-dimensional vector space.] to father is the word mother. Table 11.2 provides some additional examples of the words most similar to (i.e., closest to) particular words that we’ve picked from our word- vector vocabulary, all five of which appear pretty reasonable given our small Gutenberg corpus. [Note that the final test word in Table 11.2—ma’am—is only available because of the bigram collocation (see Examples 11.6 and 11.7).]&lt;/p&gt;
&lt;p&gt;Suppose we run the following line of code:&lt;/p&gt;
&lt;pre title=""&gt;       model.wv.doesnt_match("mother father sister brother dog".split())

&lt;/pre&gt;
&lt;p&gt;We get the output dog, indicating that dog is the least similar relative to all the other possible word pairs. We can also use the following line to observe that the similarity score between father and dog is a mere 0.44:&lt;/p&gt;
&lt;pre title=""&gt;       model.wv.similarity('father', 'dog')

&lt;/pre&gt;
&lt;p&gt;&lt;img sizes="(max-width: 656px) 100vw, 656px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_2.png 994w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_2-300x109.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_2-768x280.png 768w" height="239" width="656" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_2.png" loading="lazy"&gt;&lt;/p&gt;
&lt;p&gt;This similarity score of 0.44 is much lower than the similarity between &lt;em&gt;father&lt;/em&gt; and any of &lt;em&gt;mother, brother&lt;/em&gt;, or &lt;em&gt;sister,&lt;/em&gt; and so it’s unsurprising that &lt;em&gt;dog&lt;/em&gt; is relatively distant from the other four words within our word-vector space.&lt;/p&gt;
&lt;p&gt;As a final little intrinsic test, we can compute word-vector analogies as in Figure 2.7. For example, to calculate&lt;/p&gt;
&lt;p&gt;&lt;img height="54" width="227" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-EQ-1.png" loading="lazy"&gt;&lt;/p&gt;


&lt;p&gt;we can execute this code:&lt;/p&gt;
&lt;pre title=""&gt;model.wv.most_similar(positive=['father', 'woman'], negative=['man']) 

&lt;/pre&gt;
&lt;p&gt;The top-scoring word comes out as mother, which is the correct answer to the analogy.&lt;/p&gt;
&lt;p&gt;Suppose we likewise execute this code:&lt;/p&gt;
&lt;pre title=""&gt;model.wv.most_similar(positive=['husband', 'woman'], negative=['man']) 

&lt;/pre&gt;
&lt;p&gt;In this case, the top-scoring word comes out as wife, again the correct answer, thereby&lt;br&gt;
suggesting that our word-vector space may generally be on the right track.&lt;/p&gt;
&lt;pre&gt;A given dimension within an n-dimensional word-vector space does not necessarily 
represent any specific factor that relates words. For example, although the real-world 
differences in meaning of gender or verb tense are represented by some vector direction 
(i.e., some movement along some combination of dimensions) within the vector space, 
this meaningful vector direction may only by chance be aligned—or perhaps correlated—with 
a particular axis of the vector space.

This contrasts with some other approaches that involve n-dimensional vector spaces, 
where the axes are intended to represent some specific explanatory variable. One such 
approach that many people are familiar with is principal component anal- ysis (PCA), 
a technique for identifying linearly uncorrelated (i.e., orthogonal) vectors that 
contribute to variance in a given dataset. A corollary of this difference between 
information stored as points in PCA versus in word-vector space is that in PCA, 
the first principal components contribute most of the variance, and so you can 
focus on them and ignore later principal components; but in a word-vector space, 
all of the dimensions may be important and need to be taken into consideration. 
In this way, approaches like PCA are useful for dimensionality reduction because 
we do not need to consider all of the dimensions.
&lt;/pre&gt;
&lt;h2&gt;Plotting Word Vectors&lt;/h2&gt;
&lt;p&gt;Human brains are not well suited to visualizing anything in greater than three dimensions. Thus, plotting word vectors—which could have dozens or even hundreds of dimensions—in their native format is out of the question. Thankfully, we can use techniques for dimensionality reduction to approximately map the locations of words from high- dimensional word-vector space down to two or three dimensions. Our recommended approach for such dimensionality reduction is &lt;em&gt;t-distributed stochastic neighbor embedding&lt;/em&gt; (t-SNE; pronounced tee-snee), which was developed by Laurens van der Maaten in col- laboration with Geoff Hinton (Figure 1.16). [Note: van der Maaten, L., &amp;amp; Hinton, G. (2008). Visualizing data using t-SNE. Journal of Machine Learning Research, 9, 2579–605.]&lt;/p&gt;
&lt;p&gt;Example 11.9 provides the code from our &lt;em&gt;Natural Language Preprocessing&lt;/em&gt; notebook for reducing our 64-dimensional Project Gutenberg-derived word-vector space down to two dimensions, and then storing the resulting &lt;em&gt;x&lt;/em&gt; and &lt;em&gt;y&lt;/em&gt; coordinates within a Pandas DataFrame. There are two arguments for the &lt;code&gt;TSNE()&lt;/code&gt; method (from the &lt;em&gt;scikit-learn &lt;/em&gt;library) that we need to focus on:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;n_components&lt;/code&gt; is the number of dimensions that should be returned, so setting this to 2 results in a two-dimensional output, whereas 3 would result in a three- dimensional output.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;n_iter &lt;/code&gt;is the number of iterations over the input data. As with word2vec (Example 11.8), iterations are analogous to the epochs associated with training a neural network. More iterations corresponds to a longer training time but may improve the results (although only up to a point).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Example 11.9 t-SNE for dimensionality reduction&lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;       tsne = TSNE(n_components=2, n_iter=1000)
       X_2d = tsne.fit_transform(model.wv[model.wv.vocab])
       coords_df = pd.DataFrame(X_2d, columns=['x','y'])
       coords_df['token'] = model.wv.vocab.keys()
&lt;/pre&gt;
&lt;p&gt;Running t-SNE as in Example 11.9 may take some time on your machine, so you’re welcome to use our results if you’re feeling impatient by running the following code:&lt;/p&gt;
&lt;pre title=""&gt;coords_df = pd.read_csv('clean_gutenberg_tsne.csv')

&lt;/pre&gt;
&lt;p&gt;[Note: We created this CSV after running t-SNE on our word-vectors using this command: &lt;code&gt;coords_df.to_csv('clean_gutenberg_tsne.csv'&lt;/code&gt;, &lt;code&gt;index=False&lt;/code&gt;). Note that because t-SNE is stochastic, you will obtain a unique result every time you run it.]&lt;/p&gt;
&lt;p&gt;Whether you ran t-SNE to produce &lt;code&gt;coords_df&lt;/code&gt; on your own or you loaded in ours, you can check out the first few lines of the DataFrame by using the &lt;code&gt;head() method&lt;/code&gt;:&lt;/p&gt;
&lt;pre title=""&gt;coords_df.head()

&lt;/pre&gt;
&lt;p&gt;Our output from executing head() is shown in Figure 11.7. Example 11.10 provides code for creating a static scatterplot (Figure 11.8) of the two-dimensional data we created with t-SNE (in Example 11.9).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example 11.10 Static two-dimensional scatterplot of word-vector space&lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;_ = coords_df.plot.scatter('x', 'y', figsize=(12,12),
                                  marker='.', s=10, alpha=0.2)

&lt;/pre&gt;
&lt;p&gt;&lt;img sizes="(max-width: 692px) 100vw, 692px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_7.png 1054w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_7-300x129.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_7-768x329.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_7-1024x439.png 1024w" height="297" width="692" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_7.png" loading="lazy"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img sizes="(max-width: 583px) 100vw, 583px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_8.png 964w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_8-291x300.png 291w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_8-768x792.png 768w" height="602" width="583" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_8.png" loading="lazy"&gt;&lt;/p&gt;
&lt;p&gt;On its own, the scatterplot displayed in Figure 11.8 may look interesting, but there’s little actionable information we can take away from it. Instead, we recommend using the &lt;em&gt;bokeh&lt;/em&gt; library to create a highly interactive—and actionable—plot, as with the code provided in Example 11.11. [Note: In Example 11.11, we used the Pandas sample() method to reduce the dataset down to 5,000 tokens, because we found that using more data than this corresponded to a clunky user experience when using the bokeh plot interactively.]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example 11.11 Interactive bokeh plot of two-dimensional word-vector data&lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;       output_notebook()
       subset_df = coords_df.sample(n=5000)
       p = figure(plot_width=800, plot_height=800)
       _ = p.text(x=subset_df.x, y=subset_df.y, text=subset_df.token)
       show(p)

&lt;/pre&gt;
&lt;p&gt;The code in Example 11.11 produces the interactive scatterplot in Figure 11.9 using the &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; coordinates generated using t-SNE.&lt;/p&gt;
&lt;p&gt;&lt;img sizes="(max-width: 610px) 100vw, 610px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_9.png 892w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_9-280x300.png 280w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_9-768x823.png 768w" height="655" width="610" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_9.png" loading="lazy"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img sizes="(max-width: 753px) 100vw, 753px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_10.png 1102w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_10-300x293.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_10-768x751.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_10-1024x1002.png 1024w" height="737" width="753" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_10.png" loading="lazy"&gt;&lt;/p&gt;
&lt;p&gt;By toggling the &lt;em&gt;Wheel Zoom&lt;/em&gt; button in the top-right corner of the plot, you can use your mouse to zoom into locations within the cloud so that the words become legible. For example, as shown in Figure 11.10, we identified a region composed largely of items of clothing, with related clusters nearby, including parts of the human anatomy, colors, and fabric types. Exploring in this way provides a largely subjective intrinsic evaluation of whether related terms—and particularly synonyms—cluster together as you’d expect them to. Doing similar, you may also notice particular shortcomings of your natural-language preprocessing steps, such as the inclusion of punctuation marks, bigrams, or other tokens that you may prefer weren’t included within your word-vector vocabulary.&lt;/p&gt;
&lt;h2&gt;The Area under the ROC Curve&lt;/h2&gt;
&lt;p&gt;Our apologies for interrupting the fun, interactive plotting of word vectors. We need to take a brief break from natural language-specific content here to introduce a metric that will come in handy in the next section of the chapter, when we will evaluate the performance of deep learning NLP models.&lt;/p&gt;
&lt;p&gt;Up to this point in the book, most of our models have involved multiclass outputs: When working with the MNIST digits, for example, we used 10 output neurons to rep- resent each of the 10 possible digits that an input image could represent. In the remaining sections of this chapter, however, our deep learning models will be &lt;em&gt;binary classifiers&lt;/em&gt;: They will distinguish between only two classes. More specifically, we will build binary classifiers to predict whether the natural language of film reviews corresponds to a favorable review or negative one.&lt;/p&gt;
&lt;p&gt;Unlike artificial neural networks tasked with multiclass problems, which require as many output neurons as classes, ANNs that are acting as binary classifiers require only a single output neuron. This is because there is no extra information associated with having two output neurons. If a binary classifier is provided some input x and it calculates some output &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; for one of the classes, then the output for the other class is simply 1 – &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt;. As an example, if we feed a movie review into a binary classifier and it outputs that the probability that this review is a positive one is 0.85, then it must be the case that the probability of the review being negative is 1 − 0.85 = 0.15.&lt;/p&gt;
&lt;p&gt;Because binary classifiers have a single output, we can take advantage of metrics for evaluating our model’s performance that are sophisticated relative to the excessively black-and-white accuracy metric that dominates multiclass problems. A typical accuracy calculation, for example, would contend that if &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; &amp;gt; 0.5 then the model is predicting that the input x belongs to one class, whereas if it outputs anything less than 0.5, it belongs to the other class. To illustrate why having a specific binary threshold like this is overly simplistic, consider a situation where inputting a movie review results in a binary classifier outputting &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; = 0.48: A typical accuracy calculation threshold would hold that—because this &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; is lower than 0.5–it is being classed as a negative review. If a second film review corresponds to an output of &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; = 0.51, the model has barely any more confidence that this review is positive relative to the first review. Yet, because 0.51 is greater than the 0.5 accuracy threshold, the second review is classed as a positive review.&lt;/p&gt;
&lt;p&gt;The starkness of the accuracy metric threshold can hide a fair bit of nuance in the quality of our model’s output, and so when evaluating the performance of binary classifiers, we prefer a metric called the area under the curve of the receiver operating characteristic. The ROC AUC, as the metric is known for short, has its roots in the Second World War, when it was developed to assess the performance of radar engineers’ judgment as they attempted to identify the presence of enemy objects.&lt;/p&gt;
&lt;p&gt;We like the ROC AUC for two reasons:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;It blends together two useful metrics—true positive rate and false positive rate—into a single summary value.&lt;/li&gt;
&lt;li&gt;It enables us to evaluate the performance of our binary classifier’s output across the full range of &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt;, from 0.0 to 1.0. This contrasts with the accuracy metric, which evaluates the performance of a binary classifier at a single threshold value only— usually &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; = 0.50.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;The Confusion Matrix&lt;/h2&gt;
&lt;p&gt;The first step toward understanding how to calculate the ROC AUC metric is to under- stand the so-called &lt;em&gt;confusion matrix&lt;/em&gt;, which—as you’ll see—isn’t actually all that confusing. Rather, the matrix is a straightforward 2 × 2 table of how confused a model (or, as back in WWII, a person) is while attempting to act as a binary classifier. You can see an example of a confusion matrix in Table 11.3.&lt;/p&gt;
&lt;p&gt;&lt;img sizes="(max-width: 553px) 100vw, 553px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_3.png 916w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_3-300x92.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_3-768x235.png 768w" height="169" width="553" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_3.png" loading="lazy"&gt;&lt;/p&gt;
&lt;p&gt;To bring the confusion matrix to life with an example, let’s return to the hot dog / not hot dog binary classifier that we’ve used to construct silly examples over many of the preceding chapters:&lt;/p&gt;
&lt;p&gt;When we provide some input x to a model and it &lt;em&gt;predicts&lt;/em&gt; that the input represents a hot dog, then we’re dealing with the first row of the table, because the &lt;em&gt;predicted&lt;/em&gt; y = 1. In that case,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;True positive: If the input is&lt;em&gt; actually&lt;/em&gt; a hot dog (i.e., &lt;em&gt;actual&lt;/em&gt; y = 1), then the model correctly classified the input.&lt;/li&gt;
&lt;li&gt;False positive: If the input is &lt;em&gt;actually&lt;/em&gt; not a hot dog (i.e., &lt;em&gt;actual&lt;/em&gt; y = 0), then the model is &lt;em&gt;confused.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;False negative: If the input is actually a hot dog (i.e.,&lt;em&gt; actual&lt;/em&gt; y = 1), then the model is also confused in this circumstance.&lt;/li&gt;
&lt;li&gt;True negative: If the input is actually not a hot dog (i.e., &lt;em&gt;actual&lt;/em&gt; y = 0), then the model correctly classified the input.When we provide some input x to a model and it predicts that the input does &lt;em&gt;not&lt;/em&gt; represent a hot dog, then we’re dealing with the second row of the table, because &lt;em&gt;predicted&lt;/em&gt; y = 0. In that case,&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Calculating the ROC AUC Metric&lt;/h2&gt;
&lt;p&gt;Briefed on the confusion matrix, we can now move forward and calculate the ROC AUC metric itself, using a toy-sized example. Let’s say, as shown in Table 11.4, we provide four inputs to a binary-classification model.&lt;/p&gt;
&lt;p&gt;&lt;img sizes="(max-width: 457px) 100vw, 457px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_4.png 690w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_4-300x136.png 300w" height="207" width="457" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_4.png" loading="lazy"&gt;&lt;/p&gt;
&lt;p&gt;Two of these inputs are actually hot dogs (y = 1), and two of them are not hot dogs (y = 0). For each of these inputs, the model outputs some predicted &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt;, all four of which are provided in Table 11.4.&lt;/p&gt;
&lt;p&gt;&lt;img sizes="(max-width: 672px) 100vw, 672px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_5.png 1034w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_5-300x134.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_5-768x343.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_5-1024x458.png 1024w" height="300" width="672" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_5.png" loading="lazy"&gt;&lt;/p&gt;
&lt;p&gt;To calculate the ROC AUC metric, we consider each of the &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; values output by the model as the binary-classification threshold in turn. Let’s start with the lowest &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt;, which is 0.3 (see the “0.3 threshold” column in Table 11.5). At this threshold, only the first input is classed as not a hot dog, whereas the second through fourth inputs (all with &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; &amp;gt; 0.3) are all classed as hot dogs. We can compare each of these four predicted classifications with the confusion matrix in Table 11.3:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;True negative (TN): This is actually not a hot dog (y = 0) and was correctly predicted as such.&lt;/li&gt;
&lt;li&gt;True positive (TP): This is actually a hot dog (y = 1) and was correctly predicted as such.&lt;/li&gt;
&lt;li&gt;False positive (FP): This is actually not a hot dog (y = 0) but it was erroneously predicted to be one.&lt;/li&gt;
&lt;li&gt;True positive (TP): Like input 2, this is actually a hot dog (y = 1) and was correctly predicted as such.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The same process is repeated with the classification threshold set to 0.5 and yet again with the threshold set to 0.6, allowing us to populate the remaining columns of Table 11.5. As an exercise, it might be wise to work through these two columns, comparing the classifications at each threshold with the actual y values and the confusion matrix (Table 11.3) to ensure that you have a good handle on these concepts.Finally, note that the highest &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; value (in this case, .09) can be skipped as a potential threshold, because at such a high threshold we’d be considering all four instances to not be hot dogs, making it a ceiling instead of a classification boundary.&lt;/p&gt;
&lt;p&gt;The next step toward computing the ROC AUC metric is to calculate both the true positive rate (TPR) and the false positive rate (FPR) at each of the three thresholds. Equations 11.1 and 11.2 use the “0.3 threshold” column to provide examples of how to calculate the true positive rate and false positive rate, respectively.&lt;/p&gt;
&lt;p&gt;&lt;img sizes="(max-width: 564px) 100vw, 564px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-EQ2.png 486w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-EQ2-300x114.png 300w" height="214" width="564" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-EQ2.png" loading="lazy"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img sizes="(max-width: 596px) 100vw, 596px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-EQ3.png 550w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-EQ3-300x97.png 300w" height="193" width="596" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-EQ3.png" loading="lazy"&gt;&lt;/p&gt;
&lt;p&gt;Shorthand versions of the arithmetic for calculating TPR and FPR for the thresholds 0.5 and 0.6 are also provided for your convenience at the bottom of Table 11.5. Again, perhaps you should test if you can compute these values yourself on your own time.&lt;/p&gt;
&lt;p&gt;The final stage in calculating ROC AUC is to create a plot like the one we provide in Figure 11.11. The points that make up the shape of the receiver operating characteristic (ROC) curve are the false positive rate (horizontal, x-axis coordinate) and true positive rate (vertical, y-axis coordinate) at each of the available thresholds (which in this case is three) in Table 11.5, plus two extra points in the bottom-left and top-right corners of the plot. Specifically, these five points (shown as orange dots in Figure 11.11) are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;(0, 0) for the bottom-left corner&lt;/li&gt;
&lt;li&gt;(0, 0.5) from the 0.6 threshold&lt;/li&gt;
&lt;li&gt;(0.5, 0.5) from the 0.5 threshold&lt;/li&gt;
&lt;li&gt;(0.5, 1) from the 0.3 threshold&lt;/li&gt;
&lt;li&gt;(1, 1) for the top-right corner&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In this toy-sized example, we only used four distinct &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; values so there are only five points that determine the shape of the ROC curve, making the curve rather step shaped. When there are many available predictions providing many distinct &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; values—as is typically the case in real-world examples—the ROC curve has many more points, and so it’s much less step shaped and much more, well, curve shaped. The area under the curve (AUC) of the ROC curve is exactly what it sounds like: In Figure 11.11, we’ve shaded this area in orange and, in this example, the AUC constitutes 75 percent of all the possible area and so the ROC AUC metric comes out to 0.75.&lt;/p&gt;
&lt;p&gt;A binary classifier that works as well as chance will generate a straight diagonal running from the bottom-left corner of the plot to its top-right corner, so an ROC AUC of 0.5 indicates that the classifier works as well as flipping a coin. A perfect ROC AUC is 1.0, which is attained by having FPR = 0 and TPR = 1 across all of the available &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; thresholds. When you’re designing a binary classifier to perform well on the ROC AUC metric, the goal is thus to minimize FPR and maximize TPR across the range of &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; thresholds. That said, for most problems you encounter, attaining a perfect ROC AUC of 1.0 is not possible: There is usually some noise—perhaps a lot of noise—in the data that makes perfection unattainable. Thus, when you’re working with any given dataset, there is some (typically unknown!) maximum ROC AUC score, such that no matter how ideally suited your model is to act as a binary classifier for the problem, there’s an ROC AUC ceiling that no model can crack through.&lt;/p&gt;
&lt;p&gt;Over the remainder of this chapter we use the illuminating ROC AUC metric, alongside the simpler accuracy and cost metrics you are already acquainted with, to evaluate the performance of the binary-classifying deep learning models that we design and train.&lt;/p&gt;
&lt;p&gt;&lt;img sizes="(max-width: 660px) 100vw, 660px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_11.png 1066w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_11-300x150.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_11-768x383.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_11-1024x511.png 1024w" height="329" width="660" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_11.png" loading="lazy"&gt;&lt;/p&gt;
&lt;h2&gt;Natural Language Classification with Familiar Networks&lt;/h2&gt;
&lt;p&gt;In this section, we tie together concepts that were introduced in this chapter—natural language preprocessing best practices, the creation of word vectors, and the ROC AUC metric—with the deep learning theory from previous chapters. As we already alluded to earlier, the natural language processing model you’ll experiment with over the remainder of the chapter will be a binary classifier that predicts whether a given film review is a positive one or a negative one. We begin by classifying natural language documents using types of neural networks that you’re already familiar with—dense and convolutional— before moving along to networks that are specialized to handle data that occur in a sequence.&lt;/p&gt;
&lt;h2&gt;Loading the IMDb Film Reviews&lt;/h2&gt;
&lt;p&gt;As a performance baseline, we’ll initially train and test a relatively simple dense network. All of the code for doing this is provided within our &lt;em&gt;Dense Sentiment Classifier&lt;/em&gt; Jupyter notebook [or the &lt;a href="https://try.dominodatalab.com/u/domino-andrealowe/Natural-Language-Processing/overview"&gt;complementary Domino project&lt;/a&gt;].&lt;/p&gt;
&lt;p&gt;Example 11.12 provides the dependencies we need for our dense sentiment classifier. Many of these dependencies will be recognizable from previous chapters, but others (e.g., for loading a dataset of film reviews, saving model parameters as we train, calculating ROC AUC) are new. As usual, we cover the details of these dependencies as we apply them later on.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example 11.12 Loading sentiment classifier dependencies&lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;import keras
from keras.datasets import imdb # new!
from keras.preprocessing.sequence import pad_sequences # new!
from keras.models import Sequential
from keras.layers import Dense, Flatten, Dropout
from keras.layers import Embedding # new!
from keras.callbacks import ModelCheckpoint # new!
import os # new!
from sklearn.metrics import roc_auc_score, roc_curve # new! import pandas as pd
import matplotlib.pyplot as plt # new!
%matplotlib inline

&lt;/pre&gt;
&lt;p&gt;It’s a good programming practice to put as many hyperparameters as you can at the top of your file. This makes it easier to experiment with these hyperparameters. It also makes it easier for you (or, indeed, your colleagues) to understand what you were doing in the file when you return to it (perhaps much) later. With this in mind, we place all of our hyperparameters together in a single cell within our Jupyter notebook. The code is provided in Example 11.13.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example 11.13 Setting dense sentiment classifier hyperparameters&lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;# output directory name:
output_dir = 'model_output/dense'

# training:
epochs = 4
batch_size = 128

# vector-space embedding:
n_dim = 64
n_unique_words = 5000
n_words_to_skip = 50
max_review_length = 100
pad_type = trunc_type = 'pre'

# neural network architecture:
n_dense = 64
dropout = 0.5

&lt;/pre&gt;
&lt;p&gt;Let’s break down the purpose of each of these variables:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;output_dir&lt;/code&gt;: A directory name (ideally, a unique one) in which to store our model’s parameters after each epoch, allowing us to return to the parameters from any epoch of our choice at a later time.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;epochs&lt;/code&gt;: The number of epochs that we’d like to train for, noting that NLP models often overfit to the training data in fewer epochs than machine vision models.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;batch_size&lt;/code&gt;: As before, the number of training examples used during each round of model training (see Figure 8.5).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;n_dim&lt;/code&gt;: The number of dimensions we’d like our word-vector space to have.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;n_unique_words&lt;/code&gt;: With word2vec earlier in this chapter, we included tokens in our word-vector vocabulary only if they occurred at least a certain number of times within our corpus. An alternative approach—the one we take here—is to sort all of the tokens in our corpus by the number of times they occur, and then only use a certain number of the most popular words. Andrew Maas and his coworkers [Note: We mentioned Maas et al. (2011) earlier in this chapter. They put together the movie-review corpus we’re using in this notebook.]&amp;nbsp;opted to use the 5,000 most popular words across their film-review corpus and so we’ll do the same.[Note: This 5,000-word threshold may not be optimal, but we didn’t take the time to test lower or higher values. You are most welcome to do so yourself!]&lt;/li&gt;
&lt;li&gt;&lt;code&gt;n_words_to_skip&lt;/code&gt;: Instead of removing a manually curated list of stop words from their word-vector vocabulary, Maas et al. made the assumption that the 50 most frequently occurring words across their film-review corpus would serve as a decent list of stop words. We followed their lead and did the same.[Note: Note again that following Maas et al.’s lead may not be the optimal choice. Further, note that this means we’ll actually be including the 51st most popular word through to the 5050th most popular word in our word-vector vocabulary.]&lt;/li&gt;
&lt;li&gt;&lt;code&gt;max_review_length&lt;/code&gt;: Each movie review must have the same length so that TensorFlow knows the shape of the input data that will be flowing through our deep learning model. For this model, we selected a review length of 100 words.[Note: You are free to experiment with lengthier or shorter reviews.] Any reviews longer than 100 are truncated. Any reviews shorter than 100 are padded with a special padding character (analogous to the zero padding that can be used in machine vision, as in Figure 10.3).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pad_type&lt;/code&gt;: By selecting &lt;code&gt;'pre'&lt;/code&gt;, we add padding characters to the start of every review. The alternative is &lt;code&gt;'post'&lt;/code&gt;, which adds them to the end. With a dense network like the one in this notebook, it shouldn’t make much difference which of these options we pick. Later in this chapter, when we’re working with specialized, sequential-data layer types, [Note: For example, RNN, LSTM.] it’s generally best to use ‘pre’ because the content at the end of the document is more influential in the model and so we want the largely uninformative padding characters to be at the beginning of the document.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;trunc_type&lt;/code&gt;: As with &lt;code&gt;pad_type&lt;/code&gt;, our truncation options are &lt;code&gt;'pre'&lt;/code&gt; or &lt;code&gt;'post'&lt;/code&gt;. The former will remove words from the beginning of the review, whereas the latter will remove them from the end. By selecting &lt;code&gt;'pre'&lt;/code&gt;, we’re making (a bold!) assumption that the end of film reviews tend to include more information on review sentiment than the beginning.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;n_dense&lt;/code&gt;: The number of neurons to include in the dense layer of our neural network architecture. We waved our finger in the air to select 64, so some experimentation and optimization are warranted at your end if you feel like it. For simplicity’s sake, we also are using a single layer of dense neurons, but you could opt to have several.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dropout&lt;/code&gt;: How much dropout to apply to the neurons in the dense layer. Again, we did not take the time to optimize this hyperparameter (set at 0.5) ourselves.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Loading in the film review data is a one-liner, provided in Example 11.14.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example 11.14 Loading IMDb film review data&lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;(x_train, y_train), (x_valid, y_valid) = \
    imdb.load_data(num_words=n_unique_words, skip_top=n_words_to_skip)

&lt;/pre&gt;
&lt;p&gt;This dataset from Maas et al. (2011) is made up of the natural language of reviews from the publicly available Internet Movie Database (IMDb; &lt;a href="http://imdb.com/"&gt;imdb.com&lt;/a&gt;). It consists of 50,000 reviews, half of which are in the training dataset &lt;code&gt;(x_train)&lt;/code&gt;, and half of which are for model validation &lt;code&gt;(x_valid)&lt;/code&gt;. When submitting their review of a given film, users also provide a star rating, with a maximum of 10 stars. The labels &lt;code&gt;(y_train and y_valid)&lt;/code&gt; are binary, based on these star ratings:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Reviews with a score of four stars or fewer are considered to be a negative review (y = 0).&lt;/li&gt;
&lt;li&gt;Reviews with a score of seven stars or more, meanwhile, are classed as a positive review (y = 1).&lt;/li&gt;
&lt;li&gt;Moderate reviews—those with five or six stars—are not included in the dataset, making the binary classification task easier for any model.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;By specifying values for the &lt;code&gt;num_words&lt;/code&gt; and &lt;code&gt;skip_top&lt;/code&gt; arguments when calling &lt;code&gt;imdb.load_data()&lt;/code&gt;, we are limiting the size of our word-vector vocabulary and removing the most common (stop) words, respectively.&lt;/p&gt;
&lt;pre&gt;In our Dense Sentiment Classifier notebook, we have the convenience of loading our IMDb 
film-review data via the Keras &lt;code&gt;imdb.load_data()&lt;/code&gt; method. When you’re working with your own natural language data, you’ll likely need to preprocess many aspects of the data yourself. In addition to the general preprocessing guidance we provided earlier in this chapter, Keras provides a number of convenient text preprocessing utilities, as documented online at keras.io/preprocessing/text. In particular, the &lt;code&gt;Tokenizer()&lt;/code&gt; class may enable you to carry out all of the preprocessing steps you need in a single line of code, including - Tokenizing a corpus to the word level (or even the character level) - Setting the size of your word-vector vocabulary (with num_words) - Filtering out punctuation Converting all characters to lowercase - Converting tokens into an integer index&lt;/pre&gt;
&lt;h2&gt;Examining the IMDb Data&lt;/h2&gt;
&lt;p&gt;Executing &lt;code&gt;x_train[0:6]&lt;/code&gt;, we can examine the first six reviews from the training dataset, the first two of which are shown in Figure 11.12. These reviews are natively in an integer-index format, where each unique token from the dataset is represented by an integer. The first few integers are special cases, following a general convention that is widely used in NLP:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;0: Reserved as the padding token (which we’ll soon add to the reviews that are shorter than &lt;code&gt;max_review_length&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;1: Would be the starting token, which would indicate the beginning of a review. As per the next bullet point, however, the starting token is among the top 50 most common tokens and so is shown as “unknown.”&lt;/li&gt;
&lt;li&gt;2: Any tokens that occur very frequently across the corpus (i.e., they’re in the top 50 most common words) or rarely (i.e., they’re below the top 5,050 most common words) will be outside of our word-vector vocabulary and so are replaced with this unknown token.&lt;/li&gt;
&lt;li&gt;3: The most frequently occurring word in the corpus.&lt;/li&gt;
&lt;li&gt;4: The second-most frequently occurring word.&lt;/li&gt;
&lt;li&gt;5: The third-most frequently occurring, and so on.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Using the following code from Example 11.15, we can see the length of the first six reviews in the training dataset.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example 11.15 Printing the number of tokens in six reviews&lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;for x in x_train[0:6]:
    print(len(x))

&lt;/pre&gt;
&lt;p&gt;They are rather variable, ranging from 43 tokens up to 550 tokens. Shortly, we’ll handle these discrepancies, standardizing all reviews to the same length.&lt;/p&gt;
&lt;p&gt;&lt;img sizes="(max-width: 677px) 100vw, 677px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_12.png 1090w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_12-300x170.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_12-768x435.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_12-1024x581.png 1024w" height="384" width="677" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_12.png" loading="lazy"&gt;&lt;/p&gt;
&lt;p&gt;The film reviews are fed into our neural network model in the integer-index format of Figure 11.12 because this is a memory-efficient way to store the token information. It would require appreciably more memory to feed the tokens in as character strings, for example. For us humans, however, it is uninformative (and, frankly, uninteresting) to examine reviews in the integer-index format. To view the reviews as natural language, we create an index of words as follows, where &lt;code&gt;PAD&lt;/code&gt;, &lt;code&gt;START&lt;/code&gt;, and &lt;code&gt;UNK&lt;/code&gt; are customary for representing padding, starting, and unknown tokens, respectively:&lt;/p&gt;
&lt;pre title=""&gt;word_index = keras.datasets.imdb.get_word_index() 
word_index = {k:(v+3) for k,v in 
word_index.items()} word_index["PAD"] = 0
word_index["START"] = 1
word_index["UNK"] = 2
index_word = {v:k for k,v in word_index.items()}

&lt;/pre&gt;
&lt;p&gt;Then we can use the code in Example 11.16 to view the film review of our choice—in this case, the first review from the training data.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example 11.16 Printing a review as a character string&lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;' '.join(index_word[id] for id in x_train[0])

&lt;/pre&gt;
&lt;p&gt;The resulting string should look identical to the output shown in Figure 11.13.&lt;/p&gt;
&lt;p&gt;&lt;img sizes="(max-width: 788px) 100vw, 788px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_13.png 1082w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_13-300x135.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_13-768x346.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_13-1024x462.png 1024w" height="356" width="788" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_13.png" loading="lazy"&gt;&lt;/p&gt;
&lt;p&gt;Remembering that the review in Figure 11.13 contains the tokens that are fed into our neural network, we might nevertheless find it enjoyable to read the full review without all of the &lt;code&gt;UNK&lt;/code&gt; tokens. In some cases of debugging model results, it might indeed even be practical to be able to view the full review. For example, if we’re being too aggressive or conservative with either our &lt;code&gt;n_unique_words&lt;/code&gt; or &lt;code&gt;n_words_to_skip&lt;/code&gt; thresholds, it might become apparent by comparing a review like the one in Figure 11.13 with a full one. With our index of words &lt;code&gt;(index_words)&lt;/code&gt; already available to us, we simply need to download the full reviews:&lt;/p&gt;
&lt;pre title=""&gt;(all_x_train,_),(all_x_valid,_) = imdb.load_data()

&lt;/pre&gt;
&lt;p&gt;Then we modify Example 11.16 to execute &lt;code&gt;join()&lt;/code&gt; on the full-review list of our choice (i.e., &lt;code&gt;all_x_train&lt;/code&gt; or &lt;code&gt;all_x_valid&lt;/code&gt;), as provided in Example 11.17.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example 11.17 Print full review as character string&lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;' '.join(index_word[id] for id in all_x_train[0])

&lt;/pre&gt;
&lt;p&gt;Executing this outputs the full text of the review of our choice—again, in this case, the first training review—as shown in Figure 11.14.&lt;/p&gt;
&lt;p&gt;&lt;img sizes="(max-width: 708px) 100vw, 708px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_14.png 1080w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_14-300x132.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_14-768x337.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_14-1024x449.png 1024w" height="311" width="708" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_14.png" loading="lazy"&gt;&lt;/p&gt;
&lt;h2&gt;Standardizing the Length of the Reviews&lt;/h2&gt;
&lt;p&gt;By executing Example 11.15 earlier, we discovered that there is variability in the length of the film reviews. In order for the Keras-created TensorFlow model to run, we need to specify the size of the inputs that will be flowing into the model during training. This enables TensorFlow to optimize the allocation of memory and compute resources. Keras provides a convenient &lt;code&gt;pad_sequences()&lt;/code&gt; method that enables us to both pad and truncate documents of text in a single line. Here we standardize our training and validation data in this way, as shown in Example 11.18.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example 11.18 Standardizing input length by padding and truncating&lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;       x_train = pad_sequences(x_train, maxlen=max_review_length,
                               padding=pad_type, truncating=trunc_type, value=0)
       x_valid = pad_sequences(x_valid, maxlen=max_review_length,
                               padding=pad_type, truncating=trunc_type, value=0)
       
&lt;/pre&gt;
&lt;p&gt;Now, when printing reviews (e.g., with &lt;code&gt;x_train[0:6]&lt;/code&gt;) or their lengths (e.g., with the code from Example 11.15), we see that all of the reviews have the same length of 100 (because we set &lt;code&gt;max_review_length = 100&lt;/code&gt;). Examining x_train[5]—which previously had a length of only 43 tokens—with code similar to Example 11.16, we can observe that the beginning of the review has been padded with 57 &lt;code&gt;PAD&lt;/code&gt; tokens (see Figure 11.15).&lt;/p&gt;
&lt;p&gt;&lt;img sizes="(max-width: 687px) 100vw, 687px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_15.png 1096w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_15-300x79.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_15-768x202.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_15-1024x269.png 1024w" height="181" width="687" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_15.png" loading="lazy"&gt;&lt;/p&gt;
&lt;h2&gt;Dense Network&lt;/h2&gt;
&lt;p&gt;With sufficient NLP theory behind us, as well as our data loaded and preprocessed, we’re at long last prepared to make use of a neural network architecture to classify film reviews by their sentiment. A baseline dense network model for this task is shown in Example 11.19.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example 11.19 Dense sentiment classifier architecture&lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;model = Sequential()
model.add(Embedding(n_unique_words, n_dim,
                    input_length=max_review_length))
model.add(Flatten())
model.add(Dense(n_dense, activation='relu')) model.add(Dropout(dropout))
# model.add(Dense(n_dense, activation='relu')) 
# model.add(Dropout(dropout)) 
model.add(Dense(1, activation='sigmoid'))

&lt;/pre&gt;
&lt;p&gt;Let’s break the architecture down line by line:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We’re using a Keras &lt;code&gt;Sequential()&lt;/code&gt; method to invoke a sequential model, as we have for all of the models so far in this book.&lt;/li&gt;
&lt;li&gt;As with word2vec, the &lt;code&gt;Embedding()&lt;/code&gt; layer enables us to create word vectors from a corpus of documents—in this case, the 25,000 movie reviews of the IMDb training dataset. Relative to independently creating word vectors with word2vec (or GloVe, etc.) as we did earlier in this chapter, training your word vectors via backpropagation as a component of your broader NLP model has a potential advantage: The locations that words are assigned to within the vector space reflect not only word similarity but also the relevance of the words to the ultimate, specific purpose of the model (e.g., binary classification of IMDb reviews by sentiment). The size of the word-vector vocabulary and the number of dimensions of the vector space are specified by n_unique_words and n_dim, respectively. Because the embedding layer is the first hidden layer in our network, we must also pass into it the shape of our input layer: We do this with the input_length argument.&lt;/li&gt;
&lt;li&gt;As in Chapter 10, the &lt;code&gt;Flatten()&lt;/code&gt; layer enables us to pass a many-dimensional output (here, a two-dimensional output from the embedding layer) into a one- dimensional dense layer.&lt;/li&gt;
&lt;li&gt;Speaking of &lt;code&gt;Dense()&lt;/code&gt; layers, we used a single one consisting of relu activations in this architecture, with applied to it.&lt;/li&gt;
&lt;li&gt;We opted for a fairly shallow neural network architecture for our baseline model, but you can trivially deepen it by adding further &lt;code&gt;Dense()&lt;/code&gt;layers (see the lines that are commented out)./li&amp;gt;&lt;/li&gt;
&lt;li&gt;Finally, because there are only two classes to classify, we require only a single output neuron (because, as discussed earlier in this chapter, if one class has the probability p then the other class has the probability 1 − p). This neuron is sigmoid because we’d like it to output probabilities between 0 and 1 (refer to Figure 6.9).&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;In addition to training word vectors on natural language data alone 
(e.g., with word2vec or GloVe) or training them with an embedding layer 
as part of a deep learning model, pretrained word vectors are also 
available online.

As with using a ConvNet trained on the millions of images in ImageNet 
(Chapter 10), this natural language transfer learning is powerful, because 
these word vectors may have been trained on extremely large corpuses 
(e.g., all of Wikipedia, or the English-language Internet) that provide 
large, nuanced vocabularies that would be expensive to train yourself. 
Examples of pretrained word vectors are available at 
github .com/Kyubyong/wordvectors and nlp.stanford.edu/projects/glove. 
The fast- Text library also offers subword embeddings in 157 languages; 
these can be downloaded from fasttext.cc.

In this book, we don’t cover substituting pretrained word vectors 
(be they down- loaded or trained separately from your deep learning 
model, as we did with &lt;code&gt;Word2Vec()&lt;/code&gt; earlier in this chapter) in place of the embedding layer, because there are many different permutations on how you might like to do this. For a neat tutorial from François Chollet, the creator of Keras, go to bit.ly/preTrained.&lt;/pre&gt;
&lt;p&gt;Executing &lt;code&gt;model.summary()&lt;/code&gt;, we discover that our fairly simple NLP model has quite a few parameters, as shown in Figure 11.16:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In the embedding layer, the 320,000 parameters come from having 5,000 words, each one with a location specified in a 64-dimensional word-vector space (64 × 5,000 = 320,000).&lt;/li&gt;
&lt;li&gt;Flowing out of the embedding layer through the flatten layer and into the dense layer are 6,400 values: Each of our film-review inputs consists of 100 tokens, with each token specified by 64 word-vector-space coordinates (64 × 100 = 6,400).&lt;/li&gt;
&lt;li&gt;Each of the 64 neurons in the dense hidden layer receives input from each of the 6,400 values flowing out of the flatten layer, for a total of 64 × 6,400 = 409,600 weights. And, of course, each of the 64 neurons has a bias, for a total of 409,664 parameters in the layer.&lt;/li&gt;
&lt;li&gt;Finally, the single neuron of the output layer has 64 weights—one for the activation output by each of the neurons in the preceding layer—plus its bias, for a total of 65 parameters.&lt;/li&gt;
&lt;li&gt;Summing up the parameters from each of the layers, we have a grand total of 730,000 of them.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img sizes="(max-width: 547px) 100vw, 547px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_16.png 782w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_16-300x176.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_16-768x452.png 768w" height="322" width="547" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_16.png" loading="lazy"&gt;&lt;/p&gt;
&lt;p&gt;As shown in Example 11.20, we compile our dense sentiment classifier with a line of code that should already be familiar from recent chapters, except that—because we have a single output neuron within a binary classifier—we use &lt;code&gt;binary_crossentropy&lt;/code&gt; cost in place of the &lt;code&gt;categorical_crossentropy&lt;/code&gt; cost we used for our multiclass MNIST classifiers.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example 11.20 Compiling our sentiment classifier&lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;model.compile(loss='binary_crossentropy', optimizer='adam',
              metrics=['accuracy'])

&lt;/pre&gt;
&lt;p&gt;With the code provided in Example 11.21, we create a &lt;code&gt;ModelCheckpoint()&lt;/code&gt; object that will allow us to save our model parameters after each epoch during training. By doing this, we can return to the parameters from our epoch of choice later on during model evaluation or to make inferences in a production system. If the &lt;code&gt;output_dir&lt;/code&gt; directory doesn’t already exist, we use the &lt;code&gt;makedirs()&lt;/code&gt; method to make it.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example 11.21 Creating an object and directory for checkpointing model parameters after each epoch&lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;modelcheckpoint = ModelCheckpoint(filepath=output_dir+
                                  "/weights.{epoch:02d}.hdf5")
if not os.path.exists(output_dir): 
    os.makedirs(output_dir)

&lt;/pre&gt;
&lt;p&gt;###Insert Figure&lt;/p&gt;
&lt;p&gt;Like the compile step, the model-fitting step (Example 11.22) for our sentiment classifier should be familiar except, perhaps, for our use of the callbacks argument to pass in the &lt;code&gt;modelcheckpoint&lt;/code&gt; object. [Note: This isn’t our first use of the callbacks argument. We previously used this argument, which can take in a list of multiple different &lt;code&gt;callbacks&lt;/code&gt;, to provide data on model training progress to TensorBoard (see Chapter 9)].&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example 11.22 Fitting our sentiment classifier&lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;       model.fit(x_train, y_train,
                 batch_size=batch_size, epochs=epochs, verbose=1,
                 validation_data=(x_valid, y_valid),
                 callbacks=[modelcheckpoint])

&lt;/pre&gt;
&lt;p&gt;As shown in Figure 11.17, we achieve our lowest validation loss (0.349) and highest validation accuracy (84.5 percent) in the second epoch. In the third and fourth epochs, the model is heavily overfit, with accuracy on the training set considerably higher than on the validation set. By the fourth epoch, training accuracy stands at 99.6 percent while validation accuracy is much lower, at 83.4 percent.&lt;/p&gt;
&lt;p&gt;&lt;img sizes="(max-width: 753px) 100vw, 753px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_17.png 1094w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_17-300x67.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_17-768x173.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_17-1024x230.png 1024w" height="169" width="753" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_17.png" loading="lazy"&gt;&lt;/p&gt;
&lt;p&gt;To evaluate the results of the best epoch more thoroughly, we use the Keras &lt;code&gt;load_ weights()&lt;/code&gt; method to load the parameters from the second epoch (&lt;code&gt;weights.02.hdf5&lt;/code&gt;) back into our model, as in Example 11.23. [Note: Although the method is called &lt;code&gt;load_weights()&lt;/code&gt;, it loads in all model parameters, including biases. Because weights typically constitute the vast majority of parameters in a model, deep learning practitioners often call parameter files “weights” files. Earlier versions of Keras used zero indexing for epochs, but more recent versions index starting at 1.]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example 11.23 Loading model parameters &lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;model.load_weights(output_dir+"/weights.02.hdf5")
&lt;/pre&gt;
&lt;p&gt;We can then calculate validation set y_hat values for the best epoch by passing the &lt;code&gt;predict_proba()&lt;/code&gt; method on the &lt;code&gt;x_valid&lt;/code&gt; dataset, as shown in Example 11.24.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example 11.24 Predicting y_hat for all validation &lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;y_hat = model.predict_proba(x_valid)

&lt;/pre&gt;
&lt;p&gt;With y_hat[0], for example, we can now see the model’s prediction of the sentiment of the first movie review in the validation set. For this review, &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; = 0.09, indicating the model estimates that there’s a 9 percent chance the review is positive and, therefore, a 91 percent chance it’s negative. Executing y_valid[0] informs us that &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; = 0 for this review—that is, it is in fact a negative review—so the model’s &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; is pretty good! If you’re curious about what the content of the negative review was, you can run a slight modification on Example 11.17 to access the full text of the &lt;code&gt;all_x_valid[0]&lt;/code&gt; list item, as shown in Example 11.25.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example 11.25 Printing a full validation review&lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;' '.join(index_word[id] for id in all_x_valid[0])

&lt;/pre&gt;
&lt;p&gt;Examining individual scores can be interesting, but we get a much better sense of our model’s performance by looking at all of the validation results together. We can plot a histogram of all the validation &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; values by running the code in Example 11.26.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example 11.26 Plotting a histogram of validation data &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; values &lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;plt.hist(y_hat)
_ = plt.axvline(x=0.5, color='orange')

&lt;/pre&gt;
&lt;p&gt;The histogram output is provided in Figure 11.18.&lt;/p&gt;
&lt;p&gt;&lt;img sizes="(max-width: 718px) 100vw, 718px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_18.png 1094w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_18-300x131.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_18-768x336.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_18-1024x447.png 1024w" height="314" width="718" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_18.png" loading="lazy"&gt;&lt;/p&gt;
&lt;p&gt;The plot shows that the model often has a strong opinion on the sentiment of a given review: Some 8,000 of the 25,000 re- views (~32 percent of them) are assigned a &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; of less than 0.1, and ~6,500 (~26 percent) are given a &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; greater than 0.9.&lt;/p&gt;
&lt;p&gt;The vertical orange line in Figure 11.18 marks the 0.5 threshold above which reviews are considered by a simple accuracy calculation to be positive. As discussed earlier in the chapter, such a simple threshold can be misleading, because a review with a yˆ just be- low 0.5 is not predicted by the model to have much difference in sentiment relative to&lt;br&gt;
a review with a &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; just above 0.5. To obtain a more nuanced assessment of our model’s performance as a binary classifier, we can use the &lt;code&gt;roc_auc_score()&lt;/code&gt; method from the &lt;em&gt;scikit-learn&lt;/em&gt; metrics library to straightforwardly calculate the ROC AUC score across the validation data, as shown in Example 11.27.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example 11.27 Calculating ROC AUC for validation data &lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;pct_auc = roc_auc_score(y_valid, y_hat)*100.0
       "{:0.2f}".format(pct_auc)

&lt;/pre&gt;
&lt;p&gt;Printing the output in an easy-to-read format with the &lt;code&gt;format()&lt;/code&gt; method, we see that the percentage of the area under the receiver operating characteristic curve is (a fairly high) 92.9 percent.&lt;/p&gt;
&lt;p&gt;To get a sense of where the model breaks down, we can create a DataFrame of y and &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; validation set values, using the code in Example 11.28.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example 11.28 Creating a &lt;code&gt;ydf&lt;/code&gt; DataFrame of y and ˆy values&lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;float_y_hat = [] for y in y_hat:
           float_y_hat.append(y[0])
       ydf = pd.DataFrame(list(zip(float_y_hat, y_valid)),
                          columns=['y_hat', 'y'])
&lt;/pre&gt;
&lt;p&gt;Printing the first 10 rows of the resulting &lt;code&gt;ydf&lt;/code&gt; DataFrame with &lt;code&gt;ydf.head(10)&lt;/code&gt;, we see the output shown in Figure 11.19.&lt;/p&gt;
&lt;p&gt;&lt;img sizes="(max-width: 541px) 100vw, 541px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_19.png 970w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_19-300x206.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_19-768x527.png 768w" height="372" width="541" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_19.png" loading="lazy"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img sizes="(max-width: 690px) 100vw, 690px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_20.png 1096w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_20-300x117.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_20-768x299.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_20-1024x398.png 1024w" height="268" width="690" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_20.png" loading="lazy"&gt;&lt;/p&gt;
&lt;p&gt;Querying the &lt;code&gt;ydf&lt;/code&gt; DataFrame as we do in Examples 11.29 and 11.30 and then examining the individual reviews these queries surface by varying the list index in Example 11.25, you can get a sense of the kinds of reviews that cause the model to make its largest errors.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example 11.29 Ten cases of negative validation reviews with high &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; scores &lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;ydf[(ydf.y == 0) &amp;amp; (ydf.y_hat &amp;gt; 0.9)].head(10)

&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Example 11.30 Ten cases of positive validation reviews with low &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; scores&lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;ydf[(ydf.y == 0) &amp;amp; (ydf.y_hat &amp;gt; 0.9)].head(10)

&lt;/pre&gt;
&lt;p&gt;An example of a false positive—a negative review (y = 0) with a very high model score (&lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; = 0.97)—that was identified by running the code in Example 11.29 is provided in Figure 11.20. [Note: We output this particular review—the 387th in the validation dataset—by running the following code: &lt;code&gt;' '.join(index_word[id]&lt;/code&gt; for &lt;code&gt;id in all_x_valid[386])&lt;/code&gt;.] And an example of a false negative—a positive review (y = 1) with a very low model score (&lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; = 0.06)—that was identified by running the code in Example 11.30 is provided in Figure 11.21. [Note: R&lt;code&gt;un ' '.join(index_word[id] for id in all_x_valid[224]&lt;/code&gt;) to print out this same review yourself.]&lt;/p&gt;
&lt;p&gt;&lt;img sizes="(max-width: 705px) 100vw, 705px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_21.png 1080w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_21-300x106.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_21-768x272.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_21-1024x362.png 1024w" height="250" width="705" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_21.png" loading="lazy"&gt;&lt;/p&gt;
&lt;p&gt;Carrying out this kind of post hoc analysis of our model, one potential shortcoming that surfaces is that our dense classifier is not specialized to detect patterns of multiple tokens occurring in a sequence that might predict film-review sentiment. For example, it might be handy for patterns like the token-pair not-good to be easily detected by the model as predictive of negative sentiment.&lt;/p&gt;
&lt;h2&gt;Convolutional Networks&lt;/h2&gt;
&lt;p&gt;As covered in Chapter 10, convolutional layers are particularly adept at detecting spatial patterns. In this section, we use them to detect spatial patterns among words—like the &lt;em&gt;not-good&lt;/em&gt; sequence—and see whether they can improve upon the performance of our dense network at classifying film reviews by their sentiment. All of the code for this ConvNet can be found in our &lt;em&gt;Convolutional Sentiment Classifier&lt;/em&gt; notebook.&lt;/p&gt;
&lt;p&gt;The dependencies for this model are identical to those of our dense sentiment classifier (see Example 11.12), except that it has three new Keras layer types, as provided in Example 11.31.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example 11.31 Additional CNN dependencies&lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;from keras.layers import Conv1D, GlobalMaxPooling1D
from keras.layers import SpatialDropout1D

&lt;/pre&gt;
&lt;p&gt;The hyperparameters for our convolutional sentiment classifier are provided in Example 11.32.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example 11.32 Convolutional sentiment classifier hyperparameters &lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;# output directory name:
output_dir = 'model_output/conv'

# training:
epochs = 4
batch_size = 128

# vector-space embedding:
n_dim = 64
n_unique_words = 5000 
max_review_length = 400 
pad_type = trunc_type = 'pre' 
drop_embed = 0.2 # new!

# convolutional layer architecture: 
n_conv = 256 # filters, a.k.a. kernels 
k_conv = 3 # kernel length

# dense layer architecture:
n_dense = 256
dropout = 0.2

&lt;/pre&gt;
&lt;p&gt;Relative to the hyperparameters from our dense sentiment classifier (see Example 11.13):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We have a new, unique directory name (‘&lt;code&gt;conv&lt;/code&gt;‘) for storing model parameters after each epoch of training.&lt;/li&gt;
&lt;li&gt;Our number of epochs and batch size remain the same.&lt;/li&gt;
&lt;li&gt;Our vector-space embedding hyperparameters remain the same, except that
&lt;ul&gt;
&lt;li&gt;We quadrupled &lt;code&gt;max_review_length&lt;/code&gt; to 400. We did this because, despite the fairly dramatic increase in input volume as well as an increase in our number of hidden layers, our convolutional classifier will still have far fewer parameters relative to our dense sentiment classifier.&lt;/li&gt;
&lt;li&gt;With &lt;code&gt;drop_embed&lt;/code&gt;, we’ll be adding dropout to our embedding layer.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Our convolutional sentiment classifier will have two hidden layers after the embedding layer:
&lt;ul&gt;
&lt;li&gt;A convolutional layer with 256 filters (&lt;code&gt;n_conv&lt;/code&gt;), each with a single dimension (a length) of 3 (&lt;code&gt;k_conv&lt;/code&gt;). When working with two-dimensional images in Chapter 10, our convolutional layers had filters with two dimensions. Natural language—be it written or spoken—has only one dimension associated with it (the dimension of time) and so the convolutional layers used in this chapter will have one-dimensional filters.&lt;/li&gt;
&lt;li&gt;A dense layer with 256 neurons (&lt;code&gt;n_dense&lt;/code&gt;) and dropout of 20 percent.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The steps for loading the IMDb data and standardizing the length of the reviews are identical to those in our &lt;em&gt;Dense Sentiment Classifier notebook&lt;/em&gt; (see Examples 11.14 and 11.18). The model architecture is of course rather different, and is provided in Example 11.33.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example 11.33 Convolutional sentiment classifier architecture&lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;model = Sequential()

# vector-space embedding:
model.add(Embedding(n_unique_words, n_dim,
                    input_length=max_review_length))
model.add(SpatialDropout1D(drop_embed))

# convolutional layer:
model.add(Conv1D(n_conv, k_conv, activation='relu'))
# model.add(Conv1D(n_conv, k_conv, activation='relu')) model.add(GlobalMaxPooling1D())

# dense layer:
model.add(Dense(n_dense, activation='relu'))
model.add(Dropout(dropout))

# output layer:
model.add(Dense(1, activation='sigmoid'))

&lt;/pre&gt;
&lt;p&gt;Breaking the model down:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Our embedding layer is the same as before, except that it now has dropout applied to it.&lt;/li&gt;
&lt;li&gt;We no longer require &lt;code&gt;Flatten()&lt;/code&gt;, because the &lt;code&gt;Conv1D()&lt;/code&gt;layer takes in both dimensions of the embedding layer output.&lt;/li&gt;
&lt;li&gt;We use &lt;code&gt;relu&lt;/code&gt; activation within our one-dimensional convolutional layer. The layer has 256 unique filters, each of which is free to specialize in activating when it passes over a particular three-token sequence. The activation map for each of the 256 filters has a length of 398, for a 256×398 output shape. [Note: As described in Chapter 10, when a two-dimensional filter convolves over an image, we lose pixels around the perimeter if we don’t pad the image first. In this natural language model, our one-dimensional convolutional filter has a length of three, so, on the far left of the movie review, it begins centered on the second token and, on the far right, it ends centered on the second-to-last token. Because we didn’t pad the movie reviews at both ends before feeding them into the convolutional layer, we thus lose a token’s worth of information from each end: 400 − 1 − 1 = 398. We’re not upset about this loss.&lt;/li&gt;
&lt;li&gt;If you fancy it, you’re welcome to add additional convolutional layers, by, for example, uncommenting the second &lt;code&gt;Conv1D()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Global max-pooling&lt;/em&gt; is common for dimensionality reduction within deep learning NLP models. We use it here to squash the activation map from 256 × 398 to 256 × 1. By applying it, only the magnitude of largest activation for a given convolutional filter is retained by the maximum-calculating operation, and we lose any temporal-position-specific information the filter may have output to its 398-element-long activation map.&lt;/li&gt;
&lt;li&gt;Because the activations output from the global max-pooling layer are one- dimensional, they can be fed directly into the dense layer, which consists (again) of relu neurons and dropout is applied.&lt;/li&gt;
&lt;li&gt;The output layer remains the same.&lt;/li&gt;
&lt;li&gt;The model has a grand total of 435,000 parameters (see Figure 11.22), several hundred thousand fewer than our dense sentiment classifier. Per epoch, this model will nevertheless take longer to train because the convolutional operation is relatively computationally expensive.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img sizes="(max-width: 619px) 100vw, 619px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_22.png 872w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_22-300x180.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_22-768x460.png 768w" height="371" width="619" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_22.png" loading="lazy"&gt;&lt;/p&gt;
&lt;p&gt;A critical item to note about this model architecture is that the convolutional filters are not detecting simply triplets of &lt;em&gt;words&lt;/em&gt;. Rather, they are detecting triplets of word vectors. Following from our discussion in Chapter 2, contrasting discrete, one-hot word representations with the word-vector representations that gently smear meaning across a high-dimensional space (see Table 2.1), all of the models in this chapter become specialized in associating word &lt;em&gt;meaning&lt;/em&gt; with review sentiment—as opposed to merely associating individual words with review sentiment. As an example, if the network learns that the token pair not-good is associated with a negative review, then it should also associate the pair not-great with negative reviews, because &lt;em&gt;good&lt;/em&gt; and &lt;em&gt;great&lt;/em&gt; have similar meanings (and thus should occupy a similar location in word-vector space).&lt;/p&gt;
&lt;p&gt;The compile, checkpoint, and model-fitting steps are the same as for our dense sentiment classifier (see Examples 11.20, 11.21, and 11.22, respectively). Model-fitting progress is shown in Figure 11.23. The epoch with the lowest validation loss (0.258) and highest validation accuracy (89.6 percent) was the third epoch. Loading the model parameters from that epoch back in (with the code from Example 11.23 but specifying &lt;code&gt;weights.03.hdf5&lt;/code&gt;), we then predict &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; for all validation data (exactly as in Example 11.24). Creating a histogram (Figure 11.24) of these &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; values (with the same code as in Example 11.26), we can see visually that our CNN has a stronger opinion of review sentiment than our dense network did (refer to Figure 11.18): There are about a thousand more reviews with &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; &amp;lt; 0.1 and several thousand more with &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; &amp;gt; 0.9. Calculating ROC AUC (with the code from Example 11.27), we output a very high score of 96.12 percent, indicating that the CNN’s confidence was not misplaced: It is a marked improvement over the already high ~93 percent score of the dense net.&lt;/p&gt;
&lt;p&gt;&lt;img sizes="(max-width: 782px) 100vw, 782px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_23.png 1094w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_23-300x65.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_23-768x167.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_23-1024x223.png 1024w" height="171" width="782" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_23.png" loading="lazy"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img sizes="(max-width: 727px) 100vw, 727px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_24.png 1016w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_24-300x135.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_24-768x346.png 768w" height="328" width="727" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_24.png" loading="lazy"&gt;&lt;/p&gt;
&lt;h2&gt;Networks Designed for Sequential Data&lt;/h2&gt;
&lt;p&gt;Our ConvNet classifier outperformed our dense net—perhaps in large part because its convolutional layer is adept at learning patterns of words that predict some outcome, such as whether a film review is favorable or negative. The filters within convolutional layers tend to excel at learning short sequences like triplets of words (recall that we set &lt;code&gt;k = 3&lt;/code&gt; in Example 11.32), but a document of natural language like a movie review might contain much longer sequences of words that, when considered all together, would enable the model to accurately predict some outcome. To handle long sequences of data like this, there exists a family of deep learning models called recurrent neural networks (RNNs), which include specialized layer types like long short-term memory units (LSTMs) and &lt;em&gt;gated recurrent units&lt;/em&gt; (GRUs). In this section, we cover the essential theory of RNNs and apply several variants of them to our movie-review classification problem. We also introduce &lt;em&gt;attention&lt;/em&gt;—an especially sophisticated approach to modeling natural language data that is setting new benchmarks across NLP applications.&lt;/p&gt;
&lt;pre&gt;As mentioned at the start of the chapter, the RNN family, including LSTMs and GRUs, 
is well suited to handling not only natural language data but also any input data 
that occur in a one-dimensional sequence. This includes price data (e.g., financial 
time series, stock prices), sales figures, temperatures, and disease rates (epidemiology). 
While RNN applications other than NLP are beyond the scope of this textbook, we collate 
resources for modeling quantitative data over time at jonkrohn.com/resources under the 
heading &lt;em&gt;Time Series Prediction&lt;/em&gt;.

&lt;/pre&gt;
&lt;h2&gt;Recurrent Neural Networks&lt;/h2&gt;
&lt;p&gt;Consider the following sentences:&lt;/p&gt;
&lt;p&gt;Jon and Grant are writing a book together. They have really enjoyed writing it.&lt;/p&gt;
&lt;p&gt;The human mind can track the concepts in the second sentence quite easily. You already know that “they” in the second sentence refers to your authors, and “it” refers to the book we’re writing. Although this task is easy for you, however, it is not so trivial for a neural network.&lt;/p&gt;
&lt;p&gt;The convolutional sentiment classifier we built in the previous section was able to consider a word only in the context of the two words on either side of it (&lt;code&gt;k_conv = 3&lt;/code&gt;, as in Example 11.32). With such a small window of text, that neural network had no capacity to assess what “they” or “it” might be referring to. Our human brains can do it because our thoughts loop around each other, and we revisit earlier ideas in order to in- form our understanding of the current context. In this section we introduce the concept of recurrent neural networks, which set out to do just that: They have loops built into their structure that allow information to persist over time.&lt;/p&gt;
&lt;p&gt;The high-level structure of a recurrent neural network (RNN) is shown in Figure 11.25. On the left, the purple line indicates the loop that passes information between steps in the network. As in a dense network, where there is a neuron for each input, so too is there a neuron for each input here. We can observe this more easily on the right, where the schematic of the RNN is unpacked. There is a recurrent module for each word in the sentence (only the first four words are shown here for brevity).[Note: This is also why we have to pad shorter sentences during preprocessing: The RNN expects a sequence of a particular length, and so if the sequence is not long enough we add PAD tokens to make up the difference.] However, each module receives an additional input from the previous module, and in doing so the network is able to pass along information from earlier timesteps in the sequence. In the case of Figure 11.25, each word is represented by a distinct timestep in the RNN sequence, so the network might be able to learn that “Jon” and “Grant” were writing the book, thereby associating these terms with the word “they” that occurs later in the sequence.&lt;/p&gt;
&lt;p&gt;&lt;img sizes="(max-width: 603px) 100vw, 603px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_25.png 1000w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_25-300x169.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_25-768x432.png 768w" height="340" width="603" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_25.png" loading="lazy"&gt;&lt;/p&gt;
&lt;p&gt;Recurrent neural networks are, computationally, more complex to train than exclusively “feedforward” neural networks like the dense nets and CNNs we’ve used so far in the book. As depicted in Figure 8.6, feedforward networks involve backpropagating cost from the output layer back toward the input layer. If a network includes a recurrent layer (such as &lt;code&gt;SimpleRNN&lt;/code&gt;, &lt;code&gt;LSTM&lt;/code&gt;, or &lt;code&gt;GRU&lt;/code&gt;), then the cost must be backpropagated not only back toward the input layer, but back over the timesteps of the recurrent layer (from later timesteps back toward earlier timesteps), as well. Note that, in the same way that the gradient of learning vanishes as we backpropagate over later hidden layers toward earlier ones (see Figure 8.8), so, too, does the gradient vanish as we backpropagate over later timesteps within a recurrent layer toward earlier ones. Because of this, later timesteps in a sequence have more influence within the model than earlier ones do. [Note: If you suspect that the beginning of your sequences (e.g., the words at the beginning of a movie review) is generally more relevant to the problem you’re solving with your model (sentiment classification) than the end (the words at the end of the review), you can reverse the sequence before passing it as an input into your network. In that way, within your network’s recurrent layers, the beginning of the sequence will be backpropagated over before the end is.]&lt;/p&gt;
&lt;h2&gt;Implementing an RNN in Keras&lt;/h2&gt;
&lt;p&gt;Adding a recurrent layer to a neural network architecture to create an RNN is straightforward in Keras, as we illustrate in our &lt;em&gt;RNN Sentiment Classifier&lt;/em&gt; Jupyter notebook [or the &lt;a href="https://try.dominodatalab.com/u/domino-andrealowe/Natural-Language-Processing/overview"&gt;complementary Domino project&lt;/a&gt;]. For the sake of brevity and readability, please note that the following code cells are identical across all the Jupyter notebooks in this chapter, including the &lt;em&gt;Dense and Convolutional Sentiment Classifier&lt;/em&gt; notebooks that we’ve already covered:&lt;/p&gt;

&lt;p&gt;The code cells that vary are those in which we:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Set hyperparameters&lt;/li&gt;
&lt;li&gt;Design the neural network architecture&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The hyperparameters for our RNN are as shown in Example 11.34.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example 11.34 RNN sentiment classifier hyperparameters&lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;# output directory name:
output_dir = 'model_output/rnn'

# training:
epochs = 16 # way more!
batch_size = 128

# vector-space embedding:
n_dim = 64
n_unique_words = 10000
max_review_length = 100 # lowered due to vanishing gradient over time pad_type = trunc_type = 'pre'
drop_embed = 0.2
# RNN layer architecture:
n_rnn = 256
drop_rnn = 0.2

&lt;/pre&gt;
&lt;p&gt;Changes relative to our previous sentiment classifier notebooks are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We quadrupled epochs of training to 16 because overfitting didn’t occur in the early epochs.&lt;/li&gt;
&lt;li&gt;We lowered &lt;code&gt;max_review_length&lt;/code&gt; back down to 100, although even this is excessive for a simple RNN. We can backpropagate over about 100 timesteps (i.e., 100 tokens or words in a natural language model) with an LSTM (covered in the next section) before the gradient of learning vanishes completely, but the gradient in a plain old RNN vanishes completely after about 10 timesteps. Thus, max_review_length could probably be lowered to less than 10 before we would notice a reduction in this model’s performance.&lt;/li&gt;
&lt;li&gt;For all of the RNN-family architectures in this chapter, we experimented with doubling the word-vector vocabulary to 10000 tokens. This seemed to provide improved results for these architectures, although we didn’t test it rigorously.&lt;/li&gt;
&lt;li&gt;We set &lt;code&gt;n_rnn = 256&lt;/code&gt;, so we could say that this recurrent layer has 256 &lt;em&gt;units&lt;/em&gt;, or, alternatively, we could say it has 256 &lt;em&gt;cells&lt;/em&gt;. In the same way that having 256 convolutional filters enabled our CNN model to specialize in detecting 256 unique triplets of word meaning,43 this setting enables our RNN to detect 256 unique sequences of word meaning that may be relevant to review sentiment. [Note: “Word meaning” here refers to a location in word-vector space]&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Our RNN model architecture is provided in Example 11.35.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example 11.35 RNN sentiment classifier architecture&lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;from keras.layers import SimpleRNN

model = Sequential()
model.add(Embedding(n_unique_words, n_dim,
                    input_length=max_review_length))
model.add(SpatialDropout1D(drop_embed))
model.add(SimpleRNN(n_rnn, dropout=drop_rnn))
model.add(Dense(1, activation='sigmoid'))

&lt;/pre&gt;
&lt;p&gt;In place of a convolutional layer or a dense layer (or both) within the hidden layers of this model, we have a Keras &lt;code&gt;SimpleRNN()&lt;/code&gt; layer, which has a dropout argument; as a result, we didn’t need to add dropout in a separate line of code. Unlike putting a dense layer after a convolutional layer, it is relatively uncommon to add a dense layer after a recurrent layer, because it provides little performance advantage. You’re welcome to try it by adding in a &lt;code&gt;Dense()&lt;/code&gt; hidden layer anyway.&lt;/p&gt;
&lt;p&gt;The results of running this model (which are shown in full in our &lt;em&gt;RNN Sentiment Classifier&lt;/em&gt; notebook) were not encouraging. We found that the training loss, after going down steadily over the first half-dozen epochs, began to jump around after that. This indicates that the model is struggling to learn patterns even within the training data, which—relative to the validation data—it should be readily able to do. Indeed, all of the models fit so far in this book have had training losses that reliably attenuated epoch over epoch.&lt;/p&gt;
&lt;p&gt;As the training loss bounced around, so too did the validation loss. We observed the lowest validation loss in the seventh epoch (0.504), which corresponded to a validation accuracy of 77.6 percent and an ROC AUC of 84.9 percent. All three of these metrics are our worst yet for a sentiment classifier model. This is because, as we mentioned earlier in this section, RNNs are only able to backpropagate through ~10 time steps before the gradient diminishes so much that parameter updates become negligibly small. Because of this, simple RNNs are rarely used in practice: More-sophisticated recurrent layer types like LSTMs, which can backpropagate through ~100 time steps, are far more common.[Note: The only situation we could think of where a simple RNN would be practical is one where your sequences only had 10 or fewer consecutive timesteps of information that are relevant to the problem you’re solving with your model. This might be the case with some time series forecasting models or if you only had very short strings of natural language in your dataset.]&lt;/p&gt;
&lt;h2&gt;Long Short-Term Memory Units&lt;/h2&gt;
&lt;p&gt;As stated at the end of the preceding section, simple RNNs are adequate if the space between the relevant information and the context where it’s needed is small (fewer than 10 timesteps); however, if the task requires a broader context (which is often the case in NLP tasks), there is another recurrent layer type that is well suited to it: long short-term memory units, or LSTMs.&lt;/p&gt;
&lt;p&gt;LSTMs were introduced by Sepp Hochreiter and Jürgen Schmidhuber in 1997,[Note: Hochreiter, S., &amp;amp; Schmidhuber, J. (1997). Long short-term memory. Neural Computation, 9, 1735–80.] but they are more widely used in NLP deep learning applications today than ever before. The basic structure of an LSTM layer is the same as the simple recurrent layers captured in Figure 11.25.&lt;/p&gt;
&lt;p&gt;LSTMs receive input from the sequence of data (e.g., a particular token from a natural language document), and they also receive input from the previous time point in the sequence. The difference is that inside each cell in a simple recurrent layer (e.g., &lt;code&gt;SimpleRNN()&lt;/code&gt; in Keras), you’ll find a single neural network activation function such as a tanh function, which transforms the RNN cell’s inputs to generate its output. In contrast, the cells of an LSTM layer contain a far more complex structure, as depicted in Figure 11.26.&lt;/p&gt;
&lt;p&gt;&lt;img sizes="(max-width: 567px) 100vw, 567px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_26.png 1078w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_26-300x230.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_26-768x588.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_26-1024x785.png 1024w" height="434" width="567" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_26.png" loading="lazy"&gt;&lt;/p&gt;
&lt;p&gt;This schematic can appear daunting, and, admittedly, we agree that a full step-by-step breakdown of each component inside of an LSTM cell is unnecessarily detailed for this book. [Note: For a thorough exposition of LSTM cells, we recommend Christopher Olah’s highly visual explainer, which is available at bit.ly/colahLSTM.] That said, there are a few key points that we should nevertheless touch on here. The first is the &lt;em&gt;cell state&lt;/em&gt; running across the top of the LSTM cell. Notice that the cell state does not pass through any nonlinear activation functions. In fact, the cell state only undergoes some minor linear transformations, but otherwise it simply passes through from cell to cell. Those two linear transformations (a multiplication and an addition operation) are points where a cell in an LSTM layer can add information to the cell state, information that will be passed onto the next cell in the layer. In either case, there is a sigmoid activation (represented by σ in the figure) &lt;em&gt;before&lt;/em&gt; the information is added to the cell state. Because a sigmoid activation produces values between 0 and 1, these sigmoids act as “gates” that decide whether new information (from the current timestep) is added to the cell state or not.&lt;/p&gt;
&lt;p&gt;The new information at the current timestep is a simple concatenation of the current timestep’s input and the hidden state from the preceding timestep. This concatenation has two chances to be incorporated into the cell state—either linearly or following a nonlin- ear tanh activation—and in either case it’s those sigmoid gates that decide whether the information is combined.&lt;/p&gt;
&lt;p&gt;After the LSTM has determined what information to add to the cell state, another sigmoid gate decides whether the information from the current input is added to the final cell state, and this results in the output for the current timestep. Notice that, under a different name (“hidden state”), the output is also sent into the next LSTM module (which represents the next timestep in the sequence), where it is combined with the next timestep’s input to begin the whole process again, and that (alongside the hidden state) the final cell state is also sent to the module representing the next timestep.&lt;/p&gt;
&lt;p&gt;We know this might be a lot to come to grips with. Another way to distill this LSTM content is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The cell state enables information to persist along the length of the sequence, through each timestep in a given LSTM cell. It is the &lt;em&gt;long&lt;/em&gt;-term memory of the LSTM.&lt;/li&gt;
&lt;li&gt;The hidden state is analogous to the recurrent connections in a simple RNN and represents the short-term memory of the LSTM.&lt;/li&gt;
&lt;li&gt;Each module represents a particular point in the sequence of data (e.g., a particular token from a natural language document).&lt;/li&gt;
&lt;li&gt;At each timestep, several decisions are made (using those sigmoid gates) about whether the information at that particular timestep in the sequence is relevant to the local (hidden state) and global (cell state) contexts.&lt;/li&gt;
&lt;li&gt;The first two sigmoid gates determine whether the information from the current timestep is relevant to the global context (the cell state) and how it will be com- bined into that stream.&lt;/li&gt;
&lt;li&gt;The final sigmoid gate determines whether the information from the current timestep is relevant to the local context (i.e., whether it is added to the hidden state, which doubles as the output for the current timestep).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We recommend taking a moment to reconsider Figure 11.26 and see if you can follow how information moves through an LSTM cell. This task should be easier if you keep in mind that the sigmoid gates decide whether information is let through or not. Regardless, the primary take-aways from this section are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Simple RNN cells pass only one type of information (the hidden state) between timesteps and contain only one activation function.&lt;/li&gt;
&lt;li&gt;LSTM cells are markedly more complex: They pass two types of information between timesteps (hidden state and cell state) and contain five activation functions.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Implementing an LSTM with Keras&lt;/h2&gt;
&lt;p&gt;Despite all of their additional computational complexity, as demonstrated within our &lt;em&gt;LSTM Sentiment Classifier&lt;/em&gt; notebook, implementing LSTMs with Keras is a breeze. As shown in Example 11.36, we selected the same hyperparameters for our LSTM as we did for our simple RNN, except:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We changed the output directory name.&lt;/li&gt;
&lt;li&gt;We updated variable names to &lt;code&gt;n_lstm&lt;/code&gt; and &lt;code&gt;drop_lstm&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;We reduced the number of epochs of training to 4 because the LSTM begins to overfit to the training data much earlier than the simple RNN.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Example 11.36 LSTM sentiment classifier hyperparameters&lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;# output directory name:
output_dir = 'model_output/LSTM'

# training:
epochs = 4
batch_size = 128

# vector-space embedding:
n_dim = 64
n_unique_words = 10000
max_review_length = 100
pad_type = trunc_type = 'pre'
drop_embed = 0.2

# LSTM layer architecture:
n_lstm = 256
drop_lstm = 0.2

&lt;/pre&gt;
&lt;p&gt;Our LSTM model architecture is also the same as our RNN architecture, except that we replaced the &lt;code&gt;SimpleRNN()&lt;/code&gt; layer with &lt;code&gt;LSTM()&lt;/code&gt;; see Example 11.37.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example 11.37 LSTM sentiment classifier architecture &lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;from keras.layers import LSTM

model = Sequential()
model.add(Embedding(n_unique_words, n_dim,
                    input_length=max_review_length))
model.add(SpatialDropout1D(drop_embed))
model.add(LSTM(n_lstm, dropout=drop_lstm))
model.add(Dense(1, activation='sigmoid'))

&lt;/pre&gt;
&lt;p&gt;The results of training the LSTM are provided in full in our &lt;em&gt;LSTM Sentiment Classifier&lt;/em&gt; notebook. To summarize, training loss decreased steadily epoch over epoch, suggesting that model-fitting proceeded more conventionally than with our simple RNN. The results are not a slam dunk, however. Despite its relative sophistication, our LSTM per- formed only as well as our baseline dense model. The LSTM’s epoch with the lowest validation loss is the second one (0.349); it had a validation accuracy of 84.8 percent and an ROC AUC of 92.8 percent.&lt;/p&gt;
&lt;h2&gt;Bidirectional LSTMs&lt;/h2&gt;
&lt;p&gt;Bidirectional LSTMs (or Bi-LSTMs, for short) are a clever variation on standard LSTMs. Whereas the latter involve backpropagation in only one direction (typically backward over timesteps, such as from the end of a movie review toward the beginning), bidirectional LSTMs involve backpropagation in both directions (backward &lt;em&gt;and forward&lt;/em&gt; over timesteps) across some one-dimensional input. This extra backpropagation doubles computational complexity, but if accuracy is paramount to your application, it is often worth it: Bi-LSTMs are a popular choice in modern NLP applications because their ability to learn patterns both before and after a given token within an input document facilitates high-performing models.&lt;/p&gt;
&lt;p&gt;Converting our LSTM architecture (Example 11.37) into a Bi-LSTM architecture is painless. We need only wrap our &lt;code&gt;LSTM()&lt;/code&gt; layer within the &lt;code&gt;Bidirectional()&lt;/code&gt; wrapper, as shown in Example 11.38.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example 11.38 Bidirectional LSTM sentiment classifier architecture &lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;from keras.layers import LSTM

from keras.layers.wrappers import Bidirectional # new!
       model = Sequential()
       model.add(Embedding(n_unique_words, n_dim,
                           input_length=max_review_length))
       model.add(SpatialDropout1D(drop_embed))
       model.add(Bidirectional(LSTM(n_lstm, dropout=drop_lstm)))
       model.add(Dense(1, activation='sigmoid'))

&lt;/pre&gt;
&lt;p&gt;The straightforward conversion from LSTM to Bi-LSTM yielded substantial performance gains, as the results of model-fitting show (provided in full in our &lt;em&gt;Bi LSTM Sentiment Classifier&lt;/em&gt; notebook). The epoch with the lowest validation loss (0.331) was the fourth, which had validation accuracy of 86.0 percent and an ROC AUC of 93.5 per- cent, making it our second-best model so far as it trails behind only our convolutional architecture.&lt;/p&gt;
&lt;h2&gt;Stacked Recurrent Models&lt;/h2&gt;
&lt;p&gt;Stacking multiple RNN-family layers (be they &lt;code&gt;SimpleRNN()&lt;/code&gt;, &lt;code&gt;LSTM&lt;/code&gt;, or another type) is not quite as straightforward as stacking dense or convolutional layers in Keras—although it certainly isn’t difficult: It requires only specifying an extra argument when the layer is defined.&lt;/p&gt;
&lt;p&gt;As we’ve discussed, recurrent layers take in an ordered sequence of inputs. The recurrent nature of these layers comes from their processing each timestep in the sequence and passing along a hidden state as an input to the next timestep in the sequence. Upon reaching the &lt;em&gt;final&lt;/em&gt; timestep in the sequence, the output of a recurrent layer is the final hidden state.&lt;/p&gt;
&lt;p&gt;So in order to stack recurrent layers, we use the argument &lt;code&gt;return_sequences=True&lt;/code&gt;. This asks the recurrent layer to return the hidden states for each step in the layer’s sequence. The resulting output now has three dimensions, matching the dimensions of the input sequence that was fed into it. The default behavior of a recurrent layer is to pass only the &lt;em&gt;final&lt;/em&gt; hidden state to the next layer. This works perfectly well if we’re passing this information to, say, a dense layer. If, however, we’d like the subsequent layer in our network to be another recurrent layer, that subsequent recurrent layer must receive a sequence as its input. Thus, to pass the array of hidden states from across all individual timesteps in the sequence (as opposed to only the single final hidden state value) to this subsequent recurrent layer, we set the optional &lt;code&gt;return_sequences&lt;/code&gt; argument to &lt;code&gt;True&lt;/code&gt;. [Note: There is also a return_state argument (which, like return_sequences, defaults to False) that asks the network to return the final cell state in addition to the final hidden state. This optional argument is not used as often, but it is useful when we’d like to initialize a recurrent layer’s cell state with that of another layer, as we do in “encoder-decoder” models (introduced in the next section)]&lt;/p&gt;
&lt;p&gt;To observe this in action, check out the two-layer Bi-LSTM model shown in Example 11.39. (Notice that in this example we still leave the final recurrent layer with its default &lt;code&gt;return_sequences=False&lt;/code&gt; so that only the final hidden state of this final recurrent layer is returned for use further downstream in the network.)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example 11.39 Stacked recurrent model architecture&lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;from keras.layers import LSTM
from keras.layers.wrappers import Bidirectional

model = Sequential()
model.add(Embedding(n_unique_words, n_dim,
                    input_length=max_review_length))
model.add(SpatialDropout1D(drop_embed))
model.add(Bidirectional(LSTM(n_lstm_1, dropout=drop_lstm, 
                    return_sequences=True))) # new!
model.add(Bidirectional(LSTM(n_lstm_2, dropout=drop_lstm)))
model.add(Dense(1, activation='sigmoid'))

&lt;/pre&gt;
&lt;p&gt;As you’ve discovered a number of times since Chapter 1 of this book, additional layers within a neural network model can enable it to learn increasingly complex and abstract representations. In this case, the abstraction facilitated by the supplementary Bi-LSTM layer translated to performance gains. The stacked Bi-LSTM outperformed its unstacked cousin by a noteworthy margin, with an ROC AUC of 94.9 percent and validation accuracy of 87.8 percent in its best epoch (the second, with its validation loss of 0.296). The full results are provided in our &lt;em&gt;Stacked Bi LSTM Sentiment Classifier&lt;/em&gt; notebook.&lt;/p&gt;
&lt;p&gt;The performance of our stacked Bi-LSTM architecture, despite being considerably more sophisticated than our convolutional architecture and despite being designed specifically to handle sequential data like natural language, nevertheless lags behind the accuracy of our ConvNet model. Perhaps some hyperparameter experimentation and fine-tuning would yield better results, but ultimately our hypothesis is that because the IMDb film review dataset is so small, our LSTM models don’t have an opportunity to demonstrate their potential. We opine that a much larger natural language dataset would facilitate effective backpropagation over the many timesteps associated with LSTM layers. [Note: If you’d like to test our hypothesis yourself, we provide appropriate sentiment analysis dataset suggestions in Chapter 14.]&lt;/p&gt;
&lt;pre&gt;A relative of the LSTM within the family of RNNs is the gated recurrent unit 
(GRU). GRUs are slightly less computationally intensive than LSTMs because 
they involve only three activation functions, and yet their performance often 
approaches the performance of LSTMs. If a bit more compute isn’t a deal breaker 
for you, we see little advantage in choosing a GRU over an LSTM. If you’re 
interested in trying a GRU in Keras anyway, it’s as easy as importing the GRU() 
layer type and dropping it into a model architecture where you might otherwise 
place an LSTM() layer. Check out our &lt;em&gt;GRU Sentiment Classifier&lt;/em&gt; notebook 
for a hands-on example. [Note: Cho, K., et al. (2014). Learning phrase 
representations using RNN encoder-decoder for statistical machine translation. 
arXiv:1406.1078.]
&lt;/pre&gt;
&lt;h2&gt;Seq2seq and Attention&lt;/h2&gt;
&lt;p&gt;Natural language techniques that involve so-called &lt;em&gt;sequence-to-sequence&lt;/em&gt; (seq2seq; pronounced “seek-to-seek”) models take in an input sequence and generate an output sequence as their product. &lt;em&gt;Neural machine translation&lt;/em&gt; (NMT) is a quintessential class of seq2seq models, with Google Translate’s machine-translation algorithm serving as an example of NMT being used in a production system. [Note: Google Translate has incorporated NMT since 2016. You can read more about it at bit.ly/translateNMT.]&lt;/p&gt;
&lt;p&gt;NMTs consist of an &lt;em&gt;encoder-decoder&lt;/em&gt; structure, wherein the encoder processes the input sequence and the decoder generates the output sequence. The encoder and decoder are both RNNs, and so during the encoding step there exists a hidden state that is passed between units of the RNN. At the end of the encoding phase, the final hidden state is passed to the decoder; this final state can be referred to as the “context.” In this way, the decoder &lt;em&gt;starts&lt;/em&gt; with a context for what is happening in the input sequence. Although this idea is sound in theory, the context is often a bottleneck: It’s difficult for models to handle really long sequences, and so the context loses its punch.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Attention&lt;/em&gt; was developed to overcome the computational bottleneck associated with context. [Note: Bahdanau, D., et al. (2014). Neural machine translation by jointly learning to align and translate. arXiv:1409.0473]. In a nutshell, instead of passing a single hidden state vector (the final one) from the encoder to the decoder, with attention we pass the full sequence of hidden states to the decoder. Each of these hidden states is associated with a single step in the input sequence, although the decoder might need the context from multiple steps in the input to inform its behavior at any given step during decoding. To achieve this, for each step in the sequence the decoder calculates a score for each of the hidden states from the encoder. Each encoder hidden state is multiplied by the softmax of its score. [Note: Recall from Chapter 6 that the softmax function takes a vector of real numbers and generates a probability distribution with the same number of classes as the input vector.]&lt;/p&gt;
&lt;p&gt;This serves to amplify the most relevant contexts (they would have high scores, and thus higher softmax probabilities) while muting the ones that aren’t relevant; in essence, attention weights the available contexts for a given timestep. The weighted hidden states are summed, and this new context vector is used to predict the output for each timestep in the decoder sequence.&lt;/p&gt;
&lt;p&gt;Following this approach, the model selectively reviews what it knows about the input sequence and uses only the relevant information where necessary to inform the output. It’s &lt;em&gt;paying attention&lt;/em&gt; to the most relevant elements of the whole sentence! If this book were dedicated solely to NLP, we’d have at least a chapter covering seq2seq and attention. As it stands, we’ll have to leave it to you to further explore these techniques, which are raising the bar of the performance of many NLP applications.&lt;/p&gt;
&lt;h2&gt;Transfer Learning in NLP&lt;/h2&gt;
&lt;p&gt;Machine vision practitioners have for a number of years been helped along by the ready availability of nuanced models that have been pretrained on large, rich datasets. As covered in the “Transfer Learning” section near the end of Chapter 10, casual users can download model architectures with pretrained weights and rapidly scale up their particular vision application to a state-of-the-art model. Well, more recently, such transfer learning has become readily available for NLP, too. [Note:When we introduced Keras Embedding() layers earlier in this chapter, we touched on transfer learning with word vectors. The transfer learning approaches covered in this section—ULMFiT, ELMo, and BERT—are closer in spirit to the transfer learning of machine vision, because (analogous to the hierarchical visual features that are represented by a deep CNN; see Figure 1.17) they allow for the hierarchical representation of the elements of natural language (e.g., subwords, words, and context, as in Figure 2.9). Word vectors, in contrast, have no hierarchy; they capture only the word level of language.]&lt;/p&gt;
&lt;p&gt;First came ULMFiT (universal language model fine-tuning), wherein tools were described and open-sourced that enabled others to use a lot of what the model learns during pretraining. [Note: Howard, J., and Ruder, S. (2018). Universal language model fine-tuning for text classification. arXiv:1801.06146] In this way, models can be fine-tuned on task-specific data, thus requiring less training time and fewer data to attain high-accuracy results.&lt;/p&gt;
&lt;p&gt;Shortly thereafter, ELMo (embeddings from language models) was revealed to the world. [Note: Peters, M.E., et al. (2018). Deep contextualized word representations. arXiv:1802.05365.] In this update to the standard word vectors we introduced in this chapter, the word embeddings are dependent not only on the word itself but also on the context in which the word occurs. In place of a fixed word embedding for each word in the dictionary, ELMo looks at each word in the sentence before assigning each word a specific embedding. The ELMo model is pretrained on a very large corpus; if you had to train it yourself, it would likely strain your compute resources, but you can now nevertheless use it as a component in your own NLP models.&lt;/p&gt;
&lt;p&gt;The final transfer learning development we’ll mention is the release of BERT (bi-directional encoder representations from transformers) from Google. [Note: Devlin, J., et al. (2018). BERT: Pre-training of deep bidirectional transformers for language understanding. arXiv: 0810.04805.] Perhaps even more so than ULMFiT and ELMo, pretrained BERT models tuned to particular NLP tasks have been associated with the achievement of new state-of-the-art benchmarks across a broad range of applications, while requiring much less training time and fewer data to get there.&lt;/p&gt;
&lt;h2&gt;Non-sequential Architectures: The Keras Functional API&lt;/h2&gt;
&lt;p&gt;To solve a given problem, there are countless ways that the layer types we’ve already covered in this book can be recombined to form deep learning model architectures. For example, see our &lt;em&gt;Conv LSTM Stack Sentiment Classifier&lt;/em&gt; notebook, wherein we were extra creative in designing a model that involves a convolutional layer passing its activations into a Bi-LSTM layer.57 Thus far, however, our creativity has been con- strained by our use of the Keras &lt;code&gt;Sequential()&lt;/code&gt; model, which requires each layer to flow directly into a following one.&lt;/p&gt;
&lt;p&gt;Although sequential models constitute the vast majority of deep learning models, there are times when non-sequential architectures—which permit infinite model-design possibilities and are often more complex—could be warranted.58 In such situations, we can take advantage of the Keras &lt;em&gt;functional API&lt;/em&gt;, which makes use of the Model class instead of the Sequential models we’ve worked with so far in this book.&lt;/p&gt;
&lt;p&gt;As an example of a non-sequential architecture, we decided to riff on our highest- performing sentiment classifier, the convolutional model, to see if we could squeeze more juice out of the proverbial lemon. As diagrammed in Figure 11.27, our idea was to have three parallel streams of convolutional layers—each of which takes in word vectors from an &lt;code&gt;Embedding()&lt;/code&gt;layer.&lt;/p&gt;
&lt;p&gt;&lt;img sizes="(max-width: 702px) 100vw, 702px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_27.png 1148w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_27-300x223.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_27-768x570.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_27-1024x760.png 1024w" height="521" width="702" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_27.png" loading="lazy"&gt;&lt;/p&gt;
&lt;p&gt;As in our &lt;em&gt;Convolutional Sentiment Classifier&lt;/em&gt; notebook, one of these streams would have a filter length of three tokens. One of the others will have a filter length of two—so it will specialize in learning word-vector pairs that appear to be relevant to classifying a film review as having positive or negative sentiment. The third convolutional stream will have a filter length of four tokens, so it will specialize in detecting relevant quadruplets of word meaning.&lt;/p&gt;
&lt;p&gt;The hyperparameters for our three-convolutional-stream model are provided in Example 11.40 as well as in our &lt;em&gt;Multi ConvNet Sentiment Classifier&lt;/em&gt; Jupyter notebook [or the &lt;a href="https://try.dominodatalab.com/u/domino-andrealowe/Natural-Language-Processing/overview"&gt;complementary Domino project&lt;/a&gt;].&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example 11.40 Multi-ConvNet sentiment classifier hyperparameters &lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;# output directory name:
output_dir = 'model_output/multiconv'

# training:
epochs = 4
batch_size = 128

# vector-space embedding:
n_dim = 64
n_unique_words = 5000
max_review_length = 400
pad_type = trunc_type = 'pre'
drop_embed = 0.2

# convolutional layer architecture:
n_conv_1 = n_conv_2 = n_conv_3 = 256
k_conv_1 = 3
k_conv_2 = 2
k_conv_3 = 4

# dense layer architecture:
n_dense = 256
dropout = 0.2

&lt;/pre&gt;
&lt;p&gt;The novel hyperparameters are associated with the three convolutional layers. All three convolutional layers have 256 filters, but mirroring the diagram in Figure 11.27, the layers form parallel streams—each with a unique filter length &lt;code&gt;(k)&lt;/code&gt; that ranges from 2 up to 4.&lt;/p&gt;
&lt;p&gt;The Keras code for our multi-ConvNet model architecture is provided in Example 11.41.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example 11.41 Multi-ConvNet sentiment classifier architecture&lt;/strong&gt;&lt;/p&gt;
&lt;pre title=""&gt;from keras.models import Model
from keras.layers import Input, concatenate

# input layer:
input_layer = Input(shape=(max_review_length,),
                           dtype='int16', name='input')
# embedding:
embedding_layer = Embedding(n_unique_words, n_dim,
                            name='embedding')(input_layer)
drop_embed_layer = SpatialDropout1D(drop_embed,
                                    name='drop_embed')(embedding_layer)

# three parallel convolutional streams:
conv_1 = Conv1D(n_conv_1, k_conv_1,
                activation='relu', name='conv_1')(drop_embed_layer)
maxp_1 = GlobalMaxPooling1D(name='maxp_1')(conv_1)

conv_2 = Conv1D(n_conv_2, k_conv_2,
                activation='relu', name='conv_2')(drop_embed_layer)
       
maxp_2 = GlobalMaxPooling1D(name='maxp_2')(conv_2)

conv_3 = Conv1D(n_conv_3, k_conv_3,
                activation='relu', name='conv_3')(drop_embed_layer)

maxp_3 = GlobalMaxPooling1D(name='maxp_3')(conv_3)

# concatenate the activations from the three streams:
concat = concatenate([maxp_1, maxp_2, maxp_3])

# dense hidden layers:
dense_layer = Dense(n_dense,
                    activation='relu', name='dense')(concat)
       
drop_dense_layer = Dropout(dropout, name='drop_dense')(dense_layer)
dense_2 = Dense(int(n_dense/4),
                activation='relu', name='dense_2')(drop_dense_layer)
       
dropout_2 = Dropout(dropout, name='drop_dense_2')(dense_2)

# sigmoid output layer:
predictions = Dense(1, activation='sigmoid', name='output')(dropout_2) 

# create model:
model = Model(input_layer, predictions)

&lt;/pre&gt;
&lt;p&gt;This architecture may look a little alarming if you haven’t seen the Keras Model class used before, but as we break it down line-by-line here, it should lose any intimidating aspects it might have:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;With the &lt;code&gt;Model&lt;/code&gt; class, we specify the &lt;code&gt;Input()&lt;/code&gt; layer independently, as opposed to specifying it as the shape argument of the first hidden layer. We specified the data type (&lt;code&gt;dtype&lt;/code&gt;) explicitly: 16-bit integers (&lt;code&gt;int16&lt;/code&gt;) can range up to 32,767, which will accommodate the maximum index of the words we input.59 As with all of the layers in this model, we specify a recognizable name argument so that when we print the model later (using &lt;code&gt;model.summary()&lt;/code&gt;) it will be easy to make sense of everything.&lt;/li&gt;
&lt;li&gt;Every layer is assigned to a unique variable name, such as &lt;code&gt;input_layer&lt;/code&gt;, &lt;code&gt;embedding_layer&lt;/code&gt;, and &lt;code&gt;conv_2&lt;/code&gt;. We will use these variable names to specify the flow of data within our model.&lt;/li&gt;
&lt;li&gt;The most noteworthy aspect of using the Model class, which will be familiar to developers who have worked with functional programming languages, is the variable &lt;code&gt;name&lt;/code&gt; within the second set of parentheses following any layer call.&lt;/li&gt;
&lt;li&gt;This specifies which layer’s outputs are flowing into a given layer. For example, (&lt;code&gt;input_layer&lt;/code&gt;) in the second set of parentheses of the &lt;code&gt;embedding_layer&lt;/code&gt; indicates that the output of the input layer flows into the embedding layer.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;Embedding()&lt;/code&gt; and &lt;code&gt;SpatialDropout1D&lt;/code&gt; layers take the same arguments as before in this chapter.&lt;/li&gt;
&lt;li&gt;The output of the &lt;code&gt;SpatialDropout1D&lt;/code&gt; layer (with a variable named &lt;code&gt;drop_embed_layer&lt;/code&gt;) is the input to three separate, parallel convolutional layers: &lt;code&gt;conv_1, conv_2, and conv_3&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;As per Figure 11.27, each of the three convolutional streams includes a Conv1D layer (with a unique &lt;code&gt;k_conv&lt;/code&gt; filter length) and a &lt;code&gt;GlobalMaxPooling1D&lt;/code&gt; layer.&lt;/li&gt;
&lt;li&gt;The activations output by the &lt;code&gt;GlobalMaxPooling1D&lt;/code&gt; layer of each of the three convolutional streams are concatenated into a single array of activation values by the &lt;code&gt;concatenate()&lt;/code&gt; layer, which takes in a list of inputs ([&lt;code&gt;maxp_1, maxp_2, maxp_3&lt;/code&gt;]) as its only argument.&lt;/li&gt;
&lt;li&gt;The concatenated convolutional-stream activations are provided as input to two &lt;code&gt;Dense()&lt;/code&gt; hidden layers, each of which has a &lt;code&gt;Dropout()&lt;/code&gt; layer associated with it. (The second dense layer has one-quarter as many neurons as the first, as specified by &lt;code&gt;n_dense/4&lt;/code&gt;.)&lt;/li&gt;
&lt;li&gt;The activations output by the sigmoid output neuron (&lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; ) are assigned to the variable name predictions.&lt;/li&gt;
&lt;li&gt;Finally, the Model class ties all of the model’s layers together by taking two arguments: the variable name of the input layer (i.e., &lt;code&gt;input_layer&lt;/code&gt;) and the output layer (i.e., &lt;code&gt;predictions&lt;/code&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Our elaborate parallel network architecture ultimately provided us with a modest bump in capability to give us the best-performing sentiment classifier in this chapter (see Table 11.6). As detailed in our &lt;em&gt;Multi ConvNet Sentiment Classifier&lt;/em&gt; notebook, the lowest validation loss was attained in the second epoch (0.262), and this epoch was associated with a validation accuracy of 89.4 percent and an ROC AUC of 96.2 percent—a tenth of a percent better than our &lt;code&gt;Sequential&lt;/code&gt; convolutional model.&lt;/p&gt;
&lt;p&gt;&lt;img sizes="(max-width: 663px) 100vw, 663px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_6.png 1050w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_6-300x151.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_6-768x386.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_6-1024x515.png 1024w" height="333" width="663" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_6.png" loading="lazy"&gt;&lt;/p&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;p&gt;In this chapter, we discussed methods for preprocessing natural language data, ways to create word vectors from a corpus of natural language, and the procedure for calculating the area under the receiver operating characteristic curve. In the second half of the chapter, we applied this knowledge to experiment with a wide range of deep learning NLP models for classifying film reviews as favorable or negative. Some of these models involved layer types you were familiar with from earlier chapters (i.e., dense and convolutional layers), while later ones involved new layer types from the RNN family (LSTMs and GRUs) and, for the first time in this book, a non-sequential model architecture.&lt;/p&gt;
&lt;p&gt;A summary of the results of our sentiment-classifier experiments are provided in Table 11.6. We hypothesize that, had our natural language dataset been much larger, the Bi-LSTM architectures might have outperformed the convolutional ones.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;sup&gt;Domino editorial note: we’ve moved the “footnotes” to be embedded in the narrative to increase online readability.&lt;/sup&gt;&lt;/em&gt;&lt;/p&gt;
&lt;div&gt;&lt;h3&gt;Related posts:&lt;/h3&gt;&lt;/div&gt;    &lt;/div&gt;&lt;/div&gt;&lt;a href="https://blog.dominodatalab.com/deep-learning-illustrated-building-natural-language-processing-models/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:31:44 UT
      </pubDate>
      <guid>
        https://blog.dominodatalab.com/deep-learning-illustrated-building-natural-language-processing-models/
      </guid>
    </item>
    <item>
      <title>
        This 23-Year-Old Built and Sold His Startup While in School - Here’s How He Did It | First Round Review
      </title>
      <link>
        https://firstround.com/review/This-23-Year-Old-Built-and-Sold-His-Startup-While-In-School-Heres-What-Made-the-Difference/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;&lt;p id="text_8571c0301c70431b80a769c7f588a14a"&gt;From the moment&lt;a data-external="true" href="https://twitter.com/danshipper"&gt; Dan Shipper&lt;/a&gt;&amp;nbsp;stepped foot on the University of Pennsylvania’s campus, he knew he wanted to learn how to build a real software business with paying customers and steady revenue. He passed with flying colors last month when he both graduated from school and sold his company &lt;a data-external="true" href="http://usefirefly.com/"&gt;Firefly&lt;/a&gt; (the first company backed by &lt;a data-external="true" href="http://www.dormroomfund.com/"&gt;Dorm Room Fund&lt;/a&gt;) to&lt;a data-external="true" href="http://redeye.firstround.com/2014/06/graduationday.html"&gt; Pegasystems for multiple millions&lt;/a&gt;.&lt;/p&gt;&lt;p id="text_1a10415d48874a01a0ba742d983be012"&gt;Shipper’s success didn’t take anyone by surprise. Targeted early as a technology wunderkind, &lt;a data-external="true" href="http://www.businessinsider.com/startups-are-flinging-job-offers-at-dan-shipper-but-the-20-year-old-philosphy-major-rould-rather-stay-at-upenn-2012-5"&gt;he was receiving multiple job offers by his sophomore year&lt;/a&gt;. He chose to stay in school, he says, because he wasn’t done learning. Now, having seen his first company through an exit, he has a degree and perspective on what makes a real difference for young companies and entrepreneurs.&lt;/p&gt;&lt;p id="text_16e5685a597049f89afac3b3fbae80b0"&gt;In this exclusive First Round Review interview, Shipper shares the &lt;strong&gt;three tactics&lt;/strong&gt; that moved the needle the most for him and Firefly, and how beginning founders can get a head start on success.&lt;/p&gt;&lt;p id="text_da0b6fcf302e4e3da6e3818279a90b4d"&gt;&lt;strong&gt;Give Yourself Enough Time to Fail (or Succeed)&lt;/strong&gt;&lt;/p&gt;&lt;p id="text_e2827408554f4298a016f595574ba95e"&gt;In its first 10 months, Firefly brought in $11,000 in revenue — total. While Shipper and his co-founder &lt;a data-external="true" href="https://www.linkedin.com/pub/justin-meltzer/17/821/b"&gt;Justin Meltzer &lt;/a&gt;(pictured above, right) were sure the company solved a concrete problem — allowing two people to collaboratively browse the same webpage without any special software — sales weren’t promising. It would have been a valid decision to throw in the towel at that point, he says.&lt;/p&gt;&lt;p id="text_7b322ca351f6477c814fc740be007a69"&gt;“Because you have very limited information, it's easy to grab onto the data you have and spin a story about it,” Shipper says. “Like when you have a conversation with someone who really loves your product, you walk away thinking about how this is going to be the biggest thing ever. On the flipside, you see negative information, and you hit the lowest low, wondering why you’re even trying. Even though events like that make you feel very strong emotions, in both cases, the actual prospects for your company haven’t changed very much.”&lt;/p&gt;&lt;p id="text_6e462ae6504d4ace938657c775e85153"&gt;The human brain is not well equipped to handle uncertainty, so you anchor to whatever evidence seems solid. And if you happen to have the track record Firefly did 10 months in, you’d be hard pressed to forge on. But according to Shipper, “Knowing this is really helpful. Once you know where your brain is going to go, you can begin to see a way around things.”&lt;/p&gt;&lt;p id="text_90b7ae15657e4c08982a8a77ef2b08de"&gt;&lt;strong&gt;The other piece is to focus on what you’re learning — not just the numbers themselves&lt;/strong&gt;. “Instead of looking at who said what or how many customers are signing up, think about all the data you’re gathering,” he says. “So maybe you have this goal of getting 1,000 new customers a month, instead of looking at the past data thinking it’s impossible, think about what those bad months told you about customers, how you might do better, and how (or whether) what you’re building actually fits in to people’s lives and jobs.”&lt;/p&gt;&lt;p id="text_ccc9b5ab1e77492d88d799d6cc6eb850"&gt;For Firefly, Shipper and Meltzer made a big push to learn everything they could about the customer support industry — which they decided was the primary audience for their product. The key was to look at the last 10 months, and determine whether they needed to shift course based on the results. In their case, they stayed on the same path while making only small modifications to their approach. This allowed them to close big deals that paid off in the long run.&lt;/p&gt;&lt;p id="text_685c1433efbd47c5b99dc5edb9897700"&gt;“When you shift gears toward learning, you start thinking about whether what you’re doing really fits into the lives of the people who are buying your product,” he says. “It’s a good tool to help you manage your psychology because learning about your customers is much more immediate than something like monthly recurring revenue, which typically lags far behind.”&lt;/p&gt;&lt;p id="text_9f4ccfc69e414e898ba0d5faa8b39db3"&gt;A lot of entrepreneurs cite &lt;strong&gt;relentlessness&lt;/strong&gt; as a good quality to have. You want to be relentless about finding product market fit. You want to be relentless about building your product. There’s this idea that to succeed you can’t let up — you have to be driving hard toward your goal at all times. While Shipper agrees that this energy can be productive,&lt;strong&gt; it’s easy to be relentless about the wrong things&lt;/strong&gt;.&lt;/p&gt;&lt;p id="text_b620dac54e23436796728a92950fb937"&gt;“Being relentless is not enough,” he says. “It’s so easy to get trapped in these operant conditioning cycles where you have one good experience at a networking event, so you think you should go to every single one that’s similar even if that doesn’t directly serve the overall goals of your company.”&lt;/p&gt;&lt;blockquote id="text_06297e8db25b4be1af69293f16b59407"&gt;“You have to pair relentlessness with something else, and I think the best thing is being scrappy.”&lt;/blockquote&gt;&lt;p id="text_7f102fb5106b438eafe2f4432a45a176"&gt;As a tiny, bootstrapped company, Firefly had to make very deliberate decisions about what it could afford in terms of time and money. It had no choice but to be scrappy in its approach, which Shipper says helped him and the team execute against the right goals. “We set our sights on finding customers and trying to sell the product, and we didn’t think about anything else for a while,” he says. &lt;strong&gt;“&lt;/strong&gt;&lt;strong&gt;The best way to know if someone is going to buy a product is to actually try to sell it to them.&lt;/strong&gt;&lt;strong&gt;”&lt;/strong&gt;&lt;/p&gt;&lt;p id="text_3d1bb8bd59f045579931613ec5c5201b"&gt;Acting scrappy also makes you humble, and humility is sometimes the best sales tactic early on.&lt;/p&gt;&lt;p id="text_b2902a1cfed6492f941c25850a7ac228"&gt;“A lot of entrepreneurs — especially young entrepreneurs — enter markets without really knowing that much about them. When we started, we didn’t have a great sense of the customer service industry, but we were in a situation where we had to. You have to invest the time and energy in information gathering before you’re every going to have a good sales strategy.” Rather than try to gather information and then implement a sales strategy, in the early days Shipper and Meltzer used sales calls to actively collect data. “A lot of what we were doing was unsuccessfully pitching a lot of prospective customers and then humbly examining what had gone wrong so that we could do better next time.”&lt;/p&gt;&lt;blockquote id="text_ec4f9debefed4d5ab9f5c68261f1ba7c"&gt;“Going out there and selling is the best way to get the information you need.”&lt;/blockquote&gt;&lt;p id="text_f236050ca22c49d8904f898372782b3f"&gt;&lt;strong&gt;A lot of startups don’t give themselves enough time and runway to fail, so they never do find that coveted product-market fit. &lt;/strong&gt;As Shipper has observed, this outcome usually coincides with the belief that successful companies should see consistent, promising growth. But in his experience, startups go through long plateaus punctuated by a step change in growth. You have to wait for the step change.&lt;/p&gt;&lt;p id="text_205d741560af4d4da3bcff43d1c9ac02"&gt;“Induction doesn’t work with early stage startups. You can’t look at what’s happened in the past and project that you’ll be doing exactly the same amount of business in the future, or even along the same trajectory,” says Shipper. “Surface-level pattern recognition works very for many things, but it tends not to work well for startups. Simplistic pattern recognition says something like, ‘This company only made $1,000 in its first three months, therefore the team should pack up and go home.’ You have to understand why they only made $1,000 during those months to be able to say whether it’s because their business isn’t viable or for another reason. The psychology of running an early-stage company is difficult to manage partly because the emotional part of our brains uses surface-level pattern recognition to judge how we’re doing.”&lt;/p&gt;&lt;p id="text_a1ac9b0d73b442adb762fbf2ac6b364a"&gt;In evolutionary biology, there’s a theory called &lt;a data-external="true" href="http://en.wikipedia.org/wiki/Punctuated_equilibrium"&gt;punctuated equilibrium&lt;/a&gt;, the idea that species evolve almost imperceptibly for thousands if not millions of years, and then suddenly massive changes occur when there is a global catastrophe or the environment shifts radically. Suddenly, the rate of evolutionary change spikes.&lt;/p&gt;&lt;p id="text_657818d9ac124835962fb37fc89671c1"&gt;“Especially when you’re at the very early stages, startups behave a lot like this. One day you’re at the beginning level, and then you jump to the next, either when you get funding or land a huge customer or a big news story comes out that directly relates to your product. Something happens and you're dealing with a different situation right away. The thing is, it’s usually very hard to predict when or if that will happen to you, so you have to keep working. You can’t predict the future from the past. For example, take a look at &lt;a data-external="true" href="https://duckduckgo.com/"&gt;DuckDuckGo’s&lt;/a&gt; daily &lt;a data-external="true" href="https://duckduckgo.com/traffic.html"&gt;search queries graph&lt;/a&gt;, which is publicly available on their site. DDG was founded in 2008 as a search engine that doesn't track users' activity. The NSA scandal hit around July of 2013. Since that time, they’ve pretty much tripled the number of searches they were seeing per day.”&lt;/p&gt;&lt;p id="text_18480c9ca9814e5899d9565e71fcad95"&gt;In the case of Firefly, Shipper and Meltzer had a bunch of game-changing deals in the hopper for quite some time, with no clear sense of whether any would close. “If you’re trying to sell to larger organizations, they have a lot of priorities, a lot of people involved. You basically have to wait for the stars to align to get a green light on your product. Deals require very, very long leads," Shipper says.&lt;/p&gt;&lt;p id="text_9b96294a65f04fcfa446b919a98fc54a"&gt;“We’d have a full pipeline, but then one company would say they were going to push the deal back a quarter, others would just drop off, sometimes without us knowing why. In most cases, it was clear that larger businesses were hesitant to work with a startup, so they’d want to see how long they could keep us around, and how consistent we’d be in our service. The only thing to do was stick around and try to get people aligned around using this new technology.” Eventually Firefly’s pipeline started to produce.&lt;/p&gt;&lt;p id="text_f9c7c9e5d2e94dedb39a161b5bd60fc6"&gt;This isn’t to say that every startup should hang on to the very last straw. You simply don’t want to quit too early. “The best thing to do is nail down why things are not going well. Is it really clear that no one wants to buy what you’re selling because they don’t have the problems you’re trying to solve? Or is there evidence that your product could be useful eventually with enough feedback and traction?” You have to be brutally honest when you answer these questions, Shipper says. A lot of times things could improve if you only gave yourself more time and tried more things.&lt;/p&gt;&lt;figure id="image_6ec9612a35074d5e870ecc14941ab72d" data-zoomable="true" data-pinned="false" data-aspect_ratio="1.691" data-src_2560="https://s3.amazonaws.com/marquee-test-akiaisur2rgicbmpehea/BV3RmM6TkOercVhBHP27_founders.png" data-src_1280="https://s3.amazonaws.com/marquee-test-akiaisur2rgicbmpehea/8ZvRR619SnSIlhtIvtBk_founders.png" data-src_640="https://s3.amazonaws.com/marquee-test-akiaisur2rgicbmpehea/oMmkKu6SuWe58VGh7n8G_founders.png"&gt;&lt;p&gt;&lt;figcaption&gt;&lt;span&gt;Dan Shipper (L) and Justin Meltzer (R)&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/figcaption&gt;&lt;/p&gt;&lt;img src="https://s3.amazonaws.com/marquee-test-akiaisur2rgicbmpehea/BV3RmM6TkOercVhBHP27_founders.png"&gt;&lt;/figure&gt;&lt;p id="text_4a71a382920b4a9c885eecd5c3c5a2b7"&gt;&lt;strong&gt;Sell from the Very Beginning&lt;/strong&gt;&lt;/p&gt;&lt;p id="text_47bc3214bcc64dc59962460d2873df3c"&gt;Traditionally, companies build a product they feel good about and then try to sell it. Firefly started selling before its product was fully baked, and it turned out to be one of the best decisions they made. “We did a lot of outbound sales, cold calls, cold emails, and it was so much better from a learning perspective than using something like AdWords to sell the product,” Shipper says. “So many people say that to test an idea you should just throw up a landing page and buy some AdWords and see who you attract. Unless you have a lot of experience with AdWords that’s a bad idea. There’s this gigantic learning curve to doing online marketing right, so most likely you’re just going to buy ads that no one ever clicks on, or you’ll get people coming to your page who immediately leave when they see nothing real, and then they’ll never get converted. You could have the wrong keywords, bad ad copy, who knows?”&lt;/p&gt;&lt;p id="text_69c2df6eb6824833ae02b986c8c6ef8a"&gt;The Firefly team had a very different approach in mind — one that ended up paying off in big ways.&lt;/p&gt;&lt;p id="text_2300e743fc3348518a925c94b288a851"&gt;“We had the beginnings of the technology, and we knew which market would probably find it the most helpful — that was it. Then we started figuring out how to get it out there.”&lt;/p&gt;&lt;p id="text_9978143265a444158e0d10c1eb24cad2"&gt;Shipper and Meltzer started pitching customers who already had live customer service chat widgets that would pop up on their sites to help current visitors. They figured that being able to share a browser screen would be even better for companies to provide a higher level of service. They made a big list of those companies and emailed them to see if they were interested in what Firefly could do.&lt;/p&gt;&lt;p id="text_39660e7c4fd84acaaf529a747bc60e88"&gt;“The other thing we did was look for people within companies who had customer support or customer service roles and made appointments to talk to them. The tendency in these conversations is to do 100% of the talking, because you want to tell them everything your product can do — but you actually want the reverse. You want them to spend all the time talking. What do they not understand? Where do they keep getting stuck as you walk them through the demo? What do they ask the most questions about? That’s how you use your product as a catalyst to get information about how it should work.”&lt;/p&gt;&lt;p id="text_56653a4af94541adbca5ba602cc3b27b"&gt;Even though Firefly was still a work in progress at the time, Shipper and Meltzer were able to convert some of these early customers. They made it clear to the people they were talking to that they were specifically trying to improve their lives and jobs, and made them feel like they had a stake in the result.&lt;/p&gt;&lt;blockquote id="text_0541a19146d34fa19cd09dc059790e88"&gt;“You figure out what your product is only after selling it.”&lt;/blockquote&gt;&lt;p id="text_0acfc05ee0ea4b4496309934d80e4a6a"&gt;Of course the tactic of selling from the beginning only works if you’re prepared to immediately funnel the feedback you get into product development. Shipper and Meltzer made it a high priority to capture all of the data they gleaned from email replies and conversations to enter it into a feedback loop that yielded real, noticeable changes in how Firefly operated as software and a company.&lt;/p&gt;&lt;p id="text_7b9d1c2d0c06407897f0350d69c103b7"&gt;When asked how they managed to evolve both their product and sales process at the same time with a tiny team, Shipper says that it was critical for everyone involved to both understand the business and be able to ship code. This might sound like trying to build your own herd of unicorns, but it vastly accelerated their ability to land customers and deliver something to them on time. “Not only could everyone involved understand what was going on, but it was just easier to keep everyone in the know and on the same schedule. &lt;strong&gt;We’d all focus on sales during business hours and then switch to programming at night.&lt;/strong&gt;” At an early stage, this is feasible.&lt;/p&gt;&lt;p id="text_329a9262e1af4c04b2e4fb97822db11c"&gt;Notably, Shipper says, not all of the feedback they got through selling was about improving the product. A lot of what they learned improved their approach to sales too. “We had this initial idea of going to companies that used live chat customer service systems, but in doing so we realized how small most of them were. It occurred to us that we could sign up all of them individually and probably still not make that much. It was only after talking to them that we decided to go straight to the chat companies themselves that sell to the smaller businesses. They were bigger, making more money, looking for a competitive edge.” In their research, the Firefly team had discovered that the customer service chat sector was deeply fragmented, with upwards of 60 companies offering nearly identical products. In this environment, Firefly’s co-browsing capabilities would be a huge differentiator.&lt;/p&gt;&lt;p id="text_feedcf94061c4bd6adf7daf983eda602"&gt;This was the break the company needed to reach a much broader audience. It also led them down the path toward their current API model, allowing anyone to include their code on their platform for whatever purpose they wanted — not strictly customer support. “You can build any kind of collaborative app with our software," Shipper says. "Financial advisors can co-browse with their clients on an online portfolio, for example, without having to use straight screen sharing. We got there by seeing how we could sell to one company that would sell to many others.”&lt;/p&gt;&lt;p id="text_6eb1530a52774910a027e265ab18189d"&gt;&lt;strong&gt;Stay Small and Scrappy for as Long as Possible&lt;/strong&gt;&lt;/p&gt;&lt;p id="text_8f132dd886a44223b3591a93363e8e2a"&gt;“There are a lot of good things about not needing or even wanting to be a huge business immediately,” Shipper says. “You have time to really learn your industry and your customers, and how your product should change. It gives you time to concentrate on building the skills you’ll need to be successful instead of having your head in the clouds removed from the business on the ground.”&lt;/p&gt;&lt;p id="text_b5b4e585077c41f48a2f475b74847338"&gt;While small and scrappy can sound a lot like cash-strapped and vulnerable, Shipper argues that holding onto both can actually give you more control over your business. When you’re a small fish in a big pond, you’re immune to a lot of the problems larger and even mid-stage startups face (security issues, HR challenges, external pressure from a large pool of investors). “You end up having more flexibility to work on what you want on your own terms — and you can always reserve the option to go raise money or try to do something bigger.”&lt;/p&gt;&lt;p id="text_ceda616fabb248e6945c0f3ae8916a87"&gt;Shipper knows this on a personal level, having fielded some outrageous offers to drop out of school and join other companies. He steered Firefly the same way he steered his personal life — keeping things simple until he had all the information in hand and a clear idea of what he wanted.&lt;/p&gt;&lt;p id="text_67a7a939b29542e3a748d73db21b590b"&gt;“It’s hard to turn down a lot of money, but I kept asking myself and the team this big question:&lt;strong&gt; If we did bring in all this money, what did we actually need it for?&lt;/strong&gt; Money wasn’t really our bottleneck. Our bottleneck was figuring out a really good marketing strategy, how we could efficiently close customers, stuff like that," he says. "I think a lot of people get stuck in this mindset that if they have more employees then they’ll have more man hours and will be able to do more. They forget that more employees means more time spent hiring and more baggage. Not to mention all the time you spend raising money to pay these people.”&lt;/p&gt;&lt;p id="text_ad278f31111d439b8c5c2934afd3c4c5"&gt;Getting blinded by early millions and promises of rapid growth can actually make it harder to go fast, Shipper says. “If you’re at this early stage of discovery, where you’re doing your research and hammering out your strategy, you want a small team that doesn’t have the pressure that comes with taking a check. Once I understood that, I didn’t think about the money.”&lt;/p&gt;&lt;p id="text_fff42f54826e4c13a43f2638fc43adc9"&gt;One of the biggest problems early-stage startups that do take venture funding face is that they've sold a vision they can’t deliver on fast enough. “I think there’s a point for every startup where you have to decide if you want to go for it, and you think you can be huge, or whether you want to grow more slowly on your own. A lot of people think this point is the day you start building your product. My opinion is that it comes far down the line when you really know a lot more about your business.”&lt;/p&gt;&lt;blockquote id="text_bf7095f27dd54d9b9bff06ddada02122"&gt;“Funding can make you do things that you never would if you didn't feel like you had to.”&lt;/blockquote&gt;&lt;p id="text_a4020b90607d4538a2887a4582ca1fff"&gt;“The prevailing wisdom is that you should raise more money than you think you need, and I agree that’s probably true,” Shipper says. “It’s just that it should only happen when you’re confident in the fact that more money will allow you to grow much faster — when you’ve already found your trajectory and you just need to accelerate it. This isn’t always the case.” Until you feel this confidence, you should be building with as little money as possible. “Honestly, most products that get huge amounts of early funding could be built for something like $50,000," he says.&lt;/p&gt;&lt;p id="text_537ed0f1e14c4023b4d67bfab6ead950"&gt;Staving off large rounds can also give you more time to think about the type of backers and advisors you want to work with eventually. For Shipper, it gave him the space to cultivate relationships with people over email or through occasional dinners. He had the benefit of seeing who would maintain a longstanding interest in Firefly. “You want to look for people who will take the time themselves to really understand what’s going on not just in your business but in your industry. You want people who are in it for the long-term, and who are more interested in helping you succeed than in looking good.”&lt;/p&gt;&lt;p id="text_79be237ec08e433c8c107a424802960f"&gt;Incidentally, emphasizing this stay-small strategy also helped Firefly attract the right type of employees. “When you’re not raising any money and you’re building this thing on your own, you don’t oversell to people. I think this type of honesty resonates. Sure, there might be a chance that we’ll get big, but we’re not going to tell you that just so we can hire you or get you to work harder. You have to be here because you want to be, and you like the idea of being part of something self-sustaining, not just a big exit.”&lt;/p&gt;&lt;p id="text_3e283cdc1bad4da8bb998db543f313b4"&gt;All of this combined made Firefly an attractive acquisition target, Shipper says. By selling from the beginning and not being deterred by initial failure, their product gained so much momentum that customer support organizations were starting to demand co-browsing functionality.&lt;/p&gt;&lt;p id="text_03298643eb064d558c5b473b3b1a6d85"&gt;“More importantly, I think we gave ourselves a lot of options to choose what we wanted,” he says. “You can’t sell a company unless there’s a buyer first, and I think we found the right kind of buyer by running the company the way we wanted to for so long.”&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;a href="https://firstround.com/review/This-23-Year-Old-Built-and-Sold-His-Startup-While-In-School-Heres-What-Made-the-Difference/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:32:10 UT
      </pubDate>
      <guid>
        https://firstround.com/review/This-23-Year-Old-Built-and-Sold-His-Startup-While-In-School-Heres-What-Made-the-Difference/
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        http://danshipper.com/nothing-happens-until-the-sale-is-made
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;
                    &lt;h2&gt;&lt;a title="Permanent Link to How to get your first 10 customers" href="http://danshipper.com/nothing-happens-until-the-sale-is-made"&gt;How to get your first 10 customers&lt;/a&gt;&lt;/h2&gt;
                                        &lt;p&gt;&lt;em&gt;Preface: the assumption for this essay is that you’re building a B2B app, and you have something built but you’re having trouble getting people to pay for it&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;There are three problems with getting your first few customers:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;You (probably) don’t know how to sell things&lt;/li&gt;
&lt;li&gt;You don’t know who you’re selling to&lt;/li&gt;
&lt;li&gt;You don’t even really know &lt;em&gt;what&lt;/em&gt; you’re selling&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Nobody tells you how to answers these questions, and so most people go out to get initial traction in a haphazard way:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;They have a vague idea in mind for who wants their product&lt;/li&gt;
&lt;li&gt;They’ve already built the product, so they put together a landing page which &lt;em&gt;which, like, totally speaks to the core value proposition&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;They write some combination of any of the following:&lt;br&gt;
A few half-baked ads&lt;br&gt;
A few forum posts&lt;br&gt;
A few comments on relevant blogs&lt;br&gt;
A few blog posts&lt;br&gt;
A few cold emails to journalists (because, dude, we would BLOW UP if we could just get ‘Crunched)&lt;/li&gt;
&lt;li&gt;They send these out into the wild, and (no surprise!), get very few responses&lt;/li&gt;
&lt;li&gt;They conclude that the product must suck and that nobody wants it, because Mark Zuckerberg did exactly the same thing to launch Facebook at Harvard and look at how that worked out for him&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If you try to get initial traction this way, it’s very difficult to untangle why it didn’t work:&lt;/p&gt;
&lt;p&gt;Were the ads targeted to the wrong keyword?&lt;br&gt;
Was the copy not compelling enough?&lt;br&gt;
Was the sample size too small?&lt;br&gt;
Or does no one want what I’m selling?&lt;/p&gt;
&lt;p&gt;When they fail to get initial traction, most people conclude that the product is the problem. That no one wants what they’re selling.&lt;/p&gt;
&lt;p&gt;They never consider that &lt;em&gt;the way they’re selling&lt;/em&gt; might be COMPLETELY wrong (either in the way the product is being pitched, who it’s being pitched to, or some combination of the two.)&lt;/p&gt;
&lt;p&gt;I think most of us have been lulled into this sense that the second you post your new product to a listserve you should automatically get sucked into a 4 minute montage scene featuring dark ominous 9 Inch Nails background music only to be spat out at the end with enough money to buy that estate on the Amalfi Coast.&lt;/p&gt;
&lt;p&gt;And when that doesn’t happen, our first response is always to blame the product.&lt;/p&gt;
&lt;p&gt;Formally this is called the &lt;em&gt;actor observer bias&lt;/em&gt; which tells us that we tend to blame things that don’t go right in our lives to circumstances beyond our control:&lt;/p&gt;
&lt;p&gt;“No one responded to my emails, so the product must suck. Nobody wants it, otherwise it would already be on TechCrunch.”&lt;/p&gt;
&lt;p&gt;This is wrong. Here’s the truth:&lt;/p&gt;
&lt;p&gt;You have learned nothing from spending $200 on Adwords, or writing a few comments, or sending cold emails to journalists.&lt;/p&gt;
&lt;p&gt;Let me repeat: You have learned nothing. You get a big Zero. You have no actionable information.&lt;/p&gt;
&lt;p&gt;Your product &lt;em&gt;could&lt;/em&gt; suck. But it could still also be completely your fault. Or it could be completely random that you didn’t get any responses. Maybe the journalists were having a bad day, or the three people who clicked on your ads were just bots.&lt;/p&gt;
&lt;p&gt;The point is: buying a few ads, or sending a few emails, or writing a few blog posts is not enough to conclude anything.&lt;/p&gt;
&lt;p&gt;Untangling why you’re not making sales seems like an almost insurmountable problem, especially when you realize that at the beginning you don’t even really know &lt;em&gt;what&lt;/em&gt; you’re selling.&lt;/p&gt;
&lt;p&gt;The problem with startups is that you have to figure out WHAT you’re selling AS you’re selling it.&lt;/p&gt;
&lt;p&gt;It’s like having a big black bag with a product inside it, and you have to run around selling it to people you see on the street. And worse, you’re not allowed to look into the bag to know what it is you’re selling. You can put your hands into it and feel around, but that’s the extent of it.&lt;/p&gt;
&lt;p&gt;Ok, so how do you deal with this? How do you start to figure out what you’re selling, who you’re selling to, and how to sell? How do you get those first few customers?&lt;span id="more-182"&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Find the value&lt;/strong&gt;&lt;br&gt;
The most important question to answer when you’re starting out is this:&lt;/p&gt;
&lt;p&gt;Where’s the value of my product? Who is it valuable for? And why is it valuable for them?&lt;/p&gt;
&lt;p&gt;Everything else flows from that.&lt;/p&gt;
&lt;p&gt;And it turns out that the best way to figure out these basic things out is BY selling your product.&lt;/p&gt;
&lt;p&gt;Remember that Reid Hoffman quote about startups being like jumping off a cliff and building a plane on the way down? This is why:&lt;/p&gt;
&lt;p&gt;You need to figure out what you’re doing as you’re doing it. You need to figure out how to sell and who you’re selling to and what you’re selling &lt;strong&gt;while&lt;/strong&gt; you’re selling it. And if you took VC money you have to do that in a very, very short time period.&lt;/p&gt;
&lt;p&gt;At the beginning most people do things the opposite way: they assume that the product provides real value, they assume they know what that value is, and they combine these assumptions into a sales pitch. Then they run around and talk to a few people, get lukewarm responses, and conclude that the product sucks.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Don’t lie to yourself&lt;/strong&gt;&lt;br&gt;
There are some times in life when you’re not going to get into trouble lying to yourself.&lt;/p&gt;
&lt;p&gt;If your friend ditches you for dinner, you can always tell yourself: “Well I didn’t like him anyway.”&lt;/p&gt;
&lt;p&gt;If you get a bad score on a math test, you can say: “The teacher sucks, it’s not my fault.”&lt;/p&gt;
&lt;p&gt;We’re taught that this is an okay way to deal with the difficult situations that life throws at us. That these white lies are just harmless rationalizations that keep us sane.&lt;/p&gt;
&lt;p&gt;There are at least two industries where you can’t do this:&lt;/p&gt;
&lt;p&gt;Entrepreneurship and rocket science&lt;/p&gt;
&lt;p&gt;If a SpaceX engineer lies to himself, the rocket blows up on the launch pad. If the entrepreneur lies to herself, her company will fail before it even gets started.&lt;/p&gt;
&lt;p&gt;Telling yourself: I know what this product is, I know who wants this, and I know how to sell it, when you really don’t is only going to result in YOUR failure. Admitting to yourself that you need to find out what you don’t know is the first step in the right direction.&lt;/p&gt;
&lt;p&gt;It’s important to recognize that if you’re just starting out you have no idea where the value of your product lies. And you should make it your goal, not to ram your vision down other people’s throats, but to &lt;em&gt;honestly&lt;/em&gt; find out whether your product is valuable, and if it is, who it’s valuable for.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Start with people first, not “hits”&lt;/strong&gt;&lt;br&gt;
Most people start out by posting on forums or buying ads or writing blog posts because sitting behind a computer is a lot less scary than actually talking to people.&lt;/p&gt;
&lt;p&gt;But in order to answer the questions that you need to answer at the beginning you’re going to need to talk to people, either on the phone or face to face. And you’re going to need to do that a lot.&lt;/p&gt;
&lt;p&gt;This advice has been reiterated so many times that by now it’s pretty banal. But most blog posts say “talk to customers” and leave it at that.&lt;/p&gt;
&lt;p&gt;Let’s talk more specifically about how to do it.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Identifying prospects&lt;/strong&gt;&lt;br&gt;
Before you can go out and talk to people, you have to develop an idea of who you’re going to be talking to. Here’s a quick process for doing this:&lt;/p&gt;
&lt;p&gt;(Note this advice is primarily targeted at B2B companies, but I believe, can be successfully applied to B2C companies as well)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Develop a hypothesis about the target customer&lt;/li&gt;
&lt;li&gt;Find companies that fit the bill&lt;/li&gt;
&lt;li&gt;Think about: who at the company is going to want this?&lt;/li&gt;
&lt;li&gt;Get their email and get in touch&lt;/li&gt;
&lt;li&gt;Rinse and repeat&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;As an example of step one, our first hypothesis about potential customers for Firefly was that people who would find it useful would probably have installed a live chat program like Olark or SnapEngage on their site. So we started contacting their customers.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How to find someone at a company&lt;/strong&gt;&lt;br&gt;
Once you have a company in mind that you think will be relevant, now it’s time to actually find someone to talk to.&lt;/p&gt;
&lt;p&gt;The lowest hanging fruit is reaching out to their catchall email like sales@ or &lt;a href="mailto:team@"&gt;team@&lt;/a&gt;. I wouldn’t recommend doing this, most of that stuff gets ignored.&lt;/p&gt;
&lt;p&gt;There are really three options for doing this:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Look through LinkedIn&lt;/li&gt;
&lt;li&gt;Look at something like Hoovers (if it’s a big company)&lt;/li&gt;
&lt;li&gt;Look on their management team page&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;How to find anyone’s email with just their name&lt;/strong&gt;&lt;br&gt;
Once you find someone at a company, the next step is to actually get their email address. Most people don’t list their emails publicly so this requires some digging.&lt;/p&gt;
&lt;p&gt;What I usually like to do is take their name e.g. Bob Smith and use an email address validator tool (like &lt;a href="http://network-tools.com/"&gt;this one&lt;/a&gt;) and do a little guess and check.&lt;/p&gt;
&lt;p&gt;So if I was trying to find Bob Smith who works at XYZ company I would go to the email validator and try different combinations:&lt;/p&gt;
&lt;p&gt;&lt;a href="mailto:bob.smith@xyzcompany.com"&gt;bob.smith@xyzcompany.com&lt;/a&gt;&lt;br&gt;
&lt;a href="mailto:bsmith@xyzcompany.com"&gt;bsmith@xyzcompany.com&lt;/a&gt;&lt;br&gt;
&lt;a href="mailto:bob@xyzcompany.com"&gt;bob@xyzcompany.com&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;And very often you’ll be able to guess their email after a few tries. Be careful though, some companies have catchall accounts that make any combination valid – so you’ll have to test at least one or two to verify that you’re getting a real result.&lt;/p&gt;
&lt;p&gt;There are also other ways to do this:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Go to their Press page (many company list a press contact, and you can guess their company email format from the press contact’s email)&lt;/li&gt;
&lt;li&gt;Use something like Jigsaw.com&lt;/li&gt;
&lt;li&gt;Call their corporate number and ask to be transferred&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;If you’re a student take advantage of it&lt;/strong&gt;&lt;br&gt;
Being a student has certain advantages, and one of them is that fact that people will be more willing to talk to you, and more willing to help you out. Here’s an example cold email that you might send to someone that you want to talk to:&lt;/p&gt;
&lt;p&gt;Subject: Hello from Philly!&lt;/p&gt;
&lt;p&gt;Hi there,&lt;/p&gt;
&lt;p&gt;I’m a student and I’m working on a project.&lt;/p&gt;
&lt;p&gt;I know you work in Industry X and I’d love to get some advice. For reasons XYZ I feel like you would be really relevant for the problems I’m thinking about. Are you free to chat on X date next week?&lt;/p&gt;
&lt;p&gt;By the way we both went to UPenn.&lt;/p&gt;
&lt;p&gt;Go Quakers!&lt;/p&gt;
&lt;p&gt;This is useful because it’s a low pressure way to start talking to people. You don’t even really have to be a student to do this – but in general, asking for advice in the beginning will be much lower stress than doing “cold sales emails.” It’s also more useful when you don’t know anything.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Be honest&lt;/strong&gt;&lt;br&gt;
If you use the tactic above, be VERY careful to be honest about it. If you ask someone for advice and then go in and try to sell them they’re going to be angry. And rightfully so.&lt;/p&gt;
&lt;p&gt;If you ask someone for advice, mean it. They might buy from you eventually, but remember that you’re still in the process of learning about your product, learning about your market, and learning how to sell. The sales will come eventually if you do enough outreach. Don’t rush it.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Shut up and listen to them&lt;/strong&gt;&lt;br&gt;
When you’re on a sales call it’s very important to shut up and listen. Most people have a tendency to drone on and on about their product.&lt;/p&gt;
&lt;p&gt;Don’t do this. If your call is successful, you’ll have talked way less than your prospect. (That’s advice &lt;a href="http://www.twitter.com/natsturner"&gt;Nat Turner&lt;/a&gt; gave me and it’s golden.)&lt;/p&gt;
&lt;p&gt;Here are some questions you might want to ask:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;What’s your organizational focus in the near term? What are your priorities?&lt;/li&gt;
&lt;li&gt;How frequently do you have X problem?&lt;/li&gt;
&lt;li&gt;What’s your process like for buying software?&lt;/li&gt;
&lt;li&gt;Who would be involved in the process?&lt;/li&gt;
&lt;li&gt;How long does it normally take?&lt;/li&gt;
&lt;li&gt;What other software are you currently using?&lt;/li&gt;
&lt;li&gt;What do you do day-to-day?&lt;/li&gt;
&lt;li&gt;What kind of tasks do you do repeatedly?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Keep the chain going&lt;/strong&gt;&lt;br&gt;
The biggest mistake you can make is letting someone who’s interested get off the phone without clear next steps. You want to know where you’re going before they hang up because people are busy, and unless they’re committed to something they’re unlikely to remember to do anything.&lt;/p&gt;
&lt;p&gt;Feel free to ask: “So what are the next steps?”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;To be clear, you only have to do the outbound stuff at the beginning&lt;/strong&gt;&lt;br&gt;
I know that after I publish this article there’s going to be someone in the comments complaining about scale. “Doing this doesn’t scale,” they will say. “It doesn’t apply to a high growth business.”&lt;/p&gt;
&lt;p&gt;To be clear, I’m not advocating doing this forever (unless your business model demands it). But I do think it’s &lt;em&gt;vastly&lt;/em&gt; more effective&amp;nbsp;than just spending a couple of hundred bucks on Adwords.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Nothing happens until the sale is made&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If there’s one thing to take away from this post (practical tips aside) it’s this:&lt;/p&gt;
&lt;p&gt;You should admit to yourself that you (probably) don’t know anything about your business. That you (likely) don’t know how to sell, who you’re selling to, or what you’re selling. That your product is inside of a black bag that you can’t look into. And that you should begin to deal with that uncertainty by selling your product anyway.&lt;/p&gt;
&lt;p&gt;Something special happens every time you make a sale: a little piece of the product becomes visible. The product is still wrapped in its black bag, but when you make a sale you get to take a peak at it, only for a second.&lt;/p&gt;
&lt;p&gt;And you have to pay attention to it, and write it down, and think about it, otherwise you’ll miss it completely.&lt;/p&gt;
&lt;p&gt;The more sales you make, the more you’ll understand your product. And finally after about a year you’ll begin to know what it looks like. You’ll know every nook and cranny, every blemish and every beautiful curve. And you’ll know all of this even though you’ve never taken it out of its black bag.&lt;/p&gt;
&lt;p&gt;And you won’t find out any of this by haphazardly sending emails to journalists, or posting on forums:&lt;/p&gt;
&lt;p&gt;Nothing happens until the sale is made.&lt;/p&gt;
&lt;p&gt;The sale is where you start to find the value, it’s where you start to learn how to sell, and it’s where you start to figure out &lt;em&gt;what&lt;/em&gt; you’re selling.&lt;/p&gt;
&lt;p&gt;___&lt;/p&gt;
&lt;p&gt;If you liked this post sign up to receive future &lt;a href="http://eepurl.com/qDl21"&gt;posts by email here&lt;/a&gt;. Or follow me on &lt;a href="http://www.twitter.com/danshipper"&gt;Twitter&lt;/a&gt;.&lt;/p&gt;
		     
	  	    &lt;p&gt;
		    &lt;h3&gt;17 Jul 2013, 6:49pm | 
	            &lt;a href="http://danshipper.com/nothing-happens-until-the-sale-is-made#comments"&gt;&lt;span rel="182 http://danshipper.com/?p=182"&gt;80 comments&lt;/span&gt;&lt;/a&gt;		    &lt;/h3&gt;
                    &lt;/p&gt;
	     
		                        
                  &lt;/div&gt;&lt;/div&gt;&lt;a href="http://danshipper.com/nothing-happens-until-the-sale-is-made"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:32:13 UT
      </pubDate>
      <guid>
        http://danshipper.com/nothing-happens-until-the-sale-is-made
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        http://danshipper.com/charlie-munger-on-how-to-build-a-2-trillion-startup
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;
                    &lt;h2&gt;&lt;a title="Permanent Link to Charlie Munger On How To Build A $2 Trillion Startup" href="http://danshipper.com/charlie-munger-on-how-to-build-a-2-trillion-startup"&gt;Charlie Munger On How To Build A $2 Trillion Startup&lt;/a&gt;&lt;/h2&gt;
                                        &lt;p&gt;&lt;a href="http://danshipper.com/wp-content/uploads/2015/01/Charlie-Munger.png"&gt;&lt;img sizes="(max-width: 600px) 100vw, 600px" srcset="http://danshipper.com/wp-content/uploads/2015/01/Charlie-Munger.png 600w, http://danshipper.com/wp-content/uploads/2015/01/Charlie-Munger-300x160.png 300w" height="319" width="600" alt="Charlie-Munger" src="http://danshipper.com/wp-content/uploads/2015/01/Charlie-Munger.png" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Imagine it’s January of 1884 in Atlanta, Georgia. Glotz, an affluent fellow citizen, has invited you to participate in a peculiar competition:&lt;/p&gt;
&lt;p&gt;You and twenty others are invited to present a plan to start a business that will turn a $2 million investment into a business worth $2 trillion by the year 2034.&lt;/p&gt;
&lt;p&gt;Glotz will personally give $2 million to the person who presents the most compelling pitch in exchange for half of the equity in the new venture. There are only a few stipulations:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The new venture must exclusively sell beverages (specifically non-alcohol or “soft” beverages)&lt;/li&gt;
&lt;li&gt;For reasons unknown Glotz has decided that company must be named Coca-Cola&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You have 15 minutes. What would you say in your pitch?&lt;/p&gt;
&lt;p&gt;That’s the question that billionaire Coca-Cola investor Charlie Munger posed to an audience at a talk in July of 1996.&lt;/p&gt;
&lt;p&gt;What followed over the following few minutes was an entrancing exhibition of multi-disciplinary wisdom and business acumen. Munger’s main point is that the most complex questions often have basic answers rooted in elementary academic wisdom (mathematics, psychology, etc.) He wants to show that applying some of these ideas regularly can help us to better explain business success, and make better decisions.&lt;/p&gt;
&lt;p&gt;To start his talk, Munger lays out five principles he will use in his pitch to Glotz:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Decide big no-brainer questions first&lt;/li&gt;
&lt;li&gt;Use math to help explain the world&lt;/li&gt;
&lt;li&gt;Think through problems in reverse&lt;/li&gt;
&lt;li&gt;The best wisdom is elementary academic wisdom&lt;/li&gt;
&lt;li&gt;Big (lollapalooza) results only come from a large combination of factors&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Munger then dives in to solving the problem with his first principle: the big no-brainer questions that can be answered first.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;“Well, Glotz, the big “no-brainer” decisions that, to simplify our problem, should be made first are as follows: First, we are never going to create something worth $2 trillion by selling some generic beverage. Therefore, we must make your name, “Coca-Cola,” into a strong, legally protected trademark. Second, we can get to $2 trillion only by starting in Atlanta, then succeeding in the rest of the United States, then rapidly succeeding with our new beverage all over the world. This will require developing a product having universal appeal because it harnesses powerful elemental forces. And the right place to find such powerful elemental forces is in the subject matter of elementary academic courses.”&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Off the bat, it’s interesting to note how his prescription for growth largely mirrors the conventional startup wisdom espoused by Peter Thiel and others: grow quickly in a small market that you can dominate and then expand from there.&lt;/p&gt;
&lt;p&gt;In the case of software, that market is typically a small niche of consumers. In the case of Coca-Cola (especially in the 1800s) it’s a small concentration of consumers in a geographically circumscribed area.&lt;/p&gt;
&lt;p&gt;Next Munger moves on to his second and third principles: numerical fluency and thinking in reverse.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;“We will next use numerical fluency to ascertain what our target implies. We can guess reasonably that by 2034 there will be about eight billion beverage consumers in the world. On average, each of these consumers will be much more prosperous in real terms than the average consumer of 1884. Each consumer is composed mostly of water and must ingest about sixty-four ounces of water per day. This is eight, eight-ounce servings. Thus, if our new beverage, and other imitative beverages in our new market, can flavor and otherwise improve only twenty-five percent of ingested water worldwide, and we can occupy half of the new world market, we can sell 2.92 trillion eight-ounce servings in 2034. And if we can then net four cents per serving, we will earn $117 billion. This will be enough, if our business is still growing at a good rate, to make it easily worth $2 trillion.”&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Munger continues:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;“A big question, of course, is whether four cents per serving is a reasonable profit target for 2034. And the answer is yes if we can create a beverage with strong universal appeal. One hundred fifty years is a long time. The dollar, like the Roman drachma, will almost surely suffer monetary depreciation. Concurrently, real purchasing power of the average beverage consumer in the world will go way up. His proclivity to inexpensively improve his experience while ingesting water will go up considerably faster. Meanwhile, as technology improves, the cost of our simple product, in units of constant purchasing power, will go down. All four factors will work together in favor of our four-cent-per-serving profit target. Worldwide beverage-purchasing power in dollars will probably multiply by a factor of at least forty over 150 years. Thinking in reverse, this makes our profit-per-serving target, under 1884 conditions, a mere on fortieth of four cents or one tenth of a cent per serving. This is an easy-to-exceed target as we start out if our new product has universal appeal.”&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;In this section, Munger demonstrates the value of the basic math involved in a TAM (total addressable market) analysis as part of formulating a thesis for a business. Then he goes on to look at the basic cost structure of the business and ensures that the back-of-the-envelope math makes sense for him to reach his ultimate goal.&lt;/p&gt;
&lt;p&gt;As part of this analysis he makes a lot of forward looking predictions with the benefit of hindsight (the depreciation of the dollar, the real purchasing power of the average consumer, worldwide beverage purchasing power etc.) but for now we can ignore those issues.&lt;/p&gt;
&lt;p&gt;Munger continues on to the meat of his talk: the subject of creating a product compelling enough to be consumed daily by millions of people. This is where he’s going to bring out his fourth and fifth principles: the value of academic wisdom, and the forces that must be brought together to produce “lollapalooza” effects.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;“We must next solve the problem of invention to create universal appeal. There are two intertwined challenges of large scale: First, over 150 years, we must cause a new-beverage market to assimilate about one-fourth of the world’s water ingestion. Second, we must so operate that half the new market is ours while all of our competitors combined are left to share the remaining half. These results are lollapalooza results. Accordingly we must attack our problem by causing every favorable factor we can think of to work for us. Plainly, only a powerful combination of many factors is likely to cause the lollapalooza consequences we desire. Fortunately, the solution to these intertwined problems turns out to be fairly easy if one has stayed awake in all the freshman [college] courses.&lt;/p&gt;
&lt;p&gt;Let us start by exploring the consequences of our simplifying “no-brainer” decision that we must rely on a strong trademark. This conclusion automatically leads to an understanding of the essence of our business in proper elementary academic terms. We can see from the introductory course in psychology that, in essence, we are going into the business of creating and maintaining conditioned reflexes. The “Coca-Cola” trade name and trade dress will act as the stimuli, and the purchase and ingestion of our beverage will be the desired responses.&lt;/p&gt;
&lt;p&gt;And how does one create and maintain conditioned reflexes? Well, the psychology text gives two answers: (1) by operant conditioning and (2) by classical conditioning, often called Pavlovian conditioning to honor the great Russian scientist. And, since we want a lollapalooza result, we must use both conditioning techniques – and all we can invent to enhance effects from each technique.”&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Let’s take some time to define a few of the things that Munger is talking about here so that it’s easy to follow the rest of the argument. Munger is mostly interested in the psychology of consumer decision-making: how can we influence consumers to buy a lot of a certain type of product?&lt;/p&gt;
&lt;p&gt;There are two that he’s going to talk about here: operant conditioning and classical conditioning.&lt;/p&gt;
&lt;p&gt;Classical conditioning is the method by which a strong innate response can become invoked by a neutral stimulus.&lt;/p&gt;
&lt;p&gt;The most famous demonstration of classical conditioning is the work the Russian physiologist Ivan Pavlov did with dogs: he conditioned dogs to salivate at the sound of a bell.&lt;/p&gt;
&lt;p&gt;To do this, every time Pavlov fed his dogs he would ring a bell. After repeating this procedure a few times, Pavlov found that he could ring his bell and the dogs would salivate without any food being present! (It’s &lt;a href="http://www.cogsci.ecs.soton.ac.uk/cgi/psyc/newpsy?5.49"&gt;historically questionable&lt;/a&gt; whether Pavlov actually used a bell, but we’ll leave it in for simplicity.)&lt;/p&gt;
&lt;p&gt;Getting back to the subject at hand, it’s probably clear why this concept is so powerful: it means that it’s possible to trigger an innate biological response with a stimulus of your choice. Like, for example, a logo.&lt;/p&gt;
&lt;p&gt;Now let’s briefly talk about operant conditioning. B. F. Skinner, the famed Harvard behaviorist describes operant conditioning in this way:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;“When a bit of behavior is followed by a certain kind of consequence, it is more likely to occur again, and a consequence having this effect is called a reinforcer.”&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;In case this is confusing, Skinner elaborates with an example:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;“Food, for example, is a reinforcer to a hungry organism; anything the organism does that is followed by the receipt of food is more likely to be done again whenever the organism is hungry.”&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;There is also a distinction between different types of reinforcers: some are negative and some are positive:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;“Some stimuli are called negative reinforcers; any response which reduces the intensity of such a stimulus – or ends it – is more likely to be emitted when the stimulus recurs. Thus, if a person escapes from a hot sun when he moves under cover, he is more likely to move under cover when the sun is again hot. The reduction in temperature reinforces the behavior it is ‘contingent upon’ – that is, the behavior it follows. Operant conditioning also occurs when a person simply avoids a hot sun – when, roughly speaking, he escapes from the threat of a hot sun.”&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Now that we have a little bit more background, let’s get back to Munger. Right now he’s trying to figure out how to use operant conditioning to increase the consumption of his product:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;“The operant conditioning part of our problem is easy to solve. We need only (1) maximize rewards of our beverage’s ingestion and (2) minimize possibilities that desired reflexes, once created by us, will be extinguished through operant conditioning by proprietors of competing products.&lt;/p&gt;
&lt;p&gt;For operant conditioning rewards, there are only a few categories we will find practical:&lt;/p&gt;
&lt;p&gt;(1) Food value in calories or other inputs;&lt;/p&gt;
&lt;p&gt;(2) Flavor, texture, and aroma acting as stimuli to consumption under neural preprogramming of man through Darwinian natutal selection;&lt;/p&gt;
&lt;p&gt;(3) Stimulus, as by sugar or caffeine;&lt;/p&gt;
&lt;p&gt;(4) Cooling effect when man is too hot or warming effect when man is too cool.&lt;/p&gt;
&lt;p&gt;Wanting a lollapalooza result, we will naturally include rewards in all the categories.&lt;/p&gt;
&lt;p&gt;To start out, it is easy to decide to design our beverage for consumption cold. There is much less opportunity, without ingesting beverage, to counteract excessive heat, compared with excessive cold. Moreover, with excessive heat, much liquid must be consumed, and the reverse is not true. It also easy to decide to include both sugar and caffeine. After all, tea, coffee, and lemonade are already widely consumed. And, it is also clear that we must be fanatic about determining, through trial and error, flavor and other characteristics that will maximize human pleasure while taking in the sugared water and caffeine we will provide. And, to counteract possibilities that desired operant-conditioned reflexes, once created by us, will be extinguished by operant-conditioning-employing competing products, there is also an obvious answer: We will make it a permanent obsession in our company that our beverage, as fast as practicable, will at all times be available everywhere throughout the world. After all, a competing product, if it is never tried, can’t act as a reward creating a conflicting habit. Every spouse knows that.”&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;After talking through operant conditioning, Munger turns to classical conditioning:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;“We must next consider the Pavlovian [classical] conditioning we must also use. In Pavlovian conditioning, powerful effects come from mere association. The neural system of Pavlov’s dog causes it to salivate at the bell it can’t eat. And the brain of man yearns for the type of beverage held by the pretty woman he can’t have. And so, Glotz, we must use every sort of decent, honorable Pavlovian conditioning we can think of. For as long as we are in business, our beverage and its promotion must be associated in consumer minds with all other things consumers like or admire.&lt;/p&gt;
&lt;p&gt;Such extensive Pavlovian conditioning will cost a lot of money, particularly for advertising. We will spend big money as far ahead as we can imagine. But the money will be effectively spent. As we expand fast in our new beverage market, our competitors will face gross disadvantages of scale in buying advertising to create the Pavlovian conditioning they need. And this outcome, along with other volume-creates-power-effects, should help us gain and hold at least fifty percent of the new market everywhere. Indeed, provided buyers are scattered, our highest volumes will give us very extreme cost advantages in distribution.&lt;/p&gt;
&lt;p&gt;Moreover, Pavlovian effects from mere association will help us choose the flavor, texture, and color of our new beverage. Considering Pavlovian effects, we will have wisely chosen the exotic and expensive-sounding name “Coca-Cola,” instead of a pedestrian name like “Glotz’s sugared, caffeinated water.” For similar Pavlovian reasons, it will be wise to have our beverage look pretty much like wine, instead of sugared water. And so we will artificially color our beverage if it comes out clear. And we will carbonate our water, making our product seem like champagne, or some other expensive beverage, while also making its flavor better and imitation harder to arrange for competing products. And, because we are going to attach so many expensive psychological effects to our flavor, that flavor should be different from any other standard flavor so that we maximize difficulties for competitors and give no accidental same-flavor benefit to any existing product.”&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Having dealt with Pavlovian conditioning, Munger moves on to social proof:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;“What else, from the psychology textbook, can help our new business? Well, there is that powerful ‘monkey-see, monkey-do’ aspect of human nature that psychologists often call ‘social proof.’ Social proof, imitative consumption triggered by mere sight of consumption, will not only help induce trial of our beverage. It will also bolster perceived rewards from consumption. We will always take this powerful social-proof factor into account as we design advertising and sales promotion and as we forego present profit to enhance present and future consumption. More than with most other products, increased selling power will come from each increase in sales.&lt;/p&gt;
&lt;p&gt;We can now see, Glotz, that by combining (1) much Pavlovian conditioning, (2) powerful social-proof effects, and (3) wonderful-tasting, energy-giving, stimulating and desirably-cold beverage that causes much operant conditioning, we are going to get sales that speed up for a long time by reason of the huge mixture of factors we have chosen. Therefore, we are going to start something like an autocatalytic reaction in chemistry, precisely the sort of multi-factor-triggered lollapalooza effect we need.&lt;/p&gt;
&lt;p&gt;The logistics and the distribution strategy of our business will be simple. There are only two practical ways to sell our beverage: (1) as a syrup to fountains and restaurants, and (2) as a complete carbonated-water product in containers. Wanting lollapalooza results, we will naturally do it both ways. And, wanting huge Pavlovian and social-proof effects we will always spend on advertising and sales promotion, per serving, over 40 percent of the fountain price for syrup needed to make the serving.&lt;/p&gt;
&lt;p&gt;A few syrup-making plants can serve the world. However, to avoid needless shipping of mere space and water, we will need many bottling plants scattered over the world. We will maximize profits if (like early General Electric with light bulbs) we always set the first-sale price, either (1) for fountain syrup, or (2) for any container of our complete product. The best way to arrange this desirable profit-maximizing control is to make any independent bottler we need a subcontractor, not a vendee of syrup, and certainly not a vendee of syrup under a perpetual franchise specifying a syrup price frozen forever at its starting level.&lt;/p&gt;
&lt;p&gt;Being unable to get a patent or copyright on our super important flavor, we will work obsessively to keep our formula secret. We will make a big hoopla over our secrecy, which will enhance Pavlovian effects. Eventually food-chemical engineering will advance so that our flavor can be copied with near exactitude. But, by that time, we will be so far ahead, with such strong trademarks and complete, “always available” worldwide distribution, that good flavor copying won’t bar us from our objective. Moreover, the advances in food chemistry that help competitors will almost surely be accompanied by technological advances that will help us, including refrigeration, better transportation, and, for dieters, ability to insert a sugar taste without inserting sugar’s calories. Also, there will be related beverage opportunities we will seize.&lt;/p&gt;
&lt;p&gt;This brings us to a final reality check for our business plan. We will, once more, think in reverse like Jacobi. What must we avoid because we don’t want it? Four answers seem clear:&lt;/p&gt;
&lt;p&gt;First, we must avoid the protective, cloying, stop-consumption effects of aftertaste that are a standard part of physiology, developed through Darwinian evolution to enhance the replication of man’s genes by forcing a generally helpful moderation on the gene carrier. To serve our ends, on hot days a consumer must be able to drink container after container of our product with almost no impediment from aftertaste. We will find a wonderful no-aftertaste flavor by trial and error and will thereby solve this problem.&lt;/p&gt;
&lt;p&gt;Second, we must avoid ever losing even half of our powerful trademarked name. It will cost us mightily, for instance, if our sloppiness should ever allow sale of any other kind of “cola,” for instance, a “peppy cola.” If there is ever a “peppy cola,” we will be the proprietor of the brand.&lt;/p&gt;
&lt;p&gt;Third, with so much success coming, we must avoid bad effects from envy, given a prominent place in the Ten Commandments because envy is so much a part of human nature. The best way to avoid envy, recognized by Aristotle, is to plainly deserve the success we get. We will be fanatic about product quality, quality of product presentation, and reasonableness of prices, considering the harmless pleasure it will provide.&lt;/p&gt;
&lt;p&gt;Fourth, after our trademarked flavor dominates our new market, we must avoid making any huge and sudden change in our flavor. Even if a new flavor performs better in blind taste tests, changing to that new flavor would be a foolish thing to do. This follows because, under such conditions, our old flavor will be so entrenched in consumer preference by psychological effects that a big flavor change would do us little good. And it would do immense harm by triggering in consumers the standard deprival super-reaction syndrome that makes “take-aways” so hard to get in any type of negotiation and helps make most gamblers so irrational. Moreover, such a large flavor change would allow a competitor, by copying our old flavor, to take advantage of both (1) the hostile consumer super-reaction to deprival and (2) the huge love of our original flavor created by our previous work.&lt;/p&gt;
&lt;p&gt;Well, that is my solution to my own problem of turning $2 million into $2 trillion, even after paying out billions of dollars in dividends. I think it would have won with Glotz in 1884 and should convince you more than you expected at the outset. After all, the correct strategies are clear after being related to elementary academic ideas brought into play by the helpful notions.”&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;During the rest of the piece, Munger discusses the parallels between his fictional business plan and Coca-Cola’s actual business (hint: they’re pretty much the same.) He then goes on to relate his story to the main purpose of the talk: our failure to use basic academic wisdom to make better decisions.&lt;/p&gt;
&lt;p&gt;He chalks this up, in part, to a failure of academia to produce a useful synthesis of topics like psychology and behavioral economics. He thinks that academic departments are too narrowly focused, and the research of academics to circumscribed.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Is there bullshit to sniff out here?&lt;/strong&gt;&lt;br&gt;
If you scan the shelves at an airport bookstore, you’re likely to find lots of books that, like Munger’s talk, purport to unveil some of the key attributes of successful companies. If you’ve ever been tempted to pick up a copy of &lt;em&gt;Think Like Zuck: The Five Business Secrets of Facebook’s Improbably Brilliant CEO Mark Zuckerberg&lt;/em&gt; you know what I mean.&lt;/p&gt;
&lt;p&gt;Because this is a common trope in the business literature – and it’s one that we often swallow uncritically – I want to take a few paragraphs to instill in you a healthy dose of skepticism in any person that purports to unveil the hidden attributes of successful companies:&lt;/p&gt;
&lt;p&gt;First, anything that attempts to reduce the success of a business to a few key principles misses out on the obscene complexity that underlies the growth of any kind of organization.&lt;/p&gt;
&lt;p&gt;Second, it misses the fact that many (but not all) organizations are incentivized to hide the real story behind their growth in order to protect their image, their investors, their employees, or their (perceived or real) competitive advantages.&lt;/p&gt;
&lt;p&gt;Third, these attributes are subject to interpretation via the halo effect: they are seen as good ONLY because the company is successful. Many times you’ll see a CEO characterized as a visionary perfectionist when the stock is up, and an micro-managing egoist when the stock is down.&lt;/p&gt;
&lt;p&gt;Fourth, Munger’s talk is (knowingly) given with the benefit of hindsight. It’s easy to point to many of these things as sure signs of success – once the success has been achieved.&lt;/p&gt;
&lt;p&gt;Fifth, the attributes you see are subject to selection bias: people generally only write books or give talks about successful companies. Just because a successful company has attribute A, doesn’t mean that there aren’t a thousand other companies with attribute A that went to the graveyard.&lt;/p&gt;
&lt;p&gt;What we’re really looking for is evidence that a particular company attribute played a &lt;em&gt;causational&lt;/em&gt; role in their success – rather than just merely being associated with that success.&lt;/p&gt;
&lt;p&gt;This is incredibly difficult, if not impossible, to do.&lt;/p&gt;
&lt;p&gt;In the case of Munger’s talk I’m going to err on the side of believing him for two reasons:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;He puts his money where his mouth is. His very long investment track record provides some demonstration that his framework works at picking companies.&lt;/li&gt;
&lt;li&gt;He doesn’t claim universal applicability. His goal isn’t to give you a foolproof way of predicting company success – it’s to give you a framework, based in basic ideas, to help you think about that success.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So assuming we trust Munger, the next question we have to ask ourselves is: can we use what he’s saying?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Is all of this useful?&lt;/strong&gt;&lt;br&gt;
Clearly, if you’re running a big company this kind of framework could help you make better decisions. For example, had the executives at Coke who decided to introduce “New Coke” understood conditioning better they might have scrapped the plan before it became a disaster.&lt;/p&gt;
&lt;p&gt;Similarly, if you’re an institutional investor evaluating a large consumer business like Coke he provides you an interesting framework to think about.&lt;/p&gt;
&lt;p&gt;I think the argument can also be made that it provides a good framework for early-stage technology investors to think about – one that agrees with the startup-focused investors like Paul Graham, Peter Thiel, and others. (I think it’s always interesting when people who come from different backgrounds and work on different problems come to the similar conclusions about something, it usually means that there’s some truth to what they’re saying.)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Applying Munger’s framework to technology investing&lt;/strong&gt;&lt;br&gt;
If I had to summarize Munger’s advice in a few sentences (with the benefit of reading lots of other articles from him) it would be something like the following:&lt;/p&gt;
&lt;p&gt;In order to get large (lollapalooza) effects like rapid growth you need to harness lots of different types of elementary forces. The forces to focus on create what we call positive feedback loops: they’re self-reinforcing. A causes B, B causes more A, which causes more B.&lt;/p&gt;
&lt;p&gt;The forces of this type that Munger cites are psychological: operant conditioning and classical conditioning. All companies have to harness these kinds of psychological forces to grow. But there are other ones to look for as well:&lt;/p&gt;
&lt;ul id="draft_check_box_list_3"&gt;
&lt;li&gt;Economies of scale: the larger you are, the cheaper it is to produce your product, the more products you sell, the larger you get&lt;/li&gt;
&lt;li&gt;Network effects: the larger the network becomes, the more valuable the network is, the larger the network gets&lt;/li&gt;
&lt;li&gt;Word of mouth: the more of your product you sell, the more people talk about you, the more of your product you sell&lt;/li&gt;
&lt;li&gt;Big data effects: the more data a search engine has the, the better search results it can return, the more data it gets&lt;/li&gt;
&lt;li&gt;Incumbent advantages: the more large customers you have, the easier it gets to sign large customers, the more large customers you get&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Finding companies that harness these effects is important for technology investors because the venture investment model is predicated upon huge returns from companies that dominate large winner-take-all markets.&lt;/p&gt;
&lt;p&gt;And how do you get a winner-take all market?&lt;/p&gt;
&lt;p&gt;One company has to be able to build an ever-increasing advantage against its competitors. It needs to be able to achieve high enough velocity to escape the gravity of market competition.&lt;/p&gt;
&lt;p&gt;But how do you build this kind of ever-increasing lead?&lt;/p&gt;
&lt;p&gt;You effectively harness the self-reinforcing forces we’ve been discussing: conditioning, economies of scale, network effects, word of mouth, big data effects, and others.&lt;/p&gt;
&lt;p&gt;But what if you’re not an investor. What if you’re thinking of starting your own company? Can you use these ideas to come up with a startup?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Is this generative?&lt;/strong&gt;&lt;br&gt;
The first question to ask about his framework is this: is it generative?&lt;/p&gt;
&lt;p&gt;By this I mean, will it help me generate new ideas for businesses to start. The answer to this question is clearly: no.&lt;/p&gt;
&lt;p&gt;Thinking to yourself, “What companies can I start that will have self-reinforcing feedback loops?” doesn’t make your brain generate new ideas. As always, the best way to generate these ideas is through experience.&lt;/p&gt;
&lt;p&gt;Paul Graham writes, “The way to get startup ideas is not to try to think of startup ideas. It’s to look for problems, preferably problems you have yourself.”&lt;/p&gt;
&lt;p&gt;Ok, so Munger’s framework isn’t generative. The next question we have to ask ourselves is: is it diagnostic? In other words, assuming that Munger has identified some key causational elements of successful companies, how valuable is it for helping us diagnose companies at the idea stage?&lt;/p&gt;
&lt;p&gt;The answer to this question is: if you’re looking to build a billion dollar company, it’s at best a marginally helpful guide. And the fact that it’s not incredibly helpful isn’t really Munger’s fault. There’s just no framework of elements out there that would allow us to perfectly predict how well our ideas are going to turn out.&lt;/p&gt;
&lt;p&gt;There are lots of reasons for this. Here are a couple:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Success is stochastic not deterministic&lt;/li&gt;
&lt;li&gt;Execution is more important than mere idea&lt;/li&gt;
&lt;li&gt;Your initial idea of what you’re building is often much different than what you actually build&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Because what you actually build is often much different than what you think you’re building at the beginning, exact analysis of this kind is difficult to do. At best, what it can help you with is a general “sniff” test:&lt;/p&gt;
&lt;p&gt;In general, does my vision for this product seem like it has the potential to harness some of these forces?&lt;/p&gt;
&lt;p&gt;If the answer is yes then it’s time to get on to the next step and build the damn thing.&lt;/p&gt;
&lt;p&gt;–&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Works Cited:&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Poor Charlie’s Almanack: The Wit and Wisdom of Charles T. Munger, Expanded Third Edition&lt;/span&gt;, Charlie Munger&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Beyond Freedom and Dignity&lt;/span&gt;, B.F. Skinner&lt;/p&gt;
		     
	  	    &lt;p&gt;
		    &lt;h3&gt;19 Jan 2015, 4:45am | 
	            &lt;a href="http://danshipper.com/charlie-munger-on-how-to-build-a-2-trillion-startup#comments"&gt;&lt;span rel="224 http://danshipper.com/?p=224"&gt;2 comments&lt;/span&gt;&lt;/a&gt;		    &lt;/h3&gt;
                    &lt;/p&gt;
	     
		                        
                  &lt;/div&gt;&lt;/div&gt;&lt;a href="http://danshipper.com/charlie-munger-on-how-to-build-a-2-trillion-startup"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:32:43 UT
      </pubDate>
      <guid>
        http://danshipper.com/charlie-munger-on-how-to-build-a-2-trillion-startup
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://jlongster.com/How-I-Became-Better-Programmer
      </link>
      <description>
        &lt;a href="https://jlongster.com/How-I-Became-Better-Programmer"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 19:25:55 UT
      </pubDate>
      <guid>
        https://jlongster.com/How-I-Became-Better-Programmer
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://mostly-adequate.gitbooks.io/mostly-adequate-guide/
      </link>
      <description>
        &lt;a href="https://mostly-adequate.gitbooks.io/mostly-adequate-guide/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 22:13:42 UT
      </pubDate>
      <guid>
        https://mostly-adequate.gitbooks.io/mostly-adequate-guide/
      </guid>
    </item>
    <item>
      <title>
        Cultivate the Skill of Undivided Attention, or “Deep Work” &amp;#8211; Letters To A New Developer
      </title>
      <link>
        https://letterstoanewdeveloper.com/2019/12/19/cultivate-the-skill-of-undivided-attention-or-deep-work/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;
		&lt;p&gt;&lt;em&gt;This is a guest post from Josh Thompson. Enjoy.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Dear New Developer,&lt;/p&gt;
&lt;p&gt;You &lt;em&gt;know&lt;/em&gt; that there’s a chasm between your skill level and that of the mythical “senior software developer”.&lt;/p&gt;
&lt;p&gt;If you build a list of topics you encounter on your job that, if learned to a deep enough level, would put you on the same level as a senior developer, you’ll end up even more demoralized than before compiling that list.&lt;/p&gt;
&lt;p&gt;No need to assemble this list yourself! I’ve done it for you.&lt;/p&gt;
&lt;p&gt;Here’s the list of topics that I’d need to dedicate significant time to, in order to close the gap between me and the senior developers on our team, that I’ve encountered in my last two days of work:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Breaking complex unknowns into simpler unknowns that can be further split into individual tickets&lt;/li&gt;
&lt;li&gt;Adding tests to complex, legacy code, to guide further refactoring of said code.&lt;/li&gt;
&lt;li&gt;Using `grep` to comb through server logs to diagnose a hard-to-identify-and-reproduce problem&lt;/li&gt;
&lt;li&gt;Provisioning new servers&lt;/li&gt;
&lt;li&gt;Building bash scripts to automate complex workflows&lt;/li&gt;
&lt;li&gt;Digging into gem source code to can shed gem dependencies while maintaining certain features&lt;/li&gt;
&lt;li&gt;Understanding indexing well enough to see that certain queries that we thought were using indexes were not, and fix this oversight index on the fly, without causing any blips in availability&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Each of these line-items has many books written about the topic.&lt;/p&gt;
&lt;p&gt;It seems like you could fill a bookshelf with books that address knowledge senior developers have available to them inside their own heads.&lt;/p&gt;
&lt;p&gt;It takes me long enough to work through a single book, so imagining a bookshelf of extra-curricular reading is quite daunting.&lt;/p&gt;
&lt;p&gt;It might feel daunting for you, too.&lt;/p&gt;
&lt;h2&gt;Leading vs. lagging indicators&lt;/h2&gt;
&lt;p&gt;The above list of skills is a &lt;em&gt;lagging indicator&lt;/em&gt; of the underlying knowledge. We should not target improving &lt;em&gt;lagging&lt;/em&gt; indicators, we should improve &lt;em&gt;leading&lt;/em&gt; indicators.&lt;/p&gt;
&lt;p&gt;Josh, what is this ‘lagging and leading indicator’ stuff?&lt;/p&gt;
&lt;p&gt;Great question!&lt;/p&gt;
&lt;p&gt;A lagging indicator is “evidence that something has already happened.”&lt;/p&gt;
&lt;p&gt;If you got an A on a test, that is evidence that you learned the material.&lt;/p&gt;
&lt;p&gt;A leading indicator is “evidence that something will likely happen”.&lt;/p&gt;
&lt;p&gt;If you want to get an A on a test, you should study in a similar way as others who have gotten an A on that test. Maybe you need ten high-quality hours of study to get an A, so “number of high-quality study hours” would be a leading indicator of your grade.&lt;/p&gt;
&lt;p&gt;We no longer take tests (phew. I hated taking tests.) but we get mini-tests of our knowledge, daily. We’re paid to solve problems, which often require learning new things.&lt;/p&gt;
&lt;p&gt;Rather than focusing on a list of things other developers have learned, and targeting that list, I humbly propose that a leading indicator of acquiring this kind of knowledge is “hours per week spent in a state of intentional deep work”.&lt;/p&gt;
&lt;p&gt;The above list of topics are lagging indicators of a high degree of technical knowledge. Someone acquires the knowledge, then, and only then, can demonstrate that they have it.&lt;/p&gt;
&lt;p&gt;Leading indicators are “predictive”, in that if you can identify correctly those indicators, you can predict the outcome of the issue at hand.&lt;/p&gt;
&lt;p&gt;In this case, the issue at hand is “become significantly more experienced in the domain of software development”.&lt;/p&gt;
&lt;p&gt;I propose that a &lt;em&gt;leading indicator&lt;/em&gt; of someone gaining these skills is the amount of time they spend in a state of deep work.&lt;/p&gt;
&lt;p&gt;I’d encourage you to read &lt;a href="https://www.goodreads.com/book/show/25744928-deep-work"&gt;Deep Work: Rules for Focused Success in a Distracted World&lt;/a&gt;. The author makes a case for deep work being a key role in the success of “knowledge workers” (which includes many types of work, including, of course, software development.)&lt;/p&gt;
&lt;p&gt;If you’d rather not read the book, here’s the gist, from &lt;a href="https://www.samuelthomasdavies.com/book-summaries/business/deep-work/"&gt;this summary of the book&lt;/a&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;In order to produce the absolute best stuff you’re capable of, you need to commit to deep work.&lt;/li&gt;
&lt;li&gt;The ability to quickly master hard things and the ability to produce at an elite level, in terms of both quality and speed, are two core abilities for thriving in today’s economy.&lt;/li&gt;
&lt;li&gt;“To learn hard things quickly, you must focus intensely without distraction.”&lt;/li&gt;
&lt;li&gt;“Your work is craft, and if you hone your ability and apply it with respect and care, then like the skilled wheelwright you can generate meaning in the daily efforts of your professional life.”&lt;/li&gt;
&lt;li&gt;“The key to developing a deep work habit is to move beyond good intentions and add routines and rituals to your working life designed to minimize the amount of your limited willpower necessary to transition into and maintain a state of unbroken concentration.”&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Imagine two equally knowledgeable early-career software developers. They have the exact same skills on January 1, 2020. If the first software developer spends four hours a week doing deep work, while the second software developer spends fifteen hours a week doing deep work, their trajectories will be quite different, and that second developer will quickly gain technical knowledge and proficiencies.&lt;/p&gt;
&lt;p&gt;So, if you’re an early-career software developer, track the time you spend doing deep work. That has you focusing on a leading indicator of growing in your skills.&lt;/p&gt;
&lt;p&gt;At that point, you’ll benefit from Peter Drucker’s assessment:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;What is measured, improves.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;You’ll track how many hours you spend doing deep work, and by tracking it, you’ll do more and more of it.&lt;/p&gt;
&lt;h2&gt;In conclusion&lt;/h2&gt;
&lt;p&gt;Do more deep work, and over a year or two years, your skills will grow much faster than those doing less deep work. Eventually, you might find that you’re doing the work of a senior developer!&lt;/p&gt;
&lt;p&gt;Good luck!&lt;/p&gt;
&lt;p&gt;-Josh&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;a href="https://josh.works/"&gt;Josh&lt;/a&gt; looks forward to being a senior developer some day. He’s only a few years into his career in the software development industry, but enjoys getting to bring knowledge and skills from his prior careers into his current role. He lives in (and works remotely from) Golden, CO, with his wife and loves to rock climb and read books, and can often be spotted in Denver-area climbing gyms or local crags.&lt;/em&gt;&lt;/p&gt;
	&lt;/div&gt;&lt;/div&gt;&lt;a href="https://letterstoanewdeveloper.com/2019/12/19/cultivate-the-skill-of-undivided-attention-or-deep-work/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 22:13:53 UT
      </pubDate>
      <guid>
        https://letterstoanewdeveloper.com/2019/12/19/cultivate-the-skill-of-undivided-attention-or-deep-work/
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        http://www.jerrydallal.com/LHSP/LHSP.htm
      </link>
      <description>
        &lt;a href="http://www.jerrydallal.com/LHSP/LHSP.htm"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 22:14:06 UT
      </pubDate>
      <guid>
        http://www.jerrydallal.com/LHSP/LHSP.htm
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        http://www.catb.org/esr/faqs/hacker-howto.html
      </link>
      <description>
        &lt;a href="http://www.catb.org/esr/faqs/hacker-howto.html"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 22:14:16 UT
      </pubDate>
      <guid>
        http://www.catb.org/esr/faqs/hacker-howto.html
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://overreacted.io/my-decade-in-review/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;&lt;p&gt;I started this decade as a first-year college student fresh out of high school. I was 17, didn’t have a job, didn’t have any industry connections, and really didn’t know shit. And now you’re reading my blog! I would have been proud.&lt;/p&gt;
&lt;p&gt;I’ve told bits and pieces of my story on different podcasts. Now feels like an appropriate time to write down the parts that were most memorable to me.&lt;/p&gt;
&lt;p&gt;Every person’s story is unique and not directly reproducible. I’ve benefited immensely from the privilege of being born in an upper middle class family and looking like a typical coder stereotype. People took chances on me. Still, I hope that sharing my story can be helpful to compare our experiences. Even if our circumstances are too different, at least you might find some of it entertaining.&lt;/p&gt;
&lt;h2 id="2010"&gt;&lt;a aria-hidden="" href="#2010"&gt;&lt;/a&gt;2010&lt;/h2&gt;
&lt;p&gt;I was born in Russia and I finished the high school there in 2009. In Russia, higher education is free if you do well enough at tests. I tried my chances with a few colleges. I was particularly hoping to get into one college whose students often won programming competitions (which I thought was cool at the time).&lt;/p&gt;
&lt;p&gt;However, it turned out my math exam scores weren’t good enough. So there were not many options I could choose from that had to do with programming. From the remaining options, I picked a college that gave Macbooks to students. (Remember the white plastic ones with GarageBand? They were the best.)&lt;/p&gt;
&lt;p&gt;By the summer of 2010, I had just finished my first year there. It turned out that there wasn’t going to be much programming in the curriculum for two more years. But there was a lot of linear algebra, physics, and other subjects I didn’t find particularly interesting. Everything was well in the beginning, but I started slacking off and skipping lectures that I had to wake up early for. My gaps in knowledge gradually snowballed, and most of what I remember from my first year in the university is the anxiety associated with feeling like a total failure.&lt;/p&gt;
&lt;p&gt;Even for subjects I knew well, things didn’t quite go as I planned. Our English classes were very rudimentary, and I got a verbal approval from the teacher to skip most of them. But when I came for the final test, I wasn’t &lt;em&gt;allowed&lt;/em&gt; to turn it in unless I pay money for hours of “catch up training” with the same teacher. This experience left me resentful and suspicious of higher education.&lt;/p&gt;
&lt;p&gt;Aside from being a lousy student, I was also in my first serious relationship — and it wasn’t going very well either. I was unhappy, but I thought that you can solve this by continuing to be unhappy and “fixing” it. Unfortunately, I didn’t have the wisdom to get out of a non-working relationship for a few more years.&lt;/p&gt;
&lt;p&gt;Now onto the bright side. Professionally, 2010 was an exciting year for me. I got my first job as a software developer! Here’s how that happened.&lt;/p&gt;
&lt;p&gt;There was a small venue close to my college that hosted different events. This venue was a “business incubator” — mind you, not a Silicon Valley kind of business incubator — but a tiny Russian one. I have no idea what businesses they “incubated”. However, they hosted a talk about software development, and I decided to check it out because I was starving for that kind of content. I didn’t know any programmers in real life, and I didn’t know meetups existed!&lt;/p&gt;
&lt;p&gt;I don’t remember what the talk was about now. But I knew the person who gave it was an executive in a Russian-American outsourcing company. I’ve been programming since 12, so I approached him and asked if they’re hiring. He gave me an email, I went through their test exercises, and in a few weeks got the job.&lt;/p&gt;
&lt;p&gt;I started at my first job during the summer of 2010. My salary was $18k/year (yes that’s 18 and not 180). This is peanuts in the developed world, but again, this was Russia — so the rent was cheap too. I immediately moved out of my mom’s apartment and started renting a room for $150 a month. I was excited. With my first salary, I bought an iPhone and marvelled at how good the UI was.&lt;/p&gt;
&lt;p&gt;Summer came and went, and then the second college year started. But it started without me. Now that I was doing actual work and people payed me for it, I lost my last bits of motivation for sitting at lectures and doing exercises. I stopped going there and didn’t show up for the midterm exams. I returned my Macbook. The only time I went there again was five years later, to pick up my papers.&lt;/p&gt;
&lt;p&gt;A short digression. I’m not saying colleges are worthless, or that you should drop out. It was the right decision for me, but I knew I could fall back on my family (more on that later) when things are tough. I also already had a job.&lt;/p&gt;
&lt;p&gt;I had the privilege to be seen as knowledgeable &lt;em&gt;by default&lt;/em&gt; due to my background (a guy who started coding early). People who don’t fit this stereotype often get a degree just to gain access to that assumed competence. So there’s that.&lt;/p&gt;
&lt;h2 id="2011"&gt;&lt;a aria-hidden="" href="#2011"&gt;&lt;/a&gt;2011&lt;/h2&gt;
&lt;p&gt;Most of my job was fixing up poor code after cheaper outsourcing companies. Having no industry experience myself, I overengineered every project to try every cool technology I could get my hands on. I even put &lt;a rel="nofollow noopener noreferrer" href="https://www.microsoft.com/en-us/research/project/moles-isolation-framework-for-net/"&gt;random Microsoft Research projects&lt;/a&gt; in production. Sorry about that. I did some good work too.&lt;/p&gt;
&lt;p&gt;My first interesting work project involved a trip. Our client was an investment group in New York. I still don’t know anything about investments, but basically they had an email system that received orders, and those orders needed to go through different levels of approval. They had a service that manages that, but the service was extremely flaky, and nobody could figure out how it works. My job was to go onsite, work from New York for a month, and fix the service.&lt;/p&gt;
&lt;p&gt;The service was written by a contractor from a cheaper outsourcing company. Nine years later, I still remember his name. The most memorable part of that code was a single thirty thousand line function. To figure out what it does, I had to print it on paper, lay out the sheets on my desk, and annotate them with a pencil. It turned out that it was the same block of code, repeated fifty times with different conditions. I guess someone was paid by the number of lines of code.&lt;/p&gt;
&lt;p&gt;I spent that month adding a shitton of logging to figure out what the service does in production, and then rebuilding it from scratch to be less flaky. Working with a non-tech company was a perplexing experience. For example, I couldn’t push a bugfix without writing a Word document describing my changes and getting the IT department head to sign off on it. Now &lt;em&gt;that’s&lt;/em&gt; some code review.&lt;/p&gt;
&lt;p&gt;Close to the end of my trip, I went to see a concert at a bar late at night. The next morning I was supposed to present my month of work to the client. My meeting was scheduled for 9am. Unfortunately, I overslept and only woke up at 1pm that day. My manager apologized for me, and I went home bitterly embarrassed.&lt;/p&gt;
&lt;p&gt;There were no repercussions at work. The project was a success overall, and the client knew I’m some weird Russian dude who doesn’t know how to groom his hair. But I knew I made a fool of myself. I also wasn’t particularly looking forward to more “enterprise projects”. Work became a chore.&lt;/p&gt;
&lt;p&gt;I was back in Saint Petersburg in Russia. In the summer, the sky there doesn’t go dark. During one night of soul-searching, I hopped from a bar to another with a vague sense of unease. Around 7am, a lightbulb went off in my head. I ate a shawarma, took a subway to the office, waited for HR, and quit my job.&lt;/p&gt;
&lt;p&gt;My friend was planning a trip to Crimea (before it got annexed) and asked if I would like to join. I packed up a tent and an old Nokia phone that held battery for a week. We camped for two weeks, mostly naked, in a fog of alternative mind states. I barely remember anything from that trip except two episodes.&lt;/p&gt;
&lt;p&gt;Once, somebody threatened me with a knife. That person said he would kill me, but he was gone the next day, and everything went on as normal. Another time, I foolishly tried to swim around the cliff alone and almost drowned. I was saved by a rock in the sea that I climbed and passed out on for what felt like an hour.&lt;/p&gt;
&lt;p&gt;This trip acted like a hardware reset. My burnout was cured, and I was ready to write code again. (But don’t say I told you to almost die to cure a burnout.)&lt;/p&gt;
&lt;p&gt;The only problem was… my skills were irrelevant! Yikes.&lt;/p&gt;
&lt;p&gt;You see, I was mostly writing desktop software. Has anyone even heard of desktop software? That’s not a thing anymore. Either you do backend, or you do mobile, or you do front-end. I didn’t know anything about either of them. And I didn’t have a job. So I had to move back to live with my Mom. (Thanks, Mom!)&lt;/p&gt;
&lt;p&gt;Soon, I saw a post on a social network. It was written by a Russian guy who came back from the Silicon Valley to Russia. He was looking for people who would volunteer to work on his projects for free, in return for him teaching us web development for free. At the time, that sounded like a good deal to me.&lt;/p&gt;
&lt;p&gt;I joined this program. I found out quickly enough that there was no real teaching involved: we were given a few tutorials from the web, and we mostly learned from helping each other. Luckily, I could afford to do that for some time while I lived at my Mom’s place. I learned Git, basics of Python, Django, a bit of CSS and JavaScript, and some Bash to deploy my changes. Hello Web, here I go.&lt;/p&gt;
&lt;p&gt;Nine years later, I’m still unsure how I feel about this program. On the one hand, we were working on his projects for free. On the other hand, we were given full root access, and it was really exciting to be able to push our changes in production and learn from our mistakes. It gave us a structure for learning. It didn’t cost us anything, and you could drop out any time. The projects had some social utility due to being around education. This reminded me of open source.&lt;/p&gt;
&lt;p&gt;I still feel grateful to this person for setting up this ad hoc “bootcamp” and being my mentor. But I don’t want to imply that working for free is a good way to practice in general. I’m not offering advice here — I am only telling my story.&lt;/p&gt;
&lt;p&gt;I built a dashboard where we could track our own learning achievements. My mentor suggested that I pitch it as a product to companies that run courses. My brief foray into playing “startups” was awkward. I didn’t know what product I was building, and I pitched different things to different people. Essentially, I ended up making several completely different websites for different clients with a single engine, and earned about $200 in the process. I wasted months of my time on it, as well as the time of friends who offered to help. I was ashamed of it, and shut it down. The silver lining was that I became a web developer.&lt;/p&gt;
&lt;p&gt;But I still didn’t have a job.&lt;/p&gt;
&lt;h2 id="2012"&gt;&lt;a aria-hidden="" href="#2012"&gt;&lt;/a&gt;2012&lt;/h2&gt;
&lt;p&gt;As a 20 year old web developer, there was only one place I wanted to work at. It was a Russian social media company. Everybody in Russia used their product. That product was very polished. And the team was considered &lt;em&gt;cool&lt;/em&gt;. Almost elite.&lt;/p&gt;
&lt;p&gt;Their executives often posted about how well-paid their engineers are. The small team of engineers seemed happy with the technical challenges and how the company treated them. In the Russian tech circles, many knew their names.&lt;/p&gt;
&lt;p&gt;My mentor introduced me to their CTO, and I got a takehome exercise in JavaScript. It involved building a clone of their typeahead where you could select friends to message. I spent two weeks building it. It was pixel perfect in all browsers. I took care to replicate a similar caching and debouncing behavior.&lt;/p&gt;
&lt;p&gt;The onsite interview was a disaster. Clearly, I didn’t have the experience at their scale. However, they said they’re willing to give me a try if I “understand their product”. They gave me a take-home exercise of designing a logged out state for that social media website. They wanted it to show a picture of a feature phone — many people didn’t know the mobile website works on cheap phones.&lt;/p&gt;
&lt;p&gt;I spent a week designing that page. I did a lot of tiny details and even hid some Easter eggs in it. I was proud of myself. However, I couldn’t find any decent designs of a feature phone that wouldn’t look ugly. Instead, I put a beautiful iPhone design there. So aesthetically pleasing, I thought.&lt;/p&gt;
&lt;p&gt;Of course, I got rejected. I ignored literally the only hard requirement — why was I so dense? I cried for a few hours because I didn’t really want to work anywhere else. I was still living with my Mom and was making no money.&lt;/p&gt;
&lt;p&gt;At the time, I was seriously doubting my skills. Many things seemed “magic” to me. I started having doubts about whether dropping out was a good idea, after all. I signed up for an iOS development course on iTunes U. I also signed up for two courses on Coursera: Compilers and Machine Learning. Maybe they would make me a “real programmer”.&lt;/p&gt;
&lt;p&gt;It was lonely to go through these courses on my own. I organized a tiny meetup with a few people from our web development “bootcamp”. We would gather and watch different online courses together at my mentor’s coworking space.&lt;/p&gt;
&lt;p&gt;A month into it, I got an email. Someone was looking to hire a developer, and he heard about me from a person who went to my meetup. I was sick with mono and ignored the email, but this guy kept emailing me. He wanted to skype.&lt;/p&gt;
&lt;p&gt;Roman Mazurenko was not a typical startup founder. Roman was interested in DIY publishing. Together with a couple of friends, for a few years, he somehow &lt;a rel="nofollow noopener noreferrer" href="https://youtu.be/Wj2FmNGw47c?t=9"&gt;made Moscow cool&lt;/a&gt;. He organized parties and posed for fashion magazines. I didn’t know what to expect. But Roman was very down-to-earth and fun to talk to. His dream was to build a DIY publishing platform like in this &lt;a rel="nofollow noopener noreferrer" href="https://vimeo.com/55247463"&gt;concept video&lt;/a&gt;. I would have to move to Moscow and learn iOS development on the go. (By the way, the video guy is not Roman but a friend, and the app in the video is a fake animation made with Flash. Roman was great at crafting smoke and mirrors.)&lt;/p&gt;
&lt;p&gt;I said yes.&lt;/p&gt;
&lt;p&gt;I didn’t finish my Compilers and Machine Learning courses. I learned enough to know these topics aren’t magic. After that, I lost most of my interest in them.&lt;/p&gt;
&lt;h2 id="2013"&gt;&lt;a aria-hidden="" href="#2013"&gt;&lt;/a&gt;2013&lt;/h2&gt;
&lt;p&gt;By 2013, my salary was $30k/year — almost twice what I made at my previous job. While low by US standards, it was pretty decent in Russia. I also negotiated some stock at Stampsy (spoiler alert: it ended up completely worthless).&lt;/p&gt;
&lt;p&gt;Our team had five developers and two designers. We started by developing an iPad app, but neither of us had any real knowledge of iOS. I remember my relief when a teammate figured out how to implement the animation we needed for the first time. Until then, I thought we were doomed.&lt;/p&gt;
&lt;p&gt;For a few months, I literally lived in our office. Looking back at this period, I’m not proud of my life-work balance, and it was not healthy. However, I learned more during these months than in two years before, and I don’t regret them.&lt;/p&gt;
&lt;p&gt;Eventually, I moved out of the office. I’ve started to live in the same flat as Roman. My room cost me $1k/month. It was a spacious flat in the only area of Moscow that I enjoyed, and it was only five minutes of walk from the office.&lt;/p&gt;
&lt;p&gt;We thought that some of the code we wrote might be useful to others. So we started publishing those pieces on GitHub. We didn’t expect anything grand, and even getting a couple of contributions was really nice. The most popular project I worked on during that period has 30 stars. To us, that was a &lt;em&gt;lot&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;A designer on our team introduced me to Bret Victor’s talks — particularly, to &lt;a rel="nofollow noopener noreferrer" href="https://vimeo.com/36579366"&gt;Inventing on Principle&lt;/a&gt;. I thought it was a very good talk. A &lt;em&gt;very&lt;/em&gt; good one.&lt;/p&gt;
&lt;p&gt;In April, we released the &lt;a rel="nofollow noopener noreferrer" href="https://www.youtube.com/watch?v=PjaL0xFbEY8"&gt;iPad app&lt;/a&gt; we’ve been working on. Apple reached out to our team and asked for assets to feature it in the App Store. We were over the moon. It stayed featured for weeks, and people started using it.&lt;/p&gt;
&lt;p&gt;Our excitement quickly wore down as we realized there was no product market fit. The app was designed to create beautiful magazine-like layouts, but nobody had any beautiful content on an iPad. Also, the iPad camera had a horrible quality. The product didn’t make any sense. How could we not realize this?&lt;/p&gt;
&lt;p&gt;My personal relationship was falling apart too. We weren’t a good fit, and mostly clung to each other out of fear of being alone. We finally broke up.&lt;/p&gt;
&lt;p&gt;For a few months, I didn’t talk to people from our shared mutual circle and focused on work. But I realized that I missed one particular friend. I wrote to her, and she said she missed me too. I arranged a plan for a trip together.&lt;/p&gt;
&lt;p&gt;I caught a cold. As the day of our would-be trip got closer, I felt worse, but I was hoping that maybe I’d be okay. When my train from Moscow to St. Petersburg had arrived, I clearly had a temperature. She said to come to her place anyway. She made me some hot tea, gave me warm socks, and we kissed. I moved in.&lt;/p&gt;
&lt;h2 id="2014"&gt;&lt;a aria-hidden="" href="#2014"&gt;&lt;/a&gt;2014&lt;/h2&gt;
&lt;p&gt;For me, 2014 was the year of React.&lt;/p&gt;
&lt;p&gt;After a brief existential crisis, we abandoned the iPad app and decided to pivot to a webapp. That meant I had to learn JavaScript, this time for reals. We built a decent prototype with Backbone, but interactive parts were a pain to code.&lt;/p&gt;
&lt;p&gt;My colleague saw React but initially dismissed it. But a few months later, he told me React wasn’t actually that bad. I decided to give React a try. Ironically, the first component I converted from Backbone to React was a Like button.&lt;/p&gt;
&lt;p&gt;And it worked well. &lt;em&gt;Really&lt;/em&gt; well. It felt unlike anything I’ve seen.&lt;/p&gt;
&lt;p&gt;React wasn’t a hard sell for the team. Over the next year we gradually converted all of our UI to React while shipping new features. React and the principle of unidirectional data flow allowed us to develop faster and with fewer bugs.&lt;/p&gt;
&lt;p&gt;We started a private beta, and some photographers enjoyed creating visual stories with it. It was something between Medium, Pinterest, and Tumblr. There wasn’t a lot of traction, but it wasn’t a complete failure like the iPad app.&lt;/p&gt;
&lt;p&gt;The only problem with using React was that there was virtually no ecosystem. When we just started, there was only one router (which was &lt;em&gt;not&lt;/em&gt; React Router), and we couldn’t figure out how to use it. So we made our own. After React Router came out, we adopted it and &lt;a rel="nofollow noopener noreferrer" href="https://github.com/ReactTraining/react-router/pull/388"&gt;added&lt;/a&gt; a feature we needed for our product.&lt;/p&gt;
&lt;p&gt;There was no drag and drop solution for our use cases, so I &lt;a rel="nofollow noopener noreferrer" href="https://github.com/react-dnd/react-dnd/releases/tag/v0.1.0"&gt;ported&lt;/a&gt; my colleague’s library to React. I made &lt;a rel="nofollow noopener noreferrer" href="https://github.com/gaearon/react-document-title/releases/tag/v0.1.0"&gt;a helper&lt;/a&gt; to manage document titles. Wrote &lt;a rel="nofollow noopener noreferrer" href="https://github.com/paularmstrong/normalizr/releases/tag/v0.1.1"&gt;another library&lt;/a&gt; to normalize API responses. Jing Chen from the React IRC channel suggested the core idea, and it worked! Little did I know that in a few years, Twitter would build their new website with this library and maintain it.&lt;/p&gt;
&lt;p&gt;I wanted to contribute to React itself, too. I reached out to Paul O’Shannessy and asked if there were any pull requests I could work on. I finished &lt;a rel="nofollow noopener noreferrer" href="https://github.com/facebook/react/pull/1601"&gt;my first task&lt;/a&gt; in a few days, but it didn’t get merged until a few months later. Big project release cycles, and all that. I was frustrated by the slowness in response so I put effort into the ecosystem instead. In retrospect, that was a lot more impactful.&lt;/p&gt;
&lt;p&gt;In 2014, I did some of my first public speaking. I gave sort of a lecture about React at our office. It ended up going for two hours, and I’m still surprised that most of the people who showed up were polite enough to stay to the end.&lt;/p&gt;
&lt;p&gt;Later, I signed up to give a talk at the BerlinJS meetup. My topic was “React and Flux”. I didn’t practice my talk, and I only went through the first half when my time ran out. People rolled their eyes, and I finally learned my lesson. From that point on, I would rehearse every talk from three up to fifteen times.&lt;/p&gt;
&lt;p&gt;In 2014, I got my first email from a Facebook recruiter. I missed it in my inbox and only found it many months later. We still chatted eventually, but it turned out that hiring me in USA wouldn’t be easy because I didn’t have enough years of experience &lt;em&gt;and&lt;/em&gt; I dropped out of college. Oops.&lt;/p&gt;
&lt;p&gt;There was one project I started in 2014 that was particularly dear to me. Like most important things in my life, it happened randomly. I was converting our app from require.js to webpack to enable code splitting. I read about a bizarre webpack feature called “hot module replacement” that allowed you to edit CSS without reloading the page. But in webpack, it could work for JavaScript too.&lt;/p&gt;
&lt;p&gt;I was really confused by this feature so I &lt;a rel="nofollow noopener noreferrer" href="https://stackoverflow.com/questions/24581873/what-exactly-is-hot-module-replacement-in-webpack"&gt;asked&lt;/a&gt; about it on StackOverflow. Webpack was still very new, and its creator noticed my question and left a response. It gave me enough information to see I could tie this feature with React, in the spirit of the first demo from Bret Victor’s talk I mentioned earlier.&lt;/p&gt;
&lt;p&gt;I wrote an extremely hacky proof of concept by editing React source code and adding a bunch of global variables. I decided I won’t go to sleep until it works, and by 7am I had a demo I could &lt;a rel="nofollow noopener noreferrer" href="https://twitter.com/dan_abramov/status/485611717183819776"&gt;tweet&lt;/a&gt;. Nobody cared about my Twitter before that, but this received some likes and retweets, and those 20 retweets were hugely validating. I knew then I’m not the only one who thinks this is exciting. This proof of concept was a throwaway effort and I didn’t have time to keep working on it at my job. I took a vacation, and finished off the &lt;a rel="nofollow noopener noreferrer" href="https://github.com/gaearon/react-hot-loader/tree/v0.1.0"&gt;prototype&lt;/a&gt; there.&lt;/p&gt;
&lt;p&gt;Quick disclaimer: again, I’m not saying you “need to” work nights or vacations. I’m not glorifying hustle, and there are plenty of people with great careers who did none of that. In fact, if I were better at time management, I could probably find a way to squeeze those non-interrupted hours in my regular day, or to learn to make progress with interruptions. I am sharing this because I’m telling my story, and it would be a lie to pretend I did everything in a 40 hour week.&lt;/p&gt;
&lt;h2 id="2015"&gt;&lt;a aria-hidden="" href="#2015"&gt;&lt;/a&gt;2015&lt;/h2&gt;
&lt;p&gt;Our product went out of a private beta. It was growing, but slowly and linearly. The company was running out of funding and struggled to raise more money. And I wanted to spend more and more time on my open source projects.&lt;/p&gt;
&lt;p&gt;I also wanted to give my first conference talk. Naturally, I wanted to talk about hot reloading, but I knew somebody already mentioned it at ReactConf, and I thought people wouldn’t be excited about it. I decided to add some spice to my &lt;a rel="nofollow noopener noreferrer" href="https://github.com/react-europe/cfp-2015/pull/7"&gt;talk proposal&lt;/a&gt; by adding “with time travel” — again, inspired by Bret’s demo. The proposal got accepted, and for a few months I didn’t think much about it.&lt;/p&gt;
&lt;p&gt;In April, my salary got delayed by several weeks. It went through eventually, but I realized it’s time to look for a new job. I found some company using one of my projects, and they agreed to sponsor my work on it for a few months.&lt;/p&gt;
&lt;p&gt;My girlfriend asked if I wanted to get married. I said I thought I’d get married late in my 30s. She asked: “Why?” I couldn’t really find any justification for waiting so we soon bought rings and got married. Our wedding has cost us $100.&lt;/p&gt;
&lt;p&gt;The deadline for my talk was approaching. But I had no idea how to implement “time travel”. I knew that Elm had something similar, but I was scared to look at it because I worried I’d find out time travel can’t be implemented well in JS.&lt;/p&gt;
&lt;p&gt;At the time, there were many Flux libraries. I’ve tried a few of those, notably Flummox by Andrew Clark, and I had a vague sense that making hot reloading work with Flux would &lt;em&gt;also&lt;/em&gt; let me implement time travel. Sunil’s &lt;a rel="nofollow noopener noreferrer" href="https://gist.github.com/threepointone/43f16389fd96561a8b0b"&gt;gist&lt;/a&gt; led me to an &lt;a rel="nofollow noopener noreferrer" href="https://gist.github.com/gaearon/c02f3eb38724b64ab812"&gt;idea&lt;/a&gt;: a variant of Flux pattern with a reducer function instead of a store. I had a &lt;a rel="nofollow noopener noreferrer" href="https://twitter.com/dan_abramov/status/597391033513697281"&gt;neat name&lt;/a&gt; in mind for it already. And I really needed it for my talk!&lt;/p&gt;
&lt;p&gt;I implemented Redux just in time for my demo of time travel. My first talk rehearsal was on Skype. I was sweating, mumbling, and running over it too fast. At the end of my rehearsal, I asked the organizer if my talk was any good. He said “well… people &lt;em&gt;like&lt;/em&gt; you” which I took as an euphemism for horrible.&lt;/p&gt;
&lt;p&gt;I asked a designer friend from the startup I just quit to help make my slides pretty. I added animations and transitions. The more polished my talk looked, the calmer and more confident I felt. I practiced it a dozen times.&lt;/p&gt;
&lt;p&gt;I flew to Paris for my first technical conference. This was probably the happiest day of my life. For the first time, I put faces next to avatars. There were UI nerds and my personal heroes around me. It felt like going to Hogwarts.&lt;/p&gt;
&lt;p&gt;My talk almost didn’t happen. In the morning, I found that my laptop refused to connect to the projector. I only had a few hours left. Christopher Chedeau was kind enough to lend me his laptop, and I transferred my live demo setup to his computer (except for the Sublime license, as you may know if you watched it).&lt;/p&gt;
&lt;p&gt;At first, my demo didn’t run on Christopher’s laptop because we had different Node versions. The conference WiFi was so bad that downloading another Node version was a non-starter. Luckily, I found an npm command that rebuilds the binaries. It saved my demo. I gave my talk with his computer, and it &lt;a rel="nofollow noopener noreferrer" href="https://www.youtube.com/watch?v=xsSnOQynTHs"&gt;went well&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I met many people in the audience who I already knew from Twitter. One of them was Jing Chen. I remembered her from our IRC chat on the React channel, and came to say hi. She asked whether FB recruiters contacted me before, and I said I couldn’t get a US visa. Jing asked whether I’m interested in working at the London office, and I had no idea there even &lt;em&gt;was&lt;/em&gt; a London office! I called my wife and asked if she’s up for moving to London. I thought she’d hate the idea, but she immediately said yes. So I said yes to an interview.&lt;/p&gt;
&lt;p&gt;There were four people from FB at the conference, so Jing arranged a full interview right at the conference hotel. It was a regular interview process, except it was in Paris and everyone was sweaty because it was so hot outside. &lt;/p&gt;
&lt;p&gt;Everything happened so spontaneously that I neither had time to prepare, nor to get nervous. At one point I freaked out and panicked because I couldn’t write three lines of code that swap two items in an array. I asked Jing to look away for a few seconds. She said “I know you can swap two items”, and that gave me the confidence to finish the answer and make it through the interview. I probably didn’t pass with flying colors, but I got the offer.&lt;/p&gt;
&lt;p&gt;My talk got really popular. Andrew Clark has already deprecated Flummox — the most popular Flux library — in favor of Redux, which he co-wrote with me. People started putting Redux in production. New learners were confused by the README, which was written for early adopters who had all the existing context. I didn’t have a job, and it would take me several more months to get a UK visa.&lt;/p&gt;
&lt;p&gt;I started a Patreon to sustain my projects for a few months — and specifically to write Redux documentation, create small example apps, and record some free videos about it. I raised about $5k/month on Patreon which was more than any salary I made by that point in my life. Folks from Egghead sent me some mic gear, and I recorded my “Getting Started with Redux” course. I can’t watch it without cringing today, but it has been very popular and made me good money (around $3k/month in royalties) for quite a while — even though it was free.&lt;/p&gt;
&lt;p&gt;FB took care of handling most of the immigration process. My wife and I only had to fill some papers, and I had to take an English exam and do some health checks. FB did most of the work to relocate us, including moving our cat from Russia to UK (which cost around $5k). I was hired at engineering level 4, with initial base salary of $100k/year and an initial restricted stock unit grant of $125k vesting over four years. I also had a signing bonus of $18k which helped a lot as we were settling in. (By the way, tech salaries are lower in UK than in US.)&lt;/p&gt;
&lt;p&gt;We arrived to London at the end of November 2015. We’ve never been to London before. We took a black cab from the airport. We couldn’t figure out how to turn off the heating in the cab for ten minutes so we got very sweaty and couldn’t see anything through the window. When we turned off the fan and the window cleared up, our eyes were wide like saucers. London was beautiful.&lt;/p&gt;
&lt;p&gt;The next day, Roman Mazurenko got hit to death by a careless driver. He just got his US visa approved, and he came to Moscow to pick up his documents. He once told me that there’s something devilish about Moscow. It doesn’t just let you go. I would not see my friend again. Not in 2015, not ever.&lt;/p&gt;
&lt;p&gt;Roman has had a sort of a &lt;a rel="nofollow noopener noreferrer" href="https://romanmazurenko.com/"&gt;digital&lt;/a&gt; &lt;a rel="nofollow noopener noreferrer" href="https://www.theverge.com/a/luka-artificial-intelligence-memorial-roman-mazurenko-bot"&gt;afterlife&lt;/a&gt;, courtesy of his friends. I know for a fact he would’ve loved the irony of having a two point five star &lt;a rel="nofollow noopener noreferrer" href="https://apps.apple.com/us/app/roman-mazurenko/id958946383"&gt;App Store rating&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="2016"&gt;&lt;a aria-hidden="" href="#2016"&gt;&lt;/a&gt;2016&lt;/h2&gt;
&lt;p&gt;New job. New city. New country. Different language. Unfamiliar accent. Big company. Orientation. Meeting rooms. Projects. Teams. Documents. Forms. Shit. Fuck. Fuck. Fuckety Fuck, Shit, Oh Dear, Blimey!&lt;/p&gt;
&lt;p&gt;I barely remember the first few months. I was in a constant state of stress from trying to understand what people are saying without subtitles. What the hell is my manager telling me? Is it rude to ask to repeat again? Spell it for me?&lt;/p&gt;
&lt;p&gt;What, I need to call a lady in Scotland to get a national insurance number &lt;em&gt;by phone&lt;/em&gt;? I don’t get a word she’s saying. What even &lt;em&gt;is&lt;/em&gt; the national insurance? Why do I have a “zero” tax code and why is my salary less than I expected? Wait, people &lt;em&gt;actually pay taxes&lt;/em&gt; here? What do I do when I’m sick? What’s NHS?&lt;/p&gt;
&lt;p&gt;During my first trip to US in 2016 (part of onboarding), I forgot to eat the whole day, drank a lot of coffee, and had a full-fledged panic attack trying to explain how hot reloading works to a colleague. We called an ambulance, and I got a $800 bill (thankfully, paid by FB — or at least I don’t recall paying it myself).&lt;/p&gt;
&lt;p&gt;Relocation was nerve-wracking even though the company handled most of the difficulties. I thought I did everything in the onboarding instructions, but I forgot to register with the police. (I confused this with registering at the post office, which we also had to do.) I only found out that we screwed up months later, and we were told it might affect our visas. Luckily, it didn’t so far.&lt;/p&gt;
&lt;p&gt;Originally, I was supposed to join the React Native team in London. Usually, we hire people to go through Bootcamp and pick a team, but I didn’t have that freedom. I was preallocated. However, I wasn’t very excited about React Native in particular. I talked to Tom Occhino (he managed the React team at that time), and he suggested that I can join the &lt;a rel="nofollow noopener noreferrer" href="https://reactjs.org/community/team.html"&gt;React Core&lt;/a&gt; team (based in US) as the only UK member. I was already used to remote work from open source, so I agreed.&lt;/p&gt;
&lt;p&gt;In 2016, there was a React boom, but everybody made their own “boilerplate” with a bundler, watcher, compiler, and so on. React became synonymous with modular JavaScript, ES6, and all the tooling complexity. Christopher Chedeau suggested to prototype a command-line interface for getting started with React. We made the first version in a few weeks and released &lt;a rel="nofollow noopener noreferrer" href="https://reactjs.org/blog/2016/07/22/create-apps-with-no-configuration.html"&gt;Create React App&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="2017"&gt;&lt;a aria-hidden="" href="#2017"&gt;&lt;/a&gt;2017&lt;/h2&gt;
&lt;p&gt;Egghead courses continued to bring steady side income with royalties. I didn’t think twice before spending them on food delivery or nice clothes.&lt;/p&gt;
&lt;p&gt;It’s only in 2017 that I came to realize that these royalties are taxable as foreign income, and that I owe Her Majesty something like $30k. Oops. Like an adult, I got an accountant. Fixing this mess depleted all my savings again.&lt;/p&gt;
&lt;p&gt;At work, we spent most of 2017 rewriting React from scratch. You know the result of it as &lt;a rel="nofollow noopener noreferrer" href="https://reactjs.org/blog/2017/09/26/react-v16.0.html"&gt;React 16&lt;/a&gt;. Sophie tells the story of how we did it &lt;a rel="nofollow noopener noreferrer" href="https://engineering.fb.com/web/react-16-a-look-inside-an-api-compatible-rewrite-of-our-frontend-ui-library/"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Aside from taxes, there wasn’t a lot happening in my personal life. I was still settling in. I got less shy dealing with bureaucracies. I could make and take phone calls without freaking out. I watched movies without subtitles. I learned how to deal with NHS and with private insurance. I stopped doing side projects.&lt;/p&gt;
&lt;h2 id="20182019"&gt;&lt;a aria-hidden="" href="#20182019"&gt;&lt;/a&gt;2018–2019&lt;/h2&gt;
&lt;p&gt;The last two years have been a blur. I’m still too close to them to have a clear perspective on what was important.&lt;/p&gt;
&lt;p&gt;Professionally, our projects are as demanding as ever. If you follow React, you know about &lt;a rel="nofollow noopener noreferrer" href="https://reactjs.org/blog/2018/03/01/sneak-peek-beyond-react-16.html"&gt;some things&lt;/a&gt; &lt;a rel="nofollow noopener noreferrer" href="https://reactjs.org/blog/2018/11/13/react-conf-recap.html"&gt;we have been working on&lt;/a&gt;. I’ve grown as an engineer, and still have much to learn. Our London team has grown — I’m not alone now.&lt;/p&gt;
&lt;p&gt;People occasionally recognize me. This is humbling. Someone once recognized me in a sauna and started complaining about React. Please don’t be that person.&lt;/p&gt;
&lt;p&gt;I got promoted. I started this blog as a side project. I have &lt;a rel="nofollow noopener noreferrer" href="https://justjavascript.com/"&gt;another side project&lt;/a&gt; coming, which I’ve been musing about for the better part of these two years. I met more people from the internet and put more faces to avatars. This is fun.&lt;/p&gt;
&lt;p&gt;I always knew that I liked building UIs. I got hooked on Visual Basic. I spent this decade building UIs, and then building a way to build UIs. And then talking about it and explaining it. But I realize now that my drive to &lt;em&gt;explain&lt;/em&gt; things is just as important to me as my drive to build. Perhaps, even more important.&lt;/p&gt;
&lt;p&gt;I look forward to doing more of that in the next decade.&lt;/p&gt;
&lt;p&gt;Or, should I say, &lt;em&gt;this&lt;/em&gt; decade?&lt;/p&gt;
&lt;p&gt;Welcome to the twenties.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;a href="https://overreacted.io/my-decade-in-review/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 22:14:45 UT
      </pubDate>
      <guid>
        https://overreacted.io/my-decade-in-review/
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://www.2uo.de/myths-about-urandom/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;article&gt;
&lt;header&gt;
&lt;h2&gt;Myths about /dev/urandom&lt;/h2&gt;


&lt;/header&gt;

&lt;p&gt;
There are a few things
about /dev/urandom and /dev/random
that are repeated again and again.
Still they are false.
&lt;/p&gt;
			

			
&lt;dl&gt;

&lt;dt&gt;
&lt;p&gt;
&lt;strong&gt;
/dev/urandom is insecure. Always use /dev/random for cryptographic purposes.
&lt;/strong&gt;
&lt;/p&gt;
&lt;/dt&gt;

&lt;dd&gt;
&lt;p&gt;
Fact:
/dev/urandom
is the preferred source of
cryptographic randomness
on UNIX-like systems.
&lt;/p&gt;
&lt;/dd&gt;

&lt;dt&gt;
&lt;p&gt;
&lt;strong&gt;
/dev/urandom is a pseudo random number generator,
a &lt;abbr title="Pseudorandom number generator"&gt;PRNG&lt;/abbr&gt;,
while /dev/random is a “true” random number generator.
&lt;/strong&gt;
&lt;/p&gt;
&lt;/dt&gt;

&lt;dd&gt;
&lt;p&gt;
&lt;a href="#structure"&gt;Fact:&lt;/a&gt;
Both /dev/urandom and /dev/random
are using &lt;em&gt;the exact same&lt;/em&gt; &lt;abbr title="Cryptographically secure pseudorandom number generator"&gt;CSPRNG&lt;/abbr&gt;
(a cryptographically secure pseudorandom number generator).
They only differ
in very few ways
that have nothing to do with
“true” randomness.
&lt;/p&gt;
&lt;/dd&gt;

&lt;dt&gt;
&lt;p&gt;
&lt;strong&gt;
/dev/random is unambiguously the better choice for cryptography.
Even if /dev/urandom were comparably secure,
there's no reason to choose the latter.
&lt;/strong&gt;
&lt;/p&gt;
&lt;/dt&gt;

&lt;dd&gt;
&lt;p&gt;
&lt;a href="#blocking"&gt;Fact:&lt;/a&gt;
/dev/random has a very nasty problem: it blocks.
&lt;/p&gt;
&lt;/dd&gt;

&lt;dt&gt;
&lt;p&gt;
&lt;strong&gt;
But that's good!
/dev/random gives out exactly as much randomness
as it has entropy in its pool.
/dev/urandom will give you insecure random numbers,
even though it has long run out of entropy.
&lt;/strong&gt;
&lt;/p&gt;
&lt;/dt&gt;

&lt;dd&gt;
&lt;p&gt;
&lt;a href="#low-entropy"&gt;Fact:&lt;/a&gt;
No.
Even disregarding issues like availability
and subsequent manipulation by users,
the issue of entropy “running low” is a straw man.
About 256 bits of entropy
are enough to get computationally secure numbers
for a long, long time.
&lt;/p&gt;
&lt;p&gt;
And the fun only starts here:
how does /dev/random know
&lt;a href="#estimate"&gt;how much entropy&lt;/a&gt;
there is available to give out?
Stay tuned!
&lt;/p&gt;
&lt;/dd&gt;

&lt;dt&gt;
&lt;p&gt;
&lt;strong&gt;
But cryptographers always talk about constant re-seeding.
Doesn't that contradict your last point?
&lt;/strong&gt;
&lt;/p&gt;
&lt;/dt&gt;

&lt;dd&gt;
&lt;p&gt;
&lt;a href="#re-seed"&gt;Fact:&lt;/a&gt;
You got me! Kind of.
It is true,
the random number generator
is constantly re-seeded
using whatever entropy
the system can lay its hands on.
But that has (partly) other reasons.
&lt;/p&gt;
&lt;p&gt;
Look,
I don't claim that injecting entropy is bad.
It's good.
I just claim
that it's bad to block
when the entropy estimate is low.
&lt;/p&gt;
&lt;/dd&gt;

&lt;dt&gt;
&lt;p&gt;
&lt;strong&gt;
That's all good and nice,
but even the man page for /dev/(u)random
contradicts you!
Does &lt;em&gt;anyone&lt;/em&gt;
who knows about this stuff
actually agree with you?
&lt;/strong&gt;
&lt;/p&gt;
&lt;/dt&gt;

&lt;dd&gt;
&lt;p&gt;
&lt;a href="#man-page"&gt;Fact:&lt;/a&gt;
No, it really doesn't.
It &lt;em&gt;seems&lt;/em&gt; to imply
that /dev/urandom is insecure
for cryptographic use,
unless you really understand all that cryptographic jargon.
&lt;/p&gt;					
&lt;p&gt;
The man page does recommend
the use of /dev/random
in &lt;em&gt;some&lt;/em&gt; cases
(it doesn't hurt, in my opinion, but is not strictly necessary),
but it also recommends /dev/urandom
as the device to use
for	“normal” cryptographic use.
&lt;/p&gt;
&lt;p&gt;
And while appeal to authority is usually nothing to be proud of,
in cryptographic issues you're generally right
to be careful
and try to get
the opinion of a domain expert.
&lt;/p&gt;
&lt;p&gt;
And yes,
quite a few &lt;a href="#experts"&gt;experts&lt;/a&gt;
share my view
that /dev/urandom
is the go-to solution
for your random number needs
in a cryptography context
on UNIX-like systems.
Obviously,
their opinions influenced mine,
not the other way around.
&lt;/p&gt;
&lt;/dd&gt;
&lt;/dl&gt;
			
&lt;p&gt;
Hard to believe, right?
I must certainly be wrong!
Well, read on
and let me try to convince you.
&lt;/p&gt;
			
&lt;p&gt;
I tried to keep it out,
but I fear there are two preliminaries
to be taken care of,
before we can really tackle all those points.
&lt;/p&gt;
&lt;p&gt;
Namely,
&lt;a href="#true-randomness"&gt;what is randomness&lt;/a&gt;,
or better:
what kind of randomness am I talking about here?
&lt;/p&gt;
&lt;p&gt;
And, even more important,
I'm really &lt;a href="#stupid"&gt;not being condescending&lt;/a&gt;.
I have written this document
to have a thing to point to,
when this	discussion comes up again.
More than 140 characters.
Without repeating myself again and again.
Being able to hone the writing and the arguments itself,
benefitting many discussions in	many venues.
&lt;/p&gt;
&lt;p&gt;
And I'm certainly willing
to hear differing opinions.
I'm just saying
that it won't be enough
to state that /dev/urandom is bad.
You need to identify the points
you're disagreeing with
and engage them.
&lt;/p&gt;

&lt;h2 id="stupid"&gt;You're saying I'm stupid!&lt;/h2&gt;
&lt;p&gt;
Emphatically &lt;em&gt;no!&lt;/em&gt;
&lt;/p&gt;
&lt;p&gt;
Actually,
I used to believe
that /dev/urandom was insecure myself,
a few	years ago.
And it's something
you and I almost had to believe,
because	all those highly respected people
on Usenet, in web forums and today on	Twitter told us.
Even the &lt;a href="#man-page"&gt;man page&lt;/a&gt;
seems to say so.
Who were we
to dismiss their convincing argument
about “entropy running low”?
&lt;/p&gt;
&lt;p&gt;
This misconception isn't so rampant
because people are stupid,
it is	because with a little knowledge about cryptography
(namely some vague idea	what entropy is)
it's very easy to be convinced of it.
Intuition almost forces us there.
Unfortunately, intuition is often wrong in cryptography.
So it is here.
&lt;/p&gt;

&lt;h2 id="true-randomness"&gt;True randomness&lt;/h2&gt;
&lt;p&gt;
What does it mean
for random numbers
to be “truly random”?
&lt;/p&gt;
&lt;p&gt;
I don't want to dive into that issue too deep,
because it quickly gets philosophical.
Discussions have been known to unravel quickly,
because	everyone can wax about their favorite model of randomness,
without paying attention to anyone else.
Or even making himself understood.
&lt;/p&gt;
&lt;p&gt;
I believe
that the “gold standard”
for “true randomness”
are quantum	effects.
Observe a photon pass through a semi-transparent mirror.
Or not.
Observe some radioactive material emit alpha particles.
It's the best	idea we have
when it comes to randomness in the world.
Other people might reasonably believe
that those effects aren't truly random.
Or even	that there is no randomness in the world at all.
Let a million flowers bloom.
&lt;/p&gt;
&lt;p&gt;
Cryptographers often circumvent this philosophical debate
by disregarding
what it means for randomness to be “true”.
They care about &lt;em&gt;unpredictability&lt;/em&gt;.
As long as &lt;em&gt;nobody&lt;/em&gt;
can get &lt;em&gt;any&lt;/em&gt; information
about the next random number,
we're fine.
And when you're talking about	random numbers
as a prerequisite in using cryptography,
that's what you should aim for,
in my opinion.
&lt;/p&gt;
&lt;p&gt;
Anyway, I don't care much about those “philosophically secure” random numbers,
as I like to think of your “true” random numbers.
&lt;/p&gt;

&lt;h2 id="computationally-secure"&gt;Two kinds of security, one that matters&lt;/h2&gt;
&lt;p&gt;
But let's assume
you've obtained those “true” random numbers.
What are you going to do with them?
&lt;/p&gt;
&lt;p&gt;
You print them out,
frame them
and hang them on your living-room wall,
to revel in the beauty of a quantum universe?
That's great,
and I certainly	understand.
&lt;/p&gt;
&lt;p&gt;
Wait, what?
You're &lt;em&gt;using&lt;/em&gt; them?
For cryptographic purposes?
Well,
that spoils everything,
because now things get a bit ugly.
&lt;/p&gt;
&lt;p&gt;
You see,
your truly-random,
quantum effect blessed random numbers
are put	into some less respectable,
real-world tarnished algorithms.
&lt;/p&gt;
&lt;p&gt;
Because almost all
of the cryptographic algorithms
we use
do not hold up to &lt;strong&gt;information-theoretic security&lt;/strong&gt;.
They can “only”	offer &lt;strong&gt;computational security&lt;/strong&gt;.
The two exceptions
that come to my mind
are Shamir's Secret Sharing
and the One-time pad.
And while the first one
may be a valid counterpoint
(if you actually intend to use it),
the latter is utterly impractical.
&lt;/p&gt;
&lt;p&gt;
But all those algorithms
you know about,
&lt;abbr&gt;AES&lt;/abbr&gt;,
&lt;abbr&gt;RSA&lt;/abbr&gt;,
Diffie-Hellman,
Elliptic curves,
and all those crypto packages
you're using,
OpenSSL,
GnuTLS,
Keyczar,
your operating system's crypto API,
these are only computationally secure.
&lt;/p&gt;
&lt;p&gt;
What's the difference?
While information-theoretically secure algorithms	are secure,
&lt;em&gt;period&lt;/em&gt;,
those other algorithms cannot guarantee	security
against an adversary
with unlimited computational power
who's trying all possibilities for keys.
We still use them
because it would take
all the computers in the world taken together
longer than the universe has existed,
so far.
That's the level of “insecurity”
we're talking about	here.
&lt;/p&gt;
&lt;p&gt;
Unless some clever guy breaks the algorithm itself,
using much less	computational power.
Even computational power achievable today.
That's the big prize every cryptanalyst dreams about:
breaking &lt;abbr&gt;AES&lt;/abbr&gt; itself,
breaking &lt;abbr&gt;RSA&lt;/abbr&gt; itself
and so on.
&lt;/p&gt;
&lt;p&gt;
So now we're at the point
where you don't trust
the inner building blocks
of the random number generator,
insisting on “true randomness”
instead of “pseudo randomness”.
But then you're using those “true” random numbers in algorithms
that you so despise
that you didn't want them near
your random	number generator
in the first place!
&lt;/p&gt;
&lt;p&gt;
Truth is,
when state-of-the-art hash algorithms are broken,
or when state-of-the-art block ciphers are broken,
it doesn't matter
that you get “philosophically insecure” random numbers
because of them.
You've got nothing left
to securely use them for anyway.
&lt;/p&gt;
&lt;p&gt;
So just use those computationally-secure random numbers
for your computationally-secure algorithms.
In other words: use /dev/urandom.
&lt;/p&gt;

&lt;h2 id="structure"&gt;Structure of Linux's random number generator&lt;/h2&gt;
&lt;h3 id="incorrect-structure"&gt;An incorrect view&lt;/h3&gt;
&lt;p&gt;
Chances are,
your idea of the kernel's random number generator
is something similar to this:
&lt;/p&gt;

&lt;figure&gt;
&lt;img alt="image: mythical structure of the kernel's random number generator" src="https://www.2uo.de/myths-about-urandom/structure-no-73d42e4b.png"&gt;
&lt;figcaption&gt;
Mythical structure
of the kernel's random number generator
&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;
“True randomness”,
albeit possibly skewed and biased,
enters the system
and its entropy is precisely counted
and immediately added
to an	internal entropy counter.
After de-biasing and whitening
it's entering	the kernel's entropy pool,
where both /dev/random
and /dev/urandom
get their random numbers from.
&lt;/p&gt;
&lt;p&gt;
The “true” random number generator,
/dev/random,
takes those random numbers
straight out of the pool,
if the entropy count is sufficient
for the number of requested numbers,
decreasing the entropy counter,
of course.
If not,
it blocks
until new entropy
has entered the system.
&lt;/p&gt;
&lt;p&gt;
The important thing in this narrative is
that /dev/random basically yields the numbers
that have been input
by those randomness sources	outside,
after only the necessary whitening.
Nothing more, just pure	randomness.
&lt;/p&gt;	
&lt;p&gt;
/dev/urandom,
so the story goes,
is doing the same thing.
Except when there isn't sufficient entropy in the system.
In contrast to /dev/random,
it does not block,
but gets “low quality random” numbers
from a pseudorandom number generator
(conceded, a cryptographically secure one)
that is running
alongside the rest of the random number machinery.
This &lt;abbr&gt;CSPRNG&lt;/abbr&gt; is just seeded once
(or maybe every now and then, it doesn't matter)
with “true randomness” from the randomness pool,
but you can't really trust it.
&lt;/p&gt;
&lt;p&gt;
In this view,
that seems to be in a lot of people's minds
when they're talking
about random numbers on Linux,
avoiding /dev/urandom is plausible.
&lt;/p&gt;
&lt;p&gt;
Because either there is enough entropy left,
then you get the same
you'd have gotten from /dev/random.
Or there isn't,
then you get those low-quality random numbers
from a &lt;abbr&gt;CSPRNG&lt;/abbr&gt;
that almost never saw high-entropy input.
&lt;/p&gt;
&lt;p&gt;
Devilish, right?
Unfortunately, also utterly wrong.
In reality,
the	internal structure
of the random number generator
looks like this.
&lt;/p&gt;


&lt;h3 id="correct-structure"&gt;A better simplification&lt;/h3&gt;

&lt;h4 id="before-linux-4.8"&gt;Before Linux 4.8&lt;/h4&gt;

&lt;figure&gt;
&lt;img alt="image: actual structure of the kernel's random number generator before Linux 4.8" src="https://www.2uo.de/myths-about-urandom/structure-yes-c3cb7536.png"&gt;
&lt;figcaption&gt;
Actual structure
of the kernel's random number generator
before Linux 4.8
&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;
See the big difference?
The &lt;abbr&gt;CSPRNG&lt;/abbr&gt;
is not running
alongside the	random number generator,
filling in for those times
when /dev/urandom wants to output something,
but has nothing good to	output.
The &lt;abbr&gt;CSPRNG&lt;/abbr&gt;
is an integral part
of the random number generation process.
There is no /dev/random handing out
“good and	pure” random numbers
straight from the whitener.
Every randomness source's input
is thoroughly mixed and hashed
inside the &lt;abbr&gt;CSPRNG&lt;/abbr&gt;,
before it emerges as random numbers,
either via /dev/urandom
or /dev/random.
&lt;/p&gt;



&lt;p id="estimate"&gt;
Another important difference is
that there is no entropy &lt;em&gt;counting&lt;/em&gt; going on here,
but &lt;em&gt;estimation&lt;/em&gt;.
The amount of entropy
some source	is giving you
isn't something obvious
that you just get,
along with the data.
It has to be estimated.
Please note that
when your estimate is too optimistic,
the dearly held property of /dev/random,
that it's	only giving out
as many random numbers
as available entropy allows,
is gone.
Unfortunately,
it's hard to estimate the amount of entropy.
&lt;/p&gt;
&lt;p&gt;
The Linux kernel uses
only the arrival times of events
to estimate	their entropy.
It does that
by interpolating polynomials
of those arrival times,
to calculate
“how surprising” the actual arrival time was,
according to the model.
Whether this polynomial interpolation	model is the best way
to estimate entropy
is an interesting question.
There is also the problem
that internal hardware restrictions
might	influence those arrival times.
The sampling rates
of all kinds of	hardware components
may also play a role,
because they directly influence
the values
and the granularity
of those event arrival times.
&lt;/p&gt;
&lt;p&gt;
In the end,
to the best of our knowledge,
the kernel's entropy estimate is pretty good.
Which means it's conservative.
People argue about
how good it really is,
but that issue is far above my head.
Still,
if you insist
on never handing out random numbers
that are not “backed” by sufficient entropy,
you might be nervous here.
I'm sleeping sound
because I don't care
about the entropy estimate.
&lt;/p&gt;

&lt;p&gt;
So to make one thing crystal clear:
both /dev/random and /dev/urandom
are fed by
&lt;em&gt;the same&lt;/em&gt; &lt;abbr&gt;CSPRNG&lt;/abbr&gt;.
Only the behavior
when their respective pool runs out of entropy,
according to some estimate,
differs:
/dev/random blocks,
while /dev/urandom does not.
&lt;/p&gt;

&lt;h4 id="from-linux-4.8"&gt;From Linux 4.8 onward&lt;/h4&gt;

&lt;p&gt;
In Linux 4.8 the equivalency
between /dev/urandom and /dev/random
was given up.
Now /dev/urandom output does not come from an entropy pool,
but directly from	a &lt;abbr&gt;CSPRNG&lt;/abbr&gt;.
&lt;/p&gt;

&lt;figure&gt;
&lt;img alt="image: actual structure of the kernel's random number generator from Linux 4.8 onward" src="https://www.2uo.de/myths-about-urandom/structure-new-728f5983.png"&gt;
&lt;figcaption&gt;
Actual structure
of the kernel's random number generator
from Linux 4.8 onward
&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;
&lt;a href="#csprng"&gt;We will see shortly&lt;/a&gt;
why that is not a security problem.
&lt;/p&gt;



&lt;h2&gt;What's wrong with blocking?&lt;/h2&gt;
&lt;p&gt;
Have you ever waited for /dev/random
to give you more random numbers?
Generating a PGP key inside a virtual machine maybe?
Connecting to	a web server
that's waiting for more random numbers
to create	an ephemeral session key?
&lt;/p&gt;
&lt;p&gt;
That's the problem.
It inherently runs counter to availability.
So your system is not working.
It's not doing
what you built it	to do.
Obviously, that's bad.
You wouldn't have built it
if you didn't need it.
&lt;/p&gt;

&lt;p&gt;
But the problem runs even deeper:
people don't like
to be stopped	in their ways.
They will devise workarounds,
concoct bizarre machinations
to just get it running.
People who don't know anything about cryptography.
Normal people.
&lt;/p&gt;



&lt;p&gt;
Why not patching out the call to &lt;code&gt;random()&lt;/code&gt;?
Why not having some	guy in a web forum tell you
how to use some	strange ioctl
to increase the entropy counter?
Why not switch off &lt;abbr title="Secure sockets layer"&gt;SSL&lt;/abbr&gt; altogether?
&lt;/p&gt;
&lt;p&gt;
In the end
you just educate your users
to do foolish things
that compromise your system's security
without you ever knowing about it.
&lt;/p&gt;

&lt;p&gt;
It's easy to disregard availability,
usability
or other nice properties.
Security trumps everything, right?
So better be inconvenient,
unavailable
or unusable
than feign security.
&lt;/p&gt;
&lt;p&gt;
But that's a false dichotomy.
Blocking is not necessary for security.
As we &lt;a href="#correct-structure"&gt;saw&lt;/a&gt;,
/dev/urandom gives you the same kind of random numbers as /dev/random,
straight out of a &lt;abbr&gt;CSPRNG&lt;/abbr&gt;.
Use it!
&lt;/p&gt;

&lt;h2 id="csprng"&gt;The &lt;abbr&gt;CSPRNG&lt;/abbr&gt;s are alright&lt;/h2&gt;
&lt;p&gt;
But now everything sounds really bleak.
If even the high-quality random numbers from /dev/random
are coming out of a	&lt;abbr&gt;CSPRNG&lt;/abbr&gt;,
how	can we use them for high-security purposes?
&lt;/p&gt;
&lt;p&gt;
It turns out,
that “looking random” is &lt;em&gt;the&lt;/em&gt; basic	requirement
for a lot of our cryptographic building blocks.
If you take the output of a cryptographic hash,
it has to be indistinguishable from a random string
so that cryptographers will accept it.
If you take a block cipher,
its output
(without knowing the key)
must also be indistinguishable
from random data.
&lt;/p&gt;
&lt;p&gt;
If anyone could gain an advantage
over brute force breaking
of cryptographic building blocks,
using some perceived weakness
of those &lt;abbr&gt;CSPRNG&lt;/abbr&gt;s
over “true” randomness,
then it's the same old story:
you don't have anything left.
Block ciphers, hashes, everything
is based on the same mathematical fundament as &lt;abbr&gt;CSPRNG&lt;/abbr&gt;s.
So don't be afraid.
&lt;/p&gt;

&lt;h2 id="low-entropy"&gt;What about entropy running low?&lt;/h2&gt;
&lt;p&gt;
It doesn't matter.
&lt;/p&gt;
&lt;p&gt;
The underlying cryptographic building blocks are designed
such that an attacker cannot predict the outcome,
as long as there was	enough randomness
(a.k.a. entropy)
&lt;em&gt;in the beginning&lt;/em&gt;.
A usual lower limit for “enough” may be 256 bits.
No more.
&lt;/p&gt;
&lt;p&gt;
Considering that we were pretty hand-wavey
about the term “entropy” in the first place,
it feels right.
As we saw,
the kernel's random number generator cannot even precisely know
the amount of	entropy entering the system.
Only an estimate.
And whether the	model
that's the basis for the estimate
is good enough
is pretty	unclear,
too.
&lt;/p&gt;

&lt;h2 id="re-seed"&gt;Re-seeding&lt;/h2&gt;
&lt;p&gt;
But if entropy is so unimportant,
why is fresh entropy constantly being injected
into the random number generator?
&lt;/p&gt;

&lt;p&gt;
First, it cannot hurt.
If you've got more randomness just lying around,
by all means use it!
&lt;/p&gt;



&lt;p&gt;
There is another reason
why re-seeding the random number generator
every now and then is important:
&lt;/p&gt;
&lt;p&gt;
Imagine an attacker knows everything
about your random number generator's internal state.
That's the most severe security compromise
you can imagine,
the attacker has full access to the system.
&lt;/p&gt;
&lt;p&gt;
You've totally lost now,
because the attacker can compute all future outputs
from this point on.
&lt;/p&gt;
&lt;p&gt;
But over time,
with more and more fresh entropy being mixed into it,
the internal state gets more and more random again.
So that	such a random number generator's design is kind of self-healing.
&lt;/p&gt;
&lt;p&gt;
But this is injecting entropy
into the generator's internal state,
it has nothing to do with blocking its output.
&lt;/p&gt;

&lt;h2 id="man-page"&gt;The random and urandom man page&lt;/h2&gt;



&lt;p&gt;
The man page for /dev/random and /dev/urandom
is pretty effective
when it comes to instilling fear
into the gullible programmer's mind:
&lt;/p&gt;

&lt;blockquote&gt;
A read from the /dev/urandom device
will not block
waiting for	more entropy.
As a result,
if there is not sufficient entropy
in the entropy pool,
the returned values are theoretically vulnerable
to a cryptographic attack
on the algorithms used by the driver.
Knowledge of how to do this is not available
in the current unclassified literature,
but it is theoretically possible
that such an attack may exist.
If this is a concern in your application,
use /dev/random instead. 
&lt;/blockquote&gt;

&lt;p&gt;
Such an attack is not known in “unclassified literature”,
but the NSA certainly has one in store,
right?
And if you're really concerned
about this (you should!),
please use /dev/random,
and all your problems are solved.
&lt;/p&gt;
&lt;p&gt;
The truth is,
while there may be such an attack
available to secret services,
evil hackers
or the Bogeyman,
it's just not rational
to just take it as a given.
&lt;/p&gt;
&lt;p&gt;
And even if you need that peace of mind,
let me tell you a secret:
no practical attacks
on &lt;abbr&gt;AES&lt;/abbr&gt;,
&lt;abbr&gt;SHA-3&lt;/abbr&gt;
or other solid ciphers and hashes
are known in the “unclassified” literature,
either.
Are you going to stop using those,
as well?
Of course not!
&lt;/p&gt;
&lt;p&gt;
Now the fun part:
“use /dev/random instead”.
While /dev/urandom does not block,
its random number output comes
from the very same &lt;abbr&gt;CSPRNG&lt;/abbr&gt;
as /dev/random's.
&lt;/p&gt;
&lt;p&gt;
&lt;em&gt;If&lt;/em&gt; you really need information-theoretically secure random numbers
(you don't!),
and that's about the only reason
why the entropy	of the &lt;abbr&gt;CSPRNG&lt;/abbr&gt;'s input matters,
you can't use /dev/random,
either!
&lt;/p&gt;

&lt;p&gt;
The man page is silly,
that's all.
At least it tries to redeem itself with this:
&lt;/p&gt;

&lt;blockquote&gt;
If you are unsure about
whether you should use /dev/random or /dev/urandom,
then probably you want to use the latter.
As a general rule,
/dev/urandom should be used for everything
except long-lived	&lt;abbr&gt;GPG&lt;/abbr&gt;/&lt;abbr&gt;SSL&lt;/abbr&gt;/&lt;abbr&gt;SSH&lt;/abbr&gt; keys. 
&lt;/blockquote&gt;

	

&lt;p&gt;
Fine.
I think it's unnecessary,
but if you want to use /dev/random
for your “long-lived keys”,
by all means, do so!
You'll be waiting a few seconds
typing stuff on your keyboard,
that's no problem.
&lt;/p&gt;
&lt;p&gt;
But please don't make connections to a mail server hang forever,
just because you “wanted to be safe”.
&lt;/p&gt;

&lt;h2 id="experts"&gt;Orthodoxy&lt;/h2&gt;
&lt;p&gt;
The view espoused here
is certainly a tiny minority's opinions
on the Internet.
But ask a real cryptographer,
you'll be hard pressed
to find someone
who sympathizes much with that blocking /dev/random.
&lt;/p&gt;
&lt;p&gt;
Let's take &lt;a href="http://www.mail-archive.com/cryptography@randombit.net/msg04763.html"&gt;Daniel Bernstein&lt;/a&gt;,
better known as djb:
&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;
Cryptographers are certainly not responsible
for this superstitious nonsense.
Think about this for a moment:
whoever wrote the /dev/random manual page
seems to simultaneously believe that
&lt;/p&gt;
&lt;p&gt;
(1) we can't figure out
how to deterministically expand
one 256-bit	/dev/random output
into an endless stream
of unpredictable keys
(this is what we need from urandom),
but
&lt;/p&gt;
&lt;p&gt;
(2) we _can_ figure out
how to use a single key
to safely encrypt
many messages
(this is what we need from &lt;abbr&gt;SSL&lt;/abbr&gt;, &lt;abbr&gt;PGP&lt;/abbr&gt;, etc.).
&lt;/p&gt;
&lt;p&gt;
For a cryptographer this doesn't even pass the laugh test.
&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;
Or &lt;a href="http://security.stackexchange.com/questions/3936/is-a-rand-from-dev-urandom-secure-for-a-login-key/3939#3939"&gt;Thomas Pornin&lt;/a&gt;,
who is probably
one of the most helpful persons
I've ever encountered on the Stackexchange sites:
&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;
The short answer is yes.
The long answer is also yes.
/dev/urandom yields data
which is indistinguishable
from true randomness,
given existing technology.
Getting “better” randomness
than what /dev/urandom provides
is meaningless,
unless you are using one
of the few "information theoretic" cryptographic algorithm,
which is not your case
(you would know it).
&lt;/p&gt;
&lt;p&gt;
The man page for urandom is somewhat misleading,
arguably downright wrong,
when it suggests
that /dev/urandom may "run out of entropy"
and /dev/random should be preferred;
&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;
Or maybe &lt;a href="http://sockpuppet.org/blog/2014/02/25/safely-generate-random-numbers/"&gt;Thomas Ptacek&lt;/a&gt;,
who is not a real cryptographer
in the sense of designing cryptographic algorithms
or building cryptographic systems,
but still the founder
of a well-reputed security consultancy
that's doing a lot of penetration testing
and breaking bad cryptography:
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;
Use urandom. Use urandom. Use urandom. Use urandom. Use urandom. Use urandom.
&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id="problems"&gt;Not everything is perfect&lt;/h2&gt;
&lt;p&gt;
/dev/urandom isn't perfect.
The problems are twofold:
&lt;/p&gt;
&lt;p&gt;
On Linux,
unlike FreeBSD,
/dev/urandom never blocks.
Remember that	the whole security rested
on some starting randomness,
a seed?
&lt;/p&gt;
&lt;p&gt;
Linux's /dev/urandom happily gives you not-so-random numbers
before the kernel even had the chance
to gather entropy.
When is that?
At system start,
booting the computer.
&lt;/p&gt;
&lt;p&gt;
FreeBSD does the right thing:
they don't have the distinction
between	/dev/random and /dev/urandom,
both are the same device.
At startup /dev/random blocks once
until enough starting entropy has been gathered.
Then it won't block ever again.
&lt;/p&gt;
&lt;p&gt;
On Linux it isn't too bad,
because Linux distributions save some random numbers
when booting up the system
(but after they have gathered some entropy,
since the startup script doesn't run immediately after switching on the machine)
into a seed file
that is read next time the machine is booting.
So you carry over	the randomness
from the last running of the machine.
&lt;/p&gt;

&lt;p&gt;
Obviously that isn't as good
as if you let the shutdown scripts write out the seed,
because in that case
there would have been much more time to gather entropy.
The advantage is obviously
that this does not depend
on a proper shutdown
with execution of the shutdown scripts
(in case the computer crashes, for example).
&lt;/p&gt;
&lt;p&gt;
And it doesn't help you the very first time a machine is running,
but the Linux distributions usually do the same saving into a seed file
when running the installer.
So that's mostly okay.
&lt;/p&gt;
&lt;p&gt;
Virtual machines are the other problem.
Because people like to clone them,
or rewind them to a previously saved check point,
this seed file doesn't	help you.
&lt;/p&gt;
&lt;p&gt;
But the solution still isn't using /dev/random everywhere,
but properly seeding each and every virtual machine
after cloning,
restoring a checkpoint,
whatever.
&lt;/p&gt;



&lt;h2&gt;tldr;&lt;/h2&gt;
&lt;p&gt;
&lt;strong&gt;Just use /dev/urandom!&lt;/strong&gt;
&lt;/p&gt;



&lt;/article&gt;&lt;/div&gt;&lt;a href="https://www.2uo.de/myths-about-urandom/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Wed, 25 Mar 2020 13:42:45 UT
      </pubDate>
      <guid>
        https://www.2uo.de/myths-about-urandom/
      </guid>
    </item>
    <item>
      <title>
        10 Most(ly dead) Influential Programming Languages • Hillel Wayne
      </title>
      <link>
        https://hillelwayne.com/post/influential-dead-languages/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;article lang="en"&gt;
    

    
    

    &lt;div&gt;
  

&lt;p&gt;The other day I read &lt;a href="https://anarc.at/blog/2020-02-02-most-significant-programming-languages-history/"&gt;20 most significant programming languages in history&lt;/a&gt;, a “preposterous table I just made up.” He certainly got preposterous right: he lists Go as “most significant” but not ALGOL, Smalltalk, or ML. He also leaves off Pascal because it’s “mostly dead”. Preposterous! That defeats the whole point of what “significant in history” means.&lt;/p&gt;

&lt;p&gt;So let’s talk about some “mostly dead” languages and why they matter so much.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Disclaimer:&lt;/strong&gt; Yeah not all of these are dead and not all of these are forgotten. Like most people have heard of Smalltalk, right? Also there’s probably like a billion mistakes in this, because when you’re doing a survey of 60 years of computing history you’re gonna get some things wrong. Feel free to yell at me if you see anything!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Disclaimer 2:&lt;/strong&gt; Yeah I know some of these are “first to invent” and others are “first to popularize”. History is complicated!&lt;/p&gt;

&lt;h3 id="detecting-influence"&gt;Detecting Influence&lt;/h3&gt;

&lt;p&gt;Before we start, a quick primer on finding influence. Just knowing that X was the first language with feature Z doesn’t mean that X actually &lt;em&gt;influenced&lt;/em&gt; Z. While &lt;a href="https://core.ac.uk/download/pdf/82537271.pdf"&gt;Absys&lt;/a&gt; was arguably the first logic programming language, almost all of logic programming actually stems from Prolog, which was developed independently. Ultimately there’s only one way to know for certain that X influenced Y: citation. This means one of&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Y cites X in its reference manual&lt;/li&gt;
&lt;li&gt;Y cites a paper that cites X&lt;/li&gt;
&lt;li&gt;The author of Y says “we were influenced by X.”&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Citations are transitive. Sometimes the language manual for Q lists motivating document R, which cites paper S as an inspiration, which mentions it got the ideas from language T. Then we know that T influenced Q, even if the chain is several steps long. This means digging through many sources to find a signal. To speed this up we use heuristics to decide where to look.&lt;/p&gt;

&lt;p&gt;One effective heuristic is programming language &lt;strong&gt;cognates&lt;/strong&gt;. It’s very rare for languages to independently come up with the same syntax. So if two languages share some syntax, one likely influenced the other. For example: even without reading design decisions by Matz, we know that Ruby was influenced by Smalltalk, as they both filter a list with a &lt;code&gt;select&lt;/code&gt; method. This isn’t conclusive evidence. Maybe Matz came up with it independently, or maybe Ruby and Smalltalk were both influenced by a common ancestor. But it gives us a place to start looking.&lt;/p&gt;



&lt;h3 id="cobol"&gt;COBOL&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Background:&lt;/strong&gt; CODASYL, 1960. COBOL is shaped by the business/science split in computing. At that time high-level industry languages were either used for engineering computations or managing data. The engineers had all gotten behind FORTRAN while the business world was a mess of COMTRAN, FLOW-MATIC, and others, so the Department of Defense got a committee together to make a single universal business language. That’s COBOL.&lt;/p&gt;

&lt;p&gt;COBOL was one of the four “mother” languages, along with ALGOL, FORTRAN, and LISP. While we consider it a punchline today, it was once the most popular language in the world. It still runs a lot of our legacy business systems.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Significance&lt;/strong&gt;: In terms of syntax and semantics we don’t see much of COBOL in modern computing. COBOL’s most important addition is the concept of record data. In FORTRAN and ALGOL, your only data structure was the static array. In COBOL, though, you could read in structured files with hierarchical data, and it would automatically destructure them into the representative variables. This was a precursor to modern day structs.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Cause of Death&lt;/strong&gt;: Two factors here. One: COBOL had no overlap with other PLT efforts. Very few people built on COBOL. This meant that second or third generation languages, which built on the lessons of their ancestors, had almost no COBOL DNA. This was less intrinsic problem of COBOL and more because of the academia’s disdain for its creation process. CODASYL was a business group and obviously wasn’t worth paying attention to.&lt;sup id="fnref:disdain"&gt;&lt;a href="#fn:disdain"&gt;1&lt;/a&gt;&lt;/sup&gt; COBOL was also enormously complex, even for today’s languages. This means that COBOL compilers lagged contemporaries on microcomputers and minicomputers, giving spaces for other languages to flourish and eventually outcompete it.&lt;/p&gt;

&lt;h3 id="algol"&gt;ALGOL&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Background&lt;/strong&gt;: The ALGOL committee, 1960. ALGOL-58 came out two years before but was quickly superseded, so I’m wrapping them into each other. The committee wanted to make a good language for researching algorithms. In other words, ALGOL was a formalized “pseudocode”.&lt;/p&gt;

&lt;p&gt;Of the four mother languages, ALGOL is the most “dead”; Everybody still knows about LISP,&lt;sup id="fnref:lisp"&gt;&lt;a href="#fn:lisp"&gt;2&lt;/a&gt;&lt;/sup&gt; COBOL still powers tons of legacy systems, and most scientific packages still have some FORTRAN. But I’ve met plenty of programmers who haven’t even heard of ALGOL. You’d think it’d be the least important of the mother languages, but it’s the opposite. Of the four, only LISP comes anywhere &lt;em&gt;close&lt;/em&gt; to the pervasive importance of ALGOL.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Significance&lt;/strong&gt;: Let’s see: lexical scoping, structured programming, nested functions, formal language specifications, call-by-name semantics, BNF grammars, block comments… every modern language today is deeply influenced by ALGOL.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Cause of Death&lt;/strong&gt;: ALGOL was a research language, not a commercial language. It was designed for studying algorithms. The spec didn’t define any I/O, which kinda made it impossible to use in practice. Sure, you could write a compiler extension, but then you might as well add other stuff too.&lt;/p&gt;

&lt;p&gt;And that’s exactly what people did. In 1960 and 70 people made a huge number of ALGOL-likes by extending ALGOL with I/O and extra data structures. This includes JOVIAL, SIMULA, CLU, and CPL. Later languages were then based off these extensions, not ALGOL directly. We call C an “ALGOL-like”, but it’s actually a BCPL-like, which was a CPL-like, which was an ALGOL-like. ALGOL’s children buried it.&lt;/p&gt;

&lt;p&gt;Eventually the ALGOL people tried to extend it into ALGOL-68, which radically departed from ALGOL-60 and hasn’t had close to the same influence. The ALGOL-60 lineage continues with Niklaus Wirth’s Pascal.&lt;/p&gt;

&lt;h3 id="apl"&gt;APL&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Background&lt;/strong&gt;: Ken Iverson, 1962. Originally a hand-written notation for array math, IBM picked it up and used as an programming language. As a language, APL focused on array processing: being able to concisely manipulate large blocks of numbers.&lt;/p&gt;

&lt;p&gt;If you’ve heard of APL before, you probably know it as “that weird symbol language”. One of the most notorious code snippets is this implementation of the Game of Life:&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;code data-lang="apl"&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;life&lt;/span&gt;&lt;span&gt;←{&lt;/span&gt;&lt;span&gt;↑&lt;/span&gt;&lt;span&gt;1&lt;/span&gt; &lt;span&gt;⍵&lt;/span&gt;&lt;span&gt;∨&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;∧&lt;/span&gt;&lt;span&gt;3&lt;/span&gt; &lt;span&gt;4&lt;/span&gt;&lt;span&gt;=+&lt;/span&gt;&lt;span&gt;/&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;¯1&lt;/span&gt; &lt;span&gt;0&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;∘.&lt;/span&gt;&lt;span&gt;⊖&lt;/span&gt;&lt;span&gt;¯1&lt;/span&gt; &lt;span&gt;0&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;∘.&lt;/span&gt;&lt;span&gt;⌽⊂&lt;/span&gt;&lt;span&gt;⍵&lt;/span&gt;&lt;span&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;You had to write it with a specialized keyboard, like this:&lt;/p&gt;

&lt;figure&gt; 
  &lt;img title="IBM APL Keyboard" src="https://hillelwayne.com/post/influential-dead-languages/IDSkeyboard.jpg"&gt; 
  &lt;figcaption&gt;An APL keyboard &lt;a href="https://www.dyalog.com/50-years-of-apl/photo-gallery.htm"&gt;(source)&lt;/a&gt;&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Nonetheless, APL got popular on mainframes for running with very low memory requirements.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Significance&lt;/strong&gt;: Array processing. At a time when adding two lists of numbers meant a map or a loop, APL introduced the idea of operating on the entire array &lt;em&gt;at once&lt;/em&gt;. For example:&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;code data-lang="apl"&gt;&lt;span&gt;&lt;/span&gt;   &lt;span&gt;1&lt;/span&gt; &lt;span&gt;+&lt;/span&gt; &lt;span&gt;1&lt;/span&gt; &lt;span&gt;2&lt;/span&gt; &lt;span&gt;3&lt;/span&gt; &lt;span&gt;4&lt;/span&gt;
&lt;span&gt;2&lt;/span&gt; &lt;span&gt;3&lt;/span&gt; &lt;span&gt;4&lt;/span&gt; &lt;span&gt;5&lt;/span&gt;
   &lt;span&gt;1&lt;/span&gt; &lt;span&gt;2&lt;/span&gt; &lt;span&gt;3&lt;/span&gt; &lt;span&gt;4&lt;/span&gt; &lt;span&gt;+&lt;/span&gt; &lt;span&gt;1&lt;/span&gt; &lt;span&gt;2&lt;/span&gt; &lt;span&gt;3&lt;/span&gt; &lt;span&gt;4&lt;/span&gt;
&lt;span&gt;2&lt;/span&gt; &lt;span&gt;4&lt;/span&gt; &lt;span&gt;6&lt;/span&gt; &lt;span&gt;8&lt;/span&gt;
   &lt;span&gt;2&lt;/span&gt; &lt;span&gt;4&lt;/span&gt; &lt;span&gt;⍴&lt;/span&gt; &lt;span&gt;⍳&lt;/span&gt;&lt;span&gt;8&lt;/span&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;2&lt;/span&gt; &lt;span&gt;3&lt;/span&gt; &lt;span&gt;4&lt;/span&gt;
&lt;span&gt;5&lt;/span&gt; &lt;span&gt;6&lt;/span&gt; &lt;span&gt;7&lt;/span&gt; &lt;span&gt;8&lt;/span&gt;
   &lt;span&gt;1&lt;/span&gt; &lt;span&gt;2&lt;/span&gt; &lt;span&gt;3&lt;/span&gt; &lt;span&gt;4&lt;/span&gt; &lt;span&gt;+&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;&lt;span&gt;]&lt;/span&gt; &lt;span&gt;2&lt;/span&gt; &lt;span&gt;4&lt;/span&gt; &lt;span&gt;⍴&lt;/span&gt; &lt;span&gt;⍳&lt;/span&gt;&lt;span&gt;8&lt;/span&gt;
&lt;span&gt;2&lt;/span&gt; &lt;span&gt;4&lt;/span&gt;  &lt;span&gt;6&lt;/span&gt;  &lt;span&gt;8&lt;/span&gt;
&lt;span&gt;6&lt;/span&gt; &lt;span&gt;8&lt;/span&gt; &lt;span&gt;10&lt;/span&gt; &lt;span&gt;12&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This was a &lt;em&gt;really big deal&lt;/em&gt; in scientific circles. So much applied math boils down to large-scale operations on large matrices. When you can just take the outer product with &lt;code&gt;∘.f&lt;/code&gt;, it’s really damn easy to take outer products!&lt;/p&gt;

&lt;p&gt;Through this innovation APL lead to R, numpy, pandas, Matlab, etc. There’s also the direct descendants of APL: J, Dyalog, K, Q. They’ve been less successful but still see lots of use in the finance sector.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Cause of Death&lt;/strong&gt;: Well, the obvious problem is the keyboards. If you can’t write it in ASCII, you’re not going to write very much of it. Iverson fixed this with J, which uses digraphs instead of different symbols. Instead of &lt;code&gt;≠&lt;/code&gt;, you write &lt;code&gt;~:&lt;/code&gt;. This was in 1990, though, which is a bit late to popularize a radically different programming style.&lt;/p&gt;

&lt;p&gt;The subtler problem is that APL and J only worked on homogeneous data. You can’t store both strings and numbers in the same data structure (unless you use boxes, which is a whole other can of worms) and working with strings is generally a nightmare. So no dataframes, which excludes a lot of modern data science.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Further Reading:&lt;/strong&gt;  &lt;a href="http://www.eecg.toronto.edu/~jzhu/csc326/readings/iverson.pdf"&gt;Notation as a Tool of Thought&lt;/a&gt;&lt;/p&gt;

&lt;h3 id="basic"&gt;BASIC&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Background&lt;/strong&gt;: John Kemeny, 1964. Originally a simplified FORTRAN-like, intended to help people outside engineering use computers.&lt;/p&gt;

&lt;p&gt;BASIC really took off in the microcomputer era. The first microcomputers didn’t have enough memory to compile “real” programming languages, whereas you could cram a pared-down BASIC compiler into like 2 kilobytes. BASIC became a &lt;em&gt;lingua franca&lt;/em&gt; for early-stage programmers. If you were programming at home in the 1970’s, you were probably writing BASIC on a microcomputer.&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;code data-lang="basic"&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;10 &lt;/span&gt;&lt;span&gt;PRINT&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;"Hello, World!"&lt;/span&gt;
&lt;span&gt;20 &lt;/span&gt;&lt;span&gt;END&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Significance&lt;/strong&gt;: The biggest &lt;em&gt;technical&lt;/em&gt; impact is runtime interpretation. BASIC was the first language with a real-time interpreter (the &lt;a href="https://en.wikipedia.org/wiki/Dartmouth_Time_Sharing_System"&gt;Dartmouth Time Sharing System&lt;/a&gt;), beating APL by a year. And that APL system was only available to IBM customers, so really it was BASIC or nothing for a long time.&lt;sup id="fnref:joss"&gt;&lt;a href="#fn:joss"&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;BASIC had a bigger &lt;em&gt;social&lt;/em&gt; impact. It brought programming to households, kids especially. Many of the influential programmers in the 80’s and 90’s first learned how to program on BASIC. Many enterprise programs were also written in BASIC, which probably helped accelerate the decline of Cobol.&lt;/p&gt;

&lt;p&gt;BASIC has one more neat trick up its sleeve: Office tooling! Microsoft eventually turned BASIC into Visual Basic, which they used as the Office macro language. This then spread to OpenOffice and LibreOffice, entrenching BASIC in that particular niche. More recently it’s lost ground to JavaScript and is now a legacy macro language.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Cause of Death&lt;/strong&gt;: People saw BASIC as a “lesser” language. You might use it if you were a kid or a small business owner, but &lt;em&gt;real&lt;/em&gt; programmers used a &lt;em&gt;real&lt;/em&gt; language. Once manufacturers could cheaply make microcomputers with more than 16k of RAM they started depreciating BASIC for languages like Pascal and C.&lt;/p&gt;

&lt;p&gt;BASIC lived on for a while as a legacy kids teaching language, but seems to have died out of that niche, too.&lt;/p&gt;

&lt;h3 id="pl-i"&gt;PL/I&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Background:&lt;/strong&gt; IBM, 1966. IBM’s business was split into two languages: FORTRAN for scientists and COMTRAN for business folk. Facing competition from COBOL and wanting to streamline their systems, they tried to make a language that was useful for both engineering and business purposes. This ended up looking like a sort of superset of the two languages, with a bunch of additional features stapled on top.&lt;sup id="fnref:pli"&gt;&lt;a href="#fn:pli"&gt;4&lt;/a&gt;&lt;/sup&gt; Now everybody could use the same language and IBM can make a lot more money! Yaaaaaaaay&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Significance:&lt;/strong&gt; The authors of ALGOL-68 mockingly called PL/I an obsolete language. But everything ALGOL-68 did, PL/I did earlier and better. While COBOL got structured data first, PL/I was the first language to implement them as a type. In COBOL, reading in a user with a name would give you two global variables, &lt;code&gt;user&lt;/code&gt; and &lt;code&gt;name&lt;/code&gt;. In PL/I, you’d get one variable with a field, &lt;code&gt;user.name&lt;/code&gt;. PL/I was also the first high-level language with pointers for direct memory manipulation, constants, and function overloading.&lt;sup id="fnref:overloading"&gt;&lt;a href="#fn:overloading"&gt;5&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;Many of these ideas entered mainstream programming via C, which was a mix of both BCPL and PL/I. C even uses PL/I’s comment syntax.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Cause of Death:&lt;/strong&gt; All the FORTRAN programmers thought it was too much like COBOL and all the COBOL programmers thought it was too much like FORTRAN. IBM had tried to take on two established languages with a much more complicated one. It didn’t help that they were the only group with the compiler, meaning everybody else was mistrustful of vendor lock-in. By the time IBM was able to make headway in both of these issues the wider computing world had already moved on to the microcomputer era, where PL/I was out competed by BASIC.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Further Reading:&lt;/strong&gt; &lt;a href="https://multicians.org/pl1.html"&gt;The Choice of PL/I&lt;/a&gt;&lt;/p&gt;

&lt;h3 id="simula-67"&gt;SIMULA 67&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Background&lt;/strong&gt;: Ole Dahl and Kristen Nygaard, 1967. They extended ALGOL for doing simulations. First they made SIMULA I, which had dedicated simulation and “activity” syntax. SIMULA I saw some early use, but the two were dissatisfied with how “specialized” the language felt and how much duplicate code they had in their simulations. They wanted to make a more general framework for representing things in general, not simulations only.&lt;/p&gt;

&lt;p&gt;Their idea was to allow users to define new types called “classes” with polymorphic function resolution. Then users could build the simulation features as a special case of the object system, making it easy to customize how it all worked to their particular needs.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Significance&lt;/strong&gt;: While SIMULA wasn’t the first “true” OOP language, it was the first language with proper objects and laid much of the groundwork that others would build on. This includes the class/object split, subclassing, virtual methods, and protected attributes. It inspired almost all of the academic research into objects after 1967. Both CLU and ML cited SIMULA as a major source of inspiration. Bjarne Stroustroup did his PhD on SIMULA, eventually incorporating a lot of its ideas into C++.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Cause of Death&lt;/strong&gt;: In that same PhD Stroustroup claimed that SIMULA was waaaaaay too slow to use at scale. “Good luck getting anything done if you aren’t on a mainframe” slow. It’s worth noting that Smalltalk-80, which took the same ideas even further, had an extra 13 years of Moore’s law behind it. And even Smalltalk was often mocked as too slow. Everybody went and implemented the ideas in SIMULA that they could integrate into faster, simpler languages.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Further Reading&lt;/strong&gt;: &lt;a href="https://www.idi.ntnu.no/grupper/su/publ/simula/holmevik-simula-ieeeannals94.pdf"&gt;Compiling SIMULA: a historical study of technological genesis&lt;/a&gt;, &lt;a href="http://campus.hesge.ch/daehne/2004-2005/langages/simula.htm"&gt;The History of Simula&lt;/a&gt;&lt;/p&gt;

&lt;h3 id="pascal"&gt;Pascal&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Background&lt;/strong&gt;: Niklaus Wirth, 1970. Made to capture the essence of ALGOL-60 after ALGOL-68 got waaaaaay too complicated for Wirth’s liking. It first got big as the “introduction to CS” language, and by the early 80’s was the second-most popular language on the Usenet job boards. Wirth considers the whole family- Pascal, Modula, and Oberon- as a single unified language concept.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Significance&lt;/strong&gt;: Pascal didn’t introduce any completely new ideas. It was an intentionally conservative language that tried to pick the best parts of the past decade and provide them in a unified package.  Pascal brought ALGOL syntax outside academia, so much so that ALGOL’s assignment syntax, &lt;code&gt;:=&lt;/code&gt;, got called “Pascal style” instead. From this point on most language features that look like ALGOL were more likely inspired by Pascal than directly by ALGOL itself.&lt;/p&gt;

&lt;p&gt;While Pascal wasn’t very innovative, variants of it were. Wirth also pioneered the idea of “stepwise refinement” as a means of writing rigorous software. This eventually lead to the Modulas, which popularized first class software modules, and Euclid, the first formal verification language to see production use.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Cause of Death&lt;/strong&gt;: I’m calling a mulligan on this one. Unlike most of the other ones on this list, Pascal didn’t have major structural barriers or a sharp competitor. Sure, it competed with C, but it was still doing fine for a very long time. People usually attribute the &lt;a href="https://www.lysator.liu.se/c/bwk-on-pascal.html"&gt;Why Pascal is not my favorite language&lt;/a&gt; essay, but that’s too neat of an answer and history is a lot messier. Also, Delphi is still pretty high-ranked in the TIOBE and PYPA measurements, so it’s not exactly &lt;em&gt;dead&lt;/em&gt; in the same way SIMULA is. An accurate analysis of the fall of Pascal would be longer than the rest of this essay.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Further Reading:&lt;/strong&gt;  &lt;a href="http://web.eah-jena.de/~kleine/history/languages/Wirth-PascalRevisedReport.pdf"&gt;The Programming Language Pascal&lt;/a&gt;, &lt;a href="https://www.swissdelphicenter.ch/en/niklauswirth.php"&gt;Pascal and its Successors&lt;/a&gt;&lt;/p&gt;

&lt;h3 id="clu"&gt;CLU&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Background&lt;/strong&gt;: Barbara Liskov, 1975. Liskov wanted to mess around with abstract data types. That’s it. That’s the whole reason for CLU.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Significance&lt;/strong&gt;: CLU might be the most influential language that nobody’s ever heard of. Iterators? CLU. Abstract data types? CLU. Generics? CLU. Checked exceptions? CLU.&lt;/p&gt;

&lt;p&gt;We didn’t adopt the same terminology, so it’s not 100% obvious it all comes from CLU, but still. Every language spec for the next decade would namedrop CLU. CLU did a lot.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Cause of Death:&lt;/strong&gt; CLU was a showcase language; Liskov wanted to get people to adopt her &lt;em&gt;ideas&lt;/em&gt;, not her specific &lt;em&gt;language&lt;/em&gt;. And they did: almost every language today owes &lt;em&gt;something&lt;/em&gt; to CLU. As soon as she completed CLU she moved on to &lt;strong&gt;Argus&lt;/strong&gt;, which was supposed to showcase her ideas on concurrency. That hasn’t seen nearly the same adoption, and there’s still a lot of stuff in it left to mine.&lt;/p&gt;

&lt;p&gt;Further reading: &lt;a href="https://web.archive.org/web/20030917041834/http://www.lcs.mit.edu/publications/pubs/pdf/MIT-LCS-TR-561.pdf"&gt;A History of CLU&lt;/a&gt;&lt;/p&gt;

&lt;h3 id="ml"&gt;ML&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Background&lt;/strong&gt;: Robin Milner, 1976.&lt;sup id="fnref:ml"&gt;&lt;a href="#fn:ml"&gt;6&lt;/a&gt;&lt;/sup&gt; Milner was building the LCF Prover, one of the first &lt;strong&gt;proof assistants.&lt;/strong&gt; If you wrote a proof in the right format, LCF could check to see if it was correct or not. To assist in writing the proofs, Milner created a &lt;em&gt;metalanguage&lt;/em&gt; based on sound mathematical formalisms, which at the time meant strict static types and higher-order functions. Eventually ML was standardized as Standard ML.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Significance&lt;/strong&gt;: ML is arguably the oldest “algebraic programming language”. There’s a lot of stuff we attribute to ML: algebraic data types, modules, typed functional programming. Surprisingly, it was &lt;em&gt;not&lt;/em&gt; the first for a lot of these! The first ML was just designed to work with LCF and wasn’t a general purpose language, so lacked a lot of these features. As people started making it more general they pulled ideas from other research languages and incorporated them into ML. One &lt;em&gt;very&lt;/em&gt; important idea did start in ML, though: type inference. ML was the first statically-typed language where you didn’t &lt;em&gt;have&lt;/em&gt; to write the types out, as the compiler would figure out the types for you. This paved the way for typed FP to escape academia and enter production use.&lt;/p&gt;

&lt;p&gt;ML also greatly influenced modern theorem provers. The “program” languages for Isabelle, CVC3, and Coq are ML-based. And a &lt;em&gt;lot&lt;/em&gt; of type theory was based on ML, though in more recent years the Haskell branch of FP has become more popular.&lt;sup id="fnref:haskell"&gt;&lt;a href="#fn:haskell"&gt;7&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Cause of Death&lt;/strong&gt;: ML had a lot of interesting features, but people paid attention to it for the type inference. At the time ML was still a special purpose language for the theorem provers. SML came out the same year as Haskell, which was a much “purer” example of a typed FP language.&lt;sup id="fnref:ml"&gt;&lt;a href="#fn:ml"&gt;6&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;h3 id="smalltalk"&gt;Smalltalk&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Background&lt;/strong&gt;: Alan Kay, 1972, 1976, and 1980. It’s sort of a moving target. Smalltalk-72 was the first, Smalltalk-76 introduced the idea of “object-oriented programming” to the wider world, and Smalltalk-80 was the one that saw widespread adoption.&lt;/p&gt;

&lt;p&gt;Smalltalk wasn’t the first language with objects but it was the first “object-oriented” one. The difference was that Simula &lt;em&gt;had&lt;/em&gt; objects in addition to primitives like numbers and booleans, while in Smalltalk, booleans &lt;em&gt;were also&lt;/em&gt; objects. I wrote a bit about this &lt;a href="https://www.hillelwayne.com/post/alan-kay/"&gt;here&lt;/a&gt; if you want to learn more.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Significance&lt;/strong&gt;: We sometimes think that Smalltalk is “true” OOP and things like Java and Python aren’t “real” OOP, but that’s not true. OOP is a giant mess of many different influences, just like every other paradigm. But it was certainly the thing that &lt;em&gt;popularized&lt;/em&gt; the idea. If you crack open any general theory OOP book from the mid-80’s or early 90’s, they’ll be in Smalltalk. Many will also translate their examples to C++, and a few will use another language, but everybody will use Smalltalk.&lt;/p&gt;

&lt;p&gt;Smalltalk also spread the idea of objects as shareable data, leading the way to CORBA, and it inspired the computational Actor model.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Cause of Death&lt;/strong&gt;: The common belief is that Smalltalk lost because people used C++ instead. But that’s untrue. Smalltalk did have some issues, specifically its difficulty interoping with other tools and poor runtime performance. But even into the 1990’s Smalltalk was doing respectable business and many people assumed it would be a dominant business language.&lt;/p&gt;

&lt;p&gt;Then Java happened.&lt;/p&gt;

&lt;figure&gt; 
  &lt;img title="Popularity of languages" src="https://hillelwayne.com/post/influential-dead-languages/java.jpg"&gt; 
  &lt;figcaption&gt;&lt;a href="https://books.google.com/ngrams/graph?content=Java+language%2Csmalltalk+language%2Ceiffel+language%2Csimula+language%2Cada+language&amp;amp;case_insensitive=on&amp;amp;year_start=1980&amp;amp;year_end=2000&amp;amp;corpus=15&amp;amp;smoothing=2&amp;amp;share=&amp;amp;direct_url=t4%3B%2CJava%20language%3B%2Cc0%3B%2Cs0%3B%3BJava%20language%3B%2Cc0%3B%3BJava%20Language%3B%2Cc0%3B%3BJAVA%20LANGUAGE%3B%2Cc0%3B.t4%3B%2Csmalltalk%20language%3B%2Cc0%3B%2Cs0%3B%3BSmalltalk%20language%3B%2Cc0%3B%3BSmalltalk%20Language%3B%2Cc0%3B%3BSmallTalk%20language%3B%2Cc0%3B.t1%3B%2CEiffel%20language%3B%2Cc0%3B.t4%3B%2Csimula%20language%3B%2Cc0%3B%2Cs0%3B%3BSimula%20language%3B%2Cc0%3B%3BSIMULA%20language%3B%2Cc0%3B%3BSIMULA%20Language%3B%2Cc0%3B.t4%3B%2Cada%20language%3B%2Cc0%3B%2Cs0%3B%3BAda%20language%3B%2Cc0%3B%3BAda%20Language%3B%2Cc0%3B%3BADA%20language%3B%2Cc0%3B%3BADA%20LANGUAGE%3B%2Cc0%3B%3BADA%20Language%3B%2Cc0#t4%3B%2CJava%20language%3B%2Cc0%3B%2Cs0%3B%3BJava%20language%3B%2Cc0%3B%3BJava%20Language%3B%2Cc0%3B%3BJAVA%20LANGUAGE%3B%2Cc0%3B.t4%3B%2Csmalltalk%20language%3B%2Cc0%3B%2Cs0%3B%3BSmalltalk%20language%3B%2Cc0%3B%3BSmalltalk%20Language%3B%2Cc0%3B%3BSmallTalk%20language%3B%2Cc0%3B.t1%3B%2CEiffel%20language%3B%2Cc0%3B.t4%3B%2Csimula%20language%3B%2Cc0%3B%2Cs0%3B%3BSimula%20language%3B%2Cc0%3B%3BSIMULA%20language%3B%2Cc0%3B%3BSIMULA%20Language%3B%2Cc0%3B.t4%3B%2Cada%20language%3B%2Cc0%3B%2Cs0%3B%3BAda%20language%3B%2Cc0%3B%3BAda%20Language%3B%2Cc0%3B%3BADA%20language%3B%2Cc0%3B%3BADA%20LANGUAGE%3B%2Cc0%3B%3BADA%20Language%3B%2Cc0"&gt;(source)&lt;/a&gt;&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Smalltalk wasn’t the only casualty of the “Javapocalypse”: Java also marginalized Eiffel, Ada95, and pretty much everything else in the OOP world.  The interesting question isn’t “Why did Smalltalk die”, it’s “Why did C++ survive”. I think it’s because C++ had better C interop so was easier to extend into legacy systems.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;This is just a small sample of the important dead languages. I didn’t cover ALPHARD, ALTRAN, Argus, Automath, BCPL, COMTRAN, CPL, Eiffel, FLOW-MATIC, HOPE, Hypercard, ISWIM, JOVIAL, MacSyma, Mesa, Miranda, Multics Shell, PLANNER, SMP, Sketchpad, or SNOBOL. All of them contributed in their own way to the modern programming world. History is complicated.&lt;/p&gt;

&lt;p&gt;Most influential languages never went mainstream. Few people used any one of them. But each one inspired people, who inspired other people, so the DNA of these forgotten languages appear decades after they’re forgotten. But there are also untold languages that didn’t get their ideas out. The &lt;a href="http://hopl.info/"&gt;Encyclopaedia of Programming Languages&lt;/a&gt; lists over 8,000 programming languages. Many of them had ideas that never left their bubble. Consider how much we’d have lost if nobody had heard of SIMULA, or Liskov never shared CLU.&lt;/p&gt;

&lt;p&gt;That’s one reason I love studying history. To learn what we’ve lost and find it again.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;The first draft of this was originally shared on my &lt;a href="https://buttondown.email/hillelwayne/"&gt;newsletter&lt;/a&gt;. If you found this interesting, why not subscribe?&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Thanks to 
  
    &lt;a href="https://miikka.me/"&gt;Miikka Koskinen&lt;/a&gt;
  
, 
  
    &lt;a href="https://medium.com/@kevlinhenney"&gt;Kevlin Henney&lt;/a&gt;
  
, Eric Fischer, and Levi Pearson for corrections and feedback.&lt;/em&gt;&lt;/p&gt;


&lt;/div&gt;

    



  &lt;/article&gt;&lt;/div&gt;&lt;a href="https://hillelwayne.com/post/influential-dead-languages/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Thu, 26 Mar 2020 11:12:08 UT
      </pubDate>
      <guid>
        https://hillelwayne.com/post/influential-dead-languages/
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://mapfilterfold.com/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;
&lt;p&gt;
&lt;h2&gt;
&lt;a href="https://mapfilterfold.com/books/108" aria-label="Goto book titled Zero to One: Notes on Startups, or How to Build the Future"&gt;Zero to One: Notes on Startups, or How to Build the Future&lt;/a&gt; &lt;/h2&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;h3&gt;by
&lt;a href="https://mapfilterfold.com/books/?author=Peter%20Thiel" aria-label="Goto author: #(@book.author}"&gt;Peter Thiel&lt;/a&gt; &lt;/h3&gt;
&lt;/p&gt;
&lt;p&gt; shawn: I think it's a good one because it's a mix of analysis and history. Thiel had a unique vantage point, and he shares it well. It also challenges you to be ambitious, which is becoming a rare sentiment.
&lt;a href="https://mapfilterfold.com/books/108" aria-label="Read more comments about this book"&gt;read comments&lt;/a&gt; &lt;/p&gt;
&lt;div&gt;
&lt;p&gt; in:
&lt;a href="https://mapfilterfold.com/?nonfiction=true" aria-label="Goto nonfiction books"&gt;nonfiction&lt;/a&gt;
| &lt;a href="https://mapfilterfold.com/books/?genre=business" aria-label="Goto genre business"&gt;business&lt;/a&gt;
| &lt;a href="https://mapfilterfold.com/books/?genre=entrepreneurship" aria-label="Goto genre entrepreneurship"&gt;entrepreneurship&lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;a href="https://mapfilterfold.com/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Fri, 27 Mar 2020 14:57:39 UT
      </pubDate>
      <guid>
        https://mapfilterfold.com/
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://blog.trello.com/decision-journal
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;
&lt;p&gt;&lt;span data-hs-cos-type="rich_text" data-hs-cos-general-type="meta_field" id="hs_cos_wrapper_post_body"&gt;&lt;p&gt;&lt;img sizes="(max-width: 2400px) 100vw, 2400px" srcset="https://blog.trello.com/hs-fs/hubfs/decision%20journal%20.png?width=1200&amp;amp;name=decision%20journal%20.png 1200w, https://blog.trello.com/hs-fs/hubfs/decision%20journal%20.png?width=2400&amp;amp;name=decision%20journal%20.png 2400w, https://blog.trello.com/hs-fs/hubfs/decision%20journal%20.png?width=3600&amp;amp;name=decision%20journal%20.png 3600w, https://blog.trello.com/hs-fs/hubfs/decision%20journal%20.png?width=4800&amp;amp;name=decision%20journal%20.png 4800w, https://blog.trello.com/hs-fs/hubfs/decision%20journal%20.png?width=6000&amp;amp;name=decision%20journal%20.png 6000w, https://blog.trello.com/hs-fs/hubfs/decision%20journal%20.png?width=7200&amp;amp;name=decision%20journal%20.png 7200w" width="2400" alt="decision journal" src="https://blog.trello.com/hs-fs/hubfs/decision%20journal%20.png?width=2400&amp;amp;name=decision%20journal%20.png"&gt;&lt;/p&gt;
&lt;p&gt;Do you remember those “choose your own adventure” books from your childhood? Where the pages were filled with different options and the choices you made advanced the plot?&amp;nbsp;&lt;/p&gt;

&lt;p&gt;Yeah, real life feels a lot like that—except, it’s never-ending and not always as thrilling. That’s because we’re faced with a lot of decisions each and every day. And I mean &lt;i&gt;a lot&lt;/i&gt; of them.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;So instead of throwing your hands up in the air, what should you do instead in the face of an endless list of decisions?&amp;nbsp;&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Decisions, Decisions: Are We All Burnt Out On Making Choices?&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Some estimates go as far as to say that you need to make upwards of &lt;a rel="nofollow noopener" href="http://science.unctv.org/content/reportersblog/choices"&gt;35,000 remotely conscious choices&lt;/a&gt; on a daily basis. Even funnier? A &lt;a rel="nofollow noopener" href="https://news.cornell.edu/stories/2006/12/mindless-autopilot-drives-people-underestimate-food-decisions"&gt;study out of Cornell&lt;/a&gt; found that you make over 200 decisions a day just related to what you’ll eat or drink.&lt;/p&gt;
&lt;p&gt;It’s no wonder that so many of us feel like our decision-making muscles are worn out. In fact, the feeling of exhaustion over needing to choose between option A and option B is so relatable that it’s even been given a name: &lt;a rel="noopener" href="https://blog.trello.com/beat-decision-fatigue-with-better-brain-habits"&gt;decision fatigue&lt;/a&gt;.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;Plenty of research demonstrates that the quality of your decisions decreases as you make more choices, simply because you get plain ol’ tired of making them. And, it seems like nobody is immune. &lt;a rel="nofollow noopener" href="https://www.pnas.org/content/108/17/6889"&gt;One study&lt;/a&gt; of judges (who we’d all like to think of as sound decision-makers) found that they were way more likely to grant parole in the morning, compared with later in the day.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;Decisions can be exhausting, but they’re also an essential part of your daily life. From the small ones (what should you eat for lunch?) to the giant ones (should you change careers?), you’re in the driver’s seat.&lt;/p&gt;
&lt;p&gt;&lt;img alt="bad at making decisions" src="https://blog.trello.com/hubfs/bad%20at%20making%20decisions.gif"&gt;&lt;/p&gt;
&lt;p&gt;So, how can you get better at making choices—particularly the big ones that have potentially major consequences? Should you engage in a rousing game of eenie, meenie, miney, moe? Throw a dart at a board?&lt;/p&gt;
&lt;p&gt;As it turns out, a decision journal might just be the tool you need.&amp;nbsp;&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;So...What Is A Decision Journal?&amp;nbsp;&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;I can’t blame you if the term “decision journal” inspires visions of writing a bunch of heartfelt “dear diary” entries in a locked notebook.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;But, this concept is actually a pretty straightforward journaling exercise. In your decision journal (it can be anything from a &lt;a rel="noopener" href="https://trello.com/power-ups/55a5d916446f517774210006/google-drive"&gt;Google Document&lt;/a&gt; to a cheap notebook to even a Trello board), you simply chronicle your bigger decisions and record how you felt when you made them.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;As an &lt;a rel="nofollow noopener" href="https://fs.blog/2014/02/decision-journal/"&gt;article for Farnam Street&lt;/a&gt; recommends, when you’re faced with a large decision, use your journal to document the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The choice you’ve made&lt;/li&gt;
&lt;li&gt;What you expect to happen as a result of that choice&lt;/li&gt;
&lt;li&gt;Why you expect things to pan out that way&lt;/li&gt;
&lt;li&gt;How you feel about your decision&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For example, imagine that you were wrestling with the choice of whether or not to apply for an internal transfer to a different department within your company. Once you’ve actually made your choice (you’re going to go for it and toss your hat into the ring!), you’d use your decision journal to jot down the nuts and bolts of that decision, your assumptions, and your emotional state when you settled on your outcome.&amp;nbsp;&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;How A Decision Journal Can Help Declutter Your Brain&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;A decision journal isn’t necessarily an in-the-moment tool like a &lt;a rel="nofollow noopener" href="https://toggl.com/blog/decision-matrix"&gt;decision matrix&lt;/a&gt; or a trusty pros and cons list.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;Instead, it’s something you’ll use for reflection. By documenting and periodically reviewing the decisions you make over time, you’ll get a better grasp on your state of mind and identify things like trends or common traps you find yourself falling into.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;To put it simply, a decision journal helps to refine your decision-making process as you move forward, rather than being something that helps you actually make a choice in the moment.&lt;/p&gt;
&lt;p&gt;If that seems like an unnecessary formality, I promise it’s not—because it’ll help you overcome something called the hindsight bias.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;“Research shows that we selectively recall information that confirms what we know to be true and we try to create a narrative that makes sense out of the information we have,” explains an &lt;a rel="nofollow noopener" href="https://www.psychologicalscience.org/news/releases/i-knew-it-all-along-didnt-i-understanding-hindsight-bias.html"&gt;article for the Association for Psychological Science&lt;/a&gt;. “When this narrative is easy to generate, we interpret that to mean that the outcome must have been foreseeable.”&lt;/p&gt;
&lt;p&gt;Basically, when you stroke your ego by telling yourself that you’re a fortune teller, you create major blindspots and lose out on opportunities to improve. You need to be able to clearly see where you make mistakes and why they happen. Ultimately, that information helps you make better choices moving forward.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;Maybe your decision journal will illuminate the fact that you have the tendency to make irrational choices when you’re stressed and under the gun. Knowing this, you can move through future decisions by giving yourself some space to breathe and mull things over a little more.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;Or, perhaps every time you marked down that you felt wary of a decision, it turned out poorly. That’s a sign that maybe you need to start trusting your gut.&amp;nbsp;&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;How To Make The Most Of Your Decision Journal&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;The process of decision journaling itself is pretty cut and dried: you write down your decision, your assumptions, and your emotions.&lt;/p&gt;
&lt;p&gt;But, there are a few other tips you’ll want to keep in mind to really make the most of this practice.&amp;nbsp;&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;1. Don’t Use It For Everything&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;I know what you’re thinking: Journaling about your decisions is just another thing to add to your to-do list—which most of us don’t need, especially since &lt;a rel="nofollow noopener" href="https://www.cnbc.com/2017/03/29/most-american-workers-are-stressed-most-of-the-time.html"&gt;60% of workers&lt;/a&gt; reportedly feel stressed more than three work days per week.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;Your decision journal shouldn’t be a burdensome activity that slows down the process of making every single decision.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;Reserve it exclusively for the larger decisions that have potentially major consequences and require some serious thought and deliberation. After all, there’s no need to journal about whether you should order a turkey club or a chicken burrito for lunch that day.&amp;nbsp;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;&lt;img sizes="(max-width: 500px) 100vw, 500px" srcset="https://blog.trello.com/hs-fs/hubfs/how%20to%20use%20a%20decision%20journal.gif?width=250&amp;amp;name=how%20to%20use%20a%20decision%20journal.gif 250w, https://blog.trello.com/hs-fs/hubfs/how%20to%20use%20a%20decision%20journal.gif?width=500&amp;amp;name=how%20to%20use%20a%20decision%20journal.gif 500w, https://blog.trello.com/hs-fs/hubfs/how%20to%20use%20a%20decision%20journal.gif?width=750&amp;amp;name=how%20to%20use%20a%20decision%20journal.gif 750w, https://blog.trello.com/hs-fs/hubfs/how%20to%20use%20a%20decision%20journal.gif?width=1000&amp;amp;name=how%20to%20use%20a%20decision%20journal.gif 1000w, https://blog.trello.com/hs-fs/hubfs/how%20to%20use%20a%20decision%20journal.gif?width=1250&amp;amp;name=how%20to%20use%20a%20decision%20journal.gif 1250w, https://blog.trello.com/hs-fs/hubfs/how%20to%20use%20a%20decision%20journal.gif?width=1500&amp;amp;name=how%20to%20use%20a%20decision%20journal.gif 1500w" width="500" alt="how to use a decision journal" src="https://blog.trello.com/hs-fs/hubfs/how%20to%20use%20a%20decision%20journal.gif?width=500&amp;amp;name=how%20to%20use%20a%20decision%20journal.gif"&gt;&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;2. Keep It Simple&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Your decision journal should be used to evaluate your more complex decisions, but that doesn’t mean that the journal itself should be complicated.&lt;/p&gt;
&lt;p&gt;Remember, you want this to be something that’s easy to refer back to and reflect on. Having pages and pages about every option you considered and every detail about your emotional state will only make this a cumbersome resource for you (meaning it’ll probably just collect dust in your desk drawer).&lt;/p&gt;
&lt;p&gt;Use simple language, short sentences, and be as straightforward as possible when documenting your decisions and emotions. That will allow you to look back and get the information you really need—without wading through paragraphs of flowery language and unnecessary details.&amp;nbsp;&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;3. Create A Simple Template For Yourself&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;One of the best ways to keep things simple is to create a template that you can use time and time again. It’ll prompt you to stay focused on the need-to-know information and remove a lot of the guesswork and ambiguity from the decision journaling process.&lt;/p&gt;
&lt;p&gt;Whether you want to create a templated Trello card or start a simple document that you can keep copying, make sure that your decision journal template touches on the basics. Here’s what this could look like:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Date I made this decision: ___________________________&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;The decision I made was: ____________________________&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;I believe this decision will lead to: __________________&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Why I believe this decision will pan out this way: _____________________________________________________&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;How I feel about the decision I’ve made: ______________________________________________________&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;See? Not so difficult after all. Of course, you’re welcome to add more to your own template if it helps you, but the point is to at least get a basic process in place. That’ll make the process of journaling less daunting—and make you way more likely to stick to it.&amp;nbsp;&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;4. Review Your Journal Frequently&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;A decision journal isn’t about helping you make choices in the heat of the moment. It’s a record that you can refer back to in order to understand your blind spots and make better decisions moving forward.&lt;/p&gt;
&lt;p&gt;So, that means you need to actually look back at it—and you should plan to do so frequently (aim for every quarter, at the very least).&lt;/p&gt;
&lt;p&gt;Research shows that we all tend to have an inflated view of our own performance. In &lt;a rel="nofollow noopener" href="https://www.npr.org/templates/story/story.php?storyId=15073430"&gt;one study&lt;/a&gt;, engineers were asked if they believed they were in the top 5% of the engineers at their company, and a whopping 40% of them said “yes.”&lt;/p&gt;
&lt;p&gt;And, even further, our own self-ratings aren’t correlated with positive performance. A &lt;a rel="nofollow noopener" href="https://www.npr.org/templates/story/story.php?storyId=15073430"&gt;separate study&lt;/a&gt; of physicians found that things like supervisor and peer ratings of surgical residents were fairly accurate in predicting whether or not residents would perform well on their board exams, but there was zero relationship between self-ratings and their exam success.&lt;/p&gt;
&lt;p&gt;“We apply a lot of positive spin to evidence we get about ourselves,” explains David Dunning, a Professor of Psychology at Cornell University, in an &lt;a rel="nofollow noopener" href="https://www.npr.org/templates/story/story.php?storyId=15073430"&gt;interview with NPR&lt;/a&gt; about both studies. “People obviously want to think pleasant things about themselves. They want to avoid thinking threatening things about themselves.”&lt;/p&gt;
&lt;p&gt;In short, we aren’t great at honestly evaluating ourselves, which means we probably won’t be able to spot our decision-making weaknesses and pitfalls on our own.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;&lt;img alt="following your own advice" src="https://blog.trello.com/hubfs/following%20your%20own%20advice.gif"&gt;&lt;/p&gt;
&lt;p&gt;If you answer honestly and follow your prompts, your decision journal will serve as an unbiased third party that will equip you with valuable feedback—provided you make the time to lean on it frequently, of course.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;When it’s time for you to review your entries, give yourself some quiet, focused time to reflect:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Are there mistakes you see yourself making again and again?&lt;/li&gt;
&lt;li&gt;Are there certain types of decisions that make you feel more anxious than others?&lt;/li&gt;
&lt;li&gt;What about the types of decisions that inspire a lot of confidence?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This time for self-reflection is more than just a feel-good exercise, as you’ll quickly identify areas of improvement. And, the more you do that, the better you’ll get at making choices—which will help you kick that pesky decision fatigue we mentioned earlier to the curb.&amp;nbsp;&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Flex Those Decision-Making Muscles And Put Pen To Paper&amp;nbsp;&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;The “choose your own adventure” books of your childhood were fun. But, in real life, needing to make decision after decision can be draining and ultimately lead to some lackluster choices.&lt;/p&gt;
&lt;p&gt;That’s why a decision journal should be your not-so-secret weapon. It’ll give you some helpful insight into your own decision-making process, so you can improve your selections moving forward.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;While it’s not designed to help you pick between that turkey sandwich or burrito, it will help you approach your larger, real-life decisions with as much certainty as you had when you were a kid choosing which page to flip to.&amp;nbsp;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;Good or bad, we'd love to hear your thoughts. Find us on Twitter (&lt;a data-ol-has-click-handler="" rel="nofollow noopener" href="https://twitter.com/trello"&gt;@trello&lt;/a&gt;) or write in to&amp;nbsp;&lt;a data-ol-has-click-handler="" rel="nofollow noopener" href="mailto:support@trello.com"&gt;support@trello.com&lt;/a&gt;&amp;nbsp;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Next:&lt;/strong&gt; &lt;em&gt;&lt;a rel="noopener" href="https://blog.trello.com/do-not-have-a-plan"&gt;Feeling Uncertain? How To Move Forward Without A Plan&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;
&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;&lt;a href="https://blog.trello.com/decision-journal"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Fri, 27 Mar 2020 17:16:05 UT
      </pubDate>
      <guid>
        https://blog.trello.com/decision-journal
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://blog.ycombinator.com/science-startups/
      </link>
      <description>
        &lt;a href="https://blog.ycombinator.com/science-startups/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Fri, 27 Mar 2020 18:25:41 UT
      </pubDate>
      <guid>
        https://blog.ycombinator.com/science-startups/
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://ericlippert.com/2020/03/27/new-grad-vs-senior-dev/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;
		&lt;p&gt;A student who I used to tutor in CS occasionally sent me a meme yesterday which showed “NEW GRAD vs SENIOR DEVELOPER”; the new grad is all caps yelling&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;NO! YOU CAN’T JUST USE BRUTE FORCE HERE! WE NEED TO USE SEGMENT TREES TO GET UPDATE TIME COMPLEXITY DOWN TO O(LOG N)! BREAK THE DATA INTO CHUNKS AT LEAST! OH THE INEFFICIENCY!!!&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;and the senior developer responds&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Ha ha, nested for loops go brrrrrrrrrrrr…&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;OK, that’s silly and juvenile, but… oh no, I feel a flashback coming on.&lt;/p&gt;
&lt;p&gt;…&lt;/p&gt;
&lt;p&gt;…&lt;/p&gt;
&lt;p&gt;…&lt;/p&gt;
&lt;p&gt;It is 1994 and I am a second-year CS student at my first internship at Microsoft on the Visual Basic compiler team, reading the source code for InStr for the first time. InStr is the function in Visual Basic that takes two strings, call them &lt;strong&gt;source&lt;/strong&gt; and &lt;strong&gt;query&lt;/strong&gt;, and tells you the index at which &lt;strong&gt;query&lt;/strong&gt; first appears as a substring of &lt;strong&gt;source&lt;/strong&gt;, and the implementation is naive-brute-force.&lt;/p&gt;
&lt;p&gt;I am shocked to learn this! Shocked, I tell you!&lt;/p&gt;
&lt;p&gt;Let me digress slightly here and say what the naive brute force algorithm is for this problem.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Aside: To keep it simple we’ll ignore all the difficulties inherent in this problem entailed by the fact that VB was the first Microsoft product where one version worked everywhere in the world on every version of Windows no matter how Windows was localized; systems that used Chinese DBCS character encodings ran the same VB binary as systems that used European code pages, and we had to support all these encodings plus Unicode UTF-16. As you might imagine, the string code was a bit of a mess. (And cleaning it up in VBScript was one of my first jobs as an FTE in 1996!)&lt;/p&gt;
&lt;p&gt;Today for simplicity we’ll just assume we have a flat, zero-terminated array of chars, one character per char as was originally intended.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;The &lt;em&gt;extremely&lt;/em&gt; naive algorithm for finding a string in another goes something like this pseudo-C algorithm:&lt;/p&gt;
&lt;pre&gt;bool starts(char *source, char *query)
{
  int i = 0;
  while (query[i] != '\0')
  {
    if (source[i] != query[i])
      return false;
    i = i + 1;
  }
  return true;
}
int find(char *source, char *query)
{
  int i = 0;
  while (source[i] != '\0')
  {
    if (starts(source + i, query))
      return i;
    i = i + 1;
  }
  return -1;  
}&lt;/pre&gt;
&lt;p&gt;The attentive reader will note that this is the aforementioned &lt;strong&gt;nested for loop&lt;/strong&gt;; I’ve just extracted the nested loop into its own helper method. The extremely attentive reader will have already noticed that I wrote a few bugs into the algorithm above; what are they?&lt;/p&gt;
&lt;p&gt;Of course there are many nano-optimizations one can perform on this algorithm if you know a few C tips and tricks; again, we’ll ignore those. It’s the algorithmic complexity I’m interested in here.&lt;/p&gt;
&lt;p&gt;The action of the algorithm is straightforward. If we want to know if query “banana” is inside source “apple banana orange” then we ask:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;does “apple banana orange” start with “banana”? No.&lt;/li&gt;
&lt;li&gt;does “pple banana orange” start with “banana”? No.&lt;/li&gt;
&lt;li&gt;does “ple banana orange” start with “banana”? No.&lt;/li&gt;
&lt;li&gt;…&lt;/li&gt;
&lt;li&gt;does “banana orange” start with “banana”? Yes! We’re done.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It might not be clear why the naive algorithm is bad. The key is to think about what the worst case is. The worst case would have to be one where there is no match, because that means we have to check the most possible substrings. Of the no-match cases, what are the worst ones? The ones where &lt;strong&gt;starts&lt;/strong&gt;&amp;nbsp;does the most work to return false.&amp;nbsp; For example, suppose &lt;strong&gt;source&lt;/strong&gt; is “aaaaaaaaaaaaaaaaaaaa” — twenty characters — and &lt;strong&gt;query&lt;/strong&gt; is “aaaab”. What does the naive algorithm do?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Does “aaaaaaaaaaaaaaaaaaaa” start with “aaaab”? No, but it takes five comparisons to determine that.&lt;/li&gt;
&lt;li&gt;Does “aaaaaaaaaaaaaaaaaaa” start with “aaaab”? No, but it takes five comparisons to determine that.&lt;/li&gt;
&lt;li&gt;… and so on.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the majority of attempts it takes us the maximum number of comparisons to determine that the &lt;strong&gt;source&lt;/strong&gt; substring does not start with the &lt;strong&gt;query&lt;/strong&gt;. The naive algorithm’s worst case is O(n*m) where n is the length of &lt;strong&gt;source&lt;/strong&gt; and m is the length of the &lt;strong&gt;query&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;There are a lot of obvious ways to make minor improvements to the extremely naive version above, and in fact the implementation in VB was slightly better. The implementation in VB was basically this:&lt;/p&gt;
&lt;pre&gt;char* skipto(char *source, char c)
{
  char *result = source;
  while (*result != '\0' &amp;amp;&amp;amp; *result != c)
    result = result + 1;
  return result;
}
int find(char *source, char *query)
{
  char *current = skipto(source, query[0]);
  while (*current != '\0;)
  {
    if (starts(current, query))
      return current - source;
    current = skipto(current + 1, query[0]);
  }
  return -1;
}&lt;/pre&gt;
&lt;p&gt;(WOW, EVEN MORE BUGS! Can you spot them? It’s maybe easier this time.)&lt;/p&gt;
&lt;p&gt;This is more complicated but not actually better algorithmically; all we’ve done is moved the initial check in &lt;strong&gt;starts&lt;/strong&gt;&amp;nbsp;that checks for equality of the first letters into its own helper method. In fact, what the heck, this code looks &lt;em&gt;worse&lt;/em&gt;. It does &lt;em&gt;more work&lt;/em&gt; and is &lt;em&gt;more complicated&lt;/em&gt;. What’s going on here? We’ll come back to this.&lt;/p&gt;
&lt;p&gt;As I said, I was a second year CS student and (no surprise) a bit of a keener; I had read ahead and knew that there were string finding algorithms that are considerably better than O(n*m). The basic strategy of these better algorithms is to do some preprocessing of the strings to look for interesting features that allow you to “skip over” regions of the source string that you know cannot possibly contain the query string.&lt;/p&gt;
&lt;p&gt;This is a heavily-studied problem because, first off, obviously it is a “foundational” problem; finding substrings is useful in many other algorithms, and second, because we genuinely do have extremely difficult problems to solve in this space. “Find this DNA fragment inside this genome”, for example, involves strings that may be billions of characters long with lots of partial matches.&lt;/p&gt;
&lt;p&gt;I’m not going to go into the various different algorithms that are available to solve this problem and their many pros and cons; you can &lt;a href="https://en.wikipedia.org/wiki/String-searching_algorithm#Single-pattern_algorithms"&gt;read about them on Wikipedia&lt;/a&gt; if you’re interested.&lt;/p&gt;
&lt;p&gt;Anyways, where was I, oh yes, &lt;strong&gt;CS student summer intern vs Senior Developer&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;I read this code and was outraged that it was not the most asymptotically efficient possible code, so I got a meeting with Tim Paterson, who had written much of the string library and had the office next to me.&lt;/p&gt;
&lt;p&gt;Let me repeat that for those youngsters in the audience here, &lt;strong&gt;TIM FREAKIN’ PATERSON.&lt;/strong&gt; Tim “QDOS” Paterson, who one fine day wrote an operating system, sold it to BillG, and that became MS-DOS,&lt;em&gt; the most popular operating system in the world.&lt;/em&gt; &lt;a href="https://ericlippert.com/2003/09/26/what-could-numeric-rounding-possibly-have-to-do-with-ms-dos/"&gt;As I’ve mentioned before, Tim was very intimidating to young me and did not always suffer foolish questions gladly&lt;/a&gt;, but it turned out that in this case he was very patient with all-caps THIS IS INEFFICIENT Eric. More patient than I likely deserved.&lt;/p&gt;
&lt;p&gt;As Tim explained to me, first off, the reason why VB does this seemingly bizarre “find the first character match, then check if &lt;strong&gt;query&lt;/strong&gt; is a prefix of &lt;strong&gt;source&lt;/strong&gt;” logic is because the &lt;strong&gt;skipto&lt;/strong&gt;&amp;nbsp;method is not written in the naive fashion that I showed here. &lt;strong&gt;The skipto method is a single x86 machine instruction.&lt;/strong&gt; (&lt;strong&gt;REPNE SCASB,&lt;/strong&gt; maybe? My x86 machine code knowledge was never very good. It was something in the &lt;strong&gt;REP&lt;/strong&gt; family at least.) It is &lt;em&gt;blazingly&lt;/em&gt; fast. It harnesses the power of purpose-built hardware to solve the problem of “where’s that first character at?”&lt;/p&gt;
&lt;p&gt;That explains that; it genuinely is a big perf win to let the hardware do the heavy lifting here. But what about the asymptotic problem? Well, as Tim patiently explained to me, guess what? Most VB developers are NOT asking if “aaaab” can be found in “aaaaaaa…”. The vast majority of VB developers are asking is “London” anywhere in this address, or similar problems where the strings are normal human-language strings without a lot of repetitions, and both the source and query strings are &lt;em&gt;short&lt;/em&gt;.&amp;nbsp; Like, very short. Less than 100 characters short. Fits into a cache line short.&lt;/p&gt;
&lt;p&gt;Think about it this way; most &lt;strong&gt;source&lt;/strong&gt; strings that VB developers are searching have any given character in them maybe 2% of the time, and so for whatever the start character is of the &lt;strong&gt;query&lt;/strong&gt; string, the &lt;strong&gt;skipto&lt;/strong&gt;&amp;nbsp;step is going to find those 2% of possible matches &lt;em&gt;very quickly&lt;/em&gt;. And then the &lt;strong&gt;starts&lt;/strong&gt;&amp;nbsp;step is the vast majority of the time going to &lt;em&gt;very quickly&lt;/em&gt; identify false matches. &lt;strong&gt;In practice the naive brute force algorithm is almost always O(n + m).&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Moreover, Tim explained to me, any solution that involves allocating a table, preprocessing strings, and so on, is going to take longer to do all that stuff than the blazingly-fast-99.9999%-of-the-time brute force algorithm takes to just give you the answer. The additional complexity is simply not worth it in scenarios that are relevant to VB developers. VB developers are developing line-of-business solutions, and their line of business is not typically genomics; if it is, they have special-purpose libraries for those problems; they’re not using &lt;strong&gt;InStr&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;…&lt;/p&gt;
&lt;p&gt;…&lt;/p&gt;
&lt;p&gt;…&lt;/p&gt;
&lt;p&gt;And we’re back in 2020. I hope you enjoyed that trip down memory lane.&lt;/p&gt;
&lt;p&gt;It turns out that yes, fresh grads and keener interns &lt;em&gt;do&lt;/em&gt; complain to senior developers about asymptotic efficiency, and senior developers &lt;em&gt;do&lt;/em&gt; say “but nested for loops go &lt;em&gt;brrrrrrr&lt;/em&gt;” — yes, they go &lt;em&gt;brrrrrr&lt;/em&gt; extremely quickly much of the time, and senior developers know that!&lt;/p&gt;
&lt;p&gt;And now I am the senior developer, and I try to be patient with the fresh grads as my mentors were patient with me.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;UPDATE: Welcome, Hacker News readers. I always know when I’m linked from Hacker News because of the huge but short-lived spike in traffic. &lt;a href="https://news.ycombinator.com/item?id=22712178"&gt;The original author of the meme that inspired this post has weighed in&lt;/a&gt;. Thanks for inspiring this trip back to a simpler time!&lt;/p&gt;
			&lt;/div&gt;&lt;/div&gt;&lt;a href="https://ericlippert.com/2020/03/27/new-grad-vs-senior-dev/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sat, 28 Mar 2020 15:11:56 UT
      </pubDate>
      <guid>
        https://ericlippert.com/2020/03/27/new-grad-vs-senior-dev/
      </guid>
    </item>
    <item>
      <title>
        Radical Solutions • Damn Interesting
      </title>
      <link>
        https://www.damninteresting.com/radical-solutions/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;p&gt;© All Rights Reserved. Please do not distribute without written permission from Damn Interesting.&lt;/p&gt;&lt;article&gt;
					
	                
					
									

					&lt;p&gt;Paris, 29 May 1832. All through the night, a young Frenchman named Évariste Galois stayed awake, quill in hand, frantically scrawling notes and equations across dozens of sheets of paper. He had only been studying mathematics seriously for a few years, but he had proven to be a veritable prodigy. After quickly exhausting the knowledge of his teachers, he’d branched out into his own research, extraordinarily prescient.&lt;/p&gt;
&lt;p&gt;By all rights, Galois ought to have been lauded and laurelled by the scientific community for his work. Above all, he should have been recognised and rewarded by France’s prestigious Academy of Sciences. But Galois⁠—at least, by his own reckoning⁠—had received little but dismissal from the mathematics community. Now he sat feverishly scribbling a letter to his best friend, trying to commit as many of his recent ideas to paper as possible. Finally, in the wee hours of the morning, Galois had sketched out most of what he felt able to capture. “You know … that these aren’t the only subjects I’ve explored,” he wrote. “But I don’t have time”. Twenty-year-old Galois fully expected that he was about to be shot to death.
&lt;/p&gt;
&lt;p&gt;
Évariste Galois was born on 25 October 1811 in the town of Bourg-la-Reine, today part of the southern suburbs of Paris. Although his parents ran a well-regarded boarding school of their own, they sent young Évariste to study in Paris shortly before he turned twelve to improve his social opportunities.&lt;/p&gt;
&lt;p&gt;Galois’s new school, the &lt;i&gt;Collège royal de Louis-le-Grand&lt;/i&gt; was and remains prestigious, but in the early 19th century, it boasted not only an unparalleled list of alumni⁠—among them such luminaries as Voltaire and Charles-Marie de La Condamine⁠—but also a fearsomely draconian atmosphere. Meals were meagre, facilities failing, cold constant, rats regular, and punishments painful, with the students under constant surveillance. The punitive environment⁠—plus homesickness and health issues⁠—took its toll on Galois. In his third year, his grades began to drop, and he earned a reputation as a loner and a troublemaker. One teacher labelled him a “chatterer” who “has, I believe, taken upon himself the task of wearing me out”. That said, Galois’s time at the school would soon lead to two major upheavals in the 14-year-old’s life⁠—one political, the other intellectual.&lt;/p&gt;
&lt;figure data-embiggen="true"&gt;&lt;p&gt;&lt;img title="Evariste Galois, drawn from memory by his brother" alt="Evariste Galois, drawn from memory by his brother" data-lazy-load-src="https://damn-8791.kxcdn.com/wp-content/uploads/2020/03/Evariste-Galois.jpg" data-height-ratio="1.3636363636364" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAMAAAAoyzS7AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAAZQTFRFgYGBAAAAqeg2zgAAAAxJREFUeNpiYAAIMAAAAgABT21Z4QAAAABJRU5ErkJggg=="&gt;&lt;/p&gt;&lt;figcaption&gt;Evariste Galois, drawn from memory by his brother&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Galois grew up at the tail-end of France’s revolutionary and Napoleonic years, which had infused the country’s intellectual bloodstream with liberal ideas. Despite the restored monarchy’s attempts to crack down on this unseemly radicalism, the school had developed a liberal reputation. A new school principal, Nicolas Berthot, thought this merited a course correction, and set about inaugurating new rules harkening back to the school’s harsh old Jesuit roots. In response, students undertook a campaign of nonviolent resistance⁠—when asked to sing hymns, speak in class, or toast the King at meals, they remained mute. Berthot, apparently not one for half measures, simply expelled the students⁠—over 100 of them. While Galois was not directly involved, he was appalled by Berthot’s peremptory reaction. It was in this atmosphere of injustice and oppression that young Galois began his shift from mere liberal-minded student to full-blown anti-authoritarian.&lt;/p&gt;
&lt;p&gt;In contrast, Galois’s academic upheaval was due to a happy convergence between an academic restructuring and his own academic failure. With his grades plummeting, he was forced to repeat his entire third year. This cannot have been welcome news, but there was an unexpected upside. The third-year curriculum had just been changed, and would now introduce students to arithmetic and geometry alongside their continued study of the classics. Galois was about to meet mathematics. Few blind dates have gone so well.&lt;/p&gt;
&lt;p&gt;Instantly sparked, the 15-year-old devoured entire textbooks on algebra, calculus, and geometry. Galois’s other classes, already somewhat neglected, fell off his radar almost entirely. Faculty soon abandoned all hope of getting any other subject into his brain.&lt;/p&gt;
&lt;p&gt;Galois leapt straight into a heavily intuitive, original approach to tackling big unanswered questions. His concerned teachers suggested that he outline his problem-solving more methodically, or at least follow the basics of showing his work, but he was not interested in such elementary claptrap. Within mere months, he had outgrown his coursework and reached the extremities of contemporary mathematical knowledge. &lt;/p&gt;
&lt;p&gt;Fully aware of his own preternatural talent, Galois set his sights on attending the &lt;i&gt;École polytechnique&lt;/i&gt;⁠—France’s foremost technical school⁠—as soon as possible. As he was nearing 16, the minimum age of admission, he registered for the entrance exam immediately. Nearly as immediately, he failed. Still, failing the entrance exam was nothing to be ashamed of. Many students went into their first attempts seeking only to get a sense of how the exam worked⁠—which made sense, as it was a fast-paced verbal interrogation at a blackboard. Just one in three examinees passed on their first try. Though Galois’s failure forced him to remain at Louis-le-Grand, he could at least console himself that this was only a temporary setback.&lt;/p&gt;
&lt;p&gt;A further consolation appeared in the form of an enthusiastic new mathematics teacher who grasped the scope of Galois’s ideas and quickly became his mentor. Under this mentor’s guidance, in April 1829, 17-year-old Galois published a short paper on repeating fractions in a respected scholarly journal. Impressive though this was, for Galois this was only a side-project, dwarfed by breakthroughs he was making in the area of polynomial equations. This was a big deal. Mathematicians had collectively hit a wall with polynomials late in the 18th century, and Galois was about to suggest a way over.&lt;/p&gt;
&lt;p&gt;For people who remember algebra classes, the most familiar type of polynomial is the &lt;i&gt;quadratic equation&lt;/i&gt;, which can be useful in calculating areas, solving some accounting tasks, and addressing some physics problems. It is generally written as: &lt;/p&gt;
&lt;center&gt;&lt;i&gt;ax&lt;sup&gt;2&lt;/sup&gt; + bx + c = 0&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;“X” is the single unknown value to solve for. There are multiple ways of figuring out the possible value(s) for &lt;i&gt;x&lt;/i&gt;, but one reliable way is by taking &lt;i&gt;a&lt;/i&gt;, &lt;i&gt;b&lt;/i&gt;, and &lt;i&gt;c&lt;/i&gt; and plugging them into a formula that was discovered by Spanish mathematician Abraham bar Hiyya Ha-Nasi around the year 1100 AD. It is fittingly known as the &lt;i&gt;quadratic formula&lt;/i&gt;:&lt;/p&gt;
&lt;center&gt;&lt;img height="94" width="340" src="https://www.damninteresting.com/wp-content/uploads/2020/03/quadratic-equation-340x94.png"&gt;&lt;/center&gt;
&lt;p&gt;What makes a quadratic equation ‘quadratic’ is that &lt;i&gt;x&lt;/i&gt; is squared, or to the power of 2. So a quadratic equation is said to have a &lt;i&gt;degree&lt;/i&gt; of 2. An equation where &lt;i&gt;x&lt;/i&gt; is to the power of 3 (but nothing more) has a degree of 3, and these are called &lt;i&gt;cubic equations&lt;/i&gt;, which look like this:&lt;/p&gt;
&lt;center&gt;&lt;i&gt;ax&lt;sup&gt;3&lt;/sup&gt; + bx&lt;sup&gt;2&lt;/sup&gt; + cx + d = 0&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;The quadratic formula doesn’t help with cubic equations, but a working &lt;i&gt;cubic formula&lt;/i&gt; was discovered sequentially by three Italian mathematicians in the 16th century. A student of one of theirs went one further, literally, managing to find an enormously complicated general formula for &lt;i&gt;quartic equations&lt;/i&gt;⁠—those of degree 4.&lt;/p&gt;
&lt;p&gt;The outstanding question Galois wished to tackle was: Is there a formula to solve &lt;i&gt;quintic equations&lt;/i&gt;, i.e. those of degree 5? Prominent mathematicians of the day suspected that a general solution for quintic equations simply did not exist. However, a mere failure to find such a formula was not evidence. Italian mathematician Paolo Ruffini came close to proving that no such general solution existed for 5th-degree equations, which he published in a paper in 1799.&lt;/p&gt;
&lt;p&gt;Picking up more or less where Ruffini left off, 17-year-old Galois set out to prove that no general formula existed for quintic equations. More broadly, Galois took an interest in an overarching question: what determined &lt;i&gt;whether or not&lt;/i&gt; a general formula exists for a given degree?&lt;/p&gt;
&lt;p&gt;Galois’s approach to untangling the matter was stunningly original. He tied equations to several major new conceptual frames. He identified &lt;i&gt;groups&lt;/i&gt;: sets of entities linked by a specific set of certain properties. Then &lt;i&gt;permutations&lt;/i&gt;: all the different ways of ordering the members of a set. And &lt;i&gt;symmetries&lt;/i&gt;: ways in which entities look like other parts of themselves. There was so much uncharted territory here that Galois found himself inventing a brand-new approach to algebra. The system he devised for describing the subtle internal characteristics of groups⁠—&lt;i&gt;group theory&lt;/i&gt;⁠—was almost unprecedented, but so versatile that it could capture the behaviour of not only numbers, but all sorts of grouped items and ways in which their components showed self-similarity. When it came to polynomials, Galois’s major insight was that solvability of a given equation ultimately had far less to do with the equation’s degree, and far more to do with its internal properties related to symmetry. Astrophysicist and popular-mathematics author Mario Livio offers this analogy:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;“Classifying equations by their degree is analogous to grouping the wooden building blocks in a toy box according to their sizes. Galois’s classification by symmetry properties is equivalent to the realization that the shape of the blocks⁠—round, square, or triangular⁠—was a more important characteristic.”&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Using his own new group theory to break a complicated polynomial equation into smaller pieces and test &lt;i&gt;those&lt;/i&gt; for solvability, Galois showed definitively that quintic equations, considered as a set, would not resolve this way. His results gave mathematics a way of determining &lt;i&gt;whether&lt;/i&gt; a particular polynomial can be solved through a formula. All polynomials of degrees 2, 3, and 4 qualified. Starting at degree 5, however, some did and others did not⁠—and thus there was no way a general solution could apply to all of them.&lt;/p&gt;
&lt;figure data-embiggen="true"&gt;&lt;p&gt;&lt;img title="A depiction of Paris, 1829, by Giuseppe Canella" alt="A depiction of Paris, 1829, by Giuseppe Canella" data-lazy-load-src="https://damn-8791.kxcdn.com/wp-content/uploads/2020/03/GiuseppeCanella-PlaceLouisXVI-1829.jpg" data-height-ratio="0.70588235294118" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAMAAAAoyzS7AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAAZQTFRFgYGBAAAAqeg2zgAAAAxJREFUeNpiYAAIMAAAAgABT21Z4QAAAABJRU5ErkJggg=="&gt;&lt;/p&gt;&lt;figcaption&gt;A depiction of Paris, 1829, by Giuseppe Canella&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Galois’s mentor Louis Richard, for one, was well-aware that the boy’s ideas were visionary. Richard decided to help his brilliant protégé submit two papers to the Academy of Sciences in the spring of 1829. Getting the Academy’s attention was an essential step for any aspiring mathematician in France at the time. It was the most prestigious scientific organisation in the country, and having a paper accepted there would be a spectacular feather in Galois’s cap. It wouldn’t hurt when it came to his second attempt at being admitted to the Polytechnique, either.&lt;/p&gt;
&lt;p&gt;Only members of the Academy could present new findings to the august body, so Galois needed to find a willing sponsor to present papers on his behalf. Richard reached out to the revered Augustin-Louis Cauchy, likely because 15 years earlier, Cauchy had published two papers on general theories of permutations. Cauchy, one of the most prolific mathematicians in history, rarely had time to read and endorse other people’s work⁠—but in this case, against the odds, he agreed. In May and June 1829, he presented a pair of complementary papers by Galois to the Academy of Sciences, and made plans to present a third in January 1830.&lt;/p&gt;
&lt;p&gt;But the thrill was about to be brutally crushed. A new priest had been assigned to Galois’s hometown of Bourg-la-Reine, one who immediately clashed with its liberal and warmhearted mayor⁠—who happened to be Galois’s father, Nicolas-Gabriel Galois. Determined to save the souls of his parish from the insidious influences of broad-mindedness and insufficient monarchism, the priest devised a plan to undermine the elder Galois and force him out of office. The well-liked Nicolas-Gabriel had a fondness for playful writing at times – delighting the townsfolk with short coupled rhymes. Taking note of this idiosyncracy, the priest began to author his own rhyming couplets in the mayor’s characteristic style, making them mean-spirited rather than playful, and signing them with Nicolas-Gabriel’s name. The slanderous counterfeits spread. Ultimately, the plot proved even more successful than the priest had hoped. In July 1829, devastated by the impersonation and by the loss of his good name, Nicolas-Gabriel Galois took his own life. He had been the mayor of the town for 15 years.&lt;/p&gt;
&lt;p&gt;The truth quickly emerged. Astoundingly, the priest attempted to take part in the funeral ceremony⁠—only to find himself fleeing a mob of furious townspeople and volleys of stones. Galois witnessed the entire scene, and his grief and rage can only be imagined. He had already had reason to resent and oppose his country’s religious right wing: the political had now become intensely personal.&lt;/p&gt;
&lt;p&gt;And then, with spectacularly bad timing, the next round of entrance exams for the École polytechnique was upon him. Galois⁠—short-tempered at the best of times, labouring under the emotional toll of his father’s death, convinced of his own genius, already bitter at the perceived injustice of having been rejected the first time around⁠—was in no state to deal with a second high-stakes examination at a blackboard. He was never at his best explaining ideas verbally in the first place, and he had spent the year working on original research rather than preparing for the examination. On top of that, Galois’s examiner was a man known for asking extremely simple questions⁠—not to test candidates’ knowledge, but to gauge their reaction to being asked them. Faced with an examiner who struck him as blitheringly ignorant, Galois did not do well. Unverified legend has long claimed that the exam came to an end when the candidate flung the eraser at the examiner’s face.&lt;/p&gt;
&lt;figure data-embiggen="true"&gt;&lt;p&gt;&lt;img title="The gates of the Polytechnique in Galois's time" alt="The gates of the Polytechnique in Galois's time" data-lazy-load-src="https://damn-8791.kxcdn.com/wp-content/uploads/2020/03/Ecole_Polytechnique-1400.jpg" data-height-ratio="0.75" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAMAAAAoyzS7AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAAZQTFRFgYGBAAAAqeg2zgAAAAxJREFUeNpiYAAIMAAAAgABT21Z4QAAAABJRU5ErkJggg=="&gt;&lt;/p&gt;&lt;figcaption&gt;The gates of the Polytechnique in Galois's time&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Whether it was his mathematics or his temper that sunk him, Galois was again denied admission to the Polytechnique. He turned his attention to a backup option: the &lt;i&gt;École préparatoire&lt;/i&gt; (Preparatory School), whose main job was training teachers. It had its own set of entrance exams⁠—across a range of subjects, including several that were not mathematics. Although the application deadline for the school had passed, Galois wrote a letter to the administration asking them to let him apply anyway. His letter suggests that recent events had not compromised his cockiness. The examiners allowed him to proceed, but the science adjudicator in particular was less than impressed, commenting dryly that Galois “knows absolutely nothing”:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;“I was told this student had an aptitude for Mathematics; this surprises me greatly, as based on his examination, I think he possesses very little intelligence, or, at least, it’s so well hidden that I was unable to discover it[.]”&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Nevertheless, Galois’s scores for mathematics were high enough⁠—and his answers, for a change, expressed clearly enough⁠—that he was admitted to the École préparatoire in November 1829.&lt;/p&gt;
&lt;p&gt;Galois had a way forward. However, his fledgling mathematics career ran into turbulence shortly after takeoff, due to the untimely death of a Norwegian mathematician named Niels Henrik Abel. Amiable but hapless, Abel had been unsuccessfully clamoring for attention from French mathematicians for years. He had even travelled to Paris to seek recognition, and sent one of his own papers to Augustin-Louis Cauchy. Alas, Cauchy had failed to get around to reading it. Even Abel’s defeated letter to Cauchy several years later, requesting the return of his manuscript, went unacknowledged. Then, only 26 years old, Abel succumbed to tuberculosis.&lt;/p&gt;
&lt;p&gt;When news of Abel’s death reached the Academy in June 1829, Cauchy scrambled to defend himself⁠—awkwardly and unconvincingly⁠—for having neglected the young Norwegian. He rushed to read Abel’s three-year-old manuscript and present it to the Academy, just a few weeks after his second presentation on Galois’s work. It was immediately apparent that Abel had reached many of the same conclusions as Galois, and done so earlier⁠—publishing a proof that there could be no general formula for polynomials of any individual degree of 5 or above. That autumn, the &lt;i&gt;Bulletin de Férussac&lt;/i&gt; published both an obituary of Abel and a detailed analysis of one of his earlier papers. For those in the know, this underscored the fact that while Galois had made some phenomenal breakthroughs, Abel had reached some of the same insights first. Their methods were entirely distinct, but when it came to the conclusions, Galois⁠—nine years younger⁠—had been provably pre-empted. Unsurprisingly, Cauchy’s planned third presentation of Galois’s research did not go ahead as planned in 1830⁠—though, as science historian René Taton points out, the normally irascible Galois did not complain about this, which suggests that he voluntarily withdrew his work given the unintended overlap with Abel’s findings.&lt;/p&gt;
&lt;figure data-embiggen="true"&gt;&lt;p&gt;&lt;img title="Niels Henrik Abel" alt="Niels Henrik Abel" data-lazy-load-src="https://damn-8791.kxcdn.com/wp-content/uploads/2020/03/Niels_Henrik_Abel-1400.jpg" data-height-ratio="1.25" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAMAAAAoyzS7AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAAZQTFRFgYGBAAAAqeg2zgAAAAxJREFUeNpiYAAIMAAAAgABT21Z4QAAAABJRU5ErkJggg=="&gt;&lt;/p&gt;&lt;figcaption&gt;Niels Henrik Abel&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;That said, Galois could still salvage the considerable original components of his own work. Abel had not scooped him on group theory. While keeping up with his regular schoolwork, Galois compiled his research into a manuscript and submitted it at the end of February 1830 to the Academy’s inaugural Grand Prize in mathematics. Despite a few setbacks, Galois was carving himself a respectable place in the mathematical world. If he were to win the Grand Prize, it would cement his status as a leading light of his generation.&lt;/p&gt;
&lt;p&gt;On 28 June 1830, the results of the Grand Prize were announced, and Galois’s name was nowhere to be seen. The jury chose to award the prize to two mathematicians for their separate work on elliptic functions. One was the German Carl Gustav Jacob Jacobi; the other, posthumously, was Abel. A clause in the contest rules specified that the jury could award the prize to any paper published in the previous year, not just official entries; the Academy thus made amends to the memory of the young man it had ignored in life.&lt;/p&gt;
&lt;p&gt;Another young man, however, was available to feel disregarded in Abel’s place. Galois could not possibly have objected to the winners on mathematical grounds; he strongly identified with Abel, and Jacobi appears to have been one of the few other mathematicians he respected. What was galling for Galois was that his manuscript was not even listed as an official contest entry. Indeed, when he asked to have his paper returned, it could not be found. This turned out to be simple bad luck. The Permanent Secretary of the Academy, Joseph Fourier, had served on the jury for the Grand Prize, and had taken Galois’s manuscript home with him to read. Unfortunately, he died in mid-May; Galois’s manuscript was lost somewhere in the shuffle of his papers, and it never resurfaced.&lt;/p&gt;
&lt;p&gt;Galois already had a sizable chip on one shoulder, and was fast developing one on the other as well. He was increasingly convinced that the Academy was deliberately shunning him. Perhaps, he thought, they were too incompetent to understand his dramatically forward-thinking mathematical ideas &lt;i&gt;and&lt;/i&gt; too stodgy to approve of his dramatically forward-thinking political convictions. Galois’s resentment can only have been compounded when, in late July 1830, he took an exam on differential and integral calculus and placed only fourth out of eight students⁠—a shockingly low rank for someone who was having papers published in the same journal as Cauchy. On top of it all, he was still irritated at having twice been denied the chance to study at the Polytechnique, both for the quality of its mathematics instruction and for its opportunities in the way of anti-monarchist political activism. The second of these was about to be on full display as the tectonic plates of French politics shifted in the summer of 1830.&lt;/p&gt;
&lt;figure data-embiggen="true"&gt;&lt;p&gt;&lt;img title="King Charles X of France" alt="King Charles X of France" data-lazy-load-src="https://damn-8791.kxcdn.com/wp-content/uploads/2020/03/Carlos_X_de_Francia_François_Gérard-scaled.jpg" data-height-ratio="1.4342629482072" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAMAAAAoyzS7AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAAZQTFRFgYGBAAAAqeg2zgAAAAxJREFUeNpiYAAIMAAAAgABT21Z4QAAAABJRU5ErkJggg=="&gt;&lt;/p&gt;&lt;figcaption&gt;King Charles X of France&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;King Charles X, to put it mildly, was extremely conservative. The ministers he chose were even more so. All of them remained traumatised by the French Revolution of 1789, which had resulted in the mass decapitation of their peers⁠—including more than a few members of Charles’s family. As a result, they were dedicated to doing away with those ridiculous ideas of liberty, equality, and fraternity that the revolution had propagated. &lt;/p&gt;
&lt;p&gt;When the results of an election in the summer of 1830 favoured the liberal left, the government’s ossified leaders retaliated with a particularly boneheaded decision. A series of decrees dissolved the newly elected legislature before it had even met, reduced the assembly’s size by 170 seats, drastically curtailed voting rights in favour of the wealthy, censored opposition publications, and called for a do-over election in September. The government must have expected that the liberals would be unhappy, but as the prime minister reported that he received regular visitations from the Virgin Mary and she had told him everything would be fine, they went ahead anyway. What they didn’t take into account was that essentially abolishing the printing industry would also make the typographers unhappy. With their livelihoods gone, they spilled into the streets, quickly followed by their working-class peers, and then the furious middle class.&lt;/p&gt;
&lt;p&gt;Riots became the lightning-speed July Revolution, which quickly became mythologised as the &lt;i&gt;Trois Glorieuses&lt;/i&gt;, the “Three Glorious Days”, where all classes had united to throw out a tyrannous regime. Members of the democratically organised National Guard⁠—which had been founded during the Revolution but that Charles had abolished⁠—pulled out their old uniforms from the cupboard and spontaneously reformed the militia. They came to be known as the heroes of the hour⁠—along with the students of the Polytechnique, who also jumped into the fray.&lt;/p&gt;
&lt;p&gt;Their counterparts at the École préparatoire, on the other hand, were shut out. Or, more precisely, shut in. As the battle raged on the streets of Paris, the school’s administrators locked the doors to keep their students from taking part. The school’s new principal, Joseph-Daniel Guigniault, twice threatened to call in the military to keep order among his pupils. (This might not have accomplished anything. The royalist army was a bit preoccupied, trying to control the streets while upper-storey inhabitants of buildings showered them with furniture, including the occasional piano.) Guigniault made matters worse by uttering condescending comments about the revolutionaries. As it was, he could at least claim that he kept his students safe. The only one of them who seems to have been at any risk of injury during the Trois Glorieuses was Galois, who by most reports was so eager to get involved with the rioting that he tried to climb over the schoolyard wall.&lt;/p&gt;
&lt;p&gt;His participation was unnecessary. Charles X faced the facts and went off into exile, while France proclaimed a new constitutional monarchy under a new king, Louis-Philippe. The National Guard became a key part of the imagery surrounding the change, their blue-white-red uniforms matching the newly restored tricolour flag flapping everywhere. &lt;/p&gt;
&lt;figure data-embiggen="true"&gt;&lt;p&gt;&lt;img title="Prise de l'Hôtel de ville : le Pont d'Arcole by Amédée Bourgeois" alt="Prise de l'Hôtel de ville : le Pont d'Arcole by Amédée Bourgeois" data-lazy-load-src="https://damn-8791.kxcdn.com/wp-content/uploads/2020/03/Prise_de_lHôtel_de_ville_-_le_Pont_dArcole-scaled.jpg" data-height-ratio="0.73823529411765" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAMAAAAoyzS7AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAAZQTFRFgYGBAAAAqeg2zgAAAAxJREFUeNpiYAAIMAAAAgABT21Z4QAAAABJRU5ErkJggg=="&gt;&lt;/p&gt;&lt;figcaption&gt;&lt;i&gt;Prise de l'Hôtel de ville : le Pont d'Arcole&lt;/i&gt; by Amédée Bourgeois&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;The new regime, however, did not please everyone: it was a compromise that did not go far enough for the left and was anathema to the right. Paris, which set the tone for the whole country, remained a cramped medieval city with an underpaid, underfed working class. There were ongoing flare-ups of both rioting and disease. For Galois, the revolution also meant the loss of his best source of support at the Academy of Sciences: Cauchy, who was a right-wing Catholic and diehard supporter of the old monarchy, had left the country rather than take the required oath of loyalty to the new king. &lt;/p&gt;
&lt;p&gt;Galois’s own path, naturally, was diametrically opposed. He joined the newly founded &lt;i&gt;Société des amis du peuple&lt;/i&gt;, a republican group so radical that it was banned altogether in October 1830, after which it became a (theoretically) secret society. While the Polytechnique was being laurelled for its active liberalism, Galois was stuck behind locked doors with its despised principal Guigniault⁠—his best chance at fighting the Establishment being stifled by the Establishment. To Galois, the principal’s behaviour was infuriatingly hypocritical. At first, Guigniault had mocked and dismissed the revolutionaries⁠—only to drape himself ostentatiously in the tricolour of those same revolutionaries at the battle’s end. Guigniault also made the empty gesture of changing the name of the school itself back to its Napoleon-era name of &lt;i&gt;École normale&lt;/i&gt;, while at the same time continuing to insist that “good students should not be interested in politics”.&lt;/p&gt;
&lt;p&gt;Galois exchanged an increasingly testy series of letters with school administrators, criticising Guigniault’s response to the riots and revolution. When Galois published an “anonymous” letter in a prominent education-focused journal, spilling the matter into the press and thus the public, Guigniault simply expelled him. &lt;/p&gt;
&lt;p&gt;With school off the table, nothing prevented Galois from getting in on the glory of the National Guard. The young mathematician enlisted in one of the Guard’s artillery batteries, one known to be a hotbed of republican sentiment. A good chance lay ahead for the republicans to demonstrate their continued displeasure with current affairs. Several of Charles X’s ministers were on trial, and the consensus on the left was that anything less than death sentences would be tantamount to acquittal⁠—and grounds for another uprising.&lt;/p&gt;
&lt;p&gt;Wearing a newly purchased uniform, Galois would have been among the artillerymen stationed at the Louvre on 21 December 1830 when the sentences were announced. The ministers were sentenced to life in prison rather than death. The situation was precarious for days, and several members of the artillery were arrested for seditious behaviour. King Louis-Philippe, no fool, realised that leaving a bunch of radical republicans in charge of cannons might not be the wisest course. On 31 December, he dissolved the National Guard’s artillery units, outlawing the wearing of their uniforms. Galois’s military career had lasted, at most, three weeks.&lt;/p&gt;
&lt;p&gt;Untethered from all institutions, Galois floundered, but the Academy of Sciences extended an olive branch. One of its most respected mathematicians, Siméon Denis Poisson⁠—who had shared journal space with both Galois and Cauchy just a few months earlier⁠—requested that Galois send them a new paper. Galois wrote a new manuscript⁠—probably a re-creation of his lost submission to the Grand Prize⁠—and submitted it on 17 January 1831. After two months passed with no word, Galois followed up with a snide letter to the President of the Academy, suggesting there was something fishy in Poisson’s delay. Pointedly rehashing his experience, Galois topped it off with a direct accusation of ulterior motives:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;“…the examining committee decided &lt;i&gt;a priori&lt;/i&gt; that I could not have resolved this problem, firstly because my name was Galois, and moreover because I was a student. And the committee misplaced my paper. And I was told that my paper was misplaced. This lesson should have sufficed me […] to this day, my research has met more or less the same fate […] Will the analogy be pursued to the end? Please […] invite Messrs. Lacroix and Poisson to declare whether they have &lt;u&gt;misplaced&lt;/u&gt; my paper, or whether they intend to report on it to the Academy.”&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Needless to say, this was not a good strategy for building a career. Other mathematicians were left shaking their heads at Galois’s behaviour. Rumours flew that he was losing his mind.&lt;/p&gt;
&lt;p&gt;On 16 April 1831, nineteen of Galois’s fellow republicans were acquitted of sedition charges. Overjoyed, their allies carried them home in triumph, and quickly decided to hold a celebratory banquet in their honour. There was no right to free association in France at the time, but even the most dictatorial regimes knew better than to get between the French and a good meal. A banquet was therefore one of very few legal ways of gathering a large group of like-minded people to exchange ideas (or to collectively decide to defenestrate a bust of the king, or both). The venue was a restaurant, but not one known for its cuisine. Rather, it was the largest space in Paris that a group could book easily. A year earlier, it had hosted a liberal banquet that had laid the groundwork for the end of Charles X’s rule. Now Galois looked forward to a similar event⁠—and in preparation, he visited a local knife-maker and very eagerly ordered a ‘folding dagger’.&lt;/p&gt;
&lt;figure data-embiggen="true"&gt;&lt;p&gt;&lt;img title="Alexandre Dumas ca. 1831" alt="Alexandre Dumas ca. 1831" data-lazy-load-src="https://damn-8791.kxcdn.com/wp-content/uploads/2020/03/dumas-cropped.jpg" data-height-ratio="1.3846153846154" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAMAAAAoyzS7AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAAZQTFRFgYGBAAAAqeg2zgAAAAxJREFUeNpiYAAIMAAAAgABT21Z4QAAAABJRU5ErkJggg=="&gt;&lt;/p&gt;&lt;figcaption&gt;Alexandre Dumas ca. 1831&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;One of the other revolutionaries in attendance at the banquet was Alexandre Dumas. The future creator of the Three Musketeers and the Count of Monte Cristo, Dumas was already a renowned playwright; only a week earlier, one of his plays had become the theatrical sensation of the year. He had also been an artilleryman in the same National Guard battery as Galois and many of the nineteen acquitted republicans. Recalling the event much later in his &lt;i&gt;Memoirs&lt;/i&gt;, Dumas wrote that “it would have been difficult to find two hundred people more hostile to the government in all of Paris”. Even so, Galois eventually managed to find a way to stand out. As the number of emptied champagne bottles grew and the banqueters began to forego their promise not to make any unapproved toasts, Dumas suddenly became aware that&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;“[a]n extremely animated scene was taking place fifteen or twenty places down from me. A young man, holding his raised glass and an open dagger in the same hand, was striving to make himself heard. It was Évariste Galois, […] one of the most ardent republicans.”&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Ardent and, it must be said, drunk. Galois later admitted to a friend that if he’d been sober, he would never have behaved as he did. Dumas could not hear over the immediate roar of the crowd, but he did work out that the words “Louis-Philippe” had been uttered, that Galois’s open dagger was unambiguous, and that there were limits to his own radicalism. Catching each other’s eye, Dumas and his neighbour hopped out a window and skedaddled⁠—which, from a banquet on the ground floor, was admittedly easier than it might have been.&lt;/p&gt;
&lt;p&gt;What Galois had done was to openly call for regicide⁠—a crime so unthinkable that the criminal code classified it as being as unnatural as parricide. Dumas knew well that plays could be banned simply for alluding to it. This action was too radical even for the radicals: republicans did not want their movement reminding the nation of the constant guillotining that had marked the 1789 Revolution. But Galois’s fiery outburst was soon all over the newspapers, causing considerable embarrassment. The morning after the banquet, Galois was arrested at his mother’s house.&lt;/p&gt;
&lt;p&gt;Galois’s supporters latched onto the fact that the threat had technically been conditional⁠—“To Louis-Philippe, should he betray [his oath to uphold the constitution]”⁠—with the crowd’s noise burying the second half. Astonishingly, at his own trial on 15 June 1831, Galois did not take advantage of this escape rope. Instead, he doubled down in every possible way. Not only did he &lt;i&gt;not&lt;/i&gt; blame drunkenness, he insisted that he had &lt;i&gt;intended&lt;/i&gt; what he’d said, conditionals be damned. In open court, with a gobsmacked audience looking on, Galois confirmed that it &lt;i&gt;had&lt;/i&gt; been an assassination threat, that he had &lt;i&gt;not&lt;/i&gt; just been expressing his personal opinion, and that he &lt;i&gt;was&lt;/i&gt; attempting to goad others into making attempts on the king’s life. Indeed, Galois went on, in his opinion Louis-Philippe probably already &lt;i&gt;had&lt;/i&gt; betrayed his oath. Around this point, the judge cut the interrogation short⁠—either to keep a lid on Galois’s outrageous sentiments, or simply to stop him from digging himself even more deeply into a hole.&lt;/p&gt;
&lt;figure data-embiggen="true"&gt;&lt;p&gt;&lt;img title="King Louis-Philippe I" alt="King Louis-Philippe I" data-lazy-load-src="https://damn-8791.kxcdn.com/wp-content/uploads/2020/03/Louis_Philippe_I.jpg" data-height-ratio="1.5450643776824" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAMAAAAoyzS7AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAAZQTFRFgYGBAAAAqeg2zgAAAAxJREFUeNpiYAAIMAAAAgABT21Z4QAAAABJRU5ErkJggg=="&gt;&lt;/p&gt;&lt;figcaption&gt;King Louis-Philippe I&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Surprisingly, Galois was acquitted. Dumas’s explanation was that the jurors either agreed with Galois, or simply thought he was beyond sanity. Most other sources agree that the judge and jury took pity on him because he was so young⁠—still only 19. &lt;/p&gt;
&lt;p&gt;Against the odds, Galois had slipped out of the political noose. Not only that, but the publicity dislodged the apparent impasse at the Academy of Sciences. On the day his trial started, the newspaper &lt;i&gt;Le Globe&lt;/i&gt; published a lengthy letter detailing Galois’s experiences with the Academy. Specifically, the publication argued that Poisson⁠—who had requested the new paper from Galois in the first place⁠—had really dropped the ball. Perhaps encouraged to hurry, Poisson and his co-referee submitted their report a few weeks after Galois’s acquittal, on 4 July 1831, then presented it publicly to the Academy a week later.&lt;/p&gt;
&lt;p&gt;A months-long wait for a response to a manuscript was not actually anything unusual. The Academy was swamped with submissions. Mathematical historian Caroline Ehrhardt reports that two-thirds of the papers submitted to the Academy never received a report at all⁠—and of those that did, few got more than a few terse sentences. Galois’s complaint of neglect in March was baseless. Fortunately, the Academy did not dismiss him out-of-hand for his impudence⁠—which is just as well, for this manuscript contained what astrophysicist/author Mario Livio later called “one of the most imaginative breakthroughs in the history of algebra”⁠—the core of his invention of group theory.&lt;/p&gt;
&lt;p&gt;To their credit, the reviewers produced a lengthy, thorough, and detailed report on Galois’s manuscript. It was clear that they saw and appreciated the links between Galois’s ideas and Abel’s. But their evaluation was not what Galois had hoped for: overall, Poisson and Lacroix confessed that they were baffled. The math itself was not the problem; rather, they were not always able to follow the argumentation.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;“[…] we have made every effort to understand Mr. Galois’s demonstration. His reasoning is neither clear enough not developed enough for us to have been able to judge its exactness […] The author announces that this proposition […] is part of a general theory liable of many other applications. It is often the case that the different parts of a theory, by mutually illuminating one another, are easier to grasp when taken together rather than in isolation. We can therefore wait for the author to have published his work in its entirety before coming to a definitive opinion […]”&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Several contextual factors worked against Galois. He still did not have training in the conventions of writing out mathematical discoveries⁠—a skill he could have picked up at the Polytechnique. Added to this, his work was pure mathematics; this would have resonated with the absent Cauchy, but for the other members of the Academy at the time, what was important was applied mathematics. Plus, algebra was still thought of as a tool rather than a subfield of mathematics in and of itself; Poisson and Lacroix would have been judging Galois’s manuscript through the lens of mathematical analysis⁠—what we now call differential calculus⁠—and looking for its practical potential. Galois’s ideas likely struck them as a pointless excursion into &lt;i&gt;terra incognita&lt;/i&gt;. With the benefit of hindsight, Mario Livio slams the reviewers for reacting so lukewarmly to Galois’s manuscript. However, in modern academic parlance, the referees’ report is much more “revise and resubmit” than it is an outright rejection. More than one modern mathematician has admitted they would likely have made the same decision in response to the manuscript as it was.&lt;/p&gt;
&lt;p&gt;None of this counted for Galois. Furious, he became convinced once and for all that the Academy was out to get him. And as usual, mathematical disappointment dovetailed with political trouble. Only days later, on 14 July 1831, the police set out very early for Galois’s home. Knowing him to be a troublemaker, they were hoping to nab him in a pre-emptive roundup of republican rowdies known to have plans for commemorating the fall of the Bastille. No Évariste Galois was found⁠—because he had already left home that morning. The police eventually caught up with him and his friend Ernest Duchâtelet. The young men were going to an illegal march, with Galois illegally wearing his National Guard uniform⁠—not to mention carrying a rifle, a couple of pistols, and a dagger. Placed under arrest, the pair complied calmly enough that the officers didn’t think to confiscate their prisoners’ rifles until they were halfway to the police station.&lt;/p&gt;
&lt;figure data-embiggen="true"&gt;&lt;p&gt;&lt;img title="Sainte-Pélagie prison" alt="Sainte-Pélagie prison" data-lazy-load-src="https://damn-8791.kxcdn.com/wp-content/uploads/2020/03/Prison_de_Sainte-Pélagie_-_Vue_Extérieure-scaled.jpg" data-height-ratio="0.80294117647059" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAMAAAAoyzS7AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAAZQTFRFgYGBAAAAqeg2zgAAAAxJREFUeNpiYAAIMAAAAgABT21Z4QAAAABJRU5ErkJggg=="&gt;&lt;/p&gt;&lt;figcaption&gt;Sainte-Pélagie prison&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Galois was thrown in jail to await trial, but his stay in Sainte-Pélagie prison got off to an eventful start. As the anniversary of the July Revolution approached, the republican prisoners got more and more excited. On 28 July 1831, they happily spent the day yelling anti-royalist slogans, insulting passers-by, and throwing things out of windows. Towards evening, a loaf of bread hit a woman on the head so hard that she was left bruised and bleeding (a testament to the sort of food the inmates were given). Half an hour later, one of Galois’s cellmates began to caterwaul &lt;i&gt;La Marseillaise&lt;/i&gt; as he undressed for bed in front of the window. Outside, an exasperated local citizen sick of the ruckus let off a round of buckshot that hit the man clear in the face. Inside, panic erupted. The guards on the scene managed to regain control only by throwing three of the inmates⁠—including both Galois and Monsieur &lt;i&gt;La Marseillaise&lt;/i&gt;⁠—into the dungeon. This action itself nearly caused a riot, and rumours flew that the shot had been fired by a prison employee at the governor’s order.&lt;/p&gt;
&lt;p&gt;Galois was only in the dungeon for three days, but it was three months before he came to trial. This time around, Galois backed down and feebly claimed that he hadn’t realised that wearing his uniform was illegal. The judge was unconvinced. Probably feeling that Galois’s previous acquittal had failed to teach him a much-needed lesson, he sentenced the young man to a further six months in jail. This sentence was disproportionately long, especially considering that Duchâtelet⁠—who had sketched a guillotine on his cell wall and added verses that threatened Louis-Philippe⁠—would have to do only three.&lt;/p&gt;
&lt;p&gt;Imprisonment did not suit Galois. Still, the dampness and discipline of Sainte-Pélagie was probably more comfortable than boarding school had been. Prisoners could receive visitors every Thursday and Sunday, chat among themselves, walk about. Nevertheless, Galois soon fell into despair. Some of his co-inmates began referring to him as “an old man of twenty”. His sister Nathalie, who visited constantly, thought the same, finding him as hollow-eyed as someone 30 years older. Galois had already proven at the banquet in May that he could drink beyond his limits⁠—an ability that he now had cause to demonstrate repeatedly. Fellow inmate François-Vincent Raspail, the president of the banned &lt;i&gt;Société des amis du peuple&lt;/i&gt;, describes how prisoners taunted Galois by calling him a water-drinker. In response, Galois began downing entire bottles of brandy in one go, with predictable consequences. His mental state deteriorated, reopening his grief over the death of his father. He may even have attempted suicide, prevented only by Raspail’s intervention.&lt;/p&gt;
&lt;p&gt;But Galois also spent a great deal of time in prison pacing and doing mathematics in his head. He even worked out a plan to bypass the Academy and publish two manuscripts privately with the help of his friend Auguste Chevalier. One of these papers⁠—”On the Conditions for Solubility of Equations by Radicals”⁠—was a revision of the paper that the Academy had balked at; the other was a new work on “Primitive Equations Solvable by Radicals”, which Galois (now particularly adept at anything having to do with radicals) seems to have undertaken starting in the summer of 1830. Before he got out of prison, he had put considerable energy into drafting a preface to the two works. This was a five-page manifesto dripping with vitriol and heavy-handed sarcasm, along with self-congratulatory sentiments about his own independence from the Academy and “how lowly I esteem my adversaries”. Among other things, he was still stewing over his lost paper.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;“I must mention how manuscripts most often end up lost in the folders of Messrs. the members of the Institute, though truly I can’t conceive of such carelessness on the part of men who have the death of Abel on their conscience.”&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;He snarkily outlines how he could have clogged his manuscript with useless details to make it easier to understand and appease his reviewers’ request for additional information. He witheringly suggests that the examiners in charge of testing candidates for the Polytechnique deserve to be members of the Academy, given that “they certainly have no place in posterity”. He presents himself as a martyr figure, “knowingly exposing myself to the mockery of dunces”, and even obliquely lambastes the Academy for favouring applied over pure mathematics. Clearly, prison had done nothing to temper either Galois’s simmering rage or his self-esteem⁠—nor, for that matter, his politics.&lt;/p&gt;
&lt;p&gt;In spite of this, Galois was released from prison in March, before he had completed either his manuscripts or his sentence. The authorities sent him to a small halfway house run by a man named Denis Faultrier to recover his broken health. The transfer dramatically changed things. Back in prison, Galois had told Raspail that the one thing he truly lacked was someone he could love “with his heart alone”. Now that lack was about to be rectified⁠—but it would not end well.&lt;/p&gt;
&lt;figure data-embiggen="true"&gt;&lt;p&gt;&lt;img title="'Évariste' superimposed on 'Stéphanie' at top left, and E and S monograms bottom left" alt="'Évariste' superimposed on 'Stéphanie' at top left, and E and S monograms bottom left" data-lazy-load-src="https://damn-8791.kxcdn.com/wp-content/uploads/2020/03/evariste-stephanie.jpg" data-height-ratio="0.48823529411765" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAMAAAAoyzS7AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAAZQTFRFgYGBAAAAqeg2zgAAAAxJREFUeNpiYAAIMAAAAgABT21Z4QAAAABJRU5ErkJggg=="&gt;&lt;/p&gt;&lt;figcaption&gt;'Évariste' superimposed on 'Stéphanie' at top left, and E and S monograms bottom left&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;After his transfer, Galois became acquainted with a woman named Stéphanie, and reacted to her rather as he had to his first encounter with mathematics. It turned out that Galois fell in love as wildly as he did everything else. Even as he went over old papers, presumably still working on his pair of manuscripts, he doodled Stéphanie’s name in the margins. On one page, he superimposed the names “Évariste” and “Stéphanie”; on another, he sketched out some rather elegant monograms combining the initials “E” and “S”. Clearly, Galois had it bad.&lt;/p&gt;
&lt;p&gt;The object of his fixation was almost certainly Stéphanie Félicité Poterin du Motel, a cousin of Denis Faultrier’s. Nearly 20 years old, she did not seem to reciprocate Galois’s affections. On 14 May 1832, she wrote to him:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;“Let us please make an end of this matter. I do not have sufficient wit to follow a correspondence of this type, but I will try to have enough to converse with you as I did before anything happened… no longer think about things that could not exist and that never will exist.”&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Another excerpt was even more crushing:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;“…be persuaded, Sir, it would doubtless never have been more; you are assuming wrongly and your regrets are ill-founded.”&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;She ruled out even the possibility of a friendship, telling Galois that he was wrong to believe that men and women could ever be true friends.&lt;/p&gt;
&lt;p&gt;A heartbroken Galois swirled downwards into an emotional whirlpool. His friend Auguste Chevalier grew alarmed, thinking that Galois was revelling in his own misery; Chevalier accused him of “being drunk on the putrefied muck of a rotten world infecting [his] heart, [his] mind, and [his] hands.” In a consoling letter, Chevalier apparently urged him, not for the first time, to seek refuge in religion. On 25 May 1832, Galois wrote back.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;“[H]ow can one destroy the traces of emotions as violent as those I have passed through? How can one console oneself for having exhausted in one month the greatest source of bliss available to man, to have exhausted it without bliss, without hope, certain one has drained it dry for life? […] for your part, you feel obliged to do your best to convert me. But it is my duty to warn you, as I’ve done a hundred times, that your efforts are in vain. […] I’m disenchanted with everything, even the love of glory.”&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Still, this all-encompassing existential loathing did not stop Galois from looking forward to reuniting with Chevalier in a few days. But the trip never happened. What actually happened in the next four days is unknown, but the night of the 29th found Galois desperately dashing off additional letters instead of sleeping. One was addressed to a pair of his republican friends:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;“I have been challenged [to a duel] by two patriots…it was impossible for me to refuse.”&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Officially, duelling was illegal at the time, but Galois was right. Like most of the rest of Europe, plus the New World (hello Mr. Hamilton, Mr. Burr), France was in the grip of a duelling frenzy. If anything, the historical reality makes the way the Three Musketeers duel at the drop of a hankie seem downright restrained. More than 200 people died in duels in France between 1826 and 1834 alone. Alexandre Dumas knew this firsthand: he had won his first duel when he was 22 (though his trousers had fallen down in the process). Politicians blew out the brains of other politicians, journalists from opposing sides of the political divide killed each other with pistol or sword, authors and literary critics could be found on the fighting fields, young men took aim at each other over women, professional killers went around challenging people for jostling them in the street. In Bordeaux, a duelling club was founded whose members swore to only ever fight to the death: the association lasted three years, until a newcomer systematically killed all twelve surviving members. In 1837, two law professors took up swords over whether a certain passage in the 6th-century &lt;i&gt;Digest&lt;/i&gt; of Justinian should end with a colon or a semicolon. (Professor Semicolon won by sticking three inches of steel into Professor Colon’s arm.) The poet Lamartine, who ended up in a duel in 1825 after one of his poems included a mildly uncomplimentary line about Italy, summed up the ethos by remarking that “It takes more courage to refuse one duel than to fight ten”.&lt;/p&gt;
&lt;p&gt;In this atmosphere, there was never any question as to whether Galois would accept the challenge: any young man refusing would forever be branded a coward, and a fellow of above-average hotheadedness was unlikely to consider the possibility anyway. But Galois did not think he was fighting a duel for a particularly glorious cause. In a letter he addressed to “all republicans”, he wrote:&lt;/p&gt;
&lt;figure data-embiggen="true"&gt;&lt;p&gt;&lt;img title="A page from Galois's memoir/article, with &amp;quot;I don't have time&amp;quot; scrawled in the margin" alt="A page from Galois's memoir/article, with &amp;quot;I don't have time&amp;quot; scrawled in the margin" data-lazy-load-src="https://damn-8791.kxcdn.com/wp-content/uploads/2020/03/galois-letter.jpg" data-height-ratio="1.44" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAMAAAAoyzS7AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAAZQTFRFgYGBAAAAqeg2zgAAAAxJREFUeNpiYAAIMAAAAgABT21Z4QAAAABJRU5ErkJggg=="&gt;&lt;/p&gt;&lt;figcaption&gt;A page from Galois's memoir/article, with "I don't have time" scrawled in the margin&lt;/figcaption&gt;&lt;/figure&gt;
&lt;blockquote&gt;&lt;p&gt;“I die the victim of a shameless flirt and her two dupes. My life is being extinguished in a miserable bit of gossip. Oh! Why die for something so small⁠—die for something so contemptible!”&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;He closed by describing himself in Latin: “&lt;i&gt;Nitens lux, horrenda procella, tenebris æternis involuta&lt;/i&gt;”, which translates to “a brilliant light, swallowed by an awful tempest, wrapped in eternal darkness.” Id est, the turducken of melodrama.&lt;/p&gt;
&lt;p&gt;As Samuel Johnson said, the certainty of being hanged in the morning concentrates the mind wonderfully. The possibility of being shot did precisely the same to Galois. A few days earlier, he had been doubting his ability to ever do math again; now he began a letter to Auguste Chevalier. “My dear Friend,” he wrote, “I’ve done several new things in analysis.” Then, in small, neat handwriting, over seven pages, he frantically set about getting down as many of his original ideas as he could. These provided enough material, Galois claimed, for three manuscripts. The first was the one the Academy had shrugged at; Galois insisted he stood by it, with only a small number of corrections. He then sketched out the most important parts of the other two manuscripts that he envisioned. Only at the end of the letter did some sense of finality come into play:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;“You know, my dear Auguste, that these are not the only topics that I have explored […] But I don’t have time and my ideas are not yet very well developed in this immense area.”&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;He concluded by asking Chevalier to publish the entire text of the letter itself in the &lt;i&gt;Revue encyclopédique&lt;/i&gt;, and to publicly ask mathematicians Carl Gustav Jacob Jacobi or Carl Friedrich Gauss, or both, “to give their opinion, not on the truth, but on the importance of these theorems”. He also defended himself against the risk of again being accused of cursory mathematical argumentation:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;“In my life, I’ve often taken the risk of advancing propositions about which I wasn’t certain. But everything I’ve written here has been in my mind for almost a year, and it is too much in my interest not to make mistakes for anyone to suspect that I’ve here formulated theorems for which I don’t have complete demonstrations.”&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;And yet, on the night of the 29th, Galois also revisited the copy of the manuscript that the Academy had returned to him. At one point, he scrawled in a margin, “There is something to be completed in this proof. I don’t have time”⁠—a poignant admission that reviewers’  calls for greater clarity had not been entirely undue.&lt;/p&gt;
&lt;p&gt;At the scheduled time, on the outskirts of Paris, with a handful of witnesses, Galois and his challenger chose their pistols. It is possible that only one of them was loaded⁠—an uncommon but not unknown option that added an element of Russian roulette to the mix. The two men walked to twenty-five paces, turned to face one another, and shot. Hit in the abdomen, Galois dropped to the ground. Someone⁠—possibly an onlooker, possibly a passerby⁠—transported him to the nearby Cochin Hospital.&lt;/p&gt;
&lt;p&gt;Conscious, but badly wounded, Galois lay in a room with four or five other patients. The only family member to have heard about the duel was his younger brother Alfred, who raced to the hospital and soon became despondent. Galois’s wound was not only severe, but also oddly positioned. It was as if he had not tried to minimise his chances of being shot; he might not even have turned to the side as he faced his foe as was customary. The injury was extensive, and already infected. The hospital surgeon and both brothers all knew that there was little to be done. Alfred was in tears, but Galois stoically instructed his brother, “Don’t cry. I need all of my courage to die at the age of twenty.” He characteristically rejected an attempt to have a priest attend to him, then, at 10:00 a.m. on 31 May 1832, Évariste Galois died in his brother’s arms.&lt;/p&gt;
&lt;figure data-embiggen="true"&gt;&lt;p&gt;&lt;img title="Pistol duel in the XIX century by Bauce and Rouget" alt="Pistol duel in the XIX century by Bauce and Rouget" data-lazy-load-src="https://damn-8791.kxcdn.com/wp-content/uploads/2020/03/Duel_pistolet.jpg" data-height-ratio="0.76470588235294" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAMAAAAoyzS7AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAAZQTFRFgYGBAAAAqeg2zgAAAAxJREFUeNpiYAAIMAAAAgABT21Z4QAAAABJRU5ErkJggg=="&gt;&lt;/p&gt;&lt;figcaption&gt;&lt;i&gt;Pistol duel in the XIX century&lt;/i&gt; by Bauce and Rouget&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Legend has long held that a large crowd attended Galois’s funeral that Saturday. The Prefect of Police claimed much later in his memoirs that some two to three thousand people were there. However, on the day itself, the same man’s report to the Minister of the Interior stated that the actual number was around 150, mostly other republicans. They set off at 11:30 a.m. on 2 June to accompany Évariste Galois from Cochin Hospital to the Montparnasse graveyard. After some good old fiery political speeches, Galois’s body became the 18th of 21 to be placed in a common grave⁠—after which the attendees passed the hat around to pay for the funeral costs.&lt;/p&gt;
&lt;p&gt;Perhaps more than 150 had &lt;i&gt;intended&lt;/i&gt; to be there. Paris was (again) on the verge of insurrection, and the republicans were looking for an excuse to gather and start a riot. Galois’s funeral might have fit the bill perfectly⁠—except that the day before saw the death of General Jean Maximilien Lamarque. Lamarque was a prominent advocate for the wretched, miserable poor⁠—who, despite what certain modern stage productions suggest, were not inclined to be tuneful about their state. The republicans quickly realised that Lamarque’s funeral would be the higher-profile event, and rescheduled the rebellion. Thus, Évariste Galois was once again shoved aside and left out, even in death. His duel deprived him by just a few days of the opportunity to die a glorious republican martyr in the ill-fated 1832 June Rebellion. His friends of the Société des amis du peuple would appear thinly disguised in one of the best-selling novels of all time, but there are no mathematicians among the students in Victor Hugo’s &lt;i&gt;Les Misérables&lt;/i&gt;. Adding insult to fatal injury, among those who fought heroically on the June barricades, and survived, was a certain Étienne-François Pecheux d’Herbenville⁠—who most likely fired the bullet that prevented Galois from ever getting to join a revolution.&lt;/p&gt;
&lt;p&gt;The identity of Galois’s opponent has long been one of the many mysteries surrounding the duel. Alexandre Dumas specifically named him as d’Herbenville, but Dumas is not infallible, and other evidence seemed to suggest otherwise. Two days after the duel, a newspaper from the town of Lyon, &lt;i&gt;Le Précurseur&lt;/i&gt;, reported on the duel, describing the victor as “one of [Galois’s] old friends, like him a very young man, like him a member of the Société des amis du peuple, and who had … also been a figure in a political trial”. The article attributed the duel to a romantic argument, and identified Galois’s foe by the initials “L.D.” &lt;/p&gt;
&lt;p&gt;The &lt;i&gt;Précurseur&lt;/i&gt; article is full of small inaccuracies, but even taking these into account, it is tricky to make their depiction match Dumas’s identification. On the one hand, d’Herbenville⁠—a charming young man who liked to wrap his cartridges in pink silk paper⁠—was indeed a republican. In fact, he was one of the nineteen republicans whose acquittal was celebrated with the notorious banquet that ended with Galois’s drunken oath and Dumas’s autodefenestration. But beyond this there was no evidence of any connection between the two, let alone of old friendship. Given that Galois did not have many friends, other candidates have been sought. Mario Livio, among others, has argued for Galois’s friend and fellow prisoner Ernest Duchâtelet, who has the advantage of both being a friend and having at least one of the right initials. &lt;/p&gt;
&lt;p&gt;Recent discoveries, however, make it almost certain that Dumas was right after all. One key piece of evidence is a copy of France’s 1791 revolutionary constitution. Among its owners was a Swiss medical student named Larguier, who wrote on it, “This manuscript was given to me by Gallois killed in a duel by Pécheux d’Herbinville”. Meanwhile, Olivier Courcelle’s research has discovered that d’Herbenville’s names were rarely spelt the same way twice in the press. Among the variations were forms such as “Lepescheux” and “Dherbinville”⁠—these would give us the “L. D.” reported by &lt;i&gt;Le Précurseur&lt;/i&gt;. Most tellingly of all, recent close analysis of Galois’s manuscripts has shown that, though crossed out, d’Herbenville’s name appears in Galois’s papers, proving that the two were indeed connected somehow. How, and as of when, is unknown, but Courcelle has discovered that d’Herbenville took classes at Louis-le-Grand at the same time that Galois resided at the school. Moreover, d’Herbenville studied mathematics at school before turning his attention elsewhere, and eventually became an engineer. In d’Herbenville, Galois would have found a radical republican he could talk shop with.&lt;/p&gt;
&lt;p&gt;But knowing the identity of Galois’s killer does not solve the greater mystery of why the duel was fought at all, nor explain its oddities. The confusion over who took Galois to the hospital suggests that he went into the duel without any witnesses of his own⁠—a baffling choice given that one of the witnesses’ duties was to ensure prompt medical care for the wounded. Between this and Galois’s uncommon injury, several commentators have suggested that Galois went into the duel intending to die. One theory even holds that he was sacrificing himself for his political cause. But this is difficult to reconcile with his open letter to “all republicans”, in which he begs “my friends the patriots not to reproach me for dying for something other than the country”. Instead, he attributes the death he foresees for himself to “a miserable bit of gossip”. Moreover, one of Galois’s last-minute letters suggests that the challenger(s) “charged me &lt;i&gt;on my honour&lt;/i&gt; not to inform any patriot” (italics in original). Galois’s devastated brother Alfred, meanwhile, thought Galois had been shot by secret police agents acting on behalf of the king. This is profoundly unlikely. Even if Louis-Philippe’s regime had been prone to assassinating people⁠—which it does not appear to have been⁠—Galois was simply not important enough to warrant eliminating, particularly in such a convoluted manner.&lt;/p&gt;
&lt;figure data-embiggen="true"&gt;&lt;p&gt;&lt;img title="A French postage stamp commemorating Évariste Galois" alt="A French postage stamp commemorating Évariste Galois" data-lazy-load-src="https://damn-8791.kxcdn.com/wp-content/uploads/2020/03/galois-stamp.jpg" data-height-ratio="0.7" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAMAAAAoyzS7AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAAZQTFRFgYGBAAAAqeg2zgAAAAxJREFUeNpiYAAIMAAAAgABT21Z4QAAAABJRU5ErkJggg=="&gt;&lt;/p&gt;&lt;figcaption&gt;A French postage stamp commemorating Évariste Galois&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;More likely, it was simply a ‘matter of honour’⁠—and the generally accepted explanation is that the honour in question was Stéphanie du Motel’s. Most commentators identify the ‘shameless flirt’ of Galois’s letter as Stéphanie, though whether she deserved that appellation is entirely unknowable⁠—as is whether the challengers were in any way ‘dupes’. Quite possibly, Galois had simply importuned her so much that she had no option but to ask for assistance. Certainly, Galois indicates that he insulted his challengers, and did so to their faces: he wrote in his open letter that he “repent[s] having spoken a fateful truth to men who were so poorly prepared to hear it coolly”. With Galois’s temper, it seems unlikely that any of it was done coolly. As research continues into Galois’s papers and what he crossed out where, answers may yet come to light. Recent findings have confirmed that there was a police report about the duel; perhaps it will be found in an archive somewhere.&lt;/p&gt;
&lt;p&gt;Alfred Galois and Auguste Chevalier were left with the weighty task of doing justice to Évariste Galois’s mathematical legacy, and it took time. It was not until 1843 that Galois’s luck changed, when his work reached French mathematician (and member of the Academy) Joseph Liouville. As he worked through Galois’s papers, Liouville noted their brevity and relative opacity, but realised that what Galois had proposed years before was both mathematically rigorous and far ahead of its time. In 1846, Liouville published Galois’s “ingenious and profound” work in his own internationally renowned journal, and thus it reached the wider mathematical community at last. Within 15 years, what came to be known as &lt;i&gt;Galois theory&lt;/i&gt; was being taught in algebra classes. Historian Amir Alexander says that Galois “had become an iconic figure of the field, a revered martyr to mathematics”.&lt;/p&gt;
&lt;p&gt;It is a curious fact that what seems at first glance to be nothing but “pure” mathematics often later turns out to have important applied uses. While the Academy of Sciences could not see the practical side at the time, Galois’s new ways of approaching symmetries, permutations, and groups turned out to apply to, well, basically everything. Subtle symmetry appears to play a profound, central role in the laws of physics as we understand them. It applies just as well to the miniscule (particle physics) as to the humongous (cosmology), and is scattered throughout just about everything in nature that shows organised behaviour. One can only imagine what Galois might have been able to contribute with more than just a few years of research.&lt;/p&gt;
&lt;p&gt;The story of Évariste Galois⁠—a revolutionary in every sense⁠—has become something of a legend in the last 150 years, not least because of the dual figure he presents as mathematical visionary and political lightning-rod. Early obituaries all focused on him as a republican. As early as 1846, however, Liouville could dismiss Galois’s political activities as nothing more than “a pity”, and for several decades this was the common verdict. Neither of these is the full story. Galois’s mathematical thought and his political thinking are deeply intertwined. In one of his draft papers, an equation that cannot be broken down further leads him to write the word “Indivisible”, and beneath that, “Indivisibility of the republic”, followed on a new line by “Liberty, equality, fraternity, or death”. Among the scrawls on the same page are the words “Une femme” (“a woman”)⁠—and, deeply scrawled out and now visible only with specialised equipment, the name of Pecheux d’Herbenville.&lt;/p&gt;
&lt;p&gt;Galois closed his final mathematical statement with the bitter hope that after Jacobi and Gauss had given their opinion on the importance of his theorems, “there will be, I hope, some people who will find it to their advantage to decipher all this mess.”&lt;/p&gt;
&lt;p&gt;There were, and they did.&lt;/p&gt;
				

										
									&lt;/article&gt;&lt;/div&gt;&lt;a href="https://www.damninteresting.com/radical-solutions/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sun, 29 Mar 2020 16:28:51 UT
      </pubDate>
      <guid>
        https://www.damninteresting.com/radical-solutions/
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        http://morrick.me/archives/8840
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;
			&lt;p&gt;Every time I gather observations and thoughts for a piece on the iPad, I feel I keep returning to the same old insights I’ve had for years. I knew Apple would complicate the iPad’s user interface this way. That many people are happy with it doesn’t mean it’s inherently a good&amp;nbsp;idea.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;Anyway. The other day, Apple introduced new iPad Pros, and an updated MacBook Air line-up. Most notably on the iPad hardware front, along with improving whatever feature was improvable, Apple has presented a new accessory — the Magic Keyboard. It has a trackpad. And on the software front, the upcoming iPadOS 13.4 will offer full mouse and trackpad support.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;Trackpad support was of course well received by iPad fans and all the people using the iPad as a main (or sole) computing device for work and leisure. Some praised the innovation of the new cursor, which Apple in their marketing describe as being &lt;em&gt; The biggest thing to happen to the cursor since point and click&lt;/em&gt;. (Let me pause and &lt;em&gt;eyeroll&lt;/em&gt; for a moment here). It’s an interesting take and a good execution. It’s also the least Apple could do on such a device — devising a cursor that is more context-aware and responsive than the one you find in a traditional computer is frankly more consequential than innovative.&lt;/p&gt;
&lt;p&gt;As is consequential the fact that now the iPad supports mouse/trackpad input. Some of the comments I saw floating around mentioned how Apple has finally given in to the pressing requests from the iPad community, from people who wanted a more ‘Surface-like’ approach for the iPad, so as to make it a more suitable device for productivity.&lt;/p&gt;
&lt;p&gt;While that may also be true, what I think is that Apple has actually given in to adding mouse/trackpad support to the iPad because they were essentially out of options. And because for them it is a convenient problem solver. It’s Mr Wolf in &lt;em&gt;Pulp Fiction&lt;/em&gt;: the one you call when you need a professional to clean up your&amp;nbsp;mess.&lt;/p&gt;
&lt;p&gt;And the iPad’s user interface &lt;em&gt;still&lt;/em&gt; looks a bit messy. You may be accustomed to it. You may be so proficient at moving inside of it that you even love it. I’m not here to criticise your preferences or the iPad as a device. You wanted a ‘faster horse’ — enjoy your faster horse&lt;sup&gt;&lt;strong&gt;[&lt;a href="#ft1" name="note1"&gt;1&lt;/a&gt;]&lt;/strong&gt;&lt;/sup&gt;. I’m simply speaking from a conceptual standpoint. And from that standpoint, what I see is that the iPad’s user interface is a patchwork. Features, gestures, combinations of gestures, user interface layers, all stitched together over the&amp;nbsp;years.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;Steve Jobs was quoted as saying: “People think focus means saying yes to the thing you’ve got to focus on. But that’s not what it means at all. It means saying no to the hundred other good ideas that there are. You have to pick carefully. I’m actually as proud of the things we haven’t done as the things I have done. Innovation is saying ‘no’ to 1,000 things.”&lt;/p&gt;
&lt;p&gt;By contrast, it appears the iPad is increasingly saying yes to everything.&lt;/p&gt;
&lt;p&gt;Those who have no problems with the poor discoverability of several gestures or features still see the iPad as a flexible device that adapts to the needs of its users. They say, “If you feel that the multitasking interface is opaque, it’s okay. You’re not accustomed to it, and you probably don’t need it. The iPad keeps being intuitive for those who only use it at a basic&amp;nbsp;level.”&lt;/p&gt;
&lt;p&gt;From a visual standpoint, there might be very little difference between a feature that is not visible and a feature that is out of the way. Conceptually, this is a big deal instead. A feature that is not visible and your only way to find it is by reading about it somewhere, or seeing a video tutorial, is something undiscoverable and poorly executed. A feature that is out of the way, but you get hints of its existence by the system, is an indication of at least a modicum of design-oriented thinking behind it. If the iPad’s user interface were truly well thought-out, the more so-called ‘pro’ features would be more discoverable. I wouldn’t get feedback messages from regular folks telling me, &lt;em&gt;I didn’t know I could do this on my iPad&lt;/em&gt;, with some even adding that they discovered some gesture or feature while erroneously performing a known&amp;nbsp;one.&lt;/p&gt;
&lt;p&gt;The more layers of interaction you give to the device, the trickier things get. If the solution to a previously undiscoverable feature is to make the feature (more) discoverable through the use of a different input source, you may have found a way out of the dead end you got stuck in, but it’s not good design, strictly speaking. (I remember an exchange between a woman and an electronics shop’s employee: after buying a Windows laptop she returned to the shop to complain about the poor trackpad performance, and the employee told her to “just use a mouse”. Why not make a better trackpad, instead?)&amp;nbsp;&lt;/p&gt;
&lt;h3&gt;The comparison with Microsoft’s Surface&lt;/h3&gt;
&lt;p&gt;The iPad getting proper mouse input support, and the new Magic Keyboard for the iPad featuring a regular trackpad, have naturally invited people and reviewers to draw comparisons between the iPad and the Surface. But I don’t see it as Apple ‘catching up’ with Microsoft. I see it more as Apple bringing their racing car to a different kind of championship.&lt;/p&gt;
&lt;p&gt;Microsoft’s Surface may have its flaws. Its user interface may have its inconsistencies and limitations, but it doesn’t bear the signs of the iPad’s long-standing identity crisis. The Surface and the iPad have different origin stories, and those are reflected in the way you approach and use these devices.&lt;/p&gt;
&lt;p&gt;The Surface wasn’t really born as a pure tablet with a tailored mobile operating system on it. The concept Microsoft wanted to contribute was of an ultracompact laptop first, with tablet functionalities added on as a convenient alternative to perform quick tasks as needed, without burdening the user with a device fixed in its laptop configuration and behaving like a laptop all the&amp;nbsp;time.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;Still, all the devices in the different Surface product lines &lt;em&gt;are&lt;/em&gt; essentially laptops (of different weights and capabilities) that can work as, or transform into, tablets when the need arises. Even the first generation of Surface devices back in 2012–2013 were hardly ever seen in the wild without their keyboard, despite it being ‘optional’. They’re very much touchscreen computers with a tablet mode, with productivity as their main purpose. Technically, their Apple counterpart would be something more akin to a &lt;a href="https://en.wikipedia.org/wiki/Modbook"&gt;ModBook&lt;/a&gt; than an&amp;nbsp;iPad.&lt;/p&gt;
&lt;p&gt;Their operating system, in a way or another, has always been some version of Windows with additional touch- and tablet-friendly features enabled, to make the Surface a more versatile device.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;The Surface knows what it is. And Surface users know what to expect from it, in terms of functionality and interface. The user interface could be improved here and there, but it’s not ambiguous. The levels of interaction comfort aren’t either. There is a distinctive best/good/okay comfort range as you go from operating a Surface like a Windows laptop, to using it as a tablet with pen input, to using it with touch input with just your fingers. But that feels fine because that’s the experience the Surface is supposed to provide.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;What Microsoft has strived to do over the past eight or so years has been to improve the Surface experience within that model, within that paradigm, and I’d say they’ve been rather successful at that. The next step is represented by devices like the Neo and the Duo, that introduce the new dual screen idea in form and function. The aim is, again, to improve productivity by creating a literal dual space to multitask and facilitate interoperation between apps and tasks, if and when needed.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;The iPad, on the other hand, has had a more varied history, and has been more of a chameleon — with regard to both purpose and interface. It was born as a separate device with unique characteristics to fill the perceived void between a laptop and a smartphone. In 2010, when introducing the iPad, Steve Jobs said, &lt;em&gt; In order to really create a new category of devices, those devices are going to have to be far better at doing some key tasks. They’re gonna have to be far better at doing some really important things: better than the laptop, better than the smartphone.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;And in its first iterations, the iPad was exactly that; its identity pretty clear — ‘a big iPhone’ that could be just as easy to use as an iPhone, but better at doing certain things due to its bigger display. And better than a laptop because certain basic tasks and operations were simply more intuitive to carry out thanks to the multi-touch interface. That really killed all the remaining netbooks still in use at the time, and many non-tech-savvy people were happy to use a small laptop-sized device that was much less intimidating to use than a traditional computer. All thanks to its user interface and its very operating system, that was &lt;em&gt;not&lt;/em&gt; Mac OS X slapped on a touch-based device, but something that felt much more integrated and suitable for such a device. The learning curve was also low because people already knew iOS thanks to the iPhone’s success.&lt;/p&gt;
&lt;p&gt;Then, unfortunately, Steve Jobs passed away.&lt;/p&gt;
&lt;p&gt;I can see your eyes rolling from here, but bear with me. Although I’ve never denied my utter preference for Jobs’s leadership over Cook’s, I’m not trying to argue that the iPad would necessarily have had a better development and trajectory under Jobs, but it’s undeniable that the iPad is perhaps the device that has suffered the most from Jobs’s absence. Under his tenure, Apple released the first-generation iPad and the iPad 2. The iPad 2 was a first real improvement over the iPad 1: it was thinner, more powerful, and it had cameras. The iPads that came out afterwards, between 2012 and 2015, were essentially the same thing as the iPad 2, with obvious improvements in the hardware, and some improvements in the software. Conceptually, very little moved forward. The iPad Air 2, produced between 2014 and 2016, for all intents and purposes was just like the first iPad, just faster, better, and with more capable apps.&lt;/p&gt;
&lt;p&gt;As for its conceptual evolution, as for changing the computing experience altogether, however, the iPad felt like a device stuck in stagnant waters. And it still felt pretty much like a device that didn’t know what it wanted to become. It was created as a consumption device first, with the ability to serve as an artistic tool for creation and to do the occasional productivity task if you tried really hard, with the right apps, and jumping through the right hoops. Styluses and external keyboards have always been usable on it, but the iPad has always been a ‘touch-first’ device, meant to be used like a tablet, not like an ultraportable laptop. I can’t speak for Jobs here, but I’m pretty sure he would have said something like, &lt;em&gt;If you need to use the iPad as a laptop replacement, maybe it’s better if you just used a real laptop.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;But then an increasing number of people, especially tech nerds, started to demand from Apple something more akin to Microsoft’s Surface in features and functionality. And Apple, from 2015–2016 onwards, started to oblige, little by little. And so they have been repurposing the iPad as it goes along without really jettisoning anything. The process has been utterly additive. Employing the famous Jobs’s analogy of trucks and cars, I’d say that from its origins as a sports car, the iPad has progressively become a sports car that can be retrofitted with a trailer, off-road tyres, a 4WD transmission, and so&amp;nbsp;forth.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;Some look at the latest iPad Pro, at the full support for mouse input in iPadOS 13.4, at the new Magic Keyboard with trackpad, as a winning combination of tools that make the iPad a truly versatile device. And maybe it is so from a practical standpoint. Again, conceptually, I look at ten years of the iPad and I see its trajectory as going from being a ‘jack of some trades, master of some’ to being a ‘jack of all trades, &lt;em&gt;still&lt;/em&gt; master of some, but not&amp;nbsp;all’.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;The story and evolution of Microsoft’s Surface are perhaps simpler and less ambitious, but over the years have proceeded with a much clearer process, iterations, and intentions. Apple now probably aims for the iPad to be a sort of blank-slate device, so technically capable that it can do anything you want it to do. But all this retrofitting to make it also behave like a compact laptop has been — still is — a painful process to behold. I keep feeling the iPad could have been so much more in so many different, countercurrent ways, and all it has done in ten years is to become something more conventional.&lt;/p&gt;
&lt;p&gt;Where the iPad is truly at the forefront today is hardware (industrial design + manufacturing + tech specs). But idea, concept, purpose? Not anymore. Others are trying to match the iPad in hardware, Apple is borrowing ideas and purposes from others. If there’s combined progress in all this, it’s inertial.&lt;/p&gt;
&lt;p&gt;Again, I can’t be sure, I don’t have the ability to see alternate timelines, but I truly wonder what was Jobs’s ultimate idea for the iPad. What direction he wanted to point it. I’m not saying that things would have been better if Steve Jobs were still among us. But I’m sure we would have felt a stronger sense of direction for the iPad. A clearer vision, even if more polarising, perhaps.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;What &lt;em&gt;I felt&lt;/em&gt; back in 2010–2011 was that Jobs’s plan could have been to gradually evolve the iPad into a unique computing device, using the tablet format and the multi-touch interface to effectively &lt;em&gt;revolutionise&lt;/em&gt; what it meant to be productive using something that is not a traditional computer; to end up with a device that could go beyond the old and established paradigms and metaphors of traditional desktop computing. If he had wanted the iPad to progressively become a Surface-like device, he would have probably sherlocked the aforementioned ModBook and create a touch MacBook with Mac OS&amp;nbsp;X.&lt;/p&gt;
&lt;p&gt;Maybe this is the root of my general feeling of disappointment in the iPad — that Apple didn’t make enough efforts to come up with a transformative UI that could revolutionise how people can be productive on a tablet, without having to resort to traditional paradigms and input devices. Without reinventing the computing wheel for so many tasks just so they can be easily carried out on an iPad, even when it would make much more sense to just use a laptop.&lt;/p&gt;
&lt;p&gt;Yes, maybe my expectations have always been high on this front. But not unreasoningly so. Is it really too much to ask of a tablet today, after seeing how innovative certain parts of the Apple Newton’s user interface could be more than 20 years&amp;nbsp;ago?&lt;/p&gt;
&lt;p&gt;For some, having an iPad acquire more Surface-like capabilities may be a success, a much awaited move that will solve so many things. For me this move, that brings the iPad even closer to a Mac laptop in functionality, in turn makes the iPad &lt;em&gt;even less&lt;/em&gt; compelling.&amp;nbsp;&lt;/p&gt;
&lt;h3&gt;The big picture&lt;/h3&gt;
&lt;p&gt;Judging by previous feedback I received after publishing other articles on the iPad and ranting about my disappointment, a lot of people think I’m still clinging to the past, to the Mac and traditional computers, that I’m averse to change, that I’m ‘old’ and not flexible enough to adapt to this bright future of computing spearheaded by this incredibly awesome and innovative device that is the&amp;nbsp;iPad.&amp;nbsp;&lt;/p&gt;
&lt;p&gt;Others mistake my criticism for the iPad at the conceptual level for criticism aimed at the device itself. Nothing could be further from the truth. I do think the iPad is an impressive device. I don’t deny it’s an engineering feat. I absolutely think you can do all kinds of serious work on it. And I’m happy for all those who are able to make the most of it. (Yes, whenever the iPad vs Mac debate rages on Twitter, I have indeed indulged in some sarcasm. But come on, who doesn’t on Twitter?)&lt;/p&gt;
&lt;p&gt;However, as someone who for several years has cultivated a deep interest for the history of computing and the user interface, I simply can’t look at the iPad (or the Surface, for that matter) and see real progress. Again, I’m not talking about computing power and features. The iPad Pro today is so much more powerful than a supercomputer from the 1970s. I’m talking conceptually. The ideas that drove the computer scientists at RAND corporation to create the RAND tablet in the mid-1960s were more advanced in scope than the ideas behind any tablet available today. And in certain respects more daring, as that tablet was meant to be operated without any keyboard whatsoever. It had an amazing handwriting recognition for the time, and all input came via its stylus. And some of the capabilities of &lt;a href="https://en.wikipedia.org/wiki/Sketchpad"&gt;Sketchpad&lt;/a&gt;, the groundbreaking program written by Ivan Sutherland in 1963, are still hard to beat in intuitiveness and execution, almost sixty years&amp;nbsp;later.&lt;/p&gt;
&lt;p&gt;So when I see a tablet device in 2020 become more usable thanks to it finally supporting &lt;em&gt;mouse input&lt;/em&gt; of all things, and not because of some other advancement in touch technology, input method, user interaction or user interface design, forgive me if I feel underwhelmed and a bit disheartened. What we do with our devices today is something people like Alan Kay envisaged in the 1960s and 1970s. So no, I’m not clinging to the past or averse to change. I see where we are today and I’m baffled we haven’t advanced further. Or rather, the hardware has. But concepts, paradigms and metaphors are still the ones that have been circulating for more than sixty years. Today I see future-looking hardware marred by backward-looking software, interfaces, and interactions. In a sense, everyone’s clinging to the past, in a way or another.&lt;/p&gt;
&lt;p&gt;Then why do I still choose the Mac over the iPad? Until I see real progress on those fronts I mentioned above, why should I waste time, money, and energies to be able to do on an iPad the same things I can already do with ease, experience and efficiency on a Mac? I would gladly undergo the re-learning process if that meant mastering a new device or interface concept that would bring significant benefits over ‘the old ways’ in terms of interaction, productivity, fulfilment, and so forth — or even something new in a meaningful way, something that was not possible before. But for now I keep seeing ‘the old ways’ re-emerge here and there behind the external layer of coolness of the iPad. I can’t be averse to change when I don’t even really perceive change in the first&amp;nbsp;place.&lt;/p&gt;

&lt;hr&gt;


					&lt;/div&gt;&lt;/div&gt;&lt;a href="http://morrick.me/archives/8840"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Mon, 30 Mar 2020 11:38:05 UT
      </pubDate>
      <guid>
        http://morrick.me/archives/8840
      </guid>
    </item>
    <item>
      <title>
        How Apple Is Working From Home — The Information
      </title>
      <link>
        https://www.theinformation.com/articles/how-apple-is-working-from-home?utm_source=hackernews&amp;utm_medium=unlock
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;section id="ti-content"&gt;
        
        

        





&lt;article id="4363"&gt;

  

  

    &lt;figcaption id="hero-image-caption"&gt;
      Apple's headquarters in Cupertino, California. Photo by Bloomberg

    &lt;/figcaption&gt;

  &lt;div id="article-container"&gt;

    

    &lt;div&gt;
      &lt;p&gt;
        March 30, 2020 10:02 AM PDT
      &lt;/p&gt;
    &lt;/div&gt;

    &lt;div&gt;
          &lt;p&gt;Normally, Apple’s hardware teams meet in person at the company’s Cupertino, California, headquarters to review upcoming products, often bringing key components of their devices to show colleagues.&amp;nbsp;&lt;/p&gt;&lt;p&gt;But now that they are sidelined at home due to Covid-19, members of those teams are improvising new tactics for getting their work done. During video calls, they have resorted to tracing shapes in the air to describe components they’ve had to leave back in the office, said two employees. Because of travel restrictions, they’ve had to make decisions based on grainy photos of parts sent from Chinese factories, rather than doing so in person.&amp;nbsp;&lt;/p&gt;&lt;p&gt;As the tech industry braces for an economic downturn caused by the global pandemic, its biggest companies, which sit on billions of dollars of cash reserves, are perhaps best positioned. But Apple, one of the world’s most valuable companies, faces a unique set of challenges because of its secretive culture, focus on hardware and dependence on Chinese manufacturing, according to interviews The Information conducted in recent days with a dozen current and former employees, as well as others who work closely with the company. &lt;/p&gt;
        &lt;/div&gt;
  &lt;/div&gt;

  &lt;div id="read-this-article"&gt;
    &lt;p&gt;
      &lt;h2&gt;
        Join now to read the full story
      &lt;/h2&gt;
    &lt;/p&gt;
  &lt;/div&gt;

    &lt;div&gt;
      &lt;div&gt;
            
            &lt;p&gt;&lt;span&gt;
                  The Takeaway
                &lt;/span&gt;
                &lt;span&gt;
                    &lt;span&gt;
                      Media/Telecom
                    &lt;/span&gt;
                &lt;/span&gt;
            &lt;/p&gt;
            &lt;div&gt;
              &lt;div&gt;
                &lt;p&gt;
                  What Critics of the News Industry Get Right—and Wrong
                &lt;/p&gt;
                &lt;p&gt;
                  By Jessica E. Lessin · Feb. 6, 2021  7:46 AM PST
                &lt;/p&gt;
              &lt;/div&gt;
              &lt;div&gt;
                &lt;picture&gt;

  &lt;source srcset="https://tii.imgix.net/production/articles/5299/311bc6f4-90de-4a9c-9532-c04168b04634.png?w=400&amp;amp;fm=webp&amp;amp;auto=compress" media="(min-width: 1px) and (max-width: 9999px)" type="image/webp"&gt;
  &lt;source srcset="https://tii.imgix.net/production/articles/5299/311bc6f4-90de-4a9c-9532-c04168b04634.png?w=400&amp;amp;fm=jpeg&amp;amp;auto=compress" type="image/jpeg"&gt;
&lt;img src="https://tii.imgix.net/production/articles/5299/311bc6f4-90de-4a9c-9532-c04168b04634.png?w=400&amp;amp;fm=jpeg&amp;amp;auto=compress" alt=""&gt;
&lt;/picture&gt;
              &lt;/div&gt;
            &lt;/div&gt;
            &lt;p&gt;
              Thank you for your feedback on my column last week about the nightmare I believe is waiting for the news industry. It is clear that technology hasn’t just anointed Google, Facebook and Twitter the new gatekeepers. It has gone further and killed the very notion of a gatekeeper itself. The result is an increasingly loud mess of services where leaders can say what they want, whenever they...
            &lt;/p&gt;
          &lt;/div&gt;
&lt;div&gt;
            
              &lt;div&gt;
                &lt;p&gt;
                  Oscar Health Files to Go Public, Hippo in SPAC Talks
                &lt;/p&gt;
                &lt;p&gt;
                  By Ross Matican · Feb. 5, 2021
                &lt;/p&gt;
              &lt;/div&gt;
              &lt;div&gt;
                &lt;p&gt;
                  Microsoft Suspends Donations to Politicians Who Voted to Overturn Election
                &lt;/p&gt;
                &lt;p&gt;
                  By Kevin McLaughlin · Feb. 5, 2021
                &lt;/p&gt;
              &lt;/div&gt;
              &lt;div&gt;
                &lt;p&gt;
                  Alibaba’s $5 Billion Bond Draws Demand Despite Regulatory Crackdown
                &lt;/p&gt;
                &lt;p&gt;
                  By Wayne Ma · Feb. 5, 2021
                &lt;/p&gt;
              &lt;/div&gt;
          &lt;/div&gt;
&lt;div&gt;
      
      &lt;p&gt;&lt;img src="https://www.theinformation.com/assets/app-articles-tab-screenshot-df5e9fa155933249c0cec82b657666156d6c21acdb60d1ea971bb7bd0ac37746.png" loading="lazy" id="app-screenshot" srcset="https://www.theinformation.com/assets/app-articles-tab-screenshot@2x-3c2289fa3376fba910bde19989adba825d62fb1385dbc047be504492de139916.png 2x, https://www.theinformation.com/assets/app-articles-tab-screenshot@3x-44c65f79a467abd2d085a16eee43e179fe5282888dc9f1179bf7f237812d10f3.png 3x"&gt;
      &lt;/p&gt;
    &lt;/div&gt;
&lt;div&gt;
      &lt;p&gt;&lt;img src="https://www.theinformation.com/assets/locked-homepage-video-insert.jpg"&gt;
      &lt;/p&gt;
      
    &lt;/div&gt;
&lt;div&gt;
      
      &lt;p&gt;&lt;img src="https://www.theinformation.com/images/locked-homepage-article-insert.png"&gt;
      &lt;/p&gt;
    &lt;/div&gt;


      
    &lt;/div&gt;


&lt;/article&gt;



        
      &lt;/section&gt;&lt;/div&gt;&lt;a href="https://www.theinformation.com/articles/how-apple-is-working-from-home?utm_source=hackernews&amp;utm_medium=unlock"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Mon, 30 Mar 2020 17:53:21 UT
      </pubDate>
      <guid>
        https://www.theinformation.com/articles/how-apple-is-working-from-home?utm_source=hackernews&amp;utm_medium=unlock
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://www.aaronkharris.com/asking-questions
      </link>
      <description>
        &lt;a href="https://www.aaronkharris.com/asking-questions"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Mon, 30 Mar 2020 17:57:49 UT
      </pubDate>
      <guid>
        https://www.aaronkharris.com/asking-questions
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://www.superhighway98.com/google
      </link>
      <description>
        &lt;a href="https://www.superhighway98.com/google"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 31 Mar 2020 21:22:13 UT
      </pubDate>
      <guid>
        https://www.superhighway98.com/google
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://sulami.github.io/posts/building-a-literal-library-of-building-blocks/
      </link>
      <description>
        &lt;a href="https://sulami.github.io/posts/building-a-literal-library-of-building-blocks/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Wed, 1 Apr 2020 12:03:04 UT
      </pubDate>
      <guid>
        https://sulami.github.io/posts/building-a-literal-library-of-building-blocks/
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://gravitational.com/blog/how-to-ssh-properly/
      </link>
      <description>
        &lt;a href="https://gravitational.com/blog/how-to-ssh-properly/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Wed, 1 Apr 2020 17:29:19 UT
      </pubDate>
      <guid>
        https://gravitational.com/blog/how-to-ssh-properly/
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://increment.com/programming-languages/crash-course-in-compilers/
      </link>
      <description>
        &lt;a href="https://increment.com/programming-languages/crash-course-in-compilers/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Thu, 2 Apr 2020 21:24:50 UT
      </pubDate>
      <guid>
        https://increment.com/programming-languages/crash-course-in-compilers/
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://www.cs.cmu.edu/~mleone/how-to.html
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;A collection of advice about how to do research and how to communicate
effectively (primarily for computer scientists). 

&lt;h2&gt;Writing and Publishing&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt; &lt;a href="http://www.sce.carleton.ca/faculty/chinneck/thesis.html"&gt;
How to Organize your Thesis&lt;/a&gt;, by John W. Chinneck.
&lt;/li&gt;&lt;li&gt; &lt;a href="ftp://parcftp.xerox.com/pub/popl96/pugh/advice.ps.Z"&gt;
Advice to Authors of Extended Abstracts&lt;/a&gt;, by William Pugh.
&lt;/li&gt;&lt;li&gt; &lt;a href="ftp://ftp.math.ohio-state.edu/pub/math.style/hint.ps"&gt;Hints
on good mathematical writing&lt;/a&gt;, by David Goss
&lt;/li&gt;&lt;li&gt; &lt;a href="ftp://ftp.math.ohio-state.edu/pub/math.style/mit.ps"&gt;
A primer on mathematical writing&lt;/a&gt;, by Steven L. Kleiman
&lt;/li&gt;&lt;li&gt; &lt;a href="ftp://parcftp.xerox.com/pub/popl96/vanLeunenLipton"&gt;
How To Have Your Abstract Rejected&lt;/a&gt;,
by van Leunen and Lipton.
&lt;/li&gt;&lt;li&gt; &lt;a href="ftp://fast.cs.utah.edu/pub/writing-papers.ps"&gt;
An Evaluation of the Ninth SOSP Submissions, or, How (and How Not) to
Write a Good Systems Paper&lt;/a&gt; by Roy Levin and David D. Redell
&lt;/li&gt;&lt;li&gt; &lt;a href="http://ursamajor.uvic.ca/how.to.publish.html"&gt;
How to Get a Paper Accepted at OOPSLA&lt;/a&gt;, by Alan Snyder.
&lt;ul&gt;
&lt;li&gt; Includes &lt;a href="http://ursamajor.uvic.ca/how.to.panel.html"&gt;
comments from an OOPSLA program committee.&lt;/a&gt;
&lt;/li&gt;&lt;/ul&gt;
&lt;/li&gt;&lt;li&gt; &lt;a href="ftp://parcftp.xerox.com/pub/popl96/suggestions"&gt;
Advice for 1996 POPL submissions&lt;/a&gt;
&lt;/li&gt;&lt;/ul&gt;

&lt;h2&gt;Research Skills&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt; &lt;a href="http://www.cs.umd.edu/~oleary/gradstudy/gradstudy.html"&gt;
Graduate Study in the Computer and Mathematical Sciences: A Survival
Manual&lt;/a&gt;, by Dianne O'Leary
&lt;/li&gt;&lt;li&gt; &lt;a href="http://www.cs.indiana.edu/how.2b/how.2b.html"&gt;
How to be a Good Graduate Student/Advisor&lt;/a&gt;, by Marie desJardins
&lt;/li&gt;&lt;li&gt; &lt;a href="ftp://cs.williams.edu/pub/bailey/research.ps"&gt;
A Letter to Research Students&lt;/a&gt;, by Duane A. Bailey
&lt;/li&gt;&lt;li&gt;&lt;a href="http://www.cs.indiana.edu/mit.research.how.to.html"&gt;
How to do Research in the MIT AI Lab&lt;/a&gt;, ed. David Chapman
&lt;/li&gt;&lt;li&gt; The IUCS &lt;a href="http://www.cs.indiana.edu/docproject/handbook/part1.9.html"&gt;
Graduate Student Survival Guide&lt;/a&gt;.
&lt;ul&gt;
&lt;li&gt; Includes &lt;a href="http://www.cs.indiana.edu/docproject/handbook/section1.9.0.3.html"&gt;
Survival Skills for Graduate Women&lt;/a&gt;
&lt;/li&gt;&lt;li&gt; and &lt;a href="http://www.cs.indiana.edu/docproject/handbook/section1.9.0.6.html"&gt;
The Assistant Professor's Guide to the Galaxy&lt;/a&gt;.
&lt;/li&gt;&lt;/ul&gt;
&lt;/li&gt;&lt;/ul&gt;

&lt;h2&gt;Speaking&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt; &lt;a href="ftp://ftp.dcs.glasgow.ac.uk/pub/glasgow-fp/papers/giving-a-talk.ps.Z"&gt;
How to Give a Good Research Talk&lt;/a&gt;, by Simon Peyton Jones et al.
&lt;/li&gt;&lt;li&gt; &lt;a href="ftp://ftp.unt.edu/ian/guides/speaker/speaker.ps"&gt;
How to Present a Paper in Theoretical Computer Science&lt;/a&gt;,
by Ian Parberry.
&lt;/li&gt;&lt;/ul&gt;

&lt;h2&gt;Career Development&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt; &lt;a href="http://communication.ucsd.edu/pagre/network.html"&gt;
Networking on the Network&lt;/a&gt; by Phil Agre
&lt;/li&gt;&lt;li&gt;&lt;a href="http://www-ccsl.cs.umass.edu/~kaplan/jobs/"&gt;Computer Science Faculty and Research Positions&lt;/a&gt;
&lt;/li&gt;&lt;li&gt; &lt;a href="http://snorri.chem.washington.edu/ysnarchive/"&gt;
The Young Scientists' Network&lt;/a&gt;
&lt;/li&gt;&lt;li&gt; &lt;a href="http://cra.org/womencom.html"&gt;
CRA Committee on the Status of Women in Research&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt; Includes a &lt;a href="http://cra.org/craw-docs/gradinfokit.html"&gt;
Graduate School Information Kit for Women in
Computer Science and Engineering&lt;/a&gt;
&lt;/li&gt;&lt;li&gt; and the &lt;a href="http://cra.org/mentor.html"&gt;
Distributed Mentor Project&lt;/a&gt; for female undergraduates.
&lt;/li&gt;&lt;/ul&gt;
&lt;/li&gt;&lt;li&gt; &lt;a href="http://bunny.cs.uiuc.edu/funding/academicCareers.html"&gt;ACM
SIGMOD academic careers information&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt; Includes 
&lt;a href="ftp://ics.uci.edu/pub/mentoring-workshop"&gt;transcripts from the
Workshop on Academic Careers for Women&lt;/a&gt;.
&lt;/li&gt;&lt;/ul&gt;
&lt;/li&gt;&lt;/ul&gt;



&lt;h2&gt;Related Topics and Resources&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt; &lt;a href="http://www.eecs.nwu.edu:8001/jmyers/gradstudent.html"&gt; 
Information resources for graduate students&lt;/a&gt; by Jennifer Myers.
&lt;/li&gt;&lt;li&gt; &lt;a href="ftp://ftp.unt.edu/ian/guides/referee/manuscript.ps"&gt;
A Guide for New Referees in Theoretical Computer Science&lt;/a&gt;,
by Ian Parberry.
&lt;/li&gt;&lt;li&gt; &lt;a href="http://www.nas.edu/nap/online/obas"&gt;
On Being A Scientist: Responsible Conduct In Research&lt;/a&gt;,
from the National Academy of Sciences
&lt;/li&gt;&lt;li&gt; Papers on &lt;a href="http://www.ai.mit.edu/people/ellens/gender.html"&gt;
women in computer science&lt;/a&gt;.
&lt;ul&gt;
&lt;li&gt; Includes 
&lt;a href="http://www.ai.mit.edu/people/ellens/Gender/pap/pap.html"&gt;
&lt;cite&gt;Why Are There So Few Female Computer Scientists?&lt;/cite&gt;&lt;/a&gt;,
by Ellen Spertus.
&lt;/li&gt;&lt;/ul&gt;
&lt;/li&gt;&lt;li&gt; &lt;a href="http://www.uark.edu/depts/comminfo/www/study.html"&gt;
Study, Research, and Writing Skills&lt;/a&gt; web page
from the American Communication Association.
&lt;/li&gt;&lt;li&gt; &lt;a href="http://www.cs.umbc.edu/graduate/info.html"&gt;
Information for current and prospective graduate students&lt;/a&gt; by
Timothy Finin.
&lt;/li&gt;&lt;li&gt; &lt;a href="http://www.public.iastate.edu/~pmohseni/grad.ps"&gt;
A Guide for Applying to Graduate Schools&lt;/a&gt; 
by Piroz Mohseni.
&lt;/li&gt;&lt;li&gt; Ivan Sutherland, "Technology and Courage," in CMU Computer
Science: A 25th Anniversary Commemorative, ed. Richard F. Rashid. ACM
Press, 1991.
&lt;/li&gt;&lt;li&gt; Alan Jay Smith, "The task of the referee," IEEE Computer, April 1990,
pp. 65-71.
&lt;/li&gt;&lt;/ul&gt;

&lt;h2&gt;Dissertation Advice&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt; &lt;a href="http://www.asgs.org/Diss_Nws.htm"&gt;Dissertation News&lt;/a&gt;,
published by &lt;a href="http://www.asgs.org/"&gt;
The Association for Support of Graduate Students&lt;/a&gt;.
&lt;/li&gt;&lt;li&gt; &lt;a&gt;
Resources for dissertation research&lt;/a&gt; (gopher)
&lt;/li&gt;&lt;li&gt; &lt;a href="http://155.187.10.12/fun/burnout.html"&gt;
How to cope with "burnout"&lt;/a&gt;,
by Andreas Gehmeyr.
&lt;/li&gt;&lt;li&gt; How to Complete and Survive a Doctoral Dissertation, by 
David Sternberg.  St. Martin's Press, New York.  ISBN 0-312-39606-6
&lt;/li&gt;&lt;li&gt; How to Get Control of Your Time and Your Life, by Alan Lakein.
Signet Books.  ISBN 0-451-16772-4
&lt;/li&gt;&lt;li&gt; Procrastination:  Why you do it, what to do about it, 
by Jane Burka and Lenora Yuen.  Addison-Wesley.  ISBN 0-201-55089-X
&lt;/li&gt;&lt;/ul&gt;

&lt;h2&gt;Humor&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt; &lt;a href="http://www.cs.utah.edu/~lepreau/osdi94/keynote/abstract.html"&gt;
How to Have a Bad Career in Research/Academia&lt;/a&gt; by David Patterson
&lt;/li&gt;&lt;li&gt; &lt;a href="http://web.mit.edu/afs/athena.mit.edu/user/w/c/wchuang/News/college/MIT-views.html.gz"&gt;Burnout Prevention and Recovery at MIT&lt;/a&gt;
&lt;/li&gt;&lt;li&gt; &lt;a href="http://www.best.com/~smurman/soga/misc/research.html"&gt;
A Dictionary of Useful Research Phrases&lt;/a&gt;
&lt;/li&gt;&lt;/ul&gt;


&lt;hr&gt;
&lt;address&gt;&lt;a href="https://www.cs.cmu.edu/afs/cs.cmu.edu/user/mleone/web/whois-mleone.html"&gt;
mleone@cs.cmu.edu&lt;/a&gt;&lt;/address&gt;

&lt;/div&gt;&lt;a href="https://www.cs.cmu.edu/~mleone/how-to.html"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Fri, 3 Apr 2020 18:08:12 UT
      </pubDate>
      <guid>
        https://www.cs.cmu.edu/~mleone/how-to.html
      </guid>
    </item>
    <item>
      <title>
        An Opinionated Guide to ML Research
      </title>
      <link>
        http://joschu.net/blog/opinionated-guide-ml-research.html
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;

    &lt;h2&gt;An Opinionated Guide to ML Research&lt;/h2&gt;


    &lt;p&gt;Posted on 2020/01/24&lt;/p&gt;
    &lt;a href="http://joschu.net/blog.html"&gt;← back to blog index&lt;/a&gt;

&lt;p&gt;&lt;em&gt;I originally wrote this guide in back in December 2017 for the &lt;a href="https://openai.com/blog/openai-fellows/"&gt;OpenAI Fellows program&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;In this essay, I provide some advice to up-and-coming researchers in machine learning (ML), based on my experience doing research and advising others. The advice covers how to choose problems and organize your time. I also recommend the following prior essays on similar topics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.cs.virginia.edu/~robins/YouAndYourResearch.html"&gt;&lt;em&gt;You and Your Research&lt;/em&gt; by Richard Hamming&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://michaelnielsen.org/blog/principles-of-effective-research"&gt;&lt;em&gt;Principles of Effective Research&lt;/em&gt; by Michael Nielsen&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;My essay will cover similar ground, but it’s more tuned to the peculiar features of ML.&lt;/p&gt;
&lt;p&gt;The keys to success are working on the right problems, making continual progress on them, and achieving continual personal growth. This essay is comprised of three sections, each covering one of these topics.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;. Before continuing, it’s useful to spend a few minutes about which findings and achievements in ML have been most interesting and informative to you. Think about what makes each one stand out—whether it's a groundbreaking result that changed your perspective on some problem; or an algorithmic idea that's reusable; or a deep insight about some recurring questions. You should aspire to produce results, algorithms, and insights of this caliber.&lt;/p&gt;
&lt;h3 id="choosing-problems"&gt;Choosing Problems&lt;/h3&gt;
&lt;h4 id="honing-your-taste"&gt;Honing Your Taste&lt;/h4&gt;
&lt;p&gt;Your ability to choose the right problems to work on is even more important than your raw technical skill. This taste in problems is something you’ll develop over time by watching which ideas prosper and which ones are forgotten. You’ll see which ones serve as building blocks for new ideas and results, and which ones are ignored because they are too complicated or too fragile, or because the incremental improvement is too small.&lt;/p&gt;
&lt;p&gt;You might be wondering if there’s a way to speed up the process of developing a good taste for what problems to work on. In fact, there are several good ways.&lt;/p&gt;
&lt;ol type="1"&gt;
&lt;li&gt;Read a lot of papers, and assess them critically. If possible, discuss them with others who have a deeper knowledge of the subject.&lt;/li&gt;
&lt;li&gt;Work in a research group with other people working on similar topics. That way you can absorb their experiences as well as your own.&lt;/li&gt;
&lt;li&gt;Seek advice from experienced researchers on what to work on. There’s no shame in working on ideas suggested by other people. Ideas are cheap, and there are lots of them in the air. Your skill comes in when you decide which one to work on, and how well you execute on it.&lt;/li&gt;
&lt;li&gt;Spend time reflecting on what research is useful and fruitful. Think about questions like
&lt;ol type="a"&gt;
&lt;li&gt;When is theory useful?&lt;/li&gt;
&lt;li&gt;When are empirical results transferable?&lt;/li&gt;
&lt;li&gt;What causes some ideas to get wide uptake, whereas others are forgotten?&lt;/li&gt;
&lt;li&gt;What are the trends in your field? Which lines of work will make the other ones obsolete?&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Items 1-3 relate to optimizing your environment and getting input from other researchers, whereas item 4 is something you do alone. As empirical evidence for the importance of 1-3, consider how the biggests bursts of impactful work tend to be tightly clustered in a small number of research groups and institutions. That’s not because these people are dramatically smarter than everyone else, it’s because they have a higher density of expertise and perspective, which puts them a little ahead of the rest of the community, and thus they dominate in generating new results. If you’re not fortunate enough to be in an environment with high density of relevant expertise, don’t despair. You’ll just have to work extra-hard to get ahead of the pack, and it’s extra-important to specialize and develop your own unique perspective.&lt;/p&gt;
&lt;h4 id="idea-driven-vs-goal-driven-research"&gt;Idea-Driven vs Goal-Driven Research&lt;/h4&gt;
&lt;p&gt;Roughly speaking, there are two different ways that you might go about deciding what to work on next.&lt;/p&gt;
&lt;ol type="1"&gt;
&lt;li&gt;&lt;p&gt;Idea-driven. Follow some sector of the literature. As you read a paper showing how to do X, you have an idea of how to do X even better. Then you embark on a project to test your idea.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Goal-driven. Develop a vision of some new AI capabilities you’d like to achieve, and solve problems that bring you closer to that goal. (Below, I give a couple case studies from my own research, including the goal of using reinforcement learning for 3D humanoid locomotion.) In your experimentation, you test a variety of existing methods from the literature, and then you develop your own methods that improve on them.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Of course, these two approaches are not mutually exclusive. Any given subfield ML is concerned with some goals (e.g., object detection). Any “idea-driven” project will represent progress towards the subfield’s goals, and thus in a sense, it’s an instance of goal-driven research. But here, I’ll take goal-driven research to mean that your goal is more specific than your whole subfield’s goal, and it’s more like &lt;em&gt;make X work for the first time&lt;/em&gt; than &lt;em&gt;make X work better&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;I personally recommend goal-driven research for most people, and I’ve mostly followed this strategy myself.&lt;/p&gt;
&lt;p&gt;One major downside of idea-driven research is that there’s a high risk of getting scooped or duplicating the work of others. Researchers around the world are reading the same literature, which leads them to similar ideas. To make breakthroughs with idea-driven research, you need to develop an exceptionally deep understanding of your subject, and a perspective that diverges from the rest of the community—some can do it, but it’s difficult.&lt;/p&gt;
&lt;p&gt;On the other hand, with goal-driven research, your goal will give you a perspective that’s differentiated from the rest of the community. It will lead you to ask questions that no one else is asking, enabling you to make larger leaps of progress. Goal driven research can also be much more motivating. You can wake up every morning and imagine achieving your goal—what the result would look like and how you would feel. That makes it easier to stick to a long-running research program with ups and downs. Goals also make it possible for a team of researchers to work together and attack different aspects of the problem, whereas idea-driven research is most effectively carried out by “teams” of 1-2 people.&lt;/p&gt;
&lt;h6 id="case-study-of-goal-driven-research-my-work-during-graduate-school"&gt;Case Study of Goal-Driven Research: My Work During Graduate School&lt;/h6&gt;
&lt;p&gt;For the first half of my PhD, my goal was to enable robots to manipulate deformable objects—including surgical robots tying knots, and household robots folding clothes. While this goal was determined by my advisor, Pieter Abbeel, as the main goal for his lab, I developed my own opinion on how to achieve this goal—my approach was based on learning from human demonstrations, and I was going to start with the problem of getting the PR2 to tie knots in rope. Various unexpected subproblems arose, one of which was trajectory optimization, and my work on that subproblem ended up being the most influential product of the knot-tying project.&lt;/p&gt;
&lt;p&gt;For the second half of my PhD, I became interested in reinforcement learning. While there are many problem domains in which reinforcement learning can be applied, I decided to focus on robotic locomotion, since the goal was concrete and the end result was exciting to me. Specifically, my goal was to get a 3D robot to learn how to run from scratch using reinforcement learning. After some initial exploration, I decided to focus on policy gradient methods, since they seemed most amenable to understanding and mathematical analysis, and I could leverage my strength in optimization. During this period, I developed TRPO and GAE and eventually achieved the original goal of 3D humanoid locomotion.&lt;/p&gt;
&lt;p&gt;While I was working on locomotion and starting to get my first results with policy gradient methods, the DeepMind team presented the results using DQN on Atari. After this result, many people jumped on the bandwagon and tried to develop better versions of Q-learning and apply them to the Atari domain. However, I had already explored Q-learning and concluded that it wasn’t a good approach for the locomotion tasks I was working on, so I continued working on policy gradient methods, which led to TRPO, GAE, and later PPO—now my best known pieces of work. This example illustrates how choosing a different problem from the rest of the community can lead you to explore different ideas.&lt;/p&gt;
&lt;h6 id="goal-driven-research-restrict-yourself-to-general-solutions"&gt;Goal Driven Research: Restrict Yourself to General Solutions&lt;/h6&gt;
&lt;p&gt;One pitfall of goal-driven research is taking your goal too literally. If you have a specific capability in mind, there’s probably some way to achieve it in an uninteresting way that doesn’t advance the field of machine learning. You should constrain your search to solutions that seem general and can be applied to other problems.&lt;/p&gt;
&lt;p&gt;For example, while working on robotic locomotion, I avoided incorporating domain information into the solution—the goal was to achieve locomotion in simulation, &lt;em&gt;in a way that was general and could be applied to other problems&lt;/em&gt;. I did a bit of feature engineering and reward shaping in order to see the first signs of life, but I was careful to keep my changes simple and not let them affect the algorithm I was developing. Now that I am using videogames as a testbed, I make sure that my algorithmic ideas are not specific to this setting—that they equally well could be applied to robotics.&lt;/p&gt;
&lt;h4 id="aim-high-and-climb-incrementally-towards-high-goals"&gt;Aim High, and Climb Incrementally Towards High Goals&lt;/h4&gt;
&lt;p&gt;Sometimes, people who are both exceptionally smart and hard-working fail to do great research. In my view, the main reason for this failure is that they work on unimportant problems. When you embark on a research project, you should ask yourself: how large is the potential upside? Will this be a 10% improvement or a 10X improvement? I often see researchers take on projects that seem sensible but could only possibly yield a small improvement to some metric.&lt;/p&gt;
&lt;p&gt;Incremental work (those 10% improvements) are most useful in the context of a larger goal that you are trying to achieve. For example, the seminal paper on ImageNet classification using convolutional neural networks (Krizhevsky, Sutskever, &amp;amp; Hinton, 2012) does not contain any radically new algorithmic components, rather, it stacks up a large number of small improvements to achieve an unprecedented result that was surprising to almost everyone at the time (though we take it for granted now). During your day-to-day work, you’ll make incremental improvements in performance and in understanding. But these small steps should be moving you towards a larger goal that represents a non-incremental advance.&lt;/p&gt;
&lt;p&gt;If you are working on incremental ideas, be aware that their usefulness depends on their complexity. A method that slightly improves on the baseline better be very simple, otherwise no one will bother using it—not even you. If it gives a 10% improvement, it better be 2 lines of code, whereas if it's a 50% improvement, it can add 10 lines of code, etc. (I’m just giving these numbers for illustration, the actual numbers will obviously depend on the domain.)&lt;/p&gt;
&lt;p&gt;Go back and look at the list of machine learning achievements you admire the most. Does your long-term research plan have the potential to reach the level of those achievements? If you can’t see a path to something that you’d be proud of, then you should revise your plan so it does have that potential.&lt;/p&gt;
&lt;h3 id="making-continual-progress"&gt;Making Continual Progress&lt;/h3&gt;
&lt;p&gt;To develop new algorithms and insights in machine learning, you need to concentrate your efforts on a problem for a long period of time. This section is about developing effective habits for this long-term problem solving process, enabling you to continually build towards great results.&lt;/p&gt;
&lt;h4 id="keep-a-notebook-and-review-it"&gt;Keep a Notebook, and Review It&lt;/h4&gt;
&lt;p&gt;I strongly advise you to keep a notebook, where you record your daily ideas and experiments. I have done this through 5 years of grad school and 2 years at OpenAI, and I feel that it has been tremendously helpful.&lt;/p&gt;
&lt;p&gt;I create an entry for each day. In this entry, I write down what I’m doing, ideas I have, and experimental results (pasting in plots and tables). Every 1 or 2 weeks, I do a review, where I read all of my daily entries and I condense the information into a summary. Usually my review contains sections for &lt;em&gt;experimental findings&lt;/em&gt;, &lt;em&gt;insights&lt;/em&gt; (which might come from me, my colleagues, or things I read), &lt;em&gt;code progress&lt;/em&gt; (what did I implement), and &lt;em&gt;next steps / future work&lt;/em&gt;. After I do my week in review, I often look at the previous week to see if I followed up on everything I thought of that week. Also, while doing this review, I sometimes transfer information into other sources of notes. (For example, I keep a list of backburner ideas and projects, separate from my notebook.)&lt;/p&gt;
&lt;p&gt;What’s the value in keeping this notebook and doing the regular reviews?&lt;/p&gt;
&lt;p&gt;First, the notebook is a good place to write down ideas as soon as you have them, so you can revisit them later. Often, when I revisit my journal entries during the week in review, I’ll fill in a missing piece in a puzzle, which didn’t occur to me at the time.&lt;/p&gt;
&lt;p&gt;Second, the notebook helps you keep your experimental results in a unified place, so you can easily find the results later. It’s easy to forget about your conclusions, e.g., which hyperparameters made a difference, and you’ll want to revisit your old notebook entries.&lt;/p&gt;
&lt;p&gt;Third, the notebook lets you monitor your use of time. You might wonder “where did last week go?”, and the notebook will help you answer that question. You might be disappointed with your throughput and realize you need to work on your time management. You also might look back at several months and realize that you’ve been jumping around between ideas too much—that you have a few half-finished projects but you didn’t follow any of these threads long enough to yield a notable result.&lt;/p&gt;
&lt;h4 id="when-to-switch-problems"&gt;When to Switch Problems&lt;/h4&gt;
&lt;p&gt;To solve a challenging problem, you need to spend a sufficient amount of time on it. But in empirical machine learning research, it’s hard to know if you’ve tried an idea hard enough. Sometimes the idea has the potential to work, but if you get one detail wrong, you’ll see no signs of life. But other ideas are simply doomed to fail no matter how hard you work on them.&lt;/p&gt;
&lt;p&gt;In my experience, switching problems too frequently (and giving up on promising ideas) is a more common failure mode than not switching enough. Often, while you’re engaged in the long slog towards getting your current idea to work, another promising idea will come along, and you’ll want to jump to that idea. If your idea is quick to try and the potential upside is large, then go ahead and do it. But more commonly, your initial results on the new idea will be disappointing, and it’ll take a more sustained effort to yield significant results.&lt;/p&gt;
&lt;p&gt;As a rule of thumb, when you look back at which projects you’ve been working on over a period of months, you should find that there have been lots of small dead ends, but the majority of your time has been directed towards projects that yielded a deliverable such as a paper or a blog post. If you look back at your time and see that a substantial fraction was spent on half-finished projects—which were not definite failures, but which you abandoned in favor of some newer idea—then you should make a stronger effort towards consistency and follow-through in the future.&lt;/p&gt;
&lt;p&gt;One strategy, which I haven’t tried personally but makes a lot of sense upon reflection, is to devote some fixed time budget to trying out new ideas that diverge from your main line of work. Say, spend one day per week on something totally different from your main project. This would constitute a kind of epsilon-greedy exploration, and it would also help to broaden your knowledge.&lt;/p&gt;
&lt;h3 id="personal-development"&gt;Personal Development&lt;/h3&gt;
&lt;p&gt;No matter how you allocate your time during your research journey, you are bound to learn a lot. Each project will present new challenges, and you can pick up the background material and skills as you go along. However, you can significantly improve your chances to do great work in the long term by regularly setting aside time for your personal development. Specifically, you should allocate some fraction of your time towards improving your general knowledge of ML as opposed to working on your current project. If you don’t allocate this time, then your knowledge is likely to plateau after you learn the basics that you need for your day-to-day work. It’s easy to settle into a comfort zone of methods you understand well—you may need to expend active effort to expand this zone.&lt;/p&gt;
&lt;p&gt;The main ways to build your knowledge of ML are to read textbooks, theses and papers; and to reimplement algorithms from these sources. Early on in your career, I recommend splitting your time about evenly between textbooks and papers. You should choose a small set of relevant textbooks and theses to gradually work through, and you should also reimplement the models and algorithms from your favorite papers.&lt;/p&gt;
&lt;p&gt;Most students of machine learning don’t spend time reading textbooks after they finish their school courses. I think this is a mistake, since textbooks are a much more dense way to absorb knowledge than papers. Each conference paper typically contains one main new idea, along with a background section that’s too concise to learn anything from. There’s a lot of overhead, since you typically need to spend more time understanding the notation and terminology than the idea itself. On the other hand, good textbooks collect decades of ideas and present them in the proper order with the same notation. Besides reading the introductory machine learning textbooks, read other books in your areas of interest. A couple of my favorites were &lt;em&gt;Numerical Optimization&lt;/em&gt; by Nocedal &amp;amp; Wright, and &lt;em&gt;Elements of Information Theory&lt;/em&gt; by Cover &amp;amp; Thomas.&lt;/p&gt;
&lt;p&gt;Besides textbooks, I recommend reading PhD theses of researchers whose work interests you. PhD theses in ML usually are ordered as follows: (1) introductory and background material, (2) several papers that were previously published at conferences (it’s said that you just have to “staple together” your papers to write your thesis), and (3) a conclusion and outlook. You’re likely to benefit most from parts (1) and (3), since they contain a unifying view of the past and future of the field, written by an expert. Recent theses are often the best place to find a literature review of an active field, but older theses also often contain valuable gems of insight.&lt;/p&gt;
&lt;p&gt;Textbooks and theses are good for building up your foundational knowledge, but you’ll also need to read a lot of papers to bring your knowledge up to the frontier. When you are just starting your research career, I recommend spending a lot of time reimplementing ideas from papers, and comparing your results to the published ones. First of all, this gives you a much deeper understanding of the topic than you’d get by passively reading. Second, you’ll gain experience running experiments, and you’ll get much quicker feedback by reimplementing existing work (where the desired level of performance is known) than by doing original research. Once you can easily reproduce the state-of-the-art, you’ll be ready to go beyond it.&lt;/p&gt;
&lt;p&gt;Besides reading seminal papers and reimplementing them, you should also keep track of the less exceptional papers being published in your field. Reading and skimming the incoming papers with a critical eye helps you notice the trends in your field (perhaps you notice that a lot of papers are using some new technique and getting good results—maybe you should investigate it). It also helps you build up your taste by observing the dependency graph of ideas—which ideas become widely used and open the door to other ideas.&lt;/p&gt;
&lt;p&gt;Go forth and do great research!&lt;/p&gt;



&lt;/div&gt;&lt;a href="http://joschu.net/blog/opinionated-guide-ml-research.html"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sat, 4 Apr 2020 10:00:43 UT
      </pubDate>
      <guid>
        http://joschu.net/blog/opinionated-guide-ml-research.html
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://medium.com/@jurgens_24580/reflections-on-strategies-for-successful-meetings-with-undergraduate-researchers-ae22306ecd8d
      </link>
      <description>
        &lt;a href="https://medium.com/@jurgens_24580/reflections-on-strategies-for-successful-meetings-with-undergraduate-researchers-ae22306ecd8d"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sat, 4 Apr 2020 10:14:56 UT
      </pubDate>
      <guid>
        https://medium.com/@jurgens_24580/reflections-on-strategies-for-successful-meetings-with-undergraduate-researchers-ae22306ecd8d
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        http://www.cs.jhu.edu/~jason/advice/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;h2&gt;Advice for Research Students&lt;/h2&gt;

&lt;p&gt;Over the years, I've written a lot of advice for students and
  others.  Feel free to link to these pages.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href="http://www.cs.jhu.edu/~jason/advice/prospective-students.html"&gt;For prospective graduate students&lt;/a&gt;
  &lt;/li&gt;&lt;li&gt;&lt;a href="http://www.cs.jhu.edu/~jason/advice/how-to-work-with-a-professor.html"&gt;For undergrads who want to get involved in research&lt;/a&gt;
  &lt;/li&gt;&lt;li&gt;&lt;a href="http://www.cs.jhu.edu/~jason/advice/how-to-ask-for-a-recommendation.html"&gt;How to ask for a recommendation letter&lt;/a&gt;
  &lt;/li&gt;&lt;li&gt;&lt;a href="http://www.quora.com/How-do-I-study-to-get-into-a-PhD-program-of-a-top-US-university-two-years-from-now/answer/Jason-Eisner?share=1"&gt;How should I prepare myself for grad school?&lt;/a&gt;
  &lt;/li&gt;&lt;li&gt;&lt;a href="http://www.quora.com/Is-there-a-success-or-performance-gap-between-Ph-D-students-who-go-directly-from-their-undergrad-vs-those-who-take-a-few-years-to-work-in-the-field/answer/Jason-Eisner?share=1"&gt;Should I go straight to grad school?&lt;/a&gt;
  &lt;/li&gt;&lt;li&gt;&lt;a href="http://www.cs.jhu.edu/~jason/advice/how-to-interview.html"&gt;How to think about grad school interviews&lt;/a&gt;
&lt;br&gt;&amp;nbsp;
  &lt;/li&gt;&lt;li&gt;&lt;a href="http://www.quora.com/Do-professors-enjoy-answering-high-level-questions-more-than-low-level-ones/answer/Jason-Eisner?share=1"&gt;How
  to ask a question in class&lt;/a&gt;
  &lt;/li&gt;&lt;li&gt;&lt;a href="http://www.cs.jhu.edu/~jason/advice/how-to-read-a-paper.html"&gt;How to read a paper&lt;/a&gt;
  &lt;/li&gt;&lt;li&gt;&lt;a href="http://www.cs.jhu.edu/~jason/advice/how-to-present-a-paper.html"&gt;How to present a paper in reading group&lt;/a&gt;
  &lt;/li&gt;&lt;li&gt;&lt;a href="https://plus.google.com/109118176785250321075/posts/Dh79Nz6z1aU"&gt;How far to go with double-blind review&lt;/a&gt;
  &lt;/li&gt;&lt;li&gt;&lt;a href="http://www.cs.jhu.edu/~jason/advice/how-to-ta.html"&gt;How to be a teaching assistant&lt;/a&gt;
&lt;br&gt;&amp;nbsp;
  &lt;/li&gt;&lt;li&gt;&lt;a href="http://www.cs.jhu.edu/~jason/advice/how-to-organize-your-files.html"&gt;How to organize your files&lt;/a&gt;
  &lt;/li&gt;&lt;li&gt;&lt;a href="http://www.cs.jhu.edu/~jason/advice/how-to-evaluate-an-advisor.html"&gt;How to evaluate an advisor&lt;/a&gt;
  &lt;/li&gt;&lt;li&gt;How to deal with
  an &lt;a href="http://www.quora.com/How-do-I-deal-with-an-advisor-whos-biased-and-doesnt-give-you-time/answer/Jason-Eisner?share=1"&gt;unresponsive&lt;/a&gt;
  or &lt;a href="http://www.quora.com/PhD-Careers/How-can-you-make-it-up-to-a-research-advisor-who-is-ready-to-disown-you/answer/Jason-Eisner?share=1"&gt;angry&lt;/a&gt; advisor
  &lt;/li&gt;&lt;li&gt;&lt;a href="http://www.cs.jhu.edu/~jason/advice/how-to-find-research-problems.html"&gt;How to find research problems&lt;/a&gt;
&lt;br&gt;&amp;nbsp;
  &lt;/li&gt;&lt;li&gt;&lt;a href="http://www.cs.jhu.edu/~jason/advice/write-the-paper-first.html"&gt;Write the paper first&lt;/a&gt; (as an early step in the research)
  &lt;/li&gt;&lt;li&gt;&lt;a href="https://twitter.com/wittgen_ball/status/1097650012262027264"&gt;How
  to cite your own work without breaking anonymity&lt;/a&gt;
  &lt;/li&gt;&lt;li&gt;&lt;a href="http://www.cs.jhu.edu/~jason/advice/how-to-give-a-talk.html"&gt;How to prepare a talk&lt;/a&gt;
  &lt;/li&gt;&lt;li&gt;&lt;a href="https://www.quora.com/Should-I-meet-with-my-dissertation-committee-members-even-though-my-advisor-advises-against-it/answer/Jason-Eisner?share=1"&gt;How to meet with your dissertation committee&lt;/a&gt;
  &lt;/li&gt;&lt;li&gt;&lt;a href="http://www.cs.jhu.edu/~jason/advice/how-to-write-a-thesis.html"&gt;How to write up a Ph.D. dissertation&lt;/a&gt;
  &lt;/li&gt;&lt;li&gt;&lt;a href="http://www.cs.jhu.edu/~jason/advice/in-defense-of-footnotes.html"&gt;In defense of footnotes&lt;/a&gt;
  &lt;/li&gt;&lt;li&gt;&lt;a href="https://www.quora.com/Assuming-that-Ph-D-students-decide-to-apply-for-faculty-positions-how-much-should-their-research-proposal-differ-from-their-Ph-D-research/answer/Jason-Eisner?share=1"&gt;How to write an academic research statement&lt;/a&gt; (when applying for a faculty job)
  &lt;/li&gt;&lt;li&gt;&lt;a href="http://www.cs.jhu.edu/~jason/advice/how-to-chair-a-conference.html"&gt;How to serve as program chair of a conference&lt;/a&gt;
  &lt;/li&gt;&lt;li&gt;How to set up publication practices for a professional society:
    conferences/journals (&lt;a href="http://www.cs.jhu.edu/~jason/advice/ACLJournalConference-Eisner.pdf"&gt;2009&lt;/a&gt;, &lt;a href="http://www.cs.jhu.edu/~jason/advice/acl-publications.pdf"&gt;2010&lt;/a&gt;), &lt;a href="https://www.aclweb.org/adminwiki/index.php?title=ACL_Policies_for_Submission,_Review_and_Citation"&gt;preprint
  policies&lt;/a&gt; (&lt;a href="https://www.aclweb.org/adminwiki/images/e/e7/ACL_Guidelines_for_Submission%2C_Review_and_Citation.pdf"&gt;report 2017&lt;/a&gt;)
&lt;br&gt;&amp;nbsp;
  &lt;/li&gt;&lt;li&gt;&lt;a href="http://www.cs.jhu.edu/~jason/advice/massagechair.html"&gt;How to use the CLSP massage chair&lt;/a&gt;
&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;I've also
  been &lt;a href="http://www.quora.com/Jason-Eisner/answers?share=1"&gt;answering
    questions on Quora&lt;/a&gt; lately.  See also my &lt;a href="http://www.cs.jhu.edu/~jason/tutorials/"&gt;technical tutorials&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;A couple of writings that I like to recommend are Michael Nielsen's
     essay &lt;a href="https://michaelnielsen.org/blog/principles-of-effective-research/"&gt;Principles
     of Effective Research&lt;/a&gt; and Phil Agre's opus
  &lt;a href="https://homes.cs.washington.edu/~mernst/advice/agre-networking-on-the-network-20050814.html"&gt;Netwokring
     on the Network&lt;/a&gt;.  This give a high-level perspective on how to
     build a research career: Nielsen writes about cultivating your
     own thinking, and Agre writes about cultivating your
     relationships with other researchers.&lt;/p&gt;

&lt;p&gt;JHU students can also find a outdated collection of pointers to
good advice (mostly compiled by
me) &lt;a href="http://old-site.clsp.jhu.edu/wiki2/Student_Life_FAQ#How_can_I_be_a_successful_grad_student.3F"&gt;in
the CLSP FAQ&lt;/a&gt;, and a bigger
collection &lt;a href="http://web.engr.illinois.edu/~taoxie/advice.htm"&gt;here&lt;/a&gt;
compiled by Tao Xie.  And why not Google
for &lt;a href="http://www.google.com/search?num=50&amp;amp;q=career+advice+computer+science+graduate+students"&gt;&lt;code&gt;career
advice computer science graduate students&lt;/code&gt;&lt;/a&gt;?&lt;/p&gt;






&lt;p&gt;&lt;b&gt;Use your undergraduate education:&lt;/b&gt; "But you go to a great school, not
for knowledge so much as for arts and habits; for the habit of
attention, for the art of expression, for the art of assuming at a
moment's notice a new intellectual posture, for the art of entering
quickly into another person's thoughts, for the habit of submitting to
censure and refutation, for the art of indicating assent or dissent in
graduated terms, for the habit of regarding minute points of accuracy,
for the habit of working out what is possible in a given time, for
taste, for discrimination, for mental courage and mental soberness."
-William Johnson Cory (1861)&lt;/p&gt;

&lt;hr&gt;
This page online: &lt;code&gt;http://cs.jhu.edu/~jason/advice&lt;/code&gt;

 

&lt;/div&gt;&lt;a href="http://www.cs.jhu.edu/~jason/advice/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sat, 4 Apr 2020 10:15:10 UT
      </pubDate>
      <guid>
        http://www.cs.jhu.edu/~jason/advice/
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://jvns.ca/blog/debugging-attitude-matters/
      </link>
      <description>
        &lt;a href="https://jvns.ca/blog/debugging-attitude-matters/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sun, 5 Apr 2020 16:17:55 UT
      </pubDate>
      <guid>
        https://jvns.ca/blog/debugging-attitude-matters/
      </guid>
    </item>
    <item>
      <title>
        Your configs suck? Try a real programming language. | beepb00p
      </title>
      <link>
        https://beepb00p.xyz/configs-suck.html
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;
        &lt;article&gt;
    
    &lt;section id="post-title"&gt;
    
    &lt;p&gt;Or yet another rant about YAML
    &lt;/p&gt;&lt;/section&gt;
    

    &lt;section id="post-content"&gt;
    &lt;p&gt;
In this post, I'll try to explain why I find most config formats frustrating to use and
suggest that using a real programming language (i.e. general purpose one, like Python) is often (but &lt;a href="#cons"&gt;&lt;b&gt;not always&lt;/b&gt;&lt;/a&gt;) a feasible and more pleasant alternative for writing configs.
&lt;/p&gt;
&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#configs_suck"&gt;1. Most modern config formats suck&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#workarounds"&gt;2. Workarounds&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#real_language"&gt;3. Use a real programming language&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#cons"&gt;Downsides&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#why_python"&gt;Why Python?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#who_else"&gt;Who else does it?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#what_if_i_have_to"&gt;4. What if you don't have a choice?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#links"&gt;5. Extra links&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#fin"&gt;6. --&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#ps"&gt;7. &lt;span&gt;&lt;span&gt;[2020-04-11]&lt;/span&gt;&lt;/span&gt; P.S.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div&gt;
&lt;h2 id="configs_suck"&gt;&lt;a href="#configs_suck"&gt;¶&lt;/a&gt;&lt;span&gt;1&lt;/span&gt; Most modern config formats suck&lt;/h2&gt;
&lt;div&gt;
&lt;p&gt;
In this section, I'm mostly referring to JSON/YAML/TOML/ini files, which are the most common config formats I encounter.
&lt;/p&gt;
&lt;p&gt;
I'll refer to such configs as &lt;b&gt;&lt;span&gt;plain configs&lt;/span&gt;&lt;/b&gt;. Not sure if there is a better name for it, please let me know!
&lt;/p&gt;
&lt;p&gt;
An incomplete list of my frustrations:
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;JSON &lt;b&gt;doesn't have comments&lt;/b&gt;, &lt;a href="https://stackoverflow.com/a/33963845/706389"&gt;by design&lt;/a&gt; 🤯&lt;/li&gt;
&lt;li&gt;&lt;p&gt;
bits of configs &lt;b&gt;can't be reused&lt;/b&gt;
&lt;/p&gt;
&lt;p&gt;
For example, while YAML, in theory, supports reusing/including bits of the config (they call it &lt;a href="https://confluence.atlassian.com/bitbucket/yaml-anchors-960154027.html"&gt;anchors&lt;/a&gt;),
some software like &lt;a href="https://github.community/t5/GitHub-Actions/Support-for-YAML-anchors/td-p/30336/page/3"&gt;Github Actions&lt;/a&gt; doesn't support it
&lt;/p&gt;
&lt;p&gt;
Usually, you just don't have any means of reusing parts of your config and have to copy-paste.
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;.gitconfig&lt;/code&gt; uses a &lt;a href="https://git-scm.com/docs/git-config#_includes"&gt;custom syntax&lt;/a&gt; for merging the configs&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;
can't contain &lt;b&gt;any logic&lt;/b&gt;
&lt;/p&gt;
&lt;p&gt;
This is considered as a positive by many, but I would argue that when you can't define temporary variables, helper functions, substitute strings or concatenate lists, it's a bit fucked up.
&lt;/p&gt;
&lt;p&gt;
The workarounds (if present) are usually pretty horrible and impose cognitive overhead. Programming language constructs are &lt;b&gt;reinvented from scratch&lt;/b&gt;:
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;variables and string interpolation

&lt;ul&gt;
&lt;li&gt;Ansible uses &lt;a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_templating.html"&gt;Jinja templates&lt;/a&gt; (!) for variable manipulations.&lt;/li&gt;
&lt;li&gt;&lt;p&gt;
Github Actions use a &lt;a href="https://help.github.com/en/actions/reference/context-and-expression-syntax-for-github-actions"&gt;custom syntax&lt;/a&gt; for that
&lt;/p&gt;
&lt;p&gt;
In addition, they've got &lt;a href="https://help.github.com/en/actions/reference/context-and-expression-syntax-for-github-actions#functions"&gt;their own&lt;/a&gt; set of functions to manipulate the variables.
Have fun learning a new language you never wanted to!
&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;
scoping
&lt;/p&gt;
&lt;p&gt;
I.e. there are several custom scopes for &lt;a href="https://help.github.com/en/actions/reference/workflow-syntax-for-github-actions#env"&gt;&lt;samp&gt;env&lt;/samp&gt; directive&lt;/a&gt; in Github Actions.
&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;control flow

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;for&lt;/code&gt; loop: build matrices and 'excludes' always give me a headache&lt;/li&gt;
&lt;li&gt;&lt;code&gt;if&lt;/code&gt; statement: e.g. &lt;a href="https://circleci.com/docs/2.0/configuration-reference/#the-when-step-requires-version-21"&gt;&lt;samp&gt;when&lt;/samp&gt;&lt;/a&gt; in CircleCI&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
&lt;a href="https://blog.atomist.com/in-defense-of-yaml"&gt;"This is not structured data. This is programming masquerading as configuration."&lt;/a&gt;
&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;
can't be validated
&lt;/p&gt;
&lt;p&gt;
You can validate the config syntax itself (i.e. check JSON for correctness), but if you want more sophisticated semantic checks, you need to spend extra effort.
&lt;/p&gt;
&lt;p&gt;
This is kind of a consequence of not having logic in the config files.
Typically you'll have to write a supplementary program to check your configs and remember to call it before passing to a program.
&lt;/p&gt;
&lt;p&gt;
Very few programs bother with that. Usually, your program crashes because of something that would be &lt;b&gt;trivial to catch with any simple type system&lt;/b&gt;.
&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;
YAML simply stands out with its implicit conversions and portability issues (e.g. "The NOrway Problem")
&lt;/p&gt;
&lt;p&gt;
There are enough rants about it, so I'll just leave a link to a good one: &lt;a href="https://www.arp242.net/yaml-config.html"&gt;"YAML: probably not so great after all"&lt;/a&gt;.
&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
Summary: we spend time learning &lt;b&gt;useless syntax and reinventing programming constructs, instead of productive work&lt;/b&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div&gt;
&lt;h2 id="workarounds"&gt;&lt;a href="#workarounds"&gt;¶&lt;/a&gt;&lt;span&gt;2&lt;/span&gt; Workarounds&lt;/h2&gt;
&lt;div&gt;
&lt;p&gt;
So what happens when people encounter these problems?
Often they end up using a 'real' (i.e. general purpose, Turing complete) programming language anyway:
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;you write a program to filter out custom comment syntax&lt;/li&gt;
&lt;li&gt;you write a program to merge configs or use a templating engine&lt;/li&gt;
&lt;li&gt;&lt;p&gt;
you write a program that 'evaluates' the config
&lt;/p&gt;
&lt;p&gt;
Often, you &lt;b&gt;end up reimplementing an interpreter&lt;/b&gt; for a simple functional language in the process.
&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;
you write a program to validate the config
&lt;/p&gt;
&lt;p&gt;
For the most part, it's boilerplate for type checking. You're not only working on a solved problem but in addition, end up with mediocre error messages as a result.
&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
All this stuff is unpleasant and distracts you from your main objective.
&lt;/p&gt;
&lt;p&gt;
Perhaps you can see where I'm coming with this.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div&gt;
&lt;h2 id="real_language"&gt;&lt;a href="#real_language"&gt;¶&lt;/a&gt;&lt;span&gt;3&lt;/span&gt; Use a real programming language&lt;/h2&gt;
&lt;div&gt;
&lt;p&gt;
The idea is to write your config in your target programming language.
I'll have Python in mind here, but the same idea can be applied to &lt;b&gt;any dynamic enough language&lt;/b&gt; (e.g. Javascript/Ruby).
&lt;/p&gt;
&lt;p&gt;
Then, you simply import/evaluate your config file and voila – you're done. That's it.
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;
Toy example:
&lt;/p&gt;
&lt;p&gt;
&lt;samp&gt;config.py&lt;/samp&gt;
&lt;/p&gt;
&lt;div&gt;
&lt;pre&gt;&lt;span&gt;from&lt;/span&gt; typing &lt;span&gt;import&lt;/span&gt; NamedTuple

&lt;span&gt;class&lt;/span&gt; &lt;span&gt;Person&lt;/span&gt;(NamedTuple):
    name: &lt;span&gt;str&lt;/span&gt;
    age: &lt;span&gt;int&lt;/span&gt;

&lt;span&gt;PEOPLE&lt;/span&gt; = [
    Person(&lt;span&gt;'Ann'&lt;/span&gt;  , 22),
    Person(&lt;span&gt;'Roger'&lt;/span&gt;, 15),
    Person(&lt;span&gt;'Judy'&lt;/span&gt; , 49),
]
&lt;/pre&gt;
&lt;/div&gt;

&lt;div&gt;
&lt;pre&gt;&lt;span&gt;from&lt;/span&gt; pathlib &lt;span&gt;import&lt;/span&gt; Path

&lt;span&gt;config&lt;/span&gt; = {}
&lt;span&gt;exec&lt;/span&gt;(Path(&lt;span&gt;'config.py'&lt;/span&gt;).read_text(), config)
&lt;span&gt;people&lt;/span&gt; = config[&lt;span&gt;'PEOPLE'&lt;/span&gt;]

&lt;span&gt;print&lt;/span&gt;(people)
&lt;/pre&gt;
&lt;/div&gt;
&lt;pre&gt;[Person(name='Ann', age=22), Person(name='Roger', age=15), Person(name='Judy', age=49)]
&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
I find it pretty neat.
Let's see how it helps us with the problems I described:
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;comments: duh&lt;/li&gt;
&lt;li&gt;&lt;p&gt;
includes: trivial, use imports
&lt;/p&gt;
&lt;p&gt;
You can even import the very package you're configuring.
So you can define a DSL for configuration, which will be imported and used in the config file.
&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;
logic
&lt;/p&gt;
&lt;p&gt;
You have your language's syntax and libraries available to use.
For example, something like &lt;a href="https://docs.python.org/3/library/pathlib.html"&gt;&lt;samp&gt;pathlib&lt;/samp&gt;&lt;/a&gt; alone can save you massive amounts of config duplication.
&lt;/p&gt;
&lt;p&gt;
Of course, one could go crazy and make it incomprehensible.
But personally I'd rather accept potential for abusing the power of the language rather than being restricted.
&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;
validation
&lt;/p&gt;
&lt;p&gt;
You can keep validation logic right in the config, so it would be checked at the time of loading.
Mature static analysis tools (i.e. JS flow/eslint/pylint/mypy) can be used to aid you.
&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div&gt;
&lt;h3 id="cons"&gt;&lt;a href="#cons"&gt;¶&lt;/a&gt;Downsides&lt;/h3&gt;
&lt;div&gt;
&lt;p&gt;
Are there any problems with that approach? Sure:
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;
interoperability
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;
Okay, maybe if your program is in Python it makes sense. But what if it isn't, or you'll rewrite it to another language (i.e. compiled, like c++) later.
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;
If you'll be running your software somewhere without an interpreter, then sure, good point.
Modern &lt;a href="https://en.wikipedia.org/wiki/Foreign_function_interface"&gt;FFI&lt;/a&gt; is tedious and linking against your config is going to be pretty tricky.
&lt;/p&gt;
&lt;p&gt;
In case of Python specifically, it's present in most modern OS distributions. So you might get away with the following:
&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;make your Python config executable&lt;/li&gt;
&lt;li&gt;&lt;p&gt;
in the &lt;samp&gt;main()&lt;/samp&gt; function, build the config, convert to JSON and dump to the stdout
&lt;/p&gt;
&lt;p&gt;
This step is possible with no boilerplate due to Python's dynamic nature.
&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;in your c++ code, execute the Python config (i.e. use &lt;code&gt;popen()&lt;/code&gt;), read the raw JSON and process&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
Yep, you will still have to manually deserialize config in the c++ code. But I think that's at least &lt;b&gt;not worse&lt;/b&gt; than only using JSON and editing it manually.
&lt;/p&gt;
&lt;p&gt;
Obviously that has a performance hit (i.e. milliseconds taken to run the Python interpreter). Make your own judgment whether it's acceptable for you.
If the tool you're configuring is running for hours, you're probably going to be fine, or you can always generate the config in advance/cache.
&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;
general-purpose programming languages are &lt;b&gt;harder to reason about&lt;/b&gt;
&lt;/p&gt;
&lt;p&gt;
This is somewhat subjective. Personally, I'd be more likely overwhelmed by an overly verbose plain config. I'd always prefer a neat and compact DSL.
&lt;/p&gt;
&lt;p&gt;
A large factor here is code style: I'm sure you can make your config file readable in almost any programming language,
even for people not familiar with the language at all.
&lt;/p&gt;
&lt;p&gt;
However, I appreciate that my experience is different from other engineers (i.e. sysadmins) who would not trade off flexibility for the increase of configuration complexity.
&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;
general-purpose languages are &lt;b&gt;hard to modify programmatically&lt;/b&gt;
&lt;/p&gt;
&lt;p&gt;
To some extent it overlaps with the previous point.
For example, &lt;samp&gt;git config&lt;/samp&gt; commands manipulates the &lt;samp&gt;.git/config&lt;/samp&gt; file.
It's easy to modify an INI file, because it's basically a dictionary, so you only have to locate the key in the config file and change a single line.
&lt;/p&gt;
&lt;p&gt;
If the config is (say) a Python program, the model can be much more complicated than a dictionary, and it might be tricky to modify settings programmatically.
Most likely, you'll have to resort to only appending new code to the config, which may not always be enough.
&lt;/p&gt;
&lt;p&gt;
To me, it's a very strong point against code as a config. As counter-points:
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;not many programs have (or need) TUI/GUI for editing settings&lt;/li&gt;
&lt;li&gt;&lt;p&gt;
the settings that belong to the UI are usually very simple, and possible to adjust by appending only
&lt;/p&gt;
&lt;p&gt;
For example, Emacs customization interface is &lt;a href="https://www.gnu.org/software/emacs/manual/html_node/emacs/Saving-Customizations.html"&gt;backed by an Elisp config&lt;/a&gt;.
&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
&lt;a id="security"&gt;&lt;/a&gt;The most serious issues are probably security and termination checking:
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;
security
&lt;/p&gt;
&lt;p&gt;
I.e. if your config executes arbitrary code, then it may steal your passwords or format your hard drive.
&lt;/p&gt;
&lt;p&gt;
Whether security is actually something you need to think about &lt;b&gt;depends on your threat model&lt;/b&gt;:
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;if your configs are supplied by third parties you don't trust, then I agree that plain configs are safer.&lt;/li&gt;
&lt;li&gt;&lt;p&gt;
however, often, especially for end-user software, it's not the case
&lt;/p&gt;
&lt;p&gt;
Often the user controls their own config, and the program runs under the same permissions.
&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
In addition, this is something that can be potentially solved by sandboxing. Whether it's worth the effort depends on the nature of your project, but for something like CI executor &lt;b&gt;you need a sandbox anyway&lt;/b&gt;.
&lt;/p&gt;
&lt;p&gt;
Also, note that using a plain config format doesn't necessarily save you from trouble. See &lt;a href="https://www.arp242.net/yaml-config.html#insecure-by-default"&gt;"YAML: insecure by default"&lt;/a&gt;.
&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;
termination checking
&lt;/p&gt;
&lt;p&gt;
Even if you don't care about security, you don't want your config to hang the program.
&lt;/p&gt;
&lt;p&gt;
Personally, I've never run into such issues, but here are some potential workarounds for that:
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;explicit timeout for loading the config&lt;/li&gt;
&lt;li&gt;&lt;p&gt;
using a subset of the language might help, for example, &lt;a href="https://docs.bazel.build/versions/master/skylark/language.html#differences-with-python"&gt;Skylark&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;
Anyone knows examples of /conservative/static analysis tools that check for termination in general purpose languages?
&lt;/p&gt;
&lt;p&gt;
Note this is not the same as the &lt;a href="https://en.wikipedia.org/wiki/Halting_problem"&gt;Halting problem&lt;/a&gt;. You don't want to determine whether &lt;b&gt;any&lt;/b&gt; program terminates, you want to figure out a
&lt;b&gt;reasonable subset of the language&lt;/b&gt; that terminates.
&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
Even if your config language is Turing incomplete, you might have to resort to using timeouts anyway:
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;
your config can take &lt;b&gt;very&lt;/b&gt; long time to evaluate, while taking finite time to complete in theory
&lt;/p&gt;
&lt;p&gt;
See &lt;a href="http://www.haskellforall.com/2020/01/why-dhall-advertises-absence-of-turing.html"&gt;"Why Dhall advertises the absence of Turing-completeness"&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;
While an &lt;a href="https://gist.github.com/Gabriel439/77f715350ecc0443eed5fa613ac6b78e"&gt;Ackermann&lt;/a&gt; function is a contrived example,
that means that if you truly care about malicious inputs, you want to sandbox anyway.
If your configs support some form of including, you can &lt;a href="https://lobste.rs/s/qyhvhc/your_configs_suck_try_real_programming#c_rtbmnp"&gt;very likely&lt;/a&gt; construct an input that will inflate it
exponentially.
&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
Note that using a plain config doesn't mean it won't loop infinitely:
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;See &lt;a href="https://www.gwern.net/Turing-complete#accidentally-turing-complete"&gt;"Accidentally Turing complete"&lt;/a&gt; for an excellent overview&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div&gt;
&lt;h3 id="why_python"&gt;&lt;a href="#why_python"&gt;¶&lt;/a&gt;Why Python?&lt;/h3&gt;
&lt;div&gt;
&lt;p&gt;
Some reasons I find Python specifically enjoyable for writing config files:
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Python is present on almost all modern operating systems&lt;/li&gt;
&lt;li&gt;Python syntax is considered simple (not a bad thing!), so hopefully Python configs aren't much harder to understand than plain configs&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.python.org/3/library/dataclasses.html"&gt;data classes&lt;/a&gt;, functions and generators form a basis for a compact DSL&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.python.org/3/library/typing.html"&gt;typing annotations&lt;/a&gt; serve as documentation and validation at the same time&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
However, you can achieve a similarly pleasant experience in &lt;b&gt;most modern programming languages&lt;/b&gt; (provided they are dynamic enough).
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div&gt;
&lt;h3 id="who_else"&gt;&lt;a href="#who_else"&gt;¶&lt;/a&gt;Who else does it?&lt;/h3&gt;
&lt;div&gt;
&lt;p&gt;
Some projects that allow for using code as configuration:
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://webpack.js.org/configuration"&gt;Webpack&lt;/a&gt;, web asset bundler, uses a Javascript as a config&lt;/li&gt;
&lt;li&gt;&lt;p&gt;
&lt;a href="https://setuptools.readthedocs.io/en/latest/setuptools.html#basic-use"&gt;setuptools&lt;/a&gt;, the standard way of installing Python packages
&lt;/p&gt;
&lt;p&gt;
Allows using &lt;b&gt;both&lt;/b&gt; &lt;samp&gt;setup.cfg&lt;/samp&gt; and &lt;samp&gt;setup.py&lt;/samp&gt; files.
That way if you can't achieve something solely with plain config, you can fix this in &lt;samp&gt;setup.py&lt;/samp&gt;, which gives you a balance between declarative and flexible.
&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;
&lt;a href="https://jupyter.org/"&gt;Jupiter&lt;/a&gt;, interactive computing tool
&lt;/p&gt;
&lt;p&gt;
Uses a &lt;a href="https://github.com/jupyter/jupyter_core/blob/master/jupyter_core/tests/dotipython_empty/profile_default/ipython_nbconvert_config.py"&gt;python file&lt;/a&gt; to configure the export.
&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;
&lt;a href="https://www.gnu.org/software/emacs"&gt;Emacs&lt;/a&gt;: famously uses Elisp for its configuration
&lt;/p&gt;
&lt;p&gt;
While I'm not a fan of Elisp at all, it does make Emacs very flexible and it's possible to achieve any configuration you want.
&lt;/p&gt;
&lt;p&gt;
On the other hand, if you've ever read other people's Emacs setups, you can see it also demonstrates how things can get out of hand when you allow
a general purpose language for configuration.
&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/brookhong/Surfingkeys#edit-your-own-settings"&gt;Surfingkeys&lt;/a&gt; browser extension: uses a Javascript DSL for configuration&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.gradle.org/current/userguide/tutorial_using_tasks.html#sec:build_scripts_are_code"&gt;Gradle&lt;/a&gt; provides Groovy and Kotlin DSLs for writing build files&lt;/li&gt;
&lt;li&gt;&lt;a href="https://awesomewm.org/"&gt;Awesome Window Manager&lt;/a&gt; uses Lua for configuration&lt;/li&gt;
&lt;li&gt;&lt;a href="https://guix.gnu.org/"&gt;Guix&lt;/a&gt; package manager: uses &lt;a href="https://www.gnu.org/software/guile"&gt;Guile Scheme&lt;/a&gt; for configuration&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/getpelican/pelican"&gt;Pelican&lt;/a&gt; static site generator: uses &lt;a href="https://raw.githubusercontent.com/getpelican/pelican/master/samples/pelican.conf.py"&gt;Python&lt;/a&gt; for configuration&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
Some languages are designed specifically for configuration:
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;
&lt;a href="https://docs.bazel.build/versions/master/skylark/language.html#differences-with-python"&gt;&lt;del&gt;Bazel&lt;/del&gt; Skylark&lt;/a&gt; uses a subset of Python for describing build rules
&lt;/p&gt;
&lt;p&gt;
While it's deliberately restricted to ensure termination checking and determinism, configuring Bazel is orders of magnitude more pleasant than any other build system I've used.
&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mesonbuild.com/Syntax.html"&gt;Meson build system&lt;/a&gt;: borrows the syntax from Python&lt;/li&gt;
&lt;li&gt;&lt;p&gt;
&lt;a href="https://nixos.wiki/wiki/Nix_Expression_Language"&gt;Nix&lt;/a&gt;: language designed specifically for the Nix package manager
&lt;/p&gt;
&lt;p&gt;
While a completely new language feels like an overkill, it's still nicer to work with than plain configs.
&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;
&lt;a href="https://dhall-lang.org/"&gt;Dhall&lt;/a&gt;: language designed specifically for config files
&lt;/p&gt;
&lt;p&gt;
Dhall advertises itself as "JSON + functions + types + imports". And indeed, it looks great, and solves most of the issues I listed.
&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;
&lt;a href="https://jsonnet.org/"&gt;Jsonnet&lt;/a&gt;: JSON + variables + control flow
&lt;/p&gt;
&lt;p&gt;
See &lt;a href="https://jsonnet.org/articles/comparisons.html"&gt;comparison&lt;/a&gt; with other configuration languages
&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
Downsides of such languages is that they aren't widespread yet. If you don't have bindings for your target language, you'd end up parsing JSON again.
However, at least it makes writing configs pleasant.
&lt;/p&gt;
&lt;p&gt;
But again, if your program is written in Javascript and doesn't interact with other languages, why don't you just make the config Javascript?
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div&gt;
&lt;h2 id="what_if_i_have_to"&gt;&lt;a href="#what_if_i_have_to"&gt;¶&lt;/a&gt;&lt;span&gt;4&lt;/span&gt; What if you don't have a choice?&lt;/h2&gt;
&lt;div&gt;
&lt;p&gt;
Some ways I've found to minimize the frustration while using plain configs:
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;
write as little in config files as possible
&lt;/p&gt;
&lt;p&gt;
This typically applies to CI pipeline configs (i.e. Gitlab/Circle/Github Actions) or Dockerfiles.
&lt;/p&gt;
&lt;p&gt;
Often such configs are &lt;b&gt;bloated with shell commands&lt;/b&gt;, which makes it impossible to run locally without copying line by line.
And yeah, there &lt;a href="https://circleci.com/docs/2.0/local-cli"&gt;are&lt;/a&gt; &lt;a href="https://github.com/nektos/act"&gt;ways&lt;/a&gt; to debug, but they have a pretty slow feedback loop.
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;use tools that are better suited to set up local virtual environments, like &lt;a href="https://github.com/tox-dev/tox"&gt;tox-dev/tox&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;
prefer helper shell scripts and call them from your pipeline
&lt;/p&gt;
&lt;p&gt;
It is a bit frustrating since it introduces indirection and scatters code around.
But, as an upside, you can lint (e.g. &lt;a href="https://www.shellcheck.net/"&gt;shellcheck&lt;/a&gt;) your pipeline scripts, and make it easier to run locally.
&lt;/p&gt;
&lt;p&gt;
Sometimes you can get away if your pipeline is short, so use your own judgment.
&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
Let the CI only handle setting up a VM/container for you, caching the dependencies, and publishing artifacts.
&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;
generate the config instead of writing manually
&lt;/p&gt;
&lt;p&gt;
The downside is that the generated config may diverge if edited manually.
&lt;/p&gt;
&lt;p&gt;
You can add the warning comment that the config is autogenerated with the link to the generator, and make the config file read-only to discourage manual editing.
&lt;/p&gt;
&lt;p&gt;
In addition, if you're running CI, you can make the consistency check a part of the pipeline itself.
&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div&gt;
&lt;h2&gt;&lt;a href="#links"&gt;¶&lt;/a&gt;&lt;span&gt;5&lt;/span&gt; Extra links&lt;/h2&gt;
&lt;div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;
&lt;a href="https://www.arp242.net/flags-config.html"&gt;(commandline) flags are great for configuration&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;
Overall, I agree, but there are still cases when using flags isn't feasible.
&lt;/p&gt;
&lt;p&gt;
It's also prone to leaking secrets (keys/tokens/passwords) – both in your shell history and via &lt;samp&gt;ps&lt;/samp&gt;.
&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;
&lt;a href="https://wiki.archlinux.org/index.php/Xmonad#Configuration"&gt;Xmonad&lt;/a&gt;: config &lt;b&gt;is&lt;/b&gt; the executable
&lt;/p&gt;
&lt;p&gt;
Interesting approach, but not always feasible, e.g. you might not have the compiler installed.
&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/magefile/mage#about"&gt;Mage&lt;/a&gt;: a tool for writing makefiles in Go&lt;/li&gt;
&lt;li&gt;Dhall wiki: &lt;a href="https://github.com/dhall-lang/dhall-lang/wiki/Programmable-configuration-files"&gt;Programmable configuration files&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://news.ycombinator.com/item?id=19108787"&gt;Why are we templating YAML? (HN)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
&lt;b&gt;Updates&lt;/b&gt; from the comments (thanks everyone!):
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.lua.org/history.html"&gt;The evolution of an extension language: a history of Lua&lt;/a&gt;: apparently Lua has started as a config language&lt;/li&gt;
&lt;li&gt;&lt;p&gt;
&lt;a href="https://news.ycombinator.com/item?id=20847943"&gt;Cue&lt;/a&gt;:  A language for defining, generating, and validating data
&lt;/p&gt;
&lt;p&gt;
I've &lt;b&gt;really&lt;/b&gt; struggled to find a code example on the website, so &lt;a href="https://github.com/cuelang/cue/blob/master/doc/tutorial/kubernetes/README.md"&gt;here you go&lt;/a&gt;.
&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://news.ycombinator.com/item?id=14298715"&gt;The configuration complexity clock&lt;/a&gt;: a case for hard-coding&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div&gt;
&lt;h2 id="fin"&gt;&lt;a href="#fin"&gt;¶&lt;/a&gt;&lt;span&gt;6&lt;/span&gt; --&lt;/h2&gt;
&lt;div&gt;
&lt;p&gt;
A followup question, which I don't have an answer for: why is it that way?
I'm sure Ansible/CircleCI or Github Actions are developed by talented engineers who have considered pros and cons of using YAML.
Do the pros really outweigh the cons?
&lt;/p&gt;
&lt;p&gt;
Open to all feedback, and feel free to share your config pain and how are you solving it!
&lt;/p&gt;
&lt;p&gt;
&lt;b&gt;Updates&lt;/b&gt;:
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span&gt;&lt;span&gt;[2020-04-11]&lt;/span&gt;&lt;/span&gt; Added P.S. section&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div&gt;
&lt;h2 id="ps"&gt;&lt;a href="#ps"&gt;¶&lt;/a&gt;&lt;span&gt;7&lt;/span&gt; &lt;span&gt;&lt;span&gt;[2020-04-11]&lt;/span&gt;&lt;/span&gt; P.S.&lt;/h2&gt;
&lt;div&gt;
&lt;p&gt;
Thanks everyone for the discussions and comments!
&lt;/p&gt;
&lt;p&gt;
There were some polar opinions involved, so I'd like to clarify the most common objections here:
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;
"Programs as a config are a security nightmare"
&lt;/p&gt;
&lt;p&gt;
I admit that I have a programmer's mindset (as opposed to sysadmin's), and very likely underestimate the security risks.
&lt;/p&gt;
&lt;p&gt;
But again, &lt;a href="#security"&gt;I agree&lt;/a&gt; that executable configs are &lt;b&gt;not always&lt;/b&gt; a good idea.
You can still have the best of both worlds by providing a DSL for generating a plain config and consuming the plain config.
&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;
"If your config is a program, it might end up arbitrarily complex and incomprehensible"
&lt;/p&gt;
&lt;p&gt;
Sure, but again, it largely depends on the discipline. You can also make a plain config incomprehensible and hard to modify.
&lt;/p&gt;
&lt;p&gt;
The best compromise here is probably configuration languages like Dhall.
&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;
"What happens in 20 years, when there is no &amp;lt;insert programming language&amp;gt; around"
&lt;/p&gt;
&lt;p&gt;
That's a good point, but languages don't disappear in an eye blink. There will be plenty of time to adapt.
In addition, if your software and config are written in the same language, the software will need to be rewritten anyway, which is a bigger problem.
&lt;/p&gt;
&lt;p&gt;
Also even plain config formats come and go. 20 years ago XML was common for configuration; how many times you've seen it lately?
Does your programming language even include XML parser in the standard library?
&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;
"If your config is so complex you need a DSL, your design has gone wrong and your software sucks"
&lt;/p&gt;
&lt;p&gt;
Frankly, I've found many of such comments as very opinionated and not constructive, but I'll try to respond.
&lt;/p&gt;
&lt;p&gt;
Software comes in very different shapes and while having the simplest configuration possible is desirable (ideally, none!),
 sometimes it would change the very nature of the thing you're trying to develop. Sure, you can stop calling it 'software' and start calling a 'library'
 at this point, but I don't feel it changes the point of the discussion.
&lt;/p&gt;
&lt;p&gt;
Perhaps, my constructive takeaways from this argument would be:
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;
think how flexible your configuration might have to be, and whether you need to give up on plain configs early
&lt;/p&gt;
&lt;p&gt;
A good example of this would be some mail filtering systems, that started simple and ended as Turing complete.
&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;
in the rapid development phase, resort to having a flexible config
&lt;/p&gt;
&lt;p&gt;
&lt;b&gt;When/if&lt;/b&gt; your software matures, think about supporting plain configs or/and using a special configuration language.
&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;

    &lt;/section&gt;

    
    
    

    
    &lt;section id="post-discussion"&gt;
    
    &lt;p&gt;Discussion:&lt;/p&gt;
    &lt;ul&gt;
        &lt;li&gt;&lt;a href="https://news.ycombinator.com/item?id=22787332"&gt;hackernews&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href="https://lobste.rs/s/qyhvhc/your_configs_suck_try_real_programming"&gt;lobsters&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
    

    
&lt;/section&gt;&lt;/article&gt;
    &lt;/div&gt;&lt;/div&gt;&lt;a href="https://beepb00p.xyz/configs-suck.html"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sun, 5 Apr 2020 16:19:47 UT
      </pubDate>
      <guid>
        https://beepb00p.xyz/configs-suck.html
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        http://250bpm.com/blog:158
      </link>
      <description>
        &lt;a href="http://250bpm.com/blog:158"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sun, 5 Apr 2020 22:30:07 UT
      </pubDate>
      <guid>
        http://250bpm.com/blog:158
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        http://www.cs.jhu.edu/~jason/advice/how-to-work-with-a-professor.html
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;
&lt;h4&gt;by Jason Eisner (2012)&lt;/h4&gt;


&lt;h2&gt;Summary&lt;/h2&gt;

&lt;p&gt;This is a bit of advice for lucky students who get to do research
with a professor.&lt;/p&gt;

&lt;p&gt;Take this opportunity seriously.  Either you make it your top
priority, or you don't do it at all.  That's the message.  Read the
rest of the page if you want to know why and how.&lt;/p&gt;

&lt;h2&gt;Why This Webpage?&lt;/h2&gt;

&lt;p&gt;I'd find it awkward to say these things directly to a nice undergrad
or master's student I was starting to work with.  It would feel like talking down to them,




whereas I like my research collaborators—however junior—to
talk with me comfortably as equals, have fun, and come up with half
the ideas.&lt;/p&gt;

&lt;p&gt;Still, it's important to understand up front what the pressures are
  on faculty-student collaborations.  So here are some things to bear
  in mind.&lt;/p&gt;

&lt;h2&gt;How the Professor Sees It&lt;/h2&gt;

&lt;blockquote id="sexchange"&gt;&lt;i&gt;[If the professor is female/male, click &lt;u&gt;here&lt;/u&gt;.]&lt;/i&gt;&lt;/blockquote&gt;

&lt;p&gt;Your research advisor doesn't get much credit for working with
junior students, and would find it easier and safer to work with
senior students.  It's just that someone gave &lt;i&gt;him/her&lt;/i&gt; a chance
once: that's how he/she ended up where he/she is today.  He/She'd like
to pay that debt forward.&lt;/p&gt;

&lt;p&gt;But should it be paid forward to &lt;i&gt;you&lt;/i&gt;?  Choosing you
  represents a substantial commitment on your advisor's part, and a
  vote of confidence in you.&lt;/p&gt;

&lt;h3&gt;Time Investment&lt;/h3&gt;

&lt;p&gt;The hours that your advisor spends with you, one-on-one, are hours that
he/she no longer has available for&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt; retaining the semblance of a plausible life (sleeping / eating / parenting / avoiding divorce)
&lt;/li&gt;&lt;li&gt; consulting at rates of hundreds of dollars per hour
&lt;/li&gt;&lt;li&gt; preparing for class
&lt;/li&gt;&lt;li&gt; working on research with other students (grad or undergrad) or by himself/herself
&lt;/li&gt;&lt;li&gt; staying current with the latest papers and techniques in the field
&lt;/li&gt;&lt;li&gt; discharging many administrative and reviewing responsibilities
&lt;/li&gt;&lt;li&gt; writing grant proposals to keep his/her Ph.D. students funded
&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;So he/she does expect that you'll pay him/her back, by working as hard as he/she
did when he/she got his/her chance.&lt;/p&gt;

&lt;h3&gt;Research Agenda Investment&lt;/h3&gt;

&lt;p&gt;Your advisor is not only devoting time to you, but taking a risk.  You
are being entrusted with part of his/her research agenda.  The goal is to
make new discoveries and publish them on schedule.  If you drop the
ball, then your advisor and others in the lab will miss important
publication deadlines, or will get scooped by researchers elsewhere,
or will be unable to take the next step that was depending on you.&lt;/p&gt;



&lt;p&gt;So, don't start doing research with the idea that it's something
"extra" that may or may not work out.  This is not an advanced course
that you can just drop or do poorly in.  Unless your advisor agrees
otherwise, you are a critical player in the mission—you have a
responsibility not to let others down.  Remember, someone is taking
a chance on you.&lt;/p&gt;

&lt;h3&gt;Opportunity Cost&lt;/h3&gt;

&lt;p&gt;I heard once that your boyfriend or girlfriend will ask increasingly
tough questions as your relationship ages:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;"Am I getting something out of it?"
&lt;/li&gt;&lt;li&gt;"Am I getting back as much as I'm putting in?"
&lt;/li&gt;&lt;li&gt;"Am I getting as much as I'm worth?"
&lt;/li&gt;&lt;/ol&gt;

&lt;p&gt;Your advisor may also ask these questions.  At first, he/she'll be happy
that he/she attracted a smart student to work on a problem that needed
working on.  But he/she may sour if he/she comes to feel that he/she's wasting his/her
time on you, or would have been wiser to assign the project to someone
else.&lt;/p&gt;

&lt;h2&gt;What Do You Get Out Of It?&lt;/h2&gt;

&lt;p&gt;You too are giving up time from your other activities (including classwork!)
to do this.  So what do you get out of it?&lt;/p&gt;

&lt;p&gt;Most important, you get research experience.  This is &lt;b&gt;exceptionally
important&lt;/b&gt; if you are considering doing a Ph.D.&lt;/p&gt;

&lt;ul&gt;

&lt;li&gt;&lt;p&gt;The Ph.D. puts you on a track to focus on research for the next
5+ years and possibly for your whole life.  Are you sure you want to
get married to research?  Maybe, but try dating research first before you
commit.&lt;/p&gt;

&lt;/li&gt;&lt;li&gt;&lt;p&gt;Ph.D. programs are &lt;a href="http://www.cs.jhu.edu/~jason/advice/prospective-students.html#criteria"&gt;looking
for students&lt;/a&gt; who are already proven researchers.  Grades are not
so strongly correlated with research success.  The &lt;b&gt;most crucial&lt;/b&gt;
part of your application is letters from one or more credible faculty
who can attest—with lots of supporting detail—that you
have the creativity, intelligence, enthusiasm, productivity, technical
background, and interpersonal and intrapersonal skills to do a great Ph.D.
with your future advisor.&lt;/p&gt;

&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;A good friend of mine in college was taken under the wing of a
senior professor in a different department.  She was a demanding
taskmaster, and my friend ended up spending much more time working in
her lab than he expected.  But it changed his life.  She insisted that
he apply to grad school in her field, and
she &lt;a href="http://www.cs.jhu.edu/~jason/advice/how-to-ask-for-a-recommendation.html"&gt;got him
accepted&lt;/a&gt; to a top Ph.D. program.  He became a professor and is now
the chairman of a department at a highly respected school, where he
enjoys doing research with his own undergraduates.&lt;/p&gt;

&lt;p&gt;Even if you are not considering a Ph.D., you will learn a great deal
from working closely with a professor.  Often you may be working with
the world's leading expert on a particular topic—that's the main criterion for tenure here.  (So our tenured
faculty have passed this bar at some point, and most of our untenured
faculty are successfully building a case that they will do so.)&lt;/p&gt;

&lt;p&gt;Students don't always realize how respected and innovative our faculty
are within their own subfields, but that's why you chose to attend a
highly-ranked &lt;i&gt;research&lt;/i&gt; university.  Your advisor may or may not
be a great classroom teacher, but he/she has shown himself/herself to be extremely
good at working with graduate students to produce papers that advance
the field.  What you'll learn from doing that is quite different from
what you'll learn in the classroom.&lt;/p&gt;

&lt;a name="succeed"&gt;
&lt;h2&gt;What You Can Do to Succeed&lt;/h2&gt;

&lt;p&gt;Here's some basic advice targeted at &lt;i&gt;new&lt;/i&gt; research students.
There are also many webpages about how to be a "good grad student,"
which should also be useful to undergrads doing research.&lt;/p&gt;

&lt;/a&gt;&lt;a name="time"&gt;
&lt;h3&gt;Time Commitment&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;i&gt;Make plenty of room.&lt;/i&gt; In order to make research your
    first priority, you may need to reduce your courseload or
    extracurriculars.  This is worth discussing with both your
    academic advisor and your research advisor.&lt;/p&gt;

&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;i&gt;Find out what the deadlines are.&lt;/i&gt;  For example, there may
    be a target for submitting a paper to a particular conference.
    When planning for deadlines, bear in mind that everything will
    take twice as long as you expect—or four times as long if
    you've never done it before.  Often a paper takes roughly a year
    of work for a grad student (if it includes experiments), although
    they may be working on other things during that year as well.&lt;/p&gt;

&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;i&gt;Be honest.&lt;/i&gt;  If you suspect that you may not have time to
    do justice to the project after all, don't string your advisor
    along.  Take a deep breath, apologize, and explain the situation.
    Then your advisor can make an informed decision about whether to
    suspend the project, give it to someone else, get a grad student
    involved, etc.  This is better than a slow burn of agitation on
    both sides.&lt;/p&gt;
&lt;/li&gt;&lt;/ul&gt;

&lt;/a&gt;&lt;a name="timemanagement"&gt;
&lt;h3&gt;Time Management&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;i&gt;Prepare for meetings.&lt;/i&gt;  Establish a fixed time for weekly
    meetings with your advisor (and perhaps with senior students).
    Bring results, questions, and an agenda to your weekly meeting.

&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;i&gt;Make weekly progress.&lt;/i&gt;  Set goalposts, and be sure you
    make real progress from week to week.  Use your meeting time or email
    each week to make sure that you agree on what the goal for next
    week is.&lt;/p&gt;

&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;i&gt;Take the initiative.&lt;/i&gt;  Be somewhat
    self-directed—find readings, play around with code, do
    mini-experiments.  But do keep your advisor posted by email.
&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;

&lt;/a&gt;&lt;a name="writing"&gt;
&lt;h3&gt;Writing&lt;/h3&gt;

Writing is a form of thinking, a form of memory, and a form of
communication.  You should keep well-organized notes of several kinds.
It is often useful to date your entries in such files and to keep them
under version control.

&lt;/a&gt;&lt;ul&gt;&lt;a name="writing"&gt;
&lt;/a&gt;&lt;li&gt;&lt;a name="writing"&gt;&lt;/a&gt;&lt;p&gt;&lt;a name="writing"&gt;&lt;i&gt;"&lt;/i&gt;&lt;/a&gt;&lt;i&gt;&lt;a href="http://www.cs.jhu.edu/~jason/advice/write-the-paper-first.html"&gt;Write the paper
	first.&lt;/a&gt;"&lt;/i&gt;  The evolving paper is a way of organizing and
    sharing your thoughts and hammering out details.  New ideas
    (including future plans) can go into that document, or
    appendices to it.&lt;/p&gt;

&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;i&gt;Experimental logbook.&lt;/i&gt;  This is a file recording the
    questions you asked, the experiments you ran to answer them
    (including the command-line details needed to reproduce them
    perfectly), the results, and your analysis of the results.&lt;/p&gt;

&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;i&gt;Notes on your reading,&lt;/i&gt; including reading you plan to do.
    This should be organized by paper and/or by topic, aimed at
    helping you quickly recover the important points.&lt;/p&gt;

&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;i&gt;Planning.&lt;/i&gt;  Keep some kind of to-do list and time
    planning system that helps you set and discharge goals and track
    your effectiveness (see the
    &lt;a href="http://lifehacker.com/"&gt;LifeHacker&lt;/a&gt; website for some
    options).
&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;

&lt;a name="collab"&gt;
&lt;h3&gt;Working With Others&lt;/h3&gt;

&lt;/a&gt;&lt;ul&gt;&lt;a name="collab"&gt;

&lt;li&gt;&lt;p&gt;&lt;i&gt;Again, be honest.&lt;/i&gt;  Be very clear at all times about what
    you do and don't understand.  Don't fake it.  It's okay to say
    you're confused or don't know something; you need to ask questions
    to get unconfused.  Also be clear about what you have and haven't
    done.&lt;/p&gt;

&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;i&gt;Pick a topic of mutual interest that you can handle.&lt;/i&gt;
    This is a matter for careful discussion at the start of the
    relationship.&lt;/p&gt;

&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;i&gt;Be explicit about what you need from your advisor.&lt;/i&gt;  You
    can take some initiative in shaping the kind of advising
    relationship that will work best for you.  Every advisor has a
    typical advising style, which is some compromise between his/her
    advising philosophy, his/her personality, your personality, and
    the realities of limited time.  But if you need a different kind
    of guidance or a different way of organizing your relationship,
    ask for it.  Most advisors will appreciate the initiative and can
    adapt to some extent.&lt;/p&gt;

&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;i&gt;Know how to ask for help.&lt;/i&gt;  If you feel you would benefit
    from closer guidance, say: "Please tell me exactly what you want
    me to do by next Wednesday and I will have it done."  If you get
    stuck technically, ask your advisor to help you get unstuck!
    He/She can write out a more detailed plan for you, give you things
    to read, ask a senior grad student to work with you, point you to
    software libraries, etc.  Asking the right person can be 100 times
    faster than doing it yourself.&lt;/p&gt;

  &lt;p&gt;Your value to the project lies in how much you get done—it
    doesn't matter whether you invented it all yourself.  This is not
    homework and getting help is not cheating.  Anything that is
    already known in the field is fair game to reuse (with citations).
    And people can also help you invent the new stuff, as long as you
    acknowledge their help appropriately (possibly with
    co-authorship).  Getting them to help you is part of the research.&lt;/p&gt;

&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;i&gt;Get right as much as you can.&lt;/i&gt;  Before you hand off a
    piece of code or writing to someone else -- including another
    student, your advisor, or a reviewer -- you ought to catch all the
    problems you can catch by yourself.  For a problem that you intend
    to fix later, include a note to this effect.  This allows the
    other person to focus their limited time on spotting the problems
    that were beyond your own horizon.&lt;/p&gt;

&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;i&gt;Be a team player.&lt;/i&gt;  If there are other people on the
    project, find out what they're working on.  Ask plenty of
    questions.  Get a broader sense of the project beyond your own
    little corner.  Help out where you can.&lt;/p&gt;

&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;i&gt;Share what you do.&lt;/i&gt; Back up your work, comment your code,
    log your experiments, and be ready to hand off your code and notes
    at any time.  The project may live on after you.  It's not
    necessary to keep private files.  The best plan is to keep
    everything valuable in a shared version control repository that
    you, your advisor, and any other collaborators can browse and edit
    at any time.  (A &lt;tt&gt;README&lt;/tt&gt; file in the repository can
    describe the layout and list any additional resources, e.g., the
    URLs of a wiki, a Google Doc, etc.)  An issue tracker is also
    useful.  Discuss with your advisor how to set up this kind of
    project infrastructure, e.g., on github.&lt;/p&gt;

&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;i&gt;Avoid diffusion.&lt;/i&gt;  As a matter of etiquette, try not to
    spread your work over many different local directories,
    repositories, email threads, chat logs, Google documents, etc.
    For example, when sending email, try to continue on an existing
    thread where appropriate, rather than starting a new one.  Your
    advisor is juggling more email and projects than you, so will find
    it helpful to keep related things together.&lt;/p&gt;

&lt;/li&gt;&lt;/a&gt;&lt;li&gt;&lt;a name="collab"&gt;&lt;/a&gt;&lt;p&gt;&lt;a name="collab"&gt;&lt;i&gt;Keep track of what you've done.&lt;/i&gt;  You may want to keep
    some notes on your contributions.  You can give these to your
    advisor when it is time for a &lt;/a&gt;&lt;a href="http://www.cs.jhu.edu/~jason/advice/how-to-ask-for-a-recommendation.html"&gt;letter of recommendation&lt;/a&gt;.

&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;

&lt;a name="looking"&gt;
&lt;h2&gt;But I Don't Have a Project Yet!&lt;/h2&gt;

&lt;p&gt;Now that you've read this page, you understand more about how to
  ask a professor about research opportunities.&lt;/p&gt;

&lt;p&gt;&lt;i&gt;When to ask (not too early).&lt;/i&gt; Usually you'll need to have
  taken at least a 300- or 400-level course in the appropriate
  research area.  If you don't know basic concepts and terms, then it
  is hard to even discuss the research problem.  Don't expect the
  professor to teach you the basics in his/her office: that's what the
  course is for.&lt;/p&gt;

&lt;p&gt;&lt;i&gt;Who to ask.&lt;/i&gt; If you are doing extremely well in an upper-level
  course, then talk to the professor about whether he/she knows of any
  research opportunities in that area.  It helps if the professor
  already has a high opinion of you from good interactions in class
  and through office hours.  (You did go to office hours just to chat
  about ideas, right?)  Even if he/she doesn't have anything for
  you, he/she may be able to hook you up with a colleague.&lt;/p&gt;

&lt;p&gt;&lt;i&gt;How to ask.&lt;/i&gt; Advice from Marie desJardins: "Ask the
  professor about his/her research.  Professors &lt;i&gt;love&lt;/i&gt; to talk
  about their research.  But don't just sit there and nod.  Listen
  carefully to what he/she's saying, think about it, and respond."
  He/She is trying to get a conversation going to assess where
  you can contribute meaningfully.&lt;/p&gt;

  &lt;p&gt;To help the professor decide where to start the conversation, be
  sure to show him/her your resume and your transcript.  Also describe
  the kinds of problems you excel at.  Special skills or a remarkable
  track record may give you a foot in the door.  For example, although
  my main research area is NLP, occasionally I do have problems that
  don't require much NLP knowledge.  Rather, I'm looking for someone
  who can develop a particular theorem or algorithm, or build a solid
  piece of system software, or design a beautiful user interface.  So
  in this case, I might consider working with a great student who
  hasn't taken my NLP course.&lt;/p&gt;


&lt;p&gt;&lt;i&gt;How to ask early.&lt;/i&gt; If you're not ready to start research yet,
  it's certainly still okay to ask a professor (or a senior grad
  student) how you could &lt;i&gt;prepare&lt;/i&gt; to do research in his/her
  area.  This might involve taking courses or MOOCs, reading a
  textbook or papers, or building certain mathematical or programming
  skills.&lt;/p&gt;

&lt;p&gt;&lt;i&gt;When to ask (not too late).&lt;/i&gt; Timing is important.  Research
  may not fit neatly into a semester.  So approach the professor at
  least a year before you graduate.  This gives you a couple of
  semesters plus summer and intersession.  Hopefully, that's enough
  time for the professor to find an appropriate role for you and for
  you to get up to speed, define the problem and approach, do some
  initial work, refine the ideas, do some more work, fail, think hard,
  try again, succeed, write and submit a conference paper, revise the
  paper after acceptance, and present the paper at the conference.
  It's very common for a research project to take over a year even for
  a grad student who is doing research full-time!&lt;/p&gt;

&lt;/a&gt;&lt;p&gt;&lt;a name="looking"&gt;I'll give the final word to Jorge Chan of &lt;/a&gt;&lt;a href="http://www.phdcomics.com/"&gt;PhD Comics&lt;/a&gt;:&lt;br&gt;
  &lt;/p&gt;&lt;center&gt;&lt;a href="http://www.phdcomics.com/comics/archive.php?comicid=1093"&gt;&lt;img src="http://www.phdcomics.com/comics/archive/phd110508s.gif"&gt;&lt;/a&gt;&lt;/center&gt;

&lt;hr&gt;
This page online: &lt;code&gt;http://cs.jhu.edu/~jason/advice/how-to-work-with-a-professor.html&lt;/code&gt;




&lt;/div&gt;&lt;a href="http://www.cs.jhu.edu/~jason/advice/how-to-work-with-a-professor.html"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sun, 5 Apr 2020 22:30:09 UT
      </pubDate>
      <guid>
        http://www.cs.jhu.edu/~jason/advice/how-to-work-with-a-professor.html
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://towardsdatascience.com/feature-engineering-for-machine-learning-3a5e293a5114
      </link>
      <description>
        &lt;a href="https://towardsdatascience.com/feature-engineering-for-machine-learning-3a5e293a5114"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Wed, 8 Apr 2020 11:57:40 UT
      </pubDate>
      <guid>
        https://towardsdatascience.com/feature-engineering-for-machine-learning-3a5e293a5114
      </guid>
    </item>
    <item>
      <title>
        Zuckerberg’s Jealousy Held Back Instagram and Drove Off Founders - Bloomberg
      </title>
      <link>
        https://www.bloomberg.com/news/features/2020-04-07/zuckerberg-s-jealousy-held-back-instagram-and-drove-off-founders
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;
            
            &lt;p&gt;&lt;em&gt;Over the past decade, Instagram has become an engine of commerce and cultural influence with few peers—aside from its parent company, &lt;a href="https://www.bloomberg.com/quote/FB:US"&gt;Facebook Inc.&lt;/a&gt; Reporter Sarah Frier’s &lt;a rel="nofollow noopener" title="Redirects to the order site for Frier's book" href="http://smarturl.it/nofilterbook"&gt;inside look at Instagram&lt;/a&gt;, based on interviews with hundreds of the companies’ leaders, current and former employees, competitors, and stars, traces the union of Facebook and Instagram and the disintegration of the relationship between their chief executive officers. Facebook said in a statement that it has committed significant resources to fuel Instagram’s development and that “Instagram’s success is Facebook’s success.&lt;/em&gt;”&lt;/p&gt;&lt;p&gt;The Instagram event didn’t feel very Facebook. On a San Francisco street dotted with homeless encampments, press and the quasi celebrities known as influencers entered a former music venue through an archway made of balloons. Attendees received raspberry-cream-filled cruffins—croissants shaped like muffins—along with espresso drinks and multiple kinds of green juice. Enclaves in the space were designed specifically for selfie-taking, to encourage the influencers to hype the coming product announcement to their digital followers.&lt;/p&gt;&lt;p&gt;But the event was beset by technical difficulties. Someone misplaced the file for CEO Kevin Systrom’s presentation, so it had to be remade in a scramble while guests waited. During the delay, the corporate blog post announcing Instagram TV, a new standalone video app, went up as scheduled, ruining the surprise before Systrom arrived onstage. An hour after the event ended, his iPhone flashed. It was Chris Cox, the executive whom Facebook CEO Mark Zuckerberg had recently put in charge of all his company’s apps.&lt;/p&gt;&lt;figure data-type="image" data-image-size="column" data-id="360982996" data-align="left"&gt;&lt;div aria-label="Open image in viewer" role="button" tabindex="0"&gt;&lt;p&gt;&lt;img data-img-type="image" data-native-src="https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i6QTOCbfUvr4/v1/-1x-1.jpg" src="https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i6QTOCbfUvr4/v1/-1x-1.jpg" alt="relates to Zuckerberg’s Jealousy Held Back Instagram and Drove Off Founders"&gt;&lt;/p&gt;&lt;/div&gt;&lt;/figure&gt;&lt;p&gt;“We have a problem,” Cox said. “Mark’s very angry about your icon.”&lt;/p&gt;&lt;p&gt;“Are you serious?” Systrom asked. “What’s wrong?”&lt;/p&gt;&lt;p&gt;“It looks too much like the icon for Facebook Messenger,” Cox said, referring to Facebook’s chat service, which also had a horizontal lightning bolt shape in the center. Zuckerberg couldn’t stand that IGTV competed visually with a sister product.&lt;/p&gt;&lt;p&gt;The call was the latest in a string of reminders that, by 2018, Facebook saw even the slightest encroachment by Instagram as a threat. Systrom, who’d sold Instagram to Zuckerberg in 2012, had for years retained enough authority to wall off the parts of Facebook he didn’t like, often telling reporters he considered Zuckerberg to be more like a board member than a boss. Lately, though, Facebook was asserting more control, and Systrom found himself forced to satisfy the concerns of Zuckerberg and his lieutenants before adding products, hiring staff, or even making announcements about his app’s popularity.&lt;/p&gt;&lt;p&gt;It took months to get permission to release IGTV without any tie-ins to Facebook’s existing video product. Shortly before the event with the cruffins, Zuckerberg questioned whether Instagram should even disclose that its user count had topped 1 billion. The subtext wasn’t very sub: A Facebook property was reaching thresholds that made it look like the next Facebook, and the parent company wanted to make sure its namesake website and app didn’t suffer for the comparison.&lt;/p&gt;&lt;p&gt;Of course, Facebook’s suffering wasn’t Instagram’s fault. Zuckerberg was facing blowback from years of taking shortcuts to win his product attention and ad revenue, including abusing private user data to curry favor with software developers, allowing live broadcasts of murders and suicides, and turning a blind eye to meddling in the U.S. presidential election. Yet with a global #DeleteFacebook movement growing, Zuckerberg saw his other properties, the chat apps WhatsApp and Messenger as well as Instagram, as assets in a new sense—as an explicitly linked family of software.&lt;/p&gt;&lt;p&gt;Zuckerberg’s purchase of Instagram, considered wildly overpriced at $715 million in 2012, is worth more than $100 billion today. Instagram now delivers $20 billion in annual revenue, more than a quarter of Facebook’s total. And Zuckerberg’s promise to leave the Instagram team largely independent inspired other founders to join Facebook, too. In 2014 he bought WhatsApp for a then-stunning $22 billion, solidifying Facebook’s dominance over modern communication, and paid $2 billion for the virtual-reality company Oculus, whose hardware he hoped would lead the way into the future.&lt;/p&gt;&lt;p&gt;But in late 2018, the Instagram founders abandoned their creation, and the WhatsApp and Oculus founders left the same year. With Facebook in crisis, Zuckerberg had stopped seeing his acquisitions as a portfolio of subsidiaries that could grow into potential second acts. Instead, he would lean on Instagram to strengthen the Facebook app more directly, including by weaving the software together. Today, with his company &lt;a title="Facebook’s New FTC Probe Covers Wide Sphere But Faces Long Odds" href="https://www.bloomberg.com/news/articles/2019-07-24/facebook-says-it-s-being-investigated-by-the-ftc-over-antitrust"&gt; under investigation&lt;/a&gt; for anticompetitive behavior by the U.S. Department of Justice, the Federal Trade Commission, and 47 state attorneys general, Zuckerberg is consolidating his products’ data and building one big mega-network that will make Facebook proper look all the bigger. As one former Instagram executive complained: “Facebook was like the big sister that wants to dress you up for the party but does not want you to be prettier than she is.”&lt;/p&gt;&lt;p&gt;Systrom and co-founder Mike Krieger unveiled Instagram a decade ago as an iPhone app whose filters could quickly improve the low-quality pictures snapped on mobile devices, so anyone could feel like a professional photographer. They attracted 30 million users in 18 months, and by early 2012, their team of 12 could barely keep pace. Krieger was fixing service outages at all hours, bringing his laptop to movies, birthday parties, bars, and, in one instance, a campsite. So when Zuckerberg reached out about acquiring the company, Instagram’s founders were ready to listen. During negotiations over Easter weekend, Zuckerberg said all the right things. In exchange for what was, at the time, more money than anyone had paid for a mobile app, he would extend Facebook’s engineering and operational largesse but leave Systrom and Krieger firmly in charge.&lt;/p&gt;
    &lt;p&gt;Soon after the Instagram employees moved into a small room at Facebook’s Menlo Park, Calif., headquarters, they began to realize their new colleagues weren’t as eager to share as Zuckerberg had promised. In one early meeting, Facebook’s growth team told the Instagram staffers that before they could help, they needed to figure out whether Instagram’s popularity made people less likely to post photos on Facebook. Their study proved inconclusive but served as a warning to Instagram not to expect its software to be treated as equal.&lt;/p&gt;&lt;p&gt;Still, Zuckerberg and Systrom developed a mutual respect over monthly strategy dinners at Zuckerberg’s Palo Alto home. On paper they were extremely similar. Born just five months apart, both were raised in comfortable suburban American towns by tightknit Northeastern families. Both attended boarding schools (Zuckerberg captained the Exeter fencing team; Systrom, Middlesex lacrosse) and elite universities (Harvard and Stanford), where they nursed passions for history as well as engineering. Zuckerberg was obsessed with the ancient Greeks and Romans; Systrom loved art history.&lt;/p&gt;&lt;p&gt;Their competitive streaks manifested in different ways. When they went on a ski trip to bond shortly after the acquisition, Systrom preferred the unpredictability of backcountry trails, while Zuckerberg just wanted to race black diamonds to the bottom. No matter the stakes, Zuckerberg was win-at-all-costs. Once, when he lost a Scrabble match to a friend’s teenage daughter, he created a simple software program to cheat for him. Systrom fancied himself a Renaissance man, with a passion for self-improvement matched only by his expensive tastes for Italian leather, bespoke mountain bikes, and dinner with celebrities. In 2018, around the time Zuckerberg testified to Congress about one of Facebook’s data-sharing scandals, Systrom passed his wine sommelier exam and sat with the Kardashians at the Met Gala.&lt;/p&gt;&lt;p&gt;Instagram’s success earned Zuckerberg’s respect, but not a place on the short list of Facebook executives he counted as confidants and friends. Zuckerberg couldn’t relate to Systrom’s obsession over each contour of Instagram’s design, which slowed product development. Systrom worried that Facebook’s hard-sell approach—sending spammy emails to push users to log in, for example, or using red dots in the interface to create anxiety about missed messages—might cost Instagram the relative trust it enjoyed as a friendlier-looking social network. Still, he believed that keeping Zuckerberg happy would require him to show that Instagram remained valuable to Facebook’s future. He assumed Zuckerberg would continue to honor Instagram’s independence as long as it grew quickly—and crushed the competition.&lt;/p&gt;&lt;figure data-type="image" data-image-size="column" data-id="360983042" data-align="center"&gt;&lt;div aria-label="Open image in viewer" role="button" tabindex="0"&gt;&lt;p&gt;&lt;img data-img-type="image" data-native-src="https://assets.bwbx.io/images/users/iqjWHBFdfxIU/ivSuzObFQ0dQ/v1/-1x-1.jpg" src="https://assets.bwbx.io/images/users/iqjWHBFdfxIU/ivSuzObFQ0dQ/v1/-1x-1.jpg" alt="relates to Zuckerberg’s Jealousy Held Back Instagram and Drove Off Founders"&gt;&lt;/p&gt;&lt;/div&gt;&lt;figcaption&gt;&lt;p&gt;Photo Illustration by 731. Photos: Getty Images (7)&lt;/p&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Zuckerberg thought there was little use doing something unless you were doing it for as many people as possible. With Facebook, he had created the largest network of humans ever, and steadily worked to capture more of their time. His opponents included Twitter, Snapchat, Google, and anyone else competing for attention. He wasn’t shy about copying a competitor’s popular features, either, whether that meant incorporating more official news sources into Facebook’s news feed, like Twitter, or making a half-dozen attempts to add Snapchat-style disappearing photos. (Snapchat rejected his $3 billion buyout offer in 2013.) This bolt-on strategy often left Facebook looking less than refined, especially next to Instagram.&lt;/p&gt;&lt;p&gt;Where the viral sharing on Facebook could seem to represent the nadir of the internet, Instagram appeared to reward the beautiful and interesting for doing cool stuff. Systrom’s community, and its cultural influence, expanded as he nurtured emerging stars and pursued relationships with A-list celebrities. Systrom was less comfortable with Zuckerberg pushing him into the world of advertising. When Instagram rolled out its first ads at the end of 2013, Systrom said there should only be one sponsor allowed per day, and that he wanted to personally review each ad. (Once, he took it upon himself to edit a promotional photo of fries to make them look crispier.) Zuckerberg insisted that he abandon the white-glove model and transition to Facebook’s system, which allowed anyone with a credit card to purchase as many ads as they liked. It was the right call, in terms of dollars. Instagram reached $1 billion in annual revenue by the end of 2015.&lt;/p&gt;&lt;p&gt;Yet the news that Instagram’s growth was accelerating while Facebook’s was slowing didn’t sit well with Zuckerberg. Systrom had done his job too well.&lt;/p&gt;&lt;p&gt;By the end of 2016, just as his company was facing its first controversies related to Donald Trump’s election, Zuckerberg was focused on a different kind of threat. Typical Facebook users were posting fewer of their own thoughts and photos, and Zuckerberg suspected Instagram’s successful copying of Snapchat Stories was to blame. (The success came as a surprise even to Zuckerberg, who unbeknownst to Systrom had again tried and failed to buy Snapchat shortly before Instagram Stories debuted.) He enlisted his most trusted data scientists to study whether Instagram was becoming a Facebook alternative and threatening its dominance. Zuckerberg thought the research showed that Instagram would start eating into Facebook’s user base within six months. The word “cannibalization” started to creep into his management meetings.&lt;/p&gt;&lt;p&gt;Systrom disagreed with Zuckerberg’s assessment of the data. “This is not Instagram taking away from the Facebook pie to add to the Instagram pie,” he told Zuckerberg at a weekly Monday leadership meeting. “The total pie is getting bigger.” It wasn’t just Instagram vs. Facebook. It was all of these Facebook properties vs. every other choice in the world, like Netflix, Snapchat, Twitter, and, you know, sleep. Others in the room sided with Systrom. They were puzzled by Zuckerberg’s apparent jealousy of Instagram’s success. Zuckerberg had always said Facebook should reinvent itself before a competitor got the chance and that the company should make the decisions about how to do so based on data. “If we don’t create the thing that kills Facebook, someone else will,” the booklet passed out at employee orientation reads.&lt;/p&gt;
    &lt;p&gt;Yet Zuckerberg couldn’t seem to bear the idea that Instagram might outshine Facebook. He told Systrom he believed Instagram Stories was successful not because of its design, but because they’d happened to release the feature ahead of Facebook Stories. Facebook had helped Instagram long enough, he decided. In 2018, Instagram would have to start giving back.&lt;/p&gt;&lt;p&gt;Instagram users barely noticed Zuckerberg’s first change. He ordered Systrom to build a prominent link within the Instagram app that would send his users to Facebook. Around the same time, he had his own engineers remove the prominent link to Instagram on Facebook’s site.&lt;/p&gt;&lt;p&gt;Zuckerberg’s willingness to expand Instagram’s team had waned, too. He balked at adding engineers to facilitate the release of IGTV, even though Instagram was on track to hit 1 billion users and $10 billion in revenue that year. He allowed Systrom and Krieger to hire 93 more employees, bringing their count to around 800—still far short of what they felt they needed. Instagram’s co-founders were shocked; Zuckerberg granted Oculus, which was losing money, more than 600 new employees. Krieger dug up the numbers and learned that Facebook, which hired 8,000 people in 2018, had six times as many employees as Instagram when it added its billionth user.&lt;/p&gt;&lt;p&gt;Instagram now felt like a Facebook product arm, not an independent operation. Zuckerberg made this new order official with a massive reorg emphasizing that Facebook’s properties were to be a “family of apps.” Systrom would now be reporting to Cox, who was previously just in charge of the Facebook app. “Let’s be straight with each other,” Systrom told Cox. “I need independence. I need resources. And when something happens, I know I’m not always going to agree with it, but I need honesty. That’s what’s going to keep me here.”&lt;/p&gt;&lt;p&gt;Cox knew he couldn’t afford to lose Systrom or Krieger, especially as Facebook’s and Zuckerberg’s public images were souring. He resolved to prioritize retaining the Instagram co-founders. Soon, though, Facebook was facing a different crisis after the &lt;em&gt;Guardian&lt;/em&gt;, the U.K.’s Channel 4, and the &lt;em&gt;New York Times&lt;/em&gt; published whistleblower testimony that Cambridge Analytica, a Republican political consulting firm, had collected the private data of tens of millions of American Facebook users and attempted to influence the U.S. presidential election while Facebook looked the other way. Suddenly, all of Facebook’s problems were up for public debate. Zuckerberg made plans to hire thousands of people to work on issues of “integrity.” Systrom requested hires to address Instagram-specific concerns (anonymous users, less-visible dangerous communities), but Zuckerberg said no. Instagram would have to manage its problems with existing resources or the central integrity team.&lt;/p&gt;&lt;p&gt;After Instagram reached 1 billion users, Zuckerberg directed Javier Olivan, Facebook’s head of growth, to draw up a list of all the ways Instagram was supported by the Facebook app. Then he ordered the supporting tools turned off. Instagram would no longer be promoted in Facebook’s news feed. Sure enough, Instagram’s growth slowed to a halt.&lt;/p&gt;&lt;p&gt;Systrom had never been one to criticize Zuckerberg in front of his employees. But after months of what he saw as obstruction and bigfooting, he wrote a long internal message to his team saying he disagreed vehemently with Zuckerberg’s undercutting of Instagram. By the fall of 2018, Systrom started confiding to his close friends that if Zuckerberg wanted to run Instagram like a mere department of Facebook, maybe it was time to let him. In the name of growth, Instagram adopted some of the strategies Systrom had blocked in the past, including pushing out frequent app notifications and aggressively promoting suggested people to follow. Time spent on the app returned to its typical levels; the Facebook strategies, which had seemed so cheap and anti-Instagram, worked.&lt;/p&gt;
    &lt;p&gt;Not long after the IGTV debut, when his first child was about six months old, Systrom went on paternity leave. He was expected back at the end of July, but extended his leave by a month, then another. When he came back in late September, he and Krieger gathered their top staff in a conference room. They were &lt;a title="Instagram Founders Depart Facebook After Clashes With Zuckerberg" href="https://www.bloomberg.com/news/articles/2018-09-25/instagram-founders-depart-facebook-after-clashes-with-zuckerberg"&gt; both resigning&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Systrom was diplomatic, explaining that after six years within Facebook, it was time to try other things. But he didn’t hold back with Facebook management. Earlier that morning he’d reminded Cox that he’d asked for resources, independence, and trust. “None of the things I asked for have happened,” he told Cox.&lt;/p&gt;&lt;p&gt;In the 18 months since its founders left, Instagram has grown more in Facebook’s image than ever, prioritizing integration with Facebook over its own product development. Most Instagram users still don’t know Facebook owns the app, even though it’s been &lt;a title="Facebook Adds More Corporate Branding to Instagram, WhatsApp" href="https://www.bloomberg.com/news/articles/2019-11-04/facebook-adds-more-corporate-branding-to-instagram-whatsapp"&gt; rebranded as “Instagram from Facebook.”&lt;/a&gt; More obvious has been the increased frequency of advertising on Instagram.&lt;/p&gt;&lt;p&gt;Zuckerberg hasn’t disclosed an updated number of Instagram users since 2018. Eventually, he says, Facebook’s total user number won’t be broken out, either. The company will just report one number—total users of the Facebook “family,” including Facebook, WhatsApp, Instagram, and Messenger. The overall number sits at 2.9 billion, accounting for duplicates between the apps. Using an overall number will allow Zuckerberg to mask any slowdown in the core Facebook app’s growth. It will also make it tougher for antitrust-minded regulators to recognize that Facebook owns the world’s top Facebook alternative.&lt;/p&gt;&lt;p&gt;Cox, too, left the company in 2019 after disagreeing with Zuckerberg’s push for greater encryption across the app family. Instagram’s new top boss is Adam Mosseri, who formerly ran Facebook’s news feed. His title is “Head of Instagram.” These days, Facebook only has room for one CEO.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Excerpted from the book &lt;/em&gt;NO FILTER: The Inside Story of Instagram&lt;em&gt;, by Sarah Frier. Copyright  2020 by Sarah Frier. Reprinted with permission of Simon &amp;amp; Schuster, Inc. All rights reserved.&lt;/em&gt;&lt;/p&gt;
    &lt;ol&gt;&lt;/ol&gt;
            
        &lt;/div&gt;&lt;/div&gt;&lt;a href="https://www.bloomberg.com/news/features/2020-04-07/zuckerberg-s-jealousy-held-back-instagram-and-drove-off-founders"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Wed, 8 Apr 2020 20:04:48 UT
      </pubDate>
      <guid>
        https://www.bloomberg.com/news/features/2020-04-07/zuckerberg-s-jealousy-held-back-instagram-and-drove-off-founders
      </guid>
    </item>
    <item>
      <title>
        Close National Review Navigation&lt;/title&gt;
	&lt;path d="M11 9.645L2.575 1.22 1.898.543.543 1.898l.677.677L9.645 11 1.22 19.425l-.677.677 1.355 1.355.677-.677L11 12.355l8.425 8.425.677.677 1.355-1.355-.677-.677L12.355 11l8.425-8.425.677-.677L20.102.543l-.677.677L11 9.645z" fill="#FFF"&gt;&lt;/path&gt;
&lt;/svg&gt;
&lt;/span&gt;
			&lt;/button&gt;
		&lt;/div&gt;
		&lt;ul id="primary-menu" class="site-nav__menu"&gt;&lt;li id="menu-item-857757" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-has-children site-nav__menu-item site-nav__menu-item-has-children menu-item-857757"&gt;&lt;a href="#"&gt;Sections&lt;/a&gt;
&lt;ul class="site-nav__sub-menu"&gt;
	&lt;li id="menu-item-857758" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857758"&gt;&lt;a href="/corner/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=sections&amp;amp;utm_term=first&amp;amp;utm_content=corner"&gt;The Corner&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857759" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857759"&gt;&lt;a href="/news/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=sections&amp;amp;utm_term=second&amp;amp;utm_content=news"&gt;News&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857760" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857760"&gt;&lt;a href="/capital-matters/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=sections&amp;amp;utm_term=third&amp;amp;utm_content=capital-matters"&gt;Capital Matters&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857761" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857761"&gt;&lt;a href="/books-arts-manners/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=sections&amp;amp;utm_term=fourth&amp;amp;utm_content=books-arts-manners"&gt;Books, Arts &amp;amp; Manners&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857762" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857762"&gt;&lt;a href="/bench-memos/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=sections&amp;amp;utm_term=fifth&amp;amp;utm_content=bench-memos"&gt;Bench Memos&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857763" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857763"&gt;&lt;a href="/podcasts/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=sections&amp;amp;utm_term=sixth&amp;amp;utm_content=podcasts"&gt;Podcasts&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857764" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857764"&gt;&lt;a href="/photos/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=sections&amp;amp;utm_term=seventh&amp;amp;utm_content=photos"&gt;Photos&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857765" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857765"&gt;&lt;a href="/videos/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=sections&amp;amp;utm_term=eighth&amp;amp;utm_content=videos"&gt;Videos&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857766" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857766"&gt;&lt;a href="https://games.nationalreview.com/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=sections&amp;amp;utm_term=ninth&amp;amp;utm_content=games"&gt;Games&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857767" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857767"&gt;&lt;a href="https://www.nationalreviewwineclub.com/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=sections&amp;amp;utm_term=tenth&amp;amp;utm_content=wine-club"&gt;Wine Club&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-884378" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-884378"&gt;&lt;a href="/most-popular/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=sections&amp;amp;utm_term=eleventh&amp;amp;utm_content=most-popular"&gt;Most Popular&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857768" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857768"&gt;&lt;a href="/latest/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=sections&amp;amp;utm_term=twelfth&amp;amp;utm_content=latest-articles"&gt;Latest Articles&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857769" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857769"&gt;&lt;a href="/authors/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=sections&amp;amp;utm_term=thirteenth&amp;amp;utm_content=our-authors"&gt;Our Authors&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id="menu-item-857770" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-has-children site-nav__menu-item site-nav__menu-item-has-children menu-item-857770"&gt;&lt;a href="#"&gt;Newsletters&lt;/a&gt;
&lt;ul class="site-nav__sub-menu"&gt;
	&lt;li id="menu-item-857771" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857771"&gt;&lt;a href="/newsletter-signup/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=newsletters&amp;amp;utm_term=first&amp;amp;utm_content=newsletter-signup"&gt;Newsletter Signup&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857772" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857772"&gt;&lt;a href="/the-morning-jolt/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=newsletters&amp;amp;utm_term=second&amp;amp;utm_content=morning-jolt"&gt;The Morning Jolt&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857773" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857773"&gt;&lt;a href="/the-tuesday/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=newsletters&amp;amp;utm_term=third&amp;amp;utm_content=the-tuesday"&gt;The Tuesday&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857774" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857774"&gt;&lt;a href="/the-capital-letter/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=newsletters&amp;amp;utm_term=fourth&amp;amp;utm_content=capital-letter"&gt;The Capital Letter&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857775" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857775"&gt;&lt;a href="/the-capital-note/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=newsletters&amp;amp;utm_term=fifth&amp;amp;utm_content=capital-note"&gt;The Capital Note&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857776" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857776"&gt;&lt;a href="/the-weekend-jolt/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=newsletters&amp;amp;utm_term=sixth&amp;amp;utm_content=weekend-jolt"&gt;Weekend Jolt&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857777" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857777"&gt;&lt;a href="http://link.nationalreview.com/join/optin-nrdaily?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=newsletters&amp;amp;utm_term=seventh&amp;amp;utm_content=nr-daily"&gt;NR Daily&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857778" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857778"&gt;&lt;a href="http://link.nationalreview.com/join/optin-breaking-news?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=newsletters&amp;amp;utm_term=eighth&amp;amp;utm_content=breaking-news"&gt;Breaking News&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857779" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857779"&gt;&lt;a href="http://link.nationalreview.com/join/optin-weekinreview?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=newsletters&amp;amp;utm_term=ninth&amp;amp;utm_content=week-in-review"&gt;Week in Review&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857780" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857780"&gt;&lt;a href="http://link.nationalreview.com/join/optin-news-roundup?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=newsletters&amp;amp;utm_term=tenth&amp;amp;utm_content=news-editor-roundup"&gt;News Editor’s Roundup&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857781" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857781"&gt;&lt;a href="http://link.nationalreview.com/join/optin-latest?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=newsletters&amp;amp;utm_term=eleventh&amp;amp;utm_content=latest-issue-alerts"&gt;Latest Issue Alerts&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id="menu-item-857782" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-has-children site-nav__menu-item site-nav__menu-item-has-children menu-item-857782"&gt;&lt;a href="#"&gt;Popular Topics&lt;/a&gt;
&lt;ul class="site-nav__sub-menu"&gt;
	&lt;li id="menu-item-857783" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857783"&gt;&lt;a href="/elections/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=popular-topics&amp;amp;utm_term=first&amp;amp;utm_content=elections"&gt;Elections&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857784" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857784"&gt;&lt;a href="/politics-policy/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=popular-topics&amp;amp;utm_term=second&amp;amp;utm_content=politics-policy"&gt;Politics &amp;amp; Policy&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857785" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857785"&gt;&lt;a href="/culture/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=popular-topics&amp;amp;utm_term=third&amp;amp;utm_content=culture"&gt;Culture&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857786" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857786"&gt;&lt;a href="/white-house/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=popular-topics&amp;amp;utm_term=fourth&amp;amp;utm_content=white-house"&gt;White House&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857787" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857787"&gt;&lt;a href="/film-tv/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=popular-topics&amp;amp;utm_term=fifth&amp;amp;utm_content=film-tv"&gt;Film &amp;amp; TV&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857788" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857788"&gt;&lt;a href="/pc-culture/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=popular-topics&amp;amp;utm_term=sixth&amp;amp;utm_content=pc-culture"&gt;PC Culture&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857789" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857789"&gt;&lt;a href="/us/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=popular-topics&amp;amp;utm_term=seventh&amp;amp;utm_content=us"&gt;U.S.&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857790" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857790"&gt;&lt;a href="/world/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=popular-topics&amp;amp;utm_term=eighth&amp;amp;utm_content=world"&gt;World&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857791" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857791"&gt;&lt;a href="/immigration/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=popular-topics&amp;amp;utm_term=ninth&amp;amp;utm_content=immigration"&gt;Immigration&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857792" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857792"&gt;&lt;a href="/economy-business/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=popular-topics&amp;amp;utm_term=tenth&amp;amp;utm_content=economy-business"&gt;Economy &amp;amp; Business&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-865757" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-865757"&gt;&lt;a href="/law-the-courts/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=popular-topics&amp;amp;utm_term=eleventh&amp;amp;utm_content=law-the-courts"&gt;Law &amp;amp; the Courts&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id="menu-item-857793" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-has-children site-nav__menu-item site-nav__menu-item-has-children menu-item-857793"&gt;&lt;a href="#"&gt;NRPLUS&lt;/a&gt;
&lt;ul class="site-nav__sub-menu"&gt;
	&lt;li id="menu-item-857794" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857794"&gt;&lt;a href="/nrplus-subscribe/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=nrplus&amp;amp;utm_term=first&amp;amp;utm_content=about-nrplus"&gt;About NRPLUS&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857795" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857795"&gt;&lt;a href="#" data-react-component="SmartMenuItem" data-account-text="My Account" data-link="/login/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=nrplus&amp;amp;utm_term=second&amp;amp;utm_content=login" data-link-text="Login to NRPLUS"&gt;&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857796" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857796"&gt;&lt;a href="/subscribe/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=nrplus&amp;amp;utm_term=third&amp;amp;utm_content=subscribe"&gt;Subscribe to NRPLUS&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857797" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857797"&gt;&lt;a href="/tag/nrplus-member-articles/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=nrplus&amp;amp;utm_term=fourth&amp;amp;utm_content=member-articles"&gt;Member Articles&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857798" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857798"&gt;&lt;a href="/tag/nrplus-conference-call/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=nrplus&amp;amp;utm_term=fifth&amp;amp;utm_content=conference-call-archives"&gt;Conference Call Archive&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857799" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857799"&gt;&lt;a href="/photos/category/cartoons/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=nrplus&amp;amp;utm_term=sixth&amp;amp;utm_content=cartoon-of-the-day"&gt;Cartoons of the Day&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857800" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857800"&gt;&lt;a href="https://www.facebook.com/groups/nrplus/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=nrplus&amp;amp;utm_term=seventh&amp;amp;utm_content=nrplus-facebook-group"&gt;NRPLUS Facebook Group&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id="menu-item-857801" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-has-children site-nav__menu-item site-nav__menu-item-has-children menu-item-857801"&gt;&lt;a href="/magazine"&gt;Magazine&lt;/a&gt;
&lt;ul class="site-nav__sub-menu"&gt;
	&lt;li id="menu-item-857802" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857802"&gt;&lt;a href="/magazine/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=magazine&amp;amp;utm_term=first&amp;amp;utm_content=latest-issue"&gt;Latest Issue&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857803" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857803"&gt;&lt;a href="/magazine/archive/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=magazine&amp;amp;utm_term=first&amp;amp;utm_content=latest-issue"&gt;Issue Archive&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857804" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857804"&gt;&lt;a href="/subscribe/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=magazine&amp;amp;utm_term=third&amp;amp;utm_content=subscribe"&gt;Subscribe to NR&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857805" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857805"&gt;&lt;a href="https://w1.buysub.com/pubs/NA/NR1/NR1_Print_Digital_Combo_Gift_US.jsp?cds_page_id=220078&amp;amp;cds_mag_code=NR1&amp;amp;id=1539875512503&amp;amp;lsid=82911011055035322&amp;amp;vid=2/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=magazine&amp;amp;utm_term=fourth&amp;amp;utm_content=give-gift"&gt;Give NR as a Gift&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id="menu-item-857806" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-has-children site-nav__menu-item site-nav__menu-item-has-children menu-item-857806"&gt;&lt;a href="/podcasts"&gt;Podcasts&lt;/a&gt;
&lt;ul class="site-nav__sub-menu"&gt;
	&lt;li id="menu-item-857807" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857807"&gt;&lt;a href="/podcasts/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=podcasts&amp;amp;utm_term=first&amp;amp;utm_content=all-podcasts"&gt;All Podcasts&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857808" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857808"&gt;&lt;a href="/podcasts/the-editors/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=podcasts&amp;amp;utm_term=second&amp;amp;utm_content=the-editors"&gt;The Editors&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857809" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857809"&gt;&lt;a href="/podcasts/mad-dogs-englishmen/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=podcasts&amp;amp;utm_term=third&amp;amp;utm_content=mad-dogs-and-englishmen"&gt;Mad Dogs &amp;amp; Englishmen&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857810" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857810"&gt;&lt;a href="/podcasts/give-me-liberty-the-making-of-american-exceptionalism/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=podcasts&amp;amp;utm_term=fourth&amp;amp;utm_content=give-me-liberty"&gt;Give Me Liberty&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857811" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857811"&gt;&lt;a href="/podcasts/the-mccarthy-report/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=podcasts&amp;amp;utm_term=fifth&amp;amp;utm_content=mccarthy-report"&gt;The McCarthy Report&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857812" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857812"&gt;&lt;a href="/podcasts/the-victor-davis-hanson-podcast/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=podcasts&amp;amp;utm_term=sixth&amp;amp;utm_content=victor-davis-hanson"&gt;Victor Davis Hanson&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-897440" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-897440"&gt;&lt;a href="/podcasts/capital-record/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=podcasts&amp;amp;utm_term=seventh&amp;amp;utm_content=capital-record"&gt;Capital Record&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857814" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857814"&gt;&lt;a href="/podcasts/political-beats/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=podcasts&amp;amp;utm_term=eighth&amp;amp;utm_content=political-beats"&gt;Political Beats&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857815" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857815"&gt;&lt;a href="/podcasts/constitutionally-speaking/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=podcasts&amp;amp;utm_term=ninth&amp;amp;utm_content=constitutionally-speaking"&gt;Constitutionally Speaking&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857816" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857816"&gt;&lt;a href="/podcasts/the-great-books/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=podcasts&amp;amp;utm_term=tenth&amp;amp;utm_content=great-books"&gt;The Great Books&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857817" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857817"&gt;&lt;a href="/podcasts/the-bookmonger/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=podcasts&amp;amp;utm_term=eleventh&amp;amp;utm_content=bookmonger"&gt;The Bookmonger&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857818" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857818"&gt;&lt;a href="/podcasts/national-reviews-radio-free-california-podcast/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=podcasts&amp;amp;utm_term=twelfth&amp;amp;utm_content=radio-free-california"&gt;Radio Free California&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id="menu-item-857819" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-has-children site-nav__menu-item site-nav__menu-item-has-children menu-item-857819"&gt;&lt;a href="/photos"&gt;Photos&lt;/a&gt;
&lt;ul class="site-nav__sub-menu"&gt;
	&lt;li id="menu-item-857820" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857820"&gt;&lt;a href="/photos/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=photos&amp;amp;utm_term=first&amp;amp;utm_content=all-photos"&gt;All Photos&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857821" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857821"&gt;&lt;a href="/photos/category/news-events/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=photos&amp;amp;utm_term=second&amp;amp;utm_content=news-events"&gt;News &amp;amp; Events&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857822" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857822"&gt;&lt;a href="/photos/category/cartoons/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=photos&amp;amp;utm_term=third&amp;amp;utm_content=cartoons-of-the-day"&gt;Cartoons of the Day&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857823" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857823"&gt;&lt;a href="/photos/category/culture/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=photos&amp;amp;utm_term=fourth&amp;amp;utm_content=culture"&gt;Culture&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857824" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857824"&gt;&lt;a href="/photos/category/military/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=photos&amp;amp;utm_term=fifth&amp;amp;utm_content=military"&gt;Military&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857825" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857825"&gt;&lt;a href="/photos/category/science-technology/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=photos&amp;amp;utm_term=sixth&amp;amp;utm_content=science-tech"&gt;Science &amp;amp; Tech&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857826" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857826"&gt;&lt;a href="/photos/category/sports/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=photos&amp;amp;utm_term=seventh&amp;amp;utm_content=sports"&gt;Sports&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857827" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857827"&gt;&lt;a href="/photos/category/world/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=photos&amp;amp;utm_term=eighth&amp;amp;utm_content=world"&gt;World&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id="menu-item-857828" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857828"&gt;&lt;a href="/videos/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=videos&amp;amp;utm_term=zero&amp;amp;utm_content=videos"&gt;Videos&lt;/a&gt;&lt;/li&gt;
&lt;li id="menu-item-857829" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857829"&gt;&lt;a href="https://games.nationalreview.com/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=games&amp;amp;utm_term=zero&amp;amp;utm_content=games"&gt;Games&lt;/a&gt;&lt;/li&gt;
&lt;li id="menu-item-857830" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857830"&gt;&lt;a href="https://www.nationalreviewwineclub.com/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=wine-club&amp;amp;utm_term=zero&amp;amp;utm_content=wine-club"&gt;Wine Club&lt;/a&gt;&lt;/li&gt;
&lt;li id="menu-item-857831" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-has-children site-nav__menu-item site-nav__menu-item-has-children menu-item-857831"&gt;&lt;a href="#"&gt;Contact &amp;amp; About Us&lt;/a&gt;
&lt;ul class="site-nav__sub-menu"&gt;
	&lt;li id="menu-item-857832" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857832"&gt;&lt;a href="/frequently-asked-questions/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=about&amp;amp;utm_term=first&amp;amp;utm_content=FAQ"&gt;FAQ&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857833" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857833"&gt;&lt;a href="/about/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=about&amp;amp;utm_term=second&amp;amp;utm_content=about-NR"&gt;About NR&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857834" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857834"&gt;&lt;a href="/the-masthead/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=about&amp;amp;utm_term=third&amp;amp;utm_content=masthead"&gt;Masthead&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857835" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857835"&gt;&lt;a href="/careers/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=about&amp;amp;utm_term=fourth&amp;amp;utm_content=careers"&gt;Careers&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857836" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857836"&gt;&lt;a href="/advertise/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=about&amp;amp;utm_term=fifth&amp;amp;utm_content=advertise"&gt;Advertise&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857837" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857837"&gt;&lt;a href="/donate/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=about&amp;amp;utm_term=sixth&amp;amp;utm_content=donate"&gt;Donate&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857838" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857838"&gt;&lt;a href="/contact-us/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=about&amp;amp;utm_term=seventh&amp;amp;utm_content=contact-us"&gt;Contact Us&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857839" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857839"&gt;&lt;a href="/privacy-policy/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=about&amp;amp;utm_term=eighth&amp;amp;utm_content=privacy-policy"&gt;Privacy Policy&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857840" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857840"&gt;&lt;a href="/commenting-policy/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=about&amp;amp;utm_term=ninth&amp;amp;utm_content=commenting-policy"&gt;Commenting Policy&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857841" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857841"&gt;&lt;a href="/terms-of-service/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=about&amp;amp;utm_term=tenth&amp;amp;utm_content=terms-of-service"&gt;Terms of Service&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857842" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857842"&gt;&lt;a href="https://nrinstitute.org/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=about&amp;amp;utm_term=eleventh&amp;amp;utm_content=nri"&gt;NR Institute&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857843" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857843"&gt;&lt;a href="/tips/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=about&amp;amp;utm_term=twelfth&amp;amp;utm_content=tips"&gt;Send a Tip&lt;/a&gt;&lt;/li&gt;
	&lt;li id="menu-item-857844" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857844"&gt;&lt;a href="/?s="&gt;Search&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li id="menu-item-857845" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-857845"&gt;&lt;a href="/donate/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=donate&amp;amp;utm_term=zero&amp;amp;utm_content=donate"&gt;Donate&lt;/a&gt;&lt;/li&gt;
&lt;li id="menu-item-858069" class="menu-item menu-item-type-custom menu-item-object-custom site-nav__menu-item menu-item-858069"&gt;&lt;a href="/subscribe/?utm_source=menu&amp;amp;utm_medium=desktop&amp;amp;utm_campaign=nrplus&amp;amp;utm_term=third&amp;amp;utm_content=subscribe"&gt;Subscribe&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;	&lt;/div&gt;
&lt;/nav&gt;
			&lt;a on="tap:site-menu.close" class="menu-close" role="button" tabindex="0"&gt;&lt;/a&gt;
		&lt;/amp-sidebar&gt;
			&lt;header id="masthead" class="site-header" role="banner"&gt;
		&lt;nav class="site-header__inner"&gt;
			&lt;button class="site-header__menu-open" on="tap:site-menu.toggle"&gt;
				&lt;span class="icon-navicon"&gt;&lt;svg width="21" height="18" xmlns="http://www.w3.org/2000/svg"&gt;
	&lt;title&gt;Open National Review Navigation&lt;/title&gt;
	&lt;path d="M0 0h21v2H0V0zm0 8h21v2H0V8zm0 8h21v2H0v-2z"&gt;&lt;/path&gt;
&lt;/svg&gt;
&lt;/span&gt;
			&lt;/button&gt;

			&lt;div class="site-title"&gt;
				&lt;a href="https://www.nationalreview.com/" rel="home"&gt;
					&lt;svg width="214" height="19" xmlns="http://www.w3.org/2000/svg"&gt;
	&lt;title&gt;Large National Review Logo&lt;/title&gt;
	&lt;path d="M196.44 18.103c-.09-.332-.167-.662-.264-.99-.722-2.401-1.443-4.801-2.17-7.2-.49-1.606-.945-3.245-1.446-4.857a93.028 93.028 0 0 0-1.15-3.396c-.129-.364-.298-.751-.796-.792V.47c.08 0 .158-.02.234-.02h4.855c.159 0 .351-.028.322.218a.307.307 0 0 1-.184.209.698.698 0 0 0-.514.88c.495 2.85 1.497 5.565 2.188 8.363.019.085.042.168.066.253 0 0 .018 0 .032.025.47-1.1.928-2.204 1.414-3.296.402-.908.825-1.808 1.252-2.704.548-1.132 1.117-2.263 1.662-3.414.077-.16.173-.236.332-.19.158.045.317.09.364.19.761 1.507 1.537 3.01 2.238 4.543.702 1.533 1.333 3.132 1.995 4.7a.694.694 0 0 0 .073.099c.182-.705.349-1.396.541-2.08.35-1.264.735-2.524 1.073-3.793.243-.918.441-1.849.64-2.777.098-.435-.233-.786-.723-.8V.466c.1 0 .187-.017.283-.017h4.447c.148 0 .335-.059.357.193.017.2-.148.207-.25.305a2.265 2.265 0 0 0-.616.875c-.596 1.802-1.156 3.618-1.717 5.432-.439 1.414-.862 2.828-1.287 4.244-.659 2.2-1.319 4.4-1.982 6.6h-.612c-.11-.283-.21-.565-.338-.848-.913-2.003-1.838-4-2.752-6.001-.43-.945-.847-1.896-1.252-2.85-.2-.457-.38-.921-.568-1.397-.025.035-.048.07-.07.107-.928 2.058-1.844 4.118-2.784 6.171-.466 1.024-.967 2.033-1.458 3.047-.284.596-.59 1.189-.887 1.782l-.548-.005v-.001zM0 .568h2.173a.615.615 0 0 1 .405.17c.534.61 1.044 1.23 1.559 1.844.415.494.811 1.007 1.238 1.479.965 1.092 1.93 2.187 2.92 3.257.827.887 1.698 1.733 2.547 2.616.483.512.932 1.052 1.43 1.618 0-.11.029-.191.029-.283V5.537c0-.867-.03-1.735-.07-2.6a7.225 7.225 0 0 0-.148-1.133.831.831 0 0 0-.817-.744V.718h4.948l.015.331c-.626.226-.802.512-.816 1.383-.028 1.591-.061 3.182-.064 4.773v10.67c0 .138-.057.373-.13.392a.505.505 0 0 1-.566-.139c-.65-.679-1.352-1.31-2.018-1.98-1.709-1.697-3.412-3.4-5.112-5.109-.661-.663-1.333-1.313-1.98-1.981-.484-.503-.932-1.034-1.47-1.518v.32c0 2.263-.016 4.504 0 6.754.03.757.096 1.512.2 2.263a.781.781 0 0 0 .596.78c.088.023.132.227.243.43H0v-.406c.512-.077.756-.284.81-.728.106-.773.173-1.551.2-2.331.025-2.527.025-5.056 0-7.585A123.266 123.266 0 0 0 .87 2.083C.85 1.43.633.911 0 .975V.567v.001zM99.407.432c.203.41.427.81.604 1.23.567 1.302 1.093 2.612 1.634 3.919.591 1.429 1.174 2.863 1.773 4.292.527 1.256 1.07 2.504 1.605 3.754.347.815.673 1.638 1.053 2.436.243.472.514.927.81 1.365a.589.589 0 0 0 .242.172c.283.145.283.142.283.453h-5.405c-.045-.22-.051-.39.254-.456.306-.064.283-.361.258-.602a4.194 4.194 0 0 0-.199-.733c-.172-.49-.358-.972-.542-1.46a.349.349 0 0 0-.38-.252c-1.63 0-3.258 0-4.888.015a.418.418 0 0 0-.32.203c-.26.704-.504 1.414-.727 2.129-.15.477-.099.514.339.731.103.052.125.258.199.425h-5.184v-.356c.803-.199 1.002-.971 1.297-1.596.751-1.59 1.414-3.216 2.13-4.829.517-1.185 1.04-2.371 1.547-3.562.965-2.264 1.922-4.527 2.877-6.79.068-.163.122-.328.185-.493l.554.005h.001zm1.299 11.464l-1.684-4.674-1.768 4.674h3.452zM25.326.432c.151.283.326.54.445.83.906 2.16 1.802 4.325 2.702 6.488.9 2.166 1.791 4.356 2.727 6.509.435 1.004.958 1.98 1.471 2.94.093.175.342.263.49.418.098.133.18.278.246.43h-5.432c-.056-.232-.025-.405.283-.5.308-.096.232-.413.173-.612a36.083 36.083 0 0 0-.748-2.193.408.408 0 0 0-.314-.184 370.134 370.134 0 0 0-4.954 0 .325.325 0 0 0-.249.145c-.283.787-.583 1.573-.823 2.374a.567.567 0 0 0 .258.503c.26.096.282.229.246.467h-5.092v-.368c.633-.104.848-.664 1.094-1.165a235.225 235.225 0 0 0 2.264-5.059c.71-1.62 1.414-3.248 2.096-4.877.823-1.923 1.64-3.845 2.45-5.77.05-.12.082-.248.124-.373l.543-.003zM26.64 11.9L24.96 7.23l-1.76 4.668h3.44zm135.715 6.204c-.284-.65-.55-1.301-.85-1.946a786.922 786.922 0 0 0-2.22-5.022c-.54-1.2-1.083-2.401-1.633-3.602-.823-1.79-1.64-3.587-2.493-5.376a5.567 5.567 0 0 0-.768-1.077c-.093-.116-.283-.151-.46-.239V.448h5.177c.32 0 .486.066.407.371-.2.085-.486.118-.537.25a1.13 1.13 0 0 0-.037.728c.38 1.05.787 2.085 1.208 3.113.498 1.22 1.03 2.422 1.525 3.64.348.85.657 1.74.984 2.604.034.064.073.125.117.184.163-.453.302-.874.466-1.287.513-1.297 1.039-2.584 1.549-3.88.588-1.5 1.171-3.005 1.737-4.527.156-.412.04-.655-.282-.766a.777.777 0 0 0-.241 0v-.41c.1 0 .195-.022.283-.022h4.618c.231 0 .383.043.336.315 0 .047-.048.127-.079.129-.608.066-.78.596-.994 1.013-.607 1.206-1.154 2.44-1.717 3.679a191.71 191.71 0 0 0-1.185 2.634c-.628 1.414-1.245 2.86-1.87 4.289-.427.972-.86 1.948-1.3 2.931-.394.888-.796 1.777-1.195 2.662l-.543.003-.003.002zm-43.731-2.665a1.873 1.873 0 0 0-.065.342v2.264h-10.262l-.017-.394c.747-.08.806-.687.832-1.252.07-1.721.116-3.443.139-5.167.022-1.756 0-3.513 0-5.27 0-1.046-.035-2.096-.072-3.144a5.197 5.197 0 0 0-.143-.987c-.093-.399-.283-.718-.786-.696v-.41h5.321c.074.283.037.416-.282.501a.753.753 0 0 0-.413.508 8.554 8.554 0 0 0-.214 1.617c-.027 1.313 0 2.625 0 3.938v7.544c0 .317.111.41.406.408 1.188 0 2.377.017 3.565-.017.362-.03.716-.12 1.05-.265a.815.815 0 0 0 .507-.74h.453l-.02 1.22zM63.499.502a8.735 8.735 0 0 1 4.92 1.254 8.258 8.258 0 0 1 3.91 5.52c.195.924.254 1.87.175 2.81a8.635 8.635 0 0 1-1.842 4.81 8.906 8.906 0 0 1-4.872 3.174 9.809 9.809 0 0 1-3.228.283 8.898 8.898 0 0 1-3.322-.872 9.159 9.159 0 0 1-2.983-2.292 8.654 8.654 0 0 1-1.91-3.93 9.29 9.29 0 0 1-.108-2.773 9.139 9.139 0 0 1 1.069-3.435 8.192 8.192 0 0 1 2.059-2.455A8.899 8.899 0 0 1 60.42.949a9.053 9.053 0 0 1 3.079-.447zM57.8 9.42c.063.474.102.952.19 1.414a5.376 5.376 0 0 0 5.916 4.472 5.188 5.188 0 0 0 3.63-1.85c1.103-1.327 1.47-2.892 1.37-4.56a6.055 6.055 0 0 0-1.237-3.317 5.144 5.144 0 0 0-1.887-1.544 5.438 5.438 0 0 0-3.507-.425c-1.87.364-3.145 1.476-3.91 3.162a5.88 5.88 0 0 0-.564 2.646v.002zm21.385 8.634H74.09l-.015-.349c.742-.1.85-.685.877-1.252.074-1.8.122-3.602.142-5.403.015-1.197-.037-2.396-.037-3.596 0-1.05.06-2.099.034-3.145-.02-.85-.103-1.718-.204-2.573-.057-.475-.283-.791-.823-.774V.567h2.263a.655.655 0 0 1 .407.243c.991 1.177 1.956 2.374 2.954 3.545.567.663 1.18 1.288 1.777 1.924 1.076 1.146 2.159 2.285 3.229 3.437.507.545.985 1.118 1.48 1.675.042.048.096.09.223.21-.031-.586-.057-1.083-.081-1.58V3.238a11.696 11.696 0 0 0-.184-1.415.796.796 0 0 0-.813-.733V.73h4.931v.346c-.668.15-.721.71-.738 1.22-.054 1.59-.071 3.182-.076 4.773V17.77c0 .174-.035.448-.136.496a.518.518 0 0 1-.6-.184c-1.152-1.171-2.34-2.308-3.509-3.463-.685-.676-1.361-1.358-2.04-2.04-.678-.682-1.335-1.319-1.98-1.98-.934-.962-1.853-1.941-2.779-2.911-.051-.054-.107-.102-.212-.201v.393c0 2.353-.014 4.707 0 7.072.02.68.089 1.356.207 2.026.048.3.147.633.565.676.077-.01.137.223.23.4v-.001zm63.124-.221h-3.63a1.384 1.384 0 0 1-1.301-.68c-.8-1.275-1.67-2.509-2.507-3.76-.407-.608-.848-1.19-1.202-1.834-.254-.468-.589-.505-1.055-.414v1.889c.017.99.034 1.981.07 2.973.015.3.064.597.142.886.059.314.331.54.651.54v.383h-4.99v-.363a.708.708 0 0 0 .681-.679c.083-.456.142-.92.178-1.383.015-4.165.015-8.33 0-12.494a7.786 7.786 0 0 0-.204-1.48.542.542 0 0 0-.65-.494V.55c.452-.033.896-.087 1.343-.098 1.183-.034 2.368-.091 3.55-.06a9.926 9.926 0 0 1 3.18.502 4.84 4.84 0 0 1 1.82 1.188c.902.918 1.256 2.044 1.296 3.312a5.331 5.331 0 0 1-.504 2.56 4.86 4.86 0 0 1-1.783 1.941c-.269.172-.549.324-.876.518l.644.866 2.92 3.961c.507.685.974 1.415 1.678 1.918.09.065.178.165.283.176.302.048.305.235.265.498h.001zm-9.686-9.303c.401 0 .783.017 1.162 0a2.631 2.631 0 0 0 1.678-.712c.76-.711.916-1.636.8-2.612a2.087 2.087 0 0 0-.984-1.549c-.818-.517-1.737-.458-2.66-.397l.004 5.27zm19.241 2.492c-.147-.418-.351-.565-.85-.587-.497-.023-.947-.054-1.413-.06h-2.357c0 .102-.02.19-.02.283v3.837c0 .348.132.495.478.497h3.678c.243-.016.482-.059.716-.125a.985.985 0 0 0 .796-.808h.346v3.764h-10.362v-.374a.774.774 0 0 0 .744-.733c.073-.373.117-.751.132-1.132.031-4.034.06-8.071.067-12.106a15.093 15.093 0 0 0-.202-2.026.653.653 0 0 0-.665-.594V.47h9.998v3.836l-.402.02c-.104-.92-.848-1.032-1.521-1.07-1.251-.07-2.508-.02-3.78-.02V7.65h2.21c.581 0 1.167-.037 1.75-.067a.594.594 0 0 0 .604-.457h.438c-.024.36-.06.703-.067 1.048v2.002c-.003.102.003.203.02.302.088.435.072.468-.339.544h.001zm38.086 3.06v3.723h-10.332l-.015-.34c.617-.133.762-.408.799-1.148.094-1.812.128-3.624.147-5.438.023-2.391.023-4.782 0-7.172 0-.755-.115-1.51-.2-2.263a.615.615 0 0 0-.662-.566v-.41h10.038V1.8c-.017.73-.054 1.462-.059 2.192 0 .285-.097.377-.39.31-.155-.899-.903-1.017-1.606-1.05-1.218-.059-2.447-.017-3.692-.017V7.65c.85 0 1.675.014 2.51 0 .535-.014 1.07-.06 1.598-.139.181-.03.343-.199.516-.306l-.049-.08h.383v3.881l-.108.062a2.291 2.291 0 0 0-.348-.339 1.277 1.277 0 0 0-.583-.283c-1.299-.026-2.597 0-3.92 0 0 .05-.016.147-.016.245v3.803c0 .36.137.5.51.5h3.599c.3.003.597-.05.876-.158.238-.09.432-.266.548-.49.101-.325.232-.362.458-.263l-.002-.001zM36.803 3.497c-1.226 0-2.403-.035-3.577 0-.668.025-1.076.458-1.195 1.13h-.393V.72H45.34c0 .108.015.216.015.324v3.19c0 .322-.072.485-.422.39-.192-.801-.619-1.133-1.444-1.133h-3.292V14.87c.025.703.092 1.403.2 2.097.054.427.323.64.85.744v.348h-5.49l-.017-.369c.716-.047.848-.608.9-1.177.153-1.92.199-3.848.138-5.774-.03-2.263.017-4.526.028-6.806-.005-.137-.005-.27-.005-.437l.002.002zM171.939.913V.469c.093 0 .181-.02.269-.02h4.719c.144 0 .334-.065.364.18.031.247-.101.256-.282.312-.422.129-.49.533-.518.892a35.03 35.03 0 0 0-.139 2.722c-.014 3.396-.014 6.782 0 10.16.028.633.095 1.265.2 1.892.029.434.364.785.796.834v.374h-5.443v-.386c.849-.113.871-.803.899-1.445.068-1.698.117-3.376.14-5.065.022-1.839 0-3.678 0-5.52 0-.945-.026-1.893-.074-2.828a7.487 7.487 0 0 0-.19-1.076.666.666 0 0 0-.742-.584v.002zM52.414.718v.405a.591.591 0 0 0-.6.412c-.142.43-.23.877-.265 1.327-.049 2.45-.06 4.902-.08 7.356 0 1.21-.03 2.422 0 3.632.028.97.11 1.944.203 2.911.04.402.168.778.674.872.107.02.178.235.309.421H47.08c-.069-.254-.03-.387.282-.48.467-.133.523-.617.565-1.017.078-.927.137-1.858.14-2.789.015-3.384.015-6.768 0-10.151-.022-.6-.088-1.198-.2-1.788-.08-.49-.284-.63-.765-.664V.718h5.311z" fill="#000" fill-rule="nonzero"&gt;&lt;/path&gt;
&lt;/svg&gt;
				&lt;/a&gt;
			&lt;/div&gt;
		&lt;/nav&gt;
	&lt;/header&gt;
	&lt;div class="site-header__below"&gt;
		&lt;amp-date-display datetime="now" layout="fixed-height" height="16" class="i-amphtml-layout-fixed-height i-amphtml-layout-size-defined" style="height:16px;" i-amphtml-layout="fixed-height"&gt;
			&lt;template type="amp-mustache"&gt;
				&lt;span class="site-header__below-date"&gt;{{monthNameShort}}. {{day}}, {{year}}&lt;/span&gt;
			&lt;/template&gt;
		&lt;/amp-date-display&gt;

		&lt;nav class="site-header__utility-nav" role="navigation" amp-access-hide&gt;
			&lt;ul class="site-header__utility-menu" role="menu"&gt;
				&lt;li class="site-header__utility-menu-item site-header__utility-menu-subscribe" amp-access="NOT loggedIn" amp-access-hide&gt;
					&lt;a role="menuitem" href="https://www.nationalreview.com/subscribe?utm_source=direct&amp;amp;utm_campaign=subscribe&amp;amp;utm_content=topnav2"&gt;Subscribe&lt;/a&gt;
				&lt;/li&gt;
				&lt;li class="site-header__utility-menu-item" amp-access="NOT loggedIn" amp-access-hide&gt;
					&lt;a on="tap:amp-access.login-sign-in" role="button" tabindex="0"&gt;Login&lt;/a&gt;
				&lt;/li&gt;
				&lt;li class="site-header__utility-menu-item" amp-access="loggedIn" amp-access-hide&gt;
					&lt;a on="tap:amp-access.login-sign-out" role="button" tabindex="0"&gt;Sign Out&lt;/a&gt;
				&lt;/li&gt;
			&lt;/ul&gt;
		&lt;/nav&gt;
	&lt;/div&gt;

	&lt;article class="article-single"&gt;
		
		&lt;div class="section-content--full section-content--full--amp-wrap"&gt;
			&lt;header class="article-header article-header--full" data-component="articleHeader"&gt;
	&lt;div class="article-header__inner"&gt;
							&lt;div class="article-header__top-section"&gt;
							&lt;/div&gt;
				
		
		&lt;div class="article-header__topic"&gt;
							&lt;div class="premium-badge premium-badge--vertical-line"&gt;
			&lt;a href="/tag/nrplus-member-articles/"&gt;
			&lt;span class="premium-badge__nr"&gt;NR&lt;/span&gt;
			&lt;span class="premium-badge__plus"&gt;PLUS&lt;/span&gt;
		&lt;/a&gt;
									&lt;a href="/world/" class="underline"&gt;World&lt;/a&gt;						
	&lt;/div&gt; &lt;!-- .premium-badge --&gt;
			
					&lt;/div&gt;

				&lt;h1 class="article-header__title"&gt;							The Trail Leading Back to the Wuhan Labs					&lt;/h1&gt;
		&lt;div class="article-header__meta"&gt;
			&lt;div class="article-header__meta-byline"&gt;
				&lt;div class="article-header__meta-author-container"&gt;
																															By &lt;a href="https://www.nationalreview.com/author/jim-geraghty/" title="Posts by Jim Geraghty" class="author article-header__meta-author" rel="author" data-author-id="123348" aria-haspopup="true"&gt;Jim Geraghty&lt;/a&gt;																
									&lt;/div&gt;

				&lt;time class="article-header__meta-pubdate separator" datetime="2020-04-03T13:20:25-04:00" title="April 3, 2020 1:20 PM"&gt;April 3, 2020 1:20 PM&lt;/time&gt;			&lt;/div&gt;

							&lt;div class="article-header__meta-nav"&gt;
					&lt;nav class="article-utility-nav article-utility-nav article-utility-nav--default"&gt;
	&lt;ul class="article-utility-nav__list" data-component="shareButtons"&gt;
							&lt;li class="article-utility-nav__item" data-service="facebook"&gt;
									&lt;a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.nationalreview.com%2F2020%2F04%2Fcoronavirus-china-trail-leading-back-to-wuhan-labs%2F" title="Share on Facebook" data-service="facebook"&gt;
						&lt;span class="circle-svg-icon circle-svg-icon--facebook"&gt;
							&lt;span class="screen-reader-text"&gt;Share on Facebook&lt;/span&gt;
							&lt;svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24"&gt;
  &lt;path d="M17 2v4h-2c-.69 0-1 .81-1 1.5V10h3v4h-3v8h-4v-8H7v-4h3V6a4 4 0 0 1 4-4h3z"&gt;&lt;/path&gt;
&lt;/svg&gt;
						&lt;/span&gt;
					&lt;/a&gt;
							&lt;/li&gt;
					&lt;li class="article-utility-nav__item" data-service="twitter"&gt;
									&lt;a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fwww.nationalreview.com%2F2020%2F04%2Fcoronavirus-china-trail-leading-back-to-wuhan-labs%2F&amp;amp;text=The%20Trail%20Leading%20Back%20to%20the%20Wuhan%20Labs" title="Share on Twitter" data-service="twitter"&gt;
						&lt;span class="circle-svg-icon circle-svg-icon--twitter"&gt;
							&lt;span class="screen-reader-text"&gt;Share on Twitter&lt;/span&gt;
							&lt;svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24"&gt;
  &lt;path d="M22.46 6c-.77.35-1.6.58-2.46.69.88-.53 1.56-1.37 1.88-2.38-.83.5-1.75.85-2.72 1.05C18.37 4.5 17.26 4 16 4c-2.35 0-4.27 1.92-4.27 4.29 0 .34.04.67.11.98C8.28 9.09 5.11 7.38 3 4.79c-.37.63-.58 1.37-.58 2.15 0 1.49.75 2.81 1.91 3.56-.71 0-1.37-.2-1.95-.5v.03c0 2.08 1.48 3.82 3.44 4.21a4.22 4.22 0 0 1-1.93.07 4.28 4.28 0 0 0 4 2.98 8.521 8.521 0 0 1-5.33 1.84c-.34 0-.68-.02-1.02-.06C3.44 20.29 5.7 21 8.12 21 16 21 20.33 14.46 20.33 8.79c0-.19 0-.37-.01-.56.84-.6 1.56-1.36 2.14-2.23z"&gt;&lt;/path&gt;
&lt;/svg&gt;
						&lt;/span&gt;
					&lt;/a&gt;
							&lt;/li&gt;
					&lt;li class="article-utility-nav__item" data-service="flipboard"&gt;
									&lt;a class="circle-icon--flipboard" data-flip-widget="shareflip" href="https://share.flipboard.com/bookmarklet/popout?v=2&amp;amp;title=The%20Trail%20Leading%20Back%20to%20the%20Wuhan%20Labs&amp;amp;url=https%3A%2F%2Fwww.nationalreview.com%2F2020%2F04%2Fcoronavirus-china-trail-leading-back-to-wuhan-labs%2F&amp;amp;utm_campaign=tools&amp;amp;utm_medium=article-share&amp;amp;utm_source=https://www.nationalreview.com/" title="Share on Flipboard" data-service="flipboard"&gt;
						&lt;span class="circle-svg-icon circle-svg-icon--flipboard"&gt;
							&lt;span class="screen-reader-text"&gt;Share on Flipboard&lt;/span&gt;
							&lt;amp-img src="https://www.nationalreview.com/wp-content/themes/national-review/static/images/flipboard.png" width="30" height="30" class="amp-wp-enforced-sizes i-amphtml-layout-intrinsic i-amphtml-layout-size-defined" layout="intrinsic" i-amphtml-layout="intrinsic"&gt;&lt;i-amphtml-sizer class="i-amphtml-sizer"&gt;&lt;img alt="" aria-hidden="true" class="i-amphtml-intrinsic-sizer" role="presentation" src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzMwJyB3aWR0aD0nMzAnIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"&gt;&lt;/i-amphtml-sizer&gt;&lt;noscript&gt;&lt;img src="https://www.nationalreview.com/wp-content/themes/national-review/static/images/flipboard.png" width="30" height="30" class=""&gt;&lt;/noscript&gt;&lt;/amp-img&gt;
						&lt;/span&gt;
					&lt;/a&gt;
							&lt;/li&gt;
					&lt;li class="article-utility-nav__item" data-service="email"&gt;
									&lt;a href="mailto:?body=The%20Trail%20Leading%20Back%20to%20the%20Wuhan%20Labs%20https://www.nationalreview.com/2020/04/coronavirus-china-trail-leading-back-to-wuhan-labs/" title="Email this article" data-service="email"&gt;
						&lt;span class="circle-svg-icon circle-svg-icon--email"&gt;
							&lt;span class="screen-reader-text"&gt;Email this article&lt;/span&gt;
							&lt;svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24"&gt;
  &lt;path d="M20 8l-8 5-8-5V6l8 5 8-5m0-2H4c-1.11 0-2 .89-2 2v12a2 2 0 0 0 2 2h16a2 2 0 0 0 2-2V6a2 2 0 0 0-2-2z"&gt;&lt;/path&gt;
&lt;/svg&gt;
						&lt;/span&gt;
					&lt;/a&gt;
							&lt;/li&gt;
		
			&lt;/ul&gt;
&lt;/nav&gt;
				&lt;/div&gt;
					&lt;/div&gt;
	&lt;/div&gt;
&lt;/header&gt;

			&lt;div class="article-content"&gt;
				&lt;figure class="inline-image inline-image--captioned "&gt;
	
	
	&lt;amp-img width="789" height="460" src="https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/02/wuhan-coronavirus-10.jpg?fit=789%2C460&amp;amp;ssl=1" class="attachment-featured-single size-featured-single amp-wp-enforced-sizes i-amphtml-layout-intrinsic i-amphtml-layout-size-defined" alt="" sizes="(max-width: 789px) 100vw, 789px" srcset="https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/02/wuhan-coronavirus-10.jpg?resize=300%2C175&amp;amp;ssl=1 300w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/02/wuhan-coronavirus-10.jpg?resize=768%2C448&amp;amp;ssl=1 768w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/02/wuhan-coronavirus-10.jpg?resize=459%2C268&amp;amp;ssl=1 459w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/02/wuhan-coronavirus-10.jpg?resize=789%2C460&amp;amp;ssl=1 789w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/02/wuhan-coronavirus-10.jpg?resize=50%2C29&amp;amp;ssl=1 50w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/02/wuhan-coronavirus-10.jpg?w=1592&amp;amp;ssl=1 1592w" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"&gt;&lt;i-amphtml-sizer class="i-amphtml-sizer"&gt;&lt;img alt="" aria-hidden="true" class="i-amphtml-intrinsic-sizer" role="presentation" src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzQ2MCcgd2lkdGg9Jzc4OScgeG1sbnM9J2h0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnJyB2ZXJzaW9uPScxLjEnLz4="&gt;&lt;/i-amphtml-sizer&gt;&lt;noscript&gt;&lt;img width="789" height="460" src="https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/02/wuhan-coronavirus-10.jpg?fit=789%2C460&amp;amp;ssl=1" class="attachment-featured-single size-featured-single" alt="" loading="eager" sizes="(max-width: 789px) 100vw, 789px" srcset="https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/02/wuhan-coronavirus-10.jpg?resize=300%2C175&amp;amp;ssl=1 300w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/02/wuhan-coronavirus-10.jpg?resize=768%2C448&amp;amp;ssl=1 768w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/02/wuhan-coronavirus-10.jpg?resize=459%2C268&amp;amp;ssl=1 459w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/02/wuhan-coronavirus-10.jpg?resize=789%2C460&amp;amp;ssl=1 789w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/02/wuhan-coronavirus-10.jpg?resize=50%2C29&amp;amp;ssl=1 50w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/02/wuhan-coronavirus-10.jpg?w=1592&amp;amp;ssl=1 1592w"&gt;&lt;/noscript&gt;&lt;/amp-img&gt;
	
	
			&lt;figcaption&gt;
			Medical workers in protective suits attend to a patient inside an isolated ward of the Wuhan Red Cross Hospital in Wuhan, the epicenter of the novel coronavirus outbreak, in Hubei Province, China, February 16, 2020.											&lt;cite&gt;(China Daily via Reuters)&lt;/cite&gt;
					&lt;/figcaption&gt;
	&lt;/figure&gt;
			&lt;/div&gt;&lt;!-- .article-content --&gt;

							&lt;section amp-access="NOT hasAccess" amp-access-hide&gt;
					&lt;div class="article-content"&gt;
						&lt;p&gt;
							There’s no proof the coronavirus originated in a laboratory, but we can’t take the Chinese government’s denials at face value.						&lt;/p&gt;
					&lt;/div&gt;

					&lt;p class="article-paywall"&gt;
						&lt;a on="tap:amp-access.login-sign-in" class="button" data-z-depth="2" role="button" tabindex="0"&gt;
							&lt;span class="button-text"&gt;
								Sign in here to read more.							&lt;/span&gt;
						&lt;/a&gt;
					&lt;/p&gt;
				&lt;/section&gt;
				&lt;div amp-access="hasAccess" class="article-content"&gt;
											&lt;span class="article-header__subtitle"&gt;There’s no proof the coronavirus accidentally escaped from a laboratory, but we can’t take the Chinese government’s denials at face value.&lt;/span&gt;
										&lt;p&gt;&lt;span class="drop"&gt;
					&lt;span id="nrplus-badge-left"&gt;
						&lt;span class="nrplus-badge-rule"&gt;&lt;/span&gt;
						&lt;span class="nrplus-badge-inner"&gt;NRPLUS MEMBER ARTICLE&lt;/span&gt;
					&lt;/span&gt;
					&lt;span class="drop"&gt;I&lt;/span&gt;
				&lt;/span&gt;&lt;span class="small_caps"&gt;t&lt;/span&gt; is understandable that many would be wary of the notion that the origin of the coronavirus could be discovered by some &lt;a href="https://www.imdb.com/name/nm8426798/bio" target="_blank" rel="noopener noreferrer"&gt;documentary filmmaker&lt;/a&gt; who used to live in China. Matthew Tye, who creates YouTube videos, &lt;a href="https://www.youtube.com/watch?v=bpQFCcSI0pU&amp;amp;feature=youtu.be" target="_blank" rel="noopener noreferrer"&gt;contends he has identified the source of the coronavirus&lt;/a&gt; — and a great deal of the information that he presents, obtained from public records posted on the Internet, checks out.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.whiov.cas.cn/105341/" target="_blank" rel="noopener noreferrer"&gt;The Wuhan Institute of Virology in China indeed posted a job opening&lt;/a&gt; on November 18, 2019, “asking for scientists to come research the relationship between the coronavirus and bats.”&lt;/p&gt;
&lt;p&gt;&lt;amp-img class="aligncenter size-full wp-image-797184 amp-wp-enforced-sizes i-amphtml-layout-intrinsic i-amphtml-layout-size-defined" src="https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-1.jpg?resize=796%2C469&amp;amp;ssl=1" alt="" width="796" height="469" data-image-id="797184" srcset="https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-1.jpg?w=975&amp;amp;ssl=1 975w, https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-1.jpg?resize=300%2C177&amp;amp;ssl=1 300w, https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-1.jpg?resize=768%2C452&amp;amp;ssl=1 768w, https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-1.jpg?resize=459%2C270&amp;amp;ssl=1 459w, https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-1.jpg?resize=781%2C460&amp;amp;ssl=1 781w, https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-1.jpg?resize=50%2C29&amp;amp;ssl=1 50w" sizes="(max-width: 796px) 100vw, 796px" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"&gt;&lt;i-amphtml-sizer class="i-amphtml-sizer"&gt;&lt;img alt="" aria-hidden="true" class="i-amphtml-intrinsic-sizer" role="presentation" src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzQ2OScgd2lkdGg9Jzc5NicgeG1sbnM9J2h0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnJyB2ZXJzaW9uPScxLjEnLz4="&gt;&lt;/i-amphtml-sizer&gt;&lt;noscript&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-797184" src="https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-1.jpg?resize=796%2C469&amp;amp;ssl=1" alt="" width="796" height="469" srcset="https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-1.jpg?w=975&amp;amp;ssl=1 975w, https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-1.jpg?resize=300%2C177&amp;amp;ssl=1 300w, https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-1.jpg?resize=768%2C452&amp;amp;ssl=1 768w, https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-1.jpg?resize=459%2C270&amp;amp;ssl=1 459w, https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-1.jpg?resize=781%2C460&amp;amp;ssl=1 781w, https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-1.jpg?resize=50%2C29&amp;amp;ssl=1 50w" sizes="(max-width: 796px) 100vw, 796px"&gt;&lt;/noscript&gt;&lt;/amp-img&gt;&lt;/p&gt;
&lt;p&gt;The &lt;a href="http://www.whiov.cas.cn/105341/201911/t20191118_5438006.html" target="_blank" rel="noopener noreferrer"&gt;Google translation of the job posting is&lt;/a&gt;: “Taking bats as the research object, I will answer the molecular mechanism that can coexist with Ebola and SARS- associated coronavirus for a long time without disease, and its relationship with flight and longevity. Virology, immunology, cell biology, and multiple omics are used to compare the differences between humans and other mammals.” (“Omics” is a term for a subfield within biology, such as genomics or glycomics.)&lt;/p&gt;
&lt;p&gt;&lt;amp-img class="aligncenter size-full wp-image-797185 amp-wp-enforced-sizes i-amphtml-layout-intrinsic i-amphtml-layout-size-defined" src="https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-2.jpg?resize=796%2C310&amp;amp;ssl=1" alt="" width="796" height="310" data-image-id="797185" srcset="https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-2.jpg?w=956&amp;amp;ssl=1 956w, https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-2.jpg?resize=300%2C117&amp;amp;ssl=1 300w, https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-2.jpg?resize=768%2C299&amp;amp;ssl=1 768w, https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-2.jpg?resize=459%2C179&amp;amp;ssl=1 459w, https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-2.jpg?resize=800%2C311&amp;amp;ssl=1 800w, https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-2.jpg?resize=50%2C19&amp;amp;ssl=1 50w" sizes="(max-width: 796px) 100vw, 796px" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"&gt;&lt;i-amphtml-sizer class="i-amphtml-sizer"&gt;&lt;img alt="" aria-hidden="true" class="i-amphtml-intrinsic-sizer" role="presentation" src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzMxMCcgd2lkdGg9Jzc5NicgeG1sbnM9J2h0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnJyB2ZXJzaW9uPScxLjEnLz4="&gt;&lt;/i-amphtml-sizer&gt;&lt;noscript&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-797185" src="https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-2.jpg?resize=796%2C310&amp;amp;ssl=1" alt="" width="796" height="310" srcset="https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-2.jpg?w=956&amp;amp;ssl=1 956w, https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-2.jpg?resize=300%2C117&amp;amp;ssl=1 300w, https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-2.jpg?resize=768%2C299&amp;amp;ssl=1 768w, https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-2.jpg?resize=459%2C179&amp;amp;ssl=1 459w, https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-2.jpg?resize=800%2C311&amp;amp;ssl=1 800w, https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-2.jpg?resize=50%2C19&amp;amp;ssl=1 50w" sizes="(max-width: 796px) 100vw, 796px"&gt;&lt;/noscript&gt;&lt;/amp-img&gt;&lt;/p&gt;
&lt;p&gt;On December 24, 2019, the Wuhan Institute of Virology &lt;a href="http://www.whiov.cas.cn/105341/201912/t20191224_5471634.html" target="_blank" rel="noopener noreferrer"&gt;posted a second job posting&lt;/a&gt;. The translation of that posting includes the declaration, “long-term research on the pathogenic biology of bats carrying important viruses has confirmed the origin of bats of major new human and livestock infectious diseases such as SARS and SADS, and a large number of new bat and rodent new viruses have been discovered and identified.”&lt;/p&gt;
&lt;p&gt;&lt;amp-img class="aligncenter size-full wp-image-797186 amp-wp-enforced-sizes i-amphtml-layout-intrinsic i-amphtml-layout-size-defined" src="https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-3.jpg?resize=796%2C325&amp;amp;ssl=1" alt="" width="796" height="325" data-image-id="797186" srcset="https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-3.jpg?w=980&amp;amp;ssl=1 980w, https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-3.jpg?resize=300%2C122&amp;amp;ssl=1 300w, https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-3.jpg?resize=768%2C313&amp;amp;ssl=1 768w, https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-3.jpg?resize=459%2C187&amp;amp;ssl=1 459w, https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-3.jpg?resize=800%2C327&amp;amp;ssl=1 800w, https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-3.jpg?resize=50%2C20&amp;amp;ssl=1 50w" sizes="(max-width: 796px) 100vw, 796px" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"&gt;&lt;i-amphtml-sizer class="i-amphtml-sizer"&gt;&lt;img alt="" aria-hidden="true" class="i-amphtml-intrinsic-sizer" role="presentation" src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzMyNScgd2lkdGg9Jzc5NicgeG1sbnM9J2h0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnJyB2ZXJzaW9uPScxLjEnLz4="&gt;&lt;/i-amphtml-sizer&gt;&lt;noscript&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-797186" src="https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-3.jpg?resize=796%2C325&amp;amp;ssl=1" alt="" width="796" height="325" srcset="https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-3.jpg?w=980&amp;amp;ssl=1 980w, https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-3.jpg?resize=300%2C122&amp;amp;ssl=1 300w, https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-3.jpg?resize=768%2C313&amp;amp;ssl=1 768w, https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-3.jpg?resize=459%2C187&amp;amp;ssl=1 459w, https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-3.jpg?resize=800%2C327&amp;amp;ssl=1 800w, https://i0.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-3.jpg?resize=50%2C20&amp;amp;ssl=1 50w" sizes="(max-width: 796px) 100vw, 796px"&gt;&lt;/noscript&gt;&lt;/amp-img&gt;&lt;/p&gt;
&lt;p&gt;Tye contends that that posting meant, “we’ve discovered a new and terrible virus, and would like to recruit people to come deal with it.” He also contends that “news didn’t come out about coronavirus until ages after that.” Doctors in Wuhan &lt;a href="https://www.nationalreview.com/the-morning-jolt/chinas-devastating-lies/" target="_blank" rel="noopener noreferrer"&gt;knew that they were dealing with a cluster of pneumonia cases as December progressed&lt;/a&gt;, but it is accurate to say that a very limited number of people knew about this particular strain of coronavirus and its severity at the time of that job posting. By December 31, about three weeks after doctors first noticed the cases, the Chinese government notified the World Health Organization and the &lt;a href="https://www.scmp.com/news/china/politics/article/3044050/mystery-illness-hits-chinas-wuhan-city-nearly-30-hospitalised" target="_blank" rel="noopener noreferrer"&gt;first media reports&lt;/a&gt; about a “mystery pneumonia” appeared outside China.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Scientific American&lt;/em&gt; &lt;a href="https://www.scientificamerican.com/article/how-chinas-bat-woman-hunted-down-viruses-from-sars-to-the-new-coronavirus1/" target="_blank" rel="noopener noreferrer"&gt;verifies much of the information&lt;/a&gt; Tye mentions about Shi Zhengli, the Chinese virologist nicknamed “Bat Woman” for her work with that species.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Shi — a virologist who is often called China’s “bat woman” by her colleagues because of her virus-hunting expeditions in bat caves over the past 16 years — walked out of the conference she was attending in Shanghai and hopped on the next train back to Wuhan. “I wondered if [the municipal health authority] got it wrong,” she says. “I had never expected this kind of thing to happen in Wuhan, in central China.” Her studies had shown that the southern, subtropical areas of Guangdong, Guangxi and Yunnan have the greatest risk of coronaviruses jumping to humans from animals — &lt;em&gt;particularly bats, a known reservoir for many viruses. If coronaviruses were the culprit, she remembers thinking, “could they have come from our lab?”&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;. . . By January 7 the Wuhan team determined that the new virus had indeed caused the disease those patients suffered — a conclusion based on results from polymerase chain reaction analysis, full genome sequencing, antibody tests of blood samples and the virus’s ability to infect human lung cells in a petri dish. The genomic sequence of the virus — now officially called SARS-CoV-2 because it is related to the SARS pathogen — was 96 percent identical to that of a coronavirus the researchers had identified in horseshoe bats in Yunnan, they reported in a &lt;a href="https://www.nature.com/articles/s41586-020-2012-7" target="_blank" rel="noopener noreferrer"&gt;paper&lt;/a&gt; published last month in &lt;em&gt;Nature&lt;/em&gt;. “It’s crystal clear that bats, once again, are the natural reservoir,” says Daszak, who was not involved in the study.&lt;strong&gt;&lt;br&gt;
&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Some scientists aren’t convinced that the virus jumped straight from bats to human beings, but &lt;a href="https://www.newyorker.com/science/elements/from-bats-to-human-lungs-the-evolution-of-a-coronavirus" target="_blank" rel="noopener noreferrer"&gt;there are a few problems with the theory that some other animal was an intermediate transmitter of COVID-19&lt;/a&gt; from bats to humans:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Analyses of the &lt;em&gt;SARS&lt;/em&gt;-CoV-2 genome indicate a single spillover event, meaning the virus jumped only once from an animal to a person, which makes it likely that the virus was circulating among people before December. Unless more information about the animals at the Wuhan market is released, the transmission chain may never be clear. There are, however, numerous possibilities. A bat hunter or a wildlife trafficker might have brought the virus to the market. Pangolins happen to carry a coronavirus, which they might have picked up from bats years ago, and which is, in one crucial part of its genome, virtually identical to &lt;em&gt;SARS&lt;/em&gt;-CoV-2. But no one has yet found evidence that pangolins were at the Wuhan market, or even that venders there trafficked pangolins.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;On February 4 — one week before the World Health Organization &lt;a href="https://www.who.int/emergencies/diseases/novel-coronavirus-2019/technical-guidance/naming-the-coronavirus-disease-(covid-2019)-and-the-virus-that-causes-it" target="_blank" rel="noopener noreferrer"&gt;decided to officially name this virus “COVID-19”&lt;/a&gt; — &lt;a href="https://www.nature.com/articles/s41422-020-0282-0" target="_blank" rel="noopener noreferrer"&gt;the journal&lt;em&gt; Cell Research&lt;/em&gt;&lt;/a&gt; posted a notice written by scientists at the Wuhan Institute of Virology about the virus, concluding, “our findings reveal that remdesivir and chloroquine are highly effective in the control of 2019-nCoV infection in vitro. Since these compounds have been used in human patients with a safety track record and shown to be effective against various ailments, we suggest that they should be assessed in human patients suffering from the novel coronavirus disease.” One of the authors of that notice was the “bat woman,” Shi Zhengli.&lt;/p&gt;
&lt;p&gt;In his YouTube video, Tye focuses his attention on a &lt;a href="https://www.researchgate.net/scientific-contributions/2035568207_Yanling_Huang" target="_blank" rel="noopener noreferrer"&gt;researcher at the Wuhan Institute of Virology&lt;/a&gt; named Huang Yanling: “Most people believe her to be patient zero, and most people believe she is dead.”&lt;/p&gt;
&lt;p&gt;There was enough discussion of rumors about Huang Yanling online in China to &lt;a href="http://www.whiov.ac.cn/tzgg_105342/202002/t20200216_5500201.html" target="_blank" rel="noopener noreferrer"&gt;spur an official denial&lt;/a&gt;. On February 16, the Wuhan Institute of Virology denied that patient zero was one of their employees, and interestingly named her specifically: “Recently there has been fake information about Huang Yanling, a graduate from our institute, claiming that she was patient zero in the novel coronavirus.” &lt;a href="https://www.scmp.com/news/china/society/article/3050872/chinese-research-lab-denies-rumours-links-first-coronavirus" target="_blank" rel="noopener noreferrer"&gt;Press accounts quote the institute as saying&lt;/a&gt;, “Huang was a graduate student at the institute until 2015, when she left the province and had not returned since. Huang was in good health and had not been diagnosed with disease, it added.” None of her publicly available &lt;a href="https://www.researchgate.net/scientific-contributions/2035568207_Yanling_Huang" target="_blank" rel="noopener noreferrer"&gt;research papers&lt;/a&gt; are dated after 2015.&lt;/p&gt;
&lt;p&gt;&lt;amp-img class="aligncenter size-full wp-image-797187 amp-wp-enforced-sizes i-amphtml-layout-intrinsic i-amphtml-layout-size-defined" src="https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-4.jpg?resize=796%2C279&amp;amp;ssl=1" alt="" width="796" height="279" data-image-id="797187" srcset="https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-4.jpg?w=976&amp;amp;ssl=1 976w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-4.jpg?resize=300%2C105&amp;amp;ssl=1 300w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-4.jpg?resize=768%2C269&amp;amp;ssl=1 768w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-4.jpg?resize=459%2C161&amp;amp;ssl=1 459w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-4.jpg?resize=800%2C280&amp;amp;ssl=1 800w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-4.jpg?resize=50%2C18&amp;amp;ssl=1 50w" sizes="(max-width: 796px) 100vw, 796px" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"&gt;&lt;i-amphtml-sizer class="i-amphtml-sizer"&gt;&lt;img alt="" aria-hidden="true" class="i-amphtml-intrinsic-sizer" role="presentation" src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzI3OScgd2lkdGg9Jzc5NicgeG1sbnM9J2h0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnJyB2ZXJzaW9uPScxLjEnLz4="&gt;&lt;/i-amphtml-sizer&gt;&lt;noscript&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-797187" src="https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-4.jpg?resize=796%2C279&amp;amp;ssl=1" alt="" width="796" height="279" srcset="https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-4.jpg?w=976&amp;amp;ssl=1 976w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-4.jpg?resize=300%2C105&amp;amp;ssl=1 300w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-4.jpg?resize=768%2C269&amp;amp;ssl=1 768w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-4.jpg?resize=459%2C161&amp;amp;ssl=1 459w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-4.jpg?resize=800%2C280&amp;amp;ssl=1 800w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-4.jpg?resize=50%2C18&amp;amp;ssl=1 50w" sizes="(max-width: 796px) 100vw, 796px"&gt;&lt;/noscript&gt;&lt;/amp-img&gt;&lt;/p&gt;
&lt;p&gt;The &lt;a href="http://159.226.126.127:8082/web/17190/20" target="_blank" rel="noopener noreferrer"&gt;web page for the Wuhan Institute of Virology’s Lab of Diagnostic Microbiology&lt;/a&gt; does indeed still have “Huang Yanling” listed as a 2012 graduate student, and her picture and biography appear to have been recently removed — as have those of two other graduate students from 2013, Wang Mengyue and Wei Cuihua.&lt;/p&gt;
&lt;p&gt;&lt;amp-img class="aligncenter size-full wp-image-797188 amp-wp-enforced-sizes i-amphtml-layout-intrinsic i-amphtml-layout-size-defined" src="https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-5.jpg?resize=796%2C440&amp;amp;ssl=1" alt="" width="796" height="440" data-image-id="797188" srcset="https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-5.jpg?w=997&amp;amp;ssl=1 997w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-5.jpg?resize=300%2C166&amp;amp;ssl=1 300w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-5.jpg?resize=768%2C424&amp;amp;ssl=1 768w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-5.jpg?resize=459%2C254&amp;amp;ssl=1 459w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-5.jpg?resize=800%2C442&amp;amp;ssl=1 800w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-5.jpg?resize=50%2C28&amp;amp;ssl=1 50w" sizes="(max-width: 796px) 100vw, 796px" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"&gt;&lt;i-amphtml-sizer class="i-amphtml-sizer"&gt;&lt;img alt="" aria-hidden="true" class="i-amphtml-intrinsic-sizer" role="presentation" src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzQ0MCcgd2lkdGg9Jzc5NicgeG1sbnM9J2h0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnJyB2ZXJzaW9uPScxLjEnLz4="&gt;&lt;/i-amphtml-sizer&gt;&lt;noscript&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-797188" src="https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-5.jpg?resize=796%2C440&amp;amp;ssl=1" alt="" width="796" height="440" srcset="https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-5.jpg?w=997&amp;amp;ssl=1 997w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-5.jpg?resize=300%2C166&amp;amp;ssl=1 300w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-5.jpg?resize=768%2C424&amp;amp;ssl=1 768w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-5.jpg?resize=459%2C254&amp;amp;ssl=1 459w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-5.jpg?resize=800%2C442&amp;amp;ssl=1 800w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-5.jpg?resize=50%2C28&amp;amp;ssl=1 50w" sizes="(max-width: 796px) 100vw, 796px"&gt;&lt;/noscript&gt;&lt;/amp-img&gt;&lt;/p&gt;
&lt;p&gt;Her name still has a hyperlink, &lt;a href="http://159.226.126.127:8082/web/17190/46" target="_blank" rel="noopener noreferrer"&gt;but the linked page is blank&lt;/a&gt;. The pages for Wang Mengyue and Wei Cuihua are blank as well.&lt;/p&gt;
&lt;p&gt;&lt;amp-img class="aligncenter size-full wp-image-797182 amp-wp-enforced-sizes i-amphtml-layout-intrinsic i-amphtml-layout-size-defined" src="https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-6.jpg?resize=796%2C386&amp;amp;ssl=1" alt="" width="796" height="386" data-image-id="797182" srcset="https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-6.jpg?w=976&amp;amp;ssl=1 976w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-6.jpg?resize=300%2C145&amp;amp;ssl=1 300w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-6.jpg?resize=768%2C372&amp;amp;ssl=1 768w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-6.jpg?resize=459%2C222&amp;amp;ssl=1 459w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-6.jpg?resize=800%2C388&amp;amp;ssl=1 800w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-6.jpg?resize=50%2C24&amp;amp;ssl=1 50w" sizes="(max-width: 796px) 100vw, 796px" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"&gt;&lt;i-amphtml-sizer class="i-amphtml-sizer"&gt;&lt;img alt="" aria-hidden="true" class="i-amphtml-intrinsic-sizer" role="presentation" src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzM4Nicgd2lkdGg9Jzc5NicgeG1sbnM9J2h0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnJyB2ZXJzaW9uPScxLjEnLz4="&gt;&lt;/i-amphtml-sizer&gt;&lt;noscript&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-797182" src="https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-6.jpg?resize=796%2C386&amp;amp;ssl=1" alt="" width="796" height="386" srcset="https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-6.jpg?w=976&amp;amp;ssl=1 976w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-6.jpg?resize=300%2C145&amp;amp;ssl=1 300w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-6.jpg?resize=768%2C372&amp;amp;ssl=1 768w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-6.jpg?resize=459%2C222&amp;amp;ssl=1 459w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-6.jpg?resize=800%2C388&amp;amp;ssl=1 800w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-6.jpg?resize=50%2C24&amp;amp;ssl=1 50w" sizes="(max-width: 796px) 100vw, 796px"&gt;&lt;/noscript&gt;&lt;/amp-img&gt;&lt;/p&gt;
&lt;p&gt;(For what it is worth, the &lt;em&gt;South China Morning Post&lt;/em&gt; — a newspaper seen &lt;a href="https://www.nytimes.com/2018/03/31/world/asia/south-china-morning-post-hong-kong-alibaba.html" target="_blank" rel="noopener noreferrer"&gt;as being generally pro-Beijing&lt;/a&gt; — &lt;a href="https://www.scmp.com/news/china/society/article/3074991/coronavirus-chinas-first-confirmed-covid-19-case-traced-back" target="_blank" rel="noopener noreferrer"&gt;reported on March 13&lt;/a&gt; that “according to the government data seen by the Post, a 55 year-old from Hubei province could have been the first person to have contracted Covid-19 on November 17.”)&lt;/p&gt;
&lt;p&gt;On February 17, Zhen Shuji, a Hong Kong correspondent &lt;a href="http://www.rfi.fr/cn/%E4%B8%AD%E5%9B%BD/20200217-%E6%AD%A6%E6%B1%89%E7%A0%94%E7%A9%B6%E6%89%80%E5%A4%96%E6%B3%84%E7%97%85%E6%AF%92%E4%BC%A0%E8%A8%80%E6%9C%AA%E6%AD%A2%E5%8F%88%E6%9C%89%E6%B6%88%E6%81%AF%E6%8C%87-%E9%9B%B6%E5%8F%B7%E7%97%85%E4%BA%BA-%E6%98%AF%E7%A0%94%E7%A9%B6%E5%91%98" target="_blank" rel="noopener noreferrer"&gt;from the French public-radio service Radio France Internationale, reported&lt;/a&gt;: “when a reporter from the Beijing News of the Mainland asked the institute for rumors about patient zero, the institute first denied that there was a researcher Huang Yanling, but after learning that the name of the person on the Internet did exist, acknowledged that the person had worked at the firm but has now left the office and is unaccounted for.”&lt;/p&gt;
&lt;div class="jwplayer-inline" data-component="jwplayerInline"&gt;
&lt;p class="jwplayer-inline--title" data-video-title data-prefix="NOW WATCH"&gt;

			&lt;/p&gt;&lt;div id="jwplayer_XtkmEUkk_8HR1M1dH_div"&gt;&lt;/div&gt;
			
			
		&lt;/div&gt;
&lt;p&gt;Tye says, “everyone on the Chinese internet is searching for [Huang Yanling] but most believe that her body was quickly cremated and the people working at the crematorium were perhaps infected as they were not given any information about the virus.” (The U.S. Centers for Disease Control and Prevention says that &lt;a href="https://www.cdc.gov/coronavirus/2019-ncov/faq.html" target="_blank" rel="noopener noreferrer"&gt;handling the body of someone who has died of coronavirus is safe&lt;/a&gt; — including embalming and cremation — as long as the standard safety protocols for handing a decedent are used. It’s anyone’s guess as to whether those safety protocols were sufficiently used in China before the outbreak’s scope was known.)&lt;/p&gt;
&lt;p&gt;As Tye observes, a public appearance by Huang Yanling would dispel a lot of the public rumors, and is the sort of thing the Chinese government would quickly arrange in normal circumstances — presuming that Huang Yanling was still alive. Several officials at the Wuhan Institute of Virology issued public statements that Huang was in good health and that no one at the institute has been infected with COVID-19. In any case, the mystery around Huang Yanling may be moot, but it does point to the lab covering up something about her.&lt;/p&gt;
&lt;p&gt;China Global Television Network, a state-owned television broadcaster, &lt;a href="https://news.cgtn.com/news/2020-02-23/Rumors-stop-with-the-wise-OjMaO0RjGM/index.html" target="_blank" rel="noopener noreferrer"&gt;illuminated another rumor&lt;/a&gt; while attempting to dispel it in a February 23 report entitled “Rumors Stop With the Wise”:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;On February 17, a Weibo user who claimed herself to be Chen Quanjiao, a researcher at the Wuhan Institute of Virology, reported to the public that the Director of the Institute was responsible for leaking the novel coronavirus. The Weibo post threw a bomb in the cyberspace and the public was shocked. Soon Chen herself stepped out and declared that she had never released any report information and expressed great indignation at such identity fraud on Weibo. It has been confirmed that that particular Weibo account had been shut down several times due to the spread of misinformation about COVID-19.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;That Radio France Internationale report on February 17 also mentioned the next key part of the Tye’s YouTube video. “Xiaobo Tao, a scholar from South China University of Technology, recently published a report that researchers at Wuhan Virus Laboratory were splashed with bat blood and urine, and then quarantined for 14 days.” HK01, another Hong Kong-based news site, &lt;a href="https://www.hk01.com/%E7%A4%BE%E6%9C%83%E6%96%B0%E8%81%9E/435123/%E6%AD%A6%E6%BC%A2%E8%82%BA%E7%82%8E-%E6%AD%A6%E6%BC%A2%E7%96%BE%E6%8E%A7%E7%A0%94%E7%A9%B6%E5%93%A1%E6%9B%BE%E8%A2%AB%E8%9D%99%E8%9D%A0%E8%A5%B2%E6%93%8A-%E5%85%A7%E5%9C%B0%E5%AD%B8%E8%80%85%E8%B3%AA%E7%96%91%E7%97%85%E6%AF%92%E6%B4%A9%E6%BC%8F" target="_blank" rel="noopener noreferrer"&gt;reported the same claim&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This doctor’s name is spelled in English as both “Xiaobo Tao” and “Botao Xiao.” From 2011 to 2013, Botao Xiao was a &lt;a href="https://www2.scut.edu.cn/biology_en/2017/0614/c5951a169022/page.htm" target="_blank" rel="noopener noreferrer"&gt;postdoctoral research fellow at Harvard Medical School and Boston Children’s Hospital&lt;/a&gt;, and his &lt;a href="https://www2.scut.edu.cn/biology_en/2017/0614/c5951a169022/page.htm" target="_blank" rel="noopener noreferrer"&gt;biography is still on the web site of the South China University of Technology.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;amp-img class="aligncenter size-full wp-image-797183 amp-wp-enforced-sizes i-amphtml-layout-intrinsic i-amphtml-layout-size-defined" src="https://i2.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-7.jpg?resize=796%2C503&amp;amp;ssl=1" alt="" width="796" height="503" data-image-id="797183" srcset="https://i2.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-7.jpg?w=841&amp;amp;ssl=1 841w, https://i2.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-7.jpg?resize=300%2C189&amp;amp;ssl=1 300w, https://i2.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-7.jpg?resize=768%2C485&amp;amp;ssl=1 768w, https://i2.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-7.jpg?resize=459%2C290&amp;amp;ssl=1 459w, https://i2.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-7.jpg?resize=729%2C460&amp;amp;ssl=1 729w, https://i2.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-7.jpg?resize=50%2C32&amp;amp;ssl=1 50w" sizes="(max-width: 796px) 100vw, 796px" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"&gt;&lt;i-amphtml-sizer class="i-amphtml-sizer"&gt;&lt;img alt="" aria-hidden="true" class="i-amphtml-intrinsic-sizer" role="presentation" src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzUwMycgd2lkdGg9Jzc5NicgeG1sbnM9J2h0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnJyB2ZXJzaW9uPScxLjEnLz4="&gt;&lt;/i-amphtml-sizer&gt;&lt;noscript&gt;&lt;img loading="lazy" class="aligncenter size-full wp-image-797183" src="https://i2.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-7.jpg?resize=796%2C503&amp;amp;ssl=1" alt="" width="796" height="503" srcset="https://i2.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-7.jpg?w=841&amp;amp;ssl=1 841w, https://i2.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-7.jpg?resize=300%2C189&amp;amp;ssl=1 300w, https://i2.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-7.jpg?resize=768%2C485&amp;amp;ssl=1 768w, https://i2.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-7.jpg?resize=459%2C290&amp;amp;ssl=1 459w, https://i2.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-7.jpg?resize=729%2C460&amp;amp;ssl=1 729w, https://i2.wp.com/www.nationalreview.com/wp-content/uploads/2020/04/china-coronavirus-chart-7.jpg?resize=50%2C32&amp;amp;ssl=1 50w" sizes="(max-width: 796px) 100vw, 796px"&gt;&lt;/noscript&gt;&lt;/amp-img&gt;&lt;/p&gt;
&lt;p&gt;At some point in February, Botao Xiao posted a research paper onto ResearchGate.net, “&lt;a href="https://web.archive.org/web/20200214144447/https:/www.researchgate.net/publication/339070128_The_possible_origins_of_2019-nCoV_coronavirus" target="_blank" rel="noopener noreferrer"&gt;The Possible Origins of 2019-nCoV coronavirus.”&lt;/a&gt; He is listed as one author, along with Lei Xiao from Tian You Hospital, which is &lt;a href="https://www.wheto.gov.hk/filemanager/content/pdf/contact_information_public_private_hospitals_e.pdf" target="_blank" rel="noopener noreferrer"&gt;affiliated with the Wuhan University of Science and Technology&lt;/a&gt;. The paper was removed a short time after it was posted, but archived images of its pages can be found &lt;a href="https://web.archive.org/web/20200214144447/https:/www.researchgate.net/publication/339070128_The_possible_origins_of_2019-nCoV_coronavirus" target="_blank" rel="noopener noreferrer"&gt;here&lt;/a&gt; and &lt;a href="https://www.zerohedge.com/health/smoking-gun-chinese-scientist-finds-killer-coronavirus-probably-originated-laboratory-wuhan" target="_blank" rel="noopener noreferrer"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The first conclusion of Botao Xiao’s paper is that the bats suspected of carrying the virus are extremely unlikely to be found naturally in the city, and despite the stories of “bat soup,” they conclude that bats were not sold at the market and were unlikely to be deliberately ingested.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;The bats carrying CoV ZC45 were originally found in Yunnan or Zhejiang province, both of which were more than 900 kilometers away from the seafood market. Bats were normally found to live in caves and trees. But the seafood market is in a densely-populated district of Wuhan, a metropolitan [area] of ~15 million people. The probability was very low for the bats to fly to the market. According to municipal reports and the testimonies of 31 residents and 28 visitors, the bat was never a food source in the city, and no bat was traded in the market.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The U.S. Centers for Disease Control and Prevention and the World Health Organization &lt;a href="https://www.wsj.com/articles/scientists-link-china-virus-to-intersection-of-humans-and-wildlife-11580997600" target="_blank" rel="noopener noreferrer"&gt;could not confirm&lt;/a&gt; if bats were present at the market. Botao Xiao’s paper theorizes that the coronavirus originated from bats being used for research at either one of two research laboratories in Wuhan.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;We screened the area around the seafood market and identified two laboratories conducting research on bat coronavirus. Within ~ 280 meters from the market, there was the Wuhan Center for Disease Control &amp;amp; Prevention. WHCDC hosted animals in laboratories for research purpose, one of which was specialized in pathogens collection and identification. In one of their studies, 155 bats including &lt;em&gt;Rhinolophus affinis&lt;/em&gt; were captured in Hubei province, and other 450 bats were captured in Zhejiang province. The expert in Collection was noted in the Author Contributions (JHT). Moreover, he was broadcasted for collecting viruses on nation-wide newspapers and websites in 2017 and 2019. He described that he was once by attacked by bats and the blood of a bat shot on his skin. He knew the extreme danger of the infection so he quarantined himself for 14 days. In another accident, he quarantined himself again because bats peed on him.&lt;/p&gt;
&lt;p&gt;Surgery was performed on the caged animals and the tissue samples were collected for DNA and RNA extraction and sequencing. The tissue samples and contaminated trashes were source of pathogens. They were only ~280 meters from the seafood market. The WHCDC was also adjacent to the Union Hospital (Figure 1, bottom) where the first group of doctors were infected during this epidemic. It is plausible that the virus leaked around and some of them contaminated the initial patients in this epidemic, though solid proofs are needed in future study.&lt;/p&gt;
&lt;p&gt;The second laboratory was ~12 kilometers from the seafood market and belonged to Wuhan Institute of Virology, Chinese Academy of Sciences . . .&lt;/p&gt;
&lt;p&gt;In summary, somebody was entangled with the evolution of 2019-nCoV coronavirus. In addition to origins of natural recombination and intermediate host, the killer coronavirus probably originated from a laboratory in Wuhan. Safety level may need to be reinforced in high risk biohazardous laboratories. Regulations may be taken to relocate these laboratories far away from city center and other densely populated places.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;However, Xiao has &lt;a href="https://www.wsj.com/articles/coronavirus-epidemic-draws-scrutiny-to-labs-handling-deadly-pathogens-11583349777" target="_blank" rel="noopener noreferrer"&gt;told the &lt;em&gt;Wall Street Journal&lt;/em&gt; that he has withdrawn his paper&lt;/a&gt;. “The speculation about the possible origins in the post was based on published papers and media, and was not supported by direct proofs,” he said in a brief email on February 26.&lt;/p&gt;
&lt;div class="ad-unit--center"&gt;&lt;amp-ad type="doubleclick" width="300" height="250" data-slot="/6423/nr.mobileamp/inline_1/unruly" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" style="width:300px;height:250px;" i-amphtml-layout="fixed"&gt;&lt;/amp-ad&gt;&lt;/div&gt;
&lt;p&gt;The bat researcher that Xiao’s report refers to is virologist Tian Junhua, who works at the Wuhan Centre for Disease Control. In 2004, the World Health Organization determined that an outbreak of the SARS virus had been caused by two separate leaks at the Chinese Institute of Virology in Beijing. The Chinese government said that the leaks were a result of “negligence” and the responsible officials had been punished.&lt;/p&gt;
&lt;p&gt;In 2017, the Chinese state-owned Shanghai Media Group made a &lt;a href="https://www.youtube.com/watch?v=ovnUyTRMERI&amp;amp;feature=emb_logo" target="_blank" rel="noopener noreferrer"&gt;seven-minute documentary&lt;/a&gt; about Tian Junhua, entitled “Youth in the Wild: Invisible Defender.” Videographers followed Tian Junhua as he traveled deep into caves to collect bats. “Among all known creatures, the bats are rich with various viruses inside,” he says in Chinese. “You can find most viruses responsible for human diseases, like rabies virus, SARS, and Ebola. Accordingly, the caves frequented by bats became our main battlefields.” He emphasizes, “bats usually live in caves humans can hardly reach. Only in these places can we find the most ideal virus vector samples.”&lt;/p&gt;
&lt;div class="ad-unit--center"&gt;&lt;amp-ad type="doubleclick" width="300" height="250" data-slot="/6423/nr.mobileamp/inline_2" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" style="width:300px;height:250px;" i-amphtml-layout="fixed"&gt;&lt;/amp-ad&gt;&lt;/div&gt;
&lt;p&gt;One of his last statements on the video is: “In the past ten-plus years, we have visited every corner of Hubei Province. We explored dozens of undeveloped caves and studied more than 300 types of virus vectors. But I do hope these virus samples will only be preserved for scientific research and will never be used in real life. Because humans need not only the vaccines, but also the protection from the nature.”&lt;/p&gt;
&lt;p&gt;The description of Tian Junhua’s self-isolation came from a May 2017 report by Xinhua News Agency, &lt;a href="https://www.jqknews.com/news/393098-Latest_overseas_research_bats_carrying_new_coronavirus_may_directly_infect_people.html" target="_blank" rel="noopener noreferrer"&gt;repeated by the Chinese news site JQKNews.com&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;The environment for collecting bat samples is extremely bad. There is a stench in the bat cave. Bats carry a large number of viruses in their bodies. If they are not careful, they are at risk of infection. But Tian Junhua is not afraid to go to the mountain with his wife to catch Batman.&lt;/p&gt;
&lt;p&gt;Tian Junhua summed up the experience that the most bats can be caught by using the sky cannon and pulling the net. But in the process of operation, Tian Junhua forgot to take protective measures. Bat urine dripped on him like raindrops from the top. If he was infected, he could not find any medicine. It was written in the report.&lt;/p&gt;
&lt;p&gt;The wings of bats carry sharp claws. When the big bats are caught by bat tools, they can easily spray blood. Several times bat blood was sprayed directly on Tians skin, but he didn’t flinch at all. After returning home, Tian Junhua took the initiative to isolate for half a month. As long as the incubation period of 14 days does not occur, he will be lucky to escape, the report said.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Bat urine and blood can &lt;a href="https://www.sciencedaily.com/releases/2020/02/200210144854.htm" target="_blank" rel="noopener noreferrer"&gt;carry&lt;/a&gt; viruses. How likely is it that bat urine or blood got onto a researcher at either Wuhan Center for Disease Control &amp;amp; Prevention or the Wuhan Institute of Virology? Alternatively, what are the odds that some sort of medical waste or other material from the bats was not properly disposed of, and that was the initial transmission vector to a human being?&lt;/p&gt;
&lt;div class="ad-unit--center"&gt;&lt;amp-ad type="doubleclick" width="300" height="250" data-slot="/6423/nr.mobileamp/inline_3" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" style="width:300px;height:250px;" i-amphtml-layout="fixed"&gt;&lt;/amp-ad&gt;&lt;/div&gt;
&lt;p&gt;Virologists have been &lt;a href="https://www.livescience.com/coronavirus-not-human-made-in-lab.html" target="_blank" rel="noopener noreferrer"&gt;vehemently skeptical of the theory that COVID-19 was engineered or deliberately constructed in a laboratory&lt;/a&gt;; the director of the National Institutes of Health has &lt;a href="https://directorsblog.nih.gov/2020/03/26/genomic-research-points-to-natural-origin-of-covid-19/" target="_blank" rel="noopener noreferrer"&gt;written&lt;/a&gt; that recent genomic research “debunks such claims by providing scientific evidence that this novel coronavirus arose naturally.” And none of the above is definitive proof that COVID-19 originated from a bat at either the Wuhan Center for Disease Control &amp;amp; Prevention or the Wuhan Institute of Virology. Definitive proof would require much broader access to information about what happened in those facilities in the time period before the epidemic in the city.&lt;/p&gt;
&lt;div class="ad-unit--center"&gt;&lt;amp-ad type="doubleclick" width="300" height="250" data-slot="/6423/nr.mobileamp/inline_4" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" style="width:300px;height:250px;" i-amphtml-layout="fixed"&gt;&lt;/amp-ad&gt;&lt;/div&gt;
&lt;p&gt;But it is a remarkable coincidence that the Wuhan Institute of Virology was researching Ebola and SARS-associated coronaviruses in bats before the pandemic outbreak, and that in the month when Wuhan doctors were treating the first patients of COVID-19, the institute announced in a hiring notice that “a large number of new bat and rodent new viruses have been discovered and identified.” And the fact that the Chinese government spent six weeks insisting that COVID-19 could not be spread from person to person means that its denials about Wuhan laboratories cannot be accepted without independent verification.&lt;/p&gt;
				&lt;/div&gt;
			
				&lt;amp-sticky-ad layout="nodisplay" class="i-amphtml-layout-nodisplay" hidden="hidden" i-amphtml-layout="nodisplay"&gt;
					&lt;amp-ad type="doubleclick" width="320" height="50" data-slot="/6423/nr.mobileamp/bottom" class="i-amphtml-layout-fixed i-amphtml-layout-size-defined" style="width:320px;height:50px;" i-amphtml-layout="fixed"&gt;&lt;/amp-ad&gt;
				&lt;/amp-sticky-ad&gt;

									&lt;section amp-access="hasAccess"&gt;
						
	
		&lt;div class="ad-unit ad-unit--center ad-unit--inline"&gt;&lt;div class="BeOpWidget" data-name="non-logged-below-article"&gt;&lt;/div&gt;&lt;/div&gt;	&lt;footer class="inline-author-card"&gt;
				&lt;div class="inline-author-card__inner"&gt;
			&lt;figure class="inline-author-card__figure"&gt;
																	&lt;div class="inline-author-card__img-wrapper"&gt;
						&lt;a href="https://www.nationalreview.com/author/jim-geraghty/" title="Jim Geraghty's archive page"&gt;
															&lt;amp-img width="200" height="200" src="https://www.nationalreview.com/wp-content/uploads/2017/09/jim-geraghty_200.jpg" class="attachment-square size-square amp-wp-enforced-sizes i-amphtml-layout-intrinsic i-amphtml-layout-size-defined" alt="" sizes="(max-width: 200px) 100vw, 200px" srcset="https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2017/09/jim-geraghty_200.jpg?w=200&amp;amp;ssl=1 200w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2017/09/jim-geraghty_200.jpg?resize=150%2C150&amp;amp;ssl=1 150w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2017/09/jim-geraghty_200.jpg?resize=65%2C65&amp;amp;ssl=1 65w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2017/09/jim-geraghty_200.jpg?resize=50%2C50&amp;amp;ssl=1 50w" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"&gt;&lt;i-amphtml-sizer class="i-amphtml-sizer"&gt;&lt;img alt="" aria-hidden="true" class="i-amphtml-intrinsic-sizer" role="presentation" src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzIwMCcgd2lkdGg9JzIwMCcgeG1sbnM9J2h0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnJyB2ZXJzaW9uPScxLjEnLz4="&gt;&lt;/i-amphtml-sizer&gt;&lt;noscript&gt;&lt;img width="200" height="200" src="https://www.nationalreview.com/wp-content/uploads/2017/09/jim-geraghty_200.jpg" class="attachment-square size-square" alt="" loading="eager" sizes="(max-width: 200px) 100vw, 200px" srcset="https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2017/09/jim-geraghty_200.jpg?w=200&amp;amp;ssl=1 200w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2017/09/jim-geraghty_200.jpg?resize=150%2C150&amp;amp;ssl=1 150w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2017/09/jim-geraghty_200.jpg?resize=65%2C65&amp;amp;ssl=1 65w, https://i1.wp.com/www.nationalreview.com/wp-content/uploads/2017/09/jim-geraghty_200.jpg?resize=50%2C50&amp;amp;ssl=1 50w"&gt;&lt;/noscript&gt;&lt;/amp-img&gt;													&lt;/a&gt;
					&lt;/div&gt;
								&lt;figcaption class="inline-author-card__text"&gt;
																											&lt;span data-amp-original-style="font-weight: 400" class="amp-wp-668e0a1"&gt;&lt;a href="https://www.nationalreview.com/author/jim-geraghty/" title="Jim Geraghty's archive page"&gt;Jim Geraghty&lt;/a&gt; is the senior political correspondent of &lt;em&gt;National Review&lt;/em&gt;.&lt;/span&gt;
					
											&lt;a class="twitter-handle" href="https://www.twitter.com/@jimgeraghty" title="Jim Geraghty on Twitter"&gt;
							@jimgeraghty						&lt;/a&gt;
									&lt;/figcaption&gt;
			&lt;/figure&gt;
		&lt;/div&gt;
	&lt;/footer&gt;


	
&lt;amp-ad type="nativo" height="200" width="400" layout="responsive" data-request-url="https://amp.nationalreview.com/amp/nativo" class="i-amphtml-layout-responsive i-amphtml-layout-size-defined" i-amphtml-layout="responsive"&gt;&lt;i-amphtml-sizer style="display:block;padding-top:50.0000%;"&gt;&lt;/i-amphtml-sizer&gt;
&lt;/amp-ad&gt;
	&lt;amp-ad layout="responsive" height="1826" width="345" type="revcontent" data-revcontent data-id="145049" class="i-amphtml-layout-responsive i-amphtml-layout-size-defined" i-amphtml-layout="responsive"&gt;&lt;i-amphtml-sizer style="display:block;padding-top:529.2754%;"&gt;&lt;/i-amphtml-sizer&gt;&lt;/amp-ad&gt;

	
&lt;aside class="inline-stories inline-stories--more"&gt;
								&lt;h2 class="inline-stories__header"&gt;
				&lt;span&gt;
					More in &lt;a href="/world/"&gt;World&lt;/a&gt;				&lt;/span&gt;
			&lt;/h2&gt;
		
		
		&lt;div class="post-list post-list--inline-related-stories"&gt;
							&lt;article class="post-list-article"&gt;
					&lt;div class="post-list-article__text"&gt;
						&lt;h4 class="post-list-article__title"&gt;
							&lt;a href="https://www.nationalreview.com/2021/02/alexis-de-tocquevilles-humbling-lesson-in-office/?utm_source=recirc-%5BSCREENSIZE%5D&amp;amp;utm_medium=blog-post&amp;amp;utm_campaign=river&amp;amp;utm_content=more-in&amp;amp;utm_term=first" class="show-on-desktop"&gt;
								Alexis de Tocqueville’s Humbling Lesson in Office							&lt;/a&gt;
							&lt;a href="https://www.nationalreview.com/2021/02/alexis-de-tocquevilles-humbling-lesson-in-office/?utm_source=recirc-mobile&amp;amp;utm_medium=blog-post&amp;amp;utm_campaign=river&amp;amp;utm_content=more-in&amp;amp;utm_term=first" class="show-on-mobile"&gt;
								Alexis de Tocqueville’s Humbling Lesson in Office							&lt;/a&gt;
						&lt;/h4&gt;
						&lt;div class="post-list-article__meta"&gt;&lt;/div&gt;
					&lt;/div&gt;
				&lt;/article&gt;
							&lt;article class="post-list-article"&gt;
					&lt;div class="post-list-article__text"&gt;
						&lt;h4 class="post-list-article__title"&gt;
							&lt;a href="https://www.nationalreview.com/2021/02/will-the-boycott-israel-clique-coopt-the-scientific-community/?utm_source=recirc-%5BSCREENSIZE%5D&amp;amp;utm_medium=blog-post&amp;amp;utm_campaign=river&amp;amp;utm_content=more-in&amp;amp;utm_term=second" class="show-on-desktop"&gt;
								Will the Boycott-Israel Clique Co-opt the Scientific Community?							&lt;/a&gt;
							&lt;a href="https://www.nationalreview.com/2021/02/will-the-boycott-israel-clique-coopt-the-scientific-community/?utm_source=recirc-mobile&amp;amp;utm_medium=blog-post&amp;amp;utm_campaign=river&amp;amp;utm_content=more-in&amp;amp;utm_term=second" class="show-on-mobile"&gt;
								Will the Boycott-Israel Clique Co-opt the Scientific Community?							&lt;/a&gt;
						&lt;/h4&gt;
						&lt;div class="post-list-article__meta"&gt;&lt;/div&gt;
					&lt;/div&gt;
				&lt;/article&gt;
							&lt;article class="post-list-article"&gt;
					&lt;div class="post-list-article__text"&gt;
						&lt;h4 class="post-list-article__title"&gt;
							&lt;a href="https://www.nationalreview.com/2021/02/emmanuel-macron-envies-america/?utm_source=recirc-%5BSCREENSIZE%5D&amp;amp;utm_medium=blog-post&amp;amp;utm_campaign=river&amp;amp;utm_content=more-in&amp;amp;utm_term=third" class="show-on-desktop"&gt;
								Emmanuel Macron Envies America							&lt;/a&gt;
							&lt;a href="https://www.nationalreview.com/2021/02/emmanuel-macron-envies-america/?utm_source=recirc-mobile&amp;amp;utm_medium=blog-post&amp;amp;utm_campaign=river&amp;amp;utm_content=more-in&amp;amp;utm_term=third" class="show-on-mobile"&gt;
								Emmanuel Macron Envies America							&lt;/a&gt;
						&lt;/h4&gt;
						&lt;div class="post-list-article__meta"&gt;&lt;/div&gt;
					&lt;/div&gt;
				&lt;/article&gt;
							&lt;article class="post-list-article"&gt;
					&lt;div class="post-list-article__text"&gt;
						&lt;h4 class="post-list-article__title"&gt;
							&lt;a href="https://www.nationalreview.com/2021/02/the-times-lavishes-praise-on-chinas-coronavirus-response-and-calls-it-reporting/?utm_source=recirc-%5BSCREENSIZE%5D&amp;amp;utm_medium=blog-post&amp;amp;utm_campaign=river&amp;amp;utm_content=more-in&amp;amp;utm_term=fourth" class="show-on-desktop"&gt;
								The &lt;i&gt;Times&lt;/i&gt; Lavishes Praise on China’s Coronavirus Response and Calls It ‘Reporting’							&lt;/a&gt;
							&lt;a href="https://www.nationalreview.com/2021/02/the-times-lavishes-praise-on-chinas-coronavirus-response-and-calls-it-reporting/?utm_source=recirc-mobile&amp;amp;utm_medium=blog-post&amp;amp;utm_campaign=river&amp;amp;utm_content=more-in&amp;amp;utm_term=fourth" class="show-on-mobile"&gt;
								The &lt;i&gt;Times&lt;/i&gt; Lavishes Praise on China’s Coronavirus Response and Calls It ‘Reporting’							&lt;/a&gt;
						&lt;/h4&gt;
						&lt;div class="post-list-article__meta"&gt;&lt;/div&gt;
					&lt;/div&gt;
				&lt;/article&gt;
					&lt;/div&gt;
	&lt;/aside&gt;

&lt;footer class="entry-footer"&gt;
	&lt;/footer&gt;&lt;!-- .entry-footer --&gt;

											&lt;/section&gt;
							&lt;/div&gt;
		
	&lt;/article&gt;

	&lt;footer class="amp-wp-article-footer"&gt;
		&lt;div class="footer-logo"&gt;
			&lt;a href="https://www.nationalreview.com/" class="footer-logo"&gt;
				&lt;svg width="214" height="19" xmlns="http://www.w3.org/2000/svg"&gt;
	&lt;title&gt;Large National Review Logo
      </title>
      <link>
        https://www.nationalreview.com/2020/04/coronavirus-china-trail-leading-back-to-wuhan-labs/amp/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;
											&lt;p&gt;&lt;span&gt;There’s no proof the coronavirus accidentally escaped from a laboratory, but we can’t take the Chinese government’s denials at face value.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;
					&lt;span id="nrplus-badge-left"&gt;
						&lt;span&gt;&lt;/span&gt;
						&lt;span&gt;NRPLUS MEMBER ARTICLE&lt;/span&gt;
					&lt;/span&gt;
					&lt;span&gt;I&lt;/span&gt;
				&lt;/span&gt;&lt;span&gt;t&lt;/span&gt; is understandable that many would be wary of the notion that the origin of the coronavirus could be discovered by some &lt;a rel="noopener noreferrer" href="https://www.imdb.com/name/nm8426798/bio"&gt;documentary filmmaker&lt;/a&gt; who used to live in China. Matthew Tye, who creates YouTube videos, &lt;a rel="noopener noreferrer" href="https://www.youtube.com/watch?v=bpQFCcSI0pU&amp;amp;feature=youtu.be"&gt;contends he has identified the source of the coronavirus&lt;/a&gt; — and a great deal of the information that he presents, obtained from public records posted on the Internet, checks out.&lt;/p&gt;
&lt;p&gt;&lt;a rel="noopener noreferrer" href="http://www.whiov.cas.cn/105341/"&gt;The Wuhan Institute of Virology in China indeed posted a job opening&lt;/a&gt; on November 18, 2019, “asking for scientists to come research the relationship between the coronavirus and bats.”&lt;/p&gt;

&lt;p&gt;The &lt;a rel="noopener noreferrer" href="http://www.whiov.cas.cn/105341/201911/t20191118_5438006.html"&gt;Google translation of the job posting is&lt;/a&gt;: “Taking bats as the research object, I will answer the molecular mechanism that can coexist&amp;nbsp;with Ebola and&amp;nbsp;SARS-&amp;nbsp;associated coronavirus for a&amp;nbsp;long time&amp;nbsp;without disease, and its relationship with flight and longevity.&amp;nbsp;Virology, immunology, cell biology, and multiple omics are used to compare the differences between humans and other mammals.” (“Omics” is a term for a subfield within biology, such as genomics or glycomics.)&lt;/p&gt;

&lt;p&gt;On December 24, 2019, the Wuhan Institute of Virology &lt;a rel="noopener noreferrer" href="http://www.whiov.cas.cn/105341/201912/t20191224_5471634.html"&gt;posted a second job posting&lt;/a&gt;. The translation of that posting includes the declaration, “long-term research on the pathogenic biology of bats carrying important viruses has confirmed the&amp;nbsp;origin of bats of major new human and livestock infectious diseases such as&amp;nbsp;SARS&amp;nbsp;and&amp;nbsp;SADS,&amp;nbsp;and a large number of new bat and rodent new viruses have been discovered and identified.”&lt;/p&gt;

&lt;p&gt;Tye contends that that posting meant, “we’ve discovered a new and terrible virus, and would like to recruit people to come deal with it.” He also contends that “news didn’t come out about coronavirus until ages after that.” Doctors in Wuhan &lt;a rel="noopener noreferrer" href="https://www.nationalreview.com/the-morning-jolt/chinas-devastating-lies/"&gt;knew that they were dealing with a cluster of pneumonia cases as December progressed&lt;/a&gt;, but it is accurate to say that a very limited number of people knew about this particular strain of coronavirus and its severity at the time of that job posting. By December 31, about three weeks after doctors first noticed the cases, the Chinese government notified the World Health Organization and the &lt;a rel="noopener noreferrer" href="https://www.scmp.com/news/china/politics/article/3044050/mystery-illness-hits-chinas-wuhan-city-nearly-30-hospitalised"&gt;first media reports&lt;/a&gt; about a “mystery pneumonia” appeared outside China.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Scientific American&lt;/em&gt; &lt;a rel="noopener noreferrer" href="https://www.scientificamerican.com/article/how-chinas-bat-woman-hunted-down-viruses-from-sars-to-the-new-coronavirus1/"&gt;verifies much of the information&lt;/a&gt; Tye mentions about Shi Zhengli, the Chinese virologist nicknamed “Bat Woman” for her work with that species.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Shi — a virologist who is often called China’s “bat woman” by her colleagues because of her virus-hunting expeditions in bat caves over the past 16 years — walked out of the conference she was attending in Shanghai and hopped on the next train back to Wuhan. “I wondered if [the municipal health authority] got it wrong,” she says. “I had never expected this kind of thing to happen in Wuhan, in central China.” Her studies had shown that the southern, subtropical areas of Guangdong, Guangxi and Yunnan have the greatest risk of coronaviruses jumping to humans from animals — &lt;em&gt;particularly bats, a known reservoir for many viruses. If coronaviruses were the culprit, she remembers thinking, “could they have come from our lab?”&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;. . . By January 7 the Wuhan team determined that the new virus had indeed caused the disease those patients suffered — a conclusion based on results from polymerase chain reaction analysis, full genome sequencing, antibody tests of blood samples and the virus’s ability to infect human lung cells in a petri dish. The genomic sequence of the virus — now officially called SARS-CoV-2 because it is related to the SARS pathogen — was 96 percent identical to that of a coronavirus the researchers had identified in horseshoe bats in Yunnan, they reported in a&amp;nbsp;&lt;a rel="noopener noreferrer" href="https://www.nature.com/articles/s41586-020-2012-7"&gt;paper&lt;/a&gt;&amp;nbsp;published last month in&amp;nbsp;&lt;em&gt;Nature&lt;/em&gt;. “It’s crystal clear that bats, once again, are the natural reservoir,” says Daszak, who was not involved in the study.&lt;strong&gt;&lt;br&gt;
&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Some scientists aren’t convinced that the virus jumped straight from bats to human beings, but &lt;a rel="noopener noreferrer" href="https://www.newyorker.com/science/elements/from-bats-to-human-lungs-the-evolution-of-a-coronavirus"&gt;there are a few problems with the theory that some other animal was an intermediate transmitter of COVID-19&lt;/a&gt; from bats to humans:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Analyses of the&amp;nbsp;&lt;em&gt;SARS&lt;/em&gt;-CoV-2 genome indicate a single spillover event, meaning the virus jumped only once from an animal to a person, which makes it likely that the virus was circulating among people before December. Unless more information about the animals at the Wuhan market is released, the transmission chain may never be clear. There are, however, numerous possibilities. A bat hunter or a wildlife trafficker might have brought the virus to the market. Pangolins happen to carry a coronavirus, which they might have picked up from bats years ago, and which is, in one crucial part of its genome, virtually identical to&amp;nbsp;&lt;em&gt;SARS&lt;/em&gt;-CoV-2. But no one has yet found evidence that pangolins were at the Wuhan market, or even that venders there trafficked pangolins.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;On February 4 — one week before the World Health Organization &lt;a rel="noopener noreferrer" href="https://www.who.int/emergencies/diseases/novel-coronavirus-2019/technical-guidance/naming-the-coronavirus-disease-(covid-2019)-and-the-virus-that-causes-it"&gt;decided to officially name this virus “COVID-19”&lt;/a&gt; — &lt;a rel="noopener noreferrer" href="https://www.nature.com/articles/s41422-020-0282-0"&gt;the journal&lt;em&gt;&amp;nbsp;Cell Research&lt;/em&gt;&lt;/a&gt; posted a notice written by scientists at the Wuhan Institute of Virology about the virus, concluding, “our findings reveal that remdesivir and chloroquine are highly effective in the control of 2019-nCoV infection in vitro. Since these compounds have been used in human patients with a safety track record and shown to be effective against various ailments, we suggest that they should be assessed in human patients suffering from the novel coronavirus disease.” One of the authors of that notice was the “bat woman,” Shi Zhengli.&lt;/p&gt;
&lt;p&gt;In his YouTube video, Tye focuses his attention on a &lt;a rel="noopener noreferrer" href="https://www.researchgate.net/scientific-contributions/2035568207_Yanling_Huang"&gt;researcher at the Wuhan Institute of Virology&lt;/a&gt; named Huang Yanling: “Most people believe her to be patient zero, and most people believe she is dead.”&lt;/p&gt;
&lt;p&gt;There was enough discussion of rumors about Huang Yanling online in China to &lt;a rel="noopener noreferrer" href="http://www.whiov.ac.cn/tzgg_105342/202002/t20200216_5500201.html"&gt;spur an official denial&lt;/a&gt;. On February 16, the Wuhan Institute of Virology denied that patient zero was one of their employees, and interestingly named her specifically: “Recently there has been fake information about Huang Yanling, a graduate from our institute, claiming that she was patient zero in the novel coronavirus.” &lt;a rel="noopener noreferrer" href="https://www.scmp.com/news/china/society/article/3050872/chinese-research-lab-denies-rumours-links-first-coronavirus"&gt;Press accounts quote the institute as saying&lt;/a&gt;, “Huang was a graduate student at the institute until 2015, when she left the province and had not returned since. Huang was in good health and had not been diagnosed with disease, it added.” None of her publicly available &lt;a rel="noopener noreferrer" href="https://www.researchgate.net/scientific-contributions/2035568207_Yanling_Huang"&gt;research papers&lt;/a&gt; are dated after 2015.&lt;/p&gt;

&lt;p&gt;The &lt;a rel="noopener noreferrer" href="http://159.226.126.127:8082/web/17190/20"&gt;web page for the Wuhan Institute of Virology’s Lab of Diagnostic Microbiology&lt;/a&gt; does indeed still have “Huang Yanling” listed as a 2012 graduate student, and her picture and biography appear to have been recently removed — as have those of two other graduate students from 2013, Wang Mengyue and Wei Cuihua.&lt;/p&gt;

&lt;p&gt;Her name still has a hyperlink, &lt;a rel="noopener noreferrer" href="http://159.226.126.127:8082/web/17190/46"&gt;but the linked page is blank&lt;/a&gt;. The pages for Wang Mengyue and Wei Cuihua are blank as well.&lt;/p&gt;

&lt;p&gt;(For what it is worth, the &lt;em&gt;South China Morning Post&lt;/em&gt; — a newspaper seen &lt;a rel="noopener noreferrer" href="https://www.nytimes.com/2018/03/31/world/asia/south-china-morning-post-hong-kong-alibaba.html"&gt;as being generally pro-Beijing&lt;/a&gt; — &lt;a rel="noopener noreferrer" href="https://www.scmp.com/news/china/society/article/3074991/coronavirus-chinas-first-confirmed-covid-19-case-traced-back"&gt;reported on March 13&lt;/a&gt; that “according to the government data seen by the&amp;nbsp;Post, a 55 year-old from Hubei province could have been the first person to have contracted Covid-19 on November 17.”)&lt;/p&gt;
&lt;p&gt;On February 17, Zhen Shuji, a Hong Kong correspondent &lt;a rel="noopener noreferrer" href="http://www.rfi.fr/cn/%E4%B8%AD%E5%9B%BD/20200217-%E6%AD%A6%E6%B1%89%E7%A0%94%E7%A9%B6%E6%89%80%E5%A4%96%E6%B3%84%E7%97%85%E6%AF%92%E4%BC%A0%E8%A8%80%E6%9C%AA%E6%AD%A2%E5%8F%88%E6%9C%89%E6%B6%88%E6%81%AF%E6%8C%87-%E9%9B%B6%E5%8F%B7%E7%97%85%E4%BA%BA-%E6%98%AF%E7%A0%94%E7%A9%B6%E5%91%98"&gt;from the French public-radio service Radio France Internationale, reported&lt;/a&gt;: “when a reporter from the Beijing News of the Mainland asked the institute for rumors about patient zero, the institute first denied that there was a researcher Huang Yanling, but after learning that the name of the person on the Internet did exist, acknowledged that the person had worked at the firm but has now left the office and is unaccounted for.”&lt;/p&gt;

&lt;p&gt;Tye says, “everyone on the Chinese internet is searching for [Huang Yanling] but most believe that her body was quickly cremated and the people working at the crematorium were perhaps infected as they were not given any information about the virus.” (The U.S. Centers for Disease Control and Prevention says that &lt;a rel="noopener noreferrer" href="https://www.cdc.gov/coronavirus/2019-ncov/faq.html"&gt;handling the body of someone who has died of coronavirus is safe&lt;/a&gt; — including embalming and cremation — as long as the standard safety protocols for handing a decedent are used. It’s anyone’s guess as to whether those safety protocols were sufficiently used in China before the outbreak’s scope was known.)&lt;/p&gt;
&lt;p&gt;As Tye observes, a public appearance by Huang Yanling would dispel a lot of the public rumors, and is the sort of thing the Chinese government would quickly arrange in normal circumstances — presuming that Huang Yanling was still alive. Several officials at the Wuhan Institute of Virology issued public statements that Huang was in good health and that no one at the institute has been infected with COVID-19. In any case, the mystery around Huang Yanling may be moot, but it does point to the lab covering up something about her.&lt;/p&gt;
&lt;p&gt;China Global Television Network, a state-owned television broadcaster, &lt;a rel="noopener noreferrer" href="https://news.cgtn.com/news/2020-02-23/Rumors-stop-with-the-wise-OjMaO0RjGM/index.html"&gt;illuminated another rumor&lt;/a&gt; while attempting to dispel it in a February 23 report entitled “Rumors Stop With the Wise”:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;On February 17, a Weibo user who claimed herself to be Chen Quanjiao, a researcher at the Wuhan Institute of Virology, reported to the public that the Director of the Institute was responsible for leaking the novel coronavirus. The Weibo post threw a bomb in the cyberspace and the public was shocked. Soon Chen herself stepped out and declared that she had never released any report information and expressed great indignation at such identity fraud on Weibo. It has been confirmed that that particular Weibo account had been shut down several times due to the spread of misinformation about COVID-19.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;That Radio France Internationale report on February 17 also mentioned the next key part of the Tye’s YouTube video. “Xiaobo Tao, a scholar from South China University of Technology, recently published a report that researchers at Wuhan Virus Laboratory were splashed with bat blood and urine, and then quarantined for 14 days.” HK01, another Hong Kong-based news site, &lt;a rel="noopener noreferrer" href="https://www.hk01.com/%E7%A4%BE%E6%9C%83%E6%96%B0%E8%81%9E/435123/%E6%AD%A6%E6%BC%A2%E8%82%BA%E7%82%8E-%E6%AD%A6%E6%BC%A2%E7%96%BE%E6%8E%A7%E7%A0%94%E7%A9%B6%E5%93%A1%E6%9B%BE%E8%A2%AB%E8%9D%99%E8%9D%A0%E8%A5%B2%E6%93%8A-%E5%85%A7%E5%9C%B0%E5%AD%B8%E8%80%85%E8%B3%AA%E7%96%91%E7%97%85%E6%AF%92%E6%B4%A9%E6%BC%8F"&gt;reported the same claim&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This doctor’s name is spelled in English as both “Xiaobo Tao” and “Botao Xiao.” From 2011 to 2013, Botao Xiao was a &lt;a rel="noopener noreferrer" href="https://www2.scut.edu.cn/biology_en/2017/0614/c5951a169022/page.htm"&gt;postdoctoral research fellow at Harvard Medical School and Boston Children’s Hospital&lt;/a&gt;, and his &lt;a rel="noopener noreferrer" href="https://www2.scut.edu.cn/biology_en/2017/0614/c5951a169022/page.htm"&gt;biography is still on the web site of the South China University of Technology.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;At some point in February, Botao Xiao posted a research paper onto ResearchGate.net, “&lt;a rel="noopener noreferrer" href="https://web.archive.org/web/20200214144447/https:/www.researchgate.net/publication/339070128_The_possible_origins_of_2019-nCoV_coronavirus"&gt;The Possible Origins of 2019-nCoV coronavirus.”&lt;/a&gt; He is listed as one author, along with Lei Xiao from Tian You Hospital, which is &lt;a rel="noopener noreferrer" href="https://www.wheto.gov.hk/filemanager/content/pdf/contact_information_public_private_hospitals_e.pdf"&gt;affiliated with the Wuhan University of Science and Technology&lt;/a&gt;. The paper was removed a short time after it was posted, but archived images of its pages can be found &lt;a rel="noopener noreferrer" href="https://web.archive.org/web/20200214144447/https:/www.researchgate.net/publication/339070128_The_possible_origins_of_2019-nCoV_coronavirus"&gt;here&lt;/a&gt; and &lt;a rel="noopener noreferrer" href="https://www.zerohedge.com/health/smoking-gun-chinese-scientist-finds-killer-coronavirus-probably-originated-laboratory-wuhan"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The first conclusion of Botao Xiao’s paper is that the bats suspected of carrying the virus are extremely unlikely to be found naturally in the city, and despite the stories of “bat soup,” they conclude that bats were not sold at the market and were unlikely to be deliberately ingested.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;The bats carrying CoV ZC45 were originally found in Yunnan or Zhejiang province, both of which were more than 900 kilometers away from the seafood market. Bats were normally found to live in caves and trees. But the seafood market is in a densely-populated district of Wuhan, a metropolitan [area] of ~15 million people. The probability was very low for the bats to fly to the market. According to municipal reports and the testimonies of 31 residents and 28 visitors, the bat was never a food source in the city, and no bat was traded in the market.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The U.S. Centers for Disease Control and Prevention and the World Health Organization &lt;a rel="noopener noreferrer" href="https://www.wsj.com/articles/scientists-link-china-virus-to-intersection-of-humans-and-wildlife-11580997600"&gt;could not confirm&lt;/a&gt; if bats were present at the market. Botao Xiao’s paper theorizes that the coronavirus originated from bats being used for research at either one of two research laboratories in Wuhan.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;We screened the area around the seafood market and identified two laboratories conducting research on bat&amp;nbsp;coronavirus. Within ~ 280 meters from the market, there was the Wuhan Center for Disease Control &amp;amp; Prevention. WHCDC hosted animals in laboratories for research purpose, one of&amp;nbsp;which was specialized in pathogens collection and identification. In one of their studies, 155 bats including &lt;em&gt;Rhinolophus affinis&lt;/em&gt; were captured in Hubei province, and other 450 bats were captured in Zhejiang province. The expert in Collection was noted in the Author Contributions (JHT). Moreover, he was broadcasted for collecting viruses on nation-wide newspapers and websites in 2017 and 2019. He described that he was once by attacked by bats and the blood of a bat shot on his skin. He knew the extreme danger of the infection so he quarantined&amp;nbsp;himself for 14 days. In another accident, he quarantined himself again because bats peed on&amp;nbsp;him.&lt;/p&gt;
&lt;p&gt;Surgery was performed on the caged animals and the tissue samples were collected for DNA and RNA extraction and sequencing. The tissue samples and contaminated trashes were source of pathogens.&amp;nbsp;They were only ~280 meters from the seafood market.&amp;nbsp;The WHCDC was also adjacent to the Union Hospital (Figure 1, bottom) where the first group of doctors were infected during this epidemic.&amp;nbsp;It is plausible that the virus leaked around and some of them contaminated the initial patients in this epidemic, though solid proofs are needed in future study.&lt;/p&gt;
&lt;p&gt;The second laboratory was ~12 kilometers from the seafood market and belonged to Wuhan Institute of Virology, Chinese Academy of Sciences . . .&lt;/p&gt;
&lt;p&gt;In summary, somebody was entangled with the evolution of 2019-nCoV coronavirus.&amp;nbsp;In addition to origins of natural recombination and intermediate host, the killer coronavirus probably originated from a laboratory in Wuhan. Safety level may need to be reinforced in high risk biohazardous laboratories. Regulations may be taken to relocate these laboratories far away from city center and other densely populated places.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;However, Xiao has &lt;a rel="noopener noreferrer" href="https://www.wsj.com/articles/coronavirus-epidemic-draws-scrutiny-to-labs-handling-deadly-pathogens-11583349777"&gt;told the &lt;em&gt;Wall Street Journal&lt;/em&gt; that he has withdrawn his paper&lt;/a&gt;. “The speculation about the possible origins in the post was based on published papers and media, and was not supported by direct proofs,” he said in a brief email on February 26.&lt;/p&gt;

&lt;p&gt;The bat researcher that Xiao’s report refers to is virologist Tian Junhua, who works at the Wuhan Centre for Disease Control. In 2004, the World Health Organization determined that an outbreak of the SARS virus had been caused by two separate leaks at the Chinese Institute of Virology in Beijing. The Chinese government said that the leaks were a result of “negligence” and the responsible officials had been punished.&lt;/p&gt;
&lt;p&gt;In 2017, the Chinese state-owned Shanghai Media Group made a &lt;a rel="noopener noreferrer" href="https://www.youtube.com/watch?v=ovnUyTRMERI&amp;amp;feature=emb_logo"&gt;seven-minute documentary&lt;/a&gt; about Tian Junhua, entitled “Youth in the Wild: Invisible Defender.” Videographers followed Tian Junhua as he traveled deep into caves to collect bats. “Among all known creatures, the bats are rich with various viruses inside,” he says in Chinese. “You can find most viruses responsible for human diseases, like rabies virus, SARS, and Ebola. Accordingly, the caves frequented by bats became our main battlefields.” He emphasizes, “bats usually live in caves humans can hardly reach. Only in these places can we find the most ideal virus vector samples.”&lt;/p&gt;

&lt;p&gt;One of his last statements on the video is: “In the past ten-plus years, we have visited every corner of Hubei Province. We explored dozens of undeveloped caves and studied more than 300 types of virus vectors. But I do hope these virus samples will only be preserved for scientific research and will never be used in real life. Because humans need not only the vaccines, but also the protection from the nature.”&lt;/p&gt;
&lt;p&gt;The description of Tian Junhua’s self-isolation came from a May 2017 report by Xinhua News Agency, &lt;a rel="noopener noreferrer" href="https://www.jqknews.com/news/393098-Latest_overseas_research_bats_carrying_new_coronavirus_may_directly_infect_people.html"&gt;repeated by the Chinese news site JQKNews.com&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;The environment for collecting bat samples is extremely bad. There is a stench in the bat cave. Bats carry a large number of viruses in their bodies. If they are not careful, they are at risk of infection. But Tian Junhua is not afraid to go to the mountain with his wife to catch Batman.&lt;/p&gt;
&lt;p&gt;Tian Junhua summed up the experience that the most bats can be caught by using the sky cannon and pulling the net. But in the process of operation, Tian Junhua forgot to take protective measures. Bat urine dripped on him like raindrops from the top. If he was infected, he could not find any medicine. It was written in the report.&lt;/p&gt;
&lt;p&gt;The wings of bats carry sharp claws. When the big bats are caught by bat tools, they can easily spray blood. Several times bat blood was sprayed directly on Tians skin, but he didn’t flinch at all. After returning home, Tian Junhua took the initiative to isolate for half a month. As long as the incubation period of 14 days does not occur, he will be lucky to escape, the report said.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Bat urine and blood can &lt;a rel="noopener noreferrer" href="https://www.sciencedaily.com/releases/2020/02/200210144854.htm"&gt;carry&lt;/a&gt; viruses. How likely is it that bat urine or blood got onto a researcher at either Wuhan Center for Disease Control &amp;amp; Prevention or the Wuhan Institute of Virology? Alternatively, what are the odds that some sort of medical waste or other material from the bats was not properly disposed of, and that was the initial transmission vector to a human being?&lt;/p&gt;

&lt;p&gt;Virologists have been &lt;a rel="noopener noreferrer" href="https://www.livescience.com/coronavirus-not-human-made-in-lab.html"&gt;vehemently skeptical of the theory that COVID-19 was engineered or deliberately constructed in a laboratory&lt;/a&gt;; the director of the National Institutes of Health has &lt;a rel="noopener noreferrer" href="https://directorsblog.nih.gov/2020/03/26/genomic-research-points-to-natural-origin-of-covid-19/"&gt;written&lt;/a&gt;&amp;nbsp;that recent genomic research “debunks such claims by providing scientific evidence that this novel coronavirus arose naturally.” And none of the above is definitive proof that COVID-19 originated from a bat at either the Wuhan Center for Disease Control &amp;amp; Prevention or the Wuhan Institute of Virology. Definitive proof would require much broader access to information about what happened in those facilities in the time period before the epidemic in the city.&lt;/p&gt;

&lt;p&gt;But it is a remarkable coincidence that the Wuhan Institute of Virology was researching Ebola and&amp;nbsp;SARS-associated coronaviruses in bats before the pandemic outbreak, and that in the month when Wuhan doctors were treating the first patients of COVID-19, the institute announced in a hiring notice that “a large number of new bat and rodent new viruses have been discovered and identified.” And the fact that the Chinese government spent six weeks insisting that COVID-19 could not be spread from person to person means that its denials about Wuhan laboratories cannot be accepted without independent verification.&lt;/p&gt;
				&lt;/div&gt;&lt;/div&gt;&lt;a href="https://www.nationalreview.com/2020/04/coronavirus-china-trail-leading-back-to-wuhan-labs/amp/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sun, 12 Apr 2020 13:34:02 UT
      </pubDate>
      <guid>
        https://www.nationalreview.com/2020/04/coronavirus-china-trail-leading-back-to-wuhan-labs/amp/
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://news.ycombinator.com/item?id=22848450
      </link>
      <description>
        &lt;a href="https://news.ycombinator.com/item?id=22848450"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sun, 12 Apr 2020 16:38:20 UT
      </pubDate>
      <guid>
        https://news.ycombinator.com/item?id=22848450
      </guid>
    </item>
    <item>
      <title>
        Facebook&lt;/title&gt;&lt;path d="M13.621 11.099V13.302H12V15.995H13.621V24H16.951V15.995H19.186C19.186 15.995 19.395 14.704 19.496 13.292H16.964V11.45C16.964 11.175 17.327 10.804 17.686 10.804H19.5V8H17.033C13.539 8 13.621 10.696 13.621 11.099Z" fill="black"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/div&gt;&lt;/a&gt;&lt;/li&gt;&lt;li class="social-icons__list-item social-icons__list-item--twitter social-icons__list-item--footer thin"&gt;&lt;a aria-label="Follow us on Twitter" class="external-link social-icons__link social-icons__link--twitter social-icons__external-link" data-event-click="{&amp;quot;element&amp;quot;:&amp;quot;ExternalLink&amp;quot;,&amp;quot;outgoingURL&amp;quot;:&amp;quot;https://twitter.com/wired/&amp;quot;}" href="https://twitter.com/wired/" rel="nofollow noopener" target="_blank"&gt;&lt;div class="social-icons__icon-container"&gt;&lt;svg class="icon icon-twitter" focusable="false" viewBox="0 0 32 32" width="32" height="32" fill="none" xmlns="http://www.w3.org/2000/svg"&gt;&lt;title&gt;Twitter&lt;/title&gt;&lt;path d="M13.032 22.003C19.07 22.003 22.372 17.001 22.372 12.663C22.3719 12.5216 22.3686 12.3803 22.362 12.239C23.0045 11.7744 23.5592 11.1991 24 10.54C23.401 10.8056 22.7656 10.9799 22.115 11.057C22.8003 10.6467 23.3132 10.0013 23.558 9.24103C22.9138 9.62343 22.209 9.89297 21.474 10.038C20.9799 9.50946 20.325 9.15892 19.6112 9.04091C18.8973 8.9229 18.1644 9.04403 17.5265 9.38545C16.8886 9.72688 16.3813 10.2695 16.0836 10.9289C15.7858 11.5884 15.7142 12.3277 15.88 13.032C14.5746 12.9664 13.2976 12.6269 12.132 12.0356C10.9663 11.4444 9.93808 10.6145 9.114 9.60003C8.69297 10.3223 8.56366 11.1782 8.7525 11.9926C8.94134 12.8071 9.43407 13.5187 10.13 13.982C9.60866 13.9664 9.0987 13.8258 8.643 13.572V13.614C8.64319 14.3718 8.90547 15.1063 9.38536 15.6928C9.86525 16.2793 10.5332 16.6818 11.276 16.832C10.7924 16.9633 10.2852 16.9825 9.793 16.888C10.0027 17.5404 10.411 18.1109 10.961 18.5197C11.5109 18.9286 12.1749 19.1552 12.86 19.168C11.6971 20.0805 10.2611 20.5754 8.783 20.573C8.518 20.573 8.257 20.558 8 20.528C9.5011 21.4921 11.248 22.0038 13.032 22.002" fill="black"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/div&gt;&lt;/a&gt;&lt;/li&gt;&lt;li class="social-icons__list-item social-icons__list-item--pinterest social-icons__list-item--footer thin"&gt;&lt;a aria-label="Follow us on Pinterest" class="external-link social-icons__link social-icons__link--pinterest social-icons__external-link" data-event-click="{&amp;quot;element&amp;quot;:&amp;quot;ExternalLink&amp;quot;,&amp;quot;outgoingURL&amp;quot;:&amp;quot;https://pinterest.com/wired/&amp;quot;}" href="https://pinterest.com/wired/" rel="nofollow noopener" target="_blank"&gt;&lt;div class="social-icons__icon-container"&gt;&lt;svg class="icon icon-pinterest" focusable="false" viewBox="0 0 32 32" width="32" height="32" fill="none" xmlns="http://www.w3.org/2000/svg"&gt;&lt;title&gt;Pinterest&lt;/title&gt;&lt;path d="M15.169 18.448C14.793 20.093 14.425 21.678 13.623 22.928C13.377 23.311 13.13 23.793 12.71 24C12.09 20.807 13.387 18.12 13.899 15.436C13.246 14.103 13.652 11.846 15.051 11.59C17.077 11.22 16.543 13.664 16.2 14.8C16.01 15.424 15.671 16.021 15.722 16.705C15.835 18.146 17.648 18.24 18.577 17.497C19.909 16.436 20.295 14.385 20.164 12.7C19.967 10.135 17.062 8.85997 14.496 9.88497C13.173 10.413 11.973 11.628 11.799 13.413C11.709 14.353 11.906 15.104 12.276 15.634C12.331 15.715 12.523 15.857 12.552 16.072C12.61 16.506 12.352 16.974 12.116 17.298C10.802 16.92 10.124 15.741 10.016 14.248C9.76596 10.848 12.558 8.26397 15.841 8.02197C19.348 7.76497 22.126 9.78896 22.384 12.74C22.576 14.933 21.797 17.14 20.561 18.329C19.631 19.221 17.656 20.096 16.041 19.242C15.684 19.052 15.524 18.82 15.169 18.448Z" fill="black"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/div&gt;&lt;/a&gt;&lt;/li&gt;&lt;li class="social-icons__list-item social-icons__list-item--youtube social-icons__list-item--footer thin"&gt;&lt;a aria-label="Follow us on YouTube" class="external-link social-icons__link social-icons__link--youtube social-icons__external-link" data-event-click="{&amp;quot;element&amp;quot;:&amp;quot;ExternalLink&amp;quot;,&amp;quot;outgoingURL&amp;quot;:&amp;quot;https://www.youtube.com/user/wired/&amp;quot;}" href="https://www.youtube.com/user/wired/" rel="nofollow noopener" target="_blank"&gt;&lt;div class="social-icons__icon-container"&gt;&lt;svg class="icon icon-youtube" focusable="false" viewBox="0 0 32 32" width="32" height="32" fill="none" xmlns="http://www.w3.org/2000/svg"&gt;&lt;title&gt;YouTube&lt;/title&gt;&lt;path d="M23.666 11.76C23.5755 11.4196 23.3971 11.109 23.1488 10.8593C22.9005 10.6095 22.5909 10.4294 22.251 10.337C21.003 10 16 10 16 10C16 10 10.997 10 9.749 10.337C9.40915 10.4294 9.09955 10.6095 8.85121 10.8593C8.60287 11.109 8.42451 11.4196 8.334 11.76C8 13.016 8 15.636 8 15.636C8 15.636 8 18.256 8.334 19.512C8.42436 19.8526 8.60265 20.1634 8.851 20.4133C9.09934 20.6632 9.40903 20.8435 9.749 20.936C10.997 21.273 16 21.273 16 21.273C16 21.273 21.003 21.273 22.251 20.936C22.591 20.8435 22.9007 20.6632 23.149 20.4133C23.3974 20.1634 23.5756 19.8526 23.666 19.512C24 18.257 24 15.636 24 15.636C24 15.636 24 13.016 23.666 11.76ZM14.364 18.015V13.257L18.545 15.637L14.364 18.015Z" fill="black"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/div&gt;&lt;/a&gt;&lt;/li&gt;&lt;li class="social-icons__list-item social-icons__list-item--instagram social-icons__list-item--footer thin"&gt;&lt;a aria-label="Follow us on Instagram" class="external-link social-icons__link social-icons__link--instagram social-icons__external-link" data-event-click="{&amp;quot;element&amp;quot;:&amp;quot;ExternalLink&amp;quot;,&amp;quot;outgoingURL&amp;quot;:&amp;quot;https://instagram.com/wired/&amp;quot;}" href="https://instagram.com/wired/" rel="nofollow noopener" target="_blank"&gt;&lt;div class="social-icons__icon-container"&gt;&lt;svg class="icon icon-instagram" focusable="false" viewBox="0 0 32 32" width="32" height="32" fill="none" xmlns="http://www.w3.org/2000/svg"&gt;&lt;title&gt;Instagram&lt;/title&gt;&lt;path d="M16 8C18.173 8 18.445 8.01 19.298 8.048C20.15 8.087 20.731 8.222 21.24 8.42C21.766 8.624 22.213 8.898 22.657 9.343C23.102 9.787 23.376 10.233 23.58 10.76C23.778 11.269 23.913 11.85 23.952 12.702C23.991 13.555 24 13.827 24 16C24 18.173 23.99 18.445 23.952 19.298C23.913 20.15 23.778 20.731 23.58 21.24C23.379 21.7738 23.064 22.2574 22.657 22.657C22.213 23.102 21.767 23.376 21.24 23.58C20.731 23.778 20.15 23.913 19.298 23.952C18.445 23.991 18.173 24 16 24C13.827 24 13.555 23.99 12.702 23.952C11.85 23.913 11.269 23.778 10.76 23.58C10.2262 23.379 9.74259 23.064 9.343 22.657C8.93593 22.2574 8.62093 21.7738 8.42 21.24C8.222 20.731 8.087 20.15 8.048 19.298C8.01 18.445 8 18.173 8 16C8 13.827 8.01 13.555 8.048 12.702C8.087 11.85 8.222 11.269 8.42 10.76C8.624 10.234 8.898 9.787 9.343 9.343C9.787 8.898 10.233 8.624 10.76 8.42C11.269 8.222 11.85 8.087 12.702 8.048C13.555 8.01 13.827 8 16 8ZM16 10C14.046 10 13.814 10.007 13.043 10.043C12.329 10.075 11.942 10.194 11.683 10.295C11.3657 10.4124 11.0787 10.5993 10.843 10.842C10.586 11.098 10.427 11.342 10.295 11.684C10.195 11.942 10.075 12.329 10.043 13.043C10.007 13.814 10 14.046 10 16C10 17.954 10.007 18.186 10.043 18.957C10.075 19.671 10.194 20.058 10.295 20.317C10.427 20.658 10.586 20.902 10.842 21.157C11.098 21.414 11.342 21.573 11.684 21.705C11.942 21.805 12.329 21.925 13.043 21.957C13.814 21.993 14.046 22 16 22C17.954 22 18.186 21.993 18.957 21.957C19.671 21.925 20.058 21.806 20.317 21.705C20.658 21.573 20.902 21.414 21.157 21.158C21.414 20.902 21.573 20.658 21.705 20.316C21.805 20.058 21.925 19.671 21.957 18.957C21.993 18.186 22 17.954 22 16C22 14.046 21.993 13.814 21.957 13.043C21.925 12.329 21.806 11.942 21.705 11.683C21.5876 11.3657 21.4007 11.0787 21.158 10.843C20.9219 10.5997 20.6341 10.4124 20.316 10.295C20.058 10.195 19.671 10.075 18.957 10.043C18.186 10.007 17.954 10 16 10ZM16 11.768C16.5558 11.768 17.1061 11.8775 17.6195 12.0901C18.133 12.3028 18.5995 12.6145 18.9925 13.0075C19.3855 13.4005 19.6972 13.867 19.9099 14.3805C20.1225 14.8939 20.232 15.4442 20.232 16C20.232 16.5558 20.1225 17.1061 19.9099 17.6195C19.6972 18.133 19.3855 18.5995 18.9925 18.9925C18.5995 19.3855 18.133 19.6972 17.6195 19.9099C17.1061 20.1225 16.5558 20.232 16 20.232C14.8776 20.232 13.8012 19.7861 13.0075 18.9925C12.2139 18.1988 11.768 17.1224 11.768 16C11.768 14.8776 12.2139 13.8012 13.0075 13.0075C13.8012 12.2139 14.8776 11.768 16 11.768ZM16 18.368C16.628 18.368 17.2303 18.1185 17.6744 17.6744C18.1185 17.2303 18.368 16.628 18.368 16C18.368 15.372 18.1185 14.7697 17.6744 14.3256C17.2303 13.8815 16.628 13.632 16 13.632C15.372 13.632 14.7697 13.8815 14.3256 14.3256C13.8815 14.7697 13.632 15.372 13.632 16C13.632 16.628 13.8815 17.2303 14.3256 17.6744C14.7697 18.1185 15.372 18.368 16 18.368ZM21.3 11.85C21.3 12.155 21.1788 12.4475 20.9632 12.6632C20.7475 12.8788 20.455 13 20.15 13C19.845 13 19.5525 12.8788 19.3368 12.6632C19.1212 12.4475 19 12.155 19 11.85C19 11.545 19.1212 11.2525 19.3368 11.0368C19.5525 10.8212 19.845 10.7 20.15 10.7C20.455 10.7 20.7475 10.8212 20.9632 11.0368C21.1788 11.2525 21.3 11.545 21.3 11.85Z" fill="black"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/div&gt;&lt;/a&gt;&lt;/li&gt;&lt;li class="social-icons__list-item social-icons__list-item--tiktok social-icons__list-item--footer thin"&gt;&lt;a aria-label="Follow us on TikTok" class="external-link social-icons__link social-icons__link--tiktok social-icons__external-link" data-event-click="{&amp;quot;element&amp;quot;:&amp;quot;ExternalLink&amp;quot;,&amp;quot;outgoingURL&amp;quot;:&amp;quot;https://www.tiktok.com/@wired?lang=en&amp;quot;}" href="https://www.tiktok.com/@wired?lang=en" rel="nofollow noopener" target="_blank"&gt;&lt;div class="social-icons__icon-container"&gt;&lt;svg class="icon icon-tiktok" focusable="false" viewBox="0 0 32 32" width="32" height="32" fill="none" xmlns="http://www.w3.org/2000/svg"&gt;&lt;title&gt;Tiktok
      </title>
      <link>
        https://www.wired.com/story/lee-holloway-devastating-decline-brilliant-young-coder/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;&lt;p&gt;&lt;a href="https://www.wired.com/"&gt;&lt;span&gt;&lt;picture&gt;&lt;img sizes="100vw" srcset="" src="https://www.wired.com/verso/static/wired/assets/logo-reverse.548f3a7478ee71f618044082aa222dd05f31249c.svg" alt="WIRED"&gt;&lt;/picture&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;WIRED is where tomorrow is realized. It is the essential source of information and ideas that make sense of a world in constant transformation. The WIRED conversation illuminates how technology is changing every aspect of our lives—from culture to business, science to design. The breakthroughs and innovations that we uncover lead to new ways of thinking, new connections, and new industries.&lt;/p&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt;&lt;a rel="nofollow noopener" href="https://www.facebook.com/wired/" data-event-click="{&amp;quot;element&amp;quot;:&amp;quot;ExternalLink&amp;quot;,&amp;quot;outgoingURL&amp;quot;:&amp;quot;https://www.facebook.com/wired/&amp;quot;}" aria-label="Follow us on Facebook"&gt;&lt;p&gt;&lt;svg xmlns="http://www.w3.org/2000/svg" fill="none" height="32" width="32" viewBox="0 0 32 32"&gt;&lt;title&gt;Facebook&lt;/title&gt;&lt;path fill="black" d="M13.621 11.099V13.302H12V15.995H13.621V24H16.951V15.995H19.186C19.186 15.995 19.395 14.704 19.496 13.292H16.964V11.45C16.964 11.175 17.327 10.804 17.686 10.804H19.5V8H17.033C13.539 8 13.621 10.696 13.621 11.099Z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/p&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a rel="nofollow noopener" href="https://twitter.com/wired/" data-event-click="{&amp;quot;element&amp;quot;:&amp;quot;ExternalLink&amp;quot;,&amp;quot;outgoingURL&amp;quot;:&amp;quot;https://twitter.com/wired/&amp;quot;}" aria-label="Follow us on Twitter"&gt;&lt;p&gt;&lt;svg xmlns="http://www.w3.org/2000/svg" fill="none" height="32" width="32" viewBox="0 0 32 32"&gt;&lt;title&gt;Twitter&lt;/title&gt;&lt;path fill="black" d="M13.032 22.003C19.07 22.003 22.372 17.001 22.372 12.663C22.3719 12.5216 22.3686 12.3803 22.362 12.239C23.0045 11.7744 23.5592 11.1991 24 10.54C23.401 10.8056 22.7656 10.9799 22.115 11.057C22.8003 10.6467 23.3132 10.0013 23.558 9.24103C22.9138 9.62343 22.209 9.89297 21.474 10.038C20.9799 9.50946 20.325 9.15892 19.6112 9.04091C18.8973 8.9229 18.1644 9.04403 17.5265 9.38545C16.8886 9.72688 16.3813 10.2695 16.0836 10.9289C15.7858 11.5884 15.7142 12.3277 15.88 13.032C14.5746 12.9664 13.2976 12.6269 12.132 12.0356C10.9663 11.4444 9.93808 10.6145 9.114 9.60003C8.69297 10.3223 8.56366 11.1782 8.7525 11.9926C8.94134 12.8071 9.43407 13.5187 10.13 13.982C9.60866 13.9664 9.0987 13.8258 8.643 13.572V13.614C8.64319 14.3718 8.90547 15.1063 9.38536 15.6928C9.86525 16.2793 10.5332 16.6818 11.276 16.832C10.7924 16.9633 10.2852 16.9825 9.793 16.888C10.0027 17.5404 10.411 18.1109 10.961 18.5197C11.5109 18.9286 12.1749 19.1552 12.86 19.168C11.6971 20.0805 10.2611 20.5754 8.783 20.573C8.518 20.573 8.257 20.558 8 20.528C9.5011 21.4921 11.248 22.0038 13.032 22.002"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/p&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a rel="nofollow noopener" href="https://pinterest.com/wired/" data-event-click="{&amp;quot;element&amp;quot;:&amp;quot;ExternalLink&amp;quot;,&amp;quot;outgoingURL&amp;quot;:&amp;quot;https://pinterest.com/wired/&amp;quot;}" aria-label="Follow us on Pinterest"&gt;&lt;p&gt;&lt;svg xmlns="http://www.w3.org/2000/svg" fill="none" height="32" width="32" viewBox="0 0 32 32"&gt;&lt;title&gt;Pinterest&lt;/title&gt;&lt;path fill="black" d="M15.169 18.448C14.793 20.093 14.425 21.678 13.623 22.928C13.377 23.311 13.13 23.793 12.71 24C12.09 20.807 13.387 18.12 13.899 15.436C13.246 14.103 13.652 11.846 15.051 11.59C17.077 11.22 16.543 13.664 16.2 14.8C16.01 15.424 15.671 16.021 15.722 16.705C15.835 18.146 17.648 18.24 18.577 17.497C19.909 16.436 20.295 14.385 20.164 12.7C19.967 10.135 17.062 8.85997 14.496 9.88497C13.173 10.413 11.973 11.628 11.799 13.413C11.709 14.353 11.906 15.104 12.276 15.634C12.331 15.715 12.523 15.857 12.552 16.072C12.61 16.506 12.352 16.974 12.116 17.298C10.802 16.92 10.124 15.741 10.016 14.248C9.76596 10.848 12.558 8.26397 15.841 8.02197C19.348 7.76497 22.126 9.78896 22.384 12.74C22.576 14.933 21.797 17.14 20.561 18.329C19.631 19.221 17.656 20.096 16.041 19.242C15.684 19.052 15.524 18.82 15.169 18.448Z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/p&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a rel="nofollow noopener" href="https://www.youtube.com/user/wired/" data-event-click="{&amp;quot;element&amp;quot;:&amp;quot;ExternalLink&amp;quot;,&amp;quot;outgoingURL&amp;quot;:&amp;quot;https://www.youtube.com/user/wired/&amp;quot;}" aria-label="Follow us on YouTube"&gt;&lt;p&gt;&lt;svg xmlns="http://www.w3.org/2000/svg" fill="none" height="32" width="32" viewBox="0 0 32 32"&gt;&lt;title&gt;YouTube&lt;/title&gt;&lt;path fill="black" d="M23.666 11.76C23.5755 11.4196 23.3971 11.109 23.1488 10.8593C22.9005 10.6095 22.5909 10.4294 22.251 10.337C21.003 10 16 10 16 10C16 10 10.997 10 9.749 10.337C9.40915 10.4294 9.09955 10.6095 8.85121 10.8593C8.60287 11.109 8.42451 11.4196 8.334 11.76C8 13.016 8 15.636 8 15.636C8 15.636 8 18.256 8.334 19.512C8.42436 19.8526 8.60265 20.1634 8.851 20.4133C9.09934 20.6632 9.40903 20.8435 9.749 20.936C10.997 21.273 16 21.273 16 21.273C16 21.273 21.003 21.273 22.251 20.936C22.591 20.8435 22.9007 20.6632 23.149 20.4133C23.3974 20.1634 23.5756 19.8526 23.666 19.512C24 18.257 24 15.636 24 15.636C24 15.636 24 13.016 23.666 11.76ZM14.364 18.015V13.257L18.545 15.637L14.364 18.015Z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/p&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a rel="nofollow noopener" href="https://instagram.com/wired/" data-event-click="{&amp;quot;element&amp;quot;:&amp;quot;ExternalLink&amp;quot;,&amp;quot;outgoingURL&amp;quot;:&amp;quot;https://instagram.com/wired/&amp;quot;}" aria-label="Follow us on Instagram"&gt;&lt;p&gt;&lt;svg xmlns="http://www.w3.org/2000/svg" fill="none" height="32" width="32" viewBox="0 0 32 32"&gt;&lt;title&gt;Instagram&lt;/title&gt;&lt;path fill="black" d="M16 8C18.173 8 18.445 8.01 19.298 8.048C20.15 8.087 20.731 8.222 21.24 8.42C21.766 8.624 22.213 8.898 22.657 9.343C23.102 9.787 23.376 10.233 23.58 10.76C23.778 11.269 23.913 11.85 23.952 12.702C23.991 13.555 24 13.827 24 16C24 18.173 23.99 18.445 23.952 19.298C23.913 20.15 23.778 20.731 23.58 21.24C23.379 21.7738 23.064 22.2574 22.657 22.657C22.213 23.102 21.767 23.376 21.24 23.58C20.731 23.778 20.15 23.913 19.298 23.952C18.445 23.991 18.173 24 16 24C13.827 24 13.555 23.99 12.702 23.952C11.85 23.913 11.269 23.778 10.76 23.58C10.2262 23.379 9.74259 23.064 9.343 22.657C8.93593 22.2574 8.62093 21.7738 8.42 21.24C8.222 20.731 8.087 20.15 8.048 19.298C8.01 18.445 8 18.173 8 16C8 13.827 8.01 13.555 8.048 12.702C8.087 11.85 8.222 11.269 8.42 10.76C8.624 10.234 8.898 9.787 9.343 9.343C9.787 8.898 10.233 8.624 10.76 8.42C11.269 8.222 11.85 8.087 12.702 8.048C13.555 8.01 13.827 8 16 8ZM16 10C14.046 10 13.814 10.007 13.043 10.043C12.329 10.075 11.942 10.194 11.683 10.295C11.3657 10.4124 11.0787 10.5993 10.843 10.842C10.586 11.098 10.427 11.342 10.295 11.684C10.195 11.942 10.075 12.329 10.043 13.043C10.007 13.814 10 14.046 10 16C10 17.954 10.007 18.186 10.043 18.957C10.075 19.671 10.194 20.058 10.295 20.317C10.427 20.658 10.586 20.902 10.842 21.157C11.098 21.414 11.342 21.573 11.684 21.705C11.942 21.805 12.329 21.925 13.043 21.957C13.814 21.993 14.046 22 16 22C17.954 22 18.186 21.993 18.957 21.957C19.671 21.925 20.058 21.806 20.317 21.705C20.658 21.573 20.902 21.414 21.157 21.158C21.414 20.902 21.573 20.658 21.705 20.316C21.805 20.058 21.925 19.671 21.957 18.957C21.993 18.186 22 17.954 22 16C22 14.046 21.993 13.814 21.957 13.043C21.925 12.329 21.806 11.942 21.705 11.683C21.5876 11.3657 21.4007 11.0787 21.158 10.843C20.9219 10.5997 20.6341 10.4124 20.316 10.295C20.058 10.195 19.671 10.075 18.957 10.043C18.186 10.007 17.954 10 16 10ZM16 11.768C16.5558 11.768 17.1061 11.8775 17.6195 12.0901C18.133 12.3028 18.5995 12.6145 18.9925 13.0075C19.3855 13.4005 19.6972 13.867 19.9099 14.3805C20.1225 14.8939 20.232 15.4442 20.232 16C20.232 16.5558 20.1225 17.1061 19.9099 17.6195C19.6972 18.133 19.3855 18.5995 18.9925 18.9925C18.5995 19.3855 18.133 19.6972 17.6195 19.9099C17.1061 20.1225 16.5558 20.232 16 20.232C14.8776 20.232 13.8012 19.7861 13.0075 18.9925C12.2139 18.1988 11.768 17.1224 11.768 16C11.768 14.8776 12.2139 13.8012 13.0075 13.0075C13.8012 12.2139 14.8776 11.768 16 11.768ZM16 18.368C16.628 18.368 17.2303 18.1185 17.6744 17.6744C18.1185 17.2303 18.368 16.628 18.368 16C18.368 15.372 18.1185 14.7697 17.6744 14.3256C17.2303 13.8815 16.628 13.632 16 13.632C15.372 13.632 14.7697 13.8815 14.3256 14.3256C13.8815 14.7697 13.632 15.372 13.632 16C13.632 16.628 13.8815 17.2303 14.3256 17.6744C14.7697 18.1185 15.372 18.368 16 18.368ZM21.3 11.85C21.3 12.155 21.1788 12.4475 20.9632 12.6632C20.7475 12.8788 20.455 13 20.15 13C19.845 13 19.5525 12.8788 19.3368 12.6632C19.1212 12.4475 19 12.155 19 11.85C19 11.545 19.1212 11.2525 19.3368 11.0368C19.5525 10.8212 19.845 10.7 20.15 10.7C20.455 10.7 20.7475 10.8212 20.9632 11.0368C21.1788 11.2525 21.3 11.545 21.3 11.85Z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/p&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a rel="nofollow noopener" href="https://www.tiktok.com/@wired?lang=en" data-event-click="{&amp;quot;element&amp;quot;:&amp;quot;ExternalLink&amp;quot;,&amp;quot;outgoingURL&amp;quot;:&amp;quot;https://www.tiktok.com/@wired?lang=en&amp;quot;}" aria-label="Follow us on TikTok"&gt;&lt;p&gt;&lt;svg xmlns="http://www.w3.org/2000/svg" fill="none" height="32" width="32" viewBox="0 0 32 32"&gt;&lt;title&gt;Tiktok&lt;/title&gt;&lt;path fill="black" d="M22.6895 14.4733C22.5587 14.486 22.4275 14.4927 22.2961 14.4933C20.8554 14.4935 19.5115 13.7672 18.7223 12.5618V19.1388C18.7223 21.8235 16.546 24 13.8612 24C11.1764 24 9 21.8236 9 19.1388C9 16.454 11.1764 14.2777 13.8612 14.2777C13.9626 14.2777 14.0619 14.2868 14.1616 14.293V16.6887C14.0619 16.6767 13.9638 16.6584 13.8612 16.6584C12.4909 16.6584 11.3802 17.7692 11.3802 19.1394C11.3802 20.5097 12.4909 21.6204 13.8612 21.6204C15.2317 21.6204 16.4419 20.5407 16.4419 19.1703L16.4659 8H18.7576C18.9737 10.0552 20.6308 11.6603 22.6918 11.811V14.4733"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/p&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;a href="https://www.wired.com/story/lee-holloway-devastating-decline-brilliant-young-coder/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Wed, 15 Apr 2020 11:36:36 UT
      </pubDate>
      <guid>
        https://www.wired.com/story/lee-holloway-devastating-decline-brilliant-young-coder/
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://medium.com/better-marketing/10-skills-to-becoming-a-millionaire-in-5-years-or-less-e16b8b20500c
      </link>
      <description>
        &lt;a href="https://medium.com/better-marketing/10-skills-to-becoming-a-millionaire-in-5-years-or-less-e16b8b20500c"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Thu, 16 Apr 2020 14:51:16 UT
      </pubDate>
      <guid>
        https://medium.com/better-marketing/10-skills-to-becoming-a-millionaire-in-5-years-or-less-e16b8b20500c
      </guid>
    </item>
    <item>
      <title>
        404 - Page not found
      </title>
      <link>
        https://www.brent-jensen.com/blog/dopamine-fasting
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;&lt;p&gt;&lt;img src="https://uploads-ssl.webflow.com/5663ece1cdf237d35fd4480c/5663f7d42900ed96701ee150_404-2.png" width="206" alt="404 page"&gt;&lt;/p&gt;&lt;h2&gt;Page not found&lt;/h2&gt;
            &lt;p&gt;The page you are looking for doesn't exist or has been moved.&lt;/p&gt;
        &lt;/div&gt;&lt;/div&gt;&lt;a href="https://www.brent-jensen.com/blog/dopamine-fasting"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Fri, 17 Apr 2020 12:27:10 UT
      </pubDate>
      <guid>
        https://www.brent-jensen.com/blog/dopamine-fasting
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://davidthorpe.dev/kick-the-shit-out-of-procrastination/
      </link>
      <description>
        &lt;a href="https://davidthorpe.dev/kick-the-shit-out-of-procrastination/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Mon, 20 Apr 2020 10:45:30 UT
      </pubDate>
      <guid>
        https://davidthorpe.dev/kick-the-shit-out-of-procrastination/
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://www.intel.com/content/dam/www/program/education/us/en/documents/project-design/strategies/dep-question-socratic.pdf
      </link>
      <description>
        &lt;a href="https://www.intel.com/content/dam/www/program/education/us/en/documents/project-design/strategies/dep-question-socratic.pdf"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 21 Apr 2020 14:48:15 UT
      </pubDate>
      <guid>
        https://www.intel.com/content/dam/www/program/education/us/en/documents/project-design/strategies/dep-question-socratic.pdf
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://osu.instructure.com/courses/71145/pages/week-15-class-31
      </link>
      <description>
        &lt;a href="https://osu.instructure.com/courses/71145/pages/week-15-class-31"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 21 Apr 2020 18:37:08 UT
      </pubDate>
      <guid>
        https://osu.instructure.com/courses/71145/pages/week-15-class-31
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://medium.com/@rakyll/things-i-wished-more-developers-knew-about-databases-2d0178464f78
      </link>
      <description>
        &lt;a href="https://medium.com/@rakyll/things-i-wished-more-developers-knew-about-databases-2d0178464f78"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Wed, 22 Apr 2020 11:31:08 UT
      </pubDate>
      <guid>
        https://medium.com/@rakyll/things-i-wished-more-developers-knew-about-databases-2d0178464f78
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://opensourceconnections.com/blog/2019/11/05/understanding-bert-and-search-relevance/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;article id="post-1542"&gt;&lt;div&gt;&lt;figure&gt;&lt;img alt="Complexity" data-src="/images/complex-664440_1280.jpg" src="https://opensourceconnections.com/images/complex-664440_1280.jpg"&gt;&lt;/figure&gt;&lt;p&gt;There is a growing topic in search these days. The hype of BERT is all around us, and while it is an amazing breakthrough in contextual representation of unstructured text, newcomers to natural language processing (NLP) are left scratching their heads wondering how and why it is changing the field. Many of the examples are tailored for tasks such as text classification, language understanding, multiple choice, and question answering. So what about just plain-old findin’ stuff? This article gives an overview into the opportunities and challenges when applying advanced transformer models such as BERT to search.&lt;/p&gt;&lt;h2 id="whats-bert-and-why-is-it-important"&gt;What’s BERT and why is it important?&lt;/h2&gt;&lt;p&gt;BERT, which stands for Bidirectional Encoder Representations from Transformers is a deep learning architecture developed by Google for NLP. It is one of several approaches that leverages &lt;em&gt;transformer&lt;/em&gt; architecture. Transformers address a gap in previous architectures such as recurrent and long short-term memory neural networks, with the key difference being the focus on maintaining attention during training using a bidirectional encoder. Plenty of articles have been written about this recently. So, I won’t dive into the details of how or why this works, but I’ve added links at the bottom for further reading if you want to learn more. The important part for the practitioner is that pre-trained models and open source libraries have been released to the public for use by anyone. You don’t need to train your own model and you can use these as they are, or for transfer learning (referred to as fine-tuning in BERT).&lt;/p&gt;&lt;p&gt;What happens when you use these models is what we’ll focus on here. When you, for example, pass a document’s text through a pre-trained model using a transformer network, you get back a tensor, which is comprised of a vector representation for each token. One pre-trained large uncased model for BERT uses a feature vector of 768 floating point values. 768 features for a token, yielded from such a sophisticated model, contains a highly accurate dense contextual representation of the meaning of that token that can be further used. Also importantly, if the document has 234 words in it, you’ll get a tensor with the dimension of 234×768. If your document has 172 words, your tensor is 172×768, and so on.&lt;/p&gt;&lt;p&gt;Traditional search in inverted indexes such as Lucene maintains &lt;em&gt;zero&lt;/em&gt; context for each token – as all the words are all usually analyzed in isolation. Relevance engineers spend lots of time working around this problem. Without linguistic context, it is very difficult to associate any meaning to the words, and so search becomes a manually tuned matching system, with statistical tools for ranking.&lt;/p&gt;&lt;h2 id="how-can-we-use-bert-for-search"&gt;How can we use BERT for search?&lt;/h2&gt;&lt;p&gt;So what can you do with this tensor information? Well that’s the question at hand for many search engineers these days. We’ve been given this immensely powerful tool, and are trying to figure out how we can apply it to make relevance tuning easier and less prone to silly language issues we commonly face. Before you jump out of your chair shouting this is a solution looking for a problem, remember, the problem is that search in its current form has no connection to language and meaning. So we need to see how these two match up for a better future together.&lt;/p&gt;&lt;p&gt;The main area of exploration for search with BERT is similarity. Similarity between documents for recommendations, and similarity between &lt;em&gt;queries and documents&lt;/em&gt; for returning and ranking search results. Why? Because search relevance can be phrased as a similarity problem. What documents are most similar to what the user is trying to convey with their query? If you can use similarity to solve this problem with highly accurate results, then you’ve got a pretty great search for your product or application.&lt;/p&gt;&lt;p&gt;Commonly, the approach is to use a nearest neighbor algorithm. This takes two or more vectors, and calculates the distance (or similarity) between them in an efficient manner. To use a simple example, let’s say we’ve got two people – Alice, standing 5 meters away from a water fountain, and Bob, standing 7 meters away from the water fountain. Who is standing closest to the fountain? Alice of course. Now Carrie joins the group and stands 8 meters from the fountain. So who is Carrie standing closest to? Alice or Bob? Well, that’s easy – it’s Bob. That’s similarity with a vector of one feature. We can also have a vector of two features, such as latitude and longitude coordinates, and use that calculate who is standing closest to the fountain and who are standing in groups close to each other.&lt;/p&gt;&lt;p&gt;When we need to do this with more features, such as 3, 10, or even 768, across thousands or millions of words and documents, things get complicated. So we turn to approximate nearest neighbor algorithms to efficiently calculate this similarity as fast as possible across all these dimensions.&lt;/p&gt;&lt;p&gt;And that brings us to where much of the recent practical development has been focusing on: Efforts to apply this type of nearest neighbor calculation to documents that we index in a search engine, and also the queries that people use in the search bar. Because if you can represent all your documents as rich sets of vectors that contain embedded meaning, and cross reference those with a query also represented by a rich set of vectors, you can see which documents are most similar to the query!&lt;/p&gt;&lt;h2 id="making-progress-with-some-obstacles"&gt;Making progress, with some obstacles&lt;/h2&gt;&lt;p&gt;There’s some great stuff happening to make the above nearest neighbor tools available for use inside of search engines. Several approaches are being built to allow arbitrary vectors to be indexed inside of Lucene, and Vespa already supports indexing vectors. However, the sizes noted above are not really practical. For example, vectorizing short (three or four sentence) overview text data from 28000 movie documents balloons the representative size from 5MB to 5GB! That’s a whopping 1000x increase in size! And 28000 really isn’t very many documents.&lt;/p&gt;&lt;p&gt;There are investigations underway to distill these huge document tensors into a more maintainable size. Areas of research include fine-tuning by using another model on top of BERT for a smaller representation, or just trying to average some of the dimensions together. The problem with these approaches is as you shrink or compress the size, you lose more of the context that the original model provided. So careful testing for each dataset needs to be performed to ensure the accuracy stays reasonable as the representation is compressed.&lt;/p&gt;&lt;p&gt;This is also a very different way of doing things than most search teams are used to. Handling large models that need GPUs for effective speed, and querying across vectors instead of terms, requires a shift in technology, infrastructure, and practice. Also, debugging such a system becomes exceedingly difficult. These models are black boxes, and explainable AI is an open area of research that is out of reach for most practitioners. When you get a strange result from Lucene, you can dig down and see exactly why the result was returned. But when a document or query yields a tensor, knowing why that tensor was produced and what it means is more or less impossible.&lt;/p&gt;&lt;h2 id="the-problem-with-queries"&gt;The problem with queries&lt;/h2&gt;&lt;p&gt;All the above is wonderful, but there’s another problem – how people search. Think yourself about how you search, when approached with a need to get information from a website or from a web search engine like Google. Do you type an elaborately crafted sentence as if you were asking another person? Of course not. You type one or two words, typically a noun phrase, for what you want to find. Don’t feel bad – everyone does this, even me! People usually don’t give enough context to search engines for most of their queries. But you can’t blame people for this problem – we’ve been doing this for years because that’s how search engines usually work.&lt;/p&gt;&lt;p&gt;When you perform a similarity between those short queries and lots of documents, you are faced with the same age-old information retrieval problem: ambiguity. No matter how advanced your technology is, if people don’t provide enough context to search on, your engine is going to have a difficult time returning exactly what they were thinking. You will get documents back that reflect the meaning of the terms better, but they might not be ranked the way you expect.&lt;/p&gt;&lt;h2 id="tradeoffs-and-next-steps"&gt;Tradeoffs and next steps&lt;/h2&gt;&lt;p&gt;Search is full of trade-offs. How much time can you reasonably spend to get search right? How much money is worth improving search for 10% of your queries? Everyone has deadlines. Everyone has budgetary restrictions. Lots of smart people are working hard to make this technology cheaply available and accessible to search teams who can use it to benefit customers. Keep an eye out for more updates, as this represents the biggest shift search has seen in years, so you’re likely to see many more articles, tutorials, software, and training soon.&lt;/p&gt;&lt;h4&gt;If you’re interested in learning about and potentially applying some of the techniques described above to empower your search team, please &lt;a href="https://opensourceconnections.com/contact/"&gt;contact us&lt;/a&gt;!&lt;/h4&gt;&lt;h2 id="further-reading"&gt;Further reading&lt;/h2&gt;&lt;p&gt;These links below provide more in depth information for the concepts explained above.&lt;/p&gt;&lt;h3 id="academic-papers-on-bert-and-attention-models"&gt;Academic papers on BERT and attention models&lt;/h3&gt;&lt;p&gt;&lt;a href="https://arxiv.org/abs/1810.04805"&gt;BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://arxiv.org/pdf/1706.03762.pdf"&gt;Attention Is All You Need&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://nlp.seas.harvard.edu/2018/04/03/attention.html"&gt;The Annotated Transformer&lt;/a&gt;&lt;/p&gt;&lt;h3 id="articles-explaining-bert-in-simpler-overviews"&gt;Articles explaining BERT in simpler overviews&lt;/h3&gt;&lt;p&gt;&lt;a href="https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270"&gt;BERT explained&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.analyticsvidhya.com/blog/2019/09/demystifying-bert-groundbreaking-nlp-framework/"&gt;Demystifying BERT&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://blog.google/products/search/search-language-understanding-bert/"&gt;Understanding searches better than ever before&lt;/a&gt;&lt;/p&gt;&lt;h3 id="libraries-for-using-bert-and-other-transformers"&gt;Libraries for using BERT and other transformers&lt;/h3&gt;&lt;p&gt;&lt;a href="https://huggingface.co/transformers/"&gt;Huggingface Transformers&lt;/a&gt;&lt;/p&gt;&lt;h3 id="investigations-of-berts-true-practicality"&gt;Investigations of BERT’s true practicality&lt;/h3&gt;&lt;p&gt;&lt;a href="https://thegradient.pub/nlps-clever-hans-moment-has-arrived/"&gt;NLP’s Clever Hans Moment Has Arrived&lt;/a&gt;&lt;/p&gt;&lt;h3 id="arbitrarily-dense-vector-search"&gt;Arbitrarily dense vector search&lt;/h3&gt;&lt;p&gt;&lt;a href="https://github.com/o19s/hangry"&gt;https://github.com/o19s/hangry&lt;/a&gt;&lt;br&gt;&lt;a href="https://github.com/castorini/anserini/blob/master/docs/approximate-nearestneighbor.md"&gt;https://github.com/castorini/anserini/blob/master/docs/approximate-nearestneighbor.md&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://arxiv.org/abs/1910.10208"&gt;https://arxiv.org/abs/1910.10208&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://github.com/jobergum/dense-vector-ranking-performance"&gt;https://github.com/jobergum/dense-vector-ranking-performance&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://docs.vespa.ai/documentation/reference/tensor.html"&gt;Tensors in Vespa&lt;/a&gt;&lt;/p&gt;&lt;h4 id="attributions"&gt;Attributions&lt;/h4&gt;&lt;p&gt;Image by Pete Linforth&lt;/p&gt;&lt;/div&gt;&lt;/article&gt;&lt;/div&gt;&lt;a href="https://opensourceconnections.com/blog/2019/11/05/understanding-bert-and-search-relevance/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Wed, 22 Apr 2020 12:21:44 UT
      </pubDate>
      <guid>
        https://opensourceconnections.com/blog/2019/11/05/understanding-bert-and-search-relevance/
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://jdan.github.io/98.css/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;
    &lt;h2&gt;98.css&lt;/h2&gt;
    &lt;hr&gt;
    &lt;p&gt;A design system for building faithful recreations of old UIs.&lt;/p&gt;

    &lt;p&gt;
      &lt;a rel="nofollow" href="http://npm.im/98.css"&gt;
        &lt;img src="https://98badges.now.sh/api/version" alt="npm"&gt;
      &lt;/a&gt;
      &lt;a rel="nofollow" href="https://unpkg.com/98.css"&gt;
        &lt;img src="https://98badges.now.sh/api/size" alt="gzip size"&gt;
      &lt;/a&gt;
    &lt;/p&gt;

    &lt;h2 id="intro"&gt;Intro&lt;/h2&gt;
    &lt;p&gt;
      98.css is a CSS library for building interfaces that look like Windows 98.
      See more &lt;a href="https://github.com/jdan/98.css"&gt;on GitHub&lt;/a&gt;.
    &lt;/p&gt;

    

    &lt;p&gt;
      This library relies on the usage of &lt;strong&gt;semantic HTML&lt;/strong&gt;. To make a button, you'll need
      to use a &lt;code&gt;&amp;lt;button&amp;gt;&lt;/code&gt;. Input elements require labels. Icon buttons rely on
      &lt;code&gt;aria-label&lt;/code&gt;. This page will guide you through that process, but accessibility is a primary
      goal of this project.
    &lt;/p&gt;

    &lt;p&gt;
      You can override many of the styles of your elements while maintaining the appearance provided by
      this library. Need more padding on your buttons? Go for it. Need to add some color to your input labels?
      Be our guest.
    &lt;/p&gt;

    &lt;p&gt;
      &lt;strong&gt;This library does not contain any JavaScript&lt;/strong&gt;, it merely styles your HTML with some CSS.
      This means 98.css is compatible with your frontend framework of choice.
    &lt;/p&gt;

    &lt;p&gt;
      Here is an example of &lt;a href="https://codesandbox.io/s/objective-chandrasekhar-t5t6h?file=/src/index.js"&gt;98.css used with React&lt;/a&gt;, and
      &lt;a href="https://codesandbox.io/s/late-sound-miqho?file=/index.html"&gt;an example with vanilla JavaScript&lt;/a&gt;. The fastest way to use 98.css is to import it from unpkg.
    &lt;/p&gt;

    &lt;pre&gt;&lt;code&gt;&amp;lt;link
  rel="stylesheet"
  href="https://unpkg.com/98.css"
&amp;gt;&lt;/code&gt;&lt;/pre&gt;

    &lt;p&gt;
      You can install 98.css from the &lt;a href="https://github.com/jdan/98.css/releases"&gt;GitHub releases page&lt;/a&gt;, or &lt;a href="https://www.npmjs.com/package/98.css"&gt;from npm&lt;/a&gt;.
    &lt;/p&gt;
    &lt;pre&gt;&lt;code&gt;npm install 98.css&lt;/code&gt;&lt;/pre&gt;

    &lt;h2 id="components"&gt;Components&lt;/h2&gt;

    &lt;section&gt;
      &lt;h3 id="button"&gt;Button&lt;/h3&gt;
      &lt;div&gt;
        &lt;blockquote&gt;
          A &lt;em&gt;command button&lt;/em&gt;, also referred to as a push button, is a control
          that causes the application to perform some action when the user clicks it.

          
        &lt;/blockquote&gt;

        &lt;p&gt;
          A standard button measures 75px wide and 23px tall, with a raised outer and inner border.
          They are given 12px of horizontal padding by default.
        &lt;/p&gt;

        &lt;div&gt;
      &lt;details&gt;
        &lt;summary&gt;Show code&lt;/summary&gt;
        &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt;Click me&lt;span&gt;&amp;lt;/&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
      &lt;/details&gt;
    &lt;/div&gt;

        &lt;p&gt;
          When buttons are clicked, the raised borders become sunken.
          The following button is simulated to be in the pressed (active) state.
        &lt;/p&gt;

        
        &lt;div&gt;
      &lt;details&gt;
        &lt;summary&gt;Show code&lt;/summary&gt;
        &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt;I am being pressed&lt;span&gt;&amp;lt;/&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
      &lt;/details&gt;
    &lt;/div&gt;

        &lt;p&gt;
          Disabled buttons maintain the same raised border, but have a "washed out"
          appearance in their label.
        &lt;/p&gt;

        &lt;div&gt;
      &lt;details&gt;
        &lt;summary&gt;Show code&lt;/summary&gt;
        &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;button&lt;/span&gt; &lt;span&gt;disabled&lt;/span&gt;&amp;gt;&lt;/span&gt;I cannot be clicked&lt;span&gt;&amp;lt;/&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
      &lt;/details&gt;
    &lt;/div&gt;

        &lt;p&gt;
          Button focus is communicated with a dotted border, set 4px within the contents of the button.
          The following example is simulated to be focused.
        &lt;/p&gt;

        &lt;div&gt;
      &lt;details&gt;
        &lt;summary&gt;Show code&lt;/summary&gt;
        &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt;I am focused&lt;span&gt;&amp;lt;/&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
      &lt;/details&gt;
    &lt;/div&gt;
      &lt;/div&gt;
    &lt;/section&gt;

    &lt;section&gt;
      &lt;h3 id="checkbox"&gt;Checkbox&lt;/h3&gt;
      &lt;div&gt;
        &lt;blockquote&gt;
          A &lt;em&gt;check box&lt;/em&gt; represents an independent or non-exclusive choice.
          
        &lt;/blockquote&gt;

        &lt;p&gt;
          Checkboxes are represented with a sunken panel, populated with a "check" icon when
          selected, next to a label indicating the choice.
        &lt;/p&gt;

        &lt;p&gt;
          Note: You &lt;strong&gt;must&lt;/strong&gt; include a corresponding label &lt;strong&gt;after&lt;/strong&gt;
          your checkbox, using the &lt;code&gt;&amp;lt;label&amp;gt;&lt;/code&gt; element with a &lt;code&gt;for&lt;/code&gt; attribute
          pointed at the &lt;code&gt;id&lt;/code&gt; of your input. This ensures the checkbox is easy to use with
          assistive technologies, on top of ensuring a good user experience for all (navigating with the tab key,
          being able to click the entire label to select the box).
        &lt;/p&gt;

        &lt;div&gt;
      &lt;p&gt;
&lt;label for="example1"&gt;This is a checkbox&lt;/label&gt;&lt;/p&gt;&lt;details&gt;
        &lt;summary&gt;Show code&lt;/summary&gt;
        &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"checkbox"&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"example1"&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"example1"&lt;/span&gt;&amp;gt;&lt;/span&gt;This is a checkbox&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
      &lt;/details&gt;
    &lt;/div&gt;

        &lt;p&gt;
          Checkboxes can be selected and disabled with the standard &lt;code&gt;checked&lt;/code&gt; and &lt;code&gt;disabled&lt;/code&gt;
          attributes.
        &lt;/p&gt;

        &lt;p&gt;
          When grouping inputs, wrap each input in a container with the &lt;code&gt;field-row&lt;/code&gt; class. This ensures
          a consistent spacing between inputs.
        &lt;/p&gt;

        &lt;div&gt;
      &lt;p&gt;
  &lt;label for="example2"&gt;I am checked&lt;/label&gt;
&lt;/p&gt;
&lt;p&gt;
  &lt;label for="example3"&gt;I am inactive&lt;/label&gt;
&lt;/p&gt;
&lt;p&gt;
  &lt;label for="example4"&gt;I am inactive but still checked&lt;/label&gt;
&lt;/p&gt;
      &lt;details&gt;
        &lt;summary&gt;Show code&lt;/summary&gt;
        &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row"&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;checked&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"checkbox"&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"example2"&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"example2"&lt;/span&gt;&amp;gt;&lt;/span&gt;I am checked&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row"&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;disabled&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"checkbox"&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"example3"&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"example3"&lt;/span&gt;&amp;gt;&lt;/span&gt;I am inactive&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row"&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;checked&lt;/span&gt; &lt;span&gt;disabled&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"checkbox"&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"example4"&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"example4"&lt;/span&gt;&amp;gt;&lt;/span&gt;I am inactive but still checked&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
      &lt;/details&gt;
    &lt;/div&gt;
      &lt;/div&gt;
    &lt;/section&gt;

    &lt;section&gt;
      &lt;h3 id="option-button"&gt;OptionButton&lt;/h3&gt;
      &lt;div&gt;
        &lt;blockquote&gt;
          An &lt;em&gt;option button&lt;/em&gt;, also referred to as a radio button, represents a single
          choice within a limited set of mutually exclusive choices. That is, the user can choose only
          one set of options.

          
        &lt;/blockquote&gt;

        &lt;p&gt;
          Option buttons can be used via the &lt;code&gt;radio&lt;/code&gt; type on an input element.
        &lt;/p&gt;

        &lt;p&gt;
          Option buttons can be grouped by specifying a shared &lt;code&gt;name&lt;/code&gt; attribute on each
          input. Just as before: when grouping inputs, wrap each input in a container with the
          &lt;code&gt;field-row&lt;/code&gt; class to ensure a consistent spacing between inputs.
        &lt;/p&gt;

        &lt;div&gt;
      &lt;p&gt;
  &lt;label for="radio5"&gt;Yes&lt;/label&gt;
&lt;/p&gt;
&lt;p&gt;
  &lt;label for="radio6"&gt;No&lt;/label&gt;
&lt;/p&gt;
      &lt;details&gt;
        &lt;summary&gt;Show code&lt;/summary&gt;
        &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row"&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"radio5"&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"radio"&lt;/span&gt; &lt;span&gt;name&lt;/span&gt;=&lt;span&gt;"first-example"&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"radio5"&lt;/span&gt;&amp;gt;&lt;/span&gt;Yes&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row"&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"radio6"&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"radio"&lt;/span&gt; &lt;span&gt;name&lt;/span&gt;=&lt;span&gt;"first-example"&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"radio6"&lt;/span&gt;&amp;gt;&lt;/span&gt;No&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
      &lt;/details&gt;
    &lt;/div&gt;

        &lt;p&gt;
          Option buttons can also be &lt;code&gt;checked&lt;/code&gt; and &lt;code&gt;disabled&lt;/code&gt; with their corresponding
          HTML attributes.
        &lt;/p&gt;

        &lt;div&gt;
      &lt;p&gt;
  &lt;label for="radio7"&gt;Peanut butter should be smooth&lt;/label&gt;
&lt;/p&gt;
&lt;p&gt;
  &lt;label for="radio8"&gt;I understand why people like crunchy peanut butter&lt;/label&gt;
&lt;/p&gt;
&lt;p&gt;
  &lt;label for="radio9"&gt;Crunchy peanut butter is good&lt;/label&gt;
&lt;/p&gt;
      &lt;details&gt;
        &lt;summary&gt;Show code&lt;/summary&gt;
        &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row"&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"radio7"&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"radio"&lt;/span&gt; &lt;span&gt;name&lt;/span&gt;=&lt;span&gt;"second-example"&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"radio7"&lt;/span&gt;&amp;gt;&lt;/span&gt;Peanut butter should be smooth&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row"&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;checked&lt;/span&gt; &lt;span&gt;disabled&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"radio8"&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"radio"&lt;/span&gt; &lt;span&gt;name&lt;/span&gt;=&lt;span&gt;"second-example"&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"radio8"&lt;/span&gt;&amp;gt;&lt;/span&gt;I understand why people like crunchy peanut butter&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row"&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;disabled&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"radio9"&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"radio"&lt;/span&gt; &lt;span&gt;name&lt;/span&gt;=&lt;span&gt;"second-example"&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"radio9"&lt;/span&gt;&amp;gt;&lt;/span&gt;Crunchy peanut butter is good&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
      &lt;/details&gt;
    &lt;/div&gt;
      &lt;/div&gt;
    &lt;/section&gt;

    &lt;section&gt;
      &lt;h3 id="group-box"&gt;GroupBox&lt;/h3&gt;
      &lt;div&gt;
        &lt;blockquote&gt;
          A &lt;em&gt;group box&lt;/em&gt; is a special control you can use to organize a set of
          controls. A group box is a rectangular frame with an optional label that surrounds
          a set of controls.

          
        &lt;/blockquote&gt;

        &lt;p&gt;
          A group box can be used by wrapping your elements with the &lt;code&gt;fieldset&lt;/code&gt; tag.
          It contains a sunken outer border and a raised inner border, resembling an engraved box
          around your controls.
        &lt;/p&gt;

        &lt;div&gt;
      
      &lt;details&gt;
        &lt;summary&gt;Show code&lt;/summary&gt;
        &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;fieldset&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row"&lt;/span&gt;&amp;gt;&lt;/span&gt;Select one:&lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row"&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"radio10"&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"radio"&lt;/span&gt; &lt;span&gt;name&lt;/span&gt;=&lt;span&gt;"fieldset-example"&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"radio10"&lt;/span&gt;&amp;gt;&lt;/span&gt;Diners&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row"&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"radio11"&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"radio"&lt;/span&gt; &lt;span&gt;name&lt;/span&gt;=&lt;span&gt;"fieldset-example"&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"radio11"&lt;/span&gt;&amp;gt;&lt;/span&gt;Drive-Ins&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row"&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"radio12"&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"radio"&lt;/span&gt; &lt;span&gt;name&lt;/span&gt;=&lt;span&gt;"fieldset-example"&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"radio12"&lt;/span&gt;&amp;gt;&lt;/span&gt;Dives&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span&gt;fieldset&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
      &lt;/details&gt;
    &lt;/div&gt;

        &lt;p&gt;
          You can provide your group with a label by placing a &lt;code&gt;legend&lt;/code&gt; element
          within the &lt;code&gt;fieldset&lt;/code&gt;.
        &lt;/p&gt;

        &lt;div&gt;
      
      &lt;details&gt;
        &lt;summary&gt;Show code&lt;/summary&gt;
        &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;fieldset&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;legend&lt;/span&gt;&amp;gt;&lt;/span&gt;Today's mood&lt;span&gt;&amp;lt;/&lt;span&gt;legend&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row"&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"radio13"&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"radio"&lt;/span&gt; &lt;span&gt;name&lt;/span&gt;=&lt;span&gt;"fieldset-example2"&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"radio13"&lt;/span&gt;&amp;gt;&lt;/span&gt;Claire Saffitz&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row"&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"radio14"&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"radio"&lt;/span&gt; &lt;span&gt;name&lt;/span&gt;=&lt;span&gt;"fieldset-example2"&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"radio14"&lt;/span&gt;&amp;gt;&lt;/span&gt;Brad Leone&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row"&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"radio15"&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"radio"&lt;/span&gt; &lt;span&gt;name&lt;/span&gt;=&lt;span&gt;"fieldset-example2"&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"radio15"&lt;/span&gt;&amp;gt;&lt;/span&gt;Chris Morocco&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row"&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"radio16"&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"radio"&lt;/span&gt; &lt;span&gt;name&lt;/span&gt;=&lt;span&gt;"fieldset-example2"&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"radio16"&lt;/span&gt;&amp;gt;&lt;/span&gt;Carla Lalli Music&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span&gt;fieldset&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
      &lt;/details&gt;
    &lt;/div&gt;
      &lt;/div&gt;
    &lt;/section&gt;

    &lt;section&gt;
      &lt;h3 id="text-box"&gt;TextBox&lt;/h3&gt;
      &lt;div&gt;
        &lt;blockquote&gt;
          A &lt;em&gt;text box&lt;/em&gt; (also referred to as an edit control) is a
          rectangular control where the user enters or edits text. It can
          be defined to support a single line or multiple lines of text.

          
        &lt;/blockquote&gt;

        &lt;p&gt;
          Text boxes can rendered by specifying a &lt;code&gt;text&lt;/code&gt; type on an
          &lt;code&gt;input&lt;/code&gt; element. As with checkboxes and radio buttons, you
          should provide a corresponding label with a properly set &lt;code&gt;for&lt;/code&gt;
          attribute, and wrap both in a container with the &lt;code&gt;field-row&lt;/code&gt; class.
        &lt;/p&gt;

        &lt;div&gt;
      &lt;p&gt;&lt;label for="text17"&gt;Occupation&lt;/label&gt;
  
&lt;/p&gt;
      &lt;details&gt;
        &lt;summary&gt;Show code&lt;/summary&gt;
        &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row"&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"text17"&lt;/span&gt;&amp;gt;&lt;/span&gt;Occupation&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"text17"&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"text"&lt;/span&gt; /&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
      &lt;/details&gt;
    &lt;/div&gt;

        &lt;p&gt;
          Additionally, you can make use of the &lt;code&gt;field-row-stacked&lt;/code&gt; class
          to position your label above the input instead of beside it.
        &lt;/p&gt;

        &lt;div&gt;
      &lt;p&gt;&lt;label for="text18"&gt;Address (Line 1)&lt;/label&gt;
  
&lt;/p&gt;
&lt;p&gt;&lt;label for="text19"&gt;Address (Line 2)&lt;/label&gt;
  
&lt;/p&gt;
      &lt;details&gt;
        &lt;summary&gt;Show code&lt;/summary&gt;
        &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row-stacked"&lt;/span&gt; &lt;span&gt;style&lt;/span&gt;=&lt;span&gt;"width: 200px"&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"text18"&lt;/span&gt;&amp;gt;&lt;/span&gt;Address (Line 1)&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"text18"&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"text"&lt;/span&gt; /&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row-stacked"&lt;/span&gt; &lt;span&gt;style&lt;/span&gt;=&lt;span&gt;"width: 200px"&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"text19"&lt;/span&gt;&amp;gt;&lt;/span&gt;Address (Line 2)&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"text19"&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"text"&lt;/span&gt; /&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
      &lt;/details&gt;
    &lt;/div&gt;

        &lt;p&gt;
          To support multiple lines in the user's input, use the &lt;code&gt;textarea&lt;/code&gt;
          element instead.
        &lt;/p&gt;

        &lt;div&gt;
      &lt;p&gt;&lt;label for="text20"&gt;Additional notes&lt;/label&gt;
  
&lt;/p&gt;
      &lt;details&gt;
        &lt;summary&gt;Show code&lt;/summary&gt;
        &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row-stacked"&lt;/span&gt; &lt;span&gt;style&lt;/span&gt;=&lt;span&gt;"width: 200px"&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"text20"&lt;/span&gt;&amp;gt;&lt;/span&gt;Additional notes&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;textarea&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"text20"&lt;/span&gt; &lt;span&gt;rows&lt;/span&gt;=&lt;span&gt;"8"&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;lt;/&lt;span&gt;textarea&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
      &lt;/details&gt;
    &lt;/div&gt;
      &lt;/div&gt;
    &lt;/section&gt;

    &lt;section&gt;
      &lt;h3 id="slider"&gt;Slider&lt;/h3&gt;
      &lt;div&gt;
        &lt;blockquote&gt;
          A &lt;em&gt;slider&lt;/em&gt;, sometimes called a trackbar control, consists of a bar that
          defines the extent or range of the adjustment and an indicator that
          shows the current value for the control...

          
        &lt;/blockquote&gt;

        &lt;p&gt;
          Sliders can rendered by specifying a &lt;code&gt;range&lt;/code&gt; type on an
          &lt;code&gt;input&lt;/code&gt; element.
        &lt;/p&gt;

        &lt;div&gt;
      &lt;p&gt;&lt;label for="range21"&gt;Volume:&lt;/label&gt;
  &lt;label for="range22"&gt;Low&lt;/label&gt;
  
  &lt;label for="range23"&gt;High&lt;/label&gt;
&lt;/p&gt;
      &lt;details&gt;
        &lt;summary&gt;Show code&lt;/summary&gt;
        &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row"&lt;/span&gt; &lt;span&gt;style&lt;/span&gt;=&lt;span&gt;"width: 300px"&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"range21"&lt;/span&gt;&amp;gt;&lt;/span&gt;Volume:&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"range22"&lt;/span&gt;&amp;gt;&lt;/span&gt;Low&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"range22"&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"range"&lt;/span&gt; &lt;span&gt;min&lt;/span&gt;=&lt;span&gt;"1"&lt;/span&gt; &lt;span&gt;max&lt;/span&gt;=&lt;span&gt;"11"&lt;/span&gt; &lt;span&gt;value&lt;/span&gt;=&lt;span&gt;"5"&lt;/span&gt; /&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"range23"&lt;/span&gt;&amp;gt;&lt;/span&gt;High&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
      &lt;/details&gt;
    &lt;/div&gt;

        &lt;p&gt;
          You can make use of the &lt;code&gt;has-box-indicator&lt;/code&gt; class replace the
          default indicator with a box indicator, furthermore the slider can be wrapped
          with a &lt;code&gt;div&lt;/code&gt; using &lt;code&gt;is-vertical&lt;/code&gt; to display the input vertically.
        &lt;/p&gt;

        &lt;p&gt;
          Note: To change the length of a vertical slider, the &lt;code&gt;input&lt;/code&gt; width
          and &lt;code&gt;div&lt;/code&gt; height.
        &lt;/p&gt;

        &lt;div&gt;
      
      &lt;details&gt;
        &lt;summary&gt;Show code&lt;/summary&gt;
        &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row"&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"range24"&lt;/span&gt;&amp;gt;&lt;/span&gt;Cowbell&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"is-vertical"&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"range24"&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"has-box-indicator"&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"range"&lt;/span&gt; &lt;span&gt;min&lt;/span&gt;=&lt;span&gt;"1"&lt;/span&gt; &lt;span&gt;max&lt;/span&gt;=&lt;span&gt;"3"&lt;/span&gt; &lt;span&gt;step&lt;/span&gt;=&lt;span&gt;"1"&lt;/span&gt; &lt;span&gt;value&lt;/span&gt;=&lt;span&gt;"2"&lt;/span&gt; /&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
      &lt;/details&gt;
    &lt;/div&gt;
      &lt;/div&gt;
    &lt;/section&gt;

    &lt;section&gt;
      &lt;h3 id="dropdown"&gt;Dropdown&lt;/h3&gt;
      &lt;div&gt;
        &lt;blockquote&gt;
          A &lt;em&gt;drop-down list box&lt;/em&gt; allows the selection of only a
          single item from a list. In its closed state, the control displays
          the current value for the control. The user opens the list to change
          the value.

          
        &lt;/blockquote&gt;

        &lt;p&gt;
          Dropdowns can be rendered by using the &lt;code&gt;select&lt;/code&gt; and &lt;code&gt;option&lt;/code&gt;
          elements.
        &lt;/p&gt;

        &lt;div&gt;
      &lt;details&gt;
        &lt;summary&gt;Show code&lt;/summary&gt;
        &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;select&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;option&lt;/span&gt;&amp;gt;&lt;/span&gt;5 - Incredible!&lt;span&gt;&amp;lt;/&lt;span&gt;option&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;option&lt;/span&gt;&amp;gt;&lt;/span&gt;4 - Great!&lt;span&gt;&amp;lt;/&lt;span&gt;option&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;option&lt;/span&gt;&amp;gt;&lt;/span&gt;3 - Pretty good&lt;span&gt;&amp;lt;/&lt;span&gt;option&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;option&lt;/span&gt;&amp;gt;&lt;/span&gt;2 - Not so great&lt;span&gt;&amp;lt;/&lt;span&gt;option&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;option&lt;/span&gt;&amp;gt;&lt;/span&gt;1 - Unfortunate&lt;span&gt;&amp;lt;/&lt;span&gt;option&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span&gt;select&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
      &lt;/details&gt;
    &lt;/div&gt;

        &lt;p&gt;
          By default, the first option will be selected. You can change this by
          giving one of your &lt;code&gt;option&lt;/code&gt; elements the &lt;code&gt;selected&lt;/code&gt;
          attribute.
        &lt;/p&gt;

        &lt;div&gt;
      &lt;details&gt;
        &lt;summary&gt;Show code&lt;/summary&gt;
        &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;select&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;option&lt;/span&gt;&amp;gt;&lt;/span&gt;5 - Incredible!&lt;span&gt;&amp;lt;/&lt;span&gt;option&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;option&lt;/span&gt;&amp;gt;&lt;/span&gt;4 - Great!&lt;span&gt;&amp;lt;/&lt;span&gt;option&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;option&lt;/span&gt; &lt;span&gt;selected&lt;/span&gt;&amp;gt;&lt;/span&gt;3 - Pretty good&lt;span&gt;&amp;lt;/&lt;span&gt;option&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;option&lt;/span&gt;&amp;gt;&lt;/span&gt;2 - Not so great&lt;span&gt;&amp;lt;/&lt;span&gt;option&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;option&lt;/span&gt;&amp;gt;&lt;/span&gt;1 - Unfortunate&lt;span&gt;&amp;lt;/&lt;span&gt;option&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span&gt;select&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
      &lt;/details&gt;
    &lt;/div&gt;
      &lt;/div&gt;
    &lt;/section&gt;

    &lt;h3 id="window"&gt;Window&lt;/h3&gt;
    &lt;p&gt;
      The following components illustrate how to build complete windows using
      98.css.
    &lt;/p&gt;

    &lt;section&gt;
      &lt;h4 id="title-bar"&gt;Title Bar&lt;/h4&gt;
      &lt;div&gt;
        &lt;blockquote&gt;
          At the top edge of the window, inside its border, is the title bar
          (also reffered to as the caption or caption bar), which extends across
          the width of the window. The title bar identifies the contents of the
          window.

          
        &lt;/blockquote&gt;

        &lt;blockquote&gt;
          Include command buttons associated with the common commands of the
          primary window in the title bar. These buttons act as shortcuts to specific
          window commands.

          
        &lt;/blockquote&gt;

        &lt;p&gt;
          You can build a complete title bar by making use of three classes,
          &lt;code&gt;title-bar&lt;/code&gt;, &lt;code&gt;title-bar-text&lt;/code&gt;, and &lt;code&gt;title-bar-controls&lt;/code&gt;.
        &lt;/p&gt;

        &lt;div&gt;
      
      &lt;details&gt;
        &lt;summary&gt;Show code&lt;/summary&gt;
        &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar"&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar-text"&lt;/span&gt;&amp;gt;&lt;/span&gt;A Title Bar&lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar-controls"&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span&gt;button&lt;/span&gt; &lt;span&gt;aria-label&lt;/span&gt;=&lt;span&gt;"Close"&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;lt;/&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
      &lt;/details&gt;
    &lt;/div&gt;

        &lt;p&gt;
          We make use of &lt;code&gt;aria-label&lt;/code&gt; to render the Close button, to let
          assistive technologies know the intent of this button. You may also use
          "Minimize", "Maximize", "Restore" and "Help" like so:
        &lt;/p&gt;
        
        &lt;div&gt;
      

&lt;br&gt;



&lt;br&gt;


      &lt;details&gt;
        &lt;summary&gt;Show code&lt;/summary&gt;
        &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar"&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar-text"&lt;/span&gt;&amp;gt;&lt;/span&gt;A Title Bar&lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar-controls"&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span&gt;button&lt;/span&gt; &lt;span&gt;aria-label&lt;/span&gt;=&lt;span&gt;"Minimize"&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;lt;/&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span&gt;button&lt;/span&gt; &lt;span&gt;aria-label&lt;/span&gt;=&lt;span&gt;"Maximize"&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;lt;/&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span&gt;button&lt;/span&gt; &lt;span&gt;aria-label&lt;/span&gt;=&lt;span&gt;"Close"&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;lt;/&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;

&lt;span&gt;&amp;lt;&lt;span&gt;br&lt;/span&gt; /&amp;gt;&lt;/span&gt;

&lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar"&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar-text"&lt;/span&gt;&amp;gt;&lt;/span&gt;A Maximized Title Bar&lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar-controls"&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span&gt;button&lt;/span&gt; &lt;span&gt;aria-label&lt;/span&gt;=&lt;span&gt;"Minimize"&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;lt;/&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span&gt;button&lt;/span&gt; &lt;span&gt;aria-label&lt;/span&gt;=&lt;span&gt;"Restore"&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;lt;/&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span&gt;button&lt;/span&gt; &lt;span&gt;aria-label&lt;/span&gt;=&lt;span&gt;"Close"&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;lt;/&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;

&lt;span&gt;&amp;lt;&lt;span&gt;br&lt;/span&gt; /&amp;gt;&lt;/span&gt;

&lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar"&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar-text"&lt;/span&gt;&amp;gt;&lt;/span&gt;A Helpful Bar&lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar-controls"&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span&gt;button&lt;/span&gt; &lt;span&gt;aria-label&lt;/span&gt;=&lt;span&gt;"Help"&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;lt;/&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span&gt;button&lt;/span&gt; &lt;span&gt;aria-label&lt;/span&gt;=&lt;span&gt;"Close"&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;lt;/&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
      &lt;/details&gt;
    &lt;/div&gt;
		&lt;p&gt;
          You can make a title bar "inactive" by adding &lt;code&gt;inactive&lt;/code&gt; class,
		  useful when making more than one window.
        &lt;/p&gt;
		 &lt;div&gt;
      
      &lt;details&gt;
        &lt;summary&gt;Show code&lt;/summary&gt;
        &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar inactive"&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar-text"&lt;/span&gt;&amp;gt;&lt;/span&gt;An inactive title bar&lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar-controls"&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span&gt;button&lt;/span&gt; &lt;span&gt;aria-label&lt;/span&gt;=&lt;span&gt;"Close"&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;lt;/&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
      &lt;/details&gt;
    &lt;/div&gt;
      &lt;/div&gt;
    &lt;/section&gt;

    &lt;section&gt;
      &lt;h4 id="window-contents"&gt;Window contents&lt;/h4&gt;
      &lt;div&gt;
        &lt;blockquote&gt;
          Every window has a boundary that defines its shape.

          
        &lt;/blockquote&gt;

        &lt;p&gt;
          To give our title bar a home, we make use of the &lt;code&gt;window&lt;/code&gt;
          class. This provides a raised outer and inner border, as well as some
          padding. We can freely resize the window by specifying a width in the
          container style.
        &lt;/p&gt;

        &lt;div&gt;
      
      &lt;details&gt;
        &lt;summary&gt;Show code&lt;/summary&gt;
        &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"window"&lt;/span&gt; &lt;span&gt;style&lt;/span&gt;=&lt;span&gt;"width: 300px"&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar"&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar-text"&lt;/span&gt;&amp;gt;&lt;/span&gt;A Complete Window&lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar-controls"&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span&gt;&amp;lt;&lt;span&gt;button&lt;/span&gt; &lt;span&gt;aria-label&lt;/span&gt;=&lt;span&gt;"Minimize"&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;lt;/&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span&gt;&amp;lt;&lt;span&gt;button&lt;/span&gt; &lt;span&gt;aria-label&lt;/span&gt;=&lt;span&gt;"Maximize"&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;lt;/&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span&gt;&amp;lt;&lt;span&gt;button&lt;/span&gt; &lt;span&gt;aria-label&lt;/span&gt;=&lt;span&gt;"Close"&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;lt;/&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
      &lt;/details&gt;
    &lt;/div&gt;

        &lt;p&gt;
          To draw the contents of the window, we use the &lt;code&gt;window-body&lt;/code&gt;
          class under the title bar.
        &lt;/p&gt;

        &lt;div&gt;
      &lt;div&gt;
  &lt;div&gt;
    &lt;p&gt;A Window With Stuff In It&lt;/p&gt;
    
  &lt;/div&gt;
  &lt;p&gt;There's so much room for activities!&lt;/p&gt;
&lt;/div&gt;
      &lt;details&gt;
        &lt;summary&gt;Show code&lt;/summary&gt;
        &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"window"&lt;/span&gt; &lt;span&gt;style&lt;/span&gt;=&lt;span&gt;"width: 300px"&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar"&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar-text"&lt;/span&gt;&amp;gt;&lt;/span&gt;A Window With Stuff In It&lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar-controls"&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span&gt;&amp;lt;&lt;span&gt;button&lt;/span&gt; &lt;span&gt;aria-label&lt;/span&gt;=&lt;span&gt;"Minimize"&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;lt;/&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span&gt;&amp;lt;&lt;span&gt;button&lt;/span&gt; &lt;span&gt;aria-label&lt;/span&gt;=&lt;span&gt;"Maximize"&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;lt;/&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span&gt;&amp;lt;&lt;span&gt;button&lt;/span&gt; &lt;span&gt;aria-label&lt;/span&gt;=&lt;span&gt;"Close"&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;lt;/&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"window-body"&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span&gt;p&lt;/span&gt;&amp;gt;&lt;/span&gt;There's so much room for activities!&lt;span&gt;&amp;lt;/&lt;span&gt;p&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
      &lt;/details&gt;
    &lt;/div&gt;
      &lt;/div&gt;
    &lt;/section&gt;

    &lt;section&gt;
      &lt;h3 id="tree-view"&gt;TreeView&lt;/h3&gt;
      &lt;div&gt;
        &lt;blockquote&gt;
          A &lt;em&gt;tree view control&lt;/em&gt; is a special list box control
          that displays a set of objects as an indented outline based
          on their logical hierarchical relationship.

          
        &lt;/blockquote&gt;

        &lt;p&gt;
          To render a tree view, use an &lt;code&gt;ul&lt;/code&gt; element with the
          &lt;code&gt;tree-view&lt;/code&gt; class. The children of this list (&lt;code&gt;li&lt;/code&gt;
          elements), can contain whatever you'd like.
        &lt;/p&gt;

        &lt;div&gt;
      &lt;ul&gt;
  &lt;li&gt;We can put&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;✨ Whatever ✨&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;We want in here&lt;/li&gt;
&lt;/ul&gt;
      &lt;details&gt;
        &lt;summary&gt;Show code&lt;/summary&gt;
        &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;ul&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"tree-view"&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;We can put&lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;span&gt;strong&lt;/span&gt; &lt;span&gt;style&lt;/span&gt;=&lt;span&gt;"color: purple"&lt;/span&gt;&amp;gt;&lt;/span&gt;✨ Whatever ✨&lt;span&gt;&amp;lt;/&lt;span&gt;strong&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;We want in here&lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span&gt;ul&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
      &lt;/details&gt;
    &lt;/div&gt;

        &lt;p&gt;
          To make this a tree, we can nest further &lt;code&gt;ul&lt;/code&gt; elements
          (no class needed on these). This will provide them with a nice dotted
          border and indentation to illustrate the structure of the tree.
        &lt;/p&gt;
        &lt;p&gt;
          To create expandable sections, wrap child lists inside of
          &lt;code&gt;details&lt;/code&gt; elements.
        &lt;/p&gt;

        &lt;div&gt;
      &lt;ul&gt;
  &lt;li&gt;Table of Contents&lt;/li&gt;
  &lt;li&gt;What is web development?&lt;/li&gt;
  &lt;li&gt;
    CSS
    &lt;ul&gt;
      &lt;li&gt;Selectors&lt;/li&gt;
      &lt;li&gt;Specificity&lt;/li&gt;
      &lt;li&gt;Properties&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;details open=""&gt;
      &lt;summary&gt;JavaScript&lt;/summary&gt;
      &lt;ul&gt;
        &lt;li&gt;Avoid at all costs&lt;/li&gt;
        &lt;li&gt;
          &lt;details&gt;
            &lt;summary&gt;Unless&lt;/summary&gt;
            &lt;ul&gt;
              &lt;li&gt;Avoid&lt;/li&gt;
              &lt;li&gt;
                &lt;details&gt;
                  &lt;summary&gt;At&lt;/summary&gt;
                  &lt;ul&gt;
                    &lt;li&gt;Avoid&lt;/li&gt;
                    &lt;li&gt;At&lt;/li&gt;
                    &lt;li&gt;All&lt;/li&gt;
                    &lt;li&gt;Cost&lt;/li&gt;
                  &lt;/ul&gt;
                &lt;/details&gt;
              &lt;/li&gt;
              &lt;li&gt;All&lt;/li&gt;
              &lt;li&gt;Cost&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/details&gt;
        &lt;/li&gt;
      &lt;/ul&gt;
    &lt;/details&gt;
  &lt;/li&gt;
  &lt;li&gt;HTML&lt;/li&gt;
  &lt;li&gt;Special Thanks&lt;/li&gt;
&lt;/ul&gt;
      &lt;details&gt;
        &lt;summary&gt;Show code&lt;/summary&gt;
        &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;ul&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"tree-view"&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;Table of Contents&lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;What is web development?&lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;
    CSS
    &lt;span&gt;&amp;lt;&lt;span&gt;ul&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;Selectors&lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;Specificity&lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;Properties&lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;/&lt;span&gt;ul&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span&gt;details&lt;/span&gt; &lt;span&gt;open&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span&gt;&amp;lt;&lt;span&gt;summary&lt;/span&gt;&amp;gt;&lt;/span&gt;JavaScript&lt;span&gt;&amp;lt;/&lt;span&gt;summary&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span&gt;&amp;lt;&lt;span&gt;ul&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;Avoid at all costs&lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;
          &lt;span&gt;&amp;lt;&lt;span&gt;details&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span&gt;summary&lt;/span&gt;&amp;gt;&lt;/span&gt;Unless&lt;span&gt;&amp;lt;/&lt;span&gt;summary&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;span&gt;ul&lt;/span&gt;&amp;gt;&lt;/span&gt;
              &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;Avoid&lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;
              &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;
                &lt;span&gt;&amp;lt;&lt;span&gt;details&lt;/span&gt;&amp;gt;&lt;/span&gt;
                  &lt;span&gt;&amp;lt;&lt;span&gt;summary&lt;/span&gt;&amp;gt;&lt;/span&gt;At&lt;span&gt;&amp;lt;/&lt;span&gt;summary&lt;/span&gt;&amp;gt;&lt;/span&gt;
                  &lt;span&gt;&amp;lt;&lt;span&gt;ul&lt;/span&gt;&amp;gt;&lt;/span&gt;
                    &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;Avoid&lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;
                    &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;At&lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;
                    &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;All&lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;
                    &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;Cost&lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;
                  &lt;span&gt;&amp;lt;/&lt;span&gt;ul&lt;/span&gt;&amp;gt;&lt;/span&gt;
                &lt;span&gt;&amp;lt;/&lt;span&gt;details&lt;/span&gt;&amp;gt;&lt;/span&gt;
              &lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;
              &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;All&lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;
              &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;Cost&lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;/&lt;span&gt;ul&lt;/span&gt;&amp;gt;&lt;/span&gt;
          &lt;span&gt;&amp;lt;/&lt;span&gt;details&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span&gt;&amp;lt;/&lt;span&gt;ul&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;/&lt;span&gt;details&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;HTML&lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;Special Thanks&lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span&gt;ul&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
      &lt;/details&gt;
    &lt;/div&gt;
      &lt;/div&gt;
    &lt;/section&gt;

    &lt;h2 id="issues-contributing-etc"&gt;Issues, Contributing, etc.&lt;/h2&gt;

    &lt;p&gt;
      98.css is &lt;a href="https://github.com/jdan/98.css/blob/main/LICENSE"&gt;MIT licensed&lt;/a&gt;.
    &lt;/p&gt;

    &lt;p&gt;
      Refer to &lt;a href="https://github.com/jdan/98.css/issues"&gt;the GitHub issues page&lt;/a&gt; to see bugs
      in my CSS or report new ones. I'd really like to see your pull requests (especially those new to
      open-source!) and will happily provide code review. 98.css is a fun, silly project and I'd like
      to make it a fun place to build your open-source muscle.
    &lt;/p&gt;

    &lt;p&gt;
      Thank you for checking my little project out, I hope it brought you some joy today. Consider
      &lt;a href="https://github.com/jdan/98.css/stargazers"&gt;starring/following along on GitHub&lt;/a&gt; and maybe
      subscribing to more fun things on &lt;a href="https://twitter.com/jdan"&gt;my twitter&lt;/a&gt;. 👋
    &lt;/p&gt;
  &lt;/div&gt;&lt;/div&gt;&lt;a href="https://jdan.github.io/98.css/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Wed, 22 Apr 2020 12:25:16 UT
      </pubDate>
      <guid>
        https://jdan.github.io/98.css/
      </guid>
    </item>
    <item>
      <title>
        Incremental Regular Expressions &amp;mdash; Incremental regular expressions
      </title>
      <link>
        http://jkff.info/articles/ire/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div id="incremental-regular-expressions"&gt;
&lt;h2&gt;Incremental Regular Expressions&lt;a title="Permalink to this headline" href="#incremental-regular-expressions"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;By Eugene Kirpichov &amp;lt;ekirpichov@gmail.com&amp;gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Code available at github:&lt;/em&gt; &lt;a href="http://github.com/jkff/ire"&gt;http://github.com/jkff/ire&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This article was originally published in the Russian functional programming
journal &lt;a href="http://fprog.ru/"&gt;http://fprog.ru/&lt;/a&gt; and this translation was intended to be published
in Peter Seibel’s &lt;a href="http://codequarterly.com/"&gt;http://codequarterly.com/&lt;/a&gt; journal, but as Peter eventually decided not
to proceed with the journal, I am publishing it on my personal space.&lt;/p&gt;
&lt;p&gt;I would like to thank Peter for his multitude of extremely valuable comments that have
helped me greatly improve the clarity and flow of the article.&lt;/p&gt;
&lt;div id="introduction"&gt;
&lt;h2&gt;Introduction&lt;a title="Permalink to this headline" href="#introduction"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The problem of regular expression matching is a well-known one, with a
multitude of solutions.&lt;/p&gt;
&lt;p&gt;The corresponding algorithms are very
beautiful, motivating many curious programmers to write their own regular
expression engines for fun.&lt;/p&gt;
&lt;p&gt;The approaches to this problem are quite different in their area of
application. Here are some questions that the developer of an engine
has to answer.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Supported operators&lt;/strong&gt;: capturing groups, backreferences,
execution of arbitrary code, greedy matching? The more features
are supported, the harder it is to implement the engine
efficiently; most of the features rule out whole classes of
matching algorithms.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Number and kind of regular expressions:&lt;/strong&gt; How many regexes shall
we test for? How big shall
they be? Shall they be small expressions for data validation, or
are we talking about a full-fledged lexer with dozens of tokens
specified by their regular expressions?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pattern of usage:&lt;/strong&gt; How many times is matching against a single expression
performed? Is it OK to spend a lot of time compiling it but match
very quickly afterwards?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Size of change of matched text:&lt;/strong&gt; How big is the matched text and how often does it change?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let us list some of the existing approaches and engines.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;tt&gt;&lt;span&gt;awk&lt;/span&gt;&lt;/tt&gt;, &lt;tt&gt;&lt;span&gt;grep&lt;/span&gt;&lt;/tt&gt;, &lt;a href="http://code.google.com/p/re2/"&gt;re2&lt;/a&gt; use the so called “automata-theoretic”
approach, which allows them to guarantee linear matching time,
however some features (for example, backreferences) cannot be
implemented at all within their approach, and others (such as
capturing groups) are quite hard to implement efficiently.&lt;/p&gt;
&lt;p&gt;Also, with this approach it is difficult to control memory overhead
while retaining high efficiency — even re2 at times suffers
from exponentially large memory consumption, though it is designed
to avoid such situations.&lt;/p&gt;
&lt;p&gt;Besides, this approach allows for certain curious uses, for example,
re2 uses automata theory to compute the minimal and maximal possible
strings matching the regular expression, thus making Google Code Search
possible by greatly reducing the amount of code to be actually matched
against the expression when processing a query.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Modified automata-theoretic approach, “tagged” automata:
&lt;a href="http://laurikari.net/tre"&gt;libtre&lt;/a&gt;,
&lt;a href="http://hackage.haskell.org/package/regex-tdfa"&gt;regex-tdfa&lt;/a&gt;
— linear matching time is also
guaranteed; it is possible to do approximate search;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Semiring-based approach: &lt;a href="http://sebfisch.github.com/haskell-regexp"&gt;weighted-regexp&lt;/a&gt;
— also linear
matching time and constant memory consumption; a very simple,
beautiful and efficient implementation;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Recursive descent: most of the other engines (Perl and
PCRE-compatible engines, Java, irregexp etc.)—the whole range
of features, but “pathological” cases are possible where
matching time sharply increases.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In a fantastic &lt;a href="http://blog.sigfpe.com/2009/01/fast-incremental-regular-expression.html"&gt;blog post&lt;/a&gt;
Dan Piponi &lt;a id="id1" href="#f1"&gt;[1]&lt;/a&gt; outlined yet another approach using monoids and finger trees.&lt;/p&gt;
&lt;p&gt;This approach only works for “true” regular expressions (i.e. we
only have character classes, braces and the operators &lt;em&gt;+, *, ?,
|&lt;/em&gt;) but it allows to perform the matching &lt;strong&gt;incrementally&lt;/strong&gt;: after small
changes of the input string we can recompute the result very quickly
without scanning the whole string. These changes include concatenating
two strings and cutting a string in two pieces. Obviously these two
operations form a basis for many others (insertion into the middle,
appending or prepending a character etc).&lt;/p&gt;
&lt;p&gt;In this article we further develop Piponi’s approach, which employs a
number of beautiful algorithmic techniques from the world of functional
programming, to build a Java library for incremental regular expression
matching. This is also an interesting investigation into how the
functional approach blends together with an imperative language.&lt;/p&gt;
&lt;p&gt;There were several reasons to choose Java:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Increase the probability that this library will be indeed used and
will not remain a purely academical toy because of difficulties
with its integration with existing projects;&lt;/li&gt;
&lt;li&gt;Facilitate understanding of the presented ideas for the
(currently) quite broad community of imperative programmers;&lt;/li&gt;
&lt;li&gt;Show that studying the functional ideas and approaches is fruitful
also for programming in non-functional languages.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Where could such an approach to regular expression matching be useful?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The ability to quickly recompute the result after changes of the
input string would be useful in text editors for incremental
highlighting of arbitrary syntax, with tokens specified by their
regular expressions (vim, for instance, allows rather flexible
definition of syntax rules, but does not always do the
highlighting and re-highlighting correctly, because it uses a
rather naive approach to highlighting).&lt;/p&gt;
&lt;p&gt;Unfortunately, the engine
developed in this article has performance characteristics that
do not allow it to serve this purpose — however, not all hope is
lost: some possible improvements will be outlined.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;One could imagine a problem in bioinformatics where one assembles
a DNA sequence, say, using a genetic algorithm, from some “basis”
sequences using glue and scissors (concatenations and cuts), and
optimizes a function depending on the presence and position of
particular patterns in the sequence.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div id="problem-statement"&gt;
&lt;h3&gt;Problem statement&lt;a title="Permalink to this headline" href="#problem-statement"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The problem that we’re going to solve is incremental matching of strings
against regular expressions. There are several ambiguities to resolve here,
however. Let us outline the major features of our engine: they are
basically the same as those in Dan Piponi’s article.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;The regular expression (or set of regular expressions) is fixed:&lt;/strong&gt;
once we fix the expressions, we obtain a way to do incremental
matching of strings against them.&lt;/li&gt;
&lt;li&gt;“Incremental” means “match result is efficiently maintained under
certain operations”, where the operations include &lt;strong&gt;concatenating
two strings and splitting a string in part around an index&lt;/strong&gt;.
Obviously, these two operations form a basis for all kinds of
rearrangements, such as inserting or deleting a word from the
middle of a string, or appending characters to its back or front,
etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There is one more ambiguity to resolve: whether to make the “incremental”
interface pure or impure in the mathematical sense: whether concatenation
and splitting modify their arguments or create new results.&lt;/p&gt;
&lt;p&gt;We choose the &lt;strong&gt;pure&lt;/strong&gt; option (concatenation and splitting are mathematical
functions), because, as it is the case with nearly any kind of data
structures having both a “pure” and “impure” implementation, it turns
out dramatically easier to reason about mathematically and declaratively,
and also dramatically easier to implement, debug and test. We shall
elaborate more on the importance of this design decision in the
section ‘The importance of purity’ section.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="the-automata-theoretic-approach"&gt;
&lt;h2&gt;The automata-theoretic approach&lt;a title="Permalink to this headline" href="#the-automata-theoretic-approach"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The most well-known approach to regular expression matching is based
on finite automata and is studied in most university courses on
compiler construction. You can throuroughly familiarize yourself with
it, for example, in &lt;a href="http://swtch.com/~rsc/regexp/regexp1.html"&gt;the article&lt;/a&gt; by Russ Cox. Let us
provide just a quick refresher of the most basic concepts of how
finite automata are used for matching text. Incrementalization will
follow in a surprisingly simple fashion.&lt;/p&gt;
&lt;div id="constructing-the-automaton"&gt;
&lt;h3&gt;Constructing the automaton&lt;a title="Permalink to this headline" href="#constructing-the-automaton"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Given a regular expression, one uses, for example, the “Thompson’s
construction” (due Ken Thompson), and builds a
finite automaton where one state is declared “initial”, one is declared
“final” (though in theory nothing prevents having more than one initial
or final state, and we shall use this opportunity in our algorithm),
and some states are connected to each other by
edges.&lt;/p&gt;
&lt;p&gt;An edge from &lt;span&gt;\(A\)&lt;/span&gt; to &lt;span&gt;\(B\)&lt;/span&gt; with subscript &lt;span&gt;\(c\)&lt;/span&gt;
means: “If state &lt;span&gt;\(A\)&lt;/span&gt; is active and the character &lt;span&gt;\(c\)&lt;/span&gt; is
input, then state &lt;span&gt;\(B\)&lt;/span&gt; becomes active instead of &lt;span&gt;\(A\)&lt;/span&gt;”. There
are also ε (epsilon)-edges: if &lt;span&gt;\(A\)&lt;/span&gt; is connected to &lt;span&gt;\(B\)&lt;/span&gt; by an
ε-edge, then, upon activation of &lt;span&gt;\(A\)&lt;/span&gt;, &lt;span&gt;\(B\)&lt;/span&gt; is also
immediately activated.&lt;/p&gt;
&lt;p&gt;Epsilon edges are needed, for example, when
constructing an automaton for the “?” (“optional”) construction: given
an automaton for R, you can insert an epsilon transition from the initial
to the final state, giving an automaton for “R?”.
If no edge from state &lt;span&gt;\(A\)&lt;/span&gt; fits the input, then
it is simply deactivated.&lt;/p&gt;
&lt;p&gt;The automaton is called “non-deterministic”
because, given a state and a character, you can’t determine which edge
to follow, because there can be several of them. Instead, you follow
all of them at once and therefore, at any given moment, several states
may be active.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="the-matching-process"&gt;
&lt;h3&gt;The matching process&lt;a title="Permalink to this headline" href="#the-matching-process"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;To perform matching, the initial states are activated and each
character of the sequence is fed as input in turn. If in the end at
least one “final” state is active, then the matching is declared
successful.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; The regular expression “&lt;tt&gt;&lt;span&gt;.*a(b*a|bc+)a&lt;/span&gt;&lt;/tt&gt;”.&lt;/p&gt;
&lt;p&gt;An automaton for this expression is shown on the picture below
(somewhat simplified with respect to the Thompson’s construction, by
removing several redundant nodes and epsilon edges),
and here is the sequence of its active states upon feeding it with the
string “&lt;tt&gt;&lt;span&gt;aabcca&lt;/span&gt;&lt;/tt&gt;”.&lt;/p&gt;
&lt;div&gt;
&lt;p&gt;&lt;img src="http://jkff.info/articles/ire/_images/nfa.png" alt="_images/nfa.png"&gt;&lt;/p&gt;&lt;p&gt;A non-deterministic automaton for the regular expression “&lt;tt&gt;&lt;span&gt;.*a(b*a|bc+)a&lt;/span&gt;&lt;/tt&gt;”&lt;/p&gt;
&lt;/div&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width="34%"&gt;
&lt;col width="66%"&gt;
&lt;/colgroup&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;String seen so far&lt;/td&gt;
&lt;td&gt;Active states&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;\(s_1\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;strong&gt;a&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;\(s_1, s_2, s_3, s_4\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;a &lt;strong&gt;a&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;\(s_1, s_2, s_3, s_4, s_5, s_8\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;aa &lt;strong&gt;b&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;\(s_1, s_3, s_6\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;aab &lt;strong&gt;c&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;\(s_1, s_6, s_7, s_8\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;aabc &lt;strong&gt;c&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;\(s_1, s_6, s_7, s_8\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;aabcc &lt;strong&gt;a&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;\(s_1, s_2, s_3, s_4, s_9\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Since in the end the active set contains a final state, &lt;span&gt;\(s_9\)&lt;/span&gt;,
the matching is declared successful.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="shrinking-the-automaton"&gt;
&lt;h3&gt;Shrinking the automaton&lt;a title="Permalink to this headline" href="#shrinking-the-automaton"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;To speed up matching, one sometimes eliminates ε-edges and performs
&lt;em&gt;determinization&lt;/em&gt; of the automaton (each state can have at most 1
out-going edge with a given subscript) &lt;a id="id2" href="#f2"&gt;[2]&lt;/a&gt;. As a result, a completely
different automaton is obtained, which, however, corresponds to the
same regular expression.&lt;/p&gt;
&lt;p&gt;In a deterministic automaton, at any given moment, exactly one state
is active, which allows for a more efficient implementation of the
matching procedure.&lt;/p&gt;
&lt;p&gt;However we won’t use determinization because as a
result, the automaton may blow up exponentially &lt;a id="id3" href="#f3"&gt;[3]&lt;/a&gt;, which, as
we’ll later see, is completely unacceptable in our case.&lt;/p&gt;
&lt;p&gt;We shall use only the first part, namely &lt;strong&gt;elimination of ε-edges&lt;/strong&gt;: it can only decrease
the size of the automaton (compare the NFA above and below).&lt;/p&gt;
&lt;p&gt;The algorithm is very simple: take “shortcuts”
through ε-edges, i.e. whenever one node is reachable from another
through a chain of ε-edges, copy edges from the second node to the first.
Then remove all ε-edges (since they’re now unnecessary) and nodes that
became redundant (unreachable) as a result of this.&lt;/p&gt;
&lt;div&gt;
&lt;p&gt;&lt;img src="http://jkff.info/articles/ire/_images/nfa-ne.png" alt="_images/nfa-ne.png"&gt;&lt;/p&gt;&lt;p&gt;The non-deterministic automaton corresponding to the expression
“&lt;tt&gt;&lt;span&gt;.*a(b*a|bc+)a&lt;/span&gt;&lt;/tt&gt;”, after removing ε-edges&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Thus we have outlined the approach to testing whether a string matches
a regular expression using finite automata. Finding match positions
and capturing groups is more difficult, and we direct the reader to
&lt;a href="http://swtch.com/~rsc/regexp/regexp3.html"&gt;Russ Cox’ article&lt;/a&gt; for a more thourough treatment — we do not present
the traditional approach here ourselves, because we shall use a
different one.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="approach-to-incremental-matching"&gt;
&lt;h2&gt;Approach to incremental matching&lt;a title="Permalink to this headline" href="#approach-to-incremental-matching"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Now let us gradually arrive to the basic ideas of incremental matching.&lt;/p&gt;
&lt;p&gt;First, let us depict this automaton in a slightly different way.&lt;/p&gt;
&lt;p&gt;Every possible input character has a
“transition function”: “What will be the next states of the automaton
after feeding this character to the input, if its current state is
&lt;span&gt;\(S\)&lt;/span&gt;?” It can also be seen that the notion of such a “transition
function” makes sense not only for individual characters, but for whole
strings. &lt;strong&gt;Strings have transition functions, too!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Given a string’s transition function, however long this
string might be, we can emulate feeding it to the automaton’s input
without even looking at its characters. A string’s transition
function is computed from the transition functions of its
characters (which is also shown on the picture below);
in the same way, given transition functions for two strings, we
can compute the transition function of their concatenation.&lt;/p&gt;
&lt;div&gt;
&lt;p&gt;&lt;img src="http://jkff.info/articles/ire/_images/nfa-composition.png" alt="_images/nfa-composition.png"&gt;&lt;/p&gt;&lt;p&gt;Transition functions of a non-deterministic automaton and their composition&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Note that the transition function of a concatenation of two strings
is the composition of their transition functions, in a slighty unusual
sense.&lt;/p&gt;
&lt;p&gt;If we were speaking of deterministic automata, then transition
functions would be regular mathematical functions from &lt;span&gt;\(S\)&lt;/span&gt; to &lt;span&gt;\(S\)&lt;/span&gt;,
where &lt;span&gt;\(S\)&lt;/span&gt; is the automaton’s set of states.&lt;/p&gt;
&lt;p&gt;Given two strings &lt;span&gt;\(p\)&lt;/span&gt; and &lt;span&gt;\(q\)&lt;/span&gt; with corresponding transition
functions &lt;span&gt;\(f\)&lt;/span&gt; and &lt;span&gt;\(g\)&lt;/span&gt;, feeding &lt;span&gt;\(pq\)&lt;/span&gt; to the automaton
will take &lt;span&gt;\(s\)&lt;/span&gt; to &lt;span&gt;\(f(s)\)&lt;/span&gt; and then to &lt;span&gt;\(g(f(s))\)&lt;/span&gt;,
which means that the transition function of &lt;span&gt;\(pq\)&lt;/span&gt; is &lt;span&gt;\(g \circ f\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;However, we’re using NFAs, and transition
functions of characters and strings take states to &lt;em&gt;sets&lt;/em&gt; of states.
Note that we do &lt;em&gt;not&lt;/em&gt; say that the &lt;em&gt;inputs&lt;/em&gt; of these
functions are also sets of states: it suffices to define them
only at individual “singleton” states: applying a transition function
to a set of states means applying it to each of these states individually
and taking a union of the results (imagine that a simulation of the
automaton occurs simultaneously for all these states).&lt;/p&gt;
&lt;p&gt;So suppose again that the transition functions of &lt;span&gt;\(p\)&lt;/span&gt; and &lt;span&gt;\(q\)&lt;/span&gt;
are &lt;span&gt;\(f\)&lt;/span&gt; and &lt;span&gt;\(g\)&lt;/span&gt;. Then if the automaton’s initial state is
&lt;span&gt;\(s\)&lt;/span&gt; (some individual state), then &lt;span&gt;\(pq\)&lt;/span&gt; will take the automaton
first to &lt;span&gt;\(f(s)\)&lt;/span&gt; (a set of states) and then to &lt;span&gt;\(\bigcup_{r \leftarrow f(s)}{g(r)}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;This is the definition of
composition for transition functions of non-deterministic automata:
&lt;span&gt;\((f \circ g)(s) = \bigcup_{r \leftarrow f(s)}{g(r)}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;This definition is curious because it has several interpretations.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The interpretation given just now;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The graphical interpretation as connectivity in a two-layer graph,
as on the picture above;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Multiplication of boolean matrices: if we represent the transition
function &lt;span&gt;\(f\)&lt;/span&gt; as an &lt;span&gt;\(N x N\)&lt;/span&gt; boolean matrix (where &lt;span&gt;\(N\)&lt;/span&gt;
is the number of states in the automaton) with &lt;span&gt;\(1\)&lt;/span&gt; in cell
&lt;span&gt;\(s,t\)&lt;/span&gt; if &lt;span&gt;\(t \in f(s)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Then we may rephrase the definition
&lt;span&gt;\((f \circ g)(s) = \bigcup_{r \leftarrow f(s)}{g(r)}\)&lt;/span&gt; as follows:
&lt;span&gt;\((f \circ g)(s,t) = \bigvee_{r \leftarrow f(s)}{t \in g(r)} = \bigvee_{r \leftarrow 1..N}{(s,r) \in f \wedge (r,t) \in g}\)&lt;/span&gt; .&lt;/p&gt;
&lt;p&gt;Note the extreme similarity with matrix multiplication:
&lt;span&gt;\((AB)[i,j] = \sum_{k \leftarrow 1..N}{A[i,k]*B[k,j]}\)&lt;/span&gt;: only summation
is replaced with logical “or” (&lt;span&gt;\(\vee\)&lt;/span&gt;) and multiplication
is replaced with logical “and” (&lt;span&gt;\(\wedge\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;This interpretation is of course not new; it is a well-known fact shown
in most textbooks on graph theory that connectivity in graphs may
be computed using multiplication of boolean matrices corresponding
to their incidence matrices. However, it opens some opportunities
for optimization by employing well-known algorithms for fast matrix
multiplication.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div id="making-use-of-transition-functions"&gt;
&lt;h3&gt;Making use of transition functions&lt;a title="Permalink to this headline" href="#making-use-of-transition-functions"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Let us now consider how this knowledge of transition function multiplication
helps us implement incremental matching.&lt;/p&gt;
&lt;p&gt;We shall start with a simpler problem: &lt;strong&gt;match testing&lt;/strong&gt;, i.e. answering the
question “Does the string &lt;span&gt;\(s\)&lt;/span&gt; match regular expression &lt;span&gt;\(R\)&lt;/span&gt;?”&lt;/p&gt;
&lt;p&gt;This is by definition equivalent to the question “Does the transition function
of &lt;span&gt;\(s\)&lt;/span&gt; take &lt;span&gt;\(R\)&lt;/span&gt;‘s automaton to a final state?”. So, if we
maintain transition functions of strings under the incremental operations
(concatenations and splits), we’ll be able to also maintain the answer
to this question.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Handling concatenations is simple&lt;/strong&gt;: given that we’ve learnt to rapidly
compute transition functions of string concatenations, we’ve essentially
learnt to rapidly recompute results of “yes/no”-style match tests
after concatenations.&lt;/p&gt;
&lt;p&gt;Therefore, if we carry with each string its transition function
(a device for rapidly performing a match test), then when concatenating
two strings, we’d compose their functions, yielding again a device
for rapidly testing their concatenation for a match.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="reducing-splits-to-concatenation"&gt;
&lt;h3&gt;Reducing splits to concatenation&lt;a title="Permalink to this headline" href="#reducing-splits-to-concatenation"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Handling splits is harder&lt;/strong&gt;: it is not obvious how to get the transition
function of a part of a string, knowing only that of the whole string.&lt;/p&gt;
&lt;p&gt;However, this problem of splitting is, curiously, &lt;em&gt;reduced to the problem
of concatenation&lt;/em&gt;: if we represent a string as an hierarchical concatenation
(a tree) of several smaller parts (chunks), then parts of this string will be
concatenations of some of these chunks. More precisely, a part of the string
equals the concatenation of all complete subtrees fully
enclosed within that part, with incomplete chunks giving birth to new tiny
but complete subtrees — see picture below.&lt;/p&gt;
&lt;div&gt;
&lt;p&gt;&lt;img src="http://jkff.info/articles/ire/_images/split-as-concatenation.png" alt="_images/split-as-concatenation.png"&gt;&lt;/p&gt;&lt;p&gt;Representing a part of a string as the concatenation of its smaller parts&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;If a split goes through the middle of a chunk, we’ll still have to
recompute the transition function for the resulting “sub-chunks”
character by character, but most of the chunks or bigger parts of
the hierarchy will remain intact and &lt;strong&gt;we won’t have to recompute
their transition functions&lt;/strong&gt;, thus saving most of the computation.&lt;/p&gt;
&lt;p&gt;All that remains is to choose a good way of representing a string
as many chunks, so that concatenation and splitting are efficient,
and memory overhead is not too high. This is what we consider in the
next section.&lt;/p&gt;
&lt;p&gt;Note again that &lt;strong&gt;this still does not allow finding positions of matches&lt;/strong&gt; —
only whether the string matches the expression or not. This is perhaps
the most interesting algorithmic problem in this article, and we shall
address it later when more background is given.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="putting-it-together"&gt;
&lt;h2&gt;Putting it together&lt;a title="Permalink to this headline" href="#putting-it-together"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Now, before going to the technical and most interesting parts, let us
recap on the basic idea of incremental matching.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We represent strings as trees of chunks (small “atomic” strings).&lt;/li&gt;
&lt;li&gt;With each string (actually with each node in a tree representing
a string) we carry its transition function with respect
to the regular expression of interest.&lt;/li&gt;
&lt;li&gt;To perform a match test, we simply take the transition function,
apply it to the automaton’s initial state and check whether
we hit a final state. We don’t even look at the string per se.&lt;/li&gt;
&lt;li&gt;When concatenating two strings, we multiply their transition functions.&lt;/li&gt;
&lt;li&gt;When splitting a string into parts, we reduce that to concatenation
of some of its nodes — remember that we keep the transition
functions for all the nodes.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;An example of such a datastructure is illustrated on the picture below.&lt;/p&gt;
&lt;div&gt;
&lt;p&gt;&lt;img src="http://jkff.info/articles/ire/_images/rope-nfa.png" alt="_images/rope-nfa.png"&gt;&lt;/p&gt;&lt;p&gt;Example representation with cached transition functions for the string &lt;span&gt;\(bcabbccabcccab\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id="ropes-strings-with-fast-concatenation"&gt;
&lt;h3&gt;Ropes: Strings with fast concatenation&lt;a title="Permalink to this headline" href="#ropes-strings-with-fast-concatenation"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;This data structure, which is a tree of small arrays, is called a “rope”,
and ropes are frequently used for representing strings where efficient
concatenation and splitting are needed while preserving reasonably
low memory overhead (e.g. having a balanced tree of individual
&lt;em&gt;characters&lt;/em&gt; is not an option because it blows up memory usage).&lt;/p&gt;
&lt;p&gt;Ropes are a long-known datastructure and there are many varieties of them,
usually differing in the kind of balanced trees they use. One of these
varieties is described in the article &lt;a href="http://dx.doi.org/10.1002/spe.4380251203"&gt;Ropes: An alternative to
strings&lt;/a&gt; by Hans-J. Boehm, Russ Atkinson, and Michael Plass,
but we’ll use a different one, to be shown later in the article.&lt;/p&gt;
&lt;p&gt;Maintaining the transition functions of rope nodes at concatenations
and splits is simple for every variety of ropes: exactly as we assemble
new nodes from old nodes during rebalancing, we assemble the transition
functions of new nodes from transition functions of old nodes (by
composing them).&lt;/p&gt;
&lt;p&gt;Even the definition of rebalancing operations doesn’t have to be modified,
just the constructor for composite nodes (nodes with children) has to
multiply the children’s transition functions to obtain one for the parent,
and the constructor for chunks has to assemble the transition function
from transition functions of characters.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="generalizing-ropes"&gt;
&lt;h3&gt;Generalizing ropes&lt;a title="Permalink to this headline" href="#generalizing-ropes"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Note that there is not much special about transition functions that
allows us to maintain them under splits and concatenations. The only
reason why we could do so is because we can compute the transition
function for a concatenation of two strings from their transition
functions.&lt;/p&gt;
&lt;p&gt;So, essentially ropes allow us to maintain absolutely
any kind of “additive” characteristic (and we’re of course not
restricted to speaking about strings, i.e. lists of characters — for
example, lists of numbers are just as fine). There is just one
restriction: in order for the additivity to make any sense, it must
not be dependent on the order in which we add up the items to obtain
the whole; this property is called &lt;strong&gt;associativity&lt;/strong&gt;:
since for concatenation holds &lt;span&gt;\(a(bc) = (ab)c\)&lt;/span&gt;,
the additive characteristic &lt;span&gt;\(f\)&lt;/span&gt; must obey &lt;span&gt;\(f(a(bc)) = f((ab)c)\)&lt;/span&gt;,
that is, if the additivity is expressed as &lt;span&gt;\(f(ab) = g(f(a), f(b))\)&lt;/span&gt;,
then &lt;span&gt;\(g\)&lt;/span&gt; must obey &lt;span&gt;\(g(g(x,y),z) = g(x,g(y,z))\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Here are some examples of additive (associative) characteristics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The sum of a list of numbers&lt;/li&gt;
&lt;li&gt;The maximum and minimum number&lt;/li&gt;
&lt;li&gt;The sum of squares of a list of numbers&lt;/li&gt;
&lt;li&gt;The sum and size of a list of numbers (allowing to maintain the average, e.g. for answering “range average” queries)&lt;/li&gt;
&lt;li&gt;The number of times a given character occurs in the string
(for example, the newline character)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are many more examples, you can find them near the end of the
article, in the section “Monoids”.&lt;/p&gt;
&lt;p&gt;Below is an example of a rope of numbers maintaining the minimum
and maximum — the combining operation here is
&lt;span&gt;\(g((m_1,M_1), (m_2,M_2)) = (min(m_1,m_2), max(M_1,M_2))\)&lt;/span&gt;&lt;/p&gt;
&lt;div&gt;
&lt;p&gt;&lt;img src="http://jkff.info/articles/ire/_images/rope-minmax.png" alt="_images/rope-minmax.png"&gt;&lt;/p&gt;&lt;p&gt;A rope of numbers with “cached” minimums and maximums.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="monotone-split-operation"&gt;
&lt;h3&gt;Monotone split operation&lt;a title="Permalink to this headline" href="#monotone-split-operation"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;In addition to splitting at a position, one may implement one more
very important and beautiful operation on ropes: splitting on a monotone
predicate. We shall need this operation when we get from “testing
for a match” to “locating matches”, but we first provide an abstract
setting, because it will be a lot easier to understand how locating matches
can be done using this abstract algorithm, than to
go in the opposite direction (recognize its beauty inside the full
complicated algorithm for locating matches).&lt;/p&gt;
&lt;p&gt;Suppose &lt;span&gt;\(f\)&lt;/span&gt; is a predicate on strings. Suppose that &lt;span&gt;\(f\)&lt;/span&gt; is
such that a string may only &lt;em&gt;gain&lt;/em&gt; (but not lose) the property
&lt;span&gt;\(f\)&lt;/span&gt; when symbols are appended to it on the right, i.e.,
&lt;span&gt;\(\forall s_1, f(s_1) \Rightarrow \forall s_2, f(s_1 + s_2)\)&lt;/span&gt;.
In this case let us call &lt;span&gt;\(f\)&lt;/span&gt; &lt;strong&gt;monotone&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Then obviously each string &lt;span&gt;\(s\)&lt;/span&gt; satisfying the property &lt;span&gt;\(f\)&lt;/span&gt;
has a &lt;em&gt;minimal prefix&lt;/em&gt; satisfying &lt;span&gt;\(f\)&lt;/span&gt;. Let us illustrate
this notion and the algorithm for its efficient computation on a rope:&lt;/p&gt;
&lt;div&gt;
&lt;p&gt;&lt;img src="http://jkff.info/articles/ire/_images/split-sum-squares.png" alt="_images/split-sum-squares.png"&gt;&lt;/p&gt;&lt;p&gt;Splitting a rope of numbers by the monotone predicate “Sum of squares exceeds 140”&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;This picture shows a rope of numbers,
storing in each node the sum of squares of numbers within this node,
and it also shows how the rope is split to find &lt;em&gt;the minimal prefix whose
sum of squares is greater than 140&lt;/em&gt;. The algorithm resembles &lt;strong&gt;a “hot and cold”
game&lt;/strong&gt;; the figure shows sums of squares of prefixes before and after
various edges and (when scanning a leaf chunk) individual numbers;
those that do not yet satisfy the condition are marked with “cold” blue color,
and those that do are marked with “hot” red. This picture also shows that when
scanning through a leaf chunk, we have to recompute and add up the squares of numbers,
i.e. the information stored in nodes of the rope is not sufficient.&lt;/p&gt;
&lt;p&gt;On this picture &lt;strong&gt;an edge is marked red if the predicate is true for the
prefix which ends where this edge ends&lt;/strong&gt;. To find the split point,
we have to descend from the root of the rope to a leaf chunk, doing steps
downward or to the right, at each level scanning edges left-to-right
until we find a red edge (this is similar to a binary search procedure),
and finally split the leaf chunk, this time using regular linear search.&lt;/p&gt;
&lt;p&gt;Since we only move downward or to the right, at any moment the edges that
have been considered cover together an ever-growing prefix of the original
rope, and &lt;strong&gt;each new scanned edge appends the rope covered by this edge&lt;/strong&gt;
to this prefix. If the predicate is not true before scanning an edge but
becomes true after scanning it, this means that it becomes true somewhere
inside the part of the rope covered by the destination node of this edge,
and we have to descend downward into this node in order to find the split
point.&lt;/p&gt;
&lt;p&gt;In order to be constantly aware of whether the predicate is true, we should
be able to &lt;strong&gt;quickly compute&lt;/strong&gt; &lt;span&gt;\(f(ps)\)&lt;/span&gt;, &lt;strong&gt;given&lt;/strong&gt; &lt;span&gt;\(f(p)\)&lt;/span&gt; &lt;strong&gt;and&lt;/strong&gt; &lt;span&gt;\(f(s)\)&lt;/span&gt;
for any two ropes &lt;span&gt;\(p\)&lt;/span&gt; and &lt;span&gt;\(s\)&lt;/span&gt;, since when moving downward or
to the right, we increase the “current prefix” (&lt;span&gt;\(p\)&lt;/span&gt;) with sub-ropes
covered with each scanned edge (&lt;span&gt;\(s\)&lt;/span&gt;), and when we get to the leaf chunks,
during linear search we increase &lt;span&gt;\(p\)&lt;/span&gt; with single-element sub-ropes
corresponding to elements of the chunk.&lt;/p&gt;
&lt;p&gt;Now note that match testing also sometimes fits this pattern:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Given transition functions for &lt;span&gt;\(p\)&lt;/span&gt; and &lt;span&gt;\(s\)&lt;/span&gt;, we can quickly
compute the transition function of &lt;span&gt;\(ps\)&lt;/span&gt;, and given that transition
function, we know the answer to the match test.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Some regular expressions are monotone&lt;/strong&gt;, i.e. if a string matches the
expression, then appending characters on the right won’t make it lose
this property. One class of such regular expressions is expressions
of the form &lt;tt&gt;&lt;span&gt;.*R.*&lt;/span&gt;&lt;/tt&gt; for any &lt;tt&gt;&lt;span&gt;R&lt;/span&gt;&lt;/tt&gt;, because they correspond to
the question “Is there a match of &lt;tt&gt;&lt;span&gt;R&lt;/span&gt;&lt;/tt&gt; somewhere in the string?”,
which obviously is monotone.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So, we can use this “monotone split” procedure to find the &lt;strong&gt;smallest prefix
of the string containing a match&lt;/strong&gt; of our regex.&lt;/p&gt;
&lt;div&gt;
&lt;p&gt;&lt;img src="http://jkff.info/articles/ire/_images/tree-split-pred.png" alt="_images/tree-split-pred.png"&gt;&lt;/p&gt;&lt;p&gt;Splitting a rope for the string &lt;tt&gt;&lt;span&gt;acabaabacabccaaba&lt;/span&gt;&lt;/tt&gt; on the monotone predicate “matches &lt;tt&gt;&lt;span&gt;.*bcc.*&lt;/span&gt;&lt;/tt&gt; ”&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;This is key to finding match positions.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="finding-match-positions"&gt;
&lt;h3&gt;Finding match positions&lt;a title="Permalink to this headline" href="#finding-match-positions"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Suppose we have to find a match of &lt;span&gt;\(R\)&lt;/span&gt; in the string. This problem can
partly be reformulated as testing the string against the expression
“&lt;span&gt;\(.*R.*\)&lt;/span&gt;”, but this only tells us the answer to the question
“is there a match of &lt;span&gt;\(R\)&lt;/span&gt; somewhere in the string?”, but not to
“where is the match?”&lt;/p&gt;
&lt;p&gt;Two key ideas will help us find the match positions.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;As said above, the answer to the first question (the presence of a
match) is “monotone”. That is, starting from some
prefix of the string, the answer will be positive for all
subsequent prefixes. &lt;strong&gt;The first occurrence of&lt;/strong&gt; &lt;span&gt;\(R*\)&lt;/span&gt; &lt;strong&gt;ends
exactly where the first such prefix ends&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;It is known &lt;a id="id4" href="#f4"&gt;[4]&lt;/a&gt;  that, given a regular
expression &lt;span&gt;\(R\)&lt;/span&gt; or its corresponding automaton &lt;span&gt;\(A\)&lt;/span&gt;, one
can build a regular expression &lt;span&gt;\(R′\)&lt;/span&gt; and the automaton
&lt;span&gt;\(A′\)&lt;/span&gt; which recognize reverses of the strings recognized by
&lt;span&gt;\(R\)&lt;/span&gt; and &lt;span&gt;\(A\)&lt;/span&gt;, simply by reversing all sequences inside
&lt;span&gt;\(R\)&lt;/span&gt; and, correspondingly, all arrows in &lt;span&gt;\(A\)&lt;/span&gt;. For
example, the expression &lt;span&gt;\(a+(b|c*d)x*\)&lt;/span&gt; recognizes the string
&lt;span&gt;\(abbdxx\)&lt;/span&gt;, and the expression &lt;span&gt;\(x*(b|dc*)a+\)&lt;/span&gt;
recognizes &lt;span&gt;\(xxdbba\)&lt;/span&gt;. Therefore, &lt;strong&gt;we can find the
beginning of the match by launching the reversed
(“backward”) automaton&lt;/strong&gt; (automaton for the reversed expression)
backward over the string, starting from where the match
ends.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So, we use the “split on monotone predicate” operation to find the
end of the first match, and use it again, but this time in backward
direction and with the backward automaton, to find its beginning. If
the expression is such that strings matching it are usually small, we
can just run the backward automaton character by character; if not, we
can also have the nodes of the rope store transition functions
not only for the “forward” automaton, but also transition functions of
reversed parts of the string with respect to the “backward” automaton.&lt;/p&gt;
&lt;p&gt;It’s easy to see that all rope operations change trivially — instead
of composing one pair of transition functions, we compose two:
&lt;span&gt;\((f_1,b_1) \circ (f_2,b_2) = (f_2 \circ f_1, b_1 \circ b_2)\)&lt;/span&gt; —
note that the order of composition for backward transition functions
is reversed because for strings if &lt;span&gt;\(a=bc\)&lt;/span&gt;, then
&lt;span&gt;\(reverse(a)=reverse(c)reverse(b)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;There is actually a number of complications here, related to possible
overlaps of occurrences of different items from the given system of
regular expressions (or even self-overlaps), but the main idea is the
same: split to find the end of the match, split backward to find the
beginning. The curious reader is directed
&lt;a href="https://github.com/jkff/ire/blob/master/src/main/java/org/jkff/ire/DFAMatcher.java"&gt;to the source code&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div&gt;
&lt;h2&gt;Implementation&lt;a title="Permalink to this headline" href="#implementation"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Let us put together the presented algorithms and overview the
structure of the whole program. Graphically this structure is shown on
the pictures below. This kind of diagrams is called “concept maps”,
drawn with &lt;a href="http://cmap.ihmc.us/"&gt;IHMC CmapTools&lt;/a&gt; software.&lt;/p&gt;
&lt;div id="program-structure-overview"&gt;
&lt;h3&gt;Program structure overview&lt;a title="Permalink to this headline" href="#program-structure-overview"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;div&gt;
&lt;p&gt;&lt;img src="http://jkff.info/articles/ire/_images/ire-overview.png" alt="_images/ire-overview.png"&gt;&lt;/p&gt;&lt;p&gt;Program structure overview&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The user specifies several regular expressions as strings, which through
compilation (parsing and converting to a finite automaton) get
transformed to an object of type &lt;a href="https://github.com/jkff/ire/blob/master/src/main/java/org/jkff/ire/PatternSet.java"&gt;PatternSet&lt;/a&gt;.
Such an object
is capable of “indexing” regular strings, yielding objects of type
&lt;a href="https://github.com/jkff/ire/blob/master/src/main/java/org/jkff/ire/IndexedString.java"&gt;IndexedString&lt;/a&gt;.
They, in turn, are capable of efficiently
searching for all matches of the patterns in themselves, and they can
also efficiently be concatenated or split (on a monotone predicate).
These are of course the very ropes maintaining transition functions.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="ropes-and-additive-measures"&gt;
&lt;h3&gt;Ropes and additive measures&lt;a title="Permalink to this headline" href="#ropes-and-additive-measures"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;div&gt;
&lt;p&gt;&lt;img src="http://jkff.info/articles/ire/_images/ire-rope.png" alt="_images/ire-rope.png"&gt;&lt;/p&gt;&lt;p&gt;Program structure: ropes and additive measures&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;“Indexed strings” are implemented with ropes (&lt;a href="https://github.com/jkff/ire/blob/master/src/main/java/org/jkff/ire/rope/Rope.java"&gt;Rope&lt;/a&gt;).
The program
implements only ropes over characters, because further generalization
was not necessary within the scope of our problem and the Java type
system would cause the generic implementation to have a lot of
syntactic garbage. A rope is a string that knows its “measure” of
type &lt;tt&gt;&lt;span&gt;M&lt;/span&gt;&lt;/tt&gt;. The measure is computed as the sum of measures of
individual characters (&lt;tt&gt;&lt;span&gt;Function&amp;lt;Character,M&amp;gt;&lt;/span&gt;&lt;/tt&gt;) under an arbitrary
additive measure (&lt;a href="https://github.com/jkff/ire/blob/master/src/main/java/org/jkff/ire/util/Reducer.java"&gt;Reducer&lt;/a&gt;).
Ropes are implemented with a special kind
of balanced trees that will be described later in the article. During
rebalancing operations measures of new nodes are summed from measures
of old nodes using this additive operation.
For regular expression matching, the
additive operation composition of transition functions
for the expression’s automaton (more precisely, for two automata:
forward and reverse).&lt;/p&gt;
&lt;/div&gt;
&lt;div id="finite-automata"&gt;
&lt;h3&gt;Finite automata&lt;a title="Permalink to this headline" href="#finite-automata"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;div&gt;
&lt;p&gt;&lt;img src="http://jkff.info/articles/ire/_images/ire-fa.png" alt="_images/ire-fa.png"&gt;&lt;/p&gt;&lt;p&gt;Program structure: finite automata&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Automata are implemented in a way that facilitates representing and computing
their “transition functions”. An automaton can tell its
transition function for any given character, and the transition
function is a function from the automaton’s state type to the same
type. A value of the state type is a “black box” that only tells
what patterns are “terminated” by this state: if after scanning a
string, the automaton’s state terminates certain patterns, then there
are occurrences of these patterns ending at the end of this string.
Transition functions are represented not as arbitrary functions but as
a special kind of objects with efficient composition &lt;a id="id5" href="#f5"&gt;[5]&lt;/a&gt;.
These objects are placed into the ropes used as “indexed
strings”.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="relationship-between-dfas-and-nfas"&gt;
&lt;h3&gt;Relationship between DFAs and NFAs&lt;a title="Permalink to this headline" href="#relationship-between-dfas-and-nfas"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;div&gt;
&lt;p&gt;&lt;img src="http://jkff.info/articles/ire/_images/ire-dfa-nfa.png" alt="_images/ire-dfa-nfa.png"&gt;&lt;/p&gt;&lt;p&gt;Program structure: the connection between deterministic and non-deterministic automata&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The notion of an automaton is used
in the program in two ways: for deterministic and non-deterministic
automata. The state type of a deterministic automaton &lt;a id="id6" href="#f6"&gt;[6]&lt;/a&gt; is the set of
integer numbers from &lt;span&gt;\(0\)&lt;/span&gt; to some &lt;span&gt;\(N\)&lt;/span&gt;; correspondingly,
transition functions are functions from &lt;span&gt;\(0 … N\)&lt;/span&gt; to &lt;span&gt;\(0 … N\)&lt;/span&gt;.
They are implemented as one-dimensional &lt;tt&gt;&lt;span&gt;int[]&lt;/span&gt;&lt;/tt&gt; arrays, and
their composition is computed as easily as &lt;tt&gt;&lt;span&gt;c[i]&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;b[a[i]]&lt;/span&gt;&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;In the case of
non-deterministic automata, values of the state type are subsets of
some “basis” state set, and a transition function is determined by the
way in which it transforms each individual basis state to several
other basis state, i.e. it is specified by a transformation of the
form &lt;tt&gt;&lt;span&gt;int&lt;/span&gt;&lt;/tt&gt; → &lt;tt&gt;&lt;span&gt;int[]&lt;/span&gt;&lt;/tt&gt;. Composition of such functions is expressed as
&lt;span&gt;\(c[i] = \bigcup_{j \leftarrow a[i]} b[j]\)&lt;/span&gt; (thread the second function
through all the outputs of the first function). For the sake of efficiency, this
transformation is implemented by a boolean matrix with every element
represented as one bit in a single array &lt;a id="id7" href="#f7"&gt;[7]&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="multiple-regular-expressions"&gt;
&lt;h3&gt;Multiple regular expressions&lt;a title="Permalink to this headline" href="#multiple-regular-expressions"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The aforementioned datastructure allows to match a string against a single
regular expression. It is natural to demand a more practically useful
generalization: matching against multiple expressions (there exist also
other approaches to this problem, see for example the article
“Compact DFA structure for multiple regular expressions matching” by
Lin, Tang et al.).
The result of such a match is a set of facts of the form “The portion
&lt;span&gt;\(i..j\)&lt;/span&gt; matched expression &lt;span&gt;\(k\)&lt;/span&gt; ”.&lt;/p&gt;
&lt;p&gt;The problem of matching against multiple regular expressions
is solved quite easily: we build an automaton for their union,
&lt;span&gt;\(R_1|R_2|...\)&lt;/span&gt;, but we distinguish between final states
for different expressions, i.e. a state of the resulting automaton
is not simply “final” or “non-final”, but it has an associated bitset:
for which of the expressions it is final.&lt;/p&gt;
&lt;p&gt;This change only slightly influences other parts of the program, such as
automata minimization or finding match positions.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="examples-and-benchmarks"&gt;
&lt;h2&gt;Examples and benchmarks&lt;a title="Permalink to this headline" href="#examples-and-benchmarks"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Let us show an example of usage of the library.:&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;PatternSet pat = RegexCompiler.compile("007","008")
IndexedString s1 = pat.match("as00haklsdjhfla00");
IndexedString s2 = pat.match("7jhd7dsh008dsfa");
System.out.println(s1.append(s2).getMatches());&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;The program prints:&lt;/p&gt;

&lt;p&gt;This means that occurrences of the first and second pattern were found
correspondingly in positions 15–17 and 25–27.&lt;/p&gt;
&lt;p&gt;This code uses the following aspects of the API:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/jkff/ire/blob/master/src/main/java/org/jkff/ire/regex/RegexCompiler.java"&gt;RegexCompiler.compile&lt;/a&gt; — compile several regular
expressions to an automaton recognizing any of them.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jkff/ire/blob/master/src/main/java/org/jkff/ire/PatternSet.java"&gt;PatternSet.match&lt;/a&gt; — index a “regular” string, preparing
it to searching for the given patterns.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jkff/ire/blob/master/src/main/java/org/jkff/ire/IndexedString.java"&gt;IndexedString.append&lt;/a&gt; — compute the concatenation of two
strings indexed by the same pattern set.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jkff/ire/blob/master/src/main/java/org/jkff/ire/IndexedString.java"&gt;IndexedString.getMatches&lt;/a&gt; — find matches of the pattern
set in an indexed string.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now let us discuss the library’s performance.&lt;/p&gt;
&lt;p&gt;This discussion won’t be a simple one, because the performance is
influenced by a large number of factors.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Size of the automaton&lt;/strong&gt;, which depends approximately linearly on
the number and size of individual regular expressions: it linearly
influences both the performance of all operations and the memory
consumption (larger is worse). The program uses an algorithm for
minimization of non-deterministic automata described in
the article “On NFA reductions” by Ilie and Navarro.
(however, the implementation is extremely
inefficient, but this doesn’t influence matching performance
because minimization is only done in &lt;a href="https://github.com/jkff/ire/blob/master/src/main/java/org/jkff/ire/regex/RegexCompiler.java"&gt;RegexCompiler.compile&lt;/a&gt;),
but it usually shrinks the
automaton just by several dozen percents.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Size of the leaf chunks&lt;/strong&gt; in ropes linearly influences search
performance (larger is slower), has almost no influence at all on
concatenation performance, and linearly influences memory
consumption (the larger the chunks, the fewer the memory
overhead).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Features of the particular regular expression&lt;/strong&gt; influence the
automaton’s “shape”, which in turn influences the speed of
operations on it (“hairy” expressions lead to dense boolean
matrices for transition functions, which are slower to multiply in
the current implementation).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Number of matches&lt;/strong&gt; linearly influences the search time in the
current implementation (larger is worse), but there is room for
optimization here.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It is also necessary to balance the share of time devoted to indexing
the string, doing concatenations/splits and searching. Indexing is
done quite slowly, and one needs a large number of
concatenations/splits and search to overweight it and to get an
advantage over a “traditional” regular expression engine.&lt;/p&gt;
&lt;div id="test-setup"&gt;
&lt;h3&gt;Test setup&lt;a title="Permalink to this headline" href="#test-setup"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;In light of the above, let us consider just a single test and analyze
its performance. Take the set of regular expressions from the
&lt;a href="http://shootout.alioth.debian.org/u32q/performance.php?test=regexdna"&gt;regex-dna&lt;/a&gt;
problem from the Language Shooutout
and consider performance of matching operations compared to the
standard regular expression engine bundled with Java
(&lt;a href="http://download.oracle.com/javase/1.5.0/docs/api/java/util/regex/Pattern.html"&gt;java.util.regex.Pattern&lt;/a&gt;), varying length
of the input DNA string (but keeping constant the total number of
matches) and size of the leaf chunks: 8, 16, 32, … 512
characters.&lt;/p&gt;
&lt;p&gt;We do not measure splitting performance
separately, because splitting is used during search, and we do not
measure concatenation performance because
it is so fast (allocate a few objects and compose a few transition functions)
that it is difficult to imagine a scenario where it would be the
bottleneck.&lt;/p&gt;
&lt;p&gt;Here is the pattern set:&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;[cgt]gggtaaa|tttaccc[acg]
a[act]ggtaaa|tttacc[agt]t
ag[act]gtaaa|tttac[agt]ct
agg[act]taaa|ttta[agt]cct
aggg[acg]aaa|ttt[cgt]ccct
agggt[cgt]aa|tt[acg]accct
agggta[cgt]a|t[acg]taccct
agggtaa[cgt]|[acg]ttaccct&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;Let us generate the input as a random sequence of the characters
“ &lt;tt&gt;&lt;span&gt;a&lt;/span&gt;&lt;/tt&gt;, &lt;tt&gt;&lt;span&gt;g&lt;/span&gt;&lt;/tt&gt;, &lt;tt&gt;&lt;span&gt;c&lt;/span&gt;&lt;/tt&gt;, &lt;tt&gt;&lt;span&gt;t&lt;/span&gt;&lt;/tt&gt; ” of length &lt;span&gt;\(50000 N\)&lt;/span&gt;
(&lt;span&gt;\(N\)&lt;/span&gt; will vary from 1 to 10) where any two consequent characters
are distinct (therefore the aforementioned patterns can’t occur
there), choose 100 random positions in the sequence and insert there
occurrences of strings randomly chosen from the set of &lt;span&gt;\(8 × 2 × 3 = 48\)&lt;/span&gt;
strings defined by the given pattern set (8 patterns, each with 2 alternatives,
each alternative matching 3 different strings). The program will
compute the occurrence count of each pattern.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="benchmark-results-and-interpretation"&gt;
&lt;h3&gt;Benchmark results and interpretation&lt;a title="Permalink to this headline" href="#benchmark-results-and-interpretation"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Results of the benchmark are shown on the pictures below. The
performance characteristics of each of the two programs (our engine
and the standard Java engine) are shown in the terms that are most
appropriate for them: for our engine it is the indexing speed (in
characters per second, because indexing speed is proportional to the
number of characters) and search speed (in occurrences per second,
because search speed is proportional to the number of occurrences). For
the Java engine a more appropriate characteristic is “characters
processed per second”; it is displayed on the same graph with our
engine’s “indexing speed’, though this comparison is somewhat
flawed.&lt;/p&gt;
&lt;p&gt;On graphs in the left part of the picture, different curves correspond
to different &lt;em&gt;base sizes of chunks&lt;/em&gt; in the rope datastructure,
and the bold curve corresponds to the Java engine.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The question “When is our engine better than the Java engine?” is
best answered by the top left graph&lt;/strong&gt;, which shows the dependency of
search speed on the string length. It can be seen that the Java
engine’s search time is proportional to the length of the string, and
our engine’s time is proportional to the number of occurrences. With
small base chunk sizes (4–32 characters) our engine is much faster
for large strings.&lt;/p&gt;
&lt;p&gt;On graphs in the right part of the picture, different curves
correspond to different &lt;em&gt;lengths&lt;/em&gt; of the input string. They are
displayed to show how the base chunk size influences search and
indexing speed. It can be seen that with increase of this chunk size
indexing speed increases rapidly (but with a limit) and search speed
decreases just as rapidly.&lt;/p&gt;
&lt;p&gt;We can conclude that &lt;strong&gt;for large strings with a small number of
occurrences our engine is more efficient&lt;/strong&gt;, especially if tuned for a
small base chunk size. However, in this case there is a sharp increase
in memory consumption: memory consumption per leaf chunk does not depend
on the chunk size, but there are 128 times more of 4-character chunks
in a string then there are 512-character chunks, therefore the memory
consumption is also 128 times larger.&lt;/p&gt;
&lt;div&gt;
&lt;p&gt;&lt;img src="http://jkff.info/articles/ire/_images/benchmark.png" alt="_images/benchmark.png"&gt;&lt;/p&gt;&lt;p&gt;Performance benchmarks&lt;/p&gt;
&lt;/div&gt;
&lt;div&gt;
&lt;p&gt;&lt;img src="http://jkff.info/articles/ire/_images/memory-overhead.png" alt="_images/memory-overhead.png"&gt;&lt;/p&gt;&lt;p&gt;Memory overhead&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Almost all the time is spent composing transition functions of characters&lt;/strong&gt;
(which is done through boolean matrix multiplication) for recomputing
transition functions of leaf chunks during
splits, and almost all the memory overhead is devoted to storing these
boolean matrices.&lt;/p&gt;
&lt;p&gt;We haven’t considered how performance depends on the complexity
of regular expressions and on the number of occurrences. A
comprehensive treatment of performance questions would take up too
much space; curious readers are encouraged to play with the library
themselves.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="what-s-next"&gt;
&lt;h2&gt;What’s next?&lt;a title="Permalink to this headline" href="#what-s-next"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The current implementation has a number of drawbacks. It is not yet
clear which of these can be fixed and which can’t, but in any case, they are
interesting algorithmic problems worth thinking about.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The questions of match semantics, such as “greediness” etc. are
not considered in the program at all. It is unclear which of the
popular solutions (POSIX, Perl, …) are efficiently
implementable within the automata-theoretic approach.&lt;/li&gt;
&lt;li&gt;Capturing groups are not supported. The article
&lt;a href="http://swtch.com/~rsc/regexp/regexp3.html"&gt;Regular Expression Matching in the Wild&lt;/a&gt;
describes a way to
support them with automata, but the proposed solution does not fit
well with our approach.&lt;/li&gt;
&lt;li&gt;Multiplication of boolean matrices (used for computing the
composition of transition functions) uses a well-optimized but
rather naive algorithm; perhaps in some scenarios other algorithms
would be faster (for example, ones using sparse matrices).&lt;/li&gt;
&lt;li&gt;During matching using splits, a lot of unneeded work is done: for
example, during the backward split (which is used to find the
&lt;em&gt;beginning&lt;/em&gt; of a match) there’s no need to compute the
transition function
for the two resulting strings. Fixing this problem would increase
performance by a couple dozen percents.&lt;/li&gt;
&lt;li&gt;Matching time is proportional to the number of occurrences, the
leaf chunk size and the automaton’s size. This makes the program
nearly useless as an efficient incremental lexer, because in
lexing problems the number of occurrences is very large. One of the
ways to fix this problem is to modify the “split by monotone
predicate” algorithm to split not into two, but into many parts,
for example, on the “edges” of a monotone integer-valued
function.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;a title="Permalink to this headline" href="#conclusion"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;So, we’ve built a library that does incremental matching of strings
against a set of regular expressions using balanced trees and monoids.
The library is very efficient in the case of long strings, few
expressions, few occurrences, frequent incremental recomputation and a
lot of free memory, and is quite inefficient in other cases. It’s hard
to say, for which of the cases it is at all possible to make it
efficient: for example, whether it is possible to create a
high-performance incremental lexer with it, and whether we can at all
name this experiment an algorithmic success. The author hopes at least
that the presented techniques will inspire the algorithmically
inclined readers for new research and will prove of use to them in
other problems.&lt;/p&gt;
&lt;p&gt;In any case, we can say that this development is an interesting and
successful experience of blending the functional and imperative
approaches.&lt;/p&gt;
&lt;p&gt;Let us list the used techniques, ideas and traditions from functional
programming, and discuss how well they fit with the imperative nature
of the target language (Java).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The main datastructure, the rope, is pure (immutable). This
decision went very well with the Java language and dramatically
simplified development and debugging, despite the absence of
language features such as algebraic datatypes and pattern
matching.&lt;/li&gt;
&lt;li&gt;Nearly all of the library’s API is pure (doesn’t have side
effects). However, mutable state and side effects are abandoned
only on an architectural level, but the implementation has quite a
few usages of mutable state, both for the sake of performance
(multiplication of boolean matrices) and, paradoxically,
readability (building an automaton from a regular expression). See
the source code for, correspondingly, &lt;tt&gt;&lt;span&gt;PowerIntTable&lt;/span&gt;&lt;/tt&gt; and
&lt;tt&gt;&lt;span&gt;RegexCompiler&lt;/span&gt;&lt;/tt&gt; for details. All in all, this means that the
purely functional approach to programming fits well with
imperative languages and doesn’t prevent us from using mutable
state in the cases where it brings more use than harm.&lt;/li&gt;
&lt;li&gt;Contrary to the common myth “functional programming is inefficient
and leads to excessive memory consumption”, the only performance
bottleneck is in the imperative algorithm of transition function
multiplication, and memory is used for storing these transition
functions for rope nodes as bitmasks. Apparently there is no
connection between the overheads and the pure nature of the
algorithms &lt;a id="id9" href="#f8"&gt;[8]&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;The core of the program is manipulation of higher-order functions:
ropes are parameterized by monoids, and their most important
operation, splitting, is parameterized by a predicate. Since Java
does not have a compact syntax for function definition (such as
lambda expressions) and type inference, usage of these entities
causes quite a lot of syntactic garbage (especially types in
declarations). However, though their usage is extremely important
for the program as a whole, it is concentrated in a rather small
region of the code, isolated from the library’s end users.
However, if the Java type system were a bit more powerful and a bit
less verbose, it would be possible to generalize the library,
without loss of performance, to searching not just strings but
arbitrary sequences.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The author would like to thank Dmitry Demeschchuk, Julia Astakhova,
Alexey Ott and other reviewers of the original Russian version
of this article for their feedback.&lt;/p&gt;
&lt;p&gt;The project is published on GitHub at &lt;a href="http://github.com/jkff/ire"&gt;http://github.com/jkff/ire&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="appendix-1-implementation-of-ropes"&gt;
&lt;h2&gt;Appendix 1: Implementation of ropes&lt;a title="Permalink to this headline" href="#appendix-1-implementation-of-ropes"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;It has already been said that, when representing a string by a
balanced tree, in order to keep memory usage reasonable, one should
associate each leaf of the tree not with one character but with a
chunk. Therefore, the datastructure suggested in
&lt;a href="http://blog.sigfpe.com/2009/01/fast-incremental-regular-expression.html"&gt;Dan’s post&lt;/a&gt; (finger
trees, described, for example, &lt;a href="http://apfelmus.nfshost.com/monoid-fingertree.html"&gt;by Heinrich Apfelmus&lt;/a&gt;
and in the &lt;a href="http://www.soi.city.ac.uk/~ross/papers/FingerTree.html"&gt;original paper&lt;/a&gt;)
is not a good fit: it assumes one node
per element of the sequence (string).&lt;/p&gt;
&lt;p&gt;We should choose one of the kinds of balanced trees satisfying our
requirements. Let us list the requirements.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It should be possible for the nodes to store the sum of their
subtree with respect to an arbitrary additive measure;&lt;/li&gt;
&lt;li&gt;It should be cheap to update this sum during rebalancing
operations (and there should be few of them);&lt;/li&gt;
&lt;li&gt;The tree’s height should be logarithmic in the number of elements;&lt;/li&gt;
&lt;li&gt;Concatenation and splitting operations should be efficient.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;One of the simplest (in terms of implementation) but nevertheless
quite efficient balanced trees are &lt;strong&gt;trees of constant height&lt;/strong&gt;, for
example “2–3-trees” and “B-trees” (which are
frequently used for DBMS indices).&lt;/p&gt;
&lt;p&gt;In such trees, the length of the path
from root to each leaf is the same, therefore (since each non-leaf
node has at least 2 children) the height is logarithmic. Usually they
are used for a quite different class of problems, namely that of
representing sets and searching them, but they are also a perfect fit
for representing sequences (strings). The basic idea is that a node is
allowed to have &lt;span&gt;\(K\)&lt;/span&gt; to &lt;span&gt;\(2K-1\)&lt;/span&gt; children (for some &lt;span&gt;\(K\)&lt;/span&gt;)
and most operations, such as insertion, splitting and concatenation,
preserve this property; and when they don’t, a rebalancing occurs:
either an overflown node is split into two, or two underflown nodes
are merged into one.&lt;/p&gt;
&lt;p&gt;We shall use a variation on this theme: 2–3 trees with chunks in
leaves, where the chunk size may vary from &lt;span&gt;\(N\)&lt;/span&gt; to &lt;span&gt;\(2N-1\)&lt;/span&gt;,
and all data is stored in leaves, not in nodes &lt;a id="id10" href="#f9"&gt;[9]&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The next picture illustrates the implementations of all
operations on such trees. Essentially two operations suffice:
splitting and concatenation, all others can be expressed through them.
When digesting the pictures, it is important to remember that we’re
dealing with trees of constant height. Note also that the chunk size
invariant may be broken, but only in the case where there are less
than &lt;span&gt;\(N\)&lt;/span&gt; elements total: in this case the tree is represented by
a single underflown chunk.&lt;/p&gt;
&lt;div&gt;
&lt;p&gt;&lt;img src="http://jkff.info/articles/ire/_images/rope-ops.png" alt="_images/rope-ops.png"&gt;&lt;/p&gt;&lt;p&gt;Rope operations&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Let us explain these pictures briefly in the order in which they appear,
top to bottom, left to right:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Concatenating a rope of height &lt;span&gt;\(h+1\)&lt;/span&gt; and a rope of heigh &lt;span&gt;\(h\)&lt;/span&gt;
has two cases: when the first one is a 2-node and a 3-node respectively.&lt;/li&gt;
&lt;li&gt;Concatenating a 2-node of height &lt;span&gt;\(h+1\)&lt;/span&gt;, which is a 2-node with children
of height &lt;span&gt;\(h\)&lt;/span&gt; and another rope of height &lt;span&gt;\(h\)&lt;/span&gt; simply makes
a 3-node.&lt;/li&gt;
&lt;li&gt;Concatenating a 3-node of height &lt;span&gt;\(h+1\)&lt;/span&gt; with a node of height &lt;span&gt;\(h\)&lt;/span&gt;
is the only case where a rope’s height increases: we put those 4
&lt;span&gt;\(h\)&lt;/span&gt;-high nodes into a 2-node of 2-nodes.&lt;/li&gt;
&lt;li&gt;Concatenating a rope (2-node or 3-node) of height &lt;span&gt;\(h+1\)&lt;/span&gt; and a rope with
height smaller than &lt;span&gt;\(h\)&lt;/span&gt; is reduced, through the associativity of
concatenation, to recursively concatenating the last &lt;span&gt;\(h\)&lt;/span&gt;-node of the first
rope with the second rope, and concatenating the remainder of the first rope
with the result.&lt;/li&gt;
&lt;li&gt;Concatenating two ropes of equal height is the simplest case: they make a 2-node.&lt;/li&gt;
&lt;li&gt;Concatenating two chunks is the only slightly non-trivial case: if their
total size is smaller than the maximum chunk size (i.e. &lt;span&gt;\(2N\)&lt;/span&gt;), then
we simply concatenate the arrays and form a new chunk. If it’s bigger than
&lt;span&gt;\(2N-1\)&lt;/span&gt; (though it can’t be bigger than &lt;span&gt;\(4N-2\)&lt;/span&gt;), then half of this
number is between &lt;span&gt;\(N\)&lt;/span&gt; and &lt;span&gt;\(2N-1\)&lt;/span&gt;, which allows us to perfectly
make a 2-node of halves of their concatenation.&lt;/li&gt;
&lt;li&gt;Splitting a 2-node or 3-node is done by summing its 2 or 3 children until the
predicate of the sum becomes true, and then descending into the child that
caused this, because the split point must be somewhere inside it. Then we
assemble the splitting result of the original node from its other children
and parts of the split child. An example is drawn for the case where already
the sum of the first child satisfies the predicate.&lt;/li&gt;
&lt;li&gt;Splitting chunks is done in a most straightforward linear fashion.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;One of the most important aspects of this datastructure is its
“purity”: operations on it do not change an existing instance but form
a new one instead, i.e. they are functions in the mathematical sense.&lt;/p&gt;
&lt;p&gt;We have already mentioned the importance of the decision to make the
incremental interface “pure”, but now it is time to elaborate.&lt;/p&gt;
&lt;div id="the-importance-of-purity"&gt;
&lt;h3&gt;The importance of purity&lt;a title="Permalink to this headline" href="#the-importance-of-purity"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;There are many advantages to using a pure approach to algorithms
and datastructures, which have manifested themselves during the
implementation of this program, particularly in the implementation
of ropes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exceptional ease of implementation.&lt;/strong&gt; Essentially we can take
the diagrams drawn on the picture above and translate them
mechanically to code. Lack of mutability causes the code to be a lot
simpler, and its correctness (or lack thereof) becomes more obvious,
because the code doesn’t have the &lt;em&gt;time&lt;/em&gt; dimension anymore, and
in order to understand how it works, one does not need to mentally
trace a sequence of intermediate steps &lt;a id="id11" href="#f10"&gt;[10]&lt;/a&gt;: the code is just an enumeration of various cases
where for each branch it is declared that “such and such input yields
such and such output”. And indeed, to the author’s surprise, after
the first successful compilation only 1 or 2 silly mistakes were fixed
before the code passed all the tests.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Ease of debugging.&lt;/strong&gt; During debugging one often wants to look
at the values of some expressions “in advance” in order to
understand whether it is necessary to step into them, or their result
is correct and the error is somewhere later in the
code &lt;a id="id12" href="#f11"&gt;[11]&lt;/a&gt; When these expressions are
“pure” (i.e., don’t have side effects), such an approach is
possible. If side effects are present, then evaluating the expression
in the debugger will change the program’s internal state and further
debugging will be pointless.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Complete thread safety.&lt;/strong&gt; It is well known that most standard
mutable datastructures do not allow concurrent reading and
modification, and one must synchronize access to them in a
multi-threaded program. However, it is often desirable to provide
non-blocking read access, even if not the most current state of the
datastructure will be read. There exist tricks allowing to do that for
mutable datastructure (see, for example, the implementation of the
&lt;a href="http://www.docjar.com/html/api/java/util/concurrent/ConcurrentHashMap.java.html"&gt;ConcurrentHashMap&lt;/a&gt; or the
&lt;a href="http://www.docjar.com/html/api/java/util/concurrent/ConcurrentSkipListMap.java.html"&gt;ConcurrentSkipListMap&lt;/a&gt; classes in the
Java standard library), but for immutable datastructures no tricks
are necessary, because every instance can be safely read without
worrying about it being concurrently modified: it cannot be modified
at all.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;High performance and low memory consumption in certain
scenarios&lt;/strong&gt;. There exist situations where it is useful to preserve the
“original” version of a datastructure after applying an operation to
it (for example, to preserve access to two ropes after computing their
concatenation). Most importantly, these situations arise in
backtracking enumeration algorithms and genetic algorithms (for
example, when it is possible to combine two genomes in several ways,
when one wants to keep both the genomes and the result of their
crossover). Of course, one might just copy the original datastructure,
but that might be very inefficient, especially if the structure is
large. On the contrary, for pure datastructures there’s no need to
copy, and we get a performance advantage. Also, as shown on the picture
above, many operations on ropes allocate minuscule (constant
or logarithmic) amounts of extra memory. The picture below
shows the object graph for two ropes and
their concatenation. It can be seen that most of the memory is used in
a shared fashion, but each object is nevertheless accessible
independently.&lt;/p&gt;
&lt;div&gt;
&lt;p&gt;&lt;img src="http://jkff.info/articles/ire/_images/rope-append-sharing.png" alt="_images/rope-append-sharing.png"&gt;&lt;/p&gt;&lt;p&gt;Sharing of memory after rope concatenation.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;To even better explain how rope concatenation and splitting work, and
why they are so easy to implement correctly, let us simply show the code.&lt;/p&gt;
&lt;div&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;div&gt;&lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td&gt;&lt;div&gt;&lt;pre&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;left&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;right&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
    &lt;span&gt;int&lt;/span&gt; &lt;span&gt;blockSize&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;factory&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;getBlockSize&lt;/span&gt;&lt;span&gt;();&lt;/span&gt;
    &lt;span&gt;Reducer&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;reducer&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;factory&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;getReducer&lt;/span&gt;&lt;span&gt;();&lt;/span&gt;

    &lt;span&gt;M&lt;/span&gt; &lt;span&gt;sum&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;reducer&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;compose&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;sum&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;right&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;sum&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;

    &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;h&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;right&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;h&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
        &lt;span&gt;// Case "Two non-leaves of equal height"&lt;/span&gt;
        &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;h&lt;/span&gt; &lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
            &lt;span&gt;return&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;right&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;sum&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;

        &lt;span&gt;// Case "Two leaves, both large enough to be children of a 2-node"&lt;/span&gt;
        &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(!&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;isUnderflownBlock&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span&gt;!&lt;/span&gt;&lt;span&gt;right&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;isUnderflownBlock&lt;/span&gt;&lt;span&gt;())&lt;/span&gt;
            &lt;span&gt;return&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;right&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;sum&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;

        &lt;span&gt;// Case "Two leaf chunks, rebalancing needed"&lt;/span&gt;
        &lt;span&gt;String&lt;/span&gt; &lt;span&gt;bigBlock&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;block&lt;/span&gt; &lt;span&gt;+&lt;/span&gt; &lt;span&gt;right&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;block&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
        &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;bigBlock&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;length&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;&amp;lt;=&lt;/span&gt; &lt;span&gt;2&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; &lt;span&gt;blockSize&lt;/span&gt; &lt;span&gt;-&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
            &lt;span&gt;return&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;factory&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;bigBlock&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;sum&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
        &lt;span&gt;return&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;(&lt;/span&gt;
                &lt;span&gt;new&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;factory&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;bigBlock&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;substring&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;blockSize&lt;/span&gt;&lt;span&gt;)),&lt;/span&gt;
                &lt;span&gt;new&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;factory&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;bigBlock&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;substring&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;blockSize&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;bigBlock&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;length&lt;/span&gt;&lt;span&gt;())),&lt;/span&gt;
                &lt;span&gt;sum&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
    &lt;span&gt;}&lt;/span&gt; &lt;span&gt;else&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;h&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;right&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;h&lt;/span&gt; &lt;span&gt;+&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
        &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;c&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;null&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;// 2-node of h + h -&amp;gt; 3-node&lt;/span&gt;
            &lt;span&gt;return&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;a&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;b&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;right&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;sum&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
        &lt;span&gt;else&lt;/span&gt;                &lt;span&gt;// 3-node of h + h -&amp;gt; 2-node of 2-nodes&lt;/span&gt;
            &lt;span&gt;return&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;(&lt;/span&gt;
                    &lt;span&gt;new&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;a&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;b&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;reducer&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;compose&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;a&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;sum&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;b&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;sum&lt;/span&gt;&lt;span&gt;)),&lt;/span&gt;
                    &lt;span&gt;new&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;c&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;right&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;reducer&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;compose&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;c&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;sum&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;right&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;sum&lt;/span&gt;&lt;span&gt;)),&lt;/span&gt;
                    &lt;span&gt;sum&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
    &lt;span&gt;}&lt;/span&gt; &lt;span&gt;else&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;right&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;h&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;h&lt;/span&gt; &lt;span&gt;+&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
        &lt;span&gt;// Symmetrical&lt;/span&gt;
    &lt;span&gt;}&lt;/span&gt; &lt;span&gt;else&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;h&lt;/span&gt; &lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;right&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;h&lt;/span&gt; &lt;span&gt;+&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
        &lt;span&gt;// Break the larger tree into nodes, regroup using associativity&lt;/span&gt;
        &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;c&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;null&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
            &lt;span&gt;return&lt;/span&gt; &lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;a&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;b&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;right&lt;/span&gt;&lt;span&gt;));&lt;/span&gt;
        &lt;span&gt;else&lt;/span&gt;
            &lt;span&gt;return&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;a&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;b&lt;/span&gt;&lt;span&gt;)).&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;c&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;right&lt;/span&gt;&lt;span&gt;));&lt;/span&gt;
    &lt;span&gt;}&lt;/span&gt; &lt;span&gt;else&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;// right.h &amp;gt; left.h + 1&lt;/span&gt;
        &lt;span&gt;// Symmetrical&lt;/span&gt;
    &lt;span&gt;}&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;
&lt;p&gt;And then the splitting code, with a slightly curious interface.
This function splits a rope into two, given a monotone function on
the string represented by the rope. Monotonicity is exploited by
requiring to provide functions that compute &lt;span&gt;\(f(a+b)\)&lt;/span&gt; given
&lt;span&gt;\(f(a)\)&lt;/span&gt; and &lt;span&gt;\(b\)&lt;/span&gt;, where &lt;span&gt;\(b\)&lt;/span&gt; is either a string
(represented by a rope) or a single character (for finding the
rising edge within a leaf-level rope chunk).&lt;/p&gt;
&lt;div&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;div&gt;&lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td&gt;&lt;div&gt;&lt;pre&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;S&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;Pair&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;,&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span&gt;splitAfterRise&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;
        &lt;span&gt;S&lt;/span&gt; &lt;span&gt;seed&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
        &lt;span&gt;Function2&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;S&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;,&lt;/span&gt; &lt;span&gt;S&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;addChunk&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Function2&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;S&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Character&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;S&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;addChar&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
        &lt;span&gt;Predicate&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;S&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;toBool&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
&lt;span&gt;{&lt;/span&gt;
    &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;block&lt;/span&gt; &lt;span&gt;!=&lt;/span&gt; &lt;span&gt;null&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
        &lt;span&gt;// Simple linear search inside the chunk&lt;/span&gt;
        &lt;span&gt;S&lt;/span&gt; &lt;span&gt;s&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;seed&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
        &lt;span&gt;for&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;int&lt;/span&gt; &lt;span&gt;i&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;;&lt;/span&gt; &lt;span&gt;i&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;/span&gt; &lt;span&gt;block&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;length&lt;/span&gt;&lt;span&gt;();&lt;/span&gt; &lt;span&gt;++&lt;/span&gt;&lt;span&gt;i&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
            &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;toBool&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;isTrueFor&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;s&lt;/span&gt;&lt;span&gt;))&lt;/span&gt;
                &lt;span&gt;return&lt;/span&gt; &lt;span&gt;Pair&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;of&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;
                        &lt;span&gt;new&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;(&lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;factory&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;block&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;substring&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;i&lt;/span&gt;&lt;span&gt;)),&lt;/span&gt;
                        &lt;span&gt;new&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;(&lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;factory&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;block&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;substring&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;i&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;block&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;length&lt;/span&gt;&lt;span&gt;())));&lt;/span&gt;
            &lt;span&gt;s&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;addChar&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;applyTo&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;s&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;block&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;charAt&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;i&lt;/span&gt;&lt;span&gt;));&lt;/span&gt;
        &lt;span&gt;}&lt;/span&gt;
        &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;toBool&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;isTrueFor&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;s&lt;/span&gt;&lt;span&gt;))&lt;/span&gt;
            &lt;span&gt;return&lt;/span&gt; &lt;span&gt;Pair&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;of&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;(&lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;factory&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;""&lt;/span&gt;&lt;span&gt;));&lt;/span&gt;
        &lt;span&gt;return&lt;/span&gt; &lt;span&gt;null&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
    &lt;span&gt;}&lt;/span&gt; &lt;span&gt;else&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
        &lt;span&gt;// Start from seed&lt;/span&gt;
        &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;toBool&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;isTrueFor&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;seed&lt;/span&gt;&lt;span&gt;))&lt;/span&gt;
            &lt;span&gt;return&lt;/span&gt; &lt;span&gt;Pair&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;of&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;(&lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;factory&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;""&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
        &lt;span&gt;S&lt;/span&gt; &lt;span&gt;afterA&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;addChunk&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;applyTo&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;seed&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;a&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
        &lt;span&gt;// If adding node A made the condition true, descend into A&lt;/span&gt;
        &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;toBool&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;isTrueFor&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;afterA&lt;/span&gt;&lt;span&gt;))&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
            &lt;span&gt;// Split A and assemble result from b, c and parts of a&lt;/span&gt;
            &lt;span&gt;Pair&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;,&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span&gt;sa&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;a&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;splitAfterRise&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;seed&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;addChunk&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;addChar&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;toBool&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
            &lt;span&gt;return&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;c&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;null&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
                    &lt;span&gt;?&lt;/span&gt; &lt;span&gt;Pair&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;of&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;sa&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;first&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;sa&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;second&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;b&lt;/span&gt;&lt;span&gt;))&lt;/span&gt;
                    &lt;span&gt;:&lt;/span&gt; &lt;span&gt;Pair&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;of&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;sa&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;first&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;sa&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;second&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;b&lt;/span&gt;&lt;span&gt;).&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;c&lt;/span&gt;&lt;span&gt;));&lt;/span&gt;
        &lt;span&gt;}&lt;/span&gt;
        &lt;span&gt;// Same for B&lt;/span&gt;
        &lt;span&gt;S&lt;/span&gt; &lt;span&gt;afterB&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;addChunk&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;applyTo&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;afterA&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;b&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
        &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;toBool&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;isTrueFor&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;afterB&lt;/span&gt;&lt;span&gt;))&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
            &lt;span&gt;Pair&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;,&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span&gt;sb&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;b&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;splitAfterRise&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;afterA&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;addChunk&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;addChar&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;toBool&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
            &lt;span&gt;return&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;c&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;null&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
                    &lt;span&gt;?&lt;/span&gt; &lt;span&gt;Pair&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;of&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;a&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;sb&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;first&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;sb&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;second&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
                    &lt;span&gt;:&lt;/span&gt; &lt;span&gt;Pair&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;of&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;a&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;sb&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;first&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;sb&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;second&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;c&lt;/span&gt;&lt;span&gt;));&lt;/span&gt;
        &lt;span&gt;}&lt;/span&gt;
        &lt;span&gt;// Same for C, if this is a 3-node&lt;/span&gt;
        &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;c&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;null&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
            &lt;span&gt;return&lt;/span&gt; &lt;span&gt;null&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
        &lt;span&gt;S&lt;/span&gt; &lt;span&gt;afterC&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;addChunk&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;applyTo&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;afterB&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;c&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
        &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;toBool&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;isTrueFor&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;afterC&lt;/span&gt;&lt;span&gt;))&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
            &lt;span&gt;Pair&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;,&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span&gt;sc&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;c&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;splitAfterRise&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;afterB&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;addChunk&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;addChar&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;toBool&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
            &lt;span&gt;return&lt;/span&gt; &lt;span&gt;Pair&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;of&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;a&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;b&lt;/span&gt;&lt;span&gt;).&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;sc&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;first&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;sc&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;second&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
        &lt;span&gt;}&lt;/span&gt;
        &lt;span&gt;return&lt;/span&gt; &lt;span&gt;null&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
    &lt;span&gt;}&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="appendix-2-monoids"&gt;
&lt;h2&gt;Appendix 2: Monoids&lt;a title="Permalink to this headline" href="#appendix-2-monoids"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Remember how, given a finite automaton, we can associate every string
with a “transition function” with respect to this automaton, and when
concatenating two strings their transition functions are composed (let
us denote the composition of &lt;span&gt;\(f_1\)&lt;/span&gt; and &lt;span&gt;\(f_2\)&lt;/span&gt; as
&lt;span&gt;\(f_1 \circ f_2\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Composition of transition functions (similarly to concatenation of
strings) has a few simple and useful properties:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For any transition functions &lt;span&gt;\(f\)&lt;/span&gt;, &lt;span&gt;\(g\)&lt;/span&gt; and &lt;span&gt;\(h\)&lt;/span&gt;
holds &lt;span&gt;\(f \circ (g \circ h) = (f \circ g) \circ h\)&lt;/span&gt;. This property
of the “&lt;span&gt;\(\circ\)&lt;/span&gt; ” operator is called “associativity”.&lt;/li&gt;
&lt;li&gt;There exists a special transition function &lt;span&gt;\(u\)&lt;/span&gt; that maps
every state of the automaton to itself. It is called the
“unit” of the “ &lt;span&gt;\(\circ\)&lt;/span&gt; ” operator because, just as
&lt;span&gt;\(1 ⋅ x = x ⋅ 1 = x\)&lt;/span&gt; holds for the multiplication operator, for
&lt;span&gt;\(\circ\)&lt;/span&gt; holds &lt;span&gt;\(u \circ f = f \circ u = f\)&lt;/span&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These two properties allow us to say that transition functions of a
finite automaton form a &lt;em&gt;monoid&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;More precisely, it is said that the set &lt;span&gt;\(M\)&lt;/span&gt;, the operation
&lt;span&gt;\(⊗\)&lt;/span&gt; and the element &lt;span&gt;\(u ∈ M\)&lt;/span&gt; (called the “unit” of this
operation) form a monoid if the aforementioned two properties hold.&lt;/p&gt;
&lt;p&gt;Since the notion of a monoid is so simple and general, it is
unsurprising that upon a close look at the “casual” objects in
programming one may see dozens of monoids. Some of them are listed in
the table below. Some applications of monoids to programming
are also listed in Dan Piponi’s article &lt;a href="http://blog.sigfpe.com/2009/01/haskell-monoids-and-their-uses.html"&gt;Monoids and their uses&lt;/a&gt;.&lt;/p&gt;
&lt;table&gt;
&lt;caption&gt;Monoids&lt;/caption&gt;
&lt;colgroup&gt;
&lt;col width="20%"&gt;
&lt;col width="20%"&gt;
&lt;col width="20%"&gt;
&lt;col width="40%"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;The set &lt;span&gt;\(M\)&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;Operation ⊗&lt;/th&gt;
&lt;th&gt;Unit &lt;span&gt;\(u\)&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;Comment&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;Numbers&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;Natural, integer, real, complex, quaternions…&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Numbers&lt;/td&gt;
&lt;td&gt;×&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Integers&lt;/td&gt;
&lt;td&gt;LCM&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Polynomials&lt;/td&gt;
&lt;td&gt;LCM&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Numbers, strings…&lt;/td&gt;
&lt;td&gt;MIN, MAX&lt;/td&gt;
&lt;td&gt;Maximal and minimal element&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Booleans&lt;/td&gt;
&lt;td&gt;AND&lt;/td&gt;
&lt;td&gt;TRUE&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Booleans&lt;/td&gt;
&lt;td&gt;OR&lt;/td&gt;
&lt;td&gt;FALSE&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Matrices&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;Over numbers (+, ×), over numbers (+, MIN), over booleans (OR, AND), …&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Sets&lt;/td&gt;
&lt;td&gt;Union&lt;/td&gt;
&lt;td&gt;Empty set&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Sets&lt;/td&gt;
&lt;td&gt;Intersection&lt;/td&gt;
&lt;td&gt;Complete set&lt;/td&gt;
&lt;td&gt;Restricted to subsets of the “complete” set&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Lists, strings…&lt;/td&gt;
&lt;td&gt;Concatenation&lt;/td&gt;
&lt;td&gt;Empty sequence&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Dictionaries&lt;/td&gt;
&lt;td&gt;Union&lt;/td&gt;
&lt;td&gt;Empty dictionary&lt;/td&gt;
&lt;td&gt;“Conflicts” are resolved in another monoid: &lt;span&gt;\((dic_1 ⊗ dic_2)[key] = dic_1[key] ⊕ dic_2[key]\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Functions of type A → B&lt;/td&gt;
&lt;td&gt;&lt;span&gt;\((f ⊗ g)(a)=f(a) ⊕ g(a)\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;\(e(a) = e_B\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;\((B,⊕,e_B)\)&lt;/span&gt; is a monoid&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Permutations&lt;/td&gt;
&lt;td&gt;Multiplication&lt;/td&gt;
&lt;td&gt;Identity permutation&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Functions&lt;/td&gt;
&lt;td&gt;Composition&lt;/td&gt;
&lt;td&gt;Identity function&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Tuples &lt;span&gt;\((x,y)\)&lt;/span&gt; where &lt;span&gt;\(x ∈ X, y ∈ Y\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;\((x_1, y_1) ⊗ (x_2, y_2) = (x_1 ⊕_X x_2, y_1 ⊕_Y y_2)\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;\((u_X, u_Y)\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;If &lt;span&gt;\((X, ⊕_X, u_X)\)&lt;/span&gt; and &lt;span&gt;\((Y, ⊕_Y, u_Y)\)&lt;/span&gt; form monoids&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;…&lt;/td&gt;
&lt;td&gt;…&lt;/td&gt;
&lt;td&gt;…&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table id="f1"&gt;
&lt;colgroup&gt;&lt;col&gt;&lt;col&gt;&lt;/colgroup&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;a href="#id1"&gt;[1]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Dan Piponi is a specialist on computer graphics, having participated
in the creation of all three “Matrices”, “Star Trek” and some other movies.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table id="f2"&gt;
&lt;colgroup&gt;&lt;col&gt;&lt;col&gt;&lt;/colgroup&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;a href="#id2"&gt;[2]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;There exist several algorithms for determinization, described,
for example, in the article “An &lt;span&gt;\(O(n log n)\)&lt;/span&gt; algorithm for
minimizing the states in a finite automaton” by Hopcroft or see the
Brzozowski’s algorithm.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table id="f3"&gt;
&lt;colgroup&gt;&lt;col&gt;&lt;col&gt;&lt;/colgroup&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;a href="#id3"&gt;[3]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;For example, any deterministic automaton for an expression of the form
&lt;tt&gt;&lt;span&gt;(0|(01*)(01*)(01*)…&lt;/span&gt; &lt;span&gt;0)*&lt;/span&gt;&lt;/tt&gt; will have size &lt;span&gt;\(O(2^n)\)&lt;/span&gt;, where
&lt;span&gt;\(n\)&lt;/span&gt; is the number of repetitions of &lt;tt&gt;&lt;span&gt;(01*)&lt;/span&gt;&lt;/tt&gt;.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table id="f4"&gt;
&lt;colgroup&gt;&lt;col&gt;&lt;col&gt;&lt;/colgroup&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;a href="#id4"&gt;[4]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;This idea has been taken from the article &lt;a href="http://swtch.com/~rsc/regexp/regexp3.html"&gt;Regular Expression
Matching in the Wild&lt;/a&gt; by Russ Cox
and is used in his &lt;tt&gt;&lt;span&gt;re2&lt;/span&gt;&lt;/tt&gt; engine.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table id="f5"&gt;
&lt;colgroup&gt;&lt;col&gt;&lt;col&gt;&lt;/colgroup&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;a href="#id5"&gt;[5]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;There’s a similar situation in graphics programming: coordinate
transformations are also represented not with arbitrary functions but
with matrices of numbers that can be efficiently multiplied
(composed).&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table id="f6"&gt;
&lt;colgroup&gt;&lt;col&gt;&lt;col&gt;&lt;/colgroup&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;a href="#id6"&gt;[6]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Actually we don’t need deterministic automata in the final program;
they were only used during testing and encouraged creating the automaton
abstraction, of which these two are particular cases.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table id="f7"&gt;
&lt;colgroup&gt;&lt;col&gt;&lt;col&gt;&lt;/colgroup&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;a href="#id7"&gt;[7]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Curiously, composition of such transformations is then also
captured by multiplication of such boolean matrices.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table id="f8"&gt;
&lt;colgroup&gt;&lt;col&gt;&lt;col&gt;&lt;/colgroup&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;a href="#id9"&gt;[8]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;In the early stages of development there was a
problem where computing the transition function for a chunk of
&lt;span&gt;\(N\)&lt;/span&gt; characters would require &lt;span&gt;\(N\)&lt;/span&gt; intermediate matrices,
but this problem was easily solved with a small API change without
sacrificing its purity.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table id="f9"&gt;
&lt;colgroup&gt;&lt;col&gt;&lt;col&gt;&lt;/colgroup&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;a href="#id10"&gt;[9]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;A similar datastructure is used for a similar purpose in the
“&lt;tt&gt;&lt;span&gt;Data.Sequence&lt;/span&gt;&lt;/tt&gt;” module in the Haskell standard library.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table id="f10"&gt;
&lt;colgroup&gt;&lt;col&gt;&lt;col&gt;&lt;/colgroup&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;a href="#id11"&gt;[10]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;It is instructive to look, for comparison, at some implementation
of rebalancing in mutable red-black trees.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table id="f11"&gt;
&lt;colgroup&gt;&lt;col&gt;&lt;col&gt;&lt;/colgroup&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;a href="#id12"&gt;[11]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;However, it’s not a secret to anyone that Real
Programmers don’t use debuggers: unfortunately, they won’t be able to
appreciate this particular advantage.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;a href="http://jkff.info/articles/ire/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Wed, 22 Apr 2020 19:37:29 UT
      </pubDate>
      <guid>
        http://jkff.info/articles/ire/
      </guid>
    </item>
    <item>
      <title>
         On the shoulders of the giants | A learning journal 
      </title>
      <link>
        https://www.lpalmieri.com/posts/2020-03-08-on-the-shoulders-of-the-giants/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;section&gt;
  &lt;article&gt;
    
      
      
&lt;ul id="frontmatter"&gt;
    &lt;li&gt;
        &lt;time datetime="2020-03-08T01:05:57.74Z"&gt;March 08, 2020&lt;/time&gt;
    &lt;/li&gt;
    &lt;span&gt;&lt;/span&gt;
    &lt;li&gt; 2062 words &lt;/li&gt;
    &lt;span&gt;&lt;/span&gt;
    &lt;li&gt; 11 min &lt;/li&gt;
&lt;/ul&gt;

      &lt;p&gt;&lt;img alt="books" src="https://media.giphy.com/media/VcizxCUIgaKpa/giphy.gif"&gt;&lt;/p&gt;
&lt;p&gt;My journey in the world of software has been quite brief.&lt;/p&gt;
&lt;p&gt;I joined the industry roughly three years ago, as a not-yet-graduated mathematician converted to ML practioner.   It took me another two years to find myself in a position where building software was my main occupation.&lt;/p&gt;
&lt;p&gt;I owe loads to many awesome individuals I have met and worked with along this short walk of life.&lt;br&gt;
I owe loads as well to many others who I will probably never meet - the authors of the books I fed upon along the way.&lt;/p&gt;
&lt;p&gt;First-hand experience is extremely powerful, nonetheless time is finite.&lt;br&gt;
Books gave me a chance to tap into the compressed mastery of other practiotioners, a mastery built over thousands and thousands of hours of work. If you could only absorb 10% of that knowledge by reading it would still be a bargain.&lt;/p&gt;
&lt;p&gt;As I find myself moving from the mentee to the mentor seat in some of my professional relationships, I do happen to share more and more often lists of titles that I found useful on my own journey. &lt;/p&gt;
&lt;p&gt;Publishing this list as a public blog post will likely increase its reach and prove useful to many others.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Themes&lt;/strong&gt;&lt;/em&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://lpalmieri.com/posts/2020-03-08-on-the-shoulders-of-the-giants/#architecture"&gt;Architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://lpalmieri.com/posts/2020-03-08-on-the-shoulders-of-the-giants/#design"&gt;Design&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://lpalmieri.com/posts/2020-03-08-on-the-shoulders-of-the-giants/#testing"&gt;Testing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://lpalmieri.com/posts/2020-03-08-on-the-shoulders-of-the-giants/#epic"&gt;Epic&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://lpalmieri.com/posts/2020-03-08-on-the-shoulders-of-the-giants/#software-development-lifecycle"&gt;Software development lifecycle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://lpalmieri.com/posts/2020-03-08-on-the-shoulders-of-the-giants/#management-frameworks"&gt;Management frameworks&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="architecture"&gt;Architecture&lt;/h2&gt;
&lt;p&gt;&lt;img title="Designing Data-Intensive Applications" alt="Designing Data-Intensive Applications" src="https://www.lpalmieri.com/image/uploads/ddia.png"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.amazon.co.uk/Designing-Data-Intensive-Applications-Reliable-Maintainable/dp/1449373321"&gt;Designing Data-Intensive Applications: The Big Ideas Behind Reliable, Scalable, and Maintainable Systems&lt;/a&gt; &lt;em&gt;by Martin Kleppmann&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This book is &lt;strong&gt;dense&lt;/strong&gt;.&lt;br&gt;
It's packed with foundational material and it manages to combine a first-principles approach with a focus on the impact of those decisions on the engineering choices behind real-world large-scale distributed systems.&lt;br&gt;
I do go back to it from time to time, to re-read a chapter, re-study a set of concepts.&lt;br&gt;
I just love it.&lt;/p&gt;
&lt;p&gt;&lt;img title="Cloud Native Patterns" alt="Cloud Native Patterns" src="https://www.lpalmieri.com/image/uploads/davis-cnp-hi.png"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.amazon.com/Cloud-Native-Designing-change-tolerant-software/dp/1617294292"&gt;Cloud Native Patterns: Designing change-tolerant software&lt;/a&gt; &lt;em&gt;by Cornelia Davis&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I never believed the &lt;em&gt;&lt;a href="https://en.wikipedia.org/wiki/Digital_native"&gt;digital native&lt;/a&gt;&lt;/em&gt; narrative, but it's indeed true that as a software engineer I am Cloud native. All the systems I have been working with have always been designed, hosted and operated in the Cloud since day 0.&lt;br&gt;
Cornelia Davis did a very good job at putting together a primer on the patterns and techniques that you should have in your toolbox when designing increasingly-complex Cloud native applications.&lt;br&gt;
I recommend it often as a first read on real-world distributed systems.&lt;/p&gt;
&lt;h2 id="design"&gt;Design&lt;/h2&gt;
&lt;p&gt;&lt;img title="DDD" alt="DDD" src="https://www.lpalmieri.com/image/uploads/ddd.jpeg"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.amazon.co.uk/Domain-Driven-Design-Tackling-Complexity-Software/dp/0321125215"&gt;Domain-Driven Design: Tackling Complexity in the Heart of Software&lt;/a&gt; &lt;em&gt;by Eric Evans&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;The&lt;/strong&gt; book on DDD, also known as &lt;em&gt;The &lt;strong&gt;Big&lt;/strong&gt; Blue Book&lt;/em&gt;.&lt;br&gt;
It's long but it covers an insane amount of material: if you are in the business of &lt;a href="https://docs.google.com/presentation/d/1r5CsiHwqABOTsrN5Dlbf4gCyhcL46NTv7qv9m5mBv-o/edit?usp=sharing"&gt;writing enterprise software&lt;/a&gt;, it's a must-read.&lt;br&gt;
Translating the rules and the mental model of a complex business domain into sofware is indeed the core of the challenge when writing enterprise software.&lt;br&gt;
The techniques and the terminology introduced by Evans will pay dividends as the complexity of the domain you are tackling and the organisation you are working in increases. Different people have suggested me a shorter introduction to the subject, &lt;a href="https://www.amazon.co.uk/Domain-Driven-Design-Distilled-Vaughn-Vernon/dp/0134434420"&gt;Domain-Driven Design Distilled&lt;/a&gt; by Vaughn Vernon, but I haven't read it first hand.&lt;/p&gt;
&lt;p&gt;&lt;img title="Domain modelling made functional" alt="Domain modelling made functional" src="https://www.lpalmieri.com/image/uploads/dmmf.jpg"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.amazon.co.uk/Domain-Modeling-Made-Functional-Domain-Driven/dp/1680502549"&gt;Domain Modeling Made Functional&lt;/a&gt; &lt;em&gt;by Scott Wlaschin&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I discovered this book looking up the author from &lt;a href="https://www.youtube.com/watch?v=PLFl95c-IiU"&gt;a talk of his&lt;/a&gt; - I loved the talk and I loved the book.&lt;br&gt;
It's on its own a good introduction to DDD as well as to the broader topic of &lt;em&gt;type-driven development&lt;/em&gt;. &lt;/p&gt;
&lt;p&gt;In a nutshell, we can leverage the type system to represent the constraints of our domain, making incorrect state difficult or impossible to represent.&lt;/p&gt;
&lt;p&gt;The book presents the idea in the context of functional programming, but it's indeed viable even with non-strictly-functional programming languages as long as they have a rich typesystem (e.g. Rust).&lt;br&gt;
If you find the idea interesting, the &lt;a href="https://fsharpforfunandprofit.com/"&gt;author's website&lt;/a&gt; is a gold mine.&lt;br&gt;
If you want a blog-sized introduction to the topic, check &lt;em&gt;&lt;a href="https://lexi-lambda.github.io/blog/2019/11/05/parse-don-t-validate/"&gt;Parse, don't validate&lt;/a&gt;&lt;/em&gt; by Alexis King.&lt;/p&gt;
&lt;h2 id="testing"&gt;Testing&lt;/h2&gt;
&lt;p&gt;&lt;img title="TDD by example" alt="TDD by example" src="https://www.lpalmieri.com/image/uploads/tdd-by-example.jpg"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.amazon.co.uk/Test-Driven-Development-Addison-Wesley-Signature/dp/0321146530"&gt;Test Driven Development: by Example&lt;/a&gt; &lt;em&gt;by Kent Beck&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There is a general appreciation in our industry around Test Driven Development. Nonetheless, I haven't met many practioners who actually run it by the book, for all sorts of reasons.&lt;br&gt;
Before taking a stance on the matter I wanted to see it done &lt;em&gt;religiously&lt;/em&gt;. Short on neighbours, I turned to the author himself: Kent Beck is the creator of XP (&lt;a href="https://en.wikipedia.org/wiki/Extreme_programming"&gt;&lt;strong&gt;X&lt;/strong&gt;treme &lt;strong&gt;P&lt;/strong&gt;rogramming&lt;/a&gt;), one the main voices of TDD as well as one of the authours of the &lt;a href="https://agilemanifesto.org/"&gt;Agile manifesto&lt;/a&gt;.&lt;br&gt;
The book is nothing more nothing less than a long pair programming session with him, as he works his way using TDD through a problem (i.e. writing a testing framework - there is a meta element at play here).&lt;br&gt;
You are an observer - as a reader you don't get to play &lt;a href="https://wiki.c2.com/?PairProgrammingPingPongPattern"&gt;ping-pong&lt;/a&gt; with him; yet, it's worth reading to actually &lt;em&gt;see&lt;/em&gt; what TDD looks and feels like.&lt;/p&gt;
&lt;p&gt;&lt;img title="Working effectively with legacy code" alt="Working effectively with legacy code" src="https://www.lpalmieri.com/image/uploads/working-with-legacy-code.jpg"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.amazon.co.uk/Working-Effectively-Legacy-Michael-Feathers/dp/0131177052"&gt;Working Effectively with Legacy Code&lt;/a&gt; &lt;em&gt;by Michael Feathers&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I have come to appreciate that software is more often read than written.  As it often goes, the author has generally moved on (either in another area of the business or somewhere else entirely). Yet the system keeps running in production, hopefully producing value, and it needs to be maintained.&lt;/p&gt;
&lt;p&gt;As it happens, not all of its behaviour is covered by automated tests - it's &lt;em&gt;legacy&lt;/em&gt; code. And most engineers will spend most of their careers working on such code (that includes code they wrote themselves six or twelve months earlier). I spent a fair share of my short software career doing so already.&lt;/p&gt;
&lt;p&gt;Feathers put together a series of useful techniques to tame the beast - documenting existing behaviour using tests in order to make it possible to evolve the system itself to satisfy new requirements.&lt;br&gt;
Extremely useful as a reference when working on gnarly legacy beasts.&lt;/p&gt;
&lt;p&gt;&lt;img title="xUnit Test Patterns" alt="xUnit Test Patterns" src="https://www.lpalmieri.com/image/uploads/xunit-test-patterns.jpg"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.amazon.co.uk/xUnit-Test-Patterns-Refactoring-Signature/dp/0131495054"&gt;xUnit Test Patterns: Refactoring Test Code&lt;/a&gt; &lt;em&gt;by Gerard Meszaros&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As you approach a new project armed with the two books above, you will try to stick to a disciplined testing approach.&lt;br&gt;
I sure did when given the chance to start a greenfield service.&lt;br&gt;
After a while, our test coverage started to decrease: new code was less thoroughly tested than the code we wrote at the very beginning of the project. Did we do it on purpose?&lt;br&gt;
No - if you asked, the whole team would have probably re-stated their faith in the importance of testing. Nonetheless, it was happening.&lt;br&gt;
The truth was that our tests had started to slow us a down - it was getting cumbersome to write and maintain them as the codebase evolved. As a result, we were writing less and less tests, without acknowledging it.&lt;br&gt;
If we kept at it without changing direction, we would have probably joined the faction of those who see tests as a hindrance more than an asset. Instead, I found this book and a significant refactor of our test suite brought us back to our previous development speed without compromising on our testing practices.&lt;/p&gt;
&lt;p&gt;The book is a bit dated, but it's a useful reference for a bunch of important techniques to keep the development tax of your comprehensive test suite under control. It was indeed instrumental for ours.&lt;br&gt;
I don't suggest to read it cover to cover - it's quite repetitive and way too long.&lt;/p&gt;
&lt;h2 id="epic"&gt;Epic&lt;/h2&gt;
&lt;p&gt;&lt;img title="The Soul of a New Machine" alt="The Soul of a New Machine" src="https://www.lpalmieri.com/image/uploads/soul.png"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.amazon.co.uk/Soul-New-Machine-Tracy-Kidder/dp/0316491977"&gt;The Soul of A New Machine&lt;/a&gt; &lt;em&gt;by Tracy Kidder&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A novel - what is it doing here?&lt;br&gt;
Well, it takes quite the effort to digest the material I linked so far. Why bother? What is it that makes it worthwhile to go through all these hurdles? &lt;em&gt;(Tech money aside, perfectly legit motivation)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;The Soul of A New Machine&lt;/em&gt; resonates.&lt;br&gt;
With the part of me that loved reading about Wiles' proof of the &lt;a href="https://en.wikipedia.org/wiki/Fermat%27s_Last_Theorem_(book)"&gt;Fermat's Last Theorem&lt;/a&gt;.&lt;br&gt;
With that part of me that is fascinated by people losing themselves in the quest to solve problems that are bigger than them, almost all-consuming.&lt;/p&gt;
&lt;p&gt;On that note, I can't avoid recommending &lt;a href="http://dtrace.org/blogs/bmc/2019/02/10/reflecting-on-the-soul-of-a-new-machine/"&gt;Bryan Cantrill's review&lt;/a&gt; of the &lt;em&gt;The Soul of A New Machine&lt;/em&gt; with almost the same fervor of my recommendation for the book itself.&lt;/p&gt;
&lt;h2 id="software-development-lifecycle"&gt;Software development lifecycle&lt;/h2&gt;
&lt;p&gt;&lt;img title="CD" alt="CD" src="https://www.lpalmieri.com/image/uploads/cd.jpg"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.amazon.co.uk/Continuous-Delivery-Deployment-Automation-Addison-Wesley/dp/0321601912"&gt;Continuous Delivery: Reliable Software Releases through Build, Test, and Deployment Automation&lt;/a&gt; &lt;em&gt;by Jez Humble and David Farley&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A deep-dive into the world of &lt;strong&gt;CD&lt;/strong&gt;, &lt;strong&gt;C&lt;/strong&gt;ontinuous &lt;strong&gt;D&lt;/strong&gt;elivery.&lt;br&gt;
The book is 10 years old, but it has withstood the test of time: technologies might have changed, but the principles and the challenges highlighted here are still relevant when designing (and automating) the release pipelines of contemporary systems.&lt;/p&gt;
&lt;p&gt;&lt;img title="Accelerate" alt="Accelerate" src="https://www.lpalmieri.com/image/uploads/accelerate.jpg"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.amazon.co.uk/Accelerate-Software-Performing-Technology-Organizations/dp/1942788339"&gt;Accelerate: The Science of Lean Software and Devops&lt;/a&gt; &lt;em&gt;by Nicole Fosgren, Jez Humble and Gene Kim&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Why should you go through all the trouble of implementing what the previous book details?&lt;br&gt;
&lt;em&gt;Accelerate&lt;/em&gt; doesn't necessarily introduce a set of revolutionary metholodogies in software delivery, but it provides solid datapoints and robust research &lt;strong&gt;proving&lt;/strong&gt; that some of those methodologies (Lean, DevOps, etc.) have indeed a &lt;strong&gt;measurable impact&lt;/strong&gt; on the &lt;strong&gt;business&lt;/strong&gt; performance of an organisation.&lt;br&gt;
The &lt;a href="https://www.thoughtworks.com/radar/techniques/four-key-metrics"&gt;four key metrics&lt;/a&gt; are extremely useful to measure the health of an engineering team.&lt;/p&gt;
&lt;p&gt;The yearly &lt;em&gt;&lt;a href="https://www.devops-research.com/research.html"&gt;State of DevOps&lt;/a&gt;&lt;/em&gt; report complements &lt;em&gt;Accelerate&lt;/em&gt; and provides updates on the state of the industry.&lt;/p&gt;
&lt;h2 id="management-frameworks"&gt;Management frameworks&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.amazon.co.uk/Turn-Ship-Around-Building-Breaking/dp/0241250943"&gt;Turn The Ship Around!&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.amazon.co.uk/Manager%60s-Path-Camille-Fournier/dp/1491973897"&gt;The Manager's Path&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.amazon.co.uk/Elegant-Puzzle-Systems-Engineering-Management-ebook/dp/B07QYCHJ7V"&gt;An Elegant Puzzle: Systems of Engineering Management&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There is more to software than code.&lt;br&gt;
Code is often the easy bit - people are the tough nut to crack.&lt;/p&gt;
&lt;p&gt;Core skills and leadership are often neglected when describing the minimal toolset needed by a software engineer to be effective.&lt;br&gt;
While competency is key, it's being capable to work with others that makes it or breaks it.&lt;br&gt;
The jury is out on the existence of 10x engineers, but I am sure of the existence of 10x (and 0.1x!) teams.&lt;/p&gt;
&lt;p&gt;It goes beyond the individuals - it's a mix of practices, processes, vision, values.&lt;br&gt;
You can freestyle it as a team of 5 or 6, but it will soon spiral out of control when the organisation grows.&lt;/p&gt;
&lt;p&gt;These three books are the one I found the most interesting among the many I touched in the "management" section - they are principled, clear-written and insightful. They deserve a spot in an engineering curriculum as much as the fundamentals of testing and domain design.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Turn The Ship Around!&lt;/em&gt;, in particular, is a written account of the wonders of decentralised decision-making and high mutual-trust in an environment used to a strict &lt;em&gt;Command/Control&lt;/em&gt; management-style (the US Navy!).&lt;/p&gt;
&lt;p&gt;Empowering every single individual to channel their best version of themselves should be the goal of every (engineering) organisation.&lt;/p&gt;

      
  &lt;/article&gt;
&lt;/section&gt;&lt;/div&gt;&lt;a href="https://www.lpalmieri.com/posts/2020-03-08-on-the-shoulders-of-the-giants/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Thu, 23 Apr 2020 10:11:58 UT
      </pubDate>
      <guid>
        https://www.lpalmieri.com/posts/2020-03-08-on-the-shoulders-of-the-giants/
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://www.deeplearningbook.org/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;p&gt;The deep learning textbook can now be ordered on
&lt;a href="https://www.amazon.com/Deep-Learning-Adaptive-Computation-Machine/dp/0262035618/ref=sr_1_1?ie=UTF8&amp;amp;qid=1472485235&amp;amp;sr=8-1&amp;amp;keywords=deep+learning+book"&gt;Amazon&lt;/a&gt;.

&lt;/p&gt;&lt;p&gt;For up to date announcements, join our
&lt;a href="https://groups.google.com/forum/#!forum/deeplearningbook"&gt;mailing list&lt;/a&gt;.
&lt;/p&gt;
   &lt;h2&gt;Citing the book&lt;/h2&gt;
   To cite this book, please use this bibtex entry:
&lt;tt&gt;
&lt;pre&gt;@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}
&lt;/pre&gt;
&lt;/tt&gt;

&lt;p&gt;
To write your own document using our LaTeX style, math notation, or
to copy our notation page, download our
&lt;a href="https://github.com/goodfeli/dlbook_notation"&gt;template&lt;/a&gt; files.
&lt;/p&gt;

&lt;p&gt;
&lt;a href="https://docs.google.com/document/d/1ABlp7FluwZ0B82_fjNOFVQ2uOZkfuF8elbofhZmNXag/edit?usp=sharing"&gt;Errata in published editions&lt;/a&gt;
&lt;/p&gt;

&lt;h2&gt;Deep Learning&lt;/h2&gt;
    &lt;ul&gt;
       &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/TOC.html"&gt;Table of Contents&lt;/a&gt;&lt;/li&gt;
       &lt;li&gt;&lt;a href="https://www.deeplearningbook.org/contents/acknowledgements.html"&gt;Acknowledgements&lt;/a&gt;&lt;/li&gt;
       &lt;li&gt;&lt;a href="https://www.deeplearningbook.org/contents/notation.html"&gt;Notation&lt;/a&gt;&lt;/li&gt;
       &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/intro.html"&gt;1 Introduction&lt;/a&gt;&lt;/li&gt;
       &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/part_basics.html"&gt;Part I: Applied Math and Machine Learning Basics&lt;/a&gt;&lt;/li&gt;
        &lt;ul&gt;
        &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/linear_algebra.html"&gt;2 Linear Algebra&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/prob.html"&gt;3 Probability and Information Theory&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/numerical.html"&gt;4 Numerical Computation&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/ml.html"&gt;5 Machine Learning Basics&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
       &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/part_practical.html"&gt;Part II: Modern Practical Deep Networks&lt;/a&gt;&lt;/li&gt;
        &lt;ul&gt;
        &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/mlp.html"&gt;6 Deep Feedforward Networks&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/regularization.html"&gt;7 Regularization for Deep Learning&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/optimization.html"&gt;8 Optimization for Training Deep Models&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/convnets.html"&gt;9 Convolutional Networks&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/rnn.html"&gt;10 Sequence Modeling: Recurrent and Recursive Nets&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/guidelines.html"&gt;11 Practical Methodology&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/applications.html"&gt;12 Applications&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
       &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/part_research.html"&gt;Part III: Deep Learning Research&lt;/a&gt;&lt;/li&gt;
        &lt;ul&gt;
        &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/linear_factors.html"&gt;13 Linear Factor Models&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/autoencoders.html"&gt;14 Autoencoders&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/representation.html"&gt;15 Representation Learning&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/graphical_models.html"&gt;16 Structured Probabilistic Models for Deep Learning&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/monte_carlo.html"&gt;17 Monte Carlo Methods&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/partition.html"&gt;18 Confronting the Partition Function&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/inference.html"&gt;19 Approximate Inference&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/generative_models.html"&gt;20 Deep Generative Models&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/ul&gt;
     &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/bib.html"&gt;Bibliography&lt;/a&gt;&lt;/li&gt;
     &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/index-.html"&gt;Index&lt;/a&gt;&lt;/li&gt;
    
    


&lt;h2&gt;FAQ&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Can I get a PDF of this book?
&lt;p&gt;No, our contract with MIT Press forbids distribution of too easily copied
electronic formats of the book.
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;Why are you using HTML format for the web version of the book?
&lt;p&gt;This format is a sort of weak DRM required by our contract with MIT Press.
It's intended to discourage unauthorized copying/editing
of the book. 
&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;What is the best way to print the HTML format?
&lt;p&gt;Printing seems to work best printing directly from the browser, using Chrome.
Other browsers do not work as well.
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;Can I translate the book into Chinese?&lt;/li&gt;
&lt;p&gt;Posts and Telecom Press has purchased the rights.
&lt;/p&gt;
&lt;/ul&gt;

&lt;p&gt;
If you notice any typos (besides the known issues listed below) or have suggestions for exercises to add to the
website, do not hesitate to contact the authors directly by e-mail
at: feedback@deeplearningbook.org 
&lt;/p&gt;
&lt;p&gt;
Since the book is complete and in print, we do not make large changes,
only small corrections.
&lt;/p&gt;
&lt;p&gt;Known issues: In outdated versions of the Edge
browser, the "does not equal" sign sometimes appears as the "equals" sign.
This may be resolved by updating to the latest version.
&lt;/p&gt;
  


&lt;/div&gt;&lt;a href="https://www.deeplearningbook.org/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sun, 26 Apr 2020 13:41:14 UT
      </pubDate>
      <guid>
        https://www.deeplearningbook.org/
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://www.drmaciver.com/2009/01/writing-things-right/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;object StringUtils{
   implicit def string2RTrim(s : String) = new { def rtrim = ...; }   
}

Ruby:

class String
  def rtrim
  ...
  end
end

C#:

class StringUtils{
   public static String rtrim(this String s) {
    &amp;nbsp;...
   }
}
&lt;p&gt;What do these achieve over the previous version? Simple: You can write myString.rtrim instead of rtrim(myString). That’s it. (Actually the Ruby and Scala versions both *can* allow you to do different things than that. It’s just that here and in 90% of the use cases they aren’t used for anything else. The C# version literally doesn’t do anything else).&lt;/p&gt;
&lt;p&gt;The thing is, while I’m making fun of this to a certain degree, it’s actually a perfectly reasonable thing to want to do. Designing things in noun-verb order is a good principle of UI design, and it works for programming as well. Things chain better – when you want to add new functions to a pipeline you add them at the point your cursor is naturally at and it matches well with thinking of it as a pipeline of “take this thing, do this to it, do that to it, do this other thing to it, get this value out”. Also you write far fewer brackets. :-) (compare Haskell’s foo . bar . baz $ thing idiom for a similar bracket avoidance tool).&lt;/p&gt;
&lt;p&gt;Of these, I’d say that the Ruby solution is the most obvious (it just uses the fact that classes are open to add a new method to String), but it comes with the possibility of amusingly non-obvious runtime errors when someone else defines a conflicting method. The C# solution seems the best to me – it’s relatively little overhead over writing the utility method as you would otherwise and comes with the option to invoke it either as myString.rtrim or StringUtils.rtrim(myString), so when namespacing conflicts inevitably occur you have an easy fallback. But of course it uses a language feature specifically added to do this, while the other two are functions of more general language features. The Scala solution is, to my mind, decidedly the worst of the three.It’s syntactically noisy and comes with a significant additional runtime overhead.&lt;/p&gt;
&lt;p&gt;But honestly I’m not particularly happy with any of these solutions. The Scala and Ruby solutions come with disproportionate costs to the benefit they give and the C# solution requires an additional language feature. Moreoever, each of these solutions requires effort at each definition site in order to make something available that you always want at the use site. Wouldn’t it be better if for every utility function you automatically had the option to write it on the right?&lt;/p&gt;
&lt;p&gt;Let’s take a digression. What language is the following (rather pointless) code written in?&lt;/p&gt;
&lt;pre&gt;[1, 2, 3].sort.length&lt;/pre&gt;
&lt;p&gt;Ruby, right?&lt;/p&gt;
&lt;p&gt;Actually, no. It’s Haskell.&lt;/p&gt;
&lt;p&gt;Wait, what?&lt;/p&gt;
&lt;p&gt;Well, it’s Haskell if you do something slightly evil and redefine the (.) operator (which normally means composition):&lt;/p&gt;
&lt;pre&gt;Prelude Data.List&amp;gt; let (.) x f = f x&lt;/pre&gt;
&lt;pre&gt;Prelude Data.List&amp;gt; [1, 2, 3].sort.length&lt;/pre&gt;
&lt;pre&gt;3&lt;/pre&gt;
&lt;p&gt;I saw this trick a while ago (the author was amusingly apologetic for it). It’s evil Haskell code because of the way it redefines an operator that normally means something else (this is totally typesafe of course – existing code will continue to use the old operator definition). But it’s a perfectly valid operator definition, and a rather nice one.&lt;/p&gt;
&lt;p&gt;It works well with additional arguments to functions too:&lt;/p&gt;
&lt;p&gt;Prelude Data.List&amp;gt; [1, 2, 3].sortBy(compare).length&lt;br&gt;
3&lt;/p&gt;
&lt;p&gt;The reason this works is that sortBy takes the list argument curried as its last argument, so sortBy(compare) gives something of type [Int] -&amp;gt; [Int] which we can then apply as above (Haskell’s precedence rules make this work).&lt;/p&gt;
&lt;p&gt;So this is a nice trick, but how is it useful to you? Well, it’s probably not. I can’t think of any low noise way of making it work in any of the other languages mentioned so far (the best I can come up with is an evil evil hack in Ruby that would make god go on a kitten killing spree and a mildly nasty hack with operators and implicit conversions in Scala that’s much too noisy to really use), and using it in Haskell will make other Haskell programmers very unhappy with you. But it’s an interesting trick, and I’ll be sure to bear it in mind if I ever get around to creating DRMacIverLang.&lt;/p&gt;




&lt;nav&gt;
&lt;h3&gt;Post navigation&lt;/h3&gt;
&lt;span&gt;&lt;a rel="prev" href="https://www.drmaciver.com/2009/01/planet-just-scala/"&gt;&lt;span&gt;←&lt;/span&gt; Planet Just Scala&lt;/a&gt;&lt;/span&gt;
&lt;span&gt;&lt;a rel="next" href="https://www.drmaciver.com/2009/01/computational-linguistics-and-me/"&gt;Computational linguistics and Me &lt;span&gt;→&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;
&lt;/nav&gt;













&lt;/div&gt;&lt;a href="https://www.drmaciver.com/2009/01/writing-things-right/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Mon, 27 Apr 2020 15:15:46 UT
      </pubDate>
      <guid>
        https://www.drmaciver.com/2009/01/writing-things-right/
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://www.drmaciver.com/2007/12/no-seriously-why-scala/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;section&gt;
&lt;p&gt;&amp;gt; Scala offers a bag of features under the keyword ‘implicit’. This is one of those things that makes you go “Oh, that’s cute” when you first see it and then go “Wow, that’s powerful” six months later.&lt;/p&gt;
&lt;p&gt;I agree, that’s exactly my feeling regarding implicits.&lt;/p&gt;
&lt;p&gt;However, implicits can also make code hard to understand or follow. Looking at some code, it’s sometimes hard to see that there are implicit methods being called that are defined somewhere else, or implicit arguments being passed that are not very obvious.&lt;/p&gt;
&lt;p&gt;But ok, every powerful tools comes with the risk of misuse.&lt;/p&gt;
&lt;/section&gt;&lt;/div&gt;&lt;a href="https://www.drmaciver.com/2007/12/no-seriously-why-scala/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Mon, 27 Apr 2020 15:15:48 UT
      </pubDate>
      <guid>
        https://www.drmaciver.com/2007/12/no-seriously-why-scala/
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://macwright.org/2020/05/10/spa-fatigue.html
      </link>
      <description>
        &lt;a href="https://macwright.org/2020/05/10/spa-fatigue.html"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Mon, 11 May 2020 16:06:42 UT
      </pubDate>
      <guid>
        https://macwright.org/2020/05/10/spa-fatigue.html
      </guid>
    </item>
    <item>
      <title>
        rust-blog/learning-rust-in-2020.md at master · pretzelhammer/rust-blog · GitHub
      </title>
      <link>
        https://github.com/pretzelhammer/rust-blog/blob/master/posts/learning-rust-in-2020.md
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div id="readme"&gt;
    &lt;article&gt;&lt;h2&gt;Learning Rust in 2020&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;May 9th, 2020 · 15 minute read · #rust&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#intro"&gt;Intro&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tldr"&gt;TL;DR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#practical-rust-resource-reviews"&gt;Practical Rust Resource Reviews&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#hackerrank"&gt;HackerRank&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#project-euler"&gt;Project Euler&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#leetcode"&gt;LeetCode&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#codewars"&gt;Codewars&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#advent-of-code"&gt;Advent of Code&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#rustlings"&gt;Rustlings&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#xxercism"&gt;Exercism&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#conclusion"&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#discuss"&gt;Discuss&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#notifications"&gt;Notifications&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#further-reading"&gt;Further Reading&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Intro&lt;/h2&gt;
&lt;p&gt;When I started learning Rust I made the mistake of following the advice to read &lt;a rel="nofollow" href="https://doc.rust-lang.org/book/title-page.html"&gt;The Book&lt;/a&gt; first. While it's a great resource, it's pretty overwhelming for a beginner to get told &lt;em&gt;"If you'd like to learn this programming language the best way to start is to read this 20 chapter book!"&lt;/em&gt; Most people give up before they even get started when they get advice like this. Nobody ever told someone to read a 20 chapter book just to get started with Javascript or Python. Rust's learning curve is no joke but you gotta give the people what they want, and they want to program, not read about programming. Programming is fun and reading about programming is not as fun.&lt;/p&gt;
&lt;p&gt;The first 10% of this article is gonna be me giving you advice on how to learn Rust in 2020 following a &lt;em&gt;practical hands-on coding&lt;/em&gt; approach. This is the good part of the article. You can safely exit after this part (I'll tell you when). The remaining 90% of this article is me ranting about how most online coding challenge sites have poor support for Rust.&lt;/p&gt;
&lt;h2&gt;TL;DR&lt;/h2&gt;
&lt;p&gt;If you're a total Rust newbie and want to learn as much as possible in just one day you should read fasterthanlime's excellent &lt;a rel="nofollow" href="https://fasterthanli.me/blog/2020/a-half-hour-to-learn-rust/"&gt;A half-hour to learn Rust&lt;/a&gt; and then checkout the awesome &lt;a href="https://github.com/rust-lang/rustlings"&gt;Rustlings&lt;/a&gt; repo and complete the exercises.&lt;/p&gt;
&lt;p&gt;If you're a Rust beginner you should get started on &lt;a rel="nofollow" href="https://exercism.io/tracks/rust"&gt;Exercism's Rust Track&lt;/a&gt;. If you get stuck you should ask your friends Google and StackOverflow for help. I recommend taking the time to get comfortable reading and navigating the &lt;a rel="nofollow" href="https://doc.rust-lang.org/std/"&gt;Rust Standard Library Docs&lt;/a&gt; which is amazing and has simple practical examples for how to use everything inside of it. &lt;a rel="nofollow" href="https://doc.rust-lang.org/rust-by-example/"&gt;Rust by Example&lt;/a&gt; is also a really good high-level reference that you can use to quickly learn Rust syntax and features. If you want to gain a deeper understanding of a certain Rust concept only then do I recommend finding the appropriate chapter in &lt;a rel="nofollow" href="https://doc.rust-lang.org/book/title-page.html"&gt;The Book&lt;/a&gt; to read. The best part of completing an exercise on Exercism is that you get access to all the solutions by other members which you can sort by most-starred to see particularly idiomatic or clever solutions. This is a great way to learn!&lt;/p&gt;
&lt;p&gt;At this point you're probably an advanced beginner and can find your own path. If you need more guidance and would like to continue working on small simple programs I recommend doing the exercises from the &lt;a rel="nofollow" href="https://adventofcode.com/2018"&gt;Advent of Code 2018 Calendar&lt;/a&gt;. The reason why I specifically recommended the 2018 calendar is because once you're finished with an exercise you can compare your solution to &lt;a href="https://github.com/BurntSushi/advent-of-code"&gt;BurntSushi's Advent of Code 2018 Rust solutions&lt;/a&gt;. BurntSushi writes really clean, readable, idiomatic Rust code. Reading the code of an experienced Rustacean will teach you as much as the exercises themselves.&lt;/p&gt;
&lt;p&gt;Exit now, the good part of the article is over.&lt;/p&gt;
&lt;h2&gt;Practical Rust Resource Reviews&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Alternative title: Reviews of Free Online Resources a Rust Beginner can use to Practice Writing Small Simple Rust Programs&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Most of these resources weren't specifically created for the purpose of teaching Rust, however they can all be used to learn and practice Rust and many of them explicitly support Rust submissions and provide Rust-specific versions of problems.&lt;/p&gt;
&lt;p&gt;The resources are ordered from worst to best.&lt;/p&gt;
&lt;h3&gt;&lt;a rel="nofollow" href="https://www.hackerrank.com/"&gt;HackerRank&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Rust is a supported language on HackerRank except you aren't allowed to submit Rust solutions to most of the problems on their site. I tried to upload my solution directly and they refused it:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/pretzelhammer/rust-blog/blob/master/assets/hackerrank-more-like-failrank.png" rel="noopener noreferrer"&gt;&lt;img alt="hackerrank more like failrank" src="https://github.com/pretzelhammer/rust-blog/raw/master/assets/hackerrank-more-like-failrank.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is really strange because I was able to browse Rust solutions for the problem above submitted by other HackerRank users, so it's possible to submit a Rust solution somehow. I tried Googling this issue but Google didn't return any useful results. There's no way for me to evaluate HackerRank other than to tell you not to waste your time with it like I did.&lt;/p&gt;
&lt;h3&gt;&lt;a rel="nofollow" href="https://projecteuler.net/archives"&gt;Project Euler&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;When I first started to learn programming back in 2012 I commonly heard &lt;em&gt;"If you wanna get up to speed quickly in a new programming language solve some Project Euler problems with it!"&lt;/em&gt; which was okay advice at the time since there were not many other alternatives but in my opinion Project Euler has very little to do with programming. Project Euler problems are more math problems than they are programming problems. Their challenge lies almost entirely in the mathematical reasoning required to reach the solution as the programming required is usually trivial. I would not recommend solving Project Euler problems as a way to learn Rust unless you're very mathematically inclined and have some nostalgia for the site.&lt;/p&gt;
&lt;h3&gt;&lt;a rel="nofollow" href="https://leetcode.com/problemset/all/"&gt;LeetCode&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Rust is a supported language on LeetCode. For every problem on LeetCode you get a solution template which usually contains a single unimplemented function which you then have to implement and submit in order to solve the problem. For more involved problems the solution template might include a &lt;code&gt;struct&lt;/code&gt; and an &lt;code&gt;impl&lt;/code&gt; block with several unimplemented methods. Unfortunately, these solution templates are not created by humans, they are automatically generated, which results in a lot of really awkward and unidiomatic Rust code. Examples:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;LeetCode generated Rust&lt;/th&gt;
&lt;th&gt;Idiomatic Rust&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;tree problems represent links as &lt;code&gt;Option&amp;lt;Rc&amp;lt;RefCell&amp;lt;Node&amp;gt;&amp;gt;&amp;gt;&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;Option&amp;lt;Rc&amp;lt;RefCell&amp;lt;Node&amp;gt;&amp;gt;&amp;gt;&lt;/code&gt; is overkill for tree links and &lt;code&gt;Option&amp;lt;Box&amp;lt;Node&amp;gt;&amp;gt;&lt;/code&gt; works just as well and is much easier to work with&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;methods which obviously mutate self still borrow it immutably, e.g. &lt;code&gt;fn insert(&amp;amp;self, val: i32)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;methods that mutate self need to borrow it mutably, e.g. &lt;code&gt;fn insert(&amp;amp;mut self, val: i32)&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;signed 32-bit integers are used for all numbers, even if the problem is undefined for negative integers, e.g. &lt;code&gt;fn nth_fib(n: i32) -&amp;gt; i32&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;problems which are undefined for negative integers should use unsigned integers, e.g. &lt;code&gt;fn nth_fib(n: u32) -&amp;gt; u32&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;functions always take ownership of their arguments, even if it's unnecessary, e.g. &lt;code&gt;fn sum(nums: Vec&amp;lt;i32&amp;gt;) -&amp;gt; i32&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;if you don't need ownership then borrow &lt;code&gt;fn sum(nums: &amp;amp;[i32]) -&amp;gt; i32&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;functions sometimes ignore basic error cases, e.g. for &lt;code&gt;fn get_max(nums: Vec&amp;lt;i32&amp;gt;) -&amp;gt; i32&lt;/code&gt; what &lt;code&gt;i32&lt;/code&gt; should be returned if &lt;code&gt;nums&lt;/code&gt; is empty?&lt;/td&gt;
&lt;td&gt;if a result might be undefined the return type should be wrapped in an &lt;code&gt;Option&lt;/code&gt;, e.g. &lt;code&gt;fn get_max(nums: &amp;amp;[i32]) -&amp;gt; Option&amp;lt;i32&amp;gt;&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Other LeetCode issues, specific to Rust:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LeetCode doesn't allow you to pull in 3rd-party dependencies in solutions. Normally I think this is okay for most languages but Rust in particular has a pretty slim standard library which doesn't even include regex support so a lot of the more complex string parsing problems on LeetCode are pointlessly difficult to solve in Rust but have otherwise trivial solutions in other languages which have regex support in their standard libraries.&lt;/li&gt;
&lt;li&gt;None of the problems in the &lt;code&gt;concurrency&lt;/code&gt; category accept solutions in Rust. What? Fearless concurrency is one of Rust's major selling points!&lt;/li&gt;
&lt;li&gt;After solving a problem you can go to the problem's comments section to see other user's solutions (as many users like to publish their solutions there) but because Rust isn't very popular on LeetCode sometimes you won't find any Rust solutions ;(&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;General LeetCode issues:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LeetCode has a surprising amount of very low quality problems. Problems can be liked and disliked by users but problems are never removed even if they hit very high dislike ratios. I've seen lots of problems with 100+ votes and 80%+ dislike ratios and I don't understand why they are kept on the site.&lt;/li&gt;
&lt;li&gt;Problem difficulty ratings are kinda off. Problems are rated as Easy, Medium, or Hard but there are many Easy problems with lower solve rates than many Hard problems.&lt;/li&gt;
&lt;li&gt;Not all problems accept solutions in all languages, and you can't filter problems by which languages they accept. None of the graph problems on LeetCode accept Rust solutions, for example.&lt;/li&gt;
&lt;li&gt;LeetCode blocks "premium" problems behind a steep monthly paywall but doesn't offer any kind of premium free-trial so there's no telling if the quality is actually any better than the free problems.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Things LeetCode does right:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Solutions to problems are tested against a suite of secret unit tests, but if you fail a particular test case they show you the failed case.&lt;/li&gt;
&lt;li&gt;All of the generated Rust code at least follows rustfmt conventions.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a rel="nofollow" href="https://www.codewars.com/join?language=rust"&gt;Codewars&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Codewars is a misleading name. There's no war going on at Codewars. There's no time limit to solve problems and your solutions aren't judged on their speed of execution or memory usage. You aren't in competition with anyone else. This isn't a bad thing, just worth pointing out.&lt;/p&gt;
&lt;p&gt;Rust is a supported language on Codewars. For every problem on Codewars you get a solution template which usually contains a single unimplemented function which you then have to implement and submit in order to solve the problem. These solution templates are created by humans, including humans who aren't familiar with Rust, so you occasionally get some awkward and unidiomatic Rust. Examples:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Codewars' Rust Problems&lt;/th&gt;
&lt;th&gt;Idiomatic Rust&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;sometimes don't follow rustfmt conventions, e.g. &lt;code&gt;fn makeUppercase(s:&amp;amp;str)-&amp;gt;String&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;always follows rustfmt conventions, e.g. &lt;code&gt;fn make_uppercase(s: &amp;amp;str) -&amp;gt; String&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;sometimes takes signed integer arguments for problems that aren't defined for negative integers, e.g. &lt;code&gt;fn nth_fib(n: i32) -&amp;gt; i32&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;if a problem isn't defined for negative integers use unsigned integer arguments, e.g. &lt;code&gt;fn nth_fib(n: u32) -&amp;gt; u32&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;sometimes a problem asks you to return &lt;code&gt;-1&lt;/code&gt; for the null case, e.g. &lt;code&gt;fn get_index(needle: i32, haystack: &amp;amp;[i32]) -&amp;gt; i32&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;if a result can be null the return type should be wrapped in an &lt;code&gt;Option&lt;/code&gt;, e.g. &lt;code&gt;fn get_index(needle: i32, haystack: &amp;amp;[i32]) -&amp;gt; Option&amp;lt;usize&amp;gt;&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;sometimes don't take advantage of deref coercion, e.g. &lt;code&gt;fn do_stuff(s: &amp;amp;String, list: &amp;amp;Vec&amp;lt;i32&amp;gt;)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;takes advantage of deref coercion, e.g. &lt;code&gt;fn do_stuff(s: &amp;amp;str, list: &amp;amp;[i32])&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;All of the issues above only happen sometimes since there are Rustaceans of various skill-levels on Codewars translating problems to Rust. This is a huge step up from LeetCode where all of the generated Rust problem code is consistently unidiomatic. However, the Rust community on Codewars as a whole might lean towards the inexperienced side since I've seen some highly upvoted "idiomatic" solutions that were also a bit on the awkward side. Examples:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Codewars' highest upvoted Rust solutions&lt;/th&gt;
&lt;th&gt;Idiomatic Rust&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;sometimes use an explicit return at the end of a function block, e.g. &lt;code&gt;return result;&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;blocks are evaluated as expressions and implicitly return their last item, an explicit return at the end of a function block is unnecessary, e.g. &lt;code&gt;result&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;often use compact formatting to make the solution look more concise&lt;/td&gt;
&lt;td&gt;should follow rustfmt conventions&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;sometimes make unnecessary allocations, e.g. &lt;code&gt;str_slice.to_string().chars()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;if you don't need to allocate then don't, e.g. &lt;code&gt;str_slice.chars()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;often try to solve the problem using nothing but iterators at the cost of everything else&lt;/td&gt;
&lt;td&gt;iterators are expressive and idiomatic, but if you have to chain 15 of them in a row and there are multiple levels of nested iterators in-between then perhaps you should consider refactoring to use some helper functions, intermediate variables, and maybe even a for-loop&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Again, the issues above only happen sometimes. An experienced Rustacean can spot them easily but there are a lot of Rust newbies on these sites who have no clue they are learning anti-patterns.&lt;/p&gt;
&lt;p&gt;Other Codewars issues, specific to Rust:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Rust doesn't seem that popular on Codewars, the site has 9000 exercises but only 300 of them have been translated to Rust ;(&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Other general Codewars issues:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Your solution is tested against a suite of secret unit tests, if you fail one of the secret unit tests you aren't shown the failed test case. This is especially annoying if the test case tests for an edge case that wasn't clearly communicated in the problem description.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Things Codewars does right:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;There's a small whitelist of 3rd-party dependencies you can use to help solve problems with Rust. This whitelist includes: rand, chrono, regex, serde, itertools, and lazy_static which helps round out Rust's standard library and puts it more on par with other languages.&lt;/li&gt;
&lt;li&gt;You can filter problems by language.&lt;/li&gt;
&lt;li&gt;Submitting a solution to a problem also automatically publishes the solution. You can view and upvote other members' solutions. You can sort solutions by most upvotes to see particularly concise and clever solutions, which sometimes will also be very idiomatic (but sometimes not, as explained above).&lt;/li&gt;
&lt;li&gt;Problem difficulty grading is pretty good! Instead of grading problems as Easy, Medium, or Hard like LeetCode, Codewars chooses to grade problems from easiest to hardest as: 8 kyu, 7 kyu, 6 kyu, 5 kyu, 4 kyu, 3 kyu, 2 kyu, 1 kyu. I completed 60 problems in the 8 kyu - 4 kyu range and every level felt a little more difficult than the last, which aligned with my expectations.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a rel="nofollow" href="https://adventofcode.com/"&gt;Advent of Code&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Advent of Code is totally language-agnostic. This would seem like a minus at first but seeing how horribly HackerRank, LeetCode, and Codewars handle their support for Rust on their sites it's actually a plus. Advent of Code also gets placed above the previously mentioned sites because AoC's exercises are really interesting, diverse, and high quality in my opinion.&lt;/p&gt;
&lt;p&gt;General AoC issues:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;After you finish an exercise there's no way to see other people's Rust solutions unless you search from them on Google, and even after you find some there's no telling how good or idiomatic they are.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To solve the above issue I recommend going through the 2018 Calendar problems and comparing your solutions to &lt;a href="https://github.com/BurntSushi/advent-of-code"&gt;BurntSushi's AoC 2018 Rust solutions&lt;/a&gt;. BurntSushi writes really clean, readable, idiomatic Rust code. If you want to go through the 2019 Calendar then I recommend comparing your solutions to &lt;a href="https://github.com/bcmyers/aoc2019"&gt;bcmyers' AoC 2019 Rust solutions&lt;/a&gt;. The reason I specifically suggest bcmyers' is because he made a &lt;a rel="nofollow" href="https://www.youtube.com/playlist?list=PLQXBtq4j4Ozkx3r4eoMstdkkOG98qpBfg"&gt;youtube playlist of him coding up the solutions&lt;/a&gt; and he does a great job of explaining his thought process and why he's doing what he's doing while he's coding.&lt;/p&gt;
&lt;p&gt;Things AoC got right:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;High quality, interesting, curated exercises that are tied together with a narrative.&lt;/li&gt;
&lt;li&gt;Language agnostic, so while it doesn't teach you any Rust patterns it at least doesn't teach you any Rust anti-patterns either.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a href="https://github.com/rust-lang/rustlings"&gt;Rustlings&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Rustlings is sooo good. All Rustlings exercises are hand-crafted for Rust with love and it's a wonderful breath of fresh air. Finally, a set of exercises that really teach you idiomatic Rust!&lt;/p&gt;
&lt;p&gt;If you're a total Rust newbie you should absolutely checkout &lt;a href="https://github.com/rust-lang/rustlings"&gt;Rustlings&lt;/a&gt; and get started on the exercises. I highly recommend reading fasterthanlime's &lt;a rel="nofollow" href="https://fasterthanli.me/blog/2020/a-half-hour-to-learn-rust/"&gt;A half-hour to learn Rust&lt;/a&gt; first as it'll get you up to speed on a lot of Rust syntax and concepts super quickly.&lt;/p&gt;
&lt;p&gt;I have only 1 tiny Rustlings criticism: there are some sudden difficulty spikes in the "error-handling" and "conversions" exercises that I could see some users getting overwhelmed by. I assume most probably make it through, or at least I hope.&lt;/p&gt;
&lt;p&gt;I also have 1 tiny non-criticism: it's too short. This is a non-criticism because it's one of Rustlings design goals to be a quick and gentle introduction to Rust but it's so good that of course I wish it was somehow longer.&lt;/p&gt;
&lt;h3&gt;&lt;a rel="nofollow" href="https://exercism.io/tracks/rust"&gt;Exercism&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Exercism has a Rust track, which is a collection of exercises roughly ordered by subject and difficulty. The Rust track shares a lot of exercises in common with other tracks, but all of the exercises were translated to Rust by experienced Rustaceans and don't suffer from any of the awkward unidiomatic Rust issues that are common on LeetCode and Codewars. There are about a dozen Rust-specific problems that require you to implement a standard library trait, or write a macro, or write a parallel solution using multiple threads, or write unsafe Rust code. These exercises are by far the highlights of the track and I wish there were more of them. Exercism is second only to Rustlings as a resource for learning Rust. The only reason I placed it above Rustlings is Rustlings can be completed in an evening and Exercism's Rust track will take at least a month to complete so it just has a lot more content.&lt;/p&gt;
&lt;p&gt;Exercism issues, specific to the Rust track:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;"Mentored mode" is useless, as most of the Rust mentors on the site are inactive, and the students heavily outnumber them, so it's much better to go through a track in "practice mode".&lt;/li&gt;
&lt;li&gt;There are 92 exercises but a good chunk of them don't really teach you anything new so they kinda feel like busywork. They could probably cut ~20 exercises from the track to make it feel a lot tighter.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Things Exercism does right:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;All problems are translated to Rust or written for Rust by experienced Rustaceans.&lt;/li&gt;
&lt;li&gt;There are problems which specifically teach Rust's idioms, design patterns, and unique features.&lt;/li&gt;
&lt;li&gt;Problem difficulties are fairly graded, easy problems are easy, medium problems are medium, hard problems are hard.&lt;/li&gt;
&lt;li&gt;You can include whatever 3rd-party dependencies that you want in your solutions.&lt;/li&gt;
&lt;li&gt;All unit tests are public, if you're failing a test you know exactly why.&lt;/li&gt;
&lt;li&gt;After you submit a solution you can browse other user's solutions, and you can sort solutions by which received the most stars.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Same as the &lt;a href="#tldr"&gt;TL;DR&lt;/a&gt; :)&lt;/p&gt;
&lt;h2&gt;Discuss&lt;/h2&gt;
&lt;p&gt;Discuss this article on&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a rel="nofollow" href="https://www.reddit.com/r/learnrust/comments/ggj8tf/learning_rust_in_2020/"&gt;learnrust subreddit&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a rel="nofollow" href="https://users.rust-lang.org/t/blog-post-learning-rust-in-2020/42373"&gt;official Rust users forum&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a rel="nofollow" href="https://twitter.com/pretzelhammer/status/1259897499122360322"&gt;Twitter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a rel="nofollow" href="https://www.reddit.com/r/rust/comments/gie64f/learning_rust_in_2020/"&gt;rust subreddit&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a rel="nofollow" href="https://news.ycombinator.com/item?id=23160975"&gt;Hackernews&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pretzelhammer/rust-blog/discussions"&gt;Github&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Notifications&lt;/h2&gt;
&lt;p&gt;Get notified when the next blog post get published by&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a rel="nofollow" href="https://twitter.com/pretzelhammer"&gt;Following pretzelhammer on Twitter&lt;/a&gt; or&lt;/li&gt;
&lt;li&gt;Watching this repo's releases (click &lt;code&gt;Watch&lt;/code&gt; -&amp;gt; click &lt;code&gt;Custom&lt;/code&gt; -&amp;gt; select &lt;code&gt;Releases&lt;/code&gt; -&amp;gt; click &lt;code&gt;Apply&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Further Reading&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/pretzelhammer/rust-blog/blob/master/posts/common-rust-lifetime-misconceptions.md"&gt;Common Rust Lifetime Misconceptions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pretzelhammer/rust-blog/blob/master/posts/sizedness-in-rust.md"&gt;Sizedness in Rust&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pretzelhammer/rust-blog/blob/master/posts/too-many-brainfuck-compilers.md"&gt;Learn Assembly with Entirely Too Many Brainfuck Compilers&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;
  &lt;/div&gt;&lt;/div&gt;&lt;a href="https://github.com/pretzelhammer/rust-blog/blob/master/posts/learning-rust-in-2020.md"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 12 May 2020 19:14:43 UT
      </pubDate>
      <guid>
        https://github.com/pretzelhammer/rust-blog/blob/master/posts/learning-rust-in-2020.md
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://www.stevestreeting.com/2010/09/04/work-2-0/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;
  &lt;p&gt;I’m 37, and I’ve been a (professional) developer for 16 years. You would have thought that in that time, I’d have figured out an effective work style which delivered the desired outcomes (code cut, products shipped etc) without causing detrimental knock-on effects - but, sadly, you’d be wrong. I think the&amp;nbsp;style in which I practiced my craft for the first 15 years of my career was much the same as every other enthusiastic developer: you put a &lt;strong&gt;ton&lt;/strong&gt; of hours in. 12-16+ hour days, evening and weekend coding marathons, pizza in the keyboard, crunch times, 3am debugging sessions where you just can’t go to bed because you can &lt;em&gt;feel the source of that bug just beyond your fingertips, dammit,&lt;/em&gt; desperate last-minute sprints to deadlines where you manage to slot that last piece in, Jack Bauer-like, just before the world goes to hell. If you’re in the demographic I’m talking about, you’re nodding sagely, and probably grinning a little too, reminiscing on past trials and glories. This sort of crazy dedication is respected in our circles, and is pretty much expected of any developer who has claimed to earn their stripes.&lt;/p&gt;

&lt;p&gt;But, it turns out this kind of thing is not good for your health - who knew? Those of you who know me or keep up with my blog know that I’ve been dragged kicking and screaming away from my old ways, because of back issues that I initially ignored, then tried to cope with using token accommodations, and finally succumbed to in a big way. Being self-employed, this was a major problem. Crawling out of the pit I dug for myself took a long time and a lot of frustration - I read quite a few productivity books on the subject to try to find answers on how to keep working, and in the end found that the answers you mould for yourself tend to be the best ones. I’d like to share one of the things I learned along the way.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;But I’m ‘In The Zone’!!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;So, I want to talk about the biggest problem I encountered: concentration periods. I can’t sit at a desk for longer than about an hour at a time now; if I don’t get up and walk around, do some gentle stretching etc, at least this often, I’ll pay for it badly once I do move, and probably over the next few days too. I also can’t realistically work more than a standard 8 hour day without pain any more. The problem with this was that, as a programmer, the&amp;nbsp;style which I developed over 15+ years involved getting gradually ‘Into The Zone’ and coding for very long periods at a time, uninterrupted. This is a common theme among coders, who like to shut themselves away for hours at a time, wear headphones to avoid distractions, have ‘quiet times’ and so on - and it’s also why we tend to react really badly when interrupted. Programming requires concentration, and concentration seems to run on a valve system - it takes time to warm up, and once it’s going, you don’t want to turn it off because starting it up again is a major hassle.&lt;/p&gt;

&lt;p&gt;I thought there was no way around this, and had begun to resign myself to just being less productive because of it. However, over the last 6 &amp;nbsp;months in particular, I’ve discovered that, far from being an intractable problem, this ‘slow warm up, long uninterrupted focus time’ approach is to a large degree a learned behaviour, and it’s possible to re-train yourself to cope with things differently. It’s a little like when people learn to adopt&amp;nbsp;&lt;a href="http://www.everything2.com/index.pl?node_id=892542"&gt;polyphasic sleep patterns&lt;/a&gt; - it’s not that you can’t do it, it’s just that when you’ve become accustomed to doing things a certain way, changing that is initially very, very hard. But it’s not impossible, given the right amount of motivation and time to adjust.&lt;/p&gt;

&lt;p&gt;So, my goal was to acclimatise myself to many shorter work chunks during the day instead of a few very large ones, while still maintaining productivity. The key to this was to learn how to get back ‘In The Zone’ in the shortest time possible - much like the way polyphasic sleepers train themselves to achieve REM sleep more quickly. I’m mostly there now, or at least way better at it than I was, so, what techniques did I use to make this transition?&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Embrace interruptions&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This is less of a technique and more of a deliberate psychological adjustment which cuts across all the practical approaches I’ll cover next. Instead of being the typical coder who avoids&amp;nbsp;interruptions at all costs, you need to accept them, and learn to manage them better. It’s hard - you have to try to set aside years of resisting interruptions and initially, until you adjust, you’ll feel like you can’t get enough done. Many people will probably want to give up, unless there’s something specific motivating them to push through it - for me, daily pain was a great motivator. My main message here is that the transition is just a phase, and that it &lt;strong&gt;is&lt;/strong&gt; possible to be an interruptable programmer who still gets things done. But you have to learn not to fight against it, hence why this is the first point.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Maintain context outside of your head at all times&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Much of the problem with interruptions is that of losing context. When you’re in that Zone, you’re juggling a whole bunch of context in your head, adjusting it on the fly, and maintaining and tweaking connections between issues constantly. Interruptions make you drop all that, and it takes time to pick it all up again. My answer to this was to externalise as much as possible, on as many levels as possible:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;**Maintain a running commentary on your current task&lt;/p&gt;

&lt;p&gt;&lt;span&gt;I am my very own chronicler. &lt;/span&gt;** I write notes on what I’m doing all the time, whether it’s adding a comment line to a ticket, committing frequently and writing detailed commit notes (you do use a DVCS to make light commits more practical, right? ;)) scribbling a drawing on (ordered) pieces of paper. This really isn’t that onerous, and in fact externalising your thoughts can often help you clarify them. Basically the guide is that roughly every 30 minutes, I should have generated some new piece of context which is stored somewhere other than my head. If I haven’t, then that’s context I’d have more trouble re-building mentally if I’m interrupted. It doesn’t take much time to do, and it has other benefits too such as recording your thought &amp;amp; decision process.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;**Ruthlessly ignore tangental issues&lt;/p&gt;

&lt;p&gt;&lt;span&gt;You might have noticed that in the last bullet, I used the words ‘current task’, &lt;em&gt;singular&lt;/em&gt;. Not ‘tasks’. There is no such thing as having more than one ‘current task’ - there is only the one task you’re actually working on, and &lt;em&gt;distractions&lt;/em&gt;.&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;We probably all use bug trackers / ticket systems to track bugs and feature requests, but when you’re working on a ticket, it’s very common to spot a new bug, or identify an opportunity for improvement, or think of a cool new feature. How many of us go ahead and deal with that right away, because it’s in the area we’re already in, or it’s ‘trivial’, or it’s a cool idea that you want to try right now? &amp;nbsp;I know I did - but I don’t any more; any tangental issues not related to what I’m currently doing get dumped into the ticket system and immediately forgotten until I’m done with the current task, regardless of their size, relevance or priority.&amp;nbsp;It sounds simple and obvious, and this might even be official procedure in your organisation, but I challenge most coders to say that they actually do this all the time. The benefit is that even the tiniest of distractions add an extra level of context that you have to maintain, which is then harder to pick up again after an interruption.&lt;br&gt; For this to work, you need a ticket system which is fast, lightweight, and doesn’t require you to be anal about how much detail you put in initially. You need to be in &amp;amp; out of there in 30 seconds so you can offload that thought without getting distracted - you can flesh it out later. &lt;/span&gt;**&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;Always know what you’re doing next&lt;/strong&gt;&lt;br&gt; This is one from GTD (‘Next actions’), but it’s a good one. When you come back from a break or interruption, you should spend no time at all figuring out what you need to be doing next. Your ticket system will help you here, and so will the running commentary that hopefully you’ve been keeping on your active task. If you’ve been forced to switch gears or projects, so long as you’ve maintained this external context universally, you should have no issue knowing what the next actions on each item are. The important thing is to have &lt;em&gt;one&lt;/em&gt; next action on each project. If you have several, you’ll have to spend time choosing between them, and that’s wasted time (see the next section on prioritisation). At any one time, you should not only have just one current task, but &lt;em&gt;one&lt;/em&gt; unambiguous next action on that task. Half the problem of working effectively is knowing what you’re doing next.&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Prioritise Negatively&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I mentioned next actions in the previous section, but how do you decide what comes next? A lot of time can be frittered away agonising over priorities, and I used to struggle with it; I would plan on the assumption that I wanted to do everything on the list, and I just needed to figure out which I needed to do first. I discovered that I could cut the amount of time I spent on planning, and also get better, less ambiguous priorities by inverting the decision making process - to assume a baseline that I wouldn’t do &lt;em&gt;any&lt;/em&gt; of the tasks, and assessing the negative outcomes of&amp;nbsp;&lt;em&gt;not&lt;/em&gt; doing each one. So instead of ‘which of feature A or B is more important to have?’, it became ‘Let’s assume we ship without feature A and B. What are the issues caused by omitting them in each case?’. It might appear to be a subtle difference, but having to justify inclusion entirely, rather than trying to establish a relative ordering assuming they all get done eventually, tends to tease out more frank evaluations in my experience.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Recognise the benefits of breaks&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Much of the above is about limiting the negative aspects of taking breaks, but the fact is, that they have many work-related benefits too. I’m willing to bet that all coders have stayed late at work, or late into the night, trying to fix a problem, only to find that they fix it within 15 minutes the next day, or think of the answer in some unlikely place like the shower. The reason for this is very simple - extended periods of concentration seem productive, and can be on operational / sequential thinking, but for anything else such as creative thinking or problem solving, it’s very often exactly the opposite. Not only do tired minds think less clearly, but often the answer to a problem lies not in more extensive thinking down the current path which you’ve been exploring in vain for the last few hours, but in looking at the problem from a completely different perspective. Long periods of concentration tend to ‘lock in’ current trains of thought, making inspiration and strokes of genius all too rare. Creativity always happens when you’re not trying, and it’s an often under-appreciated but vital element of the programming toolbox. Interrupting that train of thought can actually be a very good thing indeed.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;There’s more I could talk about, but that’s quite enough for now I think. I hope someone finds this interesting or useful 😀&lt;/p&gt;

&lt;/div&gt;&lt;/div&gt;&lt;a href="https://www.stevestreeting.com/2010/09/04/work-2-0/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Thu, 14 May 2020 00:05:39 UT
      </pubDate>
      <guid>
        https://www.stevestreeting.com/2010/09/04/work-2-0/
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://superorganizers.substack.com/p/stop-trying-to-make-hard-work-easy
      </link>
      <description>
        &lt;a href="https://superorganizers.substack.com/p/stop-trying-to-make-hard-work-easy"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Thu, 14 May 2020 00:06:05 UT
      </pubDate>
      <guid>
        https://superorganizers.substack.com/p/stop-trying-to-make-hard-work-easy
      </guid>
    </item>
    <item>
      <title>
        Tips for Founders Sales: Lessons From Starting Two B2B Startups &amp;#8211; Phil Strazzulla&amp;#039;s Blog
      </title>
      <link>
        http://philstrazzulla.com/2020/04/06/tips-for-founders-sales-lessons-from-starting-two-b2b-startups/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div id="content"&gt;
		&lt;main role="main" id="main"&gt;

			
&lt;article id="post-584"&gt;
		

	
	&lt;div&gt;
		
&lt;p&gt;Thus far I’ve founded two bootstrapped B2B startups, and led sales on both.&amp;nbsp; One is off to the races, profitable, and growing.&amp;nbsp; We even hired a general manager so that I can free myself up to work on other projects.&amp;nbsp; The &lt;a href="http://selectsoftwarereviews.com/"&gt;other&lt;/a&gt; is slightly more nascent, and just barely at ramen profitability.&lt;/p&gt;



&lt;p&gt;It’s really hard to get started with founder led selling.&amp;nbsp; I’m a (slight) introvert, and had basically no sales experience before starting my first business.&amp;nbsp; While I have a business mind, and an MBA in addition to my programming skills, it was still very challenging for me to get started.&lt;/p&gt;



&lt;p&gt;I used to view sales as this dark art that I could never master.&amp;nbsp; I’m not “salesy.”&amp;nbsp; I’m much more of a steak than sizzle
person.&amp;nbsp; I’m too honest.&amp;nbsp; I don’t look, talk or act like the various
stereotypes of a sales person.&amp;nbsp; And so, I
thought it was basically unattainable for me to be successful with sales for
the first year of my first business.&lt;/p&gt;



&lt;p&gt;I’m proud to say that through a lot of struggle and learning, I’ve actually become a decent sales person.&amp;nbsp; For whatever I lacked in initial extroversion and unblended confidence, I make up for in understanding of strategy and product.&amp;nbsp; I’m even fairly confident I could hit quota for any post product/market fit b2b SaaS startup out there.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;What I’ve learned about b2b founder sales&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;It’s been nearly five years now since I started the first
business.&amp;nbsp; As a result, I get introduced
to other founders every month or two who are starting to sell their products and
want advice.&amp;nbsp; Coming out of these
conversations, I find myself repeating the same themes.&lt;/p&gt;



&lt;p&gt;So, in no particular order, here’s my advice when starting
to do B2B sales at your startup:&lt;/p&gt;



&lt;ul&gt;&lt;li&gt;Find a sales mentor who’s done pre-product/market fit selling before.&amp;nbsp; It’s essential that someone has done the selling at the earliest stages of a company’s lifecycle.&amp;nbsp; Even someone who led sales at a Series A company won’t have the proper mindset or experience to help you through this.&amp;nbsp; Ideally, it’s another founder who’s been through it, and actually done the selling vs the strategy behind sales.&amp;nbsp; Another bonus is if they’ve sold to the exact customer persona you’re trying to reach.&lt;/li&gt;&lt;li&gt;Network with account executives who sell into a similar persona.&amp;nbsp; Ask them to walk you through their entire sales process, from initial outreach to demo.&amp;nbsp; Give them your sales pitch, and listen to their feedback.&amp;nbsp; You’ll get good practice demo’ing, and some advice.&amp;nbsp; However, you should realize that most sales reps selling a post product/market fit product will have very little understanding of why someone buys their product, that’s really up to you to figure out.&lt;/li&gt;&lt;li&gt;Record your first 50 demos and listen to them each within 24 hours of the pitch.&amp;nbsp; You will start to make small adjustments in messaging, in how long you answer questions, etc.&amp;nbsp; Be your own coach and try to look objectively at your pitch.&lt;/li&gt;&lt;li&gt;Ask for demos for software you are thinking about buying.&amp;nbsp; Think about what the sales reps do well, and what they don’t do well.&amp;nbsp; Mainly do this because you will realize 90% of sales reps are pretty mediocre. They don’t show up on time.&amp;nbsp; They ramble.  They don’t do any research.&amp;nbsp; They are too aggressive.&amp;nbsp; You can be 10x better than they are as a sales person, even if you’ve never sold before.&amp;nbsp; And, you’ll have to be to get started without a brand, and a product that is probably half complete.&lt;/li&gt;&lt;li&gt;Ask sales people you admire what books and blogs they read.&amp;nbsp; My recommendations: &lt;a href="https://firstround.com/review/sales/"&gt;FirstRound Review&lt;/a&gt;’s articles, this &lt;a href="https://docs.google.com/document/d/1ZHCSm5yUAGhdpDH9VFTPS271LZ-RgF3YHkvZQePxGnM/edit"&gt;book&lt;/a&gt; on founding sales, and the &lt;a href="https://www.amazon.com/Challenger-Sale-Control-Customer-Conversation/dp/1591844355"&gt;Challenger Sale&lt;/a&gt; are good places to start.&amp;nbsp; There is also a &lt;a href="https://www.instagram.com/corporate.bro/?hl=en"&gt;hilarious instagram&lt;/a&gt; account you will start empathizing with.&lt;/li&gt;&lt;li&gt;Spend as much time in person with your prospects as possible.&amp;nbsp; That means demos, as well as conferences, dinners, coffee, whatever you can.&amp;nbsp; This will allow you to build trust, and learn a lot faster about your customer than doing calls or even video calls.  Working out of one of their offices side by side is a great way to hear how they talk, what they care about, etc.  This is great for product development, and even better for sales.&lt;/li&gt;&lt;li&gt;Sales calls will probably become the most important way you will get feedback on your product in the next 6-18 months.&amp;nbsp; Keep track of the themes you hear, and start to think about how you can build those into your offering / start charging for them.  Record the closed/lost reasons for no-sale in a structured way so you can see what % fell out of the funnel due to pricing, competitors, etc.&lt;/li&gt;&lt;li&gt;Sales can be a grind.&amp;nbsp; I used to get nervous before calls, and found that creating a routine pre-demo really helped – jumping jacks, review the script, and believe that the product I’m offering will help the person on the other end of the phone.&amp;nbsp; You also need to let go of any ego or expectations of being treated like a human being. &amp;nbsp;Most people view sales people as a nuisance.&amp;nbsp; You will get let down a lot by your prospects every single day, but that makes the wins so much sweeter.&amp;nbsp; Plus, it’s a thing that happens to everyone, not just you.&lt;/li&gt;&lt;li&gt;It’s going to take you a few months to make your first sales (assuming your product is &amp;gt;$1k/yr).&amp;nbsp; Don’t get discouraged.&amp;nbsp; Don’t think “we need to change the pitch/outreach/etc.”&amp;nbsp; If you’ve been thoughtful about your process from the get-go, just keep building your pipeline.&lt;/li&gt;&lt;li&gt;Celebrate the wins.&amp;nbsp; I’m so bad at this and have some sort of Catholic guilt about it.&amp;nbsp; When someone says “yes” – celebrate.&amp;nbsp; When someone signs the contract – celebrate.&amp;nbsp; When someone goes live – celebrate. &amp;nbsp;High five your co-founder.&amp;nbsp; Get a beer after work.&amp;nbsp;&amp;nbsp; Tell your significant other.&amp;nbsp; Enjoy the moment and pat yourself on your back.&lt;/li&gt;&lt;/ul&gt;



&lt;p&gt;There are a million nuances to sales.&amp;nbsp; My &lt;a href="http://nextwavehire.com/"&gt;first&lt;/a&gt;
business was straight B2B SaaS where we were selling HR a product to help with
their recruiting.&amp;nbsp; Getting headspace was
tough.&amp;nbsp; Getting budget was tough.&amp;nbsp; Getting them to think about their job in a
new way was tough.&lt;/p&gt;



&lt;p&gt;In my &lt;a href="https://selectsoftwarereviews.com/"&gt;new
business&lt;/a&gt;, I’m selling to marketing.&amp;nbsp;
It’s a completely different buyer that has more budget and is more
likely to experiment with new products.&amp;nbsp;
I also have an advantage in that I’m putting reviews of their software
online, which means they care a lot more than if I was selling them a tool they
can ignore.&amp;nbsp; This allows me to cut
through the noise more effectively.&amp;nbsp; Of
course, it comes with many other challenges, and some I haven’t even run into
yet.&lt;/p&gt;



&lt;p&gt;I hope you enjoy your journey to becoming an A+ sales
person, which is a very attainable goal for any founder.&amp;nbsp; My journey has helped me build win new
business, think deeper about product, and kickstarted my personal branding
efforts.&amp;nbsp; &lt;/p&gt;



&lt;p&gt;Good luck, and feel free to &lt;a href="http://twitter.com/philstrazzulla"&gt;connect&lt;/a&gt; if I can be helpful in your journey!&lt;/p&gt;
&lt;/div&gt;

	 
&lt;/article&gt;









	
		&lt;/main&gt;
	&lt;/div&gt;&lt;/div&gt;&lt;a href="http://philstrazzulla.com/2020/04/06/tips-for-founders-sales-lessons-from-starting-two-b2b-startups/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 19 May 2020 10:14:38 UT
      </pubDate>
      <guid>
        http://philstrazzulla.com/2020/04/06/tips-for-founders-sales-lessons-from-starting-two-b2b-startups/
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://eryb.space/2020/05/27/diving-into-go-by-building-a-cli-application.html
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;article&gt;
&lt;p&gt;&lt;a href="https://howtorecover.me/pogruzhenie-v-go-putem-sozdaniya-prilozheniya-cli"&gt;Russian Version&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;You have wrapped your head around the Go syntax and practised them one by one, however you won’t feel comfortable writing applications in Go unless you build one.&lt;/p&gt;
&lt;p&gt;In this blog post we’ll build a CLI application in Go, which we’ll call &lt;strong&gt;go-grab-xkcd&lt;/strong&gt;.
This application fetches comics from &lt;a href="https://xkcd.com/"&gt;XKCD&lt;/a&gt; and provides you with various options through command-line arguments.&lt;/p&gt;
&lt;p&gt;We’ll use no external dependencies and will build the entire app using only the Go standard library.&lt;/p&gt;
&lt;p&gt;The application idea looks silly but the aim is to get comfortable writing production (sort of) code in Go and not to get acquired by Google.&lt;/p&gt;
&lt;h6 id="there-is-also-a-bash-bonus-at-the-end"&gt;There is also a Bash Bonus at the end.&lt;/h6&gt;
&lt;p&gt;&lt;em&gt;Note: This post assumes that the reader is familiar with Go syntax and terminologies and is somewhere between a beginner and an intermediate.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Let’s first run the application and see it in action-&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;$ &lt;/span&gt;go-grab-xkcd &lt;span&gt;--help&lt;/span&gt;

Usage of go-grab-xkcd:
  &lt;span&gt;-n&lt;/span&gt; int
        Comic number to fetch &lt;span&gt;(&lt;/span&gt;default latest&lt;span&gt;)&lt;/span&gt;
  &lt;span&gt;-o&lt;/span&gt; string
        Print output &lt;span&gt;in &lt;/span&gt;format: text/json &lt;span&gt;(&lt;/span&gt;default &lt;span&gt;"text"&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
  &lt;span&gt;-s&lt;/span&gt;    Save image to current directory
  &lt;span&gt;-t&lt;/span&gt; int
        Client &lt;span&gt;timeout &lt;/span&gt;&lt;span&gt;in &lt;/span&gt;seconds &lt;span&gt;(&lt;/span&gt;default 30&lt;span&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;$ &lt;/span&gt;go-grab-xkcd &lt;span&gt;-n&lt;/span&gt; 323

Title: Ballmer Peak
Comic No: 323
Date: 1-10-2007
Description: Apple uses automated schnapps IVs.
Image: https://imgs.xkcd.com/comics/ballmer_peak.png
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;$ &lt;/span&gt;go-grab-xkcd &lt;span&gt;-n&lt;/span&gt; 323 &lt;span&gt;-o&lt;/span&gt; json
&lt;span&gt;{&lt;/span&gt;
  &lt;span&gt;"title"&lt;/span&gt;: &lt;span&gt;"Ballmer Peak"&lt;/span&gt;,
  &lt;span&gt;"number"&lt;/span&gt;: 323,
  &lt;span&gt;"date"&lt;/span&gt;: &lt;span&gt;"1-10-2007"&lt;/span&gt;,
  &lt;span&gt;"description"&lt;/span&gt;: &lt;span&gt;"Apple uses automated schnapps IVs."&lt;/span&gt;,
  &lt;span&gt;"image"&lt;/span&gt;: &lt;span&gt;"https://imgs.xkcd.com/comics/ballmer_peak.png"&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You can try rest of the options by downloading and running the application for your computer.&lt;/p&gt;
&lt;p&gt;After the end of this tutorial you’ll be comfortable with the following topics-&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Accepting command line arguments&lt;/li&gt;
&lt;li&gt;Interconversion between JSON and Go Structs&lt;/li&gt;
&lt;li&gt;Making API calls&lt;/li&gt;
&lt;li&gt;Creating files (Downloading and saving from Internet)&lt;/li&gt;
&lt;li&gt;String Manipulation&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Below is the project structure-&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;$ &lt;/span&gt;tree go-grab-xkcd
go-grab-xkcd
├── client
│   └── xkcd.go
└── model
    └── comic.go
├── main.go
└── go.mod
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;go.mod&lt;/code&gt; - &lt;em&gt;Go Modules&lt;/em&gt; file used in Go for package management&lt;/li&gt;
&lt;li&gt;&lt;code&gt;main.go&lt;/code&gt; - Main entrypoint of the application&lt;/li&gt;
&lt;li&gt;&lt;code&gt;comic.go&lt;/code&gt; - Go representation of the data as a &lt;code&gt;struct&lt;/code&gt; and operations on it&lt;/li&gt;
&lt;li&gt;&lt;code&gt;xkcd.go&lt;/code&gt; - xkcd client for making HTTP calls to the API, parsing response and saving to disk&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="1-initialize-the-project"&gt;1: Initialize the project&lt;/h2&gt;
&lt;p&gt;Create a &lt;code&gt;go.mod&lt;/code&gt; file-&lt;/p&gt;

&lt;p&gt;This will help in package management (think package.json in JS).&lt;/p&gt;
&lt;h2 id="2-xkcd-api"&gt;2: xkcd API&lt;/h2&gt;
&lt;p&gt;xkcd is amazing, you don’t require any signups or access keys to use their API.
Open the xkcd &lt;a href="https://xkcd.com/json.html"&gt;API “documentation”&lt;/a&gt; and you’ll find that there are 2 endpoints-&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;http://xkcd.com/info.0.json&lt;/code&gt; - GET latest comic&lt;/li&gt;
&lt;li&gt;&lt;code&gt;http://xkcd.com/614/info.0.json&lt;/code&gt; - GET specific comic by comic number&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Following is the JSON response from these endpoints-&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;{&lt;/span&gt;&lt;span&gt;
  &lt;/span&gt;&lt;span&gt;"num"&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;2311&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;
  &lt;/span&gt;&lt;span&gt;"month"&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;"5"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;
  &lt;/span&gt;&lt;span&gt;"day"&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;"25"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;
  &lt;/span&gt;&lt;span&gt;"year"&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;"2020"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;
  &lt;/span&gt;&lt;span&gt;"title"&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;"Confidence Interval"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;
  &lt;/span&gt;&lt;span&gt;"alt"&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;"The worst part is that's the millisigma interval."&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;
  &lt;/span&gt;&lt;span&gt;"img"&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;"https://imgs.xkcd.com/comics/confidence_interval.png"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;
  &lt;/span&gt;&lt;span&gt;"safe_title"&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;"Confidence Interval"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;
  &lt;/span&gt;&lt;span&gt;"link"&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;""&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;
  &lt;/span&gt;&lt;span&gt;"news"&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;""&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;
  &lt;/span&gt;&lt;span&gt;"transcript"&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;""&lt;/span&gt;&lt;span&gt;
&lt;/span&gt;&lt;span&gt;}&lt;/span&gt;&lt;span&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Relevant &lt;a href="https://xkcd.com/1481/"&gt;xkcd&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="2-create-model-for-the-comic"&gt;2: Create model for the Comic&lt;/h2&gt;
&lt;p&gt;Based on the above JSON response, we create a &lt;code&gt;struct&lt;/code&gt; called &lt;code&gt;ComicResponse&lt;/code&gt; in &lt;code&gt;comic.go&lt;/code&gt; inside the &lt;code&gt;model&lt;/code&gt; package&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;type&lt;/span&gt; &lt;span&gt;ComicResponse&lt;/span&gt; &lt;span&gt;struct&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
	&lt;span&gt;Month&lt;/span&gt;      &lt;span&gt;string&lt;/span&gt; &lt;span&gt;`json:"month"`&lt;/span&gt;
	&lt;span&gt;Num&lt;/span&gt;        &lt;span&gt;int&lt;/span&gt;    &lt;span&gt;`json:"num"`&lt;/span&gt;
	&lt;span&gt;Link&lt;/span&gt;       &lt;span&gt;string&lt;/span&gt; &lt;span&gt;`json:"link"`&lt;/span&gt;
	&lt;span&gt;Year&lt;/span&gt;       &lt;span&gt;string&lt;/span&gt; &lt;span&gt;`json:"year"`&lt;/span&gt;
	&lt;span&gt;News&lt;/span&gt;       &lt;span&gt;string&lt;/span&gt; &lt;span&gt;`json:"news"`&lt;/span&gt;
	&lt;span&gt;SafeTitle&lt;/span&gt;  &lt;span&gt;string&lt;/span&gt; &lt;span&gt;`json:"safe_title"`&lt;/span&gt;
	&lt;span&gt;Transcript&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; &lt;span&gt;`json:"transcript"`&lt;/span&gt;
	&lt;span&gt;Alt&lt;/span&gt;        &lt;span&gt;string&lt;/span&gt; &lt;span&gt;`json:"alt"`&lt;/span&gt;
	&lt;span&gt;Img&lt;/span&gt;        &lt;span&gt;string&lt;/span&gt; &lt;span&gt;`json:"img"`&lt;/span&gt;
	&lt;span&gt;Title&lt;/span&gt;      &lt;span&gt;string&lt;/span&gt; &lt;span&gt;`json:"title"`&lt;/span&gt;
	&lt;span&gt;Day&lt;/span&gt;        &lt;span&gt;string&lt;/span&gt; &lt;span&gt;`json:"day"`&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You can use the &lt;a href="https://mholt.github.io/json-to-go/"&gt;JSON-to-Go&lt;/a&gt; tool to automatically generate the struct from JSON.&lt;/p&gt;
&lt;p&gt;Also create another struct which will be used to output data from our application.&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;type&lt;/span&gt; &lt;span&gt;Comic&lt;/span&gt; &lt;span&gt;struct&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
	&lt;span&gt;Title&lt;/span&gt;       &lt;span&gt;string&lt;/span&gt; &lt;span&gt;`json:"title"`&lt;/span&gt;
	&lt;span&gt;Number&lt;/span&gt;      &lt;span&gt;int&lt;/span&gt;    &lt;span&gt;`json:"number"`&lt;/span&gt;
	&lt;span&gt;Date&lt;/span&gt;        &lt;span&gt;string&lt;/span&gt; &lt;span&gt;`json:"date"`&lt;/span&gt;
	&lt;span&gt;Description&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; &lt;span&gt;`json:"description"`&lt;/span&gt;
	&lt;span&gt;Image&lt;/span&gt;       &lt;span&gt;string&lt;/span&gt; &lt;span&gt;`json:"image"`&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Add the below two methods to &lt;code&gt;ComicResponse&lt;/code&gt; struct-&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;// FormattedDate formats individual date elements into a single string&lt;/span&gt;
&lt;span&gt;func&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;cr&lt;/span&gt; &lt;span&gt;ComicResponse&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;FormattedDate&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
	&lt;span&gt;return&lt;/span&gt; &lt;span&gt;fmt&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Sprintf&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"%s-%s-%s"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;cr&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Day&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;cr&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Month&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;cr&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Year&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;// Comic converts ComicResponse that we receive from the API to our application's output format, Comic&lt;/span&gt;
&lt;span&gt;func&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;cr&lt;/span&gt; &lt;span&gt;ComicResponse&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;Comic&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;Comic&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
	&lt;span&gt;return&lt;/span&gt; &lt;span&gt;Comic&lt;/span&gt;&lt;span&gt;{&lt;/span&gt;
		&lt;span&gt;Title&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;       &lt;span&gt;cr&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Title&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
		&lt;span&gt;Number&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;      &lt;span&gt;cr&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Num&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
		&lt;span&gt;Date&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;        &lt;span&gt;cr&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;FormattedDate&lt;/span&gt;&lt;span&gt;(),&lt;/span&gt;
		&lt;span&gt;Description&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;cr&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Alt&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
		&lt;span&gt;Image&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;       &lt;span&gt;cr&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Img&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
	&lt;span&gt;}&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then add the following two methods to the &lt;code&gt;Comic&lt;/code&gt; struct-&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;// PrettyString creates a pretty string of the Comic that we'll use as output&lt;/span&gt;
&lt;span&gt;func&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;c&lt;/span&gt; &lt;span&gt;Comic&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;PrettyString&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
	&lt;span&gt;p&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;fmt&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Sprintf&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;
		&lt;span&gt;"Title: %s&lt;/span&gt;&lt;span&gt;\n&lt;/span&gt;&lt;span&gt;Comic No: %d&lt;/span&gt;&lt;span&gt;\n&lt;/span&gt;&lt;span&gt;Date: %s&lt;/span&gt;&lt;span&gt;\n&lt;/span&gt;&lt;span&gt;Description: %s&lt;/span&gt;&lt;span&gt;\n&lt;/span&gt;&lt;span&gt;Image: %s&lt;/span&gt;&lt;span&gt;\n&lt;/span&gt;&lt;span&gt;"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
		&lt;span&gt;c&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Title&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;c&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Number&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;c&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Date&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;c&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Description&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;c&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Image&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
	&lt;span&gt;return&lt;/span&gt; &lt;span&gt;p&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;// JSON converts the Comic struct to JSON, we'll use the JSON string as output&lt;/span&gt;
&lt;span&gt;func&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;c&lt;/span&gt; &lt;span&gt;Comic&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;JSON&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
	&lt;span&gt;cJSON&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;json&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Marshal&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;c&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
	&lt;span&gt;if&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;!=&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
		&lt;span&gt;return&lt;/span&gt; &lt;span&gt;""&lt;/span&gt;
	&lt;span&gt;}&lt;/span&gt;
	&lt;span&gt;return&lt;/span&gt; &lt;span&gt;string&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;cJSON&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="3-setup-xkcd-client-for-making-request-parsing-response-and-saving-to-disk"&gt;3: Setup xkcd client for making request, parsing response and saving to disk&lt;/h2&gt;
&lt;p&gt;Create &lt;code&gt;xkcd.go&lt;/code&gt; file inside the &lt;code&gt;client&lt;/code&gt; package.&lt;/p&gt;
&lt;p&gt;First define a custom type called &lt;code&gt;ComicNumber&lt;/code&gt; as an &lt;code&gt;int&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Define constants-&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;const&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;
	&lt;span&gt;// BaseURL of xkcd&lt;/span&gt;
	&lt;span&gt;BaseURL&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;"https://xkcd.com"&lt;/span&gt;
	&lt;span&gt;// DefaultClientTimeout is time to wait before cancelling the request&lt;/span&gt;
	&lt;span&gt;DefaultClientTimeout&lt;/span&gt; &lt;span&gt;time&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Duration&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;30&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; &lt;span&gt;time&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Second&lt;/span&gt;
	&lt;span&gt;// LatestComic is the latest comic number according to the xkcd API&lt;/span&gt;
	&lt;span&gt;LatestComic&lt;/span&gt; &lt;span&gt;ComicNumber&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;
&lt;span&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Create a struct &lt;code&gt;XKCDClient&lt;/code&gt;, it will be used to make requests to the API.&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;// XKCDClient is the client for XKCD&lt;/span&gt;
&lt;span&gt;type&lt;/span&gt; &lt;span&gt;XKCDClient&lt;/span&gt; &lt;span&gt;struct&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
	&lt;span&gt;client&lt;/span&gt;  &lt;span&gt;*&lt;/span&gt;&lt;span&gt;http&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Client&lt;/span&gt;
	&lt;span&gt;baseURL&lt;/span&gt; &lt;span&gt;string&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;

&lt;span&gt;// NewXKCDClient creates a new XKCDClient&lt;/span&gt;
&lt;span&gt;func&lt;/span&gt; &lt;span&gt;NewXKCDClient&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;*&lt;/span&gt;&lt;span&gt;XKCDClient&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
	&lt;span&gt;return&lt;/span&gt; &lt;span&gt;&amp;amp;&lt;/span&gt;&lt;span&gt;XKCDClient&lt;/span&gt;&lt;span&gt;{&lt;/span&gt;
		&lt;span&gt;client&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;&amp;amp;&lt;/span&gt;&lt;span&gt;http&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Client&lt;/span&gt;&lt;span&gt;{&lt;/span&gt;
			&lt;span&gt;Timeout&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;DefaultClientTimeout&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
		&lt;span&gt;},&lt;/span&gt;
		&lt;span&gt;baseURL&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;BaseURL&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
	&lt;span&gt;}&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Add the following 4 methods to &lt;code&gt;XKCDClient&lt;/code&gt;-&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;SetTimeout()&lt;/code&gt;&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;// SetTimeout overrides the default ClientTimeout&lt;/span&gt;
&lt;span&gt;func&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;hc&lt;/span&gt; &lt;span&gt;*&lt;/span&gt;&lt;span&gt;XKCDClient&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;SetTimeout&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;d&lt;/span&gt; &lt;span&gt;time&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Duration&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
    &lt;span&gt;hc&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;client&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Timeout&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;d&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Fetch()&lt;/code&gt;&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;// Fetch retrieves the comic as per provided comic number&lt;/span&gt;
&lt;span&gt;func&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;hc&lt;/span&gt; &lt;span&gt;*&lt;/span&gt;&lt;span&gt;XKCDClient&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;Fetch&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;n&lt;/span&gt; &lt;span&gt;ComicNumber&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;save&lt;/span&gt; &lt;span&gt;bool&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;model&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Comic&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;error&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
    &lt;span&gt;resp&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;hc&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;client&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Get&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;hc&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;buildURL&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;n&lt;/span&gt;&lt;span&gt;))&lt;/span&gt;
    &lt;span&gt;if&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;!=&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
        &lt;span&gt;return&lt;/span&gt; &lt;span&gt;model&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Comic&lt;/span&gt;&lt;span&gt;{},&lt;/span&gt; &lt;span&gt;err&lt;/span&gt;
    &lt;span&gt;}&lt;/span&gt;
    &lt;span&gt;defer&lt;/span&gt; &lt;span&gt;resp&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Body&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Close&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;

    &lt;span&gt;var&lt;/span&gt; &lt;span&gt;comicResp&lt;/span&gt; &lt;span&gt;model&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;ComicResponse&lt;/span&gt;
    &lt;span&gt;if&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;json&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;NewDecoder&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;resp&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Body&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Decode&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;&amp;amp;&lt;/span&gt;&lt;span&gt;comicResp&lt;/span&gt;&lt;span&gt;);&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;!=&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
        &lt;span&gt;return&lt;/span&gt; &lt;span&gt;model&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Comic&lt;/span&gt;&lt;span&gt;{},&lt;/span&gt; &lt;span&gt;err&lt;/span&gt;
    &lt;span&gt;}&lt;/span&gt;

    &lt;span&gt;if&lt;/span&gt; &lt;span&gt;save&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
        &lt;span&gt;if&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;hc&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;SaveToDisk&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;comicResp&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Img&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;"."&lt;/span&gt;&lt;span&gt;);&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;!=&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
            &lt;span&gt;fmt&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Println&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"Failed to save image!"&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
        &lt;span&gt;}&lt;/span&gt;
    &lt;span&gt;}&lt;/span&gt;
    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;comicResp&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Comic&lt;/span&gt;&lt;span&gt;(),&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;SaveToDisk()&lt;/code&gt;&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;// SaveToDisk downloads and saves the comic locally&lt;/span&gt;
&lt;span&gt;func&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;hc&lt;/span&gt; &lt;span&gt;*&lt;/span&gt;&lt;span&gt;XKCDClient&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;SaveToDisk&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;url&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;savePath&lt;/span&gt; &lt;span&gt;string&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;error&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
    &lt;span&gt;resp&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;http&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Get&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;url&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
    &lt;span&gt;if&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;!=&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
        &lt;span&gt;return&lt;/span&gt; &lt;span&gt;err&lt;/span&gt;
    &lt;span&gt;}&lt;/span&gt;
    &lt;span&gt;defer&lt;/span&gt; &lt;span&gt;resp&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Body&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Close&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;

    &lt;span&gt;absSavePath&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;_&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;filepath&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Abs&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;savePath&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
    &lt;span&gt;filePath&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;fmt&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Sprintf&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"%s/%s"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;absSavePath&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;path&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Base&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;url&lt;/span&gt;&lt;span&gt;))&lt;/span&gt;

    &lt;span&gt;file&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;os&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Create&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;filePath&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
    &lt;span&gt;if&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;!=&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
        &lt;span&gt;return&lt;/span&gt; &lt;span&gt;err&lt;/span&gt;
    &lt;span&gt;}&lt;/span&gt;
    &lt;span&gt;defer&lt;/span&gt; &lt;span&gt;file&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Close&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;

    &lt;span&gt;_&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;io&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Copy&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;file&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;resp&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Body&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
    &lt;span&gt;if&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;!=&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
        &lt;span&gt;return&lt;/span&gt; &lt;span&gt;err&lt;/span&gt;
    &lt;span&gt;}&lt;/span&gt;
    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;buildURL()&lt;/code&gt;&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;hc&lt;/span&gt; &lt;span&gt;*&lt;/span&gt;&lt;span&gt;XKCDClient&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;buildURL&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;n&lt;/span&gt; &lt;span&gt;ComicNumber&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
    &lt;span&gt;var&lt;/span&gt; &lt;span&gt;finalURL&lt;/span&gt; &lt;span&gt;string&lt;/span&gt;
    &lt;span&gt;if&lt;/span&gt; &lt;span&gt;n&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;LatestComic&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
        &lt;span&gt;finalURL&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;fmt&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Sprintf&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"%s/info.0.json"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;hc&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;baseURL&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
    &lt;span&gt;}&lt;/span&gt; &lt;span&gt;else&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
        &lt;span&gt;finalURL&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;fmt&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Sprintf&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"%s/%d/info.0.json"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;hc&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;baseURL&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;n&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
    &lt;span&gt;}&lt;/span&gt;
    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;finalURL&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="4-connect-everything"&gt;4: Connect everything&lt;/h2&gt;
&lt;p&gt;Inside the &lt;code&gt;main()&lt;/code&gt; function we connect all the wires-&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Read command arguments&lt;/li&gt;
&lt;li&gt;Instantiate the &lt;code&gt;XKCDClient&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fetch from API using the &lt;code&gt;XKCDClient&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Output&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id="read-command-arguments-"&gt;Read command arguments-&lt;/h5&gt;
&lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;comicNo&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;flag&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Int&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;
    &lt;span&gt;"n"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;int&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;client&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;LatestComic&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;"Comic number to fetch (default latest)"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;span&gt;)&lt;/span&gt;
&lt;span&gt;clientTimeout&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;flag&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Int64&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;
    &lt;span&gt;"t"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;int64&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;client&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;DefaultClientTimeout&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Seconds&lt;/span&gt;&lt;span&gt;()),&lt;/span&gt; &lt;span&gt;"Client timeout in seconds"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;span&gt;)&lt;/span&gt;
&lt;span&gt;saveImage&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;flag&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Bool&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;
    &lt;span&gt;"s"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;false&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;"Save image to current directory"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;span&gt;)&lt;/span&gt;
&lt;span&gt;outputType&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;flag&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;String&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;
    &lt;span&gt;"o"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;"text"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;"Print output in format: text/json"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;span&gt;)&lt;/span&gt;
&lt;span&gt;flag&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Parse&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h5 id="instantiate-the-xkcdclient"&gt;Instantiate the &lt;code&gt;XKCDClient&lt;/code&gt;&lt;/h5&gt;
&lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;xkcdClient&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;client&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;NewXKCDClient&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;
&lt;span&gt;xkcdClient&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;SetTimeout&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;time&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Duration&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;*&lt;/span&gt;&lt;span&gt;clientTimeout&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; &lt;span&gt;time&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Second&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h5 id="fetch-from-api-using-the-xkcdclient"&gt;Fetch from API using the &lt;code&gt;XKCDClient&lt;/code&gt;&lt;/h5&gt;
&lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;comic&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;xkcdClient&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Fetch&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;client&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;ComicNumber&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;*&lt;/span&gt;&lt;span&gt;comicNo&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;*&lt;/span&gt;&lt;span&gt;saveImage&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
&lt;span&gt;if&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;!=&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
    &lt;span&gt;log&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Println&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;err&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h5 id="output"&gt;Output&lt;/h5&gt;
&lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;if&lt;/span&gt; &lt;span&gt;*&lt;/span&gt;&lt;span&gt;outputType&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;"json"&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
    &lt;span&gt;fmt&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Println&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;comic&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;JSON&lt;/span&gt;&lt;span&gt;())&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt; &lt;span&gt;else&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
    &lt;span&gt;fmt&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Println&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;comic&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;PrettyString&lt;/span&gt;&lt;span&gt;())&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Run the program as follows-&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;$ &lt;/span&gt;go run main.go &lt;span&gt;-n&lt;/span&gt; 323 &lt;span&gt;-o&lt;/span&gt; json
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Or build it as an executable binary for your laptop and then run-&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;$ &lt;/span&gt;go build &lt;span&gt;.&lt;/span&gt;
&lt;span&gt;$ &lt;/span&gt;./go-grab-xkcd &lt;span&gt;-n&lt;/span&gt; 323 &lt;span&gt;-s&lt;/span&gt; &lt;span&gt;-o&lt;/span&gt; json
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Find the complete source code in the Github Repository - &lt;a href="https://github.com/erybz/go-grab-xkcd"&gt;go-grab-xkcd&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="bash-bonus"&gt;Bash Bonus&lt;/h2&gt;
&lt;p&gt;Download multiple comics serially by using this simple shell magic-&lt;/p&gt;
&lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;$ &lt;/span&gt;&lt;span&gt;for &lt;/span&gt;i &lt;span&gt;in&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;1..10&lt;span&gt;}&lt;/span&gt;&lt;span&gt;;&lt;/span&gt; &lt;span&gt;do&lt;/span&gt; ./go-grab-xkcd &lt;span&gt;-n&lt;/span&gt; &lt;span&gt;$i&lt;/span&gt; &lt;span&gt;-s&lt;/span&gt;&lt;span&gt;;&lt;/span&gt; &lt;span&gt;done&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The above shell code simple calls our &lt;code&gt;go-grab-xkcd&lt;/code&gt; command in a &lt;code&gt;for&lt;/code&gt; loop, and the &lt;code&gt;i&lt;/code&gt; value is substituted as comic number since xkcd uses serial integers as comic number/ID.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;&lt;a href="https://eryb.space/2020/05/27/diving-into-go-by-building-a-cli-application.html"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Wed, 27 May 2020 10:37:39 UT
      </pubDate>
      <guid>
        https://eryb.space/2020/05/27/diving-into-go-by-building-a-cli-application.html
      </guid>
    </item>
    <item>
      <title>
        TwoHardThings
      </title>
      <link>
        https://martinfowler.com/bliki/TwoHardThings.html
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;
&lt;blockquote&gt;
&lt;p&gt;There are only two hard things in Computer Science: cache
    invalidation and naming things.&lt;/p&gt;

&lt;p&gt;-- Phil Karlton&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Long a favorite saying of mine, one for which I couldn't find a
  satisfactory URL.&lt;/p&gt;

&lt;p&gt;Like many good phrase, it's had a host of riffs on it. A couple of them I feel are worth
  adding to the page&lt;/p&gt;

&lt;div&gt;
&lt;blockquote lang="en"&gt;
    There are 2 hard problems in computer science: cache invalidation, naming things, and
    off-by-1 errors.
  &lt;a href="https://twitter.com/secretGeek/status/7269997868"&gt;-- Leon Bambrick&lt;/a&gt;&lt;/blockquote&gt;
&lt;/div&gt;

&lt;div&gt;
&lt;blockquote lang="en"&gt;
    There are only two hard problems in distributed systems: 2. Exactly-once delivery 1.
    Guaranteed order of messages 2. Exactly-once delivery
  &lt;a href="https://twitter.com/mathiasverraes/status/632260618599403520"&gt;-- Mathias Verraes&lt;/a&gt;&lt;/blockquote&gt;
&lt;/div&gt;





&lt;div&gt;
&lt;h2&gt;Revisions&lt;/h2&gt;

&lt;p&gt;2009-07-14: original post&lt;/p&gt;

&lt;p&gt;2010-12-21: added off-by-one variation (unattributed)&lt;/p&gt;

&lt;p&gt;2015-08-14: added distributed tweet&lt;/p&gt;

&lt;p&gt;2017-03-30: added proper tweet for off-by-one and mention of Tim Bray's
    source&lt;/p&gt;

&lt;p&gt;2017-12-22: added the Phillip Scott Bowden tweet&lt;/p&gt;
&lt;/div&gt;

&lt;div&gt;
&lt;h2&gt;Acknowledgements&lt;/h2&gt;&lt;p&gt;

    Leon Bambrick let me know about better sources.
  &lt;/p&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;a href="https://martinfowler.com/bliki/TwoHardThings.html"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Fri, 29 May 2020 00:26:49 UT
      </pubDate>
      <guid>
        https://martinfowler.com/bliki/TwoHardThings.html
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://prog21.dadgum.com/123.html
      </link>
      <description>
        &lt;a href="https://prog21.dadgum.com/123.html"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Wed, 3 Jun 2020 01:08:47 UT
      </pubDate>
      <guid>
        https://prog21.dadgum.com/123.html
      </guid>
    </item>
    <item>
      <title>
        Politeness
      </title>
      <link>
        https://www.cs.cornell.edu/~cristian/Politeness.html
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;
                
                
                &lt;p&gt;A computational approach to politeness with application to social factors &lt;br&gt;&lt;/p&gt;
                &lt;p&gt;Cristian Danescu-Niculescu-Mizil, Moritz Sudhof, Dan Jurafsky, Jure Leskovec, Christopher Potts&lt;br&gt;&lt;/p&gt;
                &lt;p&gt;Proceedings of ACL, 2013.&lt;br&gt;&lt;/p&gt;
                &lt;p&gt;Nominated for the Best Paper Award&lt;br&gt;&lt;/p&gt;
                
                
                &lt;p&gt;&lt;a href="https://www.cs.cornell.edu/~cristian/Politeness_files/politeness.pdf" title="Politeness_files/politeness.pdf"&gt;PDF&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
                
                
                &lt;p&gt;&lt;a href="https://www.cs.cornell.edu/~cristian/Politeness_files/politeness_talk.pdf" title="Politeness_files/politeness_talk.pdf"&gt;Talk slides&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
                
                
                &lt;p&gt;Fun: &lt;span&gt;Check how polite your requests are using our &lt;/span&gt;&lt;a href="http://politeness.cornell.edu/" title="http://politeness.cornell.edu"&gt;Politeness Web App&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
                
                
                &lt;p&gt;Data and Code: &lt;a href="http://convokit.cornell.edu/" title="http://convokit.cornell.edu"&gt;ConvoKit&lt;/a&gt;&amp;nbsp;&amp;nbsp; (legacy code: &lt;a href="https://github.com/sudhof/politeness" title="https://github.com/sudhof/politeness"&gt;Stanford Politeness API&lt;/a&gt;, legacy data:&amp;nbsp; &lt;a href="https://www.cs.cornell.edu/~cristian/Politeness_files/Readme.txt" title="Politeness_files/Readme.txt"&gt;Stanford Politeness Corpus&lt;/a&gt;)&lt;br&gt;&lt;/p&gt;
                
                
                &lt;p&gt;Related research:&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;br&gt;&lt;/p&gt;
                &lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;a href="https://www.cs.cornell.edu/~cristian/Conversations.html" title="Conversations.html"&gt;Conversational Behavior&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
                &lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;a href="https://www.cs.cornell.edu/~cristian/Antisocial.html" title="Antisocial.html"&gt;Anti-Social Computing&lt;br&gt;&lt;/a&gt;&lt;/p&gt;
                
                
                
                
                
                &lt;p&gt;Teaser:&lt;br&gt;&lt;/p&gt;
                &lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; Politeness and status: successful and failed candidates before and after elections.&lt;br&gt;&lt;/p&gt;
                
                &lt;div&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;p&gt;&lt;img alt="" src="https://www.cs.cornell.edu/~cristian/Politeness_files/statuschange.jpg"&gt;&lt;/p&gt;&lt;br&gt;&lt;/div&gt;
                &lt;div&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;div id="id1"&gt;&lt;p&gt;Editors that will eventually succeed (diamond marker) are significantly more polite than those that will fail (circle markers). Following the elections, successful editors become less polite while unsuccessful editors become more polite.&lt;/p&gt;&lt;/div&gt;&lt;br&gt;&lt;/div&gt;
                
                &lt;p&gt;ABSTRACT: &lt;br&gt;&lt;/p&gt;
                &lt;div&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;div id="id2"&gt;&lt;p&gt;We propose a computational framework for identifying linguistic aspects of politeness. Our starting point is a new corpus of requests annotated for politeness, which we use to evaluate aspects of politeness theory and to uncover new interactions between politeness markers and context. These findings guide our construction of a classifier with domain-independent lexical and syntactic features operationalizing key components of politeness theory, such as indirection, deference, impersonalization and modality. Our classifier achieves close to human performance and is effective across domains.&amp;nbsp; We use our framework to study the relationship between politeness and social power, showing that polite Wikipedia editors are more likely to achieve high status through elections, but, once elevated, they become less polite.&amp;nbsp; We see a similar negative correlation between politeness and power on Stack Exchange, where users at the top of the reputation scale are less polite than those at the bottom.&amp;nbsp; Finally, we apply our classifier to a preliminary analysis of politeness variation by gender and community.&lt;/p&gt;&lt;/div&gt;&lt;br&gt;&lt;/div&gt;
                
                
                &lt;p&gt;BibTeX ENTRY:&lt;br&gt;&lt;/p&gt;
                &lt;div&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;div id="id3"&gt;&lt;p&gt;@InProceedings{Danescu-Niculescu-Mizil+al:13b,&lt;br&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp; author={Cristian Danescu-Niculescu-Mizil and Moritz Sudhof and Dan Jurafsky &lt;br&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp; and Jure Leskovec and Christopher Potts},&lt;br&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp; title={A computational approach to politeness with application to social factors},&lt;br&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp; booktitle={Proceedings of ACL},&lt;br&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp; year={2013}&lt;br&gt;&lt;/p&gt;&lt;p&gt;}&lt;/p&gt;&lt;/div&gt;&lt;br&gt;&lt;/div&gt;
              &lt;/div&gt;&lt;/div&gt;&lt;a href="https://www.cs.cornell.edu/~cristian/Politeness.html"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Fri, 12 Jun 2020 12:02:40 UT
      </pubDate>
      <guid>
        https://www.cs.cornell.edu/~cristian/Politeness.html
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://arxiv.org/pdf/1904.01596.pdf
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;��ɟ]��r�����P\��F8%%#/q��Q��X%�;���F�����'�	��jT���B,�UJ�cb��(�36~"�-�8�d�|;������9#�b���g�c�y}�{s�����&amp;amp;Xy6]��/@a�ㄘ�1��W�q6-��\�(ؑ;|]�?l���{Z�a�!�[�4��l&amp;lt;qN��GG�S�6�^E�a|��1���'Qv�t3ү�A+��t����̻��A��Dy�&amp;lt;�,.G�wH���?��������tK�W�f8�E�N��
_tֽ�@���U��p�J-�DI$'u��U��6j�h`LG����lf�&amp;gt;�I�&amp;amp;a�g�z=h�I��i�������3$��l�r�]~�)^5���؂3&amp;gt;�ڮ�����#$����=|ӟ89�7�Re��©ѵ:
εb��6,��Y6�D�s5`���-2��g���- �`�H׵�"O7�^�S����s���r�+���d����d����{vV+f�Qg03�(�$I�H���$�����L�l0���ۖ��H?P�˨�jC!�Hd+�6y4���vY	���#mð"�=��
@�P]�۪�����f�%�+�y0�y���`��O"��H�d���_����Y)1��:���ώl$���pTۓ����3�I��d�ˆ�=	qO��x|7&amp;gt;e�ޤ��VW�u������d�s�8� ?栓�h����N���\�3M��&amp;gt;��K�4�1X� ����b��������ξғU��5G�u�"?�.�*E�lKL�X.�W0�JW��+,Pr)�"�KO`
z\�+�*�������*}檲g�J&amp;lt;#��RyJ��8��.@A�冂�b����\Z|�W��S������|��4[&amp;lt;.�����ٲn{�U�m+�OJc��/�'z.TJ
�;.S��^�y��@�����6M��ֱ�$�X�?��� ,t��ǯn��7h'�5���;zz��\r��scaG�~T��ɯ����Y�?$�؉pY��g�c�'2㗽Zļw\x��{�2����"�~;��v�PЩ&amp;amp;�������"̞$�"q��4�?[�[����Z͛���,�C���3�K�u.�Ջ�������I3��o��|�ʺ6qw�t��&amp;amp;}��?����D`��mSj���aΎ�\
*�[|~|��N�::s�4�O�K'��}�&amp;lt;�6ϋ�s�ۅ�;Wi�Z��U���� nT�F�*{^׌�B�	9�#�k��%��6����Ԟ[FP�x���rIn���h޽�'�7�ABy�h�����hj���Uu�rJq����v
+�HI��3���%`�s�i�w!�s�vp��&amp;lt;�s
����9
�-[.�zL����"����W����Vҕ�Y��1�����xX�a���s9EO�/.م�����@X$��BI��&amp;lt;~�W��A#P7Ry�y����)��z���樂1`�S�[��6��@�"��D�$��I�
�,��[�������W����N����N��]���x\9o)ts��Y0��][��,�\��F��:'�w����s���yf!��KsiKg]���muKTn^p���κ�YTk��H��8ji��=��vO��;�Y��]1�[=	"Z�N)|z��t�Pp���]���cF�w���@s�g&amp;amp;�OG�|P���= ���*�vo�0��ts�˨���z�yǿޙ��x�ab~�Aϟ{WB�T[������d̄�?T$�#endstream
endobj
162 0 obj
&amp;lt;&amp;lt; /Type /XObject /Subtype /Form /BBox [ 0 0 446 264 ]
/Filter /FlateDecode /FormType 1 /Length 10900
/PTEX.FileName (./plots/leaveout_over_time.pdf)
/PTEX.InfoDict 225 0 R /PTEX.PageNumber 1
/Resources &amp;lt;&amp;lt; /ColorSpace &amp;lt;&amp;lt; /sRGB 234 0 R &amp;gt;&amp;gt;
/ExtGState &amp;lt;&amp;lt; /GS1 227 0 R /GS2 228 0 R /GS257 230 0 R /GS258 231 0 R
/GS259 232 0 R /GS260 233 0 R /GS3 229 0 R &amp;gt;&amp;gt;
/Font &amp;lt;&amp;lt; /F2 226 0 R &amp;gt;&amp;gt; /ProcSet [ /PDF /Text ] &amp;gt;&amp;gt; &amp;gt;&amp;gt;
stream
x��}M�5�����w)-|��fo�$�re�K5Y��Pd��%�Xr���C����F�e;�B�lt7�⃝?{������?���?���ɗ�����G���O&amp;gt;�'~�ß���Z�����●���w������ޥk���O���O����#�*�&amp;gt;}|@�z��(�s�G����#��̷��=&amp;gt;�.
�U�������#�+7p=��7p�܀�=����g���H� ��C�S��tm&amp;gt;���ٞ����K�c���`�g�qw���m���&amp;lt;������2��5��x����m�W��F�����p�F���9S���ቤ$�e?�U�&amp;lt;�O�e#�-��,c߲���sy��PA�Ԝ�}?U��?�釋z��K?:���2&amp;amp;���=�I�Z~�&amp;amp;T�Q1Ƴd��
����PEz�]ZU���%�J~y�gNB5y��-wQ=/*]k��%�����E�L�Ȁ\�lJ�&amp;gt;�*�\3����e��JJ�gKJjWe͕)d�J�gmB��i=�;Y���Yn!kWr&amp;gt;��)�ʳ腺�C��"Mɞ�E/r��z�Эj���ׅ�gR%G�;]d�[��3u!��&amp;lt;��W!��N��'���.�6���ʝ6!o�9_k��^+@W��Bg����nNh�95�B7y�9_Ϛ���\冄�/���m�kS�R�3+�O4�)K���s��ѕ�F�g��������e���b�Jg���רlJ7��ޞ)+=�����J��#�%�+6Z�ZrZQ���g��Q��כkxN�u4�;=o�����ݟ5+]�_փ���*_�&amp;amp;/Mh]BʵV�^�뗴�ԥ�΂�t�=��5y�\��ZB[��=�R�,�B��)ki�]�)����Lr�akv�kd]J��-k=�����K�ґЦ�Z�.[�t(�������K_?�JO�-U�w��*kž/��zkA(C���/��U�[����|��P���&amp;gt;ǭ��E�DWz
]׋Y*%�M��&lt;/div&gt;&lt;a href="https://arxiv.org/pdf/1904.01596.pdf"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Fri, 12 Jun 2020 12:03:11 UT
      </pubDate>
      <guid>
        https://arxiv.org/pdf/1904.01596.pdf
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://www.pnas.org/content/114/25/6521
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div class="page" id="page" role="main"&gt;
    &lt;div id="block-panels-mini-whats-new-in"&gt;&lt;div&gt;
  
      
  
  &lt;p&gt;
    &lt;h2&gt;New&amp;nbsp;Research&amp;nbsp;In&lt;/h2&gt;
  &lt;/p&gt;

  
  &lt;/div&gt;
&lt;div&gt;
  
        &lt;h3&gt;&lt;span&gt;Physical Sciences&lt;/span&gt;&lt;/h3&gt;
    
  
  &lt;div id="pnas-physical-sciences"&gt;
    &lt;h4&gt;Featured Portals&lt;/h4&gt;



&lt;h4&gt;Articles by Topic&lt;/h4&gt;


  &lt;/div&gt;

  
  &lt;/div&gt;

&lt;div&gt;
  
        &lt;h3&gt;&lt;span&gt;Biological Sciences&lt;/span&gt;&lt;/h3&gt;
    
  
  &lt;div id="pnas-biological-sciences"&gt;
    &lt;h4&gt;Featured Portals&lt;/h4&gt;



&lt;h4&gt;Articles by Topic&lt;/h4&gt;


  &lt;/div&gt;

  
  &lt;/div&gt;
&lt;/div&gt;
&lt;div id="block-system-main"&gt;&lt;div&gt;
    
    &lt;p&gt;&lt;a data-target="crossmark"&gt;&lt;img alt="" src="https://crossmark-cdn.crossref.org/widget/v2.0/logos/CROSSMARK_Color_square.svg"&gt;&lt;/a&gt;&lt;/p&gt;
      &lt;/div&gt;
&lt;div data-hw-author-tooltip-instance="highwire_author_tooltip" data-apath="/pnas/114/25/6521.atom" data-pisa-master="pnas;1702413114" data-pisa="pnas;114/25/6521" id="node3349" data-node-nid="3349"&gt;
  
  
      &lt;p&gt;&lt;span&gt;Research Article&lt;/span&gt;&lt;/p&gt;
  
  
        
    	&lt;p&gt;&lt;span&gt;, &lt;span data-delta="1"&gt;Nicholas P. Camp&lt;/span&gt;, &lt;span data-delta="2"&gt;Vinodkumar Prabhakaran&lt;/span&gt;, &lt;span data-delta="3"&gt;William L. Hamilton&lt;/span&gt;, &lt;span data-delta="4"&gt;Rebecca C. Hetey&lt;/span&gt;, &lt;span data-delta="5"&gt;Camilla M. Griffiths&lt;/span&gt;, &lt;span data-delta="6"&gt;David Jurgens&lt;/span&gt;, &lt;span data-delta="7"&gt;Dan Jurafsky&lt;/span&gt;, and &lt;span data-delta="8"&gt;Jennifer L. Eberhardt&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
  
    	
  
  
    	
  
&lt;/div&gt;
&lt;div id="content-block-markup" xmlns="http://www.w3.org/1999/xhtml"&gt;&lt;ol&gt;&lt;li id="fn-1"&gt;&lt;p id="p-1"&gt;Contributed by Jennifer L. Eberhardt, March 26, 2017 (sent for review February 14, 2017; reviewed by James Pennebaker and Tom Tyler)&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;

&lt;div id="panels-ajax-tab-container-highwire_article_tabs" data-panels-ajax-tab-preloaded="jnl_pnas_tab_art"&gt;&lt;div data-highwire-cite-ref-tooltip-instance="highwire_reflinks_tooltip" id="content-block-markup" xmlns="http://www.w3.org/1999/xhtml"&gt;&lt;div&gt;&lt;h2&gt;Significance&lt;/h2&gt;&lt;p id="p-6"&gt;Police officers speak significantly less respectfully to black than to white community members in everyday traffic stops, even after controlling for officer race, infraction severity, stop location, and stop outcome. This paper presents a systematic analysis of officer body-worn camera footage, using computational linguistic techniques to automatically measure the respect level that officers display to community members. This work demonstrates that body camera footage can be used as a rich source of data rather than merely archival evidence, and paves the way for developing powerful language-based tools for studying and potentially improving police–community relations.&lt;/p&gt;&lt;/div&gt;&lt;div id="abstract-2"&gt;&lt;h2&gt;Abstract&lt;/h2&gt;&lt;p id="p-7"&gt;Using footage from body-worn cameras, we analyze the respectfulness of police officer language toward white and black community members during routine traffic stops. We develop computational linguistic methods that extract levels of respect automatically from transcripts, informed by a thin-slicing study of participant ratings of officer utterances. We find that officers speak with consistently less respect toward black versus white community members, even after controlling for the race of the officer, the severity of the infraction, the location of the stop, and the outcome of the stop. Such disparities in common, everyday interactions between police and the communities they serve have important implications for procedural justice and the building of police–community trust.&lt;/p&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;a rel="nofollow" href="https://www.pnas.org/keyword/racial-disparities"&gt;racial disparities&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a rel="nofollow" href="https://www.pnas.org/keyword/natural-language-processing"&gt;natural language processing&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a rel="nofollow" href="https://www.pnas.org/keyword/procedural-justice"&gt;procedural justice&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a rel="nofollow" href="https://www.pnas.org/keyword/traffic-stops"&gt;traffic stops&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a rel="nofollow" href="https://www.pnas.org/keyword/policing"&gt;policing&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p id="p-8"&gt;Over the last several years, our nation has been rocked by an onslaught of incidents captured on video involving police officers’ use of force with black suspects. The images from these cases are disturbing, both exposing and igniting police–community conflict all over the country: in New York, Missouri, Ohio, South Carolina, Maryland, Illinois, Wisconsin, Louisiana, Oklahoma, and North Carolina. These images have renewed conversations about modern-day race relations and have led many to question how far we have come (&lt;a href="#ref-1" id="xref-ref-1-1"&gt;1&lt;/a&gt;). In an effort to increase accountability and transparency, law enforcement agencies are adopting body-worn cameras at an extremely rapid pace (&lt;a href="#ref-2" id="xref-ref-2-1"&gt;2&lt;/a&gt;, &lt;a href="#ref-3" id="xref-ref-3-1"&gt;3&lt;/a&gt;).&lt;/p&gt;&lt;p id="p-9"&gt;Despite the rapid proliferation of body-worn cameras, no law enforcement agency has systematically analyzed the massive amounts of footage these cameras produce. Instead, the public and agencies alike tend to focus on the fraction of videos involving high-profile incidents, using footage as evidence of innocence or guilt in individual encounters.&lt;/p&gt;&lt;p id="p-10"&gt;Left unexamined are the common, everyday interactions between the police and the communities they serve. By best estimates, more than one quarter of the public (ages 16 y and over) comes into contact with the police during the course of a year, most frequently as the result of a police-initiated traffic stop (&lt;a href="#ref-4" id="xref-ref-4-1"&gt;4&lt;/a&gt;, &lt;a href="#ref-5" id="xref-ref-5-1"&gt;5&lt;/a&gt;). Here, we examine body-worn camera footage of routine traffic stops in the large, racially diverse city of Oakland, CA.&lt;/p&gt;&lt;p id="p-11"&gt;Routine traffic stops are not only common, they are consequential, each an opportunity to build or erode public trust in the police. Being treated with respect builds trust in the fairness of an officer’s behavior, whereas rude or disrespectful treatment can erode trust (&lt;a href="#ref-6" id="xref-ref-6-1"&gt;6&lt;/a&gt;, &lt;a href="#ref-7" id="xref-ref-7-1"&gt;7&lt;/a&gt;). Moreover, a person’s experiences of respect or disrespect in personal interactions with police officers play a central role in their judgments of how procedurally fair the police are as an institution, as well as their willingness to support or cooperate with the police (&lt;a href="#ref-8" id="xref-ref-8-1"&gt;8&lt;/a&gt;, &lt;a href="#ref-9" id="xref-ref-9-1"&gt;9&lt;/a&gt;).&lt;/p&gt;&lt;p id="p-12"&gt;Blacks report more negative experiences in their interactions with the police than other groups (&lt;a href="#ref-10" id="xref-ref-10-1"&gt;10&lt;/a&gt;). Across numerous studies, for example, blacks report being treated less fairly and respectfully in their contacts with the police than whites (&lt;a href="#ref-6" id="xref-ref-6-2"&gt;6&lt;/a&gt;, &lt;a href="#ref-11" id="xref-ref-11-1"&gt;11&lt;/a&gt;). Indeed, some have argued that racial disparities in perceived treatment during routine encounters help fuel the mistrust of police in the controversial officer-involved shootings that have received such great attention. However, do officers treat white community members with a greater degree of respect than they afford to blacks?&lt;/p&gt;&lt;p id="p-13"&gt;We address this question by analyzing officers’ language during vehicle stops of white and black community members. Although many factors may shape these interactions, an officer’s words are undoubtedly critical: Through them, the officer can communicate respect and understanding of a citizen’s perspective, or contempt and disregard for their voice. Furthermore, the language of those in positions of institutional power (police officers, judges, work superiors) has greater influence over the course of the interaction than the language used by those with less power (&lt;a href="#ref-12" id="xref-ref-12-1"&gt;12&lt;/a&gt;&lt;a href="#ref-13" id="xref-ref-13-1"&gt;&lt;span&gt;⇓&lt;/span&gt;&lt;/a&gt;&lt;a href="#ref-14" id="xref-ref-14-1"&gt;&lt;span&gt;⇓&lt;/span&gt;&lt;/a&gt;&lt;a href="#ref-15" id="xref-ref-15-1"&gt;&lt;span&gt;⇓&lt;/span&gt;&lt;/a&gt;–&lt;a href="#ref-16" id="xref-ref-16-1"&gt;16&lt;/a&gt;). Measuring officer language thus provides a quantitative lens on one key aspect of the quality or tone of police–community interactions, and offers new opportunities for advancing police training.&lt;/p&gt;&lt;p id="p-14"&gt;Previous research on police–community interactions has relied on citizens’ recollection of past interactions (&lt;a href="#ref-10" id="xref-ref-10-2"&gt;10&lt;/a&gt;) or researcher observation of officer behavior (&lt;a href="#ref-17" id="xref-ref-17-1"&gt;17&lt;/a&gt;&lt;a href="#ref-18" id="xref-ref-18-1"&gt;&lt;span&gt;⇓&lt;/span&gt;&lt;/a&gt;&lt;a href="#ref-19" id="xref-ref-19-1"&gt;&lt;span&gt;⇓&lt;/span&gt;&lt;/a&gt;–&lt;a href="#ref-20" id="xref-ref-20-1"&gt;20&lt;/a&gt;) to assess procedural fairness. Although these methods are invaluable, they offer an indirect view of officer behavior and are limited to a small number of interactions. Furthermore, the very presence of researchers may influence the police behavior those researchers seek to measure (&lt;a href="#ref-21" id="xref-ref-21-1"&gt;21&lt;/a&gt;).&lt;/p&gt;&lt;p id="p-15"&gt;In study 1, human participants rated officer utterances on several overlapping dimensions of respect. With a high degree of agreement, participants inferred these dimensions from officer language. Even though they were not told the race of the stopped driver, participants judged officer language directed toward black motorists to be less respectful than language directed toward whites. In study 2, we build statistical models capable of predicting aspects of respect based on linguistic features derived from theories of politeness, power, and social distance. We discuss the linguistic features that contribute to each model, finding that particular forms of politeness are implicated in perceptions of respect. In study 3, we apply these models to all vehicle stop interactions between officers of the Oakland Police Department and black/white community members during the month of April 2014. We find strong evidence that utterances spoken to white community members are consistently more respectful, even after controlling for contextual factors such as the severity of the offense or the outcome of the stop.&lt;/p&gt;&lt;div id="sec-1"&gt;&lt;h2&gt;Data&lt;/h2&gt;&lt;p id="p-16"&gt;Our dataset consists of transcribed body camera footage from vehicle stops of white and black community members conducted by the Oakland Police Department during the month of April 2014. We examined 981 stops of black (&lt;em&gt;N&lt;/em&gt; = 682) and white (&lt;em&gt;N&lt;/em&gt; = 299) drivers from this period, 68.1% of the 1,440 stops of white and black drivers in this period. These 981 stops were conducted by 245 different officers (see &lt;a href="http://www.pnas.org/lookup/suppl/doi:10.1073/pnas.1702413114/-/DCSupplemental/pnas.1702413114.sapp.pdf"&gt;&lt;em&gt;SI Appendix&lt;/em&gt;, &lt;em&gt;Data Sampling Process&lt;/em&gt;&lt;/a&gt; for inclusion criteria). Per Oakland Police Department policy, officers turn on their cameras before making contact with the driver and record for the duration of the stop. From the 183 h of footage in these interactions, we obtain 36,738 usable officer utterances for our analysis.&lt;/p&gt;&lt;div id="sec-2"&gt;&lt;h3&gt;Study 1: Perceptions of Officer Treatment from Language.&lt;/h3&gt;&lt;p id="p-17"&gt;We first test whether human raters can reliably judge respect from officers’ language, and whether these judgments reveal differences in officer respect toward black versus white community members.&lt;/p&gt;&lt;p id="p-18"&gt;Respect is a complex and gradient perception, incorporating elements of a number of correlated constructs like friendliness and formality. Therefore, in this study, we ask participants to rate transcribed utterances spoken by officers along five conceptually overlapping folk notions related to respect and officer treatment. We randomly sampled 414 unique officer utterances (1.1% of all usable utterances in the dataset) directed toward black (&lt;em&gt;N&lt;/em&gt; = 312) or white (&lt;em&gt;N&lt;/em&gt; = 102) community members. On each trial, participants viewed the text of an officer utterance, along with the driver’s utterance that immediately preceded it. All proper names and places were anonymized, and participants were not told the race or gender of the driver. Participants indicated on four-point Likert scales how respectful, polite, friendly, formal, and impartial the officer was in each exchange. Each utterance was rated by at least 10 participants.&lt;/p&gt;&lt;p id="p-19"&gt;Could participants reliably glean these qualities from such brief exchanges? Previous work has demonstrated that different perceivers can arrive at similar judgments from “thin slices” of behavior (&lt;a href="#ref-22" id="xref-ref-22-1"&gt;22&lt;/a&gt;). In a similar vein, participants showed consistency in their perceptions of officer language, with reliability for each item ranging from moderate (Cronbach’s &lt;span id="inline-formula-1"&gt;&lt;span&gt;α&lt;/span&gt;&lt;/span&gt; = 0.73) to high (&lt;span id="inline-formula-2"&gt;&lt;span&gt;α&lt;/span&gt;&lt;/span&gt; = 0.91) agreement (see &lt;a href="http://www.pnas.org/lookup/suppl/doi:10.1073/pnas.1702413114/-/DCSupplemental/pnas.1702413114.sapp.pdf"&gt;&lt;em&gt;SI Appendix&lt;/em&gt;, &lt;em&gt;Annotator Agreement&lt;/em&gt;&lt;/a&gt;). These results demonstrate that transcribed language provides a sufficient and consensual signal of officer communication, enough to gain a picture of the dynamics of an interaction at a given point in time.&lt;/p&gt;&lt;p id="p-20"&gt;To test whether participant ratings uncovered racial group differences, we averaged scores across raters to calculate a single rating on each dimension for each utterance, then built a linear mixed-effects regression model to estimate the fixed effect of community member race across interactions, controlling for variance of a random effect at the interaction level. Officer utterances directed toward black drivers were perceived as less respectful [&lt;em&gt;b&lt;/em&gt; = −0.23, 95% confidence interval (−0.34, −0.11)], polite [&lt;em&gt;b&lt;/em&gt; = −0.23 (−0.35, −0.12)], friendly [&lt;em&gt;b&lt;/em&gt; = −0.24 (−0.36, −0.12)], formal [&lt;em&gt;b&lt;/em&gt; = −0.16 (−0.30, −0.03)], and impartial [&lt;em&gt;b&lt;/em&gt; = −0.26 (−0.39, −0.12)] than language directed toward white drivers (&lt;a href="#F1" id="xref-fig-1-1"&gt;Fig. 1&lt;/a&gt;). These differences persisted even when controlling for the age and sex of the driver (see &lt;a href="http://www.pnas.org/lookup/suppl/doi:10.1073/pnas.1702413114/-/DCSupplemental/pnas.1702413114.sapp.pdf"&gt;&lt;em&gt;SI Appendix&lt;/em&gt;, &lt;em&gt;Model Outputs for Each Rated Dimension&lt;/em&gt;&lt;/a&gt;).&lt;/p&gt;&lt;div id="F1"&gt;&lt;div&gt;&lt;div&gt;&lt;p&gt;&lt;a data-hide-link-title="0" data-icon-position="" data-figure-caption="&lt;div class=&amp;quot;highwire-markup&amp;quot;&gt;&lt;div xmlns=&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;&gt;(&lt;em&gt;Left&lt;/em&gt;) Differences in raw participant ratings between interactions with black and white community members. (&lt;em&gt;Right&lt;/em&gt;) When collapsed to two uncorrelated components, Respect and Formality, we find a significant difference for Respect but none for Formality. Error bars represent 95% confidence intervals. PC, principal component.&lt;/div&gt;&lt;/div&gt;" rel="gallery-fragment-images-405739825" title="(Left) Differences in raw participant ratings between interactions with black and white community members. (Right) When collapsed to two uncorrelated components, Respect and Formality, we find a significant difference for Respect but none for Formality. Error bars represent 95% confidence intervals. PC, principal component." href="https://www.pnas.org/content/pnas/114/25/6521/F1.large.jpg?width=800&amp;amp;height=600&amp;amp;carousel=1"&gt;&lt;span&gt;&lt;img height="232" width="440" data-src="https://www.pnas.org/content/pnas/114/25/6521/F1.medium.gif" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="Fig. 1."&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;a data-hide-link-title="0" data-icon-position="" title="Download Fig. 1." href="https://www.pnas.org/content/pnas/114/25/6521/F1.large.jpg?download=true"&gt;Download figure&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a data-hide-link-title="0" data-icon-position="" href="https://www.pnas.org/content/pnas/114/25/6521/F1.large.jpg"&gt;Open in new tab&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a data-hide-link-title="0" data-icon-position="" href="https://www.pnas.org/highwire/powerpoint/19752"&gt;Download powerpoint&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;&lt;p&gt;&lt;span&gt;Fig. 1.&lt;/span&gt;&lt;/p&gt;&lt;p id="p-21"&gt;(&lt;em&gt;Left&lt;/em&gt;) Differences in raw participant ratings between interactions with black and white community members. (&lt;em&gt;Right&lt;/em&gt;) When collapsed to two uncorrelated components, Respect and Formality, we find a significant difference for Respect but none for Formality. Error bars represent 95% confidence intervals. PC, principal component.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;p id="p-22"&gt;Given the expected conceptual overlap in the five perceptual categories we presented to the participants, we used principal component analysis to decompose the ratings into their underlying components. Two principal components explained 93.2% of the variance in the data (see &lt;a href="http://www.pnas.org/lookup/suppl/doi:10.1073/pnas.1702413114/-/DCSupplemental/pnas.1702413114.sapp.pdf"&gt;&lt;em&gt;SI Appendix&lt;/em&gt;, &lt;em&gt;Principal Component Analysis (PCA) Loadings&lt;/em&gt;&lt;/a&gt; for loadings). The first component, explaining 71.3% of the variance and composed of positive loadings on the impartial, respectful, friendly, and polite dimensions with some loading on the formal dimension, we characterize as Respect, broadly construed. The second, explaining 21.9% of the variance and composed primarily of a very high positive loading on the formal dimension and a weak negative loading on the friendly dimension, we characterize as Formality. This component captures formality as distinct from respect more generally, and is likely related to social distance.&lt;/p&gt;&lt;p id="p-23"&gt;Standardizing these factor scores as outcome variables in mixed-effects models, we find that officers were equal in Formality with white and black drivers [&lt;span id="inline-formula-3"&gt;&lt;span&gt;β&lt;/span&gt;&lt;/span&gt; = −0.01 (−0.19, 0.16)], but higher in Respect with white drivers [&lt;span id="inline-formula-4"&gt;&lt;span&gt;β&lt;/span&gt;&lt;/span&gt; = 0.17 (0.00, 0.33)] (&lt;a href="#F1" id="xref-fig-1-2"&gt;Fig. 1&lt;/a&gt;).&lt;/p&gt;&lt;p id="p-24"&gt;Study 1 demonstrates that key features of police treatment can be reliably gleaned from officer speech. Participant ratings from thin slices of police–community interactions reveal racial disparities in how respectful, impartial, polite, friendly, and formal officers’ language to community members was perceived. Such differences were driven by differences in the Respect officers communicated toward drivers rather than the Formality with which officers addressed them.&lt;/p&gt;&lt;/div&gt;&lt;div id="sec-3"&gt;&lt;h3&gt;Study 2: Linguistic Correlates of Respect.&lt;/h3&gt;&lt;p id="p-25"&gt;The methods of study 1 (human coding of 414 individual utterances), although effective at discovering racial disparities in officer respect toward community members in our dataset, cannot offer a general solution to the analysis of body camera data. One problem is scale: Each year, on the order of 26 million vehicle stops are made (&lt;a href="#ref-5" id="xref-ref-5-2"&gt;5&lt;/a&gt;). Furthermore, using only a small sample of individual utterances makes it impossible to study how police treatment varies over officers, or how the interaction progresses across time in each stop.&lt;/p&gt;&lt;p id="p-26"&gt;In this study, we therefore develop computational linguistic models of respect and formality and tune them on the 414 individual utterances; in study 3, we apply these models to our full dataset of 36,738 utterances. Our method is based on linguistic theories of respect that model how speakers use respectful language (apologizing, giving agency, softening of commands, etc.) to mitigate “face-threatening acts.” We use computational linguistic methods (e.g., refs. &lt;a href="#ref-23" id="xref-ref-23-1"&gt;23&lt;/a&gt;&lt;a href="#ref-24" id="xref-ref-24-1"&gt;&lt;span&gt;⇓&lt;/span&gt;&lt;/a&gt;&lt;a href="#ref-25" id="xref-ref-25-1"&gt;&lt;span&gt;⇓&lt;/span&gt;&lt;/a&gt;–&lt;a href="#ref-26" id="xref-ref-26-1"&gt;26&lt;/a&gt;) to extract features of the language of each officer utterance. The log-transformed counts of these features are then used as independent variables in two linear regression models predicting the perceptual ratings of Respect and Formality from study 1.&lt;/p&gt;&lt;p id="p-27"&gt;Our model-assigned ratings agree with the average human from study 1 about as well as humans agree with each other. Our model for Respect obtains an adjusted &lt;em&gt;R&lt;/em&gt;&lt;sup&gt;2&lt;/sup&gt; of 0.258 on the perceptual ratings obtained in study 1, and a root-mean-square error (RMSE) of 0.840, compared with an RMSE of 0.842 for the average rater relative to other raters. Our model for Formality obtains an adjusted &lt;em&gt;R&lt;/em&gt;&lt;sup&gt;2&lt;/sup&gt; of 0.190, and an RMSE of 0.882 compared with 0.764 for the average rater (see &lt;a href="http://www.pnas.org/lookup/suppl/doi:10.1073/pnas.1702413114/-/DCSupplemental/pnas.1702413114.sapp.pdf"&gt;&lt;em&gt;SI Appendix&lt;/em&gt;, &lt;em&gt;Model Comparison to Annotators&lt;/em&gt;&lt;/a&gt; for more details on how these values were calculated). These results indicate that, despite the sophisticated social and psychological cues participants are likely drawing upon in rating officers’ utterances, a constrained set of objectively measurable linguistic features can explain a meaningful portion of the variance in these ratings.&lt;/p&gt;&lt;p id="p-28"&gt;&lt;a href="#F2" id="xref-fig-2-1"&gt;Fig. 2&lt;/a&gt; lists the linguistic features that received significant weights in our model of Respect (arranged by their model coefficients). For example, apologizing, gratitude, and expressions of concern for citizen safety are all associated with respect. The bars on the right show the log-odds of the relative proportion of interactions in our dataset taken up by each feature, where negative numbers mean that a feature comprised a larger proportion of officers’ speech in interactions with black community members and positive numbers mean the same for interactions with white community members. Example utterances containing instances of the highest-weighted features for the Respect model are shown in &lt;a href="#F3" id="xref-fig-3-1"&gt;Fig. 3&lt;/a&gt;. See &lt;a href="http://www.pnas.org/lookup/suppl/doi:10.1073/pnas.1702413114/-/DCSupplemental/pnas.1702413114.sapp.pdf"&gt;&lt;em&gt;SI Appendix&lt;/em&gt;, &lt;em&gt;Study 2&lt;/em&gt;&lt;/a&gt; for full regression outputs and more detailed discussion of particular linguistic findings.&lt;/p&gt;&lt;div id="F2"&gt;&lt;div&gt;&lt;div&gt;&lt;p&gt;&lt;a data-hide-link-title="0" data-icon-position="" data-figure-caption="&lt;div class=&amp;quot;highwire-markup&amp;quot;&gt;&lt;div xmlns=&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;&gt;(&lt;em&gt;Left&lt;/em&gt;) Respect weights assigned by final model to linguistic features and (&lt;em&gt;Right&lt;/em&gt;) the corresponding log-odds of those features occurring in officer speech directed toward black versus white community members, calculated using Fisher’s exact test. &lt;sup&gt;†&lt;/sup&gt;&lt;em&gt;P&lt;/em&gt; &lt; 0.1; &lt;sup&gt;∗&lt;/sup&gt;&lt;em&gt;P&lt;/em&gt; &lt; 0.05; &lt;sup&gt;∗∗&lt;/sup&gt;&lt;em&gt;P&lt;/em&gt; &lt; 0.01; &lt;sup&gt;∗∗∗&lt;/sup&gt;&lt;em&gt;P&lt;/em&gt; &lt; 0.001.&lt;/div&gt;&lt;/div&gt;" rel="gallery-fragment-images-405739825" title="(Left) Respect weights assigned by final model to linguistic features and (Right) the corresponding log-odds of those features occurring in officer speech directed toward black versus white community members, calculated using Fisher’s exact test. †P &lt; 0.1; ∗P &lt; 0.05; ∗∗P &lt; 0.01; ∗∗∗P &lt; 0.001." href="https://www.pnas.org/content/pnas/114/25/6521/F2.large.jpg?width=800&amp;amp;height=600&amp;amp;carousel=1"&gt;&lt;span&gt;&lt;img height="440" width="420" data-src="https://www.pnas.org/content/pnas/114/25/6521/F2.medium.gif" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="Fig. 2."&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;a data-hide-link-title="0" data-icon-position="" title="Download Fig. 2." href="https://www.pnas.org/content/pnas/114/25/6521/F2.large.jpg?download=true"&gt;Download figure&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a data-hide-link-title="0" data-icon-position="" href="https://www.pnas.org/content/pnas/114/25/6521/F2.large.jpg"&gt;Open in new tab&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a data-hide-link-title="0" data-icon-position="" href="https://www.pnas.org/highwire/powerpoint/19754"&gt;Download powerpoint&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;&lt;p&gt;&lt;span&gt;Fig. 2.&lt;/span&gt;&lt;/p&gt;&lt;p id="p-29"&gt;(&lt;em&gt;Left&lt;/em&gt;) Respect weights assigned by final model to linguistic features and (&lt;em&gt;Right&lt;/em&gt;) the corresponding log-odds of those features occurring in officer speech directed toward black versus white community members, calculated using Fisher’s exact test. &lt;sup&gt;†&lt;/sup&gt;&lt;em&gt;P&lt;/em&gt; &amp;lt; 0.1; &lt;sup&gt;∗&lt;/sup&gt;&lt;em&gt;P&lt;/em&gt; &amp;lt; 0.05; &lt;sup&gt;∗∗&lt;/sup&gt;&lt;em&gt;P&lt;/em&gt; &amp;lt; 0.01; &lt;sup&gt;∗∗∗&lt;/sup&gt;&lt;em&gt;P&lt;/em&gt; &amp;lt; 0.001.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id="F3"&gt;&lt;div&gt;&lt;div&gt;&lt;p&gt;&lt;a data-hide-link-title="0" data-icon-position="" data-figure-caption="&lt;div class=&amp;quot;highwire-markup&amp;quot;&gt;Sample sentences with automatically generated Respect scores. Features in blue have positive coefficients in the model and connote respect, such as offering reassurance (“no problem”) or mentioning community member well-being (“drive safe”). Features in red have negative coefficients in the model and connote disrespect, like informal titles (“my man”), or disfluencies (“that- that’s”).&lt;/div&gt;" rel="gallery-fragment-images-405739825" title="Sample sentences with automatically generated Respect scores. Features in blue have positive coefficients in the model and connote respect, such as offering reassurance (“no problem”) or mentioning community member well-being (“drive safe”). Features in red have negative coefficients in the model and connote disrespect, like informal titles (“my man”), or disfluencies (“that- that’s”)." href="https://www.pnas.org/content/pnas/114/25/6521/F3.large.jpg?width=800&amp;amp;height=600&amp;amp;carousel=1"&gt;&lt;span&gt;&lt;img height="440" width="321" data-src="https://www.pnas.org/content/pnas/114/25/6521/F3.medium.gif" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="Fig. 3."&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;a data-hide-link-title="0" data-icon-position="" title="Download Fig. 3." href="https://www.pnas.org/content/pnas/114/25/6521/F3.large.jpg?download=true"&gt;Download figure&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a data-hide-link-title="0" data-icon-position="" href="https://www.pnas.org/content/pnas/114/25/6521/F3.large.jpg"&gt;Open in new tab&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a data-hide-link-title="0" data-icon-position="" href="https://www.pnas.org/highwire/powerpoint/19756"&gt;Download powerpoint&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;&lt;p&gt;&lt;span&gt;Fig. 3.&lt;/span&gt;&lt;/p&gt;&lt;p id="p-30"&gt;Sample sentences with automatically generated Respect scores. Features in blue have positive coefficients in the model and connote respect, such as offering reassurance (“no problem”) or mentioning community member well-being (“drive safe”). Features in red have negative coefficients in the model and connote disrespect, like informal titles (“my man”), or disfluencies (“that- that’s”).&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id="sec-4"&gt;&lt;h3&gt;Study 3: Racial Disparities in Respect.&lt;/h3&gt;&lt;p id="p-31"&gt;Having demonstrated that people can reliably infer features of procedural justice from officer speech (study 1), and that these ratings can be reliably predicted from statistical models of linguistic features (study 2), we are now able to address our central question: Controlling for contextual factors of the interaction, is officers’ language more respectful when speaking to white as opposed to black community members?&lt;/p&gt;&lt;p id="p-32"&gt;We apply our models from study 2 to the entire corpus of transcribed interactions to generate predicted scores for Respect and Formality for each of the 36,738 utterances in our dataset. We then build linear mixed-effects models for Respect and Formality over these utterances. We include, as covariates in our primary model, community member race, age, and gender; officer race; whether a search was conducted; and the result of the stop (warning, citation, or arrest). We include random intercepts for interactions nested within officers.&lt;/p&gt;&lt;p id="p-33"&gt;Controlling for these contextual factors, utterances spoken by officers to white community members score higher in Respect [&lt;span id="inline-formula-5"&gt;&lt;span&gt;β&lt;/span&gt;&lt;/span&gt; = 0.05 (0.03, 0.08)]. Officer utterances were also higher in Respect when spoken to older [&lt;span id="inline-formula-6"&gt;&lt;span&gt;β&lt;/span&gt;&lt;/span&gt; = 0.07 (0.05, 0.09)] community members and when a citation was issued [&lt;span id="inline-formula-7"&gt;&lt;span&gt;β&lt;/span&gt;&lt;/span&gt; = 0.04 (0.02, 0.06)]; Respect was lower in stops where a search was conducted [&lt;span id="inline-formula-8"&gt;&lt;span&gt;β&lt;/span&gt;&lt;/span&gt; = −0.08 (−0.11, −0.05)]. Officer race did not contribute a significant effect. Furthermore, in an additional model on 965 stops for which geographic information was available, neither the crime rate nor density of businesses in the area of the stop were significant, although a higher crime rate was indicative of increased Formality [&lt;span id="inline-formula-9"&gt;&lt;span&gt;β&lt;/span&gt;&lt;/span&gt; = 0.03 (0.01, 0.05)].&lt;/p&gt;&lt;p id="p-34"&gt;One might consider the hypothesis that officers were less respectful when pulling over community members for more severe offenses. We tested this by running another model on a subset of 869 interactions for which we obtained ratings of offense severity on a four-point Likert scale from Oakland Police Department officers, including these ratings as a covariate in addition to those mentioned above. We found that the offense severity was not predictive of officer respect levels, and did not substantially change the results described above.&lt;/p&gt;&lt;p id="p-35"&gt;To consider whether this disparity persists in the most “everyday” interactions, we also reran our analyses on the subset of interactions that did not involve arrests or searches (&lt;em&gt;N&lt;/em&gt; = 781), and found the results from our earlier models were fundamentally unchanged. Full regression tables for all models described above are given in &lt;a href="http://www.pnas.org/lookup/suppl/doi:10.1073/pnas.1702413114/-/DCSupplemental/pnas.1702413114.sapp.pdf"&gt;&lt;em&gt;SI Appendix&lt;/em&gt;, &lt;em&gt;Study 3&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p id="p-36"&gt;Another hypothesis is that the racial disparities might have been caused by officers being more formal to white community members, and more informal or colloquial to black community members. However, we found that race was not associated with the formality of officers’ utterances. Instead, utterances were higher in Formality in interactions with older [&lt;span id="inline-formula-10"&gt;&lt;span&gt;β&lt;/span&gt;&lt;/span&gt; = 0.05 (0.03, 0.07)] and female [&lt;span id="inline-formula-11"&gt;&lt;span&gt;β&lt;/span&gt;&lt;/span&gt; = 0.02 (0.00, 0.04)] community members.&lt;/p&gt;&lt;p id="p-37"&gt;Are the racial disparities in the respectfulness of officer speech we observe driven by a small number of officers? We calculated the officer-level difference between white and black stops for every officer (&lt;em&gt;N&lt;/em&gt; = 90) in the dataset who had interactions with both blacks and whites (&lt;a href="#F4" id="xref-fig-4-1"&gt;Fig. 4&lt;/a&gt;). We find a roughly normal distribution of these deltas for officers of all races. This contrasts with the case of stop-and-frisk, where individual outlier officers account for a substantial proportion of racial disparities (&lt;a href="#ref-27" id="xref-ref-27-1"&gt;27&lt;/a&gt;); the disparities we observe here cannot be explained by a small number of extreme officers.&lt;/p&gt;&lt;div id="F4"&gt;&lt;div&gt;&lt;div&gt;&lt;p&gt;&lt;a data-hide-link-title="0" data-icon-position="" data-figure-caption="&lt;div class=&amp;quot;highwire-markup&amp;quot;&gt;&lt;div xmlns=&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;&gt;Kernel density estimate of individual officer-level differences in Respect when talking to white as opposed to black community members, for the 90 officers in our dataset who have interactions with both blacks and whites. More positive numbers on the &lt;em&gt;x&lt;/em&gt; axis represent a greater positive shift in Respect toward white community members.&lt;/div&gt;&lt;/div&gt;" rel="gallery-fragment-images-405739825" title="Kernel density estimate of individual officer-level differences in Respect when talking to white as opposed to black community members, for the 90 officers in our dataset who have interactions with both blacks and whites. More positive numbers on the x axis represent a greater positive shift in Respect toward white community members." href="https://www.pnas.org/content/pnas/114/25/6521/F4.large.jpg?width=800&amp;amp;height=600&amp;amp;carousel=1"&gt;&lt;span&gt;&lt;img height="166" width="440" data-src="https://www.pnas.org/content/pnas/114/25/6521/F4.medium.gif" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="Fig. 4."&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;a data-hide-link-title="0" data-icon-position="" title="Download Fig. 4." href="https://www.pnas.org/content/pnas/114/25/6521/F4.large.jpg?download=true"&gt;Download figure&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a data-hide-link-title="0" data-icon-position="" href="https://www.pnas.org/content/pnas/114/25/6521/F4.large.jpg"&gt;Open in new tab&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a data-hide-link-title="0" data-icon-position="" href="https://www.pnas.org/highwire/powerpoint/19758"&gt;Download powerpoint&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;&lt;p&gt;&lt;span&gt;Fig. 4.&lt;/span&gt;&lt;/p&gt;&lt;p id="p-38"&gt;Kernel density estimate of individual officer-level differences in Respect when talking to white as opposed to black community members, for the 90 officers in our dataset who have interactions with both blacks and whites. More positive numbers on the &lt;em&gt;x&lt;/em&gt; axis represent a greater positive shift in Respect toward white community members.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;p id="p-39"&gt;Because our model is able to generate scores across all utterances in our dataset, we can also consider aspects of the trajectory of interactions beyond the mean level of respect (&lt;a href="#F5" id="xref-fig-5-1"&gt;Fig. 5&lt;/a&gt;). Growth-curve analyses revealed that officers spoke with greater Respect [&lt;span id="inline-formula-12"&gt;&lt;span&gt;b&lt;/span&gt;&lt;/span&gt; = 0.35 (0.29, 0.40)] and reduced Formality [&lt;span id="inline-formula-13"&gt;&lt;span&gt;b&lt;/span&gt;&lt;/span&gt; = −0.57 (−0.62, −0.53)] as interactions progressed. However, these trajectories varied by community member race: Although stops of white and black drivers converged in the Formality expressed during the interaction [&lt;span id="inline-formula-14"&gt;&lt;span&gt;b&lt;/span&gt;&lt;/span&gt; = −0.09 (−0.13, −0.05)], the gap in Respect increased over time [&lt;span id="inline-formula-15"&gt;&lt;span&gt;b&lt;/span&gt;&lt;/span&gt; = 0.10 (0.05, 0.15)]. That is, officer Respect increased more quickly in interactions with white drivers [&lt;span id="inline-formula-16"&gt;&lt;span&gt;b&lt;/span&gt;&lt;/span&gt; = 0.45 (0.38, 0.54)] than in interactions with black drivers [&lt;span id="inline-formula-17"&gt;&lt;span&gt;b&lt;/span&gt;&lt;/span&gt; =  0.24 (0.19, 0.29)].&lt;/p&gt;&lt;div id="F5"&gt;&lt;div&gt;&lt;div&gt;&lt;p&gt;&lt;a data-hide-link-title="0" data-icon-position="" data-figure-caption="&lt;div class=&amp;quot;highwire-markup&amp;quot;&gt;&lt;div xmlns=&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;&gt;Loess-smoothed estimates of the (&lt;em&gt;Left&lt;/em&gt;) Respect and (&lt;em&gt;Right&lt;/em&gt;) Formality of officers’ utterances relative to the point in an interaction at which they occur. Respect tends to start low and increase over an interaction, whereas the opposite is true for Formality. The race discrepancy in Respect is consistent throughout the interactions in our dataset.&lt;/div&gt;&lt;/div&gt;" rel="gallery-fragment-images-405739825" title="Loess-smoothed estimates of the (Left) Respect and (Right) Formality of officers’ utterances relative to the point in an interaction at which they occur. Respect tends to start low and increase over an interaction, whereas the opposite is true for Formality. The race discrepancy in Respect is consistent throughout the interactions in our dataset." href="https://www.pnas.org/content/pnas/114/25/6521/F5.large.jpg?width=800&amp;amp;height=600&amp;amp;carousel=1"&gt;&lt;span&gt;&lt;img height="127" width="440" data-src="https://www.pnas.org/content/pnas/114/25/6521/F5.medium.gif" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="Fig. 5."&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;a data-hide-link-title="0" data-icon-position="" title="Download Fig. 5." href="https://www.pnas.org/content/pnas/114/25/6521/F5.large.jpg?download=true"&gt;Download figure&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a data-hide-link-title="0" data-icon-position="" href="https://www.pnas.org/content/pnas/114/25/6521/F5.large.jpg"&gt;Open in new tab&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a data-hide-link-title="0" data-icon-position="" href="https://www.pnas.org/highwire/powerpoint/19760"&gt;Download powerpoint&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;&lt;p&gt;&lt;span&gt;Fig. 5.&lt;/span&gt;&lt;/p&gt;&lt;p id="p-40"&gt;Loess-smoothed estimates of the (&lt;em&gt;Left&lt;/em&gt;) Respect and (&lt;em&gt;Right&lt;/em&gt;) Formality of officers’ utterances relative to the point in an interaction at which they occur. Respect tends to start low and increase over an interaction, whereas the opposite is true for Formality. The race discrepancy in Respect is consistent throughout the interactions in our dataset.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id="sec-5"&gt;&lt;h3&gt;Discussion.&lt;/h3&gt;&lt;p id="p-41"&gt;Despite the formative role officer respect plays in establishing or eroding police legitimacy (&lt;a href="#ref-7" id="xref-ref-7-2"&gt;7&lt;/a&gt;), it has been impossible to measure how police officers communicate with the public, let alone gauge racial disparities in officer respect. However, body-worn cameras capture such interactions every day. Computational linguistic techniques let us examine police–community contacts in a manner powerful enough to scale to any number of interactions, but sensitive enough to capture the interpersonal qualities that matter to the police and public alike.&lt;/p&gt;&lt;p id="p-42"&gt;In doing so, we first showed that people make consistent judgments about such interactions from officers’ language, and we identified two underlying, uncorrelated constructs perceived by participants: Respect and Formality. We then built computational linguistic models of these constructs, identifying crucial positive and negative politeness strategies in the police–community interactional context. Applying these models to an entire month of vehicle stops, we showed strong evidence for racial disparities in Respect, but not in Formality: Officers’ language is less respectful when speaking to black community members.&lt;/p&gt;&lt;p id="p-43"&gt;Indeed, we find that white community members are 57% more likely to hear an officer say one of the most respectful utterances in our dataset, whereas black community members are 61% more likely to hear an officer say one of the least respectful utterances in our dataset. (Here we define the top 10% of utterances to be most respectful and the bottom 10% to be least respectful.)&lt;/p&gt;&lt;p id="p-44"&gt;This work demonstrates the power of body camera footage as an important source of data, not just as evidence, addressing limitations with methodologies that rely on citizens’ recollection of past interactions (&lt;a href="#ref-10" id="xref-ref-10-3"&gt;10&lt;/a&gt;) or direct researcher observation of police behavior (&lt;a href="#ref-17" id="xref-ref-17-2"&gt;17&lt;/a&gt;&lt;a href="#ref-18" id="xref-ref-18-2"&gt;&lt;span&gt;⇓&lt;/span&gt;&lt;/a&gt;&lt;a href="#ref-19" id="xref-ref-19-2"&gt;&lt;span&gt;⇓&lt;/span&gt;&lt;/a&gt;–&lt;a href="#ref-20" id="xref-ref-20-2"&gt;20&lt;/a&gt;). However, studying body camera footage presents numerous hurdles, including privacy concerns and the raw scale of the data. The computational linguistic models presented here offer a path toward addressing both these concerns, allowing for the analysis of transcribed datasets of any size, and generating reliable ratings of respect automatically. These models have the potential to allow for useful information about an interaction to be extracted while maintaining officer and community member privacy.&lt;/p&gt;&lt;p id="p-45"&gt;The racial disparities in officer respect are clear and consistent, yet the causes of these disparities are less clear. It is certainly possible that some of these disparities are prompted by the language and behavior of the community members themselves, particularly as historical tensions in Oakland and preexisting beliefs about the legitimacy of the police may induce fear, anger, or stereotype threat. However, community member speech cannot be the sole cause of these disparities. Study 1 found racial disparities in police language even when annotators judged that language in the context of the community member’s utterances. We observe racial disparities in officer respect even in police utterances from the initial 5% of an interaction, suggesting that officers speak differently to community members of different races even before the driver has had the opportunity to say much at all.&lt;/p&gt;&lt;p id="p-46"&gt;Regardless of cause, we have found that police officers’ interactions with blacks tend to be more fraught, not only in terms of disproportionate outcomes (as previous work has shown) but also interpersonally, even when no arrest is made and no use of force occurs. These disparities could have adverse downstream effects, as experiences of respect or disrespect in personal interactions with police officers play a central role in community members’ judgments of how procedurally fair the police are as an institution, as well as the community’s willingness to support or cooperate with the police (&lt;a href="#ref-8" id="xref-ref-8-2"&gt;8&lt;/a&gt;, &lt;a href="#ref-9" id="xref-ref-9-2"&gt;9&lt;/a&gt;).&lt;/p&gt;&lt;p id="p-47"&gt;We now have a method for quantifying these troubled interactions. Although the circumstances of any particular stop can vary dramatically, our approach allows us to measure aggregate department-level trends, revealing disparities across hundreds of interactions. These disparities are part of a constellation of differences in officer language spoken toward black versus white community members; a simple classifier trained on only the words used by officers is able to correctly predict the race of the community member in over two thirds of the interactions (see &lt;a href="http://www.pnas.org/lookup/suppl/doi:10.1073/pnas.1702413114/-/DCSupplemental/pnas.1702413114.sapp.pdf"&gt;&lt;em&gt;SI Appendix&lt;/em&gt;, &lt;em&gt;Linguistic Classification Accuracy of Race&lt;/em&gt;&lt;/a&gt;).&lt;/p&gt;&lt;p id="p-48"&gt;Future research could expand body camera analysis beyond text to include information from the audio such as speech intonation and emotional prosody, and video, such as the citizen’s facial expressions and body movement, offering even more insight into how interactions progress and can sometimes go awry. In addition, footage analysis could help us better understand what linguistic acts lead interactions to go well, which can inform police training and quantify its impacts over time.&lt;/p&gt;&lt;p id="p-49"&gt;The studies presented here open a path toward these future opportunities and represent an important area of research for the study of policing: Computational, large-scale analyses of language give us a way to examine and improve police–community interaction that we have never had before.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id="sec-6"&gt;&lt;h2&gt;Materials and Methods&lt;/h2&gt;&lt;div id="sec-7"&gt;&lt;h3&gt;Data and Processing.&lt;/h3&gt;&lt;p id="p-50"&gt;The video for each traffic stop was transcribed into text by professional transcribers, who transcribed while listening to audio and watching the video. Extensive measures were taken to preserve privacy; data were kept on a central server, and transcribers (as well as all researchers) underwent background checks with the Oakland Police Department. Transcribers also “diarized” the text (labeling who was speaking at each time point). We used the diarization to automatically remove all officer speech to the dispatcher or to other officers, leaving only speech from the officer directed toward the community member. After transcription, transcripts were manually cleaned up, heuristically fixing transcriber diarization errors, and correcting typographical errors involving utterance timing so that all transcripts were automatically readable. Every utterance in the dataset was processed with Stanford CoreNLP 3.4.1 (&lt;a href="#ref-28" id="xref-ref-28-1"&gt;28&lt;/a&gt;) to generate sentence and word segmentation, part-of-speech tags, and dependency parses used for feature extraction and analysis.&lt;/p&gt;&lt;p id="p-51"&gt;The raw video footage associated with this paper was available for our research purposes with the cooperation of the Oakland Police Department, and naturally cannot be publicly distributed. However, we make available deidentified data frames for each study described here, so that other researchers can replicate our results. We also release all of the code for the computational linguistic models, as well as pretrained models that can be run on arbitrary text.&lt;/p&gt;&lt;/div&gt;&lt;div id="sec-8"&gt;&lt;h3&gt;Human Annotation of Utterances.&lt;/h3&gt;&lt;p id="p-52"&gt;A subset of 420 exchanges, consisting of one officer utterance (defined as a “turn” of one or more sentences by transcribers) and, if applicable, the immediately preceding community member utterance were sampled from the corpus for annotation. Utterances were sampled with the constraint that at least 15 words were spoken between the two speakers, and that at least five words were spoken by the officer. These utterances were grouped into seven “batches” of 60 utterances apiece. Due to a data error, six duplicate utterances were annotated, but were excluded from subsequent analyses, resulting in 414 unique utterances toward black (&lt;em&gt;N&lt;/em&gt; = 312) and white (&lt;em&gt;N&lt;/em&gt; = 102) community members.&lt;/p&gt;&lt;p id="p-53"&gt;Each of 70 participants (39 female, &lt;span id="inline-formula-18"&gt;&lt;span&gt;Mage&lt;/span&gt;&lt;/span&gt; = 25.3) rated a batch of 60 of these utterances, such that each utterance was rated by at least 10 participants. On each trial, participants viewed the text of an exchange between a police officer and a community member: the text of the officer utterance, as well as the text of the community member utterance that immediately preceded it, if there was one. They then indicated, on four-point bipolar Likert scales, how respectful, polite, friendly, formal, and impartial the officer was in each exchange. Participants were allowed to indicate that they could not rate an utterance on a particular dimension, but were encouraged to nonetheless indicate their best guess. Participants had no other information about the interaction besides the officer’s utterance and the immediately preceding community member utterance.&lt;/p&gt;&lt;p id="p-54"&gt;All research was approved by the Stanford University Institutional Review Board, and written informed consent was obtained from all raters before their participation.&lt;/p&gt;&lt;/div&gt;&lt;div id="sec-9"&gt;&lt;h3&gt;Computational Annotation of Utterances.&lt;/h3&gt;&lt;p id="p-55"&gt;Our model draws on linguistic theories of politeness; the technical term “politeness” refers to how concepts like respect, formality, and social distance take shape in language. These theories suggest that speakers use polite or respectful language to mitigate face-threatening acts (&lt;a href="#ref-29" id="xref-ref-29-1"&gt;29&lt;/a&gt;&lt;a href="#ref-30" id="xref-ref-30-1"&gt;&lt;span&gt;⇓&lt;/span&gt;&lt;/a&gt;–&lt;a href="#ref-31" id="xref-ref-31-1"&gt;31&lt;/a&gt;).&lt;/p&gt;&lt;p id="p-56"&gt;Negative politeness is used to mitigate direct commands or other impositions that limit the freedom of action of the listener, for example, by minimizing the imposition or emphasizing the agency of the interlocutor. Such strategies are central to police–community interactions because of the inherently coercive nature of a traffic stop. For instance, the use of the word “please” can soften requests and provide a sense of agency or choice; apologizing (“sorry,” “excuse me”) can admit regret on the part of the officer that some request is necessary; the use of hedges (“may,” “kinda,” “probably”) may reduce the perception of imposition.&lt;/p&gt;&lt;p id="p-57"&gt;Positive politeness is used to show that the speaker values the interlocutor and their interests, or to minimize the impact of actions that could damage such a perception. Positive politeness strategies are also crucial for police–community interactions, where the inherently unequal social roles at play may necessitate a particular sensitivity to the community member’s positive face. For instance, greetings and introductions can establish a friendly context at the beginning of an interaction and convey openness. Expressions of reassurance (“no big deal,” “don’t worry”) seek to assuage the community member’s potential concerns in tense circumstances, and expressions of gratitude (“thank you”) serve to reduce the perceived power differential by deferring to the actions of the community member. Mentions of safety (“Drive safely now”) explicitly acknowledge concern for the community member’s personal well-being. Referring expressions are another important component of positive politeness; formal titles (“sir,” “ma’am,” “Mr.,” “Ms.”) and surnames may convey a contrast with informal titles (“dude,” “bro,” “bud”) and first names (&lt;a href="#ref-31" id="xref-ref-31-2"&gt;31&lt;/a&gt;&lt;a href="#ref-32" id="xref-ref-32-1"&gt;&lt;span&gt;⇓&lt;/span&gt;&lt;/a&gt;–&lt;a href="#ref-33" id="xref-ref-33-1"&gt;33&lt;/a&gt;).&lt;/p&gt;&lt;p id="p-58"&gt;We also include features we expect to capture officer anxiety, such as speech disfluencies (“w- well”) and commands to keep “hands on the wheel,” which may contribute to a community member’s perception of disrespect. These are of a different character than the politeness strategies discussed above, but we found that all analyses presented here hold true even if these features are not included.&lt;/p&gt;&lt;p id="p-59"&gt;We use standard techniques to automatically extract features from the text of each utterance (&lt;a href="#ref-23" id="xref-ref-23-2"&gt;23&lt;/a&gt;&lt;a href="#ref-24" id="xref-ref-24-2"&gt;&lt;span&gt;⇓&lt;/span&gt;&lt;/a&gt;&lt;a href="#ref-25" id="xref-ref-25-2"&gt;&lt;span&gt;⇓&lt;/span&gt;&lt;/a&gt;–&lt;a href="#ref-26" id="xref-ref-26-2"&gt;26&lt;/a&gt;). These features include lexicons (lists of words). For example, to detect informal titles, we used an augmented version of a word list from ref. &lt;a href="#ref-34" id="xref-ref-34-1"&gt;34&lt;/a&gt;. We also used regular expressions, such as for detecting tag questions (“do that for me, will you?”), and syntactic parse features, such as a feature that detects when “just” is used in constructions as an adverbial modifier.&lt;/p&gt;&lt;p id="p-60"&gt;Features were modeled as log-transformed counts in each utterance, and were used as independent variables in two linear regression models predicting the human perceptual ratings of respect and formality obtained in study 1. They were introduced into the regression using stepwise forward selection by &lt;em&gt;R&lt;/em&gt;&lt;sup&gt;2&lt;/sup&gt; to remove features that don’t substantially contribute to the model’s accuracy.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id="ack-1"&gt;&lt;h2&gt;Acknowledgments&lt;/h2&gt;&lt;p id="p-61"&gt;This research was supported by the John D. and Catherine T. MacArthur Foundation, with additional support from the Stanford Institute for Research in the Social Sciences, the Stanford School of Humanities and Sciences, and the Stanford Data Science Initiative. We also thank the City of Oakland and the Oakland Police Department for their support and cooperation.&lt;/p&gt;&lt;/div&gt;&lt;div id="fn-group-1"&gt;&lt;h2&gt;Footnotes&lt;/h2&gt;&lt;ul&gt;&lt;li id="fn-2"&gt;&lt;p id="p-2"&gt;Author contributions: R.V., N.P.C., D. Jurafsky, and J.L.E. designed research; R.V. and N.P.C. performed research; V.P., W.L.H., R.C.H., C.M.G., and D. Jurgens contributed new reagents/analytic tools; R.V. and N.P.C. analyzed data; R.V., N.P.C., D. Jurafsky, and J.L.E. wrote the paper; and D. Jurafsky and J.L.E. served as PI on this project.&lt;/p&gt;&lt;/li&gt;&lt;li id="fn-3"&gt;&lt;p id="p-3"&gt;Reviewers: J.P., University of Texas at Austin; and T.T., Yale Law School.&lt;/p&gt;&lt;/li&gt;&lt;li id="fn-4"&gt;&lt;p id="p-62"&gt;Conflict of interest statement: J.L.E. was invited by a federal judge and monitor to serve as a Subject Matter Expert to assist with the Oakland Police Department’s reform efforts. The assignment began prior to the studies reported here.&lt;/p&gt;&lt;/li&gt;&lt;li id="fn-5"&gt;&lt;p id="p-63"&gt;This article contains supporting information online at &lt;a href="http://www.pnas.org/lookup/suppl/doi:10.1073/pnas.1702413114/-/DCSupplemental"&gt;www.pnas.org/lookup/suppl/doi:10.1073/pnas.1702413114/-/DCSupplemental&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;&lt;a data-hide-link-title="0" data-icon-position="" href="https://www.pnas.org/content/114/25/6521.abstract"&gt;View Abstract&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;


&lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;&lt;a href="https://www.pnas.org/content/114/25/6521"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Fri, 12 Jun 2020 12:04:00 UT
      </pubDate>
      <guid>
        https://www.pnas.org/content/114/25/6521
      </guid>
    </item>
    <item>
      <title>
        A Survival Guide to a PhD
      </title>
      <link>
        https://karpathy.github.io/2016/09/07/phd/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;article&gt;
  &lt;p&gt;This guide is patterned after my &lt;a href="http://cs.stanford.edu/people/karpathy/advice.html"&gt;“Doing well in your courses”&lt;/a&gt;, a post I wrote a long time ago on some of the tips/tricks I’ve developed during my undergrad. I’ve received nice comments about that guide, so in the same spirit, now that my PhD has come to an end I wanted to compile a similar retrospective document in hopes that it might be helpful to some. Unlike the undergraduate guide, this one was much more difficult to write because there is significantly more variation in how one can traverse the PhD experience. Therefore, many things are likely contentious and a good fraction will be specific to what I’m familiar with (Computer Science / Machine Learning / Computer Vision research). But disclaimers are boring, lets get to it!&lt;/p&gt;

&lt;h3 id="preliminaries"&gt;Preliminaries&lt;/h3&gt;

&lt;p&gt;&lt;img src="https://karpathy.github.io/assets/phd/phds.jpg"&gt;
&lt;/p&gt;

&lt;p&gt;First, should you want to get a PhD? I was in a fortunate position of knowing since young age that I really wanted a PhD. Unfortunately it wasn’t for any very well-thought-through considerations: First, I really liked school and learning things and I wanted to learn as much as possible, and second, I really wanted to be like &lt;a href="https://en.wikipedia.org/wiki/Gordon_Freeman"&gt;Gordon Freeman&lt;/a&gt; from the game Half-Life (who has a PhD from MIT in theoretical physics). I loved that game. But what if you’re more sensible in making your life’s decisions? Should you want to do a PhD? There’s a very nice &lt;a href="https://www.quora.com/I-got-a-job-offer-from-Google-Facebook-Microsoft-and-I-also-got-accepted-into-the-PhD-in-Computer-Science-program-at-MIT-Stanford-Berkeley-What-factors-should-I-consider-while-making-a-choice-between-the-two"&gt;Quora thread&lt;/a&gt; and in the summary of considerations that follows I’ll borrow/restate several from Justin/Ben/others there. I’ll assume that the second option you are considering is joining a medium-large company (which is likely most common). Ask yourself if you find the following properties appealing:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Freedom.&lt;/strong&gt; A PhD will offer you a lot of freedom in the topics you wish to pursue and learn about. You’re in charge. Of course, you’ll have an adviser who will impose some constraints but in general you’ll have much more freedom than you might find elsewhere.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Ownership.&lt;/strong&gt; The research you produce will be yours as an individual. Your accomplishments will have your name attached to them. In contrast, it is much more common to “blend in” inside a larger company. A common feeling here is becoming a “cog in a wheel”.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Exclusivity&lt;/strong&gt;. There are very few people who make it to the top PhD programs. You’d be joining a group of a few hundred distinguished individuals in contrast to a few tens of thousands (?) that will join some company.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Status.&lt;/strong&gt; Regardless of whether it should be or not, working towards and eventually getting a PhD degree is culturally revered and recognized as an impressive achievement. You also get to be a Doctor; that’s awesome.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Personal freedom.&lt;/strong&gt; As a PhD student you’re your own boss. Want to sleep in today? Sure. Want to skip a day and go on a vacation? Sure. All that matters is your final output and no one will force you to clock in from 9am to 5pm. Of course, some advisers might be more or less flexible about it and some companies might be as well, but it’s a true first order statement.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Maximizing future choice.&lt;/strong&gt; Joining a PhD program doesn’t close any doors or eliminate future employment/lifestyle options. You can go one way (PhD -&amp;gt; anywhere else) but not the other (anywhere else -&amp;gt; PhD -&amp;gt; academia/research; it is statistically less likely). Additionally (although this might be quite specific to applied ML), you’re strictly more hirable as a PhD graduate or even as a PhD dropout and many companies might be willing to put you in a more interesting position or with a higher starting salary. More generally, maximizing choice for the future you is a good heuristic to follow.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Maximizing variance.&lt;/strong&gt; You’re young and there’s really no need to rush. Once you graduate from a PhD you can spend the next ~50 years of your life in some company. Opt for more variance in your experiences.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Personal growth.&lt;/strong&gt; PhD is an intense experience of rapid growth (you learn a lot) and personal self-discovery (you’ll become a master of managing your own psychology). PhD programs (especially if you can make it into a good one) also offer a &lt;em&gt;high density&lt;/em&gt; of exceptionally bright people who will become your best friends forever.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Expertise.&lt;/strong&gt; PhD is probably your only opportunity in life to really drill deep into a topic and become a recognized leading expert &lt;em&gt;in the world&lt;/em&gt; at something. You’re exploring the edge of our knowledge as a species, without the burden of lesser distractions or constraints. There’s something beautiful about that and if you disagree, it could be a sign that PhD is not for you.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The disclaimer&lt;/strong&gt;. I wanted to also add a few words on some of the potential downsides and failure modes. The PhD is a very specific kind of experience that deserves a large disclaimer. You will inevitably find yourself working very hard (especially before paper deadlines). You need to be okay with the suffering and have enough mental stamina and determination to deal with the pressure. At some points you will lose track of what day of the week it is and go on a diet of leftover food from the microkitchens. You’ll sit exhausted and alone in the lab on a beautiful, sunny Saturday scrolling through Facebook pictures of your friends having fun on exotic trips, paid for by their 5-10x larger salaries. You will have to throw away 3 months of your work while somehow keeping your mental health intact. You’ll struggle with the realization that months of your work were spent on a paper with a few citations while your friends do exciting startups with TechCrunch articles or push products to millions of people. You’ll experience identity crises during which you’ll question your life decisions and wonder what you’re doing with some of the best years of your life. As a result, you should be quite certain that you can thrive in an unstructured environment in the pursuit research and discovery for science. If you’re unsure you should lean slightly negative by default. Ideally you should consider getting a taste of research as an undergraduate on a summer research program before before you decide to commit. In fact, one of the primary reasons that research experience is so desirable during the PhD hiring process is not the research itself, but the fact that the student is more likely to know what they’re getting themselves into.&lt;/p&gt;

&lt;p&gt;I should clarify explicitly that this post is not about convincing anyone to do a PhD, I’ve merely tried to enumerate some of the common considerations above. The majority of this post focuses on some tips/tricks for navigating the experience once if you decide to go for it (which we’ll see shortly, below).&lt;/p&gt;

&lt;p&gt;Lastly, as a random thought I heard it said that you should only do a PhD if you want to go into academia. In light of all of the above I’d argue that a PhD has strong intrinsic value - it’s an end by itself, not just a means to some end (e.g. academic job).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Getting into a PhD program: references, references, references.&lt;/strong&gt; Great, you’ve decided to go for it. Now how do you get into a good PhD program? The first order approximation is quite simple - by far most important component are strong reference letters. The ideal scenario is that a well-known professor writes you a letter along the lines of: “Blah is in top 5 of students I’ve ever worked with. She takes initiative, comes up with her own ideas, and gets them to work.” The worst letter is along the lines of: “Blah took my class. She did well.” A research publication under your belt from a summer research program is a very strong bonus, but not absolutely required provided you have strong letters. In particular note: grades are quite irrelevant but you generally don’t want them to be too low. This was not obvious to me as an undergrad and I spent a lot of energy on getting good grades. This time should have instead been directed towards research (or at the very least personal projects), as much and as early as possible, and if possible under supervision of multiple people (you’ll need 3+ letters!). As a last point, what won’t help you too much is pestering your potential advisers out of the blue. They are often incredibly busy people and if you try to approach them too aggressively in an effort to impress them somehow in conferences or over email this may agitate them.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Picking the school&lt;/strong&gt;. Once you get into some PhD programs, how do you pick the school? It’s easy, join Stanford! Just kidding. More seriously, your dream school should 1) be a top school (not because it looks good on your resume/CV but because of feedback loops; top schools attract other top people, many of whom you will get to know and work with) 2) have a few potential advisers you would want to work with. I really do mean the “few” part - this is very important and provides a safety cushion for you if things don’t work out with your top choice for any one of hundreds of reasons - things in many cases outside of your control, e.g. your dream professor leaves, moves, or spontaneously disappears, and 3) be in a good environment physically. I don’t think new admits appreciate this enough: you will spend 5+ years of your really good years living near the school campus. Trust me, this is a long time and your life will consist of much more than just research.&lt;/p&gt;

&lt;h3 id="adviser"&gt;Adviser&lt;/h3&gt;

&lt;div&gt;
&lt;p&gt;&lt;img src="https://karpathy.github.io/assets/phd/adviser.gif"&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Student adviser relationship&lt;/strong&gt;. The adviser is an extremely important person who will exercise a lot of influence over your PhD experience. It’s important to understand the nature of the relationship: the adviser-student relationship is a symbiosis; you have your own goals and want something out of your PhD, but they also have their own goals, constraints and they’re building their own career. Therefore, it is very helpful to understand your adviser’s incentive structures: how the tenure process works, how they are evaluated, how they get funding, how they fund you, what department politics they might be embedded in, how they win awards, how academia in general works and specifically how they gain recognition and respect of their colleagues. This alone will help you avoid or mitigate a large fraction of student-adviser friction points and allow you to plan appropriately. I also don’t want to make the relationship sound too much like a business transaction. The advisor-student relationship, more often that not, ends up developing into a lasting one, predicated on much more than just career advancement.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Pre-vs-post tenure&lt;/strong&gt;. Every adviser is different so it’s helpful to understand the axes of variations and their repercussions on your PhD experience. As one rule of thumb (and keep in mind there are many exceptions), it’s important to keep track of whether a potential adviser is pre-tenure or post-tenure. The younger faculty members will usually be around more (they are working hard to get tenure) and will usually be more low-level, have stronger opinions on what you should be working on, they’ll do math with you, pitch concrete ideas, or even look at (or contribute to) your code. This is a much more hands-on and possibly intense experience because the adviser will need a strong publication record to get tenure and they are incentivised to push you to work just as hard. In contrast, more senior faculty members may have larger labs and tend to have many other commitments (e.g. committees, talks, travel) other than research, which means that they can only afford to stay on a higher level of abstraction both in the area of their research and in the level of supervision for their students. To caricature, it’s a difference between “you’re missing a second term in that equation” and “you may want to read up more in this area, talk to this or that person, and sell your work this or that way”. In the latter case, the low-level advice can still come from the senior PhD students in the lab or the postdocs.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Axes of variation&lt;/strong&gt;. There are many other axes to be aware of. Some advisers are fluffy and some prefer to keep your relationship very professional. Some will try to exercise a lot of influence on the details of your work and some are much more hands off. Some will have a focus on specific models and their applications to various tasks while some will focus on tasks and more indifference towards any particular modeling approach. In terms of more managerial properties, some will meet you every week (or day!) multiple times and some you won’t see for months. Some advisers answer emails right away and some don’t answer email for a week (or ever, haha). Some advisers make demands about your work schedule (e.g. you better work long hours or weekends) and some won’t. Some advisers generously support their students with equipment and some think laptops or old computers are mostly fine. Some advisers will fund you to go to a conferences even if you don’t have a paper there and some won’t. Some advisers are entrepreneurial or applied and some lean more towards theoretical work. Some will let you do summer internships and some will consider internships just a distraction.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Finding an adviser&lt;/strong&gt;. So how do you pick an adviser? The first stop, of course, is to talk to them in person. The student-adviser relationship is sometimes referred to as a marriage and you should make sure that there is a good fit. Of course, first you want to make sure that you can talk with them and that you get along personally, but it’s also important to get an idea of what area of “professor space” they occupy with respect to the aforementioned axes, and especially whether there is an intellectual resonance between the two of you in terms of the problems you are interested in. This can be just as important as their management style.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Collecting references&lt;/strong&gt;. You should also collect references on your potential adviser. One good strategy is to talk to their students. If you want to get actual information this shouldn’t be done in a very formal way or setting but in a relaxed environment or mood (e.g. a party). In many cases the students might still avoid saying bad things about the adviser if asked in a general manner, but they will usually answer truthfully when you ask specific questions, e.g. “how often do you meet?”, or “how hands on are they?”. Another strategy is to look at where their previous students ended up (you can usually find this on the website under an alumni section), which of course also statistically informs your own eventual outcome.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Impressing an adviser&lt;/strong&gt;. The adviser-student matching process is sometimes compared to a marriage - you pick them but they also pick you. The ideal student from their perspective is someone with interest and passion, someone who doesn’t need too much hand-holding, and someone who takes initiative - who shows up a week later having done not just what the adviser suggested, but who went beyond it; improved on it in unexpected ways.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Consider the entire lab&lt;/strong&gt;. Another important point to realize is that you’ll be seeing your adviser maybe once a week but you’ll be seeing most of their students every single day in the lab and they will go on to become your closest friends. In most cases you will also end up collaborating with some of the senior PhD students or postdocs and they will play a role very similar to that of your adviser. The postdocs, in particular, are professors-in-training and they will likely be eager to work with you as they are trying to gain advising experience they can point to for their academic job search. Therefore, you want to make sure the entire group has people you can get along with, people you respect and who you can work with closely on research projects.&lt;/p&gt;

&lt;h3 id="research-topics"&gt;Research topics&lt;/h3&gt;

&lt;div&gt;
&lt;p&gt;&lt;img src="https://karpathy.github.io/assets/phd/arxiv-papers.png"&gt;&lt;/p&gt;&lt;p&gt;t-SNE visualization of a small subset of human knowledge (from &lt;a href="http://paperscape.org/"&gt;paperscape&lt;/a&gt;). Each circle is an arxiv paper and size indicates the number of citations.&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;So you’ve entered a PhD program and found an adviser. Now what do you work on?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;An exercise in the outer loop.&lt;/strong&gt; First note the nature of the experience. A PhD is simultaneously a fun and frustrating experience because you’re constantly operating on a meta problem level. You’re not just solving problems - that’s merely the simple inner loop. You spend most of your time on the outer loop, figuring out what problems are worth solving and what problems are ripe for solving. You’re constantly imagining yourself solving hypothetical problems and asking yourself where that puts you, what it could unlock, or if anyone cares. If you’re like me this can sometimes drive you a little crazy because you’re spending long hours working on things and you’re not even sure if they are the correct things to work on or if a solution exists.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Developing taste&lt;/strong&gt;. When it comes to choosing problems you’ll hear academics talk about a mystical sense of “taste”. It’s a real thing. When you pitch a potential problem to your adviser you’ll either see their face contort, their eyes rolling, and their attention drift, or you’ll sense the excitement in their eyes as they contemplate the uncharted territory ripe for exploration. In that split second a lot happens: an evaluation of the problem’s importance, difficulty, its &lt;em&gt;sexiness&lt;/em&gt;, its historical context (and possibly also its fit to their active grants). In other words, your adviser is likely to be a master of the outer loop and will have a highly developed sense of &lt;em&gt;taste&lt;/em&gt; for problems. During your PhD you’ll get to acquire this sense yourself.&lt;/p&gt;

&lt;p&gt;In particular, I think I had a terrible taste coming in to the PhD. I can see this from the notes I took in my early PhD years. A lot of the problems I was excited about at the time were in retrospect poorly conceived, intractable, or irrelevant. I’d like to think I refined the sense by the end through practice and apprenticeship.&lt;/p&gt;

&lt;p&gt;Let me now try to serialize a few thoughts on what goes into this sense of taste, and what makes a problem  interesting to work on.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;A fertile ground.&lt;/strong&gt; First, recognize that during your PhD you will dive deeply into one area and your papers will very likely chain on top of each other to create a body of work (which becomes your thesis). Therefore, you should always be thinking several steps ahead when choosing a problem. It’s impossible to predict how things will unfold but you can often get a sense of how much room there could be for additional work.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Plays to your adviser’s interests and strengths&lt;/strong&gt;. You will want to operate in the realm of your adviser’s interest. Some advisers may allow you to work on slightly tangential areas but you would not be taking full advantage of their knowledge and you are making them less likely to want to help you with your project or promote your work. For instance, (and this goes to my previous point of understanding your adviser’s job) every adviser has a “default talk” slide deck on their research that they give all the time and if your work can add new exciting cutting edge work slides to this deck then you’ll find them much more invested, helpful and involved in your research. Additionally, their talks will promote and publicize your work.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Be ambitious: the sublinear scaling of hardness.&lt;/strong&gt; People have a strange bug built into psychology: a 10x more important or impactful problem intuitively &lt;em&gt;feels&lt;/em&gt; 10x harder (or 10x less likely) to achieve. This is a fallacy - in my experience a 10x more important problem is at most 2-3x harder to achieve. In fact, in some cases a 10x harder problem may be easier to achieve. How is this? It’s because thinking 10x forces you out of the box, to confront the real limitations of an approach, to think from first principles, to change the strategy completely, to innovate. If you aspire to improve something by 10% and work hard then you will. But if you aspire to improve it by 100% you are still quite likely to, but you will do it very differently.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Ambitious but with an attack.&lt;/strong&gt; At this point it’s also important to point out that there are plenty of important problems that don’t make great projects. I recommend reading &lt;a href="https://karpathy.github.io/2016/09/07/phd/You%20and%20Your%20Research"&gt;You and Your Research&lt;/a&gt; by Richard Hamming, where this point is expanded on:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;If you do not work on an important problem, it’s unlikely you’ll do important work. It’s perfectly obvious. Great scientists have thought through, in a careful way, a number of important problems in their field, and they keep an eye on wondering how to attack them. Let me warn you, `important problem’ must be phrased carefully. The three outstanding problems in physics, in a certain sense, were never worked on while I was at Bell Labs. By important I mean guaranteed a Nobel Prize and any sum of money you want to mention. We didn’t work on (1) time travel, (2) teleportation, and (3) antigravity. They are not important problems because we do not have an attack. It’s not the consequence that makes a problem important, it is that you have a reasonable attack. That is what makes a problem important.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;The person who did X&lt;/strong&gt;. Ultimately, the goal of a PhD is to not only develop a deep expertise in a field but to also make your mark upon it. To steer it, shape it. The ideal scenario is that by the end of the PhD you own some part of an important area, preferably one that is also easy and fast to describe. You want people to say things like “she’s the person who did X”. If you can fill in a blank there you’ll be successful.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Valuable skills.&lt;/strong&gt; Recognize that during your PhD you will become an expert at the area of your choosing (as fun aside, note that [5 years]x[260 working days]x[8 hours per day] is 10,400 hours; if you believe Gladwell then a PhD is exactly the amount of time to become an expert). So imagine yourself 5 years later being a world expert in this area (the 10,000 hours will ensure that regardless of the academic impact of your work). Are these skills exciting or potentially valuable to your future endeavors?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Negative examples.&lt;/strong&gt; There are also some problems or types of papers that you ideally want to avoid. For instance, you’ll sometimes hear academics talk about &lt;em&gt;“incremental work”&lt;/em&gt; (this is the worst adjective possible in academia). Incremental work is a paper that enhances something existing by making it more complex and gets 2% extra on some benchmark. The amusing thing about these papers is that they have a reasonably high chance of getting accepted (a reviewer can’t point to anything to kill them; they are also sometimes referred to as “&lt;em&gt;cockroach papers&lt;/em&gt;”), so if you have a string of these papers accepted you can feel as though you’re being very productive, but in fact these papers won’t go on to be highly cited and you won’t go on to have a lot of impact on the field. Similarly, finding projects should ideally not include thoughts along the lines of “there’s this next logical step in the air that no one has done yet, let me do it”, or “this should be an easy poster”.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Case study: my thesis&lt;/strong&gt;. To make some of this discussion more concrete I wanted to use the example of how my own PhD unfolded. First, fun fact: my entire thesis is based on work I did in the last 1.5 years of my PhD. i.e. it took me quite a long time to wiggle around in the metaproblem space and find a problem that I felt very excited to work on (the other ~2 years I mostly meandered on 3D things (e.g. Kinect Fusion, 3D meshes, point cloud features) and video things). Then at one point in my 3rd year I randomly stopped by Richard Socher’s office on some Saturday at 2am. We had a chat about interesting problems and I realized that some of his work on images and language was in fact getting at something very interesting (of course, the area at the intersection of images and language goes back quite a lot further than Richard as well). I couldn’t quite see all the papers that would follow but it seemed heuristically very promising: it was highly fertile (a lot of unsolved problems, a lot of interesting possibilities on grounding descriptions to images), I felt that it was very cool and important, it was easy to explain, it seemed to be at the boundary of possible (Deep Learning has just started to work), the datasets had just started to become available (Flickr8K had just come out), it fit nicely into Fei-Fei’s interests and even if I were not successful I’d at least get lots of practice with optimizing interesting deep nets that I could reapply elsewhere. I had a strong feeling of a tsunami of checkmarks as everything clicked in place in my mind. I pitched this to Fei-Fei (my adviser) as an area to dive into the next day and, with relief, she enthusiastically approved, encouraged me, and would later go on to steer me within the space (e.g. Fei-Fei insisted that I do image to sentence generation while I was mostly content with ranking.). I’m happy with how things evolved from there. In short, I meandered around for 2 years stuck around the outer loop, finding something to dive into. Once it clicked for me what that was based on several heuristics, I dug in.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Resistance&lt;/strong&gt;. I’d like to also mention that your adviser is by no means infallible. I’ve witnessed and heard of many instances in which, in retrospect, the adviser made the wrong call. If you feel this way during your phd you should have the courage to sometimes ignore your adviser. Academia generally celebrates independent thinking but the response of your specific adviser can vary depending on circumstances. I’m aware of multiple cases where the bet worked out very well and I’ve also personally experienced cases where it did not. For instance, I disagreed strongly with some advice Andrew Ng gave me in my very first year. I ended up working on a problem he wasn’t very excited about and, surprise, he turned out to be very right and I wasted a few months. Win some lose some :)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Don’t play the game.&lt;/strong&gt; Finally, I’d like to challenge you to think of a PhD as more than just a sequence of papers. You’re not a paper writer. You’re a member of a research community and your goal is to push the field forward. Papers are one common way of doing that but I would encourage you to look beyond the established academic game. Think for yourself and from first principles. Do things others don’t do but should. Step off the treadmill that has been put before you. I tried to do some of this myself throughout my PhD. This blog is an example - it allows me communicate things that wouldn’t ordinarily go into papers. The ImageNet human reference experiments are an example - I felt strongly that it was important for the field to know the ballpark human accuracy on ILSVRC so I took a few weeks off and evaluated it. The academic search tools (e.g. arxiv-sanity) are an example - I felt continuously frustrated by the inefficiency of finding papers in the literature and I released and maintain the site in hopes that it can be useful to others. Teaching CS231n twice is an example - I put much more effort into it than is rationally advisable for a PhD student who should be doing research, but I felt that the field was held back if people couldn’t efficiently learn about the topic and enter. A lot of my PhD endeavors have likely come at a cost in standard academic metrics (e.g. h-index, or number of publications in top venues) but I did them anyway, I would do it the same way again, and here I am encouraging others to as well. To add a pitch of salt and wash down the ideology a bit, based on several past discussions with my friends and colleagues I know that this view is contentious and that many would disagree.&lt;/p&gt;

&lt;h3 id="writing-papers"&gt;Writing papers&lt;/h3&gt;

&lt;p&gt;&lt;img src="https://karpathy.github.io/assets/phd/latex.png"&gt;
&lt;/p&gt;

&lt;p&gt;Writing good papers is an essential survival skill of an academic (kind of like making fire for a caveman). In particular, it is very important to realize that papers are a specific thing: they look a certain way, they flow a certain way, they have a certain structure, language, and statistics that the other academics expect. It’s usually a painful exercise for me to look through some of my early PhD paper drafts because they are quite terrible. There is a lot to learn here.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Review papers.&lt;/strong&gt; If you’re trying to learn to write better papers it can feel like a sensible strategy to look at many good papers and try to distill patterns. This turns out to not be the best strategy; it’s analogous to only receiving positive examples for a binary classification problem. What you really want is to also have exposure to a large number of bad papers and one way to get this is by reviewing papers. Most good conferences have an acceptance rate of about 25% so most papers you’ll review are bad, which will allow you to build a powerful binary classifier. You’ll read through a bad paper and realize how unclear it is, or how it doesn’t define it’s variables, how vague and abstract its intro is, or how it dives in to the details too quickly, and you’ll learn to avoid the same pitfalls in your own papers. Another related valuable experience is to attend (or form) journal clubs - you’ll see experienced researchers critique papers and get an impression for how your own papers will be analyzed by others.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Get the gestalt right.&lt;/strong&gt; I remember being impressed with Fei-Fei (my adviser) once during a reviewing session. I had a stack of 4 papers I had reviewed over the last several hours and she picked them up, flipped through each one for 10 seconds, and said one of them was good and the other three bad. Indeed, I was accepting the one and rejecting the other three, but something that took me several hours took her seconds. Fei-Fei was relying on the &lt;em&gt;gestalt&lt;/em&gt; of the papers as a powerful heuristic. Your papers, as you become a more senior researcher take on a characteristic look. An introduction of ~1 page. A ~1 page related work section with a good density of citations - not too sparse but not too crowded. A well-designed pull figure (on page 1 or 2) and system figure (on page 3) that were not made in MS Paint. A technical section with some math symbols somewhere, results tables with lots of numbers and some of them bold, one additional cute analysis experiment, and the paper has exactly 8 pages (the page limit) and not a single line less. You’ll have to learn how to endow your papers with the same gestalt because many researchers rely on it as a cognitive shortcut when they judge your work.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Identify the core contribution&lt;/strong&gt;. Before you start writing anything it’s important to identify the single core contribution that your paper makes to the field. I would especially highlight the word &lt;em&gt;single&lt;/em&gt;. A paper is not a random collection of some experiments you ran that you report on. The paper sells a single thing that was not obvious or present before. You have to argue that the thing is important, that it hasn’t been done before, and then you support its merit experimentally in controlled experiments. The entire paper is organized around this core contribution with surgical precision. In particular it doesn’t have any additional fluff and it doesn’t try to pack anything else on a side. As a concrete example, I made a mistake in one of my earlier papers on &lt;a href="https://cs.stanford.edu/people/karpathy/deepvideo/deepvideo_cvpr2014.pdf"&gt;video classification&lt;/a&gt; where I tried to pack in two contributions: 1) a set of architectural layouts for video convnets and an unrelated 2) multi-resolution architecture which gave small improvements. I added it because I reasoned first that maybe someone could find it interesting and follow up on it later and second because I thought that contributions in a paper are additive: two contributions are better than one. Unfortunately, this is false and very wrong. The second contribution was minor/dubious and it diluted the paper, it was distracting, and no one cared. I’ve made a similar mistake again in my &lt;a href="https://cs.stanford.edu/people/karpathy/deepimagesent/"&gt;CVPR 2014 paper&lt;/a&gt; which presented two separate models: a ranking model and a generation model. Several good in-retrospect arguments could be made that I should have submitted two separate papers; the reason it was one is more historical than rational.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The structure.&lt;/strong&gt; Once you’ve identified your core contribution there is a default recipe for writing a paper about it. The upper level structure is by default Intro, Related Work, Model, Experiments, Conclusions. When I write my intro I find that it helps to put down a coherent top-level narrative in latex comments and then fill in the text below. I like to organize each of my paragraphs around a single concrete point stated on the first sentence that is then supported in the rest of the paragraph. This structure makes it easy for a reader to skim the paper. A good flow of ideas is then along the lines of 1) X (+define X if not obvious) is an important problem 2) The core challenges are this and that. 2) Previous work on X has addressed these with Y, but the problems with this are Z. 3) In this work we do W (?). 4) This has the following appealing properties and our experiments show this and that. You can play with this structure a bit but these core points should be clearly made. Note again that the paper is surgically organized around your exact contribution. For example, when you list the challenges you want to list exactly the things that you address later; you don’t go meandering about unrelated things to what you have done (you can speculate a bit more later in conclusion). It is important to keep a sensible structure throughout your paper, not just in the intro. For example, when you explain the model each section should: 1) explain clearly what is being done in the section, 2) explain what the core challenges are 3) explain what a baseline approach is or what others have done before 4) motivate and explain what you do 5) describe it.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Break the structure.&lt;/strong&gt; You should also feel free (and you’re encouraged to!) play with these formulas to some extent and add some spice to your papers. For example, see this amusing paper from &lt;a href="https://arxiv.org/abs/1403.6382"&gt;Razavian et al. in 2014&lt;/a&gt; that structures the introduction as a dialog between a student and the professor. It’s clever and I like it. As another example, a lot of papers from &lt;a href="https://people.eecs.berkeley.edu/~efros/"&gt;Alyosha Efros&lt;/a&gt; have a playful tone and make great case studies in writing fun papers. As only one of many examples, see this paper he wrote with Antonio Torralba: &lt;a href="https://people.csail.mit.edu/torralba/publications/datasets_cvpr11.pdf"&gt;Unbiased look at dataset bias&lt;/a&gt;. Another possibility I’ve seen work well is to include an FAQ section, possibly in the appendix.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Common mistake: the laundry list.&lt;/strong&gt; One very common mistake to avoid is the “laundry list”, which looks as follows: “Here is the problem. Okay now to solve this problem first we do X, then we do Y, then we do Z, and now we do W, and here is what we get”. You should try very hard to avoid this structure. Each point should be justified, motivated, explained. Why do you do X or Y? What are the alternatives? What have others done? It’s okay to say things like this is common (add citation if possible). Your paper is not a report, an enumeration of what you’ve done, or some kind of a translation of your chronological notes and experiments into latex. It is a highly processed and very focused discussion of a problem, your approach and its context. It is supposed to teach your colleagues something and you have to justify your steps, not just describe what you did.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The language.&lt;/strong&gt; Over time you’ll develop a vocabulary of good words and bad words to use when writing papers. Speaking about machine learning or computer vision papers specifically as concrete examples, in your papers you never “study” or “investigate” (there are boring, passive, bad words); instead you “develop” or even better you “propose”. And you don’t present a “system” or, &lt;em&gt;shudder&lt;/em&gt;, a “pipeline”; instead, you develop a “model”. You don’t learn “features”, you learn “representations”. And god forbid, you never “combine”, “modify” or “expand”. These are incremental, gross terms that will certainly get your paper rejected :).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;An internal deadlines 2 weeks prior&lt;/strong&gt;. Not many labs do this, but luckily Fei-Fei is quite adamant about an internal deadline 2 weeks before the due date in which you must submit at least a 5-page draft with all the final experiments (even if not with final numbers) that goes through an internal review process identical to the external one (with the same review forms filled out, etc). I found this practice to be extremely useful because forcing yourself to lay out the full paper almost always reveals some number of critical experiments you must run for the paper to flow and for its argument flow to be coherent, consistent and convincing.&lt;/p&gt;

&lt;p&gt;Another great resource on this topic is &lt;a href="https://cs.stanford.edu/people/widom/paper-writing.html"&gt;Tips for Writing Technical Papers&lt;/a&gt; from Jennifer Widom.&lt;/p&gt;

&lt;h3 id="writing-code"&gt;Writing code&lt;/h3&gt;

&lt;p&gt;&lt;img src="https://karpathy.github.io/assets/phd/code.jpg"&gt;
&lt;/p&gt;

&lt;p&gt;A lot of your time will of course be taken up with the &lt;em&gt;execution&lt;/em&gt; of your ideas, which likely involves a lot of coding. I won’t dwell on this too much because it’s not uniquely academic, but I would like to bring up a few points.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Release your code&lt;/strong&gt;. It’s a somewhat surprising fact but you can get away with publishing papers and not releasing your code. You will also feel a lot of incentive to not release your code: it can be a lot of work (research code can look like spaghetti since you iterate very quickly, you have to clean up a lot), it can be intimidating to think that others might judge you on your at most decent coding abilities, it is painful to maintain code and answer questions from other people about it (forever), and you might also be concerned that people could spot bugs that invalidate your results. However, it is precisely for some of these reasons that you should commit to releasing your code: it will force you to adopt better coding habits due to fear of public shaming (which will end up saving you time!), it will force you to learn better engineering practices, it will force you to be more thorough with your code (e.g. writing unit tests to make bugs much less likely), it will make others much more likely to follow up on your work (and hence lead to more citations of your papers) and of course it will be much more useful to everyone as a record of exactly what was done for posterity. When you do release your code I recommend taking advantage of &lt;a href="https://www.docker.com/"&gt;docker containers&lt;/a&gt;; this will reduce the amount of headaches people email you about when they can’t get all the dependencies (and their precise versions) installed.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Think of the future you&lt;/strong&gt;. Make sure to document all your code very well for yourself. I guarantee you that you will come back to your code base a few months later (e.g. to do a few more experiments for the camera ready version of the paper), and you will feel &lt;em&gt;completely&lt;/em&gt; lost in it. I got into the habit of creating very thorough readme.txt files in all my repos (for my personal use) as notes to future self on how the code works, how to run it, etc.&lt;/p&gt;

&lt;h3 id="giving-talks"&gt;Giving talks&lt;/h3&gt;

&lt;p&gt;&lt;img src="https://karpathy.github.io/assets/phd/talk.jpg"&gt;
&lt;/p&gt;

&lt;p&gt;So, you published a paper and it’s an oral! Now you get to give a few minute talk to a large audience of people - what should it look like?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The goal of a talk&lt;/strong&gt;. First, that there’s a common misconception that the goal of your talk is to tell your audience about what you did in your paper. This is incorrect, and should only be a second or third degree design criterion. The goal of your talk is to 1) get the audience really excited about the &lt;strong&gt;problem&lt;/strong&gt; you worked on (they must appreciate it or they will not care about your solution otherwise!) 2) teach the audience something (ideally while giving them a taste of your insight/solution; don’t be afraid to spend time on other’s related work), and 3) entertain (they will start checking their Facebook otherwise). Ideally, by the end of the talk the people in your audience are thinking some mixture of “wow, I’m working in the wrong area”, “I have to read this paper”, and “This person has an impressive understanding of the whole area”.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;A few do’s:&lt;/strong&gt; There are several properties that make talks better. For instance, Do: Lots of pictures. People Love pictures. Videos and animations should be used more sparingly because they distract. Do: make the talk actionable - talk about something someone can &lt;em&gt;do&lt;/em&gt; after your talk. Do: give a live demo if possible, it can make your talk more memorable. Do: develop a broader intellectual arch that your work is part of. Do: develop it into a story (people love stories). Do: cite, cite, cite - a lot! It takes very little slide space to pay credit to your colleagues. It pleases them and always reflects well on you because it shows that you’re humble about your own contribution, and aware that it builds on a lot of what has come before and what is happening in parallel. You can even cite related work published at the same conference and briefly advertise it. Do: practice the talk! First for yourself in isolation and later to your lab/friends. This almost always reveals very insightful flaws in your narrative and flow.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Don’t: texttexttext&lt;/strong&gt;. Don’t crowd your slides with text. There should be very few or no bullet points - speakers sometimes try to use these as a crutch to remind themselves what they should be talking about but the slides are not for you they are for the audience. These should be in your speaker notes. On the topic of crowding the slides, also avoid complex diagrams as much as you can - your audience has a fixed bit bandwidth and I guarantee that your own very familiar and “simple” diagram is not as simple or interpretable to someone seeing it for the first time.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Careful with: result tables:&lt;/strong&gt; Don’t include dense tables of results showing that your method works better. You got a paper, I’m sure your results were decent. I always find these parts boring and unnecessary unless the numbers show something interesting (other than your method works better), or of course unless there is a large gap that you’re very proud of. If you do include results or graphs build them up slowly with transitions, don’t post them all at once and spend 3 minutes on one slide.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Pitfall: the thin band between bored/confused&lt;/strong&gt;. It’s actually quite tricky to design talks where a good portion of your audience &lt;em&gt;learns&lt;/em&gt; something. A common failure case (as an audience member) is to see talks where I’m painfully bored during the first half and completely confused during the second half, learning nothing by the end. This can occur in talks that have a very general (too general) overview followed by a technical (too technical) second portion. Try to identify when your talk is in danger of having this property.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Pitfall: running out of time&lt;/strong&gt;. Many speakers spend too much time on the early intro parts (that can often be somewhat boring) and then frantically speed through all the last few slides that contain the most interesting results, analysis or demos. Don’t be that person.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Pitfall: formulaic talks&lt;/strong&gt;. I might be a special case but I’m always a fan of non-formulaic talks that challenge conventions. For instance, I &lt;em&gt;despise&lt;/em&gt; the outline slide. It makes the talk so boring, it’s like saying: “This movie is about a ring of power. In the first chapter we’ll see a hobbit come into possession of the ring. In the second we’ll see him travel to Mordor. In the third he’ll cast the ring into Mount Doom and destroy it. I will start with chapter 1” - Come on! I use outline slides for much longer talks to keep the audience anchored if they zone out (at 30min+ they inevitably will a few times), but it should be used sparingly.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Observe and learn&lt;/strong&gt;. Ultimately, the best way to become better at giving talks (as it is with writing papers too) is to make conscious effort to pay attention to what great (and not so great) speakers do and build a binary classifier in your mind. Don’t just enjoy talks; analyze them, break them down, learn from them. Additionally, pay close attention to the audience and their reactions. Sometimes a speaker will put up a complex table with many numbers and you will notice half of the audience immediately look down on their phone and open Facebook. Build an internal classifier of the events that cause this to happen and avoid them in your talks.&lt;/p&gt;

&lt;h3 id="attending-conferences"&gt;Attending conferences&lt;/h3&gt;

&lt;p&gt;&lt;img src="https://karpathy.github.io/assets/phd/posters.jpg"&gt;
&lt;/p&gt;

&lt;p&gt;On the subject of conferences:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Go.&lt;/strong&gt; It’s very important that you go to conferences, especially the 1-2 top conferences in your area. If your adviser lacks funds and does not want to pay for your travel expenses (e.g. if you don’t have a paper) then you should be willing to pay for yourself (usually about $2000 for travel, accommodation, registration and food). This is important because you want to become part of the academic community and get a chance to meet more people in the area and gossip about research topics. Science might have this image of a few brilliant lone wolfs working in isolation, but the truth is that research is predominantly a highly social endeavor - you stand on the shoulders of many people, you’re working on problems in parallel with other people, and it is these people that you’re also writing papers to. Additionally, it’s unfortunate but each field has knowledge that doesn’t get serialized into papers but is instead spread across a shared understanding of the community; things such as what are the next important topics to work on, what papers are most interesting, what is the inside scoop on papers, how they developed historically, what methods work (not just on paper, in reality), etcetc. It is very valuable (and fun!) to become part of the community and get direct access to the hivemind - to learn from it first, and to hopefully influence it later.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Talks: choose by speaker&lt;/strong&gt;. One conference trick I’ve developed is that if you’re choosing which talks to attend it can be better to look at the speakers instead of the topics. Some people give better talks than others (it’s a skill, and you’ll discover these people in time) and in my experience I find that it often pays off to see them speak even if it is on a topic that isn’t exactly connected to your area of research.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The real action is in the hallways&lt;/strong&gt;. The speed of innovation (especially in Machine Learning) now works at timescales much faster than conferences so most of the relevant papers you’ll see at the conference are in fact old news. Therefore, conferences are primarily a social event. Instead of attending a talk I encourage you to view the hallway as one of the main events that doesn’t appear on the schedule. It can also be valuable to stroll the poster session and discover some interesting papers and ideas that you may have missed.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;It is said that there are three stages to a PhD. In the first stage you look at a related paper’s reference section and you haven’t read most of the papers. In the second stage you recognize all the papers. In the third stage you’ve shared a beer with all the first authors of all the papers.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id="closing-thoughts"&gt;Closing thoughts&lt;/h3&gt;

&lt;p&gt;I can’t find the quote anymore but I heard Sam Altman of YC say that there are no shortcuts or cheats when it comes to building a startup. You can’t expect to win in the long run by somehow gaming the system or putting up false appearances. I think that the same applies in academia. Ultimately you’re trying to do good research and push the field forward and if you try to game any of the proxy metrics you won’t be successful in the long run. This is especially so because academia is in fact surprisingly small and highly interconnected, so anything shady you try to do to pad your academic resume (e.g. self-citing a lot, publishing the same idea multiple times with small remixes, resubmitting the same rejected paper over and over again with no changes, conveniently trying to leave out some baselines etc.) will eventually catch up with you and you will not be successful.&lt;/p&gt;

&lt;p&gt;So at the end of the day it’s quite simple. Do good work, communicate it properly, people will notice and good things will happen. Have a fun ride!&lt;/p&gt;



  &lt;/article&gt;&lt;/div&gt;&lt;a href="https://karpathy.github.io/2016/09/07/phd/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Fri, 12 Jun 2020 12:17:21 UT
      </pubDate>
      <guid>
        https://karpathy.github.io/2016/09/07/phd/
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://www.cs.cmu.edu/~harchol/gradschooltalk.pdf
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;���ʨޣ���R�~�k�
p�s�)bcQ��ޕ���	��.;�4�D�$�5,y]{մB&amp;amp;��
X�K��W9X����I�kg�_Ȏ��!�݌l�n����M���xc~�1	/t�GU��J�å(u H�s�9�"�J{�х�]���`�(ۯT�0DO��D��w�!��/j�$׿�P@;`�s���幌��h�W~4������j��AbIU7���	4k!�&amp;gt;H�&amp;gt;F�5�C����6������R��O���c&amp;gt;ש�k�%kn=��Q�*���:$��nK��"��HM��-�����_�Mb�4�jٴ㰙��ڿu�k���A���3�UY��������T�2��뽆{���0z����`��1M�.��U�$�����P�ch6��(��)7Z�1�^-��G3z�x�&amp;lt;�H8-B+z�к�T�#8�	 �~��x݌g0
�P�Q?���*	�\k{吒����9_5���r`6��t����mIVҁ�]�|Ntƃa�6�N
�O/���0&lt;/div&gt;&lt;a href="https://www.cs.cmu.edu/~harchol/gradschooltalk.pdf"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Fri, 12 Jun 2020 12:17:22 UT
      </pubDate>
      <guid>
        https://www.cs.cmu.edu/~harchol/gradschooltalk.pdf
      </guid>
    </item>
    <item>
      <title>
        Richard Socher - Home Page
      </title>
      <link>
        https://www.socher.org/index.php/Main/HomePage
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;

&lt;h3&gt;
Research&lt;/h3&gt;
&lt;h4&gt;
2020&lt;/h4&gt;&lt;p&gt;ProGen: Language Modeling for Protein Generation,
Ali Madani, Bryan McCann, Nikhil Naik, Nitish Shirish Keskar, Namrata Anand, Raphael R Eguchi, Possu Huang and Richard Socher.&lt;br&gt;[ &lt;a rel="nofollow" href="https://www.biorxiv.org/content/10.1101/2020.03.07.982272v2"&gt;bioRxiv link&lt;/a&gt;, &lt;a rel="nofollow" href="https://blog.einstein.ai/progen/"&gt;blog&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;The AI Economist: Improving Equality and Productivity with AI-Driven Tax Policies, Stephan Zheng, Alexander Trott, Sunil Srinivasa, Nikhil Naik, Melvin Gruesbeck, David C. Parkes, Richard Socher.&lt;br&gt;[ &lt;a rel="nofollow" href="https://arxiv.org/abs/2004.13332"&gt;arxiv link&lt;/a&gt;, &lt;a rel="nofollow" href="https://blog.einstein.ai/the-ai-economist/"&gt;blog&lt;/a&gt;, &lt;a rel="nofollow" href="https://www.youtube.com/watch?v=4iQUcGyQhdA"&gt;short video&lt;/a&gt;, &lt;a rel="nofollow" href="https://salesforce.com/company/news-press/stories/2020/4/salesforce-ai-economist/"&gt;Q&amp;amp;A&lt;/a&gt;, Press: &lt;a rel="nofollow" href="https://venturebeat.com/2020/04/29/salesforces-ai-economist-taps-reinforcement-learning-to-generate-optimal-tax-policies/"&gt;VentureBeat&lt;/a&gt;, &lt;a rel="nofollow" href="https://techcrunch.com/2020/04/29/salesforce-researchers-are-working-on-an-ai-economist-for-more-equitable-tax-policy/"&gt;TechCrunch&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;Deep Learning-enabled Breast Cancer Hormonal Receptor Status Determination from Base-level H&amp;amp;E Stains, Nikhil Naik, Ali Madani, Andre Esteva, Nitish Keskar, Michael Press, Dan Ruderman, David Agus, Richard Socher &lt;br&gt;(&lt;strong&gt;Nature Communications 2020&lt;/strong&gt;) [ &lt;a rel="nofollow" href="https://www.nature.com/articles/s41467-020-19334-3"&gt;paper&lt;/a&gt;, &lt;a rel="nofollow" href="https://blog.einstein.ai/receptornet/"&gt;blog&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;Dye-sensitized solar cells under ambient light powering machine learning: towards autonomous smart sensors for the internet of things, 
Hannes Michaels, Michael Rinderle, Richard Freitag, Lacopo Benesperi, Tomas Edvinsson, Richard Socher, Alessio Gagliardib and Marina Freitag&lt;br&gt;Issue11, (&lt;strong&gt;Chemical Science 2020&lt;/strong&gt;). 
[ &lt;a rel="nofollow" href="https://pubs.rsc.org/en/content/articlelanding/2020/sc/c9sc06145b#!divAbstract"&gt;paper link&lt;/a&gt; ]
&lt;/p&gt;
&lt;h4&gt;
2019&lt;/h4&gt;&lt;p&gt;CTRL: A Conditional Transformer Language Model for Controllable Generation,
Nitish Shirish Keskar, Bryan McCann, Lav R. Varshney, Caiming Xiong, Richard Socher.&lt;br&gt;[ &lt;a rel="nofollow" href="https://arxiv.org/abs/1909.05858"&gt;arxiv link&lt;/a&gt;, &lt;a rel="nofollow" href="https://github.com/salesforce/ctrl"&gt;code (pre-trained and fine-tuning)&lt;/a&gt;, &lt;a rel="nofollow" href="https://blog.einstein.ai/introducing-a-conditional-transformer-language-model-for-controllable-generation/"&gt;blog&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;Genie: a generator of natural language semantic parsers for virtual assistant commands,
Giovanni Campagna, Silei Xu, Mehrad Moradshahi, Richard Socher, Monica S. Lam&lt;br&gt;PLDI 2019
[ &lt;a rel="nofollow" href="https://almond-static.stanford.edu/papers/genie-pldi19.pdf"&gt;pdf link&lt;/a&gt;, &lt;a rel="nofollow" href="https://almond.stanford.edu/"&gt;https://almond.stanford.edu/&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;Keeping Your Distance: Solving Sparse Reward Tasks Using Self-Balancing Shaped Rewards, 
Alex Trott, Stephan Zheng, Caiming Xiong, Richard Socher.&lt;br&gt;Thirty-third Conference on Neural Information Processing Systems (&lt;strong&gt;NeurIPS 2019&lt;/strong&gt;).
&lt;/p&gt;
&lt;p&gt;The State of Text Summarization: A Critical Evaluation,
Wojciech Kryściński, Nitish Shirish Keskar, Bryan McCann, Caiming Xiong, Richard Socher.&lt;br&gt;2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing (&lt;strong&gt;EMNLP-IJCNLP 2019&lt;/strong&gt;).
[ &lt;a rel="nofollow" href="https://arxiv.org/abs/1908.08960"&gt;arxiv link&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;WSLLN: Weakly Supervised Natural Language Localization Networks, 
Mingfei Gao, Larry Davis, Richard Socher, Caiming Xiong.&lt;br&gt;2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing (&lt;strong&gt;EMNLP-IJCNLP 2019&lt;/strong&gt;).
[ &lt;a rel="nofollow" href="https://arxiv.org/abs/1909.00239"&gt;arxiv link&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;Editing-based SQL Query Generation for Cross-Domain Context-Dependent Questions, 
Rui Zhang, Tao Yu, Heyang Er, Sungrok Shim, Eric Xue, Xi Victoria Lin, Tianze Shi, Caiming Xiong, Richard Socher and Dragomir Radev&lt;br&gt;2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing (&lt;strong&gt;EMNLP-IJCNLP 2019&lt;/strong&gt;).
[ &lt;a rel="nofollow" href="https://arxiv.org/abs/1909.00786"&gt;arxiv link&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;CoSQL: A Conversational Text-to-SQL Challenge Towards Cross-Domain Natural Language Interfaces to Databases, Tao Yu, Rui Zhang, Heyang Er, Suyi Li, Eric Xue, Bo Pang, Xi Victoria Lin, Yi Chern Tan, Tianze Shi, Zihan Li, Youxuan Jiang, Michihiro Yasunaga, Sungrok Shim, Tao Chen, Alexander Fabbri, Zifan Li, Luyao Chen, Yuwen Zhang, Shreya Dixit, Vincent Zhang, Caiming Xiong, Richard Socher, Walter Lasecki, Dragomir Radev.&lt;br&gt;2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing (&lt;strong&gt;EMNLP-IJCNLP 2019&lt;/strong&gt;).
[ &lt;a rel="nofollow" href="https://arxiv.org/abs/1909.05378"&gt;arxiv link&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;Transferable Multi-Domain State Generator for Task-Oriented Dialogue Systems, 
Chien-Sheng Wu, Andrea Madotto, Ehsan Hosseini-Asl, Caiming Xiong, Richard Socher, Pascale Fung&lt;br&gt;The 57th Annual Meeting of the Association for Computational Linguistics (&lt;strong&gt;ACL 2019&lt;/strong&gt;).
&lt;strong&gt;&lt;span&gt;Outstanding Paper Award&lt;/span&gt;&lt;/strong&gt;.
[ &lt;a rel="nofollow" href="https://arxiv.org/abs/1905.08743"&gt;arxiv pdf&lt;/a&gt;, &lt;a rel="nofollow" href="https://github.com/jasonwu0731/trade-dst"&gt;code&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;Explain Yourself! Leveraging Language Models for Commonsense Reasoning, 
Nazneen Fatema Rajani, Bryan McCann, Caiming Xiong and Richard Socher&lt;br&gt;The 57th Annual Meeting of the Association for Computational Linguistics (&lt;strong&gt;ACL 2019&lt;/strong&gt;).
[ &lt;a rel="nofollow" href="https://arxiv.org/abs/1906.02361"&gt;arxiv pdf&lt;/a&gt;, &lt;a rel="nofollow" href="https://blog.einstein.ai/leveraging-language-models-for-commonsense/"&gt;Blog Post&lt;/a&gt;, &lt;a rel="nofollow" href="https://github.com/salesforce/cos-e"&gt;Github&lt;/a&gt;, Press: &lt;a rel="nofollow" href="https://venturebeat.com/2019/06/27/salesforces-ai-grasps-commonsense-reasoning/"&gt;VentureBeat&lt;/a&gt;, 
&lt;a rel="nofollow" href="https://siliconangle.com/2019/06/27/salesforce-aims-bring-common-sense-ai/"&gt;Silicon Angle&lt;/a&gt;, 
&lt;a rel="nofollow" href="https://www.zdnet.com/article/salesforce-open-sources-research-to-advance-state-of-the-art-in-ai-for-common-sense-reasoning/"&gt;ZDNet&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;SParC: Cross-Domain Semantic Parsing in Context, 
Tao Yu, Rui Zhang, Michihiro Yasunaga, Yi Chern Tan, Xi Victoria Lin, Suyi Li, Heyang Er, Irene Li, Bo Pang, Tao Chen, Emily Ji, Shreya Dixit, David Proctor, Sungrok Shim, Jonathan Kraft, Vincent Zhang, Caiming Xiong, Richard Socher and Dragomir Radev&lt;br&gt;The 57th Annual Meeting of the Association for Computational Linguistics (&lt;strong&gt;ACL 2019&lt;/strong&gt;).
[ &lt;a rel="nofollow" href="https://arxiv.org/pdf/1901.04713.pdf"&gt;arxiv pdf&lt;/a&gt;, &lt;a rel="nofollow" href="https://yale-lily.github.io/sparc"&gt;Challenge and Leaderboard&lt;/a&gt;  ]
&lt;/p&gt;
&lt;p&gt;Global-to-local Memory Pointer Networks for Task-Oriented Dialogue, 
Chien-Sheng Wu, Richard Socher, Caiming Xiong&lt;br&gt;International Conference on Learning Representations (&lt;strong&gt;ICLR 2019&lt;/strong&gt;). 
[ &lt;a rel="nofollow" href="https://arxiv.org/pdf/1901.04713.pdf"&gt;arxiv pdf&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;Self-Monitoring Navigation Agent via Auxiliary Progress Estimation, 
Chih-Yao Ma, Jiasen Lu, Zuxuan Wu, Ghassan AlRegib, Zsolt Kira, Richard Socher, Caiming Xiong&lt;br&gt;International Conference on Learning Representations (&lt;strong&gt;ICLR 2019&lt;/strong&gt;). 
[ &lt;a rel="nofollow" href="https://arxiv.org/pdf/1901.03035.pdf"&gt;arxiv pdf&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;Coarse-grain Fine-grain Coattention Network for Multi-evidence Question Answering, 
Victor Zhong, Caiming Xiong, Nitish Shirish Keskar, Richard Socher. &lt;br&gt;International Conference on Learning Representations (&lt;strong&gt;ICLR 2019&lt;/strong&gt;). 
[ &lt;a rel="nofollow" href="https://arxiv.org/pdf/1901.00603.pdf"&gt;arxiv pdf&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;Competitive experience replay,
Hao Liu, Alexander Trott, Richard Socher, Caiming Xiong.&lt;br&gt;International Conference on Learning Representations (&lt;strong&gt;ICLR 2019&lt;/strong&gt;). 
[ &lt;a rel="nofollow" href="https://arxiv.org/pdf/1902.00528.pdf"&gt;arxiv pdf&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;Augmented Cyclic Adversarial Learning for Low Resource Domain Adaptation, 
Ehsan Hosseini-Asl, Yingbo Zhou, Caiming Xiong, Richard Socher. &lt;br&gt;International Conference on Learning Representations (&lt;strong&gt;ICLR 2019&lt;/strong&gt;). 
[ &lt;a rel="nofollow" href="https://arxiv.org/abs/1807.00374"&gt;arxiv pdf&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;A Closer Look at Deep Learning Heuristics: Learning rate restarts, Warmup and Distillation, 
Akhilesh Gotmare, Nitish Shirish Keskar, Caiming Xiong, Richard Socher. &lt;br&gt;International Conference on Learning Representations (&lt;strong&gt;ICLR 2019&lt;/strong&gt;). 
[ &lt;a rel="nofollow" href="https://arxiv.org/pdf/1810.13243.pdf"&gt;arxiv pdf&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;AdaFrame: Adaptive Frame Selection for Fast Video Recognition, 
Zuxuan Wu, Caiming Xiong, Chih-Yao Ma, Richard Socher, Larry S Davis.&lt;br&gt;Conference on Computer Vision and Pattern Recognition (&lt;strong&gt;CVPR 2019&lt;/strong&gt;). 
[ &lt;a rel="nofollow" href="https://arxiv.org/pdf/1811.12432.pdf"&gt;arxiv pdf&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;Unifying Question Answering and Text Classification via Span Extraction, 
Nitish Shirish Keskar, Bryan McCann, Caiming Xiong, Richard Socher&lt;br&gt;[ &lt;a rel="nofollow" href="https://arxiv.org/abs/1904.09286"&gt;arxiv pdf&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;Learn to Grow: A Continual Structure Learning Framework for Catastrophic Forgetting, 
Xilai, Yingbo Zhou, Caiming Xiong, Richard Socher&lt;br&gt;The 36th International Conference on Machine Learning (&lt;strong&gt;ICML 2019&lt;/strong&gt;). 
[ &lt;a rel="nofollow" href="https://arxiv.org/abs/TODO"&gt;arxiv pdf&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;Taming MAML: Control variates for unbiased meta-reinforcement learning gradient estimation,
Hao Liu, Caiming Xiong, Richard Socher&lt;br&gt;The 36th International Conference on Machine Learning (&lt;strong&gt;ICML 2019&lt;/strong&gt;). 
[ &lt;a rel="nofollow" href="https://arxiv.org/abs/TODO"&gt;arxiv pdf&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;On the Generalization Gap in Reparameterizable Reinforcement Learning (Huan Wang, Stephan Zheng, Caiming Xiong, Richard Socher&lt;br&gt;The 36th International Conference on Machine Learning (&lt;strong&gt;ICML 2019&lt;/strong&gt;). 
[ &lt;a rel="nofollow" href="https://arxiv.org/abs/TODO"&gt;arxiv pdf&lt;/a&gt; ]
&lt;/p&gt;
&lt;h4&gt;
2018 &lt;/h4&gt;&lt;div&gt; 
&lt;p&gt;The Natural Language Decathlon: Multitask Learning as Question Answering,
Bryan McCann, Nitish Shirish Keskar, Caiming Xiong, Richard Socher&lt;br&gt;[ &lt;a rel="nofollow" href="https://arxiv.org/abs/1806.08730"&gt;arxiv pdf&lt;/a&gt;, 
&lt;a rel="nofollow" href="https://github.com/salesforce/decaNLP"&gt;code and leaderboard&lt;/a&gt;, &lt;a rel="nofollow" href="https://einstein.ai/research/the-natural-language-decathlon"&gt;blog post&lt;/a&gt;, &lt;a rel="nofollow" href="https://www.salesforce.com/company/news-press/stories/2018/6/062018-a/"&gt;Q&amp;amp;A&lt;/a&gt;, Press: &lt;a rel="nofollow" href="https://venturebeat.com/2018/06/20/salesforce-develops-natural-language-processing-model-that-performs-10-tasks-at-once/"&gt;VentureBeat&lt;/a&gt;,  &lt;a rel="nofollow" href="https://www.zdnet.com/article/salesforce-research-creates-swiss-army-knife-for-natural-language-processing/"&gt;zdnet&lt;/a&gt;, &lt;a rel="nofollow" href="http://www.faz.net/aktuell/wirtschaft/kuenstliche-intelligenz/richard-socher-wenn-der-computer-multitasking-kann-15650122.html"&gt;FAZ (German)&lt;/a&gt;, &lt;a rel="nofollow" href="https://siliconangle.com/blog/2018/06/20/salesforce-claims-big-advance-natural-language-processing/"&gt;SiliconAngle&lt;/a&gt; ]
&lt;/p&gt;&lt;/div&gt;
&lt;p&gt;Multi-Hop Knowledge Graph Reasoning with Reward Shaping, 
Xi Victoria Lin, Richard Socher, Caiming Xiong&lt;br&gt;Conference on Empirical Methods in Natural Language Processing (&lt;strong&gt;EMNLP 2018&lt;/strong&gt;). 
[ &lt;a rel="nofollow" href="https://arxiv.org/abs/1808.10568"&gt;arxiv pdf&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;Improving Abstraction in Text Summarization, 
Wojciech Kryściński, Romain Paulus, Caiming Xiong, Richard Socher&lt;br&gt;Conference on Empirical Methods in Natural Language Processing (&lt;strong&gt;EMNLP 2018&lt;/strong&gt;). 
[ &lt;a rel="nofollow" href="https://arxiv.org/pdf/1808.07913.pdf"&gt;arxiv pdf&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;A Multi-Discriminator CycleGAN for Unsupervised Non-Parallel Speech Domain Adaptation, 
Ehsan Hosseini-Asl, Yingbo Zhou, Caiming Xiong, Richard Socher&lt;br&gt;&lt;strong&gt;Interspeech 2018&lt;/strong&gt;. 
[ &lt;a rel="nofollow" href="https://arxiv.org/abs/1804.00522"&gt;arxiv pdf&lt;/a&gt;, &lt;a rel="nofollow" href="https://einstein.ai/research/a-multi-discriminator-cyclegan-for-unsupervised-non-parallel-speech-domain-adaptation"&gt;blog&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;Global-Locally Self-Attentive Encoder for Dialogue State Tracking, 
Victor Zhong, Caiming Xiong, Richard Socher. &lt;br&gt;Association for Computational Linguistics 2018 Conference (&lt;strong&gt;ACL 2018&lt;/strong&gt;).
[ &lt;a rel="nofollow" href="https://arxiv.org/abs/1805.09655"&gt;arxiv pdf&lt;/a&gt; ] 
&lt;/p&gt;
&lt;p&gt;Efficient and Robust Question Answering from Minimal Context over Documents, 
Sewon Min, Victor Zhong, Richard Socher, Caiming Xiong. &lt;br&gt;Association for Computational Linguistics 2018 Conference (&lt;strong&gt;ACL 2018&lt;/strong&gt;).
[ &lt;a rel="nofollow" href="https://arxiv.org/abs/1805.08092"&gt;arxiv pdf&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;End-to-End Dense Video Captioning with Masked Transformer, 
Luowei Zhou, Yingbo Zhou, Jason J. Corso, Richard Socher, Caiming Xiong&lt;br&gt;IEEE Conference on Computer Vision and Pattern Recognition (&lt;strong&gt;CVPR 2018&lt;/strong&gt;). &lt;span&gt; (Spotlight)&lt;/span&gt;
[ &lt;a rel="nofollow" href="https://arxiv.org/abs/1804.00819"&gt;arxiv pdf&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;An Analysis of Neural Language Modeling at Multiple Scales, 
Stephen Merity, Nitish Shirish Keskar, Richard Socher&lt;br&gt;[ &lt;a rel="nofollow" href="https://arxiv.org/abs/1803.08240"&gt;arxiv pdf&lt;/a&gt;, &lt;a rel="nofollow" href="https://github.com/salesforce/awd-lstm-lm"&gt;github code&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;Interpretable Counting for Visual Question Answering, 
Alexander Trott, Caiming Xiong, Richard Socher&lt;br&gt;International Conference on Learning Representations (&lt;strong&gt;ICLR 2018&lt;/strong&gt;).
[ &lt;a rel="nofollow" href="https://arxiv.org/abs/1712.08697"&gt;arxiv pdf&lt;/a&gt;, &lt;a rel="nofollow" href="https://einstein.ai/research/interpretable-counting-for-visual-question-answering"&gt;blog post&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;Hierarchical and Interpretable Skill Acquisition in Multi-task Reinforcement Learning, 
Tianmin Shu, Caiming Xiong, and Richard Socher&lt;br&gt;International Conference on Learning Representations (&lt;strong&gt;ICLR 2018&lt;/strong&gt;).
[ &lt;a rel="nofollow" href="https://arxiv.org/abs/1712.07294"&gt;arxiv pdf&lt;/a&gt;, &lt;a rel="nofollow" href="https://einstein.ai/research/hierarchical-reinforcement-learning"&gt;blog post&lt;/a&gt;  ]
&lt;/p&gt;
&lt;p&gt;A Deep Reinforced Model for Abstractive Summarization,
Romain Paulus, Caiming Xiong, Richard Socher&lt;br&gt;International Conference on Learning Representations (&lt;strong&gt;ICLR 2018&lt;/strong&gt;).
[ &lt;a rel="nofollow" href="https://arxiv.org/abs/1705.04304"&gt;pdf&lt;/a&gt;, &lt;a rel="nofollow" href="https://blog.einstein.ai/your-tldr-by-an-ai-a-deep-reinforced-model-for-abstractive-summarization/"&gt;blog post&lt;/a&gt;, Press: &lt;a rel="nofollow" href="https://www.forbes.com/sites/gilpress/2017/05/11/salesforce-announces-ai-breakthrough-reducing-information-overload"&gt;Forbes&lt;/a&gt;,  &lt;a rel="nofollow" href="https://www.technologyreview.com/s/607828/an-algorithm-summarizes-lengthy-text-surprisingly-well/"&gt;MIT Tech Review&lt;/a&gt;, &lt;a rel="nofollow" href="https://techcrunch.com/2017/05/11/salesforce-aims-to-save-you-time-by-summarizing-emails-and-docs-with-machine-intelligence/"&gt;TechCrunch&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;Non-Autoregressive Neural Machine Translation,
Jiatao Gu, James Bradbury, Caiming Xiong, Victor O.K. Li, Richard Socher&lt;br&gt;International Conference on Learning Representations (&lt;strong&gt;ICLR 2018&lt;/strong&gt;).
[ &lt;a rel="nofollow" href="https://arxiv.org/abs/1711.02281"&gt;arxiv pdf&lt;/a&gt;, &lt;a rel="nofollow" href="https://einstein.ai/research/non-autoregressive-neural-machine-translation"&gt;blog post&lt;/a&gt;, 
Press: &lt;a rel="nofollow" href="https://www.cnbc.com/2017/11/06/salesforce-a-i-researchers-develop-faster-machine-translation-model.html"&gt;CNBC&lt;/a&gt;, &lt;a rel="nofollow" href="https://venturebeat.com/2017/11/07/salesforce-shows-how-to-bypass-a-key-bottleneck-in-ai-translation/"&gt;Venturebeat&lt;/a&gt;, &lt;a rel="nofollow" href="https://slator.com/technology/salesforce-joins-neural-machine-translation-race/"&gt;Slator&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;DCN+: Mixed Objective and Deep Residual Coattention for Question Answering,
Caiming Xiong, Victor Zhong and Richard Socher&lt;br&gt;International Conference on Learning Representations (&lt;strong&gt;ICLR 2018&lt;/strong&gt;).
[ &lt;a rel="nofollow" href="https://arxiv.org/abs/1711.00106"&gt;arxiv pdf&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;Regularizing and Optimizing LSTM Language Models,
Stephen Merity, Nitish Shirish Keskar, Richard Socher&lt;br&gt;International Conference on Learning Representations (&lt;strong&gt;ICLR 2018&lt;/strong&gt;).
[ &lt;a rel="nofollow" href="https://arxiv.org/abs/1708.02182"&gt;pdf&lt;/a&gt;, &lt;a rel="nofollow" href="https://github.com/salesforce/awd-lstm-lm"&gt;code&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;A Flexible Approach to Automated RNN Architecture Generation, 
Stephen Merity, Martin Schrimpf, James Bradbury, Richard Socher&lt;br&gt;International Conference on Learning Representations (ICLR 2018 Workshop Track).
[ arxiv pdf, &lt;a rel="nofollow" href="https://einstein.ai/research/domain-specific-language-for-automated-rnn-architecture-search"&gt;blog post&lt;/a&gt;  ]
&lt;/p&gt;
&lt;p&gt;Improving End-to-End Speech Recognition with Policy Learning, 
Yingbo Zhou, Caiming Xiong, Richard Socher&lt;br&gt;IEEE International Conference on Acoustics, Speech and Signal Processing (&lt;strong&gt;ICASSP 2018&lt;/strong&gt;). 
[ &lt;a rel="nofollow" href="https://einstein.ai/static/images/pages/research/improving-end-to-end-speech-models/policy-learning.pdf"&gt;pdf&lt;/a&gt;, &lt;a rel="nofollow" href="https://einstein.ai/research/improving-end-to-end-speech-models"&gt;blog post&lt;/a&gt;  ]
&lt;/p&gt;
&lt;h4&gt;
2017 &lt;/h4&gt;&lt;p&gt;Improving Generalization Performance by Switching from Adam to SGD, 
Nitish Shirish Keskar, Richard Socher&lt;br&gt;[ &lt;a rel="nofollow" href="https://arxiv.org/abs/1712.07628"&gt;arxiv pdf&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;Improved Regularization Techniques for End-to-End Speech Recognition, 
Yingbo Zhou, Caiming Xiong, Richard Socher&lt;br&gt;[ &lt;a rel="nofollow" href="https://einstein.ai/static/images/pages/research/improving-end-to-end-speech-models/improved-regularization-techniques.pdf"&gt;pdf&lt;/a&gt;, &lt;a rel="nofollow" href="https://einstein.ai/research/improving-end-to-end-speech-models"&gt;blog post&lt;/a&gt;  ]
&lt;/p&gt;
&lt;p&gt;Weighted Transformer Network for Machine Translation,
Karim Ahmed, Nitish Shirish Keskar, Richard Socher&lt;br&gt;[ &lt;a rel="nofollow" href="https://arxiv.org/pdf/1711.02132"&gt;arxiv pdf&lt;/a&gt;, &lt;a rel="nofollow" href="https://einstein.ai/research/weighted-transformer"&gt;blog post&lt;/a&gt;  ]
&lt;/p&gt;
&lt;p&gt;Seq2SQL: Generating Structured Queries from Natural Language using Reinforcement Learning,
Victor Zhong, Caiming Xiong, Richard Socher&lt;br&gt;[ &lt;a rel="nofollow" href="https://arxiv.org/abs/1709.00103"&gt;arxiv pdf&lt;/a&gt;, &lt;a rel="nofollow" href="https://einstein.ai/research/how-to-talk-to-your-database"&gt;blog post&lt;/a&gt;, 
&lt;a rel="nofollow" href="https://github.com/salesforce/WikiSQL"&gt;dataset&lt;/a&gt;, Press: &lt;a rel="nofollow" href="https://techcrunch.com/2017/08/29/salesforce-is-using-ai-to-democratize-sql-so-anyone-can-query-databases-in-natural-language/"&gt;TechCrunch&lt;/a&gt;, &lt;a rel="nofollow" href="https://venturebeat.com/2017/08/29/salesforce-creates-ai-tool-for-talking-to-databases/"&gt;Venturebeat&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;Learned in Translation: Contextualized Word Vectors,
Bryan McCann, James Bradbury, Caiming Xiong, Richard Socher&lt;br&gt;Advances in Neural Information Processing Systems (&lt;strong&gt;NIPS 2017&lt;/strong&gt;). 
[ &lt;a rel="nofollow" href="https://einstein.ai/static/images/layouts/research/cove/McCann2017LearnedIT.pdf"&gt;pdf&lt;/a&gt;, &lt;a rel="nofollow" href="https://einstein.ai/research/learned-in-translation-contextualized-word-vectors"&gt;blog post&lt;/a&gt;, 
&lt;a rel="nofollow" href="https://github.com/salesforce/cove"&gt;code&lt;/a&gt;, Press: &lt;a rel="nofollow" href="https://www.technologyreview.com/s/608382/to-build-a-smarter-chatbot-first-teach-it-a-second-language/"&gt;MIT Tech Review&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;Revisiting Activation Regularization for Language RNNs,
Stephen Merity, Bryan McCann, Richard Socher&lt;br&gt;1st Workshop on Learning to Generate Natural Language at ICML 2017. 
[ &lt;a rel="nofollow" href="https://arxiv.org/abs/1708.01009"&gt;pdf&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;A Joint Many-Task Model: Growing a Neural Network for Multiple NLP Tasks,
Kazuma Hashimoto,&amp;nbsp;Caiming Xiong,&amp;nbsp;Yoshimasa Tsuruoka,&amp;nbsp;Richard Socher&lt;br&gt;Conference on Empirical Methods in Natural Language Processing (&lt;strong&gt;EMNLP 2017&lt;/strong&gt;). Also appeared in NIPS 2016 Continual Learning and Deep Networks Workshop. 
[ &lt;a rel="nofollow" href="https://arxiv.org/abs/1611.01587"&gt;pdf&lt;/a&gt;, &lt;a rel="nofollow" href="http://metamind.io/research/multiple-different-natural-language-processing-tasks-in-a-single-deep-model"&gt;blog post&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;Knowing When to Look: Adaptive Attention via A Visual Sentinel for Image Captioning,
Jiasen Lu, Caiming Xiong, Devi Parikh, Richard Socher&lt;br&gt;IEEE Computer Vision and Pattern Recognition (&lt;strong&gt;CVPR 2017&lt;/strong&gt;). 
[ &lt;a rel="nofollow" href="https://arxiv.org/abs/1612.01887"&gt;pdf&lt;/a&gt;, ]
&lt;/p&gt;

&lt;p&gt;Quasi-Recurrent Neural Networks,
James Bradbury,&amp;nbsp;Stephen Merity,&amp;nbsp;Caiming Xiong,&amp;nbsp;Richard Socher&lt;br&gt;International Conference on Learning Representations (&lt;strong&gt;ICLR 2017&lt;/strong&gt;).
[ &lt;a rel="nofollow" href="https://arxiv.org/abs/1611.01576"&gt;pdf&lt;/a&gt;, &lt;a rel="nofollow" href="http://metamind.io/research/new-neural-network-building-block-allows-faster-and-more-accurate-text-understanding/"&gt;blog post&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling,
Hakan Inan,&amp;nbsp;Khashayar Khosravi,&amp;nbsp;Richard Socher&lt;br&gt;International Conference on Learning Representations (&lt;strong&gt;ICLR 2017&lt;/strong&gt;). 
[ &lt;a rel="nofollow" href="https://arxiv.org/abs/1611.01462"&gt;pdf&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;Pointer Sentinel Mixture Models, 
Stephen Merity, Caiming Xiong, James Bradbury, Richard Socher&lt;br&gt;International Conference on Learning Representations (&lt;strong&gt;ICLR 2017&lt;/strong&gt;) and NIPS 2016 Workshop on Multi-class and Multi-label Learning in Extremely Large Label Spaces.
[ &lt;a rel="nofollow" href="http://arxiv.org/abs/1609.07843"&gt;pdf&lt;/a&gt;, &lt;a rel="nofollow" href="http://metamind.io/research/the-wikitext-long-term-dependency-language-modeling-dataset/"&gt;new dataset&lt;/a&gt; ]
&lt;/p&gt;
&lt;h4&gt;
2016&lt;/h4&gt;&lt;p&gt;A Way out of the Odyssey: Analyzing and Combining Recent Insights for LSTMs,
Shayne Longpre, Sabeek Pradhan, Caiming Xiong, Richard Socher&lt;br&gt;[ &lt;a rel="nofollow" href="https://arxiv.org/abs/1611.05104"&gt;pdf&lt;/a&gt;  ]
&lt;/p&gt;
&lt;p&gt;MetaMind Neural Machine Translation System for WMT 2016,
James Bradbury, Richard Socher&lt;br&gt;Proceedings of the First Conference on Machine Translation. Association for Computational Linguistics.&lt;br&gt;[ &lt;a rel="nofollow" href="https://aclweb.org/anthology/W/W16/W16-2308.pdf"&gt;pdf&lt;/a&gt;, &lt;a rel="nofollow" href="http://matrix.statmt.org/matrix/systems_list/1840"&gt;2nd Place in the competition&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;Dynamic Memory Networks for Visual and Textual Question Answering, 
Caiming Xiong, Stephen Merity, Richard Socher&lt;br&gt;The 33rd International Conference on Machine Learning (&lt;strong&gt;ICML 2016&lt;/strong&gt;). 
[ &lt;a rel="nofollow" href="http://arxiv.org/abs/1603.01417"&gt;pdf&lt;/a&gt; , &lt;a rel="nofollow" href="http://www.nytimes.com/2016/03/07/technology/taking-baby-steps-toward-software-that-reasons-like-humans.html"&gt;New York Times&lt;/a&gt;, &lt;a rel="nofollow" href="https://www.technologyreview.com/s/600958/the-memory-trick-making-computers-seem-smarter"&gt;MIT Technology Review&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;Ask Me Anything: Dynamic Memory Networks for Natural Language Processing, 
Ankit Kumar, Ozan Irsoy, Peter Ondruska, Mohit Iyyer, James Bradbury, Ishaan Gulrajani, Victor Zhong, Romain Paulus, Richard Socher&lt;br&gt;The 33rd International Conference on Machine Learning (&lt;strong&gt;ICML 2016&lt;/strong&gt;). &lt;br&gt;Previous versions appeared at NIPS 2015 Deep Learning Symposium; NIPS 2015 workshop on Reasoning, Attention and Memory Workshop &lt;br&gt;[ &lt;a rel="nofollow" href="http://arxiv.org/abs/1506.07285"&gt;pdf&lt;/a&gt; , &lt;a rel="nofollow" href="http://www.wired.com/2015/06/ais-next-frontier-machines-understand-language/"&gt;Wired&lt;/a&gt;, &lt;a rel="nofollow" href="http://www.technologyreview.com/news/538821/computers-are-getting-a-dose-of-common-sense/"&gt;MIT Tech Review&lt;/a&gt;, &lt;a rel="nofollow" href="https://www.metamind.io/dmn"&gt;MetaMind announcement&lt;/a&gt; ]
&lt;/p&gt;
&lt;h4&gt;
2015&lt;/h4&gt;&lt;p&gt;Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks,
Kai Sheng Tai, Richard Socher, and Christopher D. Manning&lt;br&gt;Association for Computational Linguistics 2015 Conference (&lt;strong&gt;ACL 2015&lt;/strong&gt;). [ &lt;a rel="nofollow" href="http://arxiv.org/abs/1503.00075"&gt;pdf&lt;/a&gt; , &lt;a rel="nofollow" href="https://github.com/stanfordnlp/treelstm"&gt;code&lt;/a&gt; ]
&lt;/p&gt;
&lt;h4&gt;
2014&lt;/h4&gt;
&lt;p&gt;Global Belief Recursive Neural Networks, 
Romain Paulus, Richard Socher, Christopher D. Manning &lt;br&gt;Advances in Neural Information Processing Systems (&lt;strong&gt;NIPS 2014&lt;/strong&gt;). [ &lt;a rel="nofollow" href="https://www.socher.org/uploads/Main/PaulusSocherManning_NIPS2014.pdf"&gt;pdf&lt;/a&gt; ]
&lt;/p&gt;
&lt;p&gt;Aspect Specific Sentiment Analysis using Hierarchical Deep Learning,
Himabindu Lakkaraju, Richard Socher, Chris Manning.&lt;br&gt;NIPS Workshop on Deep Learning and Representation Learning, 2014. 
[ &lt;a rel="nofollow" href="https://fb56552f-a-62cb3a1a-s-sites.googlegroups.com/site/deeplearningworkshopnips2014/58.pdf"&gt;pdf&lt;/a&gt; ]
&lt;/p&gt;



&lt;p&gt;Scaling Short-answer Grading by Combining Peer Assessment with Algorithmic Scoring, 
Chinmay Kulkarni, Richard Socher, Michael S. Bernstein, Scott R. Klemmer. &lt;br&gt;2014 ACM Conference on Learning at Scale
[ &lt;a rel="nofollow" href="https://hci.stanford.edu/publications/2014/PeerStudio/las2008-kulkarni-ScalingShort-answerGrading.pdf"&gt;pdf&lt;/a&gt; ].
&lt;/p&gt;
&lt;h4&gt;
2013&lt;/h4&gt;


&lt;p&gt;Grounded Compositional Semantics for Finding and Describing Images with Sentences, 
Richard Socher, Quoc V. Le, Christopher D. Manning, Andrew Y. Ng. &lt;br&gt;Deep Learning Workshop at NIPS 2013 (see TACL 2014 version)
&lt;/p&gt;
&lt;div&gt;
&lt;p&gt;&lt;a rel="nofollow" href="http://nlp.stanford.edu/sentiment/"&gt;Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank&lt;/a&gt;, 
Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Chris Manning,  Andrew Ng and Chris Potts. &lt;br&gt;Conference on Empirical Methods in Natural Language Processing (&lt;strong&gt;EMNLP 2013, Oral&lt;/strong&gt;). [ &lt;a rel="nofollow" href="http://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf"&gt;pdf&lt;/a&gt;, &lt;a rel="nofollow" href="http://nlp.stanford.edu/~socherr/EMNLP2013_SemComp_SuppMat.pdf"&gt;Supplementary Material&lt;/a&gt;, 
&lt;span&gt;&lt;a rel="nofollow" href="http://nlp.stanford.edu/sentiment/"&gt;Website with Live Demo and Downloads&lt;/a&gt;;&lt;/span&gt;
Press: &lt;a rel="nofollow" href="http://engineering.stanford.edu/news/stanford-algorithm-analyzes-sentence-sentiment-advances-machine-learning"&gt;Stanford release&lt;/a&gt;, 
&lt;a rel="nofollow" href="http://www.wired.com/wiredenterprise/2013/10/nasent-deep-learning/"&gt;Wired&lt;/a&gt;, 
&lt;a rel="nofollow" href="http://www.boston.com/bostonglobe/ideas/brainiac/2013/11/can_you_teach_a.html"&gt;Boston Globe&lt;/a&gt;
&lt;a rel="nofollow" href="https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/"&gt;Related Kaggle Competition&lt;/a&gt; ];
&lt;/p&gt;&lt;/div&gt;
&lt;p&gt;Bilingual Word Embeddings for Phrase-Based Machine Translation, 
Will Zou, Richard Socher, Daniel Cer and Christopher Manning. &lt;br&gt;Conference on Empirical Methods in Natural Language Processing (&lt;strong&gt;EMNLP 2013, Short&lt;/strong&gt;).
[ &lt;a rel="nofollow" href="http://ai.stanford.edu/~wzou/emnlp2013_ZouSocherCerManning.pdf"&gt;pdf&lt;/a&gt; ]
&lt;/p&gt;



&lt;p&gt;Zero-Shot Learning Through Cross-Modal Transfer, 
Richard Socher, Milind Ganjoo, Hamsa Sridhar, Osbert Bastani, Christopher D. Manning, Andrew Y. Ng. &lt;br&gt;International Conference on Learning Representations (ICLR 2013, Workshop Track, Oral).
[ &lt;a rel="nofollow" href="http://arxiv.org/pdf/1301.3666v2.pdf"&gt;pdf&lt;/a&gt;, &lt;a href="https://www.socher.org/index.php/Main/Zero-ShotLearningThroughCross-ModalTransfer"&gt;website&lt;/a&gt;  ]
&lt;/p&gt;
&lt;h4&gt;
2012&lt;/h4&gt;


&lt;p&gt;Stanford’s System for Parsing the English Web, 
David McClosky, Wanxiang Che, Marta Recasens, Mengqiu Wang, Richard Socher, and Christopher D. Manning &lt;br&gt;In Proceedings of First Workshop on Syntactic Analysis of Non-Canonical Language (SANCL at NAACL, 2012).
[ &lt;a rel="nofollow" href="http://nlp.stanford.edu/pubs/mcclosky-sancl-12.pdf"&gt;pdf&lt;/a&gt;, &lt;a rel="nofollow" href="http://nlp.stanford.edu/pubs/mcclosky-sancl-12.bib"&gt;bib&lt;/a&gt; ]
&lt;/p&gt;
&lt;h4&gt;
2011&lt;/h4&gt;



&lt;h4&gt;
2010&lt;/h4&gt;


&lt;h4&gt;
2009&lt;/h4&gt;&lt;p&gt;&lt;a href="https://www.socher.org/index.php/Main/ABayesianAnalysisOfDynamicsInFreeRecall"&gt;A Bayesian analysis of dynamics in free recall&lt;/a&gt;, 
Richard Socher, Sam J. Gershman, Adler Perotte, Per Sederberg, Ken A. Norman, and David M. Blei. &lt;br&gt;Advances in Neural Information Processing Systems 22 (&lt;strong&gt;NIPS 2009&lt;/strong&gt;). 
[ &lt;a rel="nofollow" href="https://www.socher.org/uploads/Main/BayesianRecall-nips2009.pdf"&gt;pdf&lt;/a&gt; ]
&lt;/p&gt;


&lt;h4&gt;
2008&lt;/h4&gt;
&lt;h4&gt;
Former Students&lt;/h4&gt;&lt;div&gt;
&lt;p&gt;Small subset of students or interns that I supervised at some point.
&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Jeffrey Pennington, Google Brain
&lt;/li&gt;&lt;li&gt;Mohit Iyyer, professor in computer science at UMass Amherst
&lt;/li&gt;&lt;li&gt;Tanay Tandon, Founder at Athelas
&lt;/li&gt;&lt;li&gt;Ankit Kumar - Co-Founder &amp;amp; CTO - Ubiquity6 Inc.
&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;
&lt;h4&gt;
Theses&lt;/h4&gt;
&lt;/div&gt;&lt;/div&gt;&lt;a href="https://www.socher.org/index.php/Main/HomePage"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Fri, 12 Jun 2020 12:17:46 UT
      </pubDate>
      <guid>
        https://www.socher.org/index.php/Main/HomePage
      </guid>
    </item>
    <item>
      <title>
        Page not found | Center for the Study and Teaching of Writing
      </title>
      <link>
        https://cstw.osu.edu/writing-resources/dissertation-and-thesis-support
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div data-off-canvas-main-canvas=""&gt;

&lt;header role="banner"&gt;

    &lt;div role="navigation" id="osu_navbar" aria-labelledby="osu_navbar_heading"&gt;
      &lt;h2 id="osu_navbar_heading"&gt;Ohio State nav bar&lt;/h2&gt;

      &lt;div&gt;
        &lt;div&gt;
          &lt;p&gt;&lt;a title="The Ohio State University" href="http://osu.edu/"&gt;The Ohio State University&lt;/a&gt;&lt;/p&gt;
        &lt;/div&gt;
        

        &lt;div&gt;
            &lt;ul&gt;
              &lt;li&gt;&lt;a href="http://www.osu.edu/help.php"&gt;Help&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href="http://buckeyelink.osu.edu/"&gt;BuckeyeLink&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href="http://www.osu.edu/map/"&gt;Map&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href="http://www.osu.edu/findpeople.php"&gt;Find People&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href="https://email.osu.edu/"&gt;Webmail&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href="http://www.osu.edu/search/"&gt;Search Ohio State&lt;/a&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    
    &lt;div&gt;
      &lt;p&gt;&lt;a href="https://cstw.osu.edu/"&gt;
          &lt;img id="dep-logo-img" src="https://cstw.osu.edu/sites/default/files/logos/department-logo.svg" title="Center for the Study and Teaching of Writing" alt="Center for the Study and Teaching of Writing"&gt;
        &lt;/a&gt;

        &lt;a href="https://artsandsciences.osu.edu/"&gt;
                      &lt;img id="asc-logo-img" src="https://cstw.osu.edu/themes/asc_bootstrap/images/logos/asc-logo.svg" title="College of Arts and Sciences logo" alt="College of Arts and Sciences logo"&gt;
                  &lt;/a&gt;
      &lt;/p&gt;
      &lt;p&gt;&lt;a href="https://artsandsciences.osu.edu/"&gt;
                      &lt;img id="asc-logo-img-mobile" src="https://cstw.osu.edu/themes/asc_bootstrap/images/logos/asc-logo-mobile.svg" title="College of Arts and Sciences logo" alt="College of Arts and Sciences logo"&gt;
                  &lt;/a&gt;
        &lt;a href="https://cstw.osu.edu/"&gt;
          &lt;img id="dep-logo-img" src="https://cstw.osu.edu/sites/default/files/logos/department-logo-mobile.svg" title="Center for the Study and Teaching of Writing" alt="Center for the Study and Teaching of Writing"&gt;
        &lt;/a&gt;
      &lt;/p&gt;
    &lt;/div&gt;

  &lt;/header&gt;

  &lt;div id="main-nav"&gt;
        &lt;nav aria-label="Main"&gt;
            &lt;div&gt;
    &lt;section id="block-mainnavigation"&gt;
  
    

      &lt;span aria-label="Toggle Search" role="button"&gt;
  &lt;a title="Search" href="#"&gt;
    &lt;i&gt;&lt;/i&gt;
  &lt;/a&gt;
&lt;/span&gt;

&lt;ul id="superfish-main"&gt;
  
&lt;li id="main-menu-link-content240e585f-733c-4816-9db6-1de38e706fca"&gt;&lt;a title="Our Mission here at CSTW" rel="" href="https://cstw.osu.edu/our-mission"&gt;Who We Are&lt;/a&gt;&lt;ul&gt;&lt;li id="main-menu-link-content73187732-1535-4f1b-8212-ba6ca301ec8f"&gt;&lt;a title="FAQs about the Writing Center" href="https://cstw.osu.edu/our-mission/faqs-facts-myths-about-cstw"&gt;FAQs, Facts, &amp;amp; Myths&lt;/a&gt;&lt;/li&gt;&lt;li id="main-menu-link-contentbc062670-3b72-4446-ae34-cd740e8a43c3"&gt;&lt;a title="CSTW Faculty, Staff and Consultants" href="https://cstw.osu.edu/our-mission/our-faculty-staff-tas"&gt;Faculty, Staff, &amp;amp; TAs&lt;/a&gt;&lt;/li&gt;&lt;li id="main-menu-link-content01b5ee97-d449-40c3-a9f2-599f7bd0f1ae"&gt;&lt;a title="List of Upcoming CSTW Events" href="https://cstw.osu.edu/our-mission/our-upcoming-events"&gt;Upcoming Events&lt;/a&gt;&lt;/li&gt;&lt;li id="main-menu-link-content445c6615-b451-43a0-940a-9a4b80d42c55"&gt;&lt;a title="Publications Written By CSTW Faculty, Staff, and Consultants" href="https://cstw.osu.edu/our-mission/selected-publications-cstw-faculty-staff-and-consultants"&gt;Publications&lt;/a&gt;&lt;/li&gt;&lt;li id="main-menu-link-content48db9602-4c54-4548-a90c-8a33f793d40d"&gt;&lt;a title="History of the Center for the Study and Teaching of Writing (CSTW)" href="https://cstw.osu.edu/our-mission/our-history"&gt;History&lt;/a&gt;&lt;/li&gt;&lt;li id="main-menu-link-content08e9aa34-60b2-466a-ad42-312cc3bce9e9"&gt;&lt;a title="CSTW Locations and Contact Information" href="https://cstw.osu.edu/our-mission/our-location-and-contact"&gt;Location and Contact&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li id="main-menu-link-content6c1bd44c-8688-40df-b755-f6eae5b1f6f8"&gt;&lt;a title="CSTW Programs and Services" href="https://cstw.osu.edu/our-programs"&gt;What We Do&lt;/a&gt;&lt;ul&gt;&lt;li id="main-menu-link-content9ea315ce-a775-4c9a-8bba-d040e549f712"&gt;&lt;a title="Writing Center Tutorial Services" href="https://cstw.osu.edu/our-programs/writing-center"&gt;Writing Center&lt;/a&gt;&lt;/li&gt;&lt;li id="main-menu-link-contentf859de76-baaf-41fd-9242-7097ab240917"&gt;&lt;a title="Faculty Development Help for Teaching Writing Across the Curriculum" href="https://cstw.osu.edu/our-programs/writing-across-curriculum"&gt;Writing Across the Curriculum&lt;/a&gt;&lt;/li&gt;&lt;li id="main-menu-link-content5e406027-ffc3-4b9f-95c5-8e0caedbb9e2"&gt;&lt;a title="Program that Places Tutors in Writing Courses at OSU" href="https://cstw.osu.edu/our-programs/writing-associates-program"&gt;Writing Associates Program&lt;/a&gt;&lt;/li&gt;&lt;li id="main-menu-link-contentf2d98520-673c-462d-af72-fff08e9e6dc5"&gt;&lt;a title="Collaboration with the Columbus Global Academy" href="https://cstw.osu.edu/our-programs/columbus-global-academy"&gt;Columbus Global Academy&lt;/a&gt;&lt;/li&gt;&lt;li id="main-menu-link-contenta9107449-8cb0-4012-8aa1-f55b02917b23"&gt;&lt;a title="Research Projects Undertaken by the CSTW Faculty and Staff" href="https://cstw.osu.edu/our-programs/research"&gt;Research&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li id="main-menu-link-content6c198ea8-3d22-4f51-b016-9cc5b593013f"&gt;&lt;a title="Writing Tips and Tools for Instructors and Students" href="https://cstw.osu.edu/tips-and-tools"&gt;Tips and Tools&lt;/a&gt;&lt;/li&gt;&lt;li id="main-menu-link-content2a0ff99c-9adc-42b9-9c64-740b259d1e6f"&gt;&lt;a title="Make an Appointment for Writing Center Tutoring" href="https://cstw.osu.edu/make-writing-center-appointment"&gt;Make an Appointment&lt;/a&gt;&lt;ul&gt;&lt;li id="main-menu-link-contenta6bdd499-4367-4424-b510-645edeaa9665"&gt;&lt;a title="Cancel an Individual Tutoring Appointment" href="https://cstw.osu.edu/make-writing-center-appointment/cancel-writing-center-appointment"&gt;Cancel a Writing Center Appointment&lt;/a&gt;&lt;/li&gt;&lt;li id="main-menu-link-content42d759b9-85b6-4f5a-a638-1c5294508429"&gt;&lt;a title="Instructors Schedule a Visit by Writing Center Staff to their Classrooms Here" href="https://cstw.osu.edu/make-writing-center-appointment/schedule-writing-center-classroom-visit"&gt;Schedule a Writing Center Classroom Visit&lt;/a&gt;&lt;/li&gt;&lt;li id="main-menu-link-contentbb1aed7a-3f80-4b17-af11-6363307e1d24"&gt;&lt;a title="Get Help with WCOnline Application for Scheduling Tutorials" href="https://cstw.osu.edu/make-writing-center-appointment/wconline-support"&gt;WCOnline Support&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li id="main-menu-link-contentb36d2a4c-8aa5-41f4-b6a3-dd803aba4965"&gt;&lt;a title="See and Apply for Positions at CSTW" href="https://cstw.osu.edu/work-for-us"&gt;Work for Us&lt;/a&gt;&lt;ul&gt;&lt;li id="main-menu-link-content78a1e690-26b5-4875-9943-8e75e356f649"&gt;&lt;a title="CSTW's Writing Center Positions" href="https://cstw.osu.edu/work-for-us/writing-center-positions"&gt;Writing Center Positions&lt;/a&gt;&lt;/li&gt;&lt;li id="main-menu-link-content11bbfd45-576a-4d47-b07c-4c2caae61609"&gt;&lt;a title="See and Apply for Positions in the WAC Program" href="https://cstw.osu.edu/wac-positions"&gt;WAC Positions&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li id="main-menu-link-content8a659e7d-41f9-4f60-8d14-fde195781953"&gt;&lt;a title="Find Information about Past CSTW Employees" href="https://cstw.osu.edu/alumni-and-friends"&gt;Alumni and Friends&lt;/a&gt;&lt;/li&gt;&lt;li id="main-menu-link-contentd2807631-96fb-48cd-b459-a406a5dfde57"&gt;&lt;a title="Make a donation to CSTW" href="https://cstw.osu.edu/donate"&gt;Donate&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;span aria-label="Toggle Search" role="button"&gt;
  &lt;a title="Search" href="#"&gt;
    &lt;i&gt;&lt;/i&gt;
  &lt;/a&gt;
&lt;/span&gt;

  &lt;/ul&gt;&lt;/section&gt;

&lt;div role="search" id="block-asc-bootstrap-search" data-drupal-selector="search-block-form"&gt;
  
      &lt;h2&gt;Search&lt;/h2&gt;
    
      &lt;form id="search-block-form" method="get" action="/search/node"&gt;
  &lt;div&gt;
      &lt;p&gt;&lt;label for="edit-keys"&gt;Search&lt;/label&gt;&lt;/p&gt;

  
  
  &lt;/div&gt;


&lt;/form&gt;

  &lt;/div&gt;

  &lt;/div&gt;

        &lt;/nav&gt;
      &lt;/div&gt;
  &lt;div id="breadcrumb-container"&gt;
      &lt;nav aria-label="Breadcrumb"&gt;
          &lt;div&gt;
        &lt;ol&gt;
          &lt;li&gt;
                  &lt;a href="https://cstw.osu.edu/"&gt;Home&lt;/a&gt;
              &lt;/li&gt;
          &lt;li&gt;
                  Page not found
              &lt;/li&gt;
      &lt;/ol&gt;


  &lt;/div&gt;

      &lt;/nav&gt;
    &lt;/div&gt;

    &lt;section role="main"&gt;


                
                          &lt;a id="main-content"&gt;&lt;/a&gt;
            &lt;div&gt;
        &lt;h2&gt;Page not found&lt;/h2&gt;&lt;p&gt;

  The requested page could not be found.

  &lt;/p&gt;&lt;/div&gt;

        
                
                
                
                
      &lt;/section&gt;

 

&lt;div id="subfoot"&gt;
  &lt;div&gt;
    &lt;p&gt;&lt;a href="https://osu.edu/"&gt;
        &lt;img alt="The Ohio State University logo" src="https://cstw.osu.edu/themes/asc_bootstrap/images/osu-web-footer-wordmark-rev.png"&gt;
      &lt;/a&gt;
    &lt;/p&gt;

    &lt;div&gt;
      &lt;ul&gt;
        &lt;li id="access-area"&gt;
          If you have a disability and experience difficulty accessing this site, please contact us for assistance via email at &lt;a title="Email for accessibility assistance" href="mailto:asc-accessibility@osu.edu"&gt;asc-accessibility@osu.edu&lt;/a&gt;.
        &lt;/li&gt;
        &lt;li&gt;
          &lt;a href="https://go.osu.edu/privacy"&gt;
            Privacy Policy
          &lt;/a&gt;
        &lt;/li&gt;
        &lt;li&gt;
                      &lt;a href="https://cstw.osu.edu/saml_login"&gt;
              LOGIN
            &lt;/a&gt;
                &lt;/li&gt;
      &lt;/ul&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div&gt;
    &lt;p&gt;&lt;small&gt;© 2021. The Ohio State University&lt;/small&gt;&lt;/p&gt;

    &lt;div&gt;
      &lt;p&gt;&lt;small&gt;&lt;i&gt;Designed and built by &lt;a href="https://asctech.osu.edu/services/web-services"&gt;ASCTech Web Services&lt;/a&gt;&lt;/i&gt;&lt;/small&gt;&lt;/p&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;&lt;/div&gt;&lt;a href="https://cstw.osu.edu/writing-resources/dissertation-and-thesis-support"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Thu, 25 Jun 2020 07:52:27 UT
      </pubDate>
      <guid>
        https://cstw.osu.edu/writing-resources/dissertation-and-thesis-support
      </guid>
    </item>
    <item>
      <title>
        ETS Research: Automated Scoring of Writing Quality&lt;/title&gt;
		&lt;meta name="description" content="Learn about ETS research on automated scoring of writing quality, including papers, articles, and reports on the e-rater essay scoring engine." /&gt;
		&lt;meta name="keywords" content="automated scoring, natural language processing, artificial intelligence, grading essays, e-rater" /&gt;

		&lt;script src="/rsc/fonts/fontawesome-pro-5.8.1-web/js/all.min.js"&gt;&lt;/script&gt;
		&lt;link rel="stylesheet" href="/rsc/fonts/fontawesome-pro-5.8.1-web/css/all.min.css"&gt;
		&lt;link rel="stylesheet" href="/rsc/css/base.min.css"&gt;
		&lt;link rel="stylesheet" href="/rsc/surveygizmo/ets-survey.css"&gt;
		
		&lt;!-- Google Tag Manager --&gt;
		&lt;script&gt;(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
		new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
		j=d.createElement(s),dl=l!='dataLayer'?'&amp;l='+l:'';j.async=true;j.src=
		'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
		})(window,document,'script','dataLayer','GTM-KPNMN62');&lt;/script&gt;
		&lt;!-- End Google Tag Manager --&gt;
		
			
	&lt;/head&gt;
	
	



	
	&lt;body class="ets-org init  "&gt;
&lt;!--stopindex--&gt;

		&lt;svg display="none" width="0" height="0" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
			&lt;defs&gt;
				&lt;symbol id="icon-angle-up" viewBox="0 0 658 1024"&gt;
					&lt;title&gt;angle-up&lt;/title&gt;
					&lt;path class="path1" d="M614.286 676.571q0 7.429-5.714 13.143l-28.571 28.571q-5.714 5.714-13.143 5.714t-13.143-5.714l-224.571-224.571-224.571 224.571q-5.714 5.714-13.143 5.714t-13.143-5.714l-28.571-28.571q-5.714-5.714-5.714-13.143t5.714-13.143l266.286-266.286q5.714-5.714 13.143-5.714t13.143 5.714l266.286 266.286q5.714 5.714 5.714 13.143z"&gt;&lt;/path&gt;
				&lt;/symbol&gt;
				&lt;symbol id="icon-angle-right" viewBox="0 0 366 1024"&gt;
					&lt;title&gt;angle-right&lt;/title&gt;
					&lt;path class="path1" d="M340 548.571q0 7.429-5.714 13.143l-266.286 266.286q-5.714 5.714-13.143 5.714t-13.143-5.714l-28.571-28.571q-5.714-5.714-5.714-13.143t5.714-13.143l224.571-224.571-224.571-224.571q-5.714-5.714-5.714-13.143t5.714-13.143l28.571-28.571q5.714-5.714 13.143-5.714t13.143 5.714l266.286 266.286q5.714 5.714 5.714 13.143z"&gt;&lt;/path&gt;
				&lt;/symbol&gt;
				&lt;symbol id="icon-angle-down" viewBox="0 0 658 1024"&gt;
					&lt;title&gt;angle-down&lt;/title&gt;
					&lt;path class="path1" d="M614.286 420.571q0 7.429-5.714 13.143l-266.286 266.286q-5.714 5.714-13.143 5.714t-13.143-5.714l-266.286-266.286q-5.714-5.714-5.714-13.143t5.714-13.143l28.571-28.571q5.714-5.714 13.143-5.714t13.143 5.714l224.571 224.571 224.571-224.571q5.714-5.714 13.143-5.714t13.143 5.714l28.571 28.571q5.714 5.714 5.714 13.143z"&gt;&lt;/path&gt;
				&lt;/symbol&gt;
				&lt;symbol id="icon-angle-left" viewBox="0 0 366 1024"&gt;
					&lt;title&gt;angle-left&lt;/title&gt;
					&lt;path class="path1" d="M358.286 310.857q0 7.429-5.714 13.143l-224.571 224.571 224.571 224.571q5.714 5.714 5.714 13.143t-5.714 13.143l-28.571 28.571q-5.714 5.714-13.143 5.714t-13.143-5.714l-266.286-266.286q-5.714-5.714-5.714-13.143t5.714-13.143l266.286-266.286q5.714-5.714 13.143-5.714t13.143 5.714l28.571 28.571q5.714 5.714 5.714 13.143z"&gt;&lt;/path&gt;
				&lt;/symbol&gt;
				&lt;symbol id="icon-close" viewBox="0 0 40 35"&gt;
					&lt;title&gt;close&lt;/title&gt;
					&lt;path class="ets-svg" d="M32.2246094,31.3613281c-1.0078125,1.0078125-2.640625,1.0078125-3.6464844,0L6.6879883,9.4741211 c-1.0078125-1.0083008-1.0078125-2.6411133,0-3.6489258l0,0c1.0078125-1.0083008,2.6411133-1.0083008,3.6479492,0 l21.8886719,21.8876953C33.2324219,28.7207031,33.2324219,30.3535156,32.2246094,31.3613281L32.2246094,31.3613281z"/&gt;
					&lt;path class="ets-svg" d="M32.2246094,5.8251953c1.0078125,1.0078125,1.0078125,2.640625,0,3.6489258l-21.8886719,21.887207 c-1.0078125,1.0078125-2.6411133,1.0078125-3.6479492,0l0,0c-1.0078125-1.0078125-1.0078125-2.640625,0-3.6484375 L28.5771484,5.8251953C29.5839844,4.815918,31.2167969,4.815918,32.2246094,5.8251953L32.2246094,5.8251953z"/&gt;
				&lt;/symbol&gt;
				&lt;symbol id="icon-user" viewBox="0 0 40 35"&gt;
					&lt;title&gt;user&lt;/title&gt;
					&lt;path class="ets-svg" d="M19.8041992,2c3.5874023,0,6.4956055,2.9082031,6.4956055,6.4960938 c0,3.5874023-2.9082031,6.4960938-6.4956055,6.4960938c-3.5878906,0-6.4960938-2.9086914-6.4960938-6.4960938 C13.3081055,4.9082031,16.2163086,2,19.8041992,2z M33.8046875,34c0.1269531-1,0.2089844-1.7695312,0.2089844-2.6015625 c0-8.0722656-6.2714844-14.6992188-14.0068359-14.6992188C12.2719727,16.6992188,6,23.3671875,6,31.4394531 C6,32.2714844,6.0820312,33,6.2089844,34H33.8046875z"/&gt;
				&lt;/symbol&gt;
				&lt;symbol id="icon-menu-open" viewBox="0 0 17 17"&gt;
					&lt;title&gt;menu open&lt;/title&gt;
					&lt;path class="ets-svg" d="M14.3330078,0H2.6669922C1.1962891,0,0,1.1962891,0,2.6665039v11.6674805 C0,15.8037109,1.1962891,17,2.6669922,17h11.6660156C15.8046875,17,17,15.8037109,17,14.3339844V2.6665039 C17,1.1962891,15.8046875,0,14.3330078,0z M16,14.4003906C16,15.2832031,15.2832031,16,14.3994141,16H2.6005859 C1.7167969,16,1,15.2832031,1,14.4003906V2.5996094C1,1.7163086,1.7167969,1,2.6005859,1h11.7988281 C15.2832031,1,16,1.7163086,16,2.5996094V14.4003906z"/&gt;
					&lt;rect x="4" y="8" class="ets-svg" width="9" height="1.0537109"/&gt;
				&lt;/symbol&gt;
				&lt;symbol id="icon-menu-closed" viewBox="0 0 17 17"&gt;
					&lt;title&gt;menu closed&lt;/title&gt;
					&lt;path class="ets-svg" d="M14.3330078,0H2.6669922C1.1962891,0,0,1.1962891,0,2.6665039v11.6674805 C0,15.8037109,1.1962891,17,2.6669922,17h11.6660156C15.8046875,17,17,15.8037109,17,14.3339844V2.6665039 C17,1.1962891,15.8046875,0,14.3330078,0z M16,14.4003906C16,15.2832031,15.2832031,16,14.3994141,16H2.6005859 C1.7167969,16,1,15.2832031,1,14.4003906V2.5996094C1,1.7163086,1.7167969,1,2.6005859,1h11.7988281 C15.2832031,1,16,1.7163086,16,2.5996094V14.4003906z"/&gt;
					&lt;polygon class="ets-svg" points="9,4 8,4 8,8 4,8 4,9 8,9 8,13 9,13 9,9 13,9 13,8 9,8 	"/&gt;
				&lt;/symbol&gt;
				&lt;symbol id="icon-search" viewBox="0 0 40 35"&gt;
					&lt;title&gt;search&lt;/title&gt;
					&lt;path class="ets-svg" d="M35.01,31.758l-12.02-12.02c1.36-1.948,2.164-4.312,2.164-6.863c0-6.633-5.396-12.03-12.03-12.03 c-6.633,0-12.029,5.396-12.029,12.03c0,6.633,5.396,12.029,12.029,12.029c2.625,0,5.049-0.854,7.029-2.287l11.999,11.998 L35.01,31.758z M13.125,3.515c5.162,0,9.362,4.199,9.362,9.36c0,5.162-4.2,9.361-9.362,9.361c-5.161,0-9.36-4.199-9.36-9.361 C3.765,7.714,7.963,3.515,13.125,3.515z"/&gt;
				&lt;/symbol&gt;
				&lt;symbol id="icon-language" viewBox="0 0 40 35"&gt;
					&lt;title&gt;globe&lt;/title&gt;
					&lt;path class="ets-svg" d="M18.877,34.501c-9.392,0-17.032-7.641-17.032-17.034c0-9.393,7.641-17.033,17.032-17.033 c9.392,0,17.033,7.641,17.033,17.033C35.91,26.86,28.27,34.501,18.877,34.501z M18.878,2.081c-8.484,0-15.387,6.902-15.387,15.387 c0,8.484,6.902,15.388,15.387,15.388c8.483,0,15.386-6.904,15.386-15.388C34.264,8.983,27.361,2.081,18.878,2.081z M12.729,11.732 c-0.044-0.025-0.385-0.02-0.436-0.038c-0.05-0.018-0.198-0.16-0.198-0.16s-0.349-0.13-0.6-0.049 c-0.222,0.071-0.118,0.373-0.066,0.451c0.053,0.079,0.591,0.309,0.732,0.309c0.141,0,0.626,0.013,0.672-0.017 c0.022-0.015,0.194-0.145,0.161-0.27S12.75,11.745,12.729,11.732z M21.057,5.804c-0.095-0.018-0.521,0.403-0.44,0.596 c0.08,0.191,0.854,0.672,0.991,0.682c0.523,0.042,0.726-0.188,0.809-0.379c0.083-0.193,0.019-0.597-0.102-0.68 C22.195,5.94,21.15,5.823,21.057,5.804z M30.077,21.908c-0.195,0.234-0.496,0.814-0.552,1.117c-0.057,0.303,0.207,0.881,0.068,1.102 c-0.138,0.223-0.684,0.443-0.732,0.539c-0.047,0.098,0.008,0.725,0.07,0.932c0.029,0.1,0.53,0.309,1.041,0.496 c-2.574,3.307-6.58,5.441-11.095,5.441c-7.769,0-14.067-6.299-14.067-14.068c0-1.968,0.408-3.841,1.138-5.541 c0.179,0.561,0.406,1.155,0.627,1.376c0.178,0.179,0.477,0.192,0.731,0.192c0.216,0,0.882,0.69,0.979,1.091 c0.097,0.399,0.015,1.246,0.166,1.447c0.247,0.331,1.158,0.876,1.158,1.187v2.138c0,0.705,1.642,1.924,1.642,1.924 s0.882,0.488,1.006,0.822c0.125,0.33,0.002,1.955,0.18,2.385c0.177,0.43,0.579,0.883,0.579,1.213c0,0.332,0.028,0.65,0.028,1.408 c0,0.756,1.053,2.184,1.199,2.273s0.917,0.096,1.179,0c0.262-0.098,0.163-0.717,0.155-0.848c-0.008-0.129-0.523-0.438-0.61-0.58 c-0.087-0.141-0.166-0.713-0.166-1.074s1.131-0.268,1.414-0.506c0.517-0.434,0.664-0.945,1.007-1.131 c0.523-0.271,0.812-0.299,0.979-0.799c0.166-0.496-0.199-0.887,0.014-1.354c0.164-0.354,0.5-0.863,0.827-1.072 c0.623-0.402,1.359-0.43,1.822-1.242c0.46-0.814,0.724-1.49,0.619-1.986c-0.104-0.496-0.323-1.295-0.883-1.295 c-0.238,0-0.931,0.05-1.254-0.123c-0.181-0.099-0.536-0.89-0.705-1.009c-0.593-0.414-2.234-0.068-2.8-0.345 c-0.199-0.097-0.469-1.407-1.124-1.716c-0.135-0.064-1.228-0.083-1.634-0.048c-0.274,0.022-0.71,0.646-1.131,0.703 c-0.421,0.056-1.283,0.233-1.517-0.126c-0.215-0.327-0.73-1.281-0.849-1.625c-0.118-0.347-0.626-0.787-0.875-0.884 c-0.249-0.097-0.553-0.359-0.553-0.69c0-0.427,0.011-0.972,0.011-0.972s0.651-0.875,1.121-0.916 c0.468-0.042,0.744,0.371,0.965,0.371c0.221,0,0.898,0.029,1.117-0.164c0.22-0.194,0.568-0.513,0.814-0.787 c0.245-0.272-0.012-0.802,0.468-1.09c0.48-0.286,1.234,0.3,1.917-0.178c0.276-0.193,0.441-0.925,0.606-1.048 c0.166-0.125,1.402-0.112,1.863-0.112c0.46,0,0.44-0.329,0.44-0.606c0-0.277-0.635-0.6-1.917-0.579c-0.45,0.007-1.742,0.065-2.013,0 c-0.138-0.033-0.387-0.438-0.6-0.831c0.523-0.244,1.058-0.463,1.614-0.643c0.312,0.346,0.663,0.711,0.765,0.729 c0.384,0.07,0.747-0.167,0.869-0.276c0.059-0.052,0.003-0.458-0.067-0.86c0.716-0.141,1.455-0.216,2.207-0.245 c-0.083,0.378-0.157,0.786-0.126,0.934c0.063,0.302,0.303,0.502,0.758,0.53c0.469,0.029,0.766,0.014,0.883-0.138 s0.018-0.449,0.274-0.593c0.193-0.107,0.669,0.08,0.896,0.007c0.096-0.03,0.24-0.264,0.384-0.526 c1.278,0.233,2.491,0.642,3.626,1.195c0.014,0.295,0.025,0.608,0.033,0.868c0.007,0.392-0.703,0.911-0.76,1.366 C24.28,7.3,24.249,7.62,24.365,7.964c0.096,0.29,0.924,0.288,1.13,0.25c0.221-0.042,0.633-0.018,0.688-0.333 c0.057-0.313-0.088-0.651,0.016-0.924c0.103-0.273,0.564-0.18,0.951-0.165c0.388,0.016,0.178,0.579,0.703,0.718 c0.076,0.02,0.354,0.031,0.552,0c0.054-0.008,0.196-0.018,0.377-0.025c0.747,0.742,1.403,1.575,1.972,2.47 c-0.753-0.222-1.59-0.431-2.061-0.431c-0.992,0-3.752,0.483-3.752,1.641c0,0.482,0.006,0.89,0.045,1.233 c0.086,0.701,1.281,1.263,1.488,1.593c0.207,0.33,0.262,1.654,0.496,1.974c0.233,0.317,1.186,0.263,1.322,0.166 c0.139-0.101,0.455-0.595,0.689-0.663c0.234-0.069,0.974-0.148,1.173-0.11c0.331,0.061,0.602,0.153,0.661,0.759 c0.11,1.103-0.164,1.033-0.562,1.308c-0.236,0.161-0.095,1.071-0.043,1.188c0.124,0.275,1.326,0.652,1.364,0.965 c0.041,0.314-0.009,1.596-0.206,1.793C31.176,21.57,30.387,21.535,30.077,21.908z"/&gt;
				&lt;/symbol&gt;
				&lt;symbol id="icon-bars" viewBox="0 0.394 40 46.8"&gt;
					&lt;title&gt;bars&lt;/title&gt;
					&lt;path class="ets-svg" d="M38.5,7.1235352c0,1.4599609-1.1855469,2.9169922-2.6445312,2.9169922H4.1967773 C2.7358398,10.0405273,1.5,8.5834961,1.5,7.1235352V6.8134766c0-1.4599609,1.2358398-2.7729492,2.6967773-2.7729492h31.6606445 C37.3144531,4.0405273,38.5,5.3535156,38.5,6.8134766V7.1235352z"/&gt;
					&lt;path class="ets-svg" d="M38.5,18.2011719c0,1.4609375-1.1855469,2.8398438-2.6445312,2.8398438H4.1967773 C2.7358398,21.0410156,1.5,19.6621094,1.5,18.2011719v-0.3095703c0-1.4599609,1.2358398-2.8500977,2.6967773-2.8500977h31.6606445 c1.4570312,0,2.6425781,1.3901367,2.6425781,2.8500977V18.2011719z"/&gt;
					&lt;path class="ets-svg" d="M38.5,29.3964844c0,1.4589844-1.1855469,2.6445312-2.6445312,2.6445312H4.1967773 C2.7358398,32.0410156,1.5,30.8554688,1.5,29.3964844v-0.3105469c0-1.4589844,1.2358398-3.0449219,2.6967773-3.0449219h31.6606445 c1.4570312,0,2.6425781,1.5859375,2.6425781,3.046875V29.3964844z"/&gt;
				&lt;/symbol&gt;
				&lt;symbol id="icon-contact" viewBox="0 0 40 35"&gt;
					&lt;title&gt;phone&lt;/title&gt;
					&lt;path class="ets-svg" d="M6.553,10.634C7.214,8.075,8.19,6.146,9.486,4.851l0.496-0.499c0.795-0.793,1.523-1.175,2.185-1.143 c0.66,0.037,1.432,0.493,2.311,1.374c2.498,2.501,2.85,4.649,1.055,6.446l-0.801,0.8c-0.609,0.609-0.958,1.134-1.047,1.569 c-0.088,0.438,0.037,1.046,0.375,1.826c0.586,1.366,1.878,3.051,3.878,5.051c2.025,2.026,3.734,3.321,5.125,3.882 c1.227,0.485,2.312,0.256,3.251-0.684l0.763-0.763c1.836-1.84,4.022-1.492,6.552,1.042c0.855,0.854,1.311,1.602,1.358,2.237 c0.053,0.634-0.283,1.312-1.002,2.034l-0.585,0.586c-1.244,1.246-3.195,2.256-5.854,3.038c-2.04-0.858-4.077-2.008-6.112-3.449 c-2.031-1.442-4.061-3.175-6.085-5.202c-2.051-2.054-3.808-4.108-5.274-6.17C8.608,14.768,7.435,12.702,6.553,10.634z"/&gt;
				&lt;/symbol&gt;
				&lt;symbol id="icon-store" viewBox="0 0 40 35"&gt;
					&lt;title&gt;store
      </title>
      <link>
        https://www.ets.org/research/topics/as_nlp/writing_quality/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;

	

























				









		








	

























				









		



&lt;p&gt;The &lt;span&gt;e-rater&lt;/span&gt;&lt;sup&gt;®&lt;/sup&gt; automated writing evaluation engine is ETS's patented capability for automated evaluation of expository, persuasive and summary essays. Multiple assessment programs use the engine. The engine is used in combination with human raters to score the writing sections of the &lt;span&gt;TOEFL iBT&lt;/span&gt;&lt;sup&gt;®&lt;/sup&gt; and &lt;span&gt;GRE&lt;/span&gt;&lt;sup&gt;®&lt;/sup&gt; tests.&lt;/p&gt;
&lt;p&gt;The &lt;span&gt;e-rater&lt;/span&gt; engine is also used as the sole score in learning contexts, such as formative use in a classroom setting with ETS's &lt;span&gt;Criterion&lt;/span&gt;&lt;sup&gt;®&lt;/sup&gt; online essay evaluation system. In the &lt;span&gt;Criterion&lt;/span&gt; application, the engine is used to generate individualized feedback for students, addressing an increasingly important need for automated essay evaluation that is reliable, valid, fast and flexible.&lt;/p&gt;
&lt;p&gt;The &lt;span&gt;e-rater&lt;/span&gt; engine features related to writing quality include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;errors in grammar (e.g., subject-verb agreement)&lt;/li&gt;
&lt;li&gt;usage (e.g., preposition selection)&lt;/li&gt;
&lt;li&gt;mechanics (e.g., capitalization)&lt;/li&gt;
&lt;li&gt;style (e.g., repetitious word use)&lt;/li&gt;
&lt;li&gt;discourse structure (e.g., presence of a thesis statement, main points)&lt;/li&gt;
&lt;li&gt;vocabulary usage (e.g., relative sophistication of vocabulary)&lt;/li&gt;
&lt;li&gt;sentence variety&lt;/li&gt;
&lt;li&gt;source use&lt;/li&gt;
&lt;li&gt;discourse coherence quality&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;span&gt;e-rater&lt;/span&gt; engine can also automatically detect responses that are off-topic or otherwise anomalous and, therefore, should not be scored.&lt;/p&gt;
&lt;p&gt;ETS has an active research agenda that investigates new automated scoring features for genres of writing beyond traditional essay genres, and now includes source-based and argumentative writing tasks found on assessments, as well as lab reports or social science papers.&lt;/p&gt;
&lt;h2&gt;Featured Publications&lt;/h2&gt;
&lt;p&gt;Below are some recent or significant publications that our researchers have authored that highlight research in automated writing evaluation.&lt;/p&gt;
&lt;h3&gt;2017&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href="https://www.ets.org/research/policy_research_reports/publications/chapter/2017/jzbr"&gt;Exploring Relationships Between Writing &amp;amp; Broader Outcomes with Automated Writing Evaluation&lt;/a&gt;&lt;/strong&gt;&lt;br&gt;J. Burstein, D. McCaffrey, B. Beigman Klebanov, &amp;amp; G. Ling&lt;br&gt;Paper in &lt;em&gt;Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications&lt;/em&gt;, pp. 101–108&lt;/p&gt;
&lt;p&gt;The exploratory study was conducted using test-taker essays from a standardized writing assessment of postsecondary student learning outcomes. Findings showed that for the essays, automated writing evaluation (AWE) features were found to be predictors of broader outcomes measures: college success indicators and learning outcomes measures. &lt;a href="https://www.ets.org/research/policy_research_reports/publications/chapter/2017/jzbr"&gt;Learn more about this publication &amp;gt; &lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href="https://www.ets.org/research/policy_research_reports/publications/chapter/2017/jzbs"&gt;Detecting Good Arguments in a Non-Topic-Specific Way: An Oxymoron?&lt;/a&gt;&lt;/strong&gt;&lt;br&gt;B. Beigman Klebanov, B. Gyawali, &amp;amp; Y. Song&lt;br&gt;Paper in &lt;em&gt;Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, Volume 2: Short Papers&lt;/em&gt;, pp. 244–249&lt;/p&gt;
&lt;p&gt;We investigate the extent to which it is possible to close the performance gap between topic-specific and across-topics models for identification of good arguments. &lt;a href="https://www.ets.org/research/policy_research_reports/publications/chapter/2017/jzbs"&gt;Learn more about this publication &amp;gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;2016&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://journals.equinoxpub.com/index.php/CALICO/article/view/26374"&gt;&lt;span&gt;Informing Automated Writing Evaluation Using the Lens of Genre: Two Studies&lt;/span&gt;&lt;/a&gt;&lt;br&gt; J. Burstein, N. Elliott, &amp;amp; H. Molloy&lt;br&gt;&lt;em&gt;CALICO Journal, &lt;/em&gt;Vol. 33, No. 1&lt;/p&gt;
&lt;p&gt;To construct-relevant systems used for writing instruction and assessment, researchers conducted two investigations of post-secondary writing requirements and faculty perceptions of student writing proficiency. Study results suggested ways that the role of automated writing evaluation might be expanded and aligned with instruction in higher education. &lt;a href="https://journals.equinoxpub.com/index.php/CALICO/article/view/26374"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;2015&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://aclweb.org/anthology/W/W15/W15-1402.pdf"&gt;&lt;span&gt;Supervised Word-Level Metaphor Detection: Experiments with Concreteness and Reweighting of Examples&lt;/span&gt;&lt;/a&gt;&lt;br&gt; B. Beigman-Klebanov, C. W. Leong, &amp;amp; M. Flor&lt;br&gt; Paper in &lt;span&gt;Proceedings of the Third Workshop on Metaphor in NLP&lt;/span&gt;, pp. 11–20&lt;/p&gt;
&lt;p&gt;The authors discuss a supervised machine learning system that classifies all content words in a running text as either metaphorical or nonmetaphorical. &lt;a href="http://aclweb.org/anthology/W/W15/W15-1402.pdf"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.aclweb.org/anthology/W15-0605"&gt;&lt;span&gt;Automated Scoring of Picture-based Story Narration&lt;/span&gt;&lt;/a&gt;&lt;br&gt; S. Somasundaran, C.-M. Lee, M. Chodorow, &amp;amp; X. Wang&lt;br&gt; Paper in &lt;span&gt;Proceedings of the Tenth Workshop on Innovative Use of NLP for Building Educational Applications&lt;/span&gt;, pp. 42–48&lt;/p&gt;
&lt;p&gt;This paper describes an investigation of linguistically motivated features for automatically scoring a spoken picture-based narration task. &lt;a href="http://www.aclweb.org/anthology/W15-0605"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.aclweb.org/anthology/W15-0608"&gt;&lt;span&gt;Scoring Persuasive Essays Using Opinions and their Targets&lt;/span&gt;&lt;/a&gt;&lt;br&gt; N. Farra, S. Somasundaran, &amp;amp; J. Burstein&lt;br&gt; Paper in &lt;span&gt;Proceedings of the Tenth Workshop on Innovative Use of NLP for Building Educational Applications, pp&lt;/span&gt;. 64–74&lt;/p&gt;
&lt;p&gt;In this work, researchers investigate whether the analysis of opinion expressions can help in scoring persuasive essays. Experiments on test taker essays show that essay scores produced using opinion features are indeed correlated with human scores. &lt;a href="http://www.aclweb.org/anthology/W15-0608"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.guilford.com/books/Handbook-of-Writing-Research/MacArthur-Graham-Fitzgerald/9781462522439/contents"&gt;&lt;span&gt;Automated Writing Evaluation: A Growing Body of Knowledge&lt;/span&gt;&lt;/a&gt;&lt;br&gt; M. Shermis, J. Burstein, N. Elliot, S. Miel, &amp;amp; P. Foltz. In C. MacArthur, S. Graham, &amp;amp; J. Fitzgerald (Eds.), &lt;span&gt;Handbook of Writing Research, 2nd Edition&lt;/span&gt; Guilford &lt;span&gt;Press&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The authors present automated writing evaluation in terms of the categories of evidence that are used to demonstrate that these systems are useful in teaching and assessing writing. &lt;a href="http://www.guilford.com/books/Handbook-of-Writing-Research/MacArthur-Graham-Fitzgerald/9781462522439/contents"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.ets.org/research/policy_research_reports/publications/report/2015/junr"&gt;&lt;span&gt;Automated Analysis of Text in Graduate School Recommendations&lt;/span&gt;&lt;/a&gt;&lt;br&gt; M. Heilman, F. J. Breyer, F. Williams, D. Klieger, &amp;amp; M. Flor&lt;br&gt; ETS Research Report No. RR-15-23&lt;/p&gt;
&lt;p&gt;This report explores evaluation of sentiment in letters of recommendation. Researchers developed and evaluated an approach to analyzing recommendations that involves (a) identifying which sentences are actually about the student; (b) measuring specificity; (c) measuring sentiment; and (d) predicting recommender ratings. &lt;a href="http://www.ets.org/research/policy_research_reports/publications/report/2015/junr"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://bells.uib.no/index.php/bells/article/view/811/751"&gt;&lt;span&gt;Patterns of Misspellings in L2 and L1 English: A View from the ETS Spelling Corpus&lt;/span&gt;&lt;/a&gt;&lt;br&gt; M. Flor, Y. Futagi, M. Lopez, &amp;amp; M. Mulholland&lt;br&gt; &lt;span&gt;Bergen Language and Linguistics Studies&lt;/span&gt;, Vol. 6&lt;/p&gt;
&lt;p&gt;This paper presents a study of misspellings, based on annotated data from ETS's spelling corpus. Researchers examined data from the &lt;span&gt;TOEFL&lt;/span&gt;&lt;sup&gt;®&lt;/sup&gt; and GRE tests and found that the rate of misspellings decreased as writing proficiency (essay score) increased for test takers in both testing programs. &lt;a href="https://bells.uib.no/index.php/bells/article/view/811/751"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;2014&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://acl2014.org/acl2014/P14-2/pdf/P14-2041.pdf"&gt;&lt;span&gt;Content Importance Models for Scoring Writing From Sources&lt;/span&gt;&lt;/a&gt;&lt;br&gt; B. Beigman Klebanov, N. Madnani, N., J. Burstein, &amp;amp; S. Somasundaran&lt;br&gt; Paper in &lt;span&gt;Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers)&lt;/span&gt;, pp. 247–252&lt;/p&gt;
&lt;p&gt;This paper describes an integrative summarization task used in an assessment of English proficiency for nonnative speakers applying to higher education institutions in the United States. Researchers evaluate a variety of content importance models that help predict which parts of the source material the test taker would need to include in a successful response. &lt;a href="http://acl2014.org/acl2014/P14-2/pdf/P14-2041.pdf"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.ets.org/research/policy_research_reports/publications/report/2014/jsei"&gt;&lt;span&gt;Using Writing Process and Product Features to Assess Writing Quality and Explore How Those Features Relate to Other Literacy Tasks&lt;/span&gt;&lt;/a&gt;&lt;br&gt; P. Deane&lt;br&gt; ETS Research Report No. RR-14-03&lt;/p&gt;
&lt;p&gt;This report explores automated methods for measuring features of student writing and determining its relationship to writing quality and other features of literacy, such as reading test scores. The &lt;span&gt;e-rater&lt;/span&gt; automated essay-scoring system and keystroke logging are a central focus. &lt;a href="http://www.ets.org/research/policy_research_reports/publications/report/2014/jsei"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.ets.org/research/policy_research_reports/publications/chapter/2014/jswe"&gt;&lt;span&gt;Predicting Grammaticality on an Ordinal Scale&lt;/span&gt;&lt;/a&gt;&lt;br&gt; M. Heilman, A. Cahill, N. Madnani, M. Lopez, M. Mulholland, &amp;amp; J. Tetreault&lt;br&gt; Paper in &lt;span&gt;Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics&lt;/span&gt;, (Short Papers), pp. 174–180&lt;/p&gt;
&lt;p&gt;This paper describes a system for predicting the grammaticality of sentences on an ordinal scale. Such a system could be used in educational applications such as essay scoring. &lt;a href="http://www.ets.org/research/policy_research_reports/publications/chapter/2014/jswe"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.ets.org/research/policy_research_reports/publications/chapter/2014/jswf"&gt;&lt;span&gt;An Explicit Feedback System for Preposition Errors based on Wikipedia Revisions&lt;/span&gt;&lt;/a&gt;&lt;br&gt; N. Madnani &amp;amp; A. Cahill&lt;br&gt; Paper in &lt;span&gt;Proceedings of the Ninth Workshop on Innovative Use of NLP for Building Educational Applications&lt;/span&gt;, pp. 79–88&lt;/p&gt;
&lt;p&gt;In this paper, the authors describe a novel tool they developed to provide automated explicit feedback to language learners based on data mined from Wikipedia revisions. They demonstrate how the tool works for the task of identifying preposition selection errors. &lt;a href="http://www.ets.org/research/policy_research_reports/publications/chapter/2014/jswf"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.ets.org/research/policy_research_reports/publications/chapter/2014/jswn"&gt;&lt;span&gt;Difficult Cases: From Data to Learning and Back&lt;/span&gt;&lt;/a&gt;&lt;br&gt; B. Beigman Klebanov &amp;amp; E. Beigman&lt;br&gt; Paper in Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, (Short Papers), pp. 390–396&lt;/p&gt;
&lt;p&gt;This paper addresses cases in annotated datasets that are difficult to annotate reliably. Using a semantic annotation task, the authors provide empirical evidence that difficult cases can thwart supervised machine learning on the one hand and provide valuable insights into the characteristics of the data representation chosen for the task on the other. &lt;a href="http://www.ets.org/research/policy_research_reports/publications/chapter/2014/jswn"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.ets.org/research/policy_research_reports/publications/chapter/2014/jswm"&gt;&lt;span&gt;Different Texts, Same Metaphors: Unigrams and Beyond&lt;/span&gt;&lt;/a&gt;&lt;br&gt; B. Beigman Klebanov, C. Leong, M. Heilman, &amp;amp; M. Flor (2014)&lt;br&gt; Paper in &lt;span&gt;Proceedings of the Second Workshop on Metaphor in NLP&lt;/span&gt;, pp. 11–17&lt;/p&gt;
&lt;p&gt;This paper describes the development of a supervised learning system to classify all content words in a running text as either being used metaphorically or not. &lt;a href="http://www.ets.org/research/policy_research_reports/publications/chapter/2014/jswm"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.aclweb.org/anthology/C14-1090"&gt;&lt;span&gt;Lexical Chaining for Measuring Discourse Coherence Quality in Test-taker Essays&lt;/span&gt;&lt;/a&gt;&lt;br&gt; S. Somasundaran, J. Burstein, &amp;amp; M. Chodorow&lt;br&gt; In The 25th International Conference on Computational Linguistics (COLING), Dublin, Ireland, August 23–29, 2014.&lt;br&gt; Paper in &lt;span&gt;Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers&lt;/span&gt;, pp. 950–961&lt;/p&gt;
&lt;p&gt;Researchers investigated a technique known as lexical chaining for measuring discourse coherence quality in test-taker essays. In this paper, they describe the contexts in which they achieved the best system performance. &lt;a href="http://www.aclweb.org/anthology/C14-1090"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.ets.org/research/policy_research_reports/publications/chapter/2014/jswo"&gt;&lt;span&gt;Applying Argumentation Schemes for Essay Scoring&lt;/span&gt;&lt;/a&gt;&lt;br&gt; Y. Song, M. Heilman, B. Beigman Klebanov, &amp;amp; P. Deane&lt;br&gt; Paper in &lt;span&gt;Proceedings of the First Workshop on Argumentation Mining&lt;/span&gt;, pp. 69–78&lt;/p&gt;
&lt;p&gt;In this paper, the authors develop an annotation approach based on the theory of argumentation schemes to analyze the structure of arguments and implement an NLP system for automatically predicting where critical questions are raised in essays. &lt;a href="http://www.ets.org/research/policy_research_reports/publications/chapter/2014/jswo"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;2013&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.taylorandfrancis.com/books/details/9780415810968/"&gt;&lt;span&gt;Handbook of Automated Essay Evaluation: Current Applications and New Directions&lt;/span&gt;&lt;/a&gt;&lt;br&gt; M. D. Shermis &amp;amp; J. Burstein&lt;/p&gt;
&lt;p&gt;This comprehensive, interdisciplinary handbook reviews the latest methods and technologies used in automated essay evaluation (AEE) methods and technologies. New York: Routledge. &lt;a href="http://search.ets.org/researcher/cs.html?url=http%3A//www.ets.org/research/policy_research_reports/publications/book/2013/jqej&amp;amp;qt=TI%3A%E2%80%A2+TI%3AHandbook+TI%3Aof+TI%3AAutomated+TI%3AEssay+TI%3AEvaluation%3A+TI%3ACurrent+TI%3AApplications+TI%3Aand+TI%253"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.aclweb.org/anthology/P13-1113.pdf"&gt;&lt;span&gt;Word Association Profiles and their Use for Automated Scoring of Essays&lt;/span&gt;&lt;/a&gt;&lt;br&gt; B. Beigman Klebanov &amp;amp; M. Flor&lt;br&gt; Paper in &lt;span&gt;Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics&lt;/span&gt; (Volume 1: Long Papers). pp. 1148–1158&lt;/p&gt;
&lt;p&gt;The authors describe a new representation of the content vocabulary in a text, which they refer to as "word association profile." The paper presents a study of the relationship between quality of writing and word association profiles. &lt;a href="http://www.aclweb.org/anthology/P13-1113.pdf"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://search.ets.org/researcher/cs.html?url=http%3A//www.ets.org/research/policy_research_reports/publications/chapter/2013/jrhc&amp;amp;qt=TI%3ARobust+TI%3ASystems+TI%3Afor+TI%3APreposition+TI%3AError+TI%3ACorrection+TI%3AUsing+TI%3AWikipedia+TI%3ARevisions&amp;amp;col="&gt;&lt;span&gt;Robust Systems for Preposition Error Correction Using Wikipedia Revisions&lt;/span&gt;&lt;/a&gt;&lt;br&gt; A. Cahill, N. Madnani, J. Tetreault, &amp;amp; D. Napolitano&lt;br&gt; In &lt;span&gt;Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies&lt;/span&gt;, pp. 507–517, Atlanta, Ga.&lt;/p&gt;
&lt;p&gt;This paper addresses the lack of generalizability in preposition error correction systems across different test sets. The authors then present a large new annotated corpus to be used in training such systems, and illustrate the use of the corpus in training systems across three separate test sets. &lt;a href="http://search.ets.org/researcher/cs.html?url=http%3A//www.ets.org/research/policy_research_reports/publications/chapter/2013/jrhc&amp;amp;qt=TI%3ARobust+TI%3ASystems+TI%3Afor+TI%3APreposition+TI%3AError+TI%3ACorrection+TI%3AUsing+TI%3AWikipedia+TI%3ARevisions&amp;amp;col="&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.ets.org/research/policy_research_reports/publications/chapter/2013/jrhm"&gt;&lt;span&gt;Detecting Missing Hyphens in Learner Text&lt;/span&gt;&lt;/a&gt;&lt;br&gt; A. Cahill, M. Chodorow, S. Wolff &amp;amp; N. Madnani&lt;br&gt; In &lt;span&gt;Proceedings of the Eighth Workshop on Innovative Use of NLP for Building Educational Applications&lt;/span&gt;, pp. 300–305, Atlanta, Ga.&lt;/p&gt;
&lt;p&gt;This paper presents a method for automatically detecting missing hyphens in English text. &lt;a href="https://www.ets.org/research/policy_research_reports/publications/chapter/2013/jrhm"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://search.ets.org/researcher/cs.html?url=http%3A//www.ets.org/research/policy_research_reports/publications/chapter/2013/jqez&amp;amp;qt=TI%3A%E2%80%A2+TI%3AThe+TI%3AE-rater%C2%AE+TI%3AAutomated+TI%3AEssay+TI%3AScoring+TI%3ASystem&amp;amp;col=rsrchr&amp;amp;n=1"&gt;&lt;span&gt;The &lt;span&gt;e-rater&lt;/span&gt;&lt;sup&gt;®&lt;/sup&gt; Automated Essay Scoring System&lt;/span&gt;&lt;/a&gt;&lt;br&gt; J. Burstein, J. Tetreault, &amp;amp; N. Madnani. In M. D. Shermis &amp;amp; J. Burstein (Eds.), &lt;span&gt;Handbook of Automated Essay Scoring: Current Applications and Future Directions.&lt;/span&gt; New York: Routledge.&lt;/p&gt;
&lt;p&gt;This handbook chapter includes a description of the &lt;span&gt;e-rater&lt;/span&gt; automated essay scoring system and its NLP-centered approach, and a discussion of the system's applications and development efforts for current and future educational settings. &lt;a href="http://search.ets.org/researcher/cs.html?url=http%3A//www.ets.org/research/policy_research_reports/publications/chapter/2013/jqez&amp;amp;qt=TI%3A%E2%80%A2+TI%3AThe+TI%3AE-rater%C2%AE+TI%3AAutomated+TI%3AEssay+TI%3AScoring+TI%3ASystem&amp;amp;col=rsrchr&amp;amp;n=1"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;2012&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.ets.org/research/policy_research_reports/publications/article/2012/jewi"&gt;&lt;span&gt;A Fast and Flexible Architecture for Very Large Word n-gram Datasets&lt;/span&gt;&lt;/a&gt;&lt;br&gt; M. Flor&lt;br&gt; &lt;span&gt;Natural Language Engineering, FirstView&lt;/span&gt; online publication, pp. 1–33&lt;/p&gt;
&lt;p&gt;This paper presents a versatile architecture that uses a novel architecture, features lossless compression, and optimizes both speed and memory use. &lt;a href="https://www.ets.org/research/policy_research_reports/publications/article/2012/jewi"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.ets.org/research/policy_research_reports/publications/chapter/2012/jfoj"&gt;&lt;span&gt;Correcting Comma Errors in Learner Essays, and Restoring Commas in Newswire Text&lt;/span&gt;&lt;/a&gt;&lt;br&gt; R. Israel, J. Tetreault, &amp;amp; M. Chodorow (2012)&lt;br&gt; &lt;span&gt;Proceedings of the 2012 Meeting of the North American Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)&lt;/span&gt;, pp. 284–294&lt;br&gt; Association for Computational Linguistics&lt;/p&gt;
&lt;p&gt;The authors present a system for detection and correction of the placement of commas in English-language sentences. The system likewise can restore commas in well-crafted sentences. &lt;a href="https://www.ets.org/research/policy_research_reports/publications/chapter/2012/jfoj"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.ets.org/research/policy_research_reports/publications/chapter/2012/jfon"&gt;&lt;span&gt;On Using Context for Automatic Correction of Non-Word Misspellings in Student Essays&lt;/span&gt;&lt;/a&gt;&lt;br&gt; M. Flor &amp;amp; Y. Futagi&lt;br&gt; &lt;span&gt;Proceedings of the 7th Workshop on Innovative Use of Natural Language Processing for Building Educational Applications (BEA)&lt;/span&gt; pp. 105–115&lt;/p&gt;
&lt;p&gt;The authors discuss a new system for spell-checking that uses contextual information to perform automatic correction of non-word misspellings. The article relates how the system has been evaluated against a large body of &lt;span&gt;TOEFL&lt;/span&gt;&lt;sup&gt;®&lt;/sup&gt; and &lt;span&gt;GRE&lt;/span&gt;&lt;sup&gt;®&lt;/sup&gt; essays, which were written by both native and nonnative English speakers. &lt;a href="https://www.ets.org/research/policy_research_reports/publications/chapter/2012/jfon"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;2010&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.ets.org/research/policy_research_reports/publications/chapter/2010/imrx"&gt;&lt;span&gt;Using Parse Features for Preposition Selection and Error Detection&lt;/span&gt;&lt;/a&gt;&lt;br&gt; J. Tetreault, J. Foster, &amp;amp; M. Chodorow&lt;br&gt; &lt;span&gt;Proceedings of the 2010 Association for Computational Linguistics (ACL 2010)&lt;/span&gt;&lt;br&gt; Association for Computational Linguistics&lt;/p&gt;
&lt;p&gt;This paper evaluates the effect of adding features that aim to improve the detection of preposition errors in writing from speakers of English as a second language. &lt;a href="https://www.ets.org/research/policy_research_reports/publications/chapter/2010/imrx"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.ets.org/research/policy_research_reports/publications/chapter/2010/iltf"&gt;&lt;span&gt;Progress and New Directions in Technology for Automated Essay Evaluation&lt;/span&gt;&lt;/a&gt;&lt;br&gt; J. Burstein &amp;amp; M. Chodorow&lt;br&gt; &lt;span&gt;The Oxford Handbook of Applied Linguistics, 2nd Edition&lt;/span&gt;, pp. 487–497&lt;br&gt; Oxford University Press&lt;/p&gt;
&lt;p&gt;This ETS-authored work is part of a 39-chapter volume that covers topics in applied linguistics with the goal of providing a survey of the field, showing the many connections among its subdisciplines, and exploring likely directions of its future development. &lt;a href="http://www.ets.org/research/policy_research_reports/publications/chapter/2010/iltf"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.ets.org/research/policy_research_reports/publications/chapter/2010/imsf"&gt;&lt;span&gt;Using Entity-Based Features to Model Coherence in Student Essays&lt;/span&gt;&lt;/a&gt;&lt;br&gt; J. Burstein, J. Tetreault, &amp;amp; S. Andreyev&lt;br&gt; &lt;span&gt;Human language technologies: The 2010 Annual Conference of the North American Chapter of the ACL&lt;/span&gt;, pp. 681–684&lt;br&gt; Association for Computational Linguistics&lt;/p&gt;
&lt;p&gt;This paper describes a study in which researchers combined an algorithm for observing what computational linguists refer to as entities — nouns and pronouns — with natural language processing features related to grammar errors and word usage with the aim of creating applications that can evaluate evidence of coherence in essays. &lt;a href="https://www.ets.org/research/policy_research_reports/publications/chapter/2010/imsf"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;2008&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.ets.org/research/policy_research_reports/publications/report/2008/hyfi"&gt;&lt;span&gt;A Developmental Writing Scale&lt;/span&gt;&lt;/a&gt;&lt;br&gt; Y. Attali &amp;amp; D. Powers&lt;br&gt; ETS Research Report No. RR-08-19&lt;/p&gt;
&lt;p&gt;This report describes the development of grade norms for timed-writing performance in two modes of writing: persuasive and descriptive. &lt;a href="https://www.ets.org/research/policy_research_reports/publications/report/2008/hyfi"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;2006&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.ets.org/research/policy_research_reports/publications/article/2006/hsjv"&gt;&lt;span&gt;Automated Essay Scoring With &lt;span&gt;e-rater&lt;/span&gt; v.2.0&lt;/span&gt;&lt;/a&gt;&lt;br&gt; Y. Attali &amp;amp; J. Burstein&lt;br&gt; &lt;span&gt;Journal of Technology, Learning, and Assessment&lt;/span&gt;, Vol. 4, No. 3&lt;/p&gt;
&lt;p&gt;This article describes Version 2 of ETS's &lt;span&gt;e-rater&lt;/span&gt; essay scoring engine. The authors present evidence on the validity and reliability of the scores that the system generates. &lt;a href="https://www.ets.org/research/policy_research_reports/publications/article/2006/hsjv"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;2003&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.ets.org/research/policy_research_reports/publications/article/2003/hyhm"&gt;&lt;span&gt;Finding the WRITE Stuff: Automatic Identification of Discourse Structure in Student Essays&lt;/span&gt;&lt;/a&gt;&lt;br&gt; J. Burstein, D. Marcu, &amp;amp; K. Knight&lt;br&gt; &lt;span&gt;IEEE Intelligent Systems: Special Issue on Advances in Natural Language Processing&lt;/span&gt;, Vol. 18, No. 1, pp. 32–39&lt;/p&gt;
&lt;p&gt;In this article, the authors discuss the use of automated essay-scoring applications in the elementary through university levels for large-scale assessment and classroom instruction. &lt;a href="https://www.ets.org/research/policy_research_reports/publications/article/2003/hyhm"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Find More Articles&lt;/h2&gt;
&lt;p&gt;View more research publications related to &lt;a href="http://search.ets.org/researcher/query.html?fl0=KW%3A&amp;amp;ty0=p&amp;amp;op0=&amp;amp;tx0=Automated%20Scoring%20of%20Writing%20Quality"&gt;automated scoring of writing quality&lt;/a&gt;.&lt;/p&gt;





					&lt;/div&gt;&lt;/div&gt;&lt;a href="https://www.ets.org/research/topics/as_nlp/writing_quality/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Thu, 25 Jun 2020 07:54:45 UT
      </pubDate>
      <guid>
        https://www.ets.org/research/topics/as_nlp/writing_quality/
      </guid>
    </item>
    <item>
      <title>
        types
      </title>
      <link>
        https://cs.lmu.edu/~ray/notes/types/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;
        &lt;h2&gt;Types&lt;/h2&gt;


&lt;p&gt;Programs manipulate values according to their type. There is more to the study of types than you might think.&lt;/p&gt;

&lt;h2&gt;Why Types?&lt;/h2&gt;

&lt;p&gt;Our very intuition makes the concept of types inescapable.&lt;/p&gt;

&lt;p&gt;We have an intuition that integers are different from strings which are different from people which are different from books which are different from planets which are, you get the idea. These differences arise from behavior: You can &lt;em&gt;open&lt;/em&gt; a socket, but not an integer; you can request the &lt;em&gt;parents&lt;/em&gt; of a person, but not a dictionary; you can &lt;em&gt;push&lt;/em&gt; an object onto a stack, but not onto character. Therefore:&lt;/p&gt;

&lt;blockquote&gt;A value’s type constrains the way it may be used in a program.&lt;/blockquote&gt;

&lt;p&gt;More philosophically:&lt;/p&gt;

&lt;blockquote&gt;Types impose constraints on what we can and cannot say.&lt;/blockquote&gt;

&lt;p&gt;More formally:&lt;/p&gt;

&lt;blockquote&gt;A type consists of a set of values and a set of allowable operations.&lt;/blockquote&gt;

&lt;h2&gt;Examples&lt;/h2&gt;

&lt;p&gt;What are some types you know about from previous programming practice? Here are some you might have seen, Keep in mind, as you go through this list, that types are characterized by their operations (more so than their “values”):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;span&gt;void&lt;/span&gt;, the empty type; the type of no values at all.&lt;/li&gt;
  &lt;li&gt;&lt;span&gt;boolean&lt;/span&gt;, the type containing the values &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;false&lt;/code&gt;, with operations such as &lt;code&gt;and&lt;/code&gt;, &lt;code&gt;or&lt;/code&gt;, &lt;code&gt;xor&lt;/code&gt;, and &lt;code&gt;not&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;span&gt;atom&lt;/span&gt;: The type of named symbols. Atoms just have name, and that’s it. You don’t really operate on them (other than testing them for equality perhaps); you just pass them around. They just exist.&lt;/li&gt;
  &lt;li&gt;&lt;dfn&gt;Numeric types&lt;/dfn&gt;, with operations such as plus, minus, multiply, divide, remainder, modulo, abs, sign, sin, cos, tan, and on and on and on. Numeric types can be integral, fixed-point, floating point, or complex; bounded or unbounded; signed or unsigned. Examples include:
  &lt;span&gt;number&lt;/span&gt;,
  &lt;span&gt;int8&lt;/span&gt;,
  &lt;span&gt;int16&lt;/span&gt;,
  &lt;span&gt;int32&lt;/span&gt;,
  &lt;span&gt;int64&lt;/span&gt;,
  &lt;span&gt;int128&lt;/span&gt;,
  &lt;span&gt;int&lt;/span&gt;,
  &lt;span&gt;uint8&lt;/span&gt;,
  &lt;span&gt;uint16&lt;/span&gt;,
  &lt;span&gt;uint32&lt;/span&gt;,
  &lt;span&gt;uint64&lt;/span&gt;,
  &lt;span&gt;uint128&lt;/span&gt;,
  &lt;span&gt;uint&lt;/span&gt;,
  &lt;span&gt;bigint&lt;/span&gt;,
  &lt;span&gt;fixed&lt;/span&gt;,
  &lt;span&gt;float32&lt;/span&gt;,
  &lt;span&gt;float64&lt;/span&gt;,
  &lt;span&gt;float128&lt;/span&gt;,
  &lt;span&gt;complex64&lt;/span&gt;,
  &lt;span&gt;complex128&lt;/span&gt;,
  &lt;span&gt;ratio&lt;/span&gt;,
  &lt;span&gt;decimal&lt;/span&gt;,
  &lt;span&gt;bigdecimal&lt;/span&gt;.
  &lt;/li&gt;
  &lt;li&gt;&lt;span&gt;char&lt;/span&gt;: The type of “characters”, i.e., units of textual information. Exactly what a character is might differ from language to language.&lt;/li&gt;
  &lt;li&gt;&lt;dfn&gt;Collection Types&lt;/dfn&gt;, with operations such as &lt;em&gt;size&lt;/em&gt;, &lt;em&gt;is_empty&lt;/em&gt;, &lt;em&gt;contains&lt;/em&gt;, &lt;em&gt;add&lt;/em&gt;, &lt;em&gt;remove&lt;/em&gt;, &lt;em&gt;retain&lt;/em&gt;, &lt;em&gt;clear&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;dfn&gt;Set Types&lt;/dfn&gt;, which are unordered collections of unique elements.&lt;/li&gt;
  &lt;li&gt;&lt;dfn&gt;Sequence Types&lt;/dfn&gt;. So many of these. Lists, stacks, queues, dequeues, priority queues, blocking queues. Even the famous &lt;dfn&gt;string&lt;/dfn&gt; is a kind of sequence, but there’s not a lot of agreement about what exactly strings are sequences of. Are they sequences of bytes? character codes? code points? unicode scalars? graphemes? String types are generally broken. You don't need them.&lt;/li&gt;
  &lt;li&gt;&lt;dfn&gt;Mapping Types&lt;/dfn&gt;, types that maps keys to values. If the keys are unique we call them &lt;dfn&gt;maps&lt;/dfn&gt; or &lt;dfn&gt;dictionaries&lt;/dfn&gt;; if keys do not have to be unique we call them &lt;dfn&gt;multimaps&lt;/dfn&gt;. Normally the keys are unordered, but &lt;dfn&gt;orderedmaps&lt;/dfn&gt; or those that are automatically iterated by in key-order (assuming keys are comparable).&lt;/li&gt;
  &lt;li&gt;&lt;dfn&gt;Singleton types&lt;/dfn&gt;, which are types that only have one value in them. The operations on that individual value vary, of course.&lt;/li&gt;
  &lt;li&gt;&lt;dfn&gt;Sum Types&lt;/dfn&gt;. The type $T_1 + T_2$ consists of all the values of $T_1$ plus all the values of $T_2$. Sums are often called &lt;dfn&gt;unions&lt;/dfn&gt;. If the alternatives are labeled (named), we get &lt;dfn&gt;tagged unions&lt;/dfn&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;dfn&gt;Product Types&lt;/dfn&gt;, The type $T_1 \times T_2$ consists of all pairs $(x, y)$ where $x$ has type $T_1$ and $y$ has type $T_2$. In general you can have products of any size: $T_1 \times T_2 \times \ldots \times T_n$. If $n=0$ you have what’s sometimes called the unit type: the type of only one value. In general, product types are called &lt;dfn&gt;tuple types&lt;/dfn&gt;. If the components are labeled (named), we get &lt;dfn&gt;records&lt;/dfn&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;dfn&gt;Routines&lt;/dfn&gt;, which can be &lt;dfn&gt;subroutines&lt;/dfn&gt; or &lt;dfn&gt;coroutines&lt;/dfn&gt;. Operations on routines include &lt;em&gt;invoke&lt;/em&gt; and &lt;em&gt;invokeLater&lt;/em&gt;. Other terms for &lt;em&gt;invoke&lt;/em&gt; include &lt;em&gt;call&lt;/em&gt; and &lt;em&gt;apply&lt;/em&gt; (from the idea of function “application” — “applying” a function to its argument(s)).&lt;/li&gt;
  &lt;li&gt;&lt;dfn&gt;Function types&lt;/dfn&gt;, computational mappings from arguments to results. We can classify functions in many ways: there are &lt;dfn&gt;predicates&lt;/dfn&gt;, which return booleans, &lt;dfn&gt;consumers&lt;/dfn&gt;, that accept arguments but do not return results, &lt;dfn&gt;suppliers&lt;/dfn&gt;, which take no arguments but return results.&lt;/li&gt;
  &lt;li&gt;&lt;dfn&gt;Processes&lt;/dfn&gt;, &lt;dfn&gt;Threads&lt;/dfn&gt;, and &lt;dfn&gt;Tasks&lt;/dfn&gt;, which are things that run asynchronously. Generally these things send messages to each other, but shared memory is sometimes used. They are generally created with a &lt;em&gt;spwan&lt;/em&gt; operation. Internally they use &lt;em&gt;send&lt;/em&gt; and &lt;em&gt;receive&lt;/em&gt; to communicate.&lt;/li&gt;
  &lt;li&gt;The type &lt;span&gt;type&lt;/span&gt;, whose members are...types!&lt;/li&gt;
  &lt;li&gt;The type &lt;span&gt;any&lt;/span&gt;, which is the type of all values.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;b&gt;Exercise&lt;/b&gt;: Spend some time thinking about the behaviors of each of the types above.
&lt;/p&gt;
&lt;h2&gt;Classifying Types&lt;/h2&gt;

&lt;p&gt;It is tempting to try to put types into a hierarchy, or at least a directed acyclic graph:&lt;/p&gt;

&lt;p&gt;&lt;img alt="typehierarchy.png" src="https://cs.lmu.edu/~ray/images/typehierarchy.png"&gt;&lt;/p&gt;
&lt;p&gt;But it’s actually difficult to this because there are so many other ways to classify type that defy hierarchy. In fact, there’s this whole idea of classifying types into something called &lt;dfn&gt;typeclasses&lt;/dfn&gt;, which are things like this:&lt;/p&gt;

&lt;p&gt;A type is &lt;dfn&gt;equatable&lt;/dfn&gt;, or is an &lt;dfn&gt;eqtype&lt;/dfn&gt;, if values of the type can be tested for equality (&lt;code&gt;==&lt;/code&gt;).&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;In some languages, all types are equatable because most of the types have reference semantics. In Haskell, however, functions, for example, are not equatable.&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;A type is &lt;dfn&gt;comparable&lt;/dfn&gt; (a.k.a. &lt;dfn&gt;ordered&lt;/dfn&gt;) if values of the type can be compared with &lt;code&gt;&amp;lt;&lt;/code&gt; (and often also with &lt;code&gt;&amp;lt;=&lt;/code&gt;, &lt;code&gt;&amp;gt;&lt;/code&gt;, and &lt;code&gt;&amp;gt;=&lt;/code&gt;, and often &lt;code&gt;&amp;lt;=&amp;gt;&lt;/code&gt;).&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;Generally (at least in the vast majority of languages), if you make your own class, it won’t be comparable be default.&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;A type is &lt;dfn&gt;bounded&lt;/dfn&gt; if there is a minimum value of the type and a maximum value of the type.&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;Fixed-size integers and simple enumerations are bounded.&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;A type is &lt;dfn&gt;showable&lt;/dfn&gt;, or is a &lt;dfn&gt;showtype&lt;/dfn&gt; if values of the type can be converted to strings.&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;Functions and binary streams are generally not showable.&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;A type is &lt;dfn&gt;callable&lt;/dfn&gt; if values of its type can be called on, or applied to, other values.&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;Functions are callable. In Python, so are types!&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;A type is &lt;dfn&gt;enumerable&lt;/dfn&gt; if it has successor and predecessor operations on its values.&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;Integers are enumerable, as are characters (enumerated via their code points). Note this definition does not apply to languages with very complex &lt;code&gt;enum&lt;/code&gt; things, like Swift. Those concepts are completely different.&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;A type is &lt;dfn&gt;monoidal&lt;/dfn&gt;, or is a &lt;dfn&gt;monoid&lt;/dfn&gt;, if it has an associative composition operator, and an identity operator for the composition.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Concrete example: Functions! They have function composition and the identity &lt;code&gt;x =&amp;gt; x&lt;/code&gt; (JS notation).&lt;/li&gt;
&lt;li&gt;Abstractly: $\exists e, \bullet:\; \forall a, b, c: a \bullet (b \bullet c) = (a \bullet b) \bullet c \wedge a \bullet e = e \bullet a$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A type is &lt;dfn&gt;monadic&lt;/dfn&gt;, or is a &lt;dfn&gt;monad&lt;/dfn&gt;, if values of the type “wrap” underlying values in some way (e.g. optional, list), and there is an operator to wrap a value, and an associative composition operator on functions that unwrap a value and do something to it to produce a new wrapped value, such that the wrapper is an identity for the composition.&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;&lt;a href="https://wiki.haskell.org/Monad_tutorials_timeline"&gt;Need a tutorial?&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;

&lt;blockquote&gt;&lt;b&gt;Typeclasses in Practice&lt;/b&gt;&lt;p&gt;Languages vary greatly in their treatment of typeclasses. Haskell has a distinguished typeclass concept (called a &lt;code&gt;class&lt;/code&gt;. Swift implements them via protocols, and other languages just use their own interface or mixin construct.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;b&gt;Exercise&lt;/b&gt;: Find the built-in Swift protocols for equatables and comparables. How do they work? Craft an example that uses them.
&lt;/p&gt;
&lt;h2&gt;A Type Algebra&lt;/h2&gt;

&lt;p&gt;We can arrange types by building them up algebraically, similar to how sets are built up, for example:&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;&lt;tr&gt;&lt;th&gt;Kind of Type&lt;/th&gt;&lt;th&gt;Notation&lt;/th&gt;&lt;th&gt;Notes&lt;/th&gt;&lt;/tr&gt;

  &lt;tr&gt;&lt;td&gt;Empty&lt;/td&gt;&lt;td&gt;$\perp$&lt;/td&gt;&lt;td&gt;Type with no members at all. A &lt;dfn&gt;bottom type&lt;/dfn&gt; (meaning it is a subtype of all types). Sometimes called &lt;code&gt;Void&lt;/code&gt;.&lt;/td&gt;&lt;/tr&gt;

  &lt;tr&gt;&lt;td&gt;Singleton&lt;/td&gt;&lt;td&gt;$x$&lt;/td&gt;&lt;td&gt;Type with only a single member. Examples:&lt;table&gt;
    &lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;null&lt;/code&gt;&lt;/td&gt;&lt;td&gt;type containing only the value &lt;code&gt;null&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt;&lt;td&gt;type containing only the value &lt;code&gt;true&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;&lt;code&gt;"hello"&lt;/code&gt;&lt;/td&gt;&lt;td&gt;ttype containing only the value &lt;code&gt;"hello"&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;&lt;code&gt;5&lt;/code&gt;&lt;/td&gt;&lt;td&gt;type containing only the value &lt;code&gt;5&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;&lt;code&gt;blue&lt;/code&gt;&lt;/td&gt;&lt;td&gt;type containing only the value &lt;code&gt;blue&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt;
  &lt;/tbody&gt;&lt;/table&gt;&lt;/td&gt;&lt;/tr&gt;

  &lt;tr&gt;&lt;td&gt;Sum&lt;/td&gt;&lt;td&gt;$T_1\;|\;T_2\;|\,...|\;T_n$&lt;br&gt;&lt;i&gt;or&lt;/i&gt;&lt;br&gt;$x_1: T_1\;|\,...|\;x_n: T_n$&lt;/td&gt;&lt;td&gt;Also written $T_1 \cup T_2$ or $T_1 + T_2$. If unlabeled, generally called a &lt;dfn&gt;Union&lt;/dfn&gt;. If labeled, generally called a &lt;dfn&gt;Tagged Union&lt;/dfn&gt;. Examples:&lt;table&gt;
    &lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;true | false&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;&lt;code&gt;red | green | blue&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;&lt;code&gt;string | null&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;&lt;code&gt;int | bool | float&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;&lt;code&gt;1 | 2 | 3 | 4 | 5 | 6&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;&lt;code&gt;circle: float | rectangle: float × float&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;&lt;code&gt;enum { circle: Float; rectangle: (Float, Float) }&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt;
  &lt;/tbody&gt;&lt;/table&gt;&lt;/td&gt;&lt;/tr&gt;

  &lt;tr&gt;&lt;td&gt;Product&lt;/td&gt;&lt;td&gt;$(T_1, T_2, ... T_n)$&lt;br&gt;&lt;i&gt;or&lt;/i&gt;&lt;br&gt;$(x_1: T_1,..., x_n: T_n)$&lt;/td&gt;&lt;td&gt;Also written $T_1 \times T_2$. If unlabled, generally called a &lt;dfn&gt;Tuple&lt;/dfn&gt;. If labeled, generally called a &lt;dfn&gt;Record&lt;/dfn&gt; or &lt;dfn&gt;Struct&lt;/dfn&gt;. Examples: &lt;table&gt;
    &lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;bool × int&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;&lt;code&gt;(Bool, Int)&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;&lt;code&gt;()&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;&lt;code&gt;x: int × y: int&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;&lt;code&gt;struct { x: int; y: int; }&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt;
  &lt;/tbody&gt;&lt;/table&gt;&lt;/td&gt;&lt;/tr&gt;

  &lt;tr&gt;&lt;td&gt;Sequence&lt;/td&gt;&lt;td&gt;$T*$&lt;/td&gt;&lt;td&gt;a.k.a. Array or List. Examples:&lt;table&gt;
    &lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;[Int]&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Swift&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;&lt;code&gt;[]float64&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Go&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;&lt;code&gt;bool list&lt;/code&gt;&lt;/td&gt;&lt;td&gt;SML&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;&lt;code&gt;List&amp;lt;String&amp;gt;&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Java&lt;/td&gt;&lt;/tr&gt;
  &lt;/tbody&gt;&lt;/table&gt;&lt;/td&gt;&lt;/tr&gt;

  &lt;tr&gt;&lt;td&gt;Function&lt;/td&gt;&lt;td&gt;$T_1 \rightarrow T_2$&lt;/td&gt;&lt;td&gt;A function from $T_1$ to $T_2$. Use $\perp$ or a product type for $T_1$ to simulate zero or multiple arguments, and $\perp$ or a product type for $T_2$ to simulate zero or multiple return values. Examples:&lt;table&gt;
    &lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;Int -&amp;gt; Int&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;&lt;code&gt;Bool* -&amp;gt; Int × String&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;&lt;code&gt;Int × Int × String -&amp;gt; Int&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;&lt;code&gt;Float → Void&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt;
  &lt;/tbody&gt;&lt;/table&gt;&lt;/td&gt;&lt;/tr&gt;

  &lt;tr&gt;&lt;td&gt;Any&lt;/td&gt;&lt;td&gt;$\top$&lt;/td&gt;&lt;td&gt;All values are a member of this type. The “type of everything.” A &lt;dfn&gt;top type&lt;/dfn&gt; (meaning all types are a subtype of it). Examples:&lt;table&gt;
    &lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;any&lt;/code&gt;&lt;/td&gt;&lt;td&gt;TypeScript&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;&lt;code&gt;interface{}&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Go&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;&lt;code&gt;BasicObject&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Ruby&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;&lt;code&gt;object&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Python&lt;/td&gt;&lt;/tr&gt;
    &lt;/tbody&gt;&lt;/table&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;p&gt;This arrangement actually works pretty well, as it covers most everything we need:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The &lt;dfn&gt;boolean type&lt;/dfn&gt; is really just &lt;code&gt;true | false&lt;/code&gt; for singleton types &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;A &lt;dfn&gt;string type&lt;/dfn&gt; is just a sequence of some underlying elements, maybe bytes, maybe character codes, maybe graphemes.&lt;/li&gt;
  &lt;li&gt;An &lt;dfn&gt;optional type&lt;/dfn&gt; is just &lt;code&gt;T | null&lt;/code&gt; for any type &lt;code&gt;T&lt;/code&gt; and singleton type &lt;code&gt;null&lt;/code&gt;. This is often abbreviated &lt;code&gt;T?&lt;/code&gt; or &lt;code&gt;Optional&amp;lt;T&amp;gt;&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Are sequence types really primitive? Seems like we can just write $T* = T \cup (T \times T) \cup (T \times T \times T) \cup \ldots$, but the abbreviation is simpler, of course. Be pragmatic.&lt;/li&gt;
  &lt;li&gt;Many statically typed languages have a generic &lt;dfn&gt;Either&lt;/dfn&gt; type, a tagged union with labels such as &lt;code&gt;left&lt;/code&gt; and &lt;code&gt;right&lt;/code&gt;, or a similarly structured tagged union called &lt;dfn&gt;Result&lt;/dfn&gt; with labels &lt;code&gt;success&lt;/code&gt; and &lt;code&gt;failure&lt;/code&gt;. The latter is commonly used for returning, rather than throwing errors.&lt;/li&gt;
  &lt;li&gt;There is a type called &lt;code&gt;Never&lt;/code&gt;, which isn’t really a type, but used in place of a return type in a function that does not return, either because it enters an infinite loop or throws an error.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;b&gt;Exercise&lt;/b&gt;: In your own words, describe the difference between a sum type and a product type.
&lt;/p&gt;
&lt;p&gt;In case you haven’t seen singleton or union types before, you might not have seen TypeScript.&lt;/p&gt;

&lt;p&gt;&lt;img alt="typescripterror.png" src="https://cs.lmu.edu/~ray/images/typescripterror.png"&gt;&lt;/p&gt;
&lt;h2&gt;Type Systems&lt;/h2&gt;

&lt;p&gt;In programming language theory, a language’s &lt;dfn&gt;type system&lt;/dfn&gt; answers questions such as:
&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;Is the set of types fixed, or can you create new ones?
&lt;/li&gt;&lt;li&gt;Are types extra-lingual, or are they themselves values? If values, are they first-class? Also if values, do they themselves belong to one of possibly many types or is there just one type? If not, can they be categorized into different, um, say, typeclasses?
&lt;/li&gt;&lt;li&gt;What exactly &lt;em&gt;are&lt;/em&gt; the types of the language, and how are new types built?
&lt;/li&gt;&lt;li&gt;How do we infer the type of an expression (gets tricky with variables)
&lt;/li&gt;&lt;li&gt;How do we know when two types are exactly the same?
&lt;/li&gt;&lt;li&gt;How do we know when two types are compatible?
&lt;/li&gt;&lt;li&gt;What do we do when expressions are used in a way inconsistent with their type?
&lt;/li&gt;&lt;/ol&gt;

&lt;h2&gt;Fixed Type Systems&lt;/h2&gt;

&lt;p&gt;Some languages predefine the set of types and do &lt;em&gt;not&lt;/em&gt; let you define new ones. These include:
&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;&lt;b&gt;JavaScript&lt;/b&gt;: The only types are these eight: Undefined, Null, Boolean, String, Number, BigInt, Symbol, Object
&lt;/li&gt;&lt;li&gt;&lt;b&gt;Lua&lt;/b&gt;: The only types are these eight: nil, boolean, number, string, function, thread, userdata, table.
&lt;/li&gt;&lt;li&gt;&lt;b&gt;Erlang&lt;/b&gt;: The only types are: atom, integer, float, binary, ref, pid, port, function, list, tuple, map.
&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;JavaScript really does have only eight types, but it kind of &lt;em&gt;feels&lt;/em&gt; like it has more. For example:

&lt;/p&gt;&lt;pre&gt;class Dog { bark() { return 'woof'; } }
class Rat { squeak() { return 'peep'; } }
const d = new Dog();
const r = new Rat();
d.constructor              // Dog
r.constructor              // Rat
typeof d                   // 'object'
typeof r                   // 'object'
&lt;img src="https://cs.lmu.edu/~ray/images/js-logo32.png"&gt;&lt;/pre&gt;

&lt;p&gt;So in JavaScript you can make lots of different kinds of objects (even arrays, functions, dates, and regular expressions are objects), but all of these objects have the same type. They have different constructors, but constructors aren’t types.

&lt;/p&gt;&lt;h2&gt;Are Types Values?&lt;/h2&gt;

&lt;p&gt;In JavaScript, the value 100 has the type “number”, but this “number type” itself is not a JavaScript value. Types in JavaScript are &lt;dfn&gt;extra-lingual&lt;/dfn&gt;. You can ask for an expression’s type, but you’ll just get back a string:

&lt;/p&gt;&lt;pre&gt;typeof 3 === 'number'
typeof 'hello' === 'string'
typeof { x: 1, y: 2 } === 'object'
typeof typeof 3 === 'string'
&lt;img src="https://cs.lmu.edu/~ray/images/js-logo32.png"&gt;&lt;/pre&gt;

&lt;p&gt;Ditto for Lua:

&lt;/p&gt;&lt;pre&gt;type(3) == 'number'
type('hello') == 'string'
type({ x=1, y=2 }) == 'table'
type(type(3)) == 'string'
&lt;img src="https://cs.lmu.edu/~ray/images/lua-logo32.png"&gt;&lt;/pre&gt;&lt;p&gt;

In Erlang, you can’t even ask for the type, but there are built-in functions to tell you whether or not an expression has a type:

&lt;/p&gt;&lt;pre&gt;is_atom(ten).
is_integer($a).
is_float(-3.55e-8).
is_function(fun (X) -&amp;gt; X*X end).
is_reference(make_ref()).
is_tuple({dog, "Nika", 5, 'G-SHEP'}).
is_list("a string").
&lt;img src="https://cs.lmu.edu/~ray/images/erlang-logo32.png"&gt;&lt;/pre&gt;

&lt;blockquote&gt;This is probably a good thing, because as we’ll see, values can have multiple types at the same time. So asking for &lt;strong&gt;the&lt;/strong&gt; type of an expression might be an indication of a type system that is less sophisticated than it could be.&lt;/blockquote&gt;

&lt;p&gt;In C, you can't even ask or check for a type, but you can see them! The types exist in the code, but they are not values that can be assigned to variables or passed as arguments or returned from functions.

&lt;/p&gt;&lt;p&gt;&lt;b&gt;Exercise&lt;/b&gt;: Try writing C code that uses &lt;code&gt;int&lt;/code&gt; as a value. What problems do you run into?
&lt;/p&gt;
&lt;p&gt;In Python, on the other hand, the value 100 has the type &lt;code&gt;int&lt;/code&gt;, and &lt;code&gt;int&lt;/code&gt; itself is a value in Python. In fact it has the type &lt;code&gt;type&lt;/code&gt;. And, you guessed it, &lt;code&gt;type&lt;/code&gt; is a value whose type is... yes, &lt;code&gt;type&lt;/code&gt;!

&lt;/p&gt;&lt;pre&gt;type(3) == int
type('hello') == str
type({ 'x':1, 'y':2 }) == dict
type(int) == type
type(type) == type
type(type(type(type(3)))) == type
&lt;img src="https://cs.lmu.edu/~ray/images/python-logo32.png"&gt;&lt;/pre&gt;

&lt;p&gt;Same with Ruby, though in Ruby you tend to see classes more than types:

&lt;/p&gt;&lt;pre&gt;3.class == Integer
'hello'.class == String
{x: 1, y: 2}.class == Hash
Integer.class == Class
Class.class == Class
&lt;img src="https://cs.lmu.edu/~ray/images/ruby-logo32.png"&gt;&lt;/pre&gt;

&lt;p&gt;Java, too, has objects representing classes:

&lt;/p&gt;&lt;pre&gt;System.out.println(new Integer(3).getClass());        // class java.lang.Integer
System.out.println(int.class);                        // int
System.out.println("hello".getClass());               // class java.lang.String
System.out.println(new int[]{1, 2, 3}.getClass());    // class [I
System.out.println(String.class);                     // class java.lang.String
System.out.println("hi".getClass().getClass());       // class java.lang.Class
&lt;/pre&gt;

&lt;p&gt;Augh, wait, WTF...we have types and now &lt;em&gt;classes&lt;/em&gt;?

&lt;/p&gt;&lt;h2&gt;Types vs. Classes&lt;/h2&gt;

&lt;p&gt;So what is this thing we call a &lt;dfn&gt;class&lt;/dfn&gt;? A little hard to define, maybe.... Some languages conflate the notion of type and class, but most people agree there is a difference.

&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;&lt;th&gt;TYPE&lt;/th&gt;&lt;th&gt;CLASS
&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Is all about behavior&lt;/td&gt;&lt;td&gt;Is about both structure and behavior
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;An object can have many types&lt;/td&gt;&lt;td&gt;An object belongs to exactly one class
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Is about interfacing and usage&lt;/td&gt;&lt;td&gt;Is about construction, and things like fields/properties and methods
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;

&lt;/p&gt;&lt;p&gt;&lt;b&gt;Example&lt;/b&gt;: A string object in Java has multiple types, including &lt;code&gt;String&lt;/code&gt;, &lt;code&gt;Comparable&lt;/code&gt;, and &lt;code&gt;Object&lt;/code&gt;. But only &lt;em&gt;one&lt;/em&gt; class: &lt;code&gt;String&lt;/code&gt;.
&lt;/p&gt;
&lt;pre&gt;String s = "hello";                          // "hello" ∈ type String
Comparable c = s;                            // "hello" ∈ type Comparable
Object o = s;                                // "hello" ∈ type Object
System.out.println(o.getClass().getName());  // THE class of "hello" is String
&lt;img src="https://cs.lmu.edu/~ray/images/java-logo32.png"&gt;&lt;/pre&gt;

&lt;p&gt;In most languages, declaring a class gives rise to a type. The exceptions to this rule are JavaScript and CoffeeScript, where the word &lt;code&gt;class&lt;/code&gt; does not make a type: instead it is a funny way of declaring a function and a prototype.

&lt;/p&gt;&lt;p&gt;Other languages are similar to Java in having a &lt;code&gt;class&lt;/code&gt; construct that makes a type, but they also have ways to make types that “mixin” behaviors, for example Ruby has &lt;code&gt;module&lt;/code&gt;s and Swift has &lt;code&gt;protocol&lt;/code&gt;s. Go has &lt;code&gt;struct&lt;/code&gt;s for the class-concept and &lt;code&gt;interface&lt;/code&gt;s for the pure behavior-only types.

&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;Oversimplying just a bit...&lt;/b&gt;&lt;p&gt;A class is an object factory; a type is a behavioral specification.&lt;/p&gt;&lt;/blockquote&gt;

&lt;h2&gt;Type Expressions&lt;/h2&gt;

&lt;p&gt;In many languages, you get a set of basic types and mechanisms for making new types. Some examples:

&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;
  &lt;th&gt;Language
  &lt;/th&gt;&lt;th&gt;Basic Types
  &lt;/th&gt;&lt;th&gt;Type formers
&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;
  &lt;td&gt;C
  &lt;/td&gt;&lt;td&gt;char, signed char, unsigned char, short, unsigned short, int, unsigned, long, unsigned long, long long, unsigned long long, float, double, long double, _Bool, float _Complex, double _Complex, long double _Complex, float _Imaginary, double _Imaginary, long double _Imaginary
  &lt;/td&gt;&lt;td&gt;enum, *, [], (), union, struct
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;
  &lt;td&gt;Java
  &lt;/td&gt;&lt;td&gt;boolean, byte, char, short, int, long, float, double
  &lt;/td&gt;&lt;td&gt;interface, class, enum, []
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;
  &lt;td&gt;Standard ML
  &lt;/td&gt;&lt;td&gt;unit, bool, int, word, real, char, string
  &lt;/td&gt;&lt;td&gt;-&amp;gt;, *, list, option, exn, ref, frag, datatype, {}
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;
  &lt;td&gt;Python
  &lt;/td&gt;&lt;td&gt;NoneType, NotImplementedType, ellipsis, int, bool, float, complex, str, bytes, tuple, list, bytearray, set, frozenset, dict, function, generator, method, classmethod, staticmethod, module, slice, range, type
  &lt;/td&gt;&lt;td&gt;class
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;
  &lt;td&gt;Go
  &lt;/td&gt;&lt;td&gt;bool, int8 (byte), int16, int32 (rune), int64, int, uint8, uint16, uint32, uint64, uintptr, float32, float64, complex64, complex128, string, error
  &lt;/td&gt;&lt;td&gt;[], map, *, func, struct, interface, chan
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;
  &lt;td&gt;Rust
  &lt;/td&gt;&lt;td&gt;bool, i8, i16, i32, i64, i128, isize, u8, u16, u32, u64, u128, usize, f32, f64, char, str, !
  &lt;/td&gt;&lt;td&gt;(T1, T2), [T ; N], [T], struct, enum, union, &lt;code&gt;-&amp;gt;&lt;/code&gt;, &amp;amp;, &amp;amp;mut, *const, *mut, trait, impl
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;
  &lt;td&gt;Swift
  &lt;/td&gt;&lt;td&gt;Bool, Int8, Int16, Int32, Int64, Int, UInt8, UInt16, UInt32 UInt64, UInt, Float, Double, Character, String,
  &lt;/td&gt;&lt;td&gt;(T1, T2), T?, [T], Set&amp;lt;T&amp;gt;, [K:V], T-&amp;gt;U, struct, class
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;
  &lt;td&gt;Haskell
  &lt;/td&gt;&lt;td&gt;Bool, Int, Integer, Float, Double, Char
  &lt;/td&gt;&lt;td&gt;[a], (a,b), a-&amp;gt;b, data
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;

&lt;/p&gt;&lt;p&gt;So it looks like one of the most common ways to introduce a new type is to use that &lt;code&gt;class&lt;/code&gt; notion we saw above. As in Python, for example:

&lt;/p&gt;&lt;pre&gt;&amp;gt;&amp;gt;&amp;gt; &lt;kbd&gt;class C: pass&lt;/kbd&gt;
...
&amp;gt;&amp;gt;&amp;gt; &lt;kbd&gt;class D: pass&lt;/kbd&gt;
...
&amp;gt;&amp;gt;&amp;gt; &lt;kbd&gt;c, d = C(), D()&lt;/kbd&gt;
&amp;gt;&amp;gt;&amp;gt; &lt;kbd&gt;type(c), type(d), type(c) == type(d)&lt;/kbd&gt;
(&amp;lt;class '__main__.C'&amp;gt;, &amp;lt;class '__main__.D'&amp;gt;, False)
&lt;img src="https://cs.lmu.edu/~ray/images/python-logo32.png"&gt;&lt;/pre&gt;

&lt;p&gt;But something cooler and more computer sciencey are the &lt;dfn&gt;type operators&lt;/dfn&gt; of the ML-family of languages, like &lt;code&gt;list&lt;/code&gt; (for lists), &lt;code&gt;*&lt;/code&gt; (for tuples), and &lt;code&gt;-&amp;gt;&lt;/code&gt; (for functions):

&lt;/p&gt;&lt;pre&gt;7                                     (*   int                       *)
(4, "dog")                            (*   int * string              *)
[5, 3, 2, 7]                          (*   int list                  *)
[ [], [3,3,3], [], [1] ]              (*   int list list             *)
[(3, 4.0),(1, 5.5)]                   (*   (int * real) list         *)
(5, [2.2, 1.0E~4])                    (*   int * real list           *)
fn x =&amp;gt; x + 8                         (*   int -&amp;gt; int                *)
fn x =&amp;gt; fn y =&amp;gt; x ^ Int.toString(y)   (*   string -&amp;gt; int -&amp;gt; string   *)
&lt;img src="https://cs.lmu.edu/~ray/images/sml-logo32.png"&gt;&lt;/pre&gt;

&lt;p&gt;Mmmm, so here’s something interesting. SML has type called &lt;code&gt;int list&lt;/code&gt;. Does Python? No, in Python, the type is just called &lt;code&gt;list&lt;/code&gt;. So &lt;code&gt;[1, "hello"]&lt;/code&gt; is legal in Python but illegal in SML. SML has &lt;dfn&gt;parameterized types&lt;/dfn&gt;.

&lt;/p&gt;&lt;h2&gt;Parameterized Types&lt;/h2&gt;

&lt;p&gt;In Standard ML, the types &lt;code&gt;int list&lt;/code&gt; and &lt;code&gt;string list&lt;/code&gt; and &lt;code&gt;((int * string) -&amp;gt; bool) list&lt;/code&gt; are all different, but they are all instances of the parameterized type &lt;code&gt;'a&amp;nbsp;list&lt;/code&gt;. Lots of languages are like this. Here are some simple examples:

&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;&lt;th&gt;Language&lt;/th&gt;&lt;th&gt;Example Parameterized Type&lt;/th&gt;&lt;th&gt;Example Instantiated Type&lt;/th&gt;&lt;th&gt;Notes
&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan="3"&gt;Standard&amp;nbsp;ML&lt;/td&gt;&lt;td&gt;&lt;code&gt;'a list&lt;/code&gt;&lt;/td&gt;&lt;td&gt;&lt;code&gt;string list&lt;/code&gt;&lt;/td&gt;&lt;td rowspan="3"&gt;Type variables are &lt;code&gt;'a&lt;/code&gt;, &lt;code&gt;'b&lt;/code&gt;, &lt;code&gt;'c&lt;/code&gt; and so on. If the instantiating type must admit equality, then we write &lt;code&gt;''a&lt;/code&gt;, &lt;code&gt;''b&lt;/code&gt;, &lt;code&gt;''c&lt;/code&gt;, and so on.
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;'a * 'b&lt;/code&gt;&lt;/td&gt;&lt;td&gt;&lt;code&gt;string * bool&lt;/code&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;nobr&gt;&lt;code&gt;'a -&amp;gt; 'b -&amp;gt; 'a&lt;/code&gt;&lt;/nobr&gt;&lt;/td&gt;&lt;td&gt;&lt;nobr&gt;&lt;code&gt;int-&amp;gt;(bool*int)-&amp;gt;int&lt;/code&gt;&lt;/nobr&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Haskell&lt;/td&gt;&lt;td&gt;&lt;code&gt;[a]&lt;/code&gt;&lt;br&gt;&lt;code&gt;a-&amp;gt;b&lt;/code&gt;&lt;/td&gt;&lt;td&gt;&lt;code&gt;List Int&lt;/code&gt;&lt;br&gt;&lt;code&gt;Int-&amp;gt;String&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Types begin with a capital letter and type variables with a lowercase letter.
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Java&lt;/td&gt;&lt;td&gt;&lt;code&gt;List&amp;lt;T&amp;gt;&lt;/code&gt;&lt;/td&gt;&lt;td&gt;&lt;code&gt;List&amp;lt;String&amp;gt;&lt;/code&gt;&lt;/td&gt;&lt;td&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Swift&lt;/td&gt;&lt;td&gt;&lt;code&gt;Set&amp;lt;T&amp;gt;&lt;/code&gt;&lt;/td&gt;&lt;td&gt;&lt;code&gt;Set&amp;lt;String&amp;gt;&lt;/code&gt;&lt;/td&gt;&lt;td&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;

&lt;/p&gt;&lt;p&gt;By the way, &lt;strong&gt;type parameters do not have to be just a simple type variable&lt;/strong&gt;.&lt;/p&gt;

&lt;h2&gt;Type Equivalence&lt;/h2&gt;

&lt;p&gt;When are two types the same?

&lt;/p&gt;&lt;pre&gt;typedef struct {
   int a;
   int b;
} Point;

typedef struct {
   int a;
   int b;
} Pair;

Point x;
Pair y;
&lt;img src="https://cs.lmu.edu/~ray/images/c-logo32.png"&gt;&lt;/pre&gt;

&lt;p&gt;Do &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; have the same type?  Should we say “yes” (because they have the same structure), or “no” (because their types have different names, and furthermore appear in different declarations)?  These two approaches to determining whether types are the same are &lt;b&gt;structural&lt;/b&gt; and &lt;b&gt;named&lt;/b&gt; equivalence:

&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;th&gt;Structural Equivalence
&lt;/th&gt;&lt;th&gt;Name Equivalence
&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;
&lt;td rowspan="2"&gt;Check equivalence by expanding structures all the way down to basic types
&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Strict&lt;/strong&gt;: Every type declaration defines a new type
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Loose&lt;/strong&gt;: Factor out aliases
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;

&lt;/p&gt;&lt;p&gt;Here is an example from Michael L. Scott:

&lt;/p&gt;&lt;pre&gt;type alink = pointer to cell;
subtype blink = alink;
p, q : pointer to cell;
r    : alink;
s    : blink;
t    : pointer to cell;
u    : alink;

-- If structural: [p q r s t u]

-- If strict name: [p q] [r u] [s] [t]

-- If loose name: [p q] [r s u] [t]
&lt;/pre&gt;

&lt;p&gt;Loose name equivalence is pretty common: we like to distinguish things like &lt;code&gt;Point&lt;/code&gt; and &lt;code&gt;Pair&lt;/code&gt; above but want the flexibility of aliasing. In Ada we can do both explicitly:

&lt;/p&gt;&lt;pre&gt;type Height is new Integer;
type Weight is new Integer;
-- Can’t add heights and weights

subtype Height is Integer;
subtype Weight is Integer;
-- Now you can freely mix them
&lt;img src="https://cs.lmu.edu/~ray/images/ada-logo32.png"&gt;&lt;/pre&gt;

&lt;p&gt;ML seems to use structural equivalence:
&lt;/p&gt;&lt;pre&gt;type pair = int * int;
type point = int * int;
val x: point = (1, 4);
val y: pair = x;
type person = {name: string, age: int};
type school = {name: string, age: int};
val p: person = {name="Alice", age=22};
val s: school = p;
&lt;img src="https://cs.lmu.edu/~ray/images/sml-logo32.png"&gt;&lt;/pre&gt;
&lt;p&gt;But that’s because &lt;code&gt;type&lt;/code&gt; does not define a new
type!  Only a datatype or abstype declaration creates a new type.
&lt;/p&gt;&lt;pre&gt;abstype person = P of string * int with
  fun new_person (s, i) = P(s, i)
  fun name (P(s, i)) = s
  fun age (P(s, i)) = i
end;
&lt;img src="https://cs.lmu.edu/~ray/images/sml-logo32.png"&gt;&lt;/pre&gt;

&lt;h2&gt;Type Compatibility&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;When can a value of type A be used in a context
that expects type B?&lt;/em&gt;

&lt;/p&gt;&lt;p&gt;Possible answers:
&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;When A and B are equivalent (the same type)
&lt;/li&gt;&lt;li&gt;When A is a subtype of B
&lt;/li&gt;&lt;li&gt;When an A can be &lt;em&gt;coerced&lt;/em&gt; to a B
&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;So.... In:

&lt;/p&gt;&lt;pre&gt;int a;
float b;
float c;
c = a + b;
&lt;/pre&gt;

&lt;p&gt;Is this
&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;An error, fixable by writing &lt;code&gt;c = int_to_float(a) + b&lt;/code&gt;?
&lt;/li&gt;&lt;li&gt;Allowable?
&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;A language that allows this is said to &lt;b&gt;coerce&lt;/b&gt; ints
to floats, and we say "int is compatible with float".

&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;Ada, Modula, ML: no coercion
&lt;/li&gt;&lt;li&gt;Fortran: lots of coercion
&lt;/li&gt;&lt;li&gt;C: lots of coercion in numeric types
&lt;/li&gt;&lt;li&gt;C++: user can define coercions, even accidentally!
&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;Important definitions:

&lt;/p&gt;&lt;dl&gt;
&lt;dt&gt;Type Conversion
&lt;/dt&gt;&lt;dd&gt;Explicit operation that takes in an object of
one type and returns an object of a different type
that has the "same value" (not necessarily the same
bit pattern).
&lt;/dd&gt;&lt;dt&gt;Type Coercion
&lt;/dt&gt;&lt;dd&gt;Implicit
&lt;/dd&gt;&lt;dt&gt;Non-converting Type Cast
&lt;/dt&gt;&lt;dd&gt;"Reinterpret" an object as an object of another
type by preserving its bit pattern, regardless of value.
&lt;/dd&gt;&lt;/dl&gt;


&lt;h2&gt;Type Inference&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;How do we determine the type of an expression?&lt;/em&gt;

&lt;/p&gt;&lt;p&gt;ML seems to do it the most general way possible. It looks
at all the types of the primitive expressions,
then at the types of arguments that the subroutines and
operators expect, and work your way out to the whole expression.

&lt;/p&gt;&lt;pre&gt;1   fun fib (n) =
2       let fun fib_helper (f1, f2, i) =
3           if i = n then f2
4           else fib_helper (f2, f1+f2, i+1)
5       in
6           fib_helper (0, 1, 0)
7       end;
&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;i is int, because it is added to 1 at line 4
&lt;/li&gt;&lt;li&gt;n is int, because it is compared to i at line 3
&lt;/li&gt;&lt;li&gt;all three args at line 6 are int consts, and that’s the only use of
    fib_helper (given scope of let), so f1 and f2 are int
&lt;/li&gt;&lt;li&gt;also 3rd arg is consistent with known int type of i (good!)
&lt;/li&gt;&lt;li&gt;and the types of the arguments to the recursive call at line 4 are
    similarly consistent
&lt;/li&gt;&lt;li&gt;since fib_helper returns f2 (known to be int) at line 3, the result of
    the call at line 6 will be int
&lt;/li&gt;&lt;li&gt;Since fib immediately returns this result as its own result,
    the return type of fib is int
&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;If there’s not enough information to resolve to a known type, ML’s inferencer
will bring in &lt;b&gt;type variables&lt;/b&gt;. Note how clever it is:

&lt;/p&gt;&lt;pre&gt;fun I x = x;                              'a -&amp;gt; 'a
fun p x y = y                             'a -&amp;gt; 'b -&amp;gt; 'b
fun first (x, y) = x;                     'a * 'b -&amp;gt; 'a
fun q x = (hd o hd) x;                    'a list list -&amp;gt; 'a
fun c x y = if x = y then "y" else "n";   ''a -&amp;gt; ''a -&amp;gt; string
&lt;/pre&gt;

&lt;p&gt;In ML, a type variable beginning with two primes can
only be instantiated with a type that admits equality.

&lt;/p&gt;&lt;p&gt;ML’s inferencing is more powerful than that of other languages,  Go, Rust, and Scala
  require that you put types on parameters.

&lt;/p&gt;&lt;pre&gt;scala&amp;gt; &lt;kbd&gt;var x = 3;&lt;/kbd&gt;
x: Int = 3
scala&amp;gt; &lt;kbd&gt;var y = x + 3;&lt;/kbd&gt;
y: Int = 6
scala&amp;gt; &lt;kbd&gt;def f(x) = x + 3;&lt;/kbd&gt;
&lt;span&gt;&amp;lt;console&amp;gt;:1: error: ':' expected but ')' found.
       def f(x) = x + 3;
              ^&lt;/span&gt;
scala&amp;gt; &lt;kbd&gt;def f(x:Int) = x + 3;&lt;/kbd&gt;
f: (x: Int)Int
&lt;/pre&gt;

&lt;p&gt;&lt;a href="http://play.golang.org/p/IVfzp9-OWZ"&gt;Go example&lt;/a&gt;.

&lt;/p&gt;&lt;p&gt;&lt;a href="http://is.gd/MkoeCA"&gt;Rust example&lt;/a&gt;.

&lt;/p&gt;&lt;p&gt;&lt;b&gt;Exercise&lt;/b&gt;: Two things complicate type inference are overloading and coercion. Give concrete examples of complications that arise for each.
&lt;/p&gt;

&lt;h2&gt;Type Checking&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;What if you use an expression in a manner inconsistent
with its type, like trying to compute the age of a string (instead
of a person). Should the evaluation result in an error, or return
a "best guess"?&lt;/em&gt;

&lt;/p&gt;&lt;h3&gt;Strong Typing vs. Weak Typing&lt;/h3&gt;

&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;&lt;th&gt;Strong Typing&lt;/th&gt;&lt;th&gt;Weak Typing
&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;
&lt;td&gt;Type clashes among unrelated types result
in errors. they may be compile time, or even run time (e.g.
NoSuchMethodError, or ClassCastException) but they are errors.
&lt;/td&gt;&lt;td&gt;Type clashes don’t really exist... the language implementation
will try to cast the argument into some reasonable (!) type and carry
out the operation.

&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;
&lt;td&gt;Alternate definition: you can’t really circumvent the type system. Example: In Java, even if you explicitly add a cast to cast a string to an int, you get an error.
&lt;/td&gt;&lt;td&gt;Alternate definition: you can easily circumvent the type system. Example: In C++, you can cast a pointer to an int to a void*, then to a string*, and you get away with it.
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;

&lt;p&gt;Some people would argue strong vs. weak typing isn’t a terribly useful thing to worry about. the static/dynamic dimension is a bigger deal.


&lt;/p&gt;&lt;h3&gt;Static Typing vs. Dynamic Typing&lt;/h3&gt;

&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;&lt;th&gt;Static Typing&lt;/th&gt;&lt;th&gt;Dynamic Typing
&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;
&lt;td&gt;Type checking done at compile time
&lt;p&gt;Once a variable’s type is known, it can only be assigned expressions of that type (including related types that can be coerced to it, of course).
&lt;/p&gt;&lt;/td&gt;&lt;td&gt;Type checking done at run time
&lt;p&gt;Because checking is deferred until run-time a variable
can be assigned an expression of one type and then later
an expression of another type.
&lt;/p&gt;&lt;pre&gt;var x;
x = 2;
print x + 5;
x = "dog";
print concat(x, "house");
&lt;/pre&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;

&lt;p&gt;It is common for languages to have some static typing
and some dynamic typing.

&lt;/p&gt;&lt;h3&gt;Manifest Typing vs. Implicit Typing&lt;/h3&gt;

&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;&lt;th&gt;Manifest Typing&lt;/th&gt;&lt;th&gt;Implicit Typing
&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;
&lt;td&gt;Types of variables must be given in their
declarations.
&lt;pre&gt;void f(int x, list&amp;lt;int&amp;gt; z) {
  int y = x * x;
  z.push_back(y);
}
&lt;/pre&gt;

&lt;/td&gt;&lt;td&gt;the types of variables will be inferred from context
&lt;pre&gt;fun f x z =
  let y = x * x in z @ [y] end
&lt;/pre&gt;
x must be an int because of the "*" operator, so y must
be an int as well, and then z must be an int list,
and finally f must be int -&amp;gt; int list -&amp;gt; int list.
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;

&lt;h3&gt;What about some popular languages?&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Common Lisp: strong, dynamic, implicit
  &lt;/li&gt;&lt;li&gt;Ada: strong, static, manifest
  &lt;/li&gt;&lt;li&gt;Pascal: strong, almost static, manifest
  &lt;/li&gt;&lt;li&gt;Java: strong, some static and some dynamic, manifest
  &lt;/li&gt;&lt;li&gt;ML: strong, static, implicit
  &lt;/li&gt;&lt;li&gt;JavaScript and Perl: weak, dynamic
  &lt;/li&gt;&lt;li&gt;Ruby and Python: strong, dynamic
&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;&lt;b&gt;Exercise&lt;/b&gt;: Classify Classic Lisp, Smalltalk, Go, and Rust
&lt;/p&gt;
&lt;h3&gt;Declarations and Static Typing&lt;/h3&gt;

&lt;p&gt;In order to do static typing, you must sometimes specify types when declaring
  variables, functions, parameters, etc. How is this done?

&lt;/p&gt;&lt;ul&gt;
  &lt;li&gt;&lt;a href="http://blog.golang.org/gos-declaration-syntax"&gt;A comparison of C and Go&lt;/a&gt;
&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;&lt;b&gt;Exercise&lt;/b&gt;: Rewrite the examples in the C and Go comparision article in Rust.
&lt;/p&gt;
&lt;h3&gt;Type Checking with Type Variables&lt;/h3&gt;

&lt;p&gt;Suppose f has type &lt;code&gt;'a * int -&amp;gt; 'b * 'b  -&amp;gt; string&lt;/code&gt;.
then the following expressions are legal
&lt;/p&gt;&lt;pre&gt;    f(4, 5)("sd","de")
    f(1,1)(2,2)
    f([],5)([],[4,4])
&lt;/pre&gt;
&lt;p&gt;but these are not
&lt;/p&gt;&lt;pre&gt;    f(3,2)(4,"p")
    f((3,2),5)([5.5,2.2],[1,6])
&lt;/pre&gt;

&lt;h3&gt;Further Reading&lt;/h3&gt;

&lt;p&gt;the literature on strong/weak, static/dynamic, and manifest/implicit
typing is enormous, as are the debates and flame wars. Some good
reading:

&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="http://perl.plover.com/yak/typing/"&gt;Mark Jason Dominus on Strong Typing in Perl (awesome presentation)&lt;/a&gt;
&lt;/li&gt;&lt;li&gt;Wikipedia articles on &lt;a href="http://en.wikipedia.org/wiki/Datatype"&gt;data types&lt;/a&gt; and &lt;a href="http://en.wikipedia.org/wiki/Type_system"&gt;type systems&lt;/a&gt;
&lt;/li&gt;&lt;/ul&gt;

&lt;h2&gt;Dependent Types&lt;/h2&gt;&lt;p&gt;

A &lt;dfn&gt;dependent type&lt;/dfn&gt; is a type whose definition depends on a value. Examples:
&lt;/p&gt;&lt;ul&gt;
  &lt;li&gt;Arrays of length n&lt;/li&gt;
  &lt;li&gt;Integers less than 8&lt;/li&gt;
  &lt;li&gt;Pairs of integers that sum to 21&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Does C++ have dependent types? I mean, you can do:&lt;/p&gt;
&lt;pre&gt;template &amp;lt;int n&amp;gt;
class BoundedList {
public:
  int contents[n];
}
&lt;img src="https://cs.lmu.edu/~ray/images/cpp-logo32.png"&gt;&lt;/pre&gt;

&lt;p&gt;but all types that instantiate this template are created at compile time.&lt;/p&gt;

&lt;p&gt;Languages that fully support dynamic dependent types can eliminate many logic errors at compile time! (The type system essentially lets you formulate compile-time proofs that a program will have a certain run time behavior, in terms of the values it will produce.)&lt;/p&gt;

&lt;p&gt;Start your study of dependent types at &lt;a href="https://stackoverflow.com/q/9338709/831878"&gt;this Stack Overflow question&lt;/a&gt; then go to &lt;a href="https://en.wikipedia.org/wiki/Dependent_type"&gt;Wikipedia&lt;/a&gt;.&lt;/p&gt;

&lt;h2&gt;Overview of Common Types&lt;/h2&gt;

&lt;h3&gt;Numeric Types&lt;/h3&gt;
&lt;p&gt;Lots of variety here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Integer or Floating point or fixed point or ratios
&lt;/li&gt;&lt;li&gt;Integer: Signed or unsigned
&lt;/li&gt;&lt;li&gt;Integer: Saturated or unsaturated
&lt;/li&gt;&lt;li&gt;Integer: Fixed size (8, 16, 32, 64, 128) or unbounded ("BigInt")
&lt;/li&gt;&lt;li&gt;Ratios are also called Rationals&lt;/li&gt;
&lt;li&gt;Some languages have a particular kind of ratio type called &lt;code&gt;Decimal&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Floats: by size (32, 64, 80, 128)
&lt;/li&gt;&lt;/ul&gt;

&lt;h3&gt;Enumerations&lt;/h3&gt;
&lt;p&gt;In type theory, an enumeration is a type with a fixed number of distinct values, ordered from smallest to largest. Typical examples are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;type TrafficLight is (RED, AMBER, GREEN)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;type Direction is (NORTH, EAST, SOUTH, WEST)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The Boolean type is an enum of the values False and True.&lt;/p&gt;
&lt;p&gt;Many languages have a character type which is essentially an enumeration. Each character’s "value" is its code point.&lt;/p&gt;

&lt;h3&gt;Ranges&lt;/h3&gt;
&lt;p&gt;Some languages allow you to make types such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;range(1, 100)
&lt;/li&gt;&lt;li&gt;range(3, 900, 5)&lt;/li&gt;
&lt;li&gt;1..100
&lt;/li&gt;&lt;li&gt;1...100&lt;/li&gt;
&lt;li&gt;1..&amp;lt;100
&lt;/li&gt;&lt;/ul&gt;

&lt;h3&gt;Sum Types and Product Types&lt;/h3&gt;

&lt;p&gt;Suppose we have two types, Boolean and Byte, where:
&lt;/p&gt;&lt;ul&gt;
  &lt;li&gt;Boolean has the values {false, true}&lt;/li&gt;
  &lt;li&gt;Byte has the values {-128, -127, ... 126, 127}&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now we form new types:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Boolean + Byte = {false, true, -128, -127, -126, ..., 126, 127}&lt;/li&gt;
  &lt;li&gt;Boolean × Byte = {(false, -128), (false, -127), ... (false, 127), (true, -128), (true, -127), ..., true(true, 127}&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Note Boolean has 2 values, Byte has 256 values. Boolean + Byte has 2+256 = 258 values, and Boolean × Byte has 2 * 256 = 512 values. Boolean + Byte is a &lt;dfn&gt;sum type&lt;/dfn&gt; and Boolean × Byte is a &lt;dfn&gt;product type&lt;/dfn&gt;.&lt;/p&gt;

&lt;p&gt;Product types are very common; Python calls them &lt;dfn&gt;tuples&lt;/dfn&gt;. Haskell and ML just let you write the product type name directly, e.g. &lt;code&gt;Int * String&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Often sums and products can be &lt;dfn&gt;tagged&lt;/dfn&gt;.&lt;/p&gt;

&lt;h3&gt;Option Types&lt;/h3&gt;

&lt;p&gt;Option types are one solution to the billion dollar mistake. Basically an object of type &lt;code&gt;T?&lt;/code&gt; is pretty much the sum type of &lt;code&gt;T&lt;/code&gt; and the type containing a single value representing null.&lt;/p&gt;

&lt;h3&gt;Records, a.k.a. Structs&lt;/h3&gt;

&lt;p&gt;Tagged product types go by many names: record, struct, object, hash, etc. Values of such types are thought of as key-value pairs.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Named fields, order may or may not matter
&lt;/li&gt;&lt;li&gt;Memory layout often contiguous, but may have holes for alignment reasons, with some languages giving you explicit control over this (Ada has pragmas for it)
&lt;/li&gt;&lt;li&gt;Compilers may rearrange fields
&lt;/li&gt;&lt;li&gt;Usually you can copy but not compare
&lt;/li&gt;&lt;li&gt;Copy can be bitwise, shallow, or deep
&lt;/li&gt;&lt;/ul&gt;

&lt;h3&gt;Unions&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Cheap way to make a type whose instances can have different forms
&lt;/li&gt;&lt;li&gt;Also known as variant records
&lt;/li&gt;&lt;li&gt;Generally implemented with overlaying (Fortran uses &lt;code&gt;EQUIVALENCE&lt;/code&gt;)
&lt;/li&gt;&lt;li&gt;Not needed in languages with subclassing (or with a flexible datatype declaration like ML’s)
&lt;/li&gt;&lt;li&gt;Language design choice: is the variant part "tagged"?
&lt;/li&gt;&lt;li&gt;If not (C is a good example of this), the whole idea of strong typing goes out the window
&lt;/li&gt;&lt;li&gt;If it is tagged, several design choices...
  &lt;ul&gt;
    &lt;li&gt;the tag could be permanent once set
    &lt;/li&gt;&lt;li&gt;Changing the tag could invalidate the object
    &lt;/li&gt;&lt;li&gt;We could prohibit changing just the tag and require a
    full reassignment (Ada, Algol68)
  &lt;/li&gt;&lt;/ul&gt;
&lt;/li&gt;&lt;/ul&gt;
&lt;pre&gt;  datatype primary_color = Red | Blue | Green

  Red                                   primary_color
  (Red, 4)                              primary_color * int
&lt;/pre&gt;


&lt;h3&gt;Arrays&lt;/h3&gt;

&lt;p&gt;Usually by &lt;em&gt;array&lt;/em&gt; we mean a collection of elements indexed
by integers or some other enumerated type, that has constant time
access of any element given its index. Contrast this with a &lt;em&gt;list&lt;/em&gt;,
which needn’t have constant time access, and with a &lt;em&gt;map&lt;/em&gt; (a.k.a
dictionary or associative array), which can be indexed by anything, not
just integers or related enumerated types.

&lt;/p&gt;&lt;h4&gt;Array Bounds&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Normally, array "types" are unbounded, but array instances have
bounds.
&lt;/li&gt;&lt;li&gt;Is accessing an array outside of its bounds an error?  Or does
the array object expand to accommodate?
&lt;/li&gt;&lt;li&gt;C doesn’t really have arrays!  C "arrays" are just pointers
and don’t know about bounds or not. Use at your own risk, and
be careful!
&lt;/li&gt;&lt;li&gt;If the bounds are not known at compile time, we generally
make use of a dope vector. (Note that with dope vectors, like
any other indirect storage mechanism, watch out for shallow
vs. deep copy and equality testing.)
&lt;/li&gt;&lt;li&gt;If the bounds are known at compile time, compilers can
generate code for element access that uses simple algebraic
transforms to compute as much up-front (at compile time) as possible
&lt;/li&gt;&lt;/ul&gt;

&lt;h4&gt;Lifetime and Shape&lt;/h4&gt;

&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;
  &lt;th&gt;&amp;nbsp;&lt;/th&gt;
  &lt;th&gt;Static Bounds&lt;/th&gt;
  &lt;th&gt;Bounds Set at Elaboration&lt;/th&gt;
  &lt;th&gt;Bounds Can be Changed&lt;br&gt;(Dynamic Shape)&lt;/th&gt;
&lt;/tr&gt;&lt;tr&gt;
  &lt;th&gt;Global&lt;br&gt;Lifetime&lt;/th&gt;
  &lt;td&gt;C globals
  &lt;/td&gt;&lt;td&gt;
  &lt;/td&gt;&lt;td&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;
  &lt;th&gt;Local&lt;br&gt;Lifetime&lt;/th&gt;
  &lt;td&gt;C locals
  &lt;/td&gt;&lt;td&gt;Ada locals
  &lt;/td&gt;&lt;td&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;
  &lt;th&gt;Arbitrary&lt;br&gt;Lifetime&lt;/th&gt;
  &lt;td&gt;
  &lt;/td&gt;&lt;td&gt;Java
  &lt;/td&gt;&lt;td&gt;Perl, APL
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;

&lt;ul&gt;
&lt;li&gt;Local lifetime / Bounds set at elaboration category is
interesting: one can use the &lt;code&gt;alloca&lt;/code&gt; syscall to implement
these, giving you automatic dealloaction on block exit.
&lt;/li&gt;&lt;/ul&gt;

&lt;h4&gt;Implementation&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Column Major
&lt;/li&gt;&lt;li&gt;Row Major (allows 2-D arrays to be the same as arrays of arrays)
&lt;/li&gt;&lt;li&gt;Row Pointers — necessary for ragged arrays, good on machines
  with small segments.
&lt;/li&gt;&lt;/ul&gt;

&lt;h4&gt;Slices&lt;/h4&gt;

&lt;p&gt;Several languages (Perl, APL, Fortran 90) have nice syntax for slices. Fortran 90 allows (these examples are from Scott):
&lt;/p&gt;&lt;pre&gt;matrix(3:6, 4:7)        columns 3-6, rows 4-7
matrix(6:, 5)           columns 6-end, row 5
matrix(:4, 2:8:2)       columns 1-4, every other row from 2-8
matrix(:, /2, 5, 9/)    all columns, rows 2, 5, and 9
&lt;/pre&gt;

&lt;p&gt;&lt;b&gt;Exercise&lt;/b&gt;: Give the equivalent expressions in Julia.
&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Exercise&lt;/b&gt;: How are these represented in Python’s numpy library?
&lt;/p&gt;
&lt;p&gt;Good to know: Go uses the term “slice“ to mean something else.&lt;/p&gt;

&lt;h3&gt;Strings&lt;/h3&gt;

&lt;p&gt;Most (all?) languages have them, but care is needed:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Are often built-in&lt;/li&gt;
&lt;li&gt;Usually have easy to use literal forms, with escape characters&lt;/li&gt;
&lt;li&gt;May be immutable&lt;/li&gt;
&lt;li&gt;May be interchangeable with character arrays&lt;/li&gt;
&lt;li&gt;If mutable, are usually resizable (except in old Pascal&lt;/li&gt;
&lt;li&gt;May or may not allow newlines or control characters&lt;/li&gt;
&lt;li&gt;Interpolation may or may not be supported&lt;/li&gt;
&lt;li&gt;Length is ill-defined! (Number of bytes? number of characters? number of code points? number of graphemes?&lt;/li&gt;
&lt;li&gt;Indexing may also be difficult&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;Sets&lt;/h3&gt;

&lt;p&gt;Mathematically, a &lt;dfn&gt;set&lt;/dfn&gt; is an unordered collection of unique elements.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Usually aren’t built-in but most libraries have them&lt;/li&gt;
&lt;li&gt;May be mutable or immutable (Python has &lt;code&gt;set&lt;/code&gt; and &lt;code&gt;frozenset&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Implemented with search trees, tries, hashtables or bitsets&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;Pointers&lt;/h3&gt;

&lt;p&gt;A pointer is, more or less, an object through which you reference some other object. They appear in system languages and low level languages.

&lt;/p&gt;&lt;pre&gt;int x = 5;
int* p = &amp;amp;x;
int* q = NULL;
int* r = new int;
int* s = new int[100];

cout &amp;lt;&amp;lt; *p &amp;lt;&amp;lt; *r &amp;lt;&amp;lt; s[20];
cout &amp;lt;&amp;lt; *q; // crash
&lt;/pre&gt;

&lt;h4&gt;Basics&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Pointers are used for dynamic, linked data structures.
&lt;/li&gt;&lt;li&gt;Pointers are at a higher level of abstraction than addresses
since address computation and error checks can be done on the fly,
and in some languages you can overload the dereference operators.
&lt;/li&gt;&lt;li&gt;In some languages, pointers can refer &lt;em&gt;only&lt;/em&gt; to heap-allocated
objects.
&lt;/li&gt;&lt;li&gt;In many languages (Java, LISP, ML) pointers are implicit. Example from Lisp:
&lt;pre&gt;(R (X () ()) (Y (Z ()()) (W ()())))
&lt;/pre&gt;
And from ML:
&lt;pre&gt;datatype tree = empty | node of 'a * 'a tree * 'a tree;
val x_zw = node ('R',
                 node ('X', empty, empty),
                 node ('Y',
                           node ('Z', empty, empty),
                           node ('W', empty, empty)));
&lt;/pre&gt;
&lt;/li&gt;&lt;/ul&gt;

&lt;h4&gt;Reference and Dereference Syntax&lt;/h4&gt;

&lt;p&gt;Can be always explicit, always implicit, or sometimes-implicit
(like in Ada).

&lt;/p&gt;&lt;p&gt;&lt;img alt="pointer.png" src="https://cs.lmu.edu/~ray/images/pointer.png"&gt;&lt;/p&gt;
&lt;p&gt;If the pointer is called p (or $p in Perl), then
&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;&lt;th&gt;In&lt;/th&gt;&lt;th&gt;the referent is called&lt;/th&gt;&lt;th&gt;and the field is called&lt;/th&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;C&lt;/td&gt;&lt;td&gt;&lt;code&gt;*p&lt;/code&gt;&lt;/td&gt;&lt;td&gt;&lt;code&gt;(*p).x&lt;/code&gt; or &lt;code&gt;p-&amp;gt;x&lt;/code&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Ada&lt;/td&gt;&lt;td&gt;&lt;code&gt;p.all&lt;/code&gt;&lt;/td&gt;&lt;td&gt;&lt;code&gt;p.all.x&lt;/code&gt; or &lt;code&gt;p.x&lt;/code&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Modula-2&lt;/td&gt;&lt;td&gt;&lt;code&gt;p^&lt;/code&gt;&lt;/td&gt;&lt;td&gt;&lt;code&gt;p^.x&lt;/code&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Java&lt;/td&gt;&lt;td&gt;&lt;code&gt;p&lt;/code&gt;&lt;/td&gt;&lt;td&gt;&lt;code&gt;p.x&lt;/code&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Perl&lt;/td&gt;&lt;td&gt;&lt;code&gt;%$p&lt;/code&gt;&lt;/td&gt;&lt;td&gt;&lt;code&gt;$$p{x} or $p-&amp;gt;{x}&lt;/code&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;

&lt;/p&gt;&lt;p&gt;If the referent is called p (or %p in Perl), then
&lt;table&gt;
&lt;tbody&gt;&lt;tr&gt;&lt;th&gt;In&lt;/th&gt;&lt;th&gt;the pointer is called&lt;/th&gt;&lt;th&gt;and the field is called&lt;/th&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;C&lt;/td&gt;&lt;td&gt;&lt;code&gt;&amp;amp;p&lt;/code&gt;&lt;/td&gt;&lt;td&gt;&lt;code&gt;p.x&lt;/code&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Ada&lt;/td&gt;&lt;td&gt;&lt;code&gt;p'access&lt;/code&gt;&lt;/td&gt;&lt;td&gt;&lt;code&gt;p.x&lt;/code&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Perl&lt;/td&gt;&lt;td&gt;&lt;code&gt;\%p&lt;/code&gt;&lt;/td&gt;&lt;td&gt;&lt;code&gt;$p{x}&lt;/code&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;

&lt;/p&gt;&lt;h4&gt;Memory Leaks and Dangling Pointers&lt;/h4&gt;

&lt;p&gt;In languages like C requiring explicit allocation and explicit deallocation, it is possible to:
&lt;/p&gt;&lt;ul&gt;
    &lt;li&gt;detach references to heap-allocated objects (&lt;b&gt;memory leak&lt;/b&gt;)
    &lt;/li&gt;&lt;li&gt;deallocate an objected through a shared pointer (&lt;b&gt;dangling pointer&lt;/b&gt;)
&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;How can we prevent such things?
&lt;/p&gt;&lt;ul&gt;
    &lt;li&gt;Prohibit explicit deallocation and use a garbage collector (yeah but this is a cop out sometimes)
    &lt;/li&gt;&lt;li&gt;Give programmers some nice tools and conventions, like C++ (this does NOT solve the problem)
    &lt;/li&gt;&lt;li&gt;Put in run-time checks to ensure pointers cannot outlive referenced objects (expensive?)
    &lt;/li&gt;&lt;li&gt;Put in compile-time checks to ensure pointers cannot outlive referenced objects (a la Rust)
&lt;/li&gt;&lt;/ul&gt;

&lt;h4&gt;Garbage Collection&lt;/h4&gt;

&lt;p&gt;Covered separately. For now, you can read
&lt;a href="http://en.wikipedia.org/wiki/Garbage_collection_%28computer_science%29"&gt;Wikipedia’s
article on garbage collection&lt;/a&gt;, and an interesting developerworks article
on &lt;a href="http://www-128.ibm.com/developerworks/java/library/j-jtp09275.html"&gt;Java
performance and garbage collection&lt;/a&gt;.

&lt;/p&gt;&lt;h4&gt;Pointers and Arrays in C&lt;/h4&gt;

&lt;p&gt;Sometimes, these ideas get conflated in C. After all:

&lt;/p&gt;&lt;blockquote&gt;
&lt;code&gt;e1[e2]&lt;/code&gt; is the same as *(e1 + e2)
&lt;/blockquote&gt;

&lt;p&gt;For &lt;em&gt;definitions&lt;/em&gt; these are completely different things:

&lt;/p&gt;&lt;pre&gt;  int *x;           /* is totally different from: */
  int x[100];

  int *a[n];        /* is totally different from: */
  int a[n][100];
&lt;/pre&gt;

&lt;p&gt;But for declarations, at least in parameter declarations, you
can blur the distinction:

&lt;/p&gt;&lt;pre&gt;  void f(int* a) { ... }
  void g(int b[]) { ... }
&lt;/pre&gt;

&lt;p&gt;An array of ints, or pointer to an int, can be passed to either.

&lt;/p&gt;&lt;h3&gt;Streams&lt;/h3&gt;

&lt;p&gt;The term &lt;dfn&gt;stream&lt;/dfn&gt; is a bit overloaded. Abstractly, a stream:
&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;is an object that can be read from and written to, usually sequentially, but sometimes with "random access"
&lt;/li&gt;&lt;li&gt;is called, if read-only, called a "source"; if write-only, a "sink"
&lt;/li&gt;&lt;li&gt;is an excellent abstraction; in practice streams are attached to memory buffers, network connections, database connections, files, pipes, whatever....
&lt;/li&gt;&lt;li&gt;can be made by pasting two streams together.
&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;Sometimes we use the term stream to refer to files.&lt;/p&gt;

&lt;p&gt;In Java, streams are their own thing. They work like the streams described above (they are processed sequentially), but are in a pretty large subsystem of their own.&lt;/p&gt;

&lt;h3&gt;Regular Expressions&lt;/h3&gt;

&lt;p&gt;Covered separately.

&lt;/p&gt;&lt;h3&gt;Subroutines&lt;/h3&gt;

&lt;p&gt;Subroutines are often objects with their own types.
We’ll see these later when we discuss subroutines.

&lt;/p&gt;&lt;h3&gt;Processes and threads&lt;/h3&gt;

&lt;p&gt;Will be covered later when we discuss concurrency.



&lt;/p&gt;&lt;h2&gt;Orthogonality&lt;/h2&gt;

&lt;p&gt;If a type system is &lt;dfn&gt;orthogonal&lt;/dfn&gt;, then no type is more special and capable than others. The questions you want to ask to see whether a system is orthogonal or not are: Can an object of &lt;em&gt;any&lt;/em&gt; type:
&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;be represented as a literal?
&lt;/li&gt;&lt;li&gt;be declared at all?
&lt;/li&gt;&lt;li&gt;have an initializer?
&lt;/li&gt;&lt;li&gt;be assigned to?
&lt;/li&gt;&lt;li&gt;be passed as a parameter?
&lt;/li&gt;&lt;li&gt;be returned from a function?
&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;You might be surprised at how un-orthogonal some language’s type systems are.&lt;/p&gt;

&lt;p&gt;A related question is: Are types themselves objects?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;they aren’t in JavaScript, C, C++, Erlang, or Elixir.&lt;/li&gt;
&lt;li&gt;Python has a type called &lt;code&gt;type&lt;/code&gt;, so yes there.&lt;/li&gt;
&lt;li&gt;Java, Ruby, and many other languages have a class called &lt;code&gt;Class&lt;/code&gt;, so yes there too.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It’s sometimes undesirable, or maybe even impossible, to get true orthogonality, since:
&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;Expression oriented languages need an empty type and other languages want to ignore them.
&lt;/li&gt;&lt;li&gt;First class subroutines might be difficult to implement or too slow in languages that claim to be fast.
&lt;/li&gt;&lt;li&gt;Some languages allow arrays of anything; others can store only scalars?
&lt;/li&gt;&lt;li&gt;Array indexing really can only be done by discrete types.
&lt;/li&gt;&lt;li&gt;Member, Local, and Anonymous classes in Java don’t act like top-level ones.
&lt;/li&gt;&lt;li&gt;Should blocks of code be values?
&lt;/li&gt;&lt;li&gt;Simple languages just take short cuts: did you know, in Pascal, you can’t return complex objects from functions?&lt;/li&gt;
&lt;/ul&gt;




      &lt;/div&gt;&lt;/div&gt;&lt;a href="https://cs.lmu.edu/~ray/notes/types/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Fri, 17 Jul 2020 22:20:24 UT
      </pubDate>
      <guid>
        https://cs.lmu.edu/~ray/notes/types/
      </guid>
    </item>
    <item>
      <title>
        Tutorial #2: few-shot learning and meta-learning I&lt;/title&gt;

  &lt;meta http-equiv="X-UA-Compatible" content="IE=Edge"/&gt;
  &lt;meta name="viewport" content="width=device-width,initial-scale=1"&gt;
  &lt;meta name="description" content=""&gt;

  
  
    
    
        
      &lt;link hreflang="en" href="/en/blog/tutorial-2-few-shot-learning-and-meta-learning-i/"&gt;
      
    
  

  
  &lt;link rel="canonical" href="/en/blog/tutorial-2-few-shot-learning-and-meta-learning-i/" &gt;

  &lt;link rel="alternate" type="application/rss+xml" title="BorealisAI" href="http://www.borealisai.com/en/rss.xml" /&gt;

  &lt;link rel="shortcut icon" href="/static/images/favicon.ico"&gt;
  &lt;link href="https://fonts.googleapis.com/css?family=Merriweather:300,700|Source+Code+Pro|Source+Sans+Pro:300,400,600"
        rel="stylesheet"&gt;
  &lt;link href="https://fonts.googleapis.com/css2?family=Source+Sans+Pro:wght@200&amp;display=swap" rel="stylesheet"&gt;

  &lt;link rel="stylesheet" href="/static/css/flickity.min.css"&gt;
  &lt;link rel="stylesheet" href="/static/css/global.css"&gt;
  &lt;link rel="stylesheet" href="/static/css/layout.css"&gt;
  &lt;link rel="stylesheet" href="/static/css/buttons.css"&gt;
  &lt;link rel="stylesheet" href="/static/css/card.css"&gt;
  &lt;link rel="stylesheet" href="/static/css/header.css"&gt;
  &lt;link rel="stylesheet" href="/static/css/mobile-menu.css"&gt;
  &lt;link rel="stylesheet" href="/static/css/footer.css"&gt;
  &lt;link rel="stylesheet" href="/static/css/page-header.css"&gt;
  &lt;link rel="stylesheet" href="/static/css/pagination.css"&gt;
  &lt;link rel="stylesheet" href="/static/css/tables.css"&gt;

  


  &lt;script type="application/ld+json"&gt;
    {
      "@context": "http://schema.org",
      "@type": "Organization",
      "name": "Borealis AI",
      "description": "Borealis AI, a RBC Institute for Research, is a curiosity-driven research center dedicated to achieving state-of-the-art in machine learning. Established in 2016, and with labs in Toronto, Edmonton, Montreal, Vancouver, and Waterloo, we support open academic collaborations and partner with world-class research centers in artificial intelligence. With a focus on ethical AI that will help communities thrive, our machine learning scientists perform fundamental and applied research in areas such as reinforcement learning, natural language processing, deep learning, and unsupervised learning to solve ground-breaking problems in diverse fields.",
      "url": "https://www.borealisai.com/",
      "logo": "href="/static/images/logo.svg",
      "sameAs": [
        "https://twitter.com/BorealisAI",
        "https://www.youtube.com/channel/UCYgO8AT3rKH0nnAwu64JDyw",
        "https://www.linkedin.com/company/borealis-ai/"
      ]
    }
  &lt;/script&gt;
&lt;/head&gt;
&lt;body&gt;
  &lt;!-- ////// --&gt;
&lt;!-- Loading Animation --&gt;
&lt;!-- ////// --&gt;
&lt;div class="loading-animation-wrapper"&gt;
  &lt;img src="/static/images/dual-ball-1s-200px.svg" alt="loading page"&gt;
&lt;/div&gt;
&lt;!-- Google Tag Manager (noscript) --&gt;
&lt;noscript&gt;
  &lt;iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NP49GJV"
          height="0" width="0" style="display:none;visibility:hidden"&gt;&lt;/iframe&gt;
&lt;/noscript&gt;
&lt;!-- End Google Tag Manager (noscript) --&gt;



&lt;div class="site-wrapper"&gt;

  &lt;!-- ////// --&gt;
  &lt;!-- Header --&gt;
  &lt;!-- ////// --&gt;

  

&lt;div class="header-wrapper"&gt;
  


&lt;div class="mobile-menu" itemscope itemtype="http://www.schema.org/SiteNavigationElement"&gt;
  
    &lt;div
      class="mobile-menu__item mobile-menu__item--contains-dropdown"
      itemprop="name"
    &gt;
      
        &lt;div class="mobile-menu__link "&gt;Research&lt;/div&gt;
        &lt;div class="sub-mobile-menu"&gt;
          



  &lt;div
    class="sub-mobile-menu__item"
    role="menuitem"
    itemprop="name"
  &gt;
    &lt;a
      href="/en/research/open-source/"
      class="sub-mobile-menu__link"
      data-event="global-header-navigation-click"
      data-detail1="Open Source"
      itemprop="url"
    &gt;Open Source&lt;/a&gt;
  &lt;/div&gt;

  &lt;div
    class="sub-mobile-menu__item"
    role="menuitem"
    itemprop="name"
  &gt;
    &lt;a
      href="/en/research/publications/"
      class="sub-mobile-menu__link"
      data-event="global-header-navigation-click"
      data-detail1="Publications"
      itemprop="url"
    &gt;Publications&lt;/a&gt;
  &lt;/div&gt;

  &lt;div
    class="sub-mobile-menu__item"
    role="menuitem"
    itemprop="name"
  &gt;
    &lt;a
      href="/en/research/blog/"
      class="sub-mobile-menu__link"
      data-event="global-header-navigation-click"
      data-detail1="Blog"
      itemprop="url"
    &gt;Blog&lt;/a&gt;
  &lt;/div&gt;

        &lt;/div&gt;
      
    &lt;/div&gt;
  
    &lt;div
      class="mobile-menu__item mobile-menu__item--contains-dropdown"
      itemprop="name"
    &gt;
      
        &lt;div class="mobile-menu__link "&gt;Applying AI&lt;/div&gt;
        &lt;div class="sub-mobile-menu"&gt;
          



  &lt;div
    class="sub-mobile-menu__item"
    role="menuitem"
    itemprop="name"
  &gt;
    &lt;a
      href="/en/applying-ai/overview/"
      class="sub-mobile-menu__link"
      data-event="global-header-navigation-click"
      data-detail1="Overview"
      itemprop="url"
    &gt;Overview&lt;/a&gt;
  &lt;/div&gt;

  &lt;div
    class="sub-mobile-menu__item"
    role="menuitem"
    itemprop="name"
  &gt;
    &lt;a
      href="/en/applying-ai/aiden/"
      class="sub-mobile-menu__link"
      data-event="global-header-navigation-click"
      data-detail1="Aiden"
      itemprop="url"
    &gt;Aiden&lt;/a&gt;
  &lt;/div&gt;

  &lt;div
    class="sub-mobile-menu__item"
    role="menuitem"
    itemprop="name"
  &gt;
    &lt;a
      href="/en/applying-ai/digital-money-management/"
      class="sub-mobile-menu__link"
      data-event="global-header-navigation-click"
      data-detail1="Digital Money Management"
      itemprop="url"
    &gt;Digital Money Management&lt;/a&gt;
  &lt;/div&gt;

  &lt;div
    class="sub-mobile-menu__item"
    role="menuitem"
    itemprop="name"
  &gt;
    &lt;a
      href="/en/applying-ai/respect-ai/"
      class="sub-mobile-menu__link"
      data-event="global-header-navigation-click"
      data-detail1="RESPECT AI"
      itemprop="url"
    &gt;RESPECT AI&lt;/a&gt;
  &lt;/div&gt;

  &lt;div
    class="sub-mobile-menu__item"
    role="menuitem"
    itemprop="name"
  &gt;
    &lt;a
      href="/en/applying-ai/industry-blog/"
      class="sub-mobile-menu__link"
      data-event="global-header-navigation-click"
      data-detail1="Industry Blog"
      itemprop="url"
    &gt;Industry Blog&lt;/a&gt;
  &lt;/div&gt;

        &lt;/div&gt;
      
    &lt;/div&gt;
  
    &lt;div
      class="mobile-menu__item "
      itemprop="name"
    &gt;
      
        &lt;a
          href="/en/news/"
          class="mobile-menu__link "
          data-event="global-header-navigation-click"
          data-detail1="News"
          itemprop="url"
        &gt;News&lt;/a&gt;
      
    &lt;/div&gt;
  
    &lt;div
      class="mobile-menu__item mobile-menu__item--contains-dropdown"
      itemprop="name"
    &gt;
      
        &lt;div class="mobile-menu__link "&gt;About&lt;/div&gt;
        &lt;div class="sub-mobile-menu"&gt;
          



  &lt;div
    class="sub-mobile-menu__item"
    role="menuitem"
    itemprop="name"
  &gt;
    &lt;a
      href="/en/about/our-story/"
      class="sub-mobile-menu__link"
      data-event="global-header-navigation-click"
      data-detail1="Our Story"
      itemprop="url"
    &gt;Our Story&lt;/a&gt;
  &lt;/div&gt;

  &lt;div
    class="sub-mobile-menu__item"
    role="menuitem"
    itemprop="name"
  &gt;
    &lt;a
      href="/en/about/locations/"
      class="sub-mobile-menu__link"
      data-event="global-header-navigation-click"
      data-detail1="Locations"
      itemprop="url"
    &gt;Locations&lt;/a&gt;
  &lt;/div&gt;

  &lt;div
    class="sub-mobile-menu__item"
    role="menuitem"
    itemprop="name"
  &gt;
    &lt;a
      href="/en/about/team/"
      class="sub-mobile-menu__link"
      data-event="global-header-navigation-click"
      data-detail1="Team"
      itemprop="url"
    &gt;Team&lt;/a&gt;
  &lt;/div&gt;

  &lt;div
    class="sub-mobile-menu__item"
    role="menuitem"
    itemprop="name"
  &gt;
    &lt;a
      href="/en/about/partnerships/"
      class="sub-mobile-menu__link"
      data-event="global-header-navigation-click"
      data-detail1="Partnerships"
      itemprop="url"
    &gt;Partnerships&lt;/a&gt;
  &lt;/div&gt;

  &lt;div
    class="sub-mobile-menu__item"
    role="menuitem"
    itemprop="name"
  &gt;
    &lt;a
      href="/en/about/fellowships/"
      class="sub-mobile-menu__link"
      data-event="global-header-navigation-click"
      data-detail1="Fellowships"
      itemprop="url"
    &gt;Fellowships&lt;/a&gt;
  &lt;/div&gt;

        &lt;/div&gt;
      
    &lt;/div&gt;
  
    &lt;div
      class="mobile-menu__item mobile-menu__item--contains-dropdown"
      itemprop="name"
    &gt;
      
        &lt;div class="mobile-menu__link "&gt;Careers&lt;/div&gt;
        &lt;div class="sub-mobile-menu"&gt;
          



  &lt;div
    class="sub-mobile-menu__item"
    role="menuitem"
    itemprop="name"
  &gt;
    &lt;a
      href="/en/careers/culture/"
      class="sub-mobile-menu__link"
      data-event="global-header-navigation-click"
      data-detail1="Culture"
      itemprop="url"
    &gt;Culture&lt;/a&gt;
  &lt;/div&gt;

  &lt;div
    class="sub-mobile-menu__item"
    role="menuitem"
    itemprop="name"
  &gt;
    &lt;a
      href="/en/careers/internships/"
      class="sub-mobile-menu__link"
      data-event="global-header-navigation-click"
      data-detail1="Internships"
      itemprop="url"
    &gt;Internships&lt;/a&gt;
  &lt;/div&gt;

  &lt;div
    class="sub-mobile-menu__item"
    role="menuitem"
    itemprop="name"
  &gt;
    &lt;a
      href="/en/careers/employment/"
      class="sub-mobile-menu__link"
      data-event="global-header-navigation-click"
      data-detail1="Employment"
      itemprop="url"
    &gt;Employment&lt;/a&gt;
  &lt;/div&gt;

        &lt;/div&gt;
      
    &lt;/div&gt;
  

  

  &lt;div class="social-links"&gt;
    &lt;a
      href="https://twitter.com/BorealisAI"
      class="social-links__item"
      target="_blank"
      data-event="mobile-nav-social-external-link"
      data-detail1="Twitter"
    &gt;
      &lt;img src="/static/images/icon-twitter-light.svg" alt="BorealisAI Twitter Account" class="icon-twitter"&gt;
    &lt;/a&gt;
    &lt;a
      href="https://www.youtube.com/channel/UCYgO8AT3rKH0nnAwu64JDyw"
      class="social-links__item"
      target="_blank"
      data-event="mobile-nav-social-external-link"
      data-detail1="Youtube"
    &gt;
      &lt;img src="/static/images/icon-youtube-light.svg" alt="BorealisAI Youtube Account" class="icon-youtube"&gt;
    &lt;/a&gt;
    &lt;a
      href="https://www.linkedin.com/company/11324622/"
      class="social-links__item"
      target="_blank"
      data-event="mobile-nav-social-external-link"
      data-detail1="Linkedin"
    &gt;
      &lt;img src="/static/images/icon-linkedin-light.svg" alt="BorealisAI Twitter Linkedin" class="icon-linkedin"&gt;
    &lt;/a&gt;
  &lt;/div&gt;
&lt;/div&gt;

  

&lt;header&gt;
  &lt;a href="/" class="header-logo" alt="BorealisAI logo"&gt;
    &lt;img src="/static/images/logo.svg" alt="BorealisAI Logo"&gt;
  &lt;/a&gt;
  &lt;button aria-label="Menu button" class="mobile-menu-button"&gt;&lt;/button&gt;

  &lt;div class="menu" role="menubar" itemscope itemtype="http://www.schema.org/SiteNavigationElement"&gt;

    
      
        
        &lt;div
        class="menu__item  menu__item--contains-dropdown"
        itemprop="name"
      &gt;
          &lt;div class="menu__link "&gt;Research&lt;/div&gt;
          &lt;div class="submenu" role="menu" hidden="true"&gt;
            




  &lt;div
    class="submenu__item"
    role="menuitem"
    itemprop="name"
  &gt;
    &lt;a
      href="/en/research/open-source/"
      class="submenu__link"
      data-event="global-header-navigation-click"
      data-detail1="Open Source"
      itemprop="url"
    &gt;Open Source&lt;/a&gt;
  &lt;/div&gt;


  &lt;div
    class="submenu__item"
    role="menuitem"
    itemprop="name"
  &gt;
    &lt;a
      href="/en/research/publications/"
      class="submenu__link"
      data-event="global-header-navigation-click"
      data-detail1="Publications"
      itemprop="url"
    &gt;Publications&lt;/a&gt;
  &lt;/div&gt;


  &lt;div
    class="submenu__item"
    role="menuitem"
    itemprop="name"
  &gt;
    &lt;a
      href="/en/research/blog/"
      class="submenu__link"
      data-event="global-header-navigation-click"
      data-detail1="Blog"
      itemprop="url"
    &gt;Blog&lt;/a&gt;
  &lt;/div&gt;

          &lt;/div&gt;
        &lt;/div&gt;
        
   
    
      
        
        &lt;div
        class="menu__item  menu__item--contains-dropdown"
        itemprop="name"
      &gt;
          &lt;div class="menu__link "&gt;Applying AI&lt;/div&gt;
          &lt;div class="submenu" role="menu" hidden="true"&gt;
            




  &lt;div
    class="submenu__item"
    role="menuitem"
    itemprop="name"
  &gt;
    &lt;a
      href="/en/applying-ai/overview/"
      class="submenu__link"
      data-event="global-header-navigation-click"
      data-detail1="Overview"
      itemprop="url"
    &gt;Overview&lt;/a&gt;
  &lt;/div&gt;


  &lt;div
    class="submenu__item"
    role="menuitem"
    itemprop="name"
  &gt;
    &lt;a
      href="/en/applying-ai/aiden/"
      class="submenu__link"
      data-event="global-header-navigation-click"
      data-detail1="Aiden"
      itemprop="url"
    &gt;Aiden&lt;/a&gt;
  &lt;/div&gt;


  &lt;div
    class="submenu__item"
    role="menuitem"
    itemprop="name"
  &gt;
    &lt;a
      href="/en/applying-ai/digital-money-management/"
      class="submenu__link"
      data-event="global-header-navigation-click"
      data-detail1="Digital Money Management"
      itemprop="url"
    &gt;Digital Money Management&lt;/a&gt;
  &lt;/div&gt;


  &lt;div
    class="submenu__item"
    role="menuitem"
    itemprop="name"
  &gt;
    &lt;a
      href="/en/applying-ai/respect-ai/"
      class="submenu__link"
      data-event="global-header-navigation-click"
      data-detail1="RESPECT AI"
      itemprop="url"
    &gt;RESPECT AI&lt;/a&gt;
  &lt;/div&gt;


  &lt;div
    class="submenu__item"
    role="menuitem"
    itemprop="name"
  &gt;
    &lt;a
      href="/en/applying-ai/industry-blog/"
      class="submenu__link"
      data-event="global-header-navigation-click"
      data-detail1="Industry Blog"
      itemprop="url"
    &gt;Industry Blog&lt;/a&gt;
  &lt;/div&gt;

          &lt;/div&gt;
        &lt;/div&gt;
        
   
    
      
        
        &lt;div
    role="menuitem"
        class="menu__item  "
        itemprop="name"
      &gt;
          &lt;a
          
            href="/en/news/"
            class="menu__link "
            data-event="global-header-navigation-click"
            data-detail1="News"
            itemprop="url"
          &gt;
          News&lt;/a&gt;   
        &lt;/div&gt;
        
   
    
      
        
        &lt;div
        class="menu__item  menu__item--contains-dropdown"
        itemprop="name"
      &gt;
          &lt;div class="menu__link "&gt;About&lt;/div&gt;
          &lt;div class="submenu" role="menu" hidden="true"&gt;
            




  &lt;div
    class="submenu__item"
    role="menuitem"
    itemprop="name"
  &gt;
    &lt;a
      href="/en/about/our-story/"
      class="submenu__link"
      data-event="global-header-navigation-click"
      data-detail1="Our Story"
      itemprop="url"
    &gt;Our Story&lt;/a&gt;
  &lt;/div&gt;


  &lt;div
    class="submenu__item"
    role="menuitem"
    itemprop="name"
  &gt;
    &lt;a
      href="/en/about/locations/"
      class="submenu__link"
      data-event="global-header-navigation-click"
      data-detail1="Locations"
      itemprop="url"
    &gt;Locations&lt;/a&gt;
  &lt;/div&gt;


  &lt;div
    class="submenu__item"
    role="menuitem"
    itemprop="name"
  &gt;
    &lt;a
      href="/en/about/team/"
      class="submenu__link"
      data-event="global-header-navigation-click"
      data-detail1="Team"
      itemprop="url"
    &gt;Team&lt;/a&gt;
  &lt;/div&gt;


  &lt;div
    class="submenu__item"
    role="menuitem"
    itemprop="name"
  &gt;
    &lt;a
      href="/en/about/partnerships/"
      class="submenu__link"
      data-event="global-header-navigation-click"
      data-detail1="Partnerships"
      itemprop="url"
    &gt;Partnerships&lt;/a&gt;
  &lt;/div&gt;


  &lt;div
    class="submenu__item"
    role="menuitem"
    itemprop="name"
  &gt;
    &lt;a
      href="/en/about/fellowships/"
      class="submenu__link"
      data-event="global-header-navigation-click"
      data-detail1="Fellowships"
      itemprop="url"
    &gt;Fellowships&lt;/a&gt;
  &lt;/div&gt;

          &lt;/div&gt;
        &lt;/div&gt;
        
   
    
      
        
        &lt;div
        class="menu__item  menu__item--contains-dropdown"
        itemprop="name"
      &gt;
          &lt;div class="menu__link "&gt;Careers&lt;/div&gt;
          &lt;div class="submenu" role="menu" hidden="true"&gt;
            




  &lt;div
    class="submenu__item"
    role="menuitem"
    itemprop="name"
  &gt;
    &lt;a
      href="/en/careers/culture/"
      class="submenu__link"
      data-event="global-header-navigation-click"
      data-detail1="Culture"
      itemprop="url"
    &gt;Culture&lt;/a&gt;
  &lt;/div&gt;


  &lt;div
    class="submenu__item"
    role="menuitem"
    itemprop="name"
  &gt;
    &lt;a
      href="/en/careers/internships/"
      class="submenu__link"
      data-event="global-header-navigation-click"
      data-detail1="Internships"
      itemprop="url"
    &gt;Internships&lt;/a&gt;
  &lt;/div&gt;


  &lt;div
    class="submenu__item"
    role="menuitem"
    itemprop="name"
  &gt;
    &lt;a
      href="/en/careers/employment/"
      class="submenu__link"
      data-event="global-header-navigation-click"
      data-detail1="Employment"
      itemprop="url"
    &gt;Employment&lt;/a&gt;
  &lt;/div&gt;

          &lt;/div&gt;
        &lt;/div&gt;
        
   
    
&lt;/div&gt;
&lt;/header&gt;
&lt;/div&gt;




  &lt;!-- /////// --&gt;
  &lt;!-- Content --&gt;
  &lt;!-- /////// --&gt;

  
&lt;link href="/static/css/blog-post-detail.css" media="screen" rel="stylesheet" type="text/css"/&gt;


  &lt;div  role="main" class="site-body-wrapper post-detail"&gt;
    &lt;div class="container"&gt;

      &lt;div class="page-header col-2"&gt;
        &lt;div class="col-2__item"&gt;
          &lt;div class="page-header__title"&gt;
            &lt;h1&gt;Tutorial #2: few-shot learning and meta-learning I&lt;/h1&gt;
          &lt;/div&gt;
          &lt;!-- &lt;div class="page-header__description"&gt;&lt;/div&gt; --&gt;
        &lt;/div&gt;
        &lt;div class="col-2__item"&gt;
          &lt;div class="page-header__date"&gt;Oct. 8, 2019&lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;

      
        &lt;div class="author-inline hide-desktop"&gt;
        Authors:
        
  
    
      &lt;a
        class=""
        href="/en/about/team/wenjie-zi/"
        data-event="author-name-select"
        data-detail2="W. Zi"
      &gt;W. Zi&lt;/a&gt;
    
    , 
  

  
    &lt;span class=""&gt;L. S. Ghoraie&lt;/span&gt;, 
  

  
    
      &lt;a
        class=""
        href="/en/about/team/simon-prince/"
        data-event="author-name-select"
        data-detail2="S. Prince"
      &gt;S. Prince&lt;/a&gt;
    
    
  

&lt;/span&gt;


        &lt;/div&gt;
      

      

      &lt;section class="section section--no-divider"&gt;
        &lt;div class="col-2"&gt;
          &lt;div class="col-2__item wysiwyg-content"&gt;
            &lt;h2&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Humans can recognize new object classes from very few instances. However, most machine learning techniques require thousands of examples to achieve similar performance. The goal of &lt;em&gt;few-shot learning&lt;/em&gt; is to classify new data having seen only a few training examples. In the extreme, there might only be a single example of each class (&lt;em&gt;one shot learning&lt;/em&gt;). In practice, few-shot learning is useful when training examples are hard to find (e.g., cases of a rare disease), or where the cost of labelling data is high.&lt;/p&gt;

&lt;p&gt;Few-shot learning is usually studied using &lt;em&gt;N-way-K-shot classification&lt;/em&gt;. Here, we aim to discriminate between $N$ classes with $K$ examples of each. A typical problem size might be to discriminate between $N=10$ classes with only $K=5$ samples from each to train from. We cannot train a classifier using conventional methods here; any modern classification algorithm will depend on far more parameters than there are training examples, and will generalize poorly.&lt;/p&gt;

&lt;p&gt;If the data is insufficient to constrain the problem, then one possible solution is to gain experience from other similar problems. To this end, most approaches characterize few-shot learning as a &lt;em&gt;meta-learning&lt;/em&gt; problem.&lt;/p&gt;

&lt;h2&gt;The meta learning framework&lt;/h2&gt;

&lt;p&gt;In the classical learning framework, we learn a how to classify from training data and evaluate the results using test data. In the meta-learning framework, we &lt;em&gt;learn how to learn&lt;/em&gt; to classify given a set of &lt;em&gt;training tasks&lt;/em&gt; and evaluate using a set of t&lt;em&gt;est tasks&lt;/em&gt; (figure 1); In other words, we use one set of classification problems to help solve other unrelated sets.&lt;/p&gt;

&lt;p class="image"&gt;








&lt;img class="image--full-width" src="/media/filer_public_thumbnails/filer_public/50/6a/506a0057-93f9-4d7a-9f91-14c4f0c8339f/t2_figure1.png__3000x1372_q85_subject_location-1500%2C686_subsampling-2.png"
    
    
    
    
&gt;



        &lt;span class="caption"&gt;Figure 1. Meta-learning framework. An algorithm is trained using a series of training tasks. Here, each task is a 3-way-2-shot classification problem because each training task contains a support set with three different classes and two examples of each. During training the cost function assesses performance on the query set for each task in turn given the respective support set. At test time, we use a completely different set of tasks, and evaluate performance on the query set, given the support set. Note that there is no overlap between the classes in the two training tasks {cat, lamb, pig}, {dog, shark, lion} and between those in the test task {duck, dolphin, hen}, so the algorithm must learn to classify image classes in general rather than any particular set.&lt;/span&gt;





 &lt;/p&gt;

&lt;p&gt;Here, each task mimics the few-shot scenario, so for N-way-K-shot classification, each task includes $N$ classes with $K$ examples of each. These are known as the &lt;i&gt;support set&lt;/i&gt; for the task and are used for learning how to solve this task. In addition, there are further examples of the same classes, known as a &lt;i&gt;query set&lt;/i&gt;, which are used to evaluating the performance on this task. Each task can be completely non-overlapping; we may never see the classes from one task in any of the others. The idea is that the system repeatedly sees instances (tasks) during training that match the structure of the final few-shot task, but contain different classes.&lt;/p&gt;

&lt;p&gt;At each step of meta-learning, we update the model parameters based on a randomly selected training task. The loss function is determined by the classification performance on the query set of this training task, based on knowledge gained from its support set. Since the network is presented with a different task at each time step, it must learn how to discriminate data classes in general, rather than a particular subset of classes.&lt;/p&gt;

&lt;p&gt;To evaluate few-shot performance, we use a set of test tasks. Each contains only unseen classes that were not in any of the training tasks. For each, we measure performance on the query set based on knowledge of their support set.&lt;/p&gt;

&lt;h2&gt;&lt;small&gt;Approaches to meta-learning&lt;/small&gt;&lt;/h2&gt;

&lt;p&gt;Approaches to meta-learning are diverse and there is no consensus on the best approach. However, there are three distinct families, each of which exploits a different type of prior knowledge:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Prior knowledge about similarity: &lt;/strong&gt;We learn embeddings in training tasks that tend to separate different classes even when they are unseen.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Prior knowledge about learning:&lt;/strong&gt; We use prior knowledge to constrain the learning algorithm to choose parameters that generalize well from few examples.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Prior knowledge of data:&lt;/strong&gt; We exploit prior knowledge about the structure and variability of the data and this allows us to learn viable models from few examples.&lt;/p&gt;

&lt;p&gt;An overview these methods can be seen in figure 2. In this review, we will consider each family of methods in turn. &lt;/p&gt;

&lt;p class="image"&gt;








&lt;img class="image--full-width" src="/media/filer_public_thumbnails/filer_public/44/d3/44d348ed-41e4-45c3-8286-2d98b01eec9a/t2_figure2.png__3000x1625_q85_subject_location-1500%2C814_subsampling-2.png"
    
    
    
    
&gt;



        &lt;span class="caption"&gt;Figure 2. Few-shot learning methods can be divided into three families. The first family learns prior knowledge about the similarity and dissimilarity of classes (in the form of embeddings) from training tasks. The second family exploits prior knowledge about how to learn that it has garnered from training tasks. The third family exploits prior knowledge about the data and its likely variation that is has learned from training tasks.&lt;/span&gt;





 &lt;/p&gt;

&lt;h2&gt;Prior knowledge of similarity&lt;/h2&gt;

&lt;p&gt;This family of algorithms aims to learn compact representations (embeddings) in which the data vector is mostly unaffected by intra-class variations but retains information about class membership. Early work focused on pairwise comparators which aim to judge whether two data examples are from the same or different classes, even though the system may not have seen these classes before. Subsequent research focused on multi-class comparators which allow assignment of new examples to one of several classes.&lt;/p&gt;

&lt;h2&gt;&lt;small&gt;Pairwise comparators&lt;/small&gt;&lt;/h2&gt;

&lt;p&gt;Pairwise comparators take two examples and classify them as either belonging to the same or different classes. This differs from the standard N-way-K-shot configuration and does not obviously map onto the above description of meta-learning although as we will see later there is in fact a close relationship.&lt;/p&gt;

&lt;h4&gt;&lt;strong&gt;Siamese networks&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;&lt;a href="https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf" target="_blank"&gt;Koch &lt;em&gt;et al.&lt;/em&gt; (2015)&lt;/a&gt; trained a model that outputs the probability $Pr(y_a=y_{b})$ that two data examples $\mathbf{x}_{a}$ and $\mathbf{x}_{b}$ belong to the same class (figure 3a). The two examples are passed through identical multi-layer neural networks (hence Siamese) to create two embeddings. The component-wise absolute distance between the embeddings is computed and passed to a subsequent comparison network that reduces this distance vector to a single number. This is passed though a sigmoidal output for classification as being the same or different with a cross-entropy loss.&lt;/p&gt;

&lt;p class="image"&gt;








&lt;img class="image--full-width" src="/media/filer_public_thumbnails/filer_public/76/e2/76e24938-4b43-4cde-9b12-4be2d067561b/t2_figure3.png__3000x1185_q85_subject_location-1500%2C593_subsampling-2.png"
    
    
    
    
&gt;



        &lt;span class="caption"&gt;Figure 3. Pairwise comparators. a) Siamese networks take two examples $\mathbf{x}_{a}$ and $\mathbf{x}_{b}$ and return the probability $Pr(y_{a}=y_{b})$ that they are the same class. They do this by passing each example through an identical network (hence Siamese) and then using the pairwise difference between the embeddings as the basis of the decision. b) Triplet networks take two examples of the same class $\mathbf{x}_{a}$ and $\mathbf{x}_{+}$ and one of a different class $\mathbf{x}_{-}$ and pass all three through identical networks to create three embeddings. The triplet loss encourages the embeddings of examples from the same class to be closer together than those from different classes. c) In the test phase for triplet networks, we pass two examples $\mathbf{x}_{a}$ and $\mathbf{x}_{b}$ through the same network and judge whether they come from the same class or not based on the distance.&lt;/span&gt;





 &lt;/p&gt;

&lt;p&gt;During training, each pair of examples are randomly drawn from a super-set of training classes. Hence, the system learns to discriminate between classes is general, rather than two classes in particular. In testing, completely different classes are used. Although this does not have the formal structure of the N-way-K-shot task, the spirit is similar.&lt;/p&gt;

&lt;h4&gt;Triplet networks&lt;/h4&gt;

&lt;p&gt;Triplet networks (&lt;a href="https://arxiv.org/abs/1412.6622" target="_blank"&gt;Hoffer &amp;amp; Ailon 2015&lt;/a&gt;) consist of three identical networks that are trained by triplets $\{\mathbf{x}_{+},\mathbf{x}_{a},\mathbf{x}_{-}\}$ of the form (positive, anchor, negative). The positive and anchor samples are from the same class, whereas the negative sample is from a different class. The learning criterion is &lt;em&gt;triplet loss&lt;/em&gt; which encourages the anchor to be closer to the positive example than it is to the negative example in the embedding space (figure 3b). Hence it is based on two pairwise comparisons.&lt;/p&gt;

&lt;p&gt;After training, the system can take two examples and establish whether they are from the same or different classes, by thresholding the distance in the learned embedding space. This was employed in the context of face verification by &lt;a href="https://arxiv.org/abs/1503.03832" target="_blank"&gt;Schroff &lt;em&gt;et al.&lt;/em&gt; (2015)&lt;/a&gt;. This line of work is part of a greater literature on learning distance metrics (see &lt;a href="https://arxiv.org/abs/1812.05944" target="_blank"&gt;Suarez &lt;em&gt;et al.&lt;/em&gt; 2018&lt;/a&gt; for overview).&lt;/p&gt;

&lt;h2&gt;&lt;small&gt;Multi-class comparators&lt;/small&gt;&lt;/h2&gt;

&lt;p&gt;Pairwise comparators can be adapted to the N-way-K-shot setting by assigning the class for an example in the query set based on its maximum similarity to one of the examples in the support set. However, multi-class comparators attempt to do the same thing in a more principled way; here the representation and final classification are learned in an end-to-end fashion.&lt;/p&gt;

&lt;p&gt;In this section, we'll use the notation $\mathbf{x}_{nk}$ to denote the $k$th support example from the $n$th class in the N-Way-K-Shot classification task, and $y_{nk}$ to denote the corresponding label. For simplicity, we'll assume there is a single query example $\hat{\mathbf{x}}$ and the goal is to predict the associated label $\hat{y}$.&lt;/p&gt;

&lt;h4&gt;Matching Networks&lt;/h4&gt;

&lt;p&gt;Matching networks (&lt;a href="https://arxiv.org/abs/1606.04080" target="_blank"&gt;Vinyals &lt;em&gt;et al.&lt;/em&gt; 2016&lt;/a&gt;) predict the one-hot encoded query-set label $\hat{\mathbf{y}}$ as a weighted sum of all of the one-hot encoded support-set labels $\{\mathbf{y}_{nk}\}_{n,k=1}^{NK}$. The weight is based on a computed similarity $a[\hat{\mathbf{x}},\mathbf{x}_{nk}]$ between the query-set data $\hat{\mathbf{x}}$ and each training example $\{\mathbf{x}_{nk}\}_{n,k=1}^{N,K}$.&lt;/p&gt;

&lt;p&gt;\begin{equation}&lt;br&gt;
    \hat{\mathbf{y}} = \sum_{n=1}^{N}\sum_{k=1}^{K} a[\mathbf{x}_{nk},\hat{\mathbf{x}}]\mathbf{y}_{nk} \tag{1.1}&lt;br&gt;
\end{equation}&lt;/p&gt;

&lt;p&gt;where the similarities have been constrained to be positive and sum to one. &lt;/p&gt;

&lt;p&gt;To compute the similarity $a[\hat{\mathbf{x}},\mathbf{x}_{nk}]$, they pass each support example $\mathbf{x}_{nk}$ through a network $\mbox{ f}[\bullet]$ to produce an embedding and pass the query example $\hat{\mathbf{x}}$ through a different network $\mbox{ g}[\bullet]$ to produce a different embedding. They then compute the cosine similarity between these embeddings (figure 5a)&lt;/p&gt;

&lt;p&gt;\begin{equation}&lt;br&gt;
     d[\mathbf{x}_{nk}, \hat{\mathbf{x}}] = \frac{\mbox{ f}[\mathbf{x}_{nk}]^{T}\mbox{ g}[\hat{\mathbf{x}}]} {||\mbox{ f}[\mathbf{x}_{nk}]||\cdot||\mbox{ g}[\hat{\mathbf{x}}]||}, \tag{1.2}&lt;br&gt;
\end{equation}&lt;/p&gt;

&lt;p&gt;and normalise using a softmax function:&lt;/p&gt;

&lt;p&gt;\begin{equation}&lt;br&gt;
    a[\hat{\mathbf{x}}_{nk},\mathbf{x}] = \frac{\exp[d[\mathbf{x}_{nk},\hat{\mathbf{x}}]]}{\sum_{n=1}^{N}\sum_{k=1}^{K}\exp[d[\mathbf{x}_{nk},\hat{\mathbf{x}}]]}. \tag{1.3}&lt;br&gt;
\end{equation}&lt;/p&gt;

&lt;p&gt;to produce positive similarities that sum to one. This system can be trained end to end for the N-way-K-shot learning task.&lt;sup&gt;1 &lt;/sup&gt;At each learning iteration, the system is presented with a training task; the predicted labels are computed for the query set (the calculation is based on the support set) and the loss function is the cross entropy of the ground truth and predicted labels.&lt;/p&gt;

&lt;p&gt;Matching networks compute similarities between the embeddings of each support example and the query example. This has the disadvantage that the algorithm is not robust to data imbalance; if there are more support examples for some classes than others (i.e., we have departed from the N-way-K-shot scenario), the ones with more frequent training data may dominate.&lt;/p&gt;

&lt;h4&gt;Prototypical Networks&lt;/h4&gt;

&lt;p&gt;Prototypical networks (&lt;a href="https://arxiv.org/abs/1703.05175" target="_blank"&gt;Snell et al. 2017&lt;/a&gt;) are robust to data imbalance by construction; they average the embeddings $\{\mathbf{z}_{nk}\}_{k=1}^{K}$ of the examples for class $n$ to compute their mean embedding or &lt;em&gt;prototype&lt;/em&gt; $\mathbf{p}_{n}$. They then use the similarity between each prototype and the query embedding (figures 4 and 5 b) as a basis for classification.&lt;/p&gt;

&lt;p class="image"&gt;








&lt;img class="image--full-width" src="/media/filer_public_thumbnails/filer_public/97/02/970270e1-d976-49c1-ba8c-a9310c00d2c0/t2_figure4.png__3000x1215_q85_subject_location-1500%2C607_subsampling-2.png"
    
    
    
    
&gt;



        &lt;span class="caption"&gt;Figure 4. Prototypical networks. The support examples $\mathbf{x}_{nk}$ are all mapped to the embedding space to create embedding $\mathbf{z}_{nk}$ (coloured circles). All of the embeddings for class $k$ are averaged to create a prototype $\mathbf{p}_{n}$. To classify query examples $\hat{\mathbf{x}}$, we first compute its embedding $\hat{\mathbf{z}}$ and then base the decision on the relative distance to the prototypes.&lt;/span&gt;





 &lt;/p&gt;

&lt;p&gt;The similarity is computed as a negative multiple of the Euclidean distance (so that larger distances now give smaller numbers). They pass these similarities to a softmax function to give a probability over classes. This model effectively learns a metric space where the average of a few examples of a class is a good representation of that class and class membership can be assigned based on distance.&lt;/p&gt;

&lt;p&gt;They noted that (i) the choice of distance function is vital as squared Euclidean distance outperformed cosine distance, (ii) having a higher number of classes in the support set helps to achieve better performance, and that (iii) the system works best when the support size of each class is matched in the training and test tasks.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://arxiv.org/abs/1803.00676" target="_blank"&gt;Ren et al. (2018)&lt;/a&gt; extended this system to take advantage of additional unlabeled data which might be from the test task classes or from other distractor classes. &lt;a href="https://arxiv.org/abs/1805.10123" target="_blank"&gt;Oreshkin et al. (2018)&lt;/a&gt; extended this approach by learning a task-dependent metric on the feature space, so that the distance metric changes from place to place in the embedding space.&lt;/p&gt;

&lt;h4&gt;Relation Networks&lt;/h4&gt;

&lt;p&gt;Matching networks and prototypical networks both focus on learning the embedding and compare examples using a pre-defined metric (cosine and Euclidean distance, respectively). Relation networks (&lt;a href="https://dl.acm.org/citation.cfm?id=3045585" target="_blank"&gt;Santoro et al. 2016&lt;/a&gt;) also learn a metric for comparison of the embeddings (figure 5c). Similarly to prototypical networks, the relation network averages the embeddings of each class in the support set together to form a single prototype. Each prototype is then concatenated with the query embedding and passed to a &lt;em&gt;relation module&lt;/em&gt;. This is a learnable non-linear operator that produces a similarity score between 0 and 1 where 1 indicates that the query example belongs to this class prototype. This approach is clean and elegant and can be trained end-to-end.&lt;/p&gt;

&lt;h2&gt;&lt;small&gt;Comparison between models&lt;/small&gt;&lt;/h2&gt;

&lt;p&gt;All of the pairwise and multi-class comparators are closely related to one another. Each learns an embedding space for data examples. In matching networks, there are different embeddings for support and query examples, but in the other models, they are the same. For prototypical networks and relation networks, multiple embeddings from the same class are averaged to form prototypes. Distances between support set embeddings/prototypes and query set embeddings are computed using either pre-determined distance functions such as Euclidean or cosine distance (triplet networks, matching networks, prototypical networks) or by learning a distance metric (Siamese networks and relation networks).&lt;/p&gt;

&lt;p class="image"&gt;








&lt;img class="image--full-width" src="/media/filer_public_thumbnails/filer_public/d6/16/d616cbd2-189e-4d7a-b724-290ee8d9b821/t2_figure5.png__3000x1438_q85_subject_location-1500%2C721_subsampling-2.png"
    
    
    
    
&gt;



        &lt;span class="caption"&gt;Figure 5. Multi-class comparators. a) Matching networks compute separate embeddings for support examples (here $\mathbf{x}_{11},\mathbf{x}_{12},\mathbf{x}_{21},\mathbf{x}_{22}$) and the query example $\hat{\mathbf{x}}$. Here $\mathbf{x}_{nk}$ is the $k$th example from the $n$th class. They compute the cosine similarity between each support embedding and the the query embedding, and then use these similarities to choose the class. This has the disadvantage that if there are many more examples of one class than the others, the relatively abundant class may be chosen too frequently. b) Prototypical networks embed the query and support examples using the same network, but average together support embeddings to make prototypes for each class, and so it doesn&amp;#39;t matter if the numbers are unbalanced. The Euclidean distance between query embeddings and prototypes is used to support classification. c) Relation networks replace this Euclidean distance with a learned non-linear distance metric.&lt;/span&gt;





 &lt;/p&gt;

&lt;p&gt;The multi-class networks have the advantage that they can be trained end-to-end for the N-way-K-shot classification task. This is not true for the pairwise comparators which are trained to produce a similarity or distance between pairs of data examples (which could itself subsequently be used to support multi-class classification).&lt;/p&gt;

&lt;p&gt;Although it is not obvious how the pairwise comparators map to the meta-learning framework, it is possible to consider their data as consisting of minimal training and test tasks. For Siamese networks, each pair of examples is a training task, consisting of one support example and one query example, where their classes may not necessarily match. For triplet networks, there are two support examples (from different classes) and one query example (from one of the classes).&lt;/p&gt;

&lt;h2&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;In part I of this tutorial we have described the few-shot and meta-learning problems and introduced a taxonomy of methods. We have also discussed methods that use a series of training tasks to learn prior knowledge about the similarity and dissimilarity of classes that can be exploited for future few-shot tasks. This knowledge takes the form of data embeddings that reduce within-class variance relative to between-class variance, and hence make it easier to learn from just a few data points.&lt;/p&gt;

&lt;p&gt;In &lt;a href="https://www.borealisai.com/en/blog/tutorial-3-few-shot-learning-and-meta-learning-ii/"&gt;part II&lt;/a&gt; of this tutorial, we'll discuss methods that incorporate prior knowledge about how to learn models, and that incorporate prior knowledge about the data itself.&lt;/p&gt;

&lt;p&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;cite&gt;&lt;a href="https://arxiv.org/abs/1606.04080" target="_blank"&gt;Vinyals et al. (2016)&lt;/a&gt;. also introduced a novel &lt;em&gt;context embedding&lt;/em&gt; method which took the full context of the support set $\mathcal{S}$ into account so that $\mbox{ g}[\bullet] = \mbox{ g}[\mathbf{x}, \mathcal{S}]$. Here, the support set was considered as a sequence and encoded by a bi-directional LSTM. &lt;a href="https://arxiv.org/abs/1703.05175" target="_blank"&gt;Snell et al. (2017)&lt;/a&gt; later argued that this context embedding was problematic and redundant.&lt;/cite&gt;&lt;/p&gt;
          &lt;/div&gt;


          &lt;div class="col-2__item"&gt;
            &lt;div class="authors hide-mobile"&gt;
                
  
    &lt;div class="authors__heading"&gt;Authors&lt;/div&gt;
  


  &lt;div class="authors-list"&gt;
    
      &lt;div class="authors-list__item"&gt;
        
          &lt;a
            class="authors-list__link"
            href="/en/about/team/wenjie-zi/"
            data-event="author-name-select"
            data-detail2="W. Zi"
          &gt;W. Zi&lt;/a&gt;
        
      &lt;/div&gt;
    
      &lt;div class="authors-list__item"&gt;
        
          &lt;div class="authors-list__link"&gt;L. S. Ghoraie&lt;/div&gt;
        
      &lt;/div&gt;
    
      &lt;div class="authors-list__item"&gt;
        
          &lt;a
            class="authors-list__link"
            href="/en/about/team/simon-prince/"
            data-event="author-name-select"
            data-detail2="S. Prince"
          &gt;S. Prince&lt;/a&gt;
        
      &lt;/div&gt;
    
  &lt;/div&gt;

  

            &lt;/div&gt;

          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/section&gt;

      


    &lt;/div&gt;
  &lt;/div&gt;

  &lt;div class="max-width-section homepage-blog-slider post-detail-related-box"&gt;
    &lt;p&gt;Sed laoreet urna odio non gravida magna malesuada sed pellentesque placerat nisl erat et rhoncus justo tempus at donec finibus nulla.&lt;/p&gt;
  &lt;/div&gt;

  &lt;script&gt;
    (function() {
      'use strict';

      // -----------
      // Application
      // -----------

      wrapTables();

      // ---------
      // Functions
      // ---------

      function wrapTables() {
        // Wrap all of the tables within wysiwyg content with a table-wrapper div
        // This div will allow the user to scroll the table if it gets too long

        var tables = document.querySelectorAll('.wysiwyg-content table');

        for (var i = 0; i &lt; tables.length; i++) {
          var parentNode = tables[i].parentNode;
          var table = tables[i].cloneNode(true);
              table.setAttribute('bordercolor', 'red');
          var wrapper = document.createElement('div');
          wrapper.classList.add('table-wrapper');
          wrapper.appendChild(table);

          parentNode.replaceChild(wrapper, tables[i]);
        }
      }
    })();
  &lt;/script&gt;


  &lt;!-- ////// --&gt;
  &lt;!-- Footer --&gt;
  &lt;!-- ////// --&gt;

  
    
&lt;footer class="footer"&gt;
    &lt;div class="footer-container"&gt;
      &lt;div class="footer__logo"&gt;
        &lt;img src="/static/images/footer-logo.png" alt="BorealisAI footer logo"&gt;
      &lt;/div&gt;
      &lt;div class="social-links"&gt;
        &lt;a
          href="https://twitter.com/BorealisAI"
          target="_blank"
          class="social-links__item"
          data-event="global-footer-social-external-link"
          data-detail1="Twitter"
        &gt;
          &lt;svg width="22px" height="18px" viewBox="0 0 22 18" version="1.1" xmlns="http://www.w3.org/2000/svg"
               xmlns:xlink="http://www.w3.org/1999/xlink" class="icon-twitter"&gt;
               &lt;title&gt;Twitter icon&lt;/title&gt;
            &lt;defs&gt;
              &lt;polygon id="twitter-path-1"
                       points="0 0.00104392157 21.9789778 0.00104392157 21.9789778 17.3771186 0 17.3771186"&gt;&lt;/polygon&gt;
            &lt;/defs&gt;
            &lt;g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"&gt;
              &lt;g  transform="translate(-196.000000, -52.000000)"&gt;
                &lt;g &gt;
                  &lt;g transform="translate(196.000000, 50.000000)"&gt;
                    &lt;g id="twitter" transform="translate(0.000000, 2.000000)"&gt;
                      &lt;mask id="twitter-mask-2" fill="white"&gt;
                        &lt;use xlink:href="#twitter-path-1"&gt;&lt;/use&gt;
                      &lt;/mask&gt;
                      &lt;g &gt;&lt;/g&gt;
                      &lt;path class="icon-hover"
                            d="M1.53061799,0.808840373 C1.53061799,0.808840373 4.90325291,5.14857147 10.7675915,5.4493203 C10.7675915,5.4493203 9.97628995,2.88425587 12.4090942,0.923174641 C14.8418984,-1.04039212 17.8560148,0.622425808 18.4347661,1.36311302 C18.4347661,1.36311302 20.1454116,1.10461815 21.341327,0.324162502 C21.341327,0.324162502 20.9495175,1.82045008 19.5077608,2.72518211 C19.5077608,2.72518211 21.1979196,2.50645569 21.9789778,2.06403178 C21.9789778,2.06403178 21.1543852,3.346564 19.7305545,4.32834738 C19.7305545,4.32834738 20.3323534,9.7443119 15.5358878,14.2182615 C10.7394222,18.6946966 2.84689312,17.7626238 -0.000768253968,15.4187713 C-0.000768253968,15.4187713 3.86611005,15.841311 6.59085079,13.589423 C6.59085079,13.589423 3.37442751,13.5272848 2.44484021,10.6142465 C2.44484021,10.6142465 4.05305185,10.7360374 4.33218413,10.4352886 C4.33218413,10.4352886 0.86735873,9.62252105 0.836628571,6.1079851 C0.836628571,6.1079851 1.88913651,6.62000377 2.84689312,6.6498301 C2.84689312,6.6498301 -0.49501164,4.30846316 1.53061799,0.808840373"
                             fill="#FFFFFF" mask="url(#twitter-mask-2)"&gt;&lt;/path&gt;
                    &lt;/g&gt;
                  &lt;/g&gt;
                &lt;/g&gt;
              &lt;/g&gt;
            &lt;/g&gt;
          &lt;/svg&gt;
        &lt;/a&gt;
        &lt;a
          href="https://www.youtube.com/channel/UCYgO8AT3rKH0nnAwu64JDyw"
          target="_blank"
          class="social-links__item"
          data-event="global-footer-social-external-link"
          data-detail1="Youtube"
        &gt;
          &lt;svg width="22px" height="15px" viewBox="0 0 22 15" version="1.1" xmlns="http://www.w3.org/2000/svg"
               xmlns:xlink="http://www.w3.org/1999/xlink" class="icon-youtube"&gt;
               &lt;title&gt;Youtube icon&lt;/title&gt;
            &lt;defs&gt;
              &lt;polygon id="youtube-path-1"
                       points="3.60019352e-05 0 21.1211353 0 21.1211353 14.443106 3.60019352e-05 14.443106"&gt;&lt;/polygon&gt;
            &lt;/defs&gt;
            &lt;g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"&gt;
              &lt;g  transform="translate(-240.000000, -54.000000)"&gt;
                &lt;g &gt;
                  &lt;g transform="translate(196.000000, 50.000000)"&gt;
                    &lt;g id="youtube" transform="translate(44.000000, 4.000000)"&gt;
                      &lt;g &gt;
                        &lt;mask id="youtube-mask-2" fill="white"&gt;
                          &lt;use xlink:href="#youtube-path-1"&gt;&lt;/use&gt;
                        &lt;/mask&gt;
                        &lt;g &gt;&lt;/g&gt;
                        &lt;path class="icon-hover"
                              d="M20.6797876,2.25531793 C20.4368945,1.36753139 19.721296,0.668437341 18.8123672,0.431174 C17.1653987,-2.32953698e-05 10.5606036,-2.32953698e-05 10.5606036,-2.32953698e-05 C10.5606036,-2.32953698e-05 3.95580863,-2.32953698e-05 2.3087201,0.431174 C1.39991125,0.668437341 0.684192776,1.36753139 0.441299721,2.25531793 C3.60019352e-05,3.86432913 3.60019352e-05,7.22154135 3.60019352e-05,7.22154135 C3.60019352e-05,7.22154135 3.60019352e-05,10.5786371 0.441299721,12.1878812 C0.684192776,13.0755513 1.39991125,13.7746453 2.3087201,14.0120252 C3.95580863,14.443106 10.5606036,14.443106 10.5606036,14.443106 C10.5606036,14.443106 17.1653987,14.443106 18.8123672,14.0120252 C19.721296,13.7746453 20.4368945,13.0755513 20.6797876,12.1878812 C21.1211713,10.5786371 21.1211713,7.22154135 21.1211713,7.22154135 C21.1211713,7.22154135 21.1211713,3.86432913 20.6797876,2.25531793"
                               fill="#FFFFFF" mask="url(#youtube-mask-2)"&gt;&lt;/path&gt;
                      &lt;/g&gt;
                      &lt;polygon  fill="#091434"
                               points="8.40045154 10.2696357 13.9207483 7.22166947 8.40045154 4.17347033"&gt;&lt;/polygon&gt;
                    &lt;/g&gt;
                  &lt;/g&gt;
                &lt;/g&gt;
              &lt;/g&gt;
            &lt;/g&gt;
          &lt;/svg&gt;
        &lt;/a&gt;
        &lt;a
          href="https://www.linkedin.com/company/11324622/"
          target="_blank"
          class="social-links__item"
          data-event="global-footer-social-external-link"
          data-detail1="LinkedIn"
        &gt;
          &lt;svg width="21px" height="18px" viewBox="0 0 21 18" version="1.1" xmlns="http://www.w3.org/2000/svg"
               xmlns:xlink="http://www.w3.org/1999/xlink" class="icon-linkedin"&gt;
               &lt;title&gt;Linkedin icon&lt;/title&gt;
            &lt;defs&gt;&lt;/defs&gt;
            &lt;g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"&gt;
              &lt;g  transform="translate(-288.000000, -52.000000)"&gt;
                &lt;g &gt;
                  &lt;g transform="translate(196.000000, 50.000000)"&gt;
                    &lt;g id="linkedin" transform="translate(92.000000, 2.000000)"&gt;
                      &lt;path class="icon-hover"
                            d="M16.2793953,0 L1.29662791,0 C0.581162791,0 0,0.550797538 0,1.22957729 L0,15.8328222 C0,16.5125499 0.581162791,17.0642955 1.29662791,17.0642955 L16.2793953,17.0642955 C16.9958372,17.0642955 17.5813953,16.5125499 17.5813953,15.8328222 L17.5813953,1.22957729 C17.5813953,0.550797538 16.9958372,0 16.2793953,0"
                             fill="#FFFFFF"&gt;&lt;/path&gt;
                      &lt;path d="M3.91078605,2.34918468 C4.74541395,2.34918468 5.42229767,3.00710807 5.42229767,3.81624008 C5.42229767,4.62632011 4.74541395,5.28376949 3.91078605,5.28376949 C3.07322791,5.28376949 2.3978093,4.62632011 2.3978093,3.81624008 C2.3978093,3.00710807 3.07322791,2.34918468 3.91078605,2.34918468 Z M2.60487907,14.5406758 L5.21522791,14.5406758 L5.21522791,6.39768878 L2.60487907,6.39768878 L2.60487907,14.5406758 Z"
                            id="Fill-3" fill="#091434"&gt;&lt;/path&gt;
                      &lt;path d="M6.8515186,6.39749918 L9.35100698,6.39749918 L9.35100698,7.50999644 L9.38665814,7.50999644 C9.73437907,6.86961135 10.5856116,6.19462367 11.853914,6.19462367 C14.4925884,6.19462367 14.9804721,7.88067086 14.9804721,10.0739068 L14.9804721,14.5404862 L12.3754953,14.5404862 L12.3754953,10.5810956 C12.3754953,9.63639726 12.3559605,8.42151423 11.0197744,8.42151423 C9.66307674,8.42151423 9.45600698,9.45011204 9.45600698,10.5123644 L9.45600698,14.5404862 L6.8515186,14.5404862 L6.8515186,6.39749918 Z"
                            id="Fill-5" fill="#091434"&gt;&lt;/path&gt;
                    &lt;/g&gt;
                  &lt;/g&gt;
                &lt;/g&gt;
              &lt;/g&gt;
            &lt;/g&gt;
          &lt;/svg&gt;
        &lt;/a&gt;&lt;a
          href="http://www.borealisai.com/en/rss.xml"
          target="_blank"
          class="social-links__item"
          data-event="global-footer-rss-external-link"
         
          data-detail1="RSS"
        &gt;&lt;svg width="22px" height="22px" viewBox="0 0 128 128" version="1.1" xmlns="http://www.w3.org/2000/svg"
                xmlns="http://www.w3.org/2000/svg"
                xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve"
                xmlns:serif="http://www.serif.com/" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linejoin:round;stroke-miterlimit:1.41421;"&gt;
           &lt;title&gt;RSS
      </title>
      <link>
        https://www.borealisai.com/en/blog/tutorial-2-few-shot-learning-and-meta-learning-i/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;
            &lt;h2&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Humans can recognize new object classes from very few instances. However, most machine learning techniques require thousands of examples to achieve similar performance. The goal of &lt;em&gt;few-shot learning&lt;/em&gt;&amp;nbsp;is to classify new data having seen only a few training examples. In the extreme, there might only be a single example of each class (&lt;em&gt;one shot learning&lt;/em&gt;). In practice, few-shot learning is useful when training examples are hard to find (e.g., cases of a rare disease), or where the cost of labelling data is high.&lt;/p&gt;

&lt;p&gt;Few-shot learning is usually studied using &lt;em&gt;N-way-K-shot classification&lt;/em&gt;. Here, we aim to discriminate between $N$ classes with $K$ examples of each. A typical problem size might be to discriminate between $N=10$ classes with only $K=5$ samples from each to train from. We cannot train a classifier using conventional methods here; any modern classification algorithm will depend on far more parameters than there are training examples, and will generalize poorly.&lt;/p&gt;

&lt;p&gt;If the data is insufficient to constrain the problem, then one possible solution is to gain experience from other similar problems. To this end, most approaches characterize few-shot learning as a &lt;em&gt;meta-learning&lt;/em&gt;&amp;nbsp;problem.&lt;/p&gt;

&lt;h2&gt;The meta learning framework&lt;/h2&gt;

&lt;p&gt;In the classical learning framework, we learn a how to classify from training data and evaluate the results using test data. In the meta-learning framework, we &lt;em&gt;learn how to learn&lt;/em&gt;&amp;nbsp;to classify given a set of &lt;em&gt;training tasks&lt;/em&gt;&amp;nbsp;and evaluate using a set of t&lt;em&gt;est tasks&lt;/em&gt;&amp;nbsp;(figure 1); In other words, we use one set of classification problems to help solve other unrelated sets.&lt;/p&gt;

&lt;p&gt;








&lt;img src="https://www.borealisai.com/media/filer_public_thumbnails/filer_public/50/6a/506a0057-93f9-4d7a-9f91-14c4f0c8339f/t2_figure1.png__3000x1372_q85_subject_location-1500%2C686_subsampling-2.png"&gt;



        &lt;span&gt;Figure 1. Meta-learning framework. An algorithm is trained using a series of training tasks. Here, each task is a 3-way-2-shot classification problem because each training task contains a support set with three different classes and two examples of each. During training the cost function assesses performance on the query set for each task in turn given the respective support set. At test time, we use a completely different set of tasks, and evaluate performance on the query set, given the support set.&amp;nbsp;Note that there is no overlap between the classes in the two training tasks {cat, lamb, pig}, {dog, shark, lion} and between those in the test task {duck, dolphin, hen}, so the algorithm must learn to classify image classes in general rather than any particular set.&lt;/span&gt;





 &lt;/p&gt;

&lt;p&gt;Here, each task mimics the few-shot scenario, so for N-way-K-shot classification, each task includes $N$ classes with $K$ examples of each. These are known as the&amp;nbsp;&lt;i&gt;support set&lt;/i&gt;&amp;nbsp;for the task and are used for learning how to solve this task. In addition, there are further examples of the same&amp;nbsp;classes, known as a&amp;nbsp;&lt;i&gt;query set&lt;/i&gt;, which are used to evaluating the performance on this task. Each task can be completely non-overlapping; we may never see the classes from one task in any of the others. The idea is that the system repeatedly sees instances (tasks) during training that match the structure of the final few-shot task, but contain different classes.&lt;/p&gt;

&lt;p&gt;At each step of meta-learning, we update the model parameters based on a randomly selected training task. The loss function is determined by the classification performance on the query set of this training task, based on knowledge gained from its support set. Since the network is presented with a different task at each time step, it must learn how to discriminate data classes in general, rather than a particular subset of classes.&lt;/p&gt;

&lt;p&gt;To evaluate few-shot performance, we use a set of test tasks. Each contains only unseen classes that were not in any of the training tasks. For each, we measure performance on the query set based on knowledge of their support set.&lt;/p&gt;

&lt;h2&gt;&lt;small&gt;Approaches to meta-learning&lt;/small&gt;&lt;/h2&gt;

&lt;p&gt;Approaches to meta-learning are diverse and there is no consensus on the best approach.&amp;nbsp;However, there are three distinct families, each of which exploits a different type of prior knowledge:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Prior knowledge about similarity:&amp;nbsp;&lt;/strong&gt;We learn embeddings in training tasks that tend to separate different classes even when they are unseen.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Prior knowledge about learning:&lt;/strong&gt;&amp;nbsp;We use prior knowledge to constrain the learning algorithm to choose parameters that generalize well from few examples.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Prior knowledge of data:&lt;/strong&gt;&amp;nbsp;We exploit prior knowledge about the structure and variability of the data and this allows us to learn viable models from few examples.&lt;/p&gt;

&lt;p&gt;An overview these methods can be seen in figure 2. In this review, we will consider each family of methods in turn.&amp;nbsp;&lt;/p&gt;

&lt;p&gt;








&lt;img src="https://www.borealisai.com/media/filer_public_thumbnails/filer_public/44/d3/44d348ed-41e4-45c3-8286-2d98b01eec9a/t2_figure2.png__3000x1625_q85_subject_location-1500%2C814_subsampling-2.png"&gt;



        &lt;span&gt;Figure 2. Few-shot learning methods can be divided into three families. The first family learns prior knowledge about the similarity and dissimilarity of classes (in the form of embeddings) from training tasks. The second family exploits prior knowledge about how to learn that it has garnered from training tasks. The third family exploits prior knowledge about the data and its likely variation that is has learned from training tasks.&lt;/span&gt;





 &lt;/p&gt;

&lt;h2&gt;Prior knowledge of similarity&lt;/h2&gt;

&lt;p&gt;This family of algorithms aims to learn compact representations (embeddings) in which the data vector is mostly unaffected by intra-class variations but retains information about class membership. Early work focused on pairwise comparators which aim to judge whether two data examples are from the same or different classes, even though the system may not have seen these classes before. Subsequent research focused on multi-class comparators which allow assignment of new examples to one of several classes.&lt;/p&gt;

&lt;h2&gt;&lt;small&gt;Pairwise comparators&lt;/small&gt;&lt;/h2&gt;

&lt;p&gt;Pairwise comparators take two examples and classify them as either belonging to the same or different classes. This differs from the standard N-way-K-shot configuration and does not obviously map onto the above description of meta-learning although as we will see later there is in fact a close relationship.&lt;/p&gt;

&lt;h4&gt;&lt;strong&gt;Siamese networks&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;&lt;a href="https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf"&gt;Koch&amp;nbsp;&lt;em&gt;et al.&lt;/em&gt; (2015)&lt;/a&gt; trained a model that outputs the probability $Pr(y_a=y_{b})$ that two data examples $\mathbf{x}_{a}$ and $\mathbf{x}_{b}$ belong to the same class (figure 3a). The two examples are passed through identical multi-layer neural networks (hence Siamese) to create two embeddings. The component-wise absolute distance between the embeddings is computed and passed to a subsequent comparison network that reduces this distance vector to a single number. This is passed though a sigmoidal output for classification as being the same or different with a cross-entropy loss.&lt;/p&gt;

&lt;p&gt;








&lt;img src="https://www.borealisai.com/media/filer_public_thumbnails/filer_public/76/e2/76e24938-4b43-4cde-9b12-4be2d067561b/t2_figure3.png__3000x1185_q85_subject_location-1500%2C593_subsampling-2.png"&gt;



        &lt;span&gt;Figure 3. Pairwise comparators. a) Siamese networks take two examples $\mathbf{x}_{a}$ and $\mathbf{x}_{b}$ and return the probability $Pr(y_{a}=y_{b})$ that they are the same class. They do this by passing each example through an identical network (hence Siamese) and then using the pairwise difference between the embeddings as the basis of the decision.&amp;nbsp;b) Triplet networks take two examples of the same class $\mathbf{x}_{a}$ and $\mathbf{x}_{+}$ and one of a different class $\mathbf{x}_{-}$ and pass all three through identical networks to create three embeddings. The triplet loss encourages the embeddings of examples from the same class to be closer together than those from different classes. c) In the test phase for triplet networks, we pass two examples $\mathbf{x}_{a}$ and $\mathbf{x}_{b}$ through the same network and judge whether they come from the same class or not based on the distance.&lt;/span&gt;





 &lt;/p&gt;

&lt;p&gt;During training, each pair of examples are randomly drawn from a super-set of training classes. Hence, the system learns to discriminate between classes is general, rather than two classes in particular. In testing, completely different classes are used. Although this does not have the formal structure of the N-way-K-shot task, the spirit is similar.&lt;/p&gt;

&lt;h4&gt;Triplet networks&lt;/h4&gt;

&lt;p&gt;Triplet networks (&lt;a href="https://arxiv.org/abs/1412.6622"&gt;Hoffer &amp;amp; Ailon 2015&lt;/a&gt;) consist of three identical networks that are trained by triplets $\{\mathbf{x}_{+},\mathbf{x}_{a},\mathbf{x}_{-}\}$ of the form (positive, anchor, negative). The positive and anchor samples are from the same class, whereas the negative sample is from a different class. The learning criterion is &lt;em&gt;triplet loss&lt;/em&gt;&amp;nbsp;which encourages the anchor to be closer to the positive example than it is to the negative example in the embedding space (figure 3b).&amp;nbsp;Hence it is based on two pairwise comparisons.&lt;/p&gt;

&lt;p&gt;After training, the system can take two examples and establish whether they are from the same or different classes, by thresholding the distance in the learned embedding space.&amp;nbsp;This was employed in the context of face verification by &lt;a href="https://arxiv.org/abs/1503.03832"&gt;Schroff &lt;em&gt;et al.&lt;/em&gt; (2015)&lt;/a&gt;. This line of work is part of a greater literature on learning distance metrics (see &lt;a href="https://arxiv.org/abs/1812.05944"&gt;Suarez &lt;em&gt;et al.&lt;/em&gt;&amp;nbsp;2018&lt;/a&gt; for overview).&lt;/p&gt;

&lt;h2&gt;&lt;small&gt;Multi-class comparators&lt;/small&gt;&lt;/h2&gt;

&lt;p&gt;Pairwise comparators can be adapted to the N-way-K-shot setting by assigning the class for an example in the query set based on its maximum similarity to one of the examples in the support set.&amp;nbsp;However, multi-class comparators attempt to do the same thing in a more principled way; here the representation and final classification are learned in an end-to-end fashion.&lt;/p&gt;

&lt;p&gt;In this section, we'll use the notation $\mathbf{x}_{nk}$ to denote the $k$th support example from the $n$th class in the N-Way-K-Shot classification task, and $y_{nk}$ to denote the corresponding label. For simplicity, we'll assume there is a single query example $\hat{\mathbf{x}}$ and the goal is to predict the associated label $\hat{y}$.&lt;/p&gt;

&lt;h4&gt;Matching Networks&lt;/h4&gt;

&lt;p&gt;Matching networks&amp;nbsp;(&lt;a href="https://arxiv.org/abs/1606.04080"&gt;Vinyals &lt;em&gt;et al.&lt;/em&gt;&amp;nbsp;2016&lt;/a&gt;) predict the one-hot encoded query-set label $\hat{\mathbf{y}}$ as a weighted sum of all of the one-hot encoded support-set labels $\{\mathbf{y}_{nk}\}_{n,k=1}^{NK}$. The weight is based on a computed similarity $a[\hat{\mathbf{x}},\mathbf{x}_{nk}]$ between the query-set data $\hat{\mathbf{x}}$ and each training example $\{\mathbf{x}_{nk}\}_{n,k=1}^{N,K}$.&lt;/p&gt;

&lt;p&gt;\begin{equation}&lt;br&gt;
&amp;nbsp; &amp;nbsp; \hat{\mathbf{y}} = \sum_{n=1}^{N}\sum_{k=1}^{K} a[\mathbf{x}_{nk},\hat{\mathbf{x}}]\mathbf{y}_{nk}&amp;nbsp;\tag{1.1}&lt;br&gt;
\end{equation}&lt;/p&gt;

&lt;p&gt;where the similarities have been constrained to be positive and sum to one.&amp;nbsp;&lt;/p&gt;

&lt;p&gt;To compute the similarity $a[\hat{\mathbf{x}},\mathbf{x}_{nk}]$, they pass each support example $\mathbf{x}_{nk}$ through a network $\mbox{ f}[\bullet]$ to produce an embedding and pass the query example $\hat{\mathbf{x}}$ through a different network $\mbox{ g}[\bullet]$ to produce a different embedding. They then compute the cosine similarity between these embeddings (figure 5a)&lt;/p&gt;

&lt;p&gt;\begin{equation}&lt;br&gt;
&amp;nbsp; &amp;nbsp; &amp;nbsp;d[\mathbf{x}_{nk}, \hat{\mathbf{x}}] = \frac{\mbox{ f}[\mathbf{x}_{nk}]^{T}\mbox{ g}[\hat{\mathbf{x}}]} {||\mbox{ f}[\mathbf{x}_{nk}]||\cdot||\mbox{ g}[\hat{\mathbf{x}}]||},&amp;nbsp;\tag{1.2}&lt;br&gt;
\end{equation}&lt;/p&gt;

&lt;p&gt;and normalise using a softmax function:&lt;/p&gt;

&lt;p&gt;\begin{equation}&lt;br&gt;
&amp;nbsp; &amp;nbsp; a[\hat{\mathbf{x}}_{nk},\mathbf{x}] = \frac{\exp[d[\mathbf{x}_{nk},\hat{\mathbf{x}}]]}{\sum_{n=1}^{N}\sum_{k=1}^{K}\exp[d[\mathbf{x}_{nk},\hat{\mathbf{x}}]]}.&amp;nbsp;\tag{1.3}&lt;br&gt;
\end{equation}&lt;/p&gt;

&lt;p&gt;to produce positive similarities that sum to one. This system can be trained end to end for the N-way-K-shot learning task.&lt;sup&gt;1&amp;nbsp;&lt;/sup&gt;At each learning iteration, the system is presented with a training task; the predicted labels are computed for the query set (the calculation is based on the support set) and the loss function is the cross entropy of the ground truth and predicted labels.&lt;/p&gt;

&lt;p&gt;Matching networks compute similarities between the embeddings of each support example and the query example. This has the disadvantage that the algorithm is not robust to data imbalance; if there are more support examples for some classes than others (i.e., we have departed from the N-way-K-shot scenario), the ones with more frequent training data may dominate.&lt;/p&gt;

&lt;h4&gt;Prototypical Networks&lt;/h4&gt;

&lt;p&gt;Prototypical networks&amp;nbsp;(&lt;a href="https://arxiv.org/abs/1703.05175"&gt;Snell et al.&amp;nbsp;2017&lt;/a&gt;) are robust to data imbalance by construction; they average the embeddings $\{\mathbf{z}_{nk}\}_{k=1}^{K}$ of the examples for class $n$ to compute their mean embedding or &lt;em&gt;prototype&lt;/em&gt;&amp;nbsp;$\mathbf{p}_{n}$. They then use the similarity between each prototype and the query embedding (figures 4 and 5 b) as a basis for classification.&lt;/p&gt;

&lt;p&gt;








&lt;img src="https://www.borealisai.com/media/filer_public_thumbnails/filer_public/97/02/970270e1-d976-49c1-ba8c-a9310c00d2c0/t2_figure4.png__3000x1215_q85_subject_location-1500%2C607_subsampling-2.png"&gt;



        &lt;span&gt;Figure 4. Prototypical networks. The support examples $\mathbf{x}_{nk}$ are all mapped to the embedding space to create embedding $\mathbf{z}_{nk}$ (coloured circles). All of the embeddings for class $k$ are averaged to create a prototype $\mathbf{p}_{n}$. To classify query examples $\hat{\mathbf{x}}$, we first compute its embedding $\hat{\mathbf{z}}$ and then base the decision on the relative distance to the prototypes.&lt;/span&gt;





 &lt;/p&gt;

&lt;p&gt;The similarity is computed as a negative multiple of the Euclidean distance (so that larger distances now give smaller numbers). They pass these similarities to a softmax function to give a probability over classes. This model effectively learns a metric space where the average of a few examples of a class is a good representation of that class and class membership can be assigned based on distance.&lt;/p&gt;

&lt;p&gt;They noted that (i) the choice of distance function is vital as squared Euclidean distance outperformed cosine distance, (ii) having a higher number of classes in the support set helps to achieve better performance, and that (iii) the system works best when the support size of each class is matched in the training and test tasks.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://arxiv.org/abs/1803.00676"&gt;Ren et al. (2018)&lt;/a&gt; extended this system to take advantage of additional unlabeled data which might be from the test task classes or from other distractor classes. &lt;a href="https://arxiv.org/abs/1805.10123"&gt;Oreshkin et al. (2018)&lt;/a&gt; extended this approach by learning a task-dependent metric on the feature space, so that the distance metric changes from place to place in the embedding space.&lt;/p&gt;

&lt;h4&gt;Relation Networks&lt;/h4&gt;

&lt;p&gt;Matching networks and prototypical networks both focus on learning the embedding and compare examples using a pre-defined metric (cosine and Euclidean distance, respectively).&amp;nbsp;Relation networks (&lt;a href="https://dl.acm.org/citation.cfm?id=3045585"&gt;Santoro et al.&amp;nbsp;2016&lt;/a&gt;) also learn a metric for comparison of the embeddings (figure 5c). Similarly to prototypical networks, the relation network averages the embeddings of each class in the support set together to form a single prototype. Each prototype is then concatenated with the query embedding and passed to a &lt;em&gt;relation module&lt;/em&gt;. This is a learnable non-linear operator that produces a similarity score between 0 and 1 where 1&amp;nbsp;indicates that the query example belongs to this class prototype. This approach is clean and elegant and can be trained end-to-end.&lt;/p&gt;

&lt;h2&gt;&lt;small&gt;Comparison between models&lt;/small&gt;&lt;/h2&gt;

&lt;p&gt;All of the pairwise and multi-class comparators are closely related to one another. Each learns an embedding space for data examples. In matching networks, there are different embeddings for support and query examples, but in the other models, they are the same. For prototypical networks and relation networks, multiple embeddings from the same class are averaged to form prototypes. Distances between support set embeddings/prototypes and query set embeddings are computed using either pre-determined distance functions such as Euclidean or cosine distance (triplet networks, matching networks, prototypical networks) or by learning a distance metric (Siamese networks and relation networks).&lt;/p&gt;

&lt;p&gt;








&lt;img src="https://www.borealisai.com/media/filer_public_thumbnails/filer_public/d6/16/d616cbd2-189e-4d7a-b724-290ee8d9b821/t2_figure5.png__3000x1438_q85_subject_location-1500%2C721_subsampling-2.png"&gt;



        &lt;span&gt;Figure 5. Multi-class comparators. a) Matching networks compute separate embeddings for support examples (here $\mathbf{x}_{11},\mathbf{x}_{12},\mathbf{x}_{21},\mathbf{x}_{22}$) and the query example $\hat{\mathbf{x}}$. Here $\mathbf{x}_{nk}$ is the $k$th example from the $n$th class. They compute the cosine similarity between each support embedding and the the query embedding, and then use these similarities to choose the class. This has the disadvantage that if there are many more examples of one class than the others, the relatively abundant class may be chosen too frequently.&amp;nbsp;b) Prototypical networks embed the query and support examples using the same network, but average together support embeddings to make prototypes for each class, and so it doesn't matter if the numbers are unbalanced. The Euclidean distance between query embeddings and prototypes is used to support classification. c) Relation networks replace this Euclidean distance with a learned non-linear distance metric.&lt;/span&gt;





 &lt;/p&gt;

&lt;p&gt;The multi-class networks have the advantage that they can be trained end-to-end for the N-way-K-shot classification task. This is not true for the pairwise comparators which are trained to produce a similarity or distance between pairs of data examples (which could itself subsequently be used to support multi-class classification).&lt;/p&gt;

&lt;p&gt;Although it is not obvious how the pairwise comparators map to the meta-learning framework, it is possible to consider their data as consisting of minimal training and test tasks. For Siamese networks, each pair of examples is a training task, consisting of one support example and one query example, where their classes may not necessarily match. For triplet networks, there are two support examples (from different classes) and one query example (from one of the classes).&lt;/p&gt;

&lt;h2&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;In part I of this tutorial we have described the few-shot and meta-learning problems and introduced a taxonomy of methods. We have also discussed methods that use a series of training tasks to learn prior knowledge about the similarity and dissimilarity of classes that can be exploited for future few-shot tasks.&amp;nbsp;This knowledge takes the form of data embeddings that reduce within-class variance relative to between-class variance, and hence make it easier to learn from just a few data points.&lt;/p&gt;

&lt;p&gt;In &lt;a href="https://www.borealisai.com/en/blog/tutorial-3-few-shot-learning-and-meta-learning-ii/"&gt;part II&lt;/a&gt; of this tutorial, we'll discuss methods that incorporate prior knowledge about how to learn models, and that incorporate prior knowledge about the data itself.&lt;/p&gt;

&lt;p&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;cite&gt;&lt;a href="https://arxiv.org/abs/1606.04080"&gt;Vinyals et al. (2016)&lt;/a&gt;. also introduced a novel &lt;em&gt;context embedding&lt;/em&gt;&amp;nbsp;method which took the full context of the support set $\mathcal{S}$ into account so that $\mbox{ g}[\bullet] = \mbox{ g}[\mathbf{x}, \mathcal{S}]$. Here, the support set was considered as a sequence and encoded by a bi-directional LSTM. &lt;a href="https://arxiv.org/abs/1703.05175"&gt;Snell et al. (2017)&lt;/a&gt; later argued that this context embedding was problematic and redundant.&lt;/cite&gt;&lt;/p&gt;
          &lt;/div&gt;&lt;/div&gt;&lt;a href="https://www.borealisai.com/en/blog/tutorial-2-few-shot-learning-and-meta-learning-i/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sat, 18 Jul 2020 15:47:40 UT
      </pubDate>
      <guid>
        https://www.borealisai.com/en/blog/tutorial-2-few-shot-learning-and-meta-learning-i/
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://cs.stanford.edu/~pliang/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;
  &lt;p&gt;
  My goal is to develop trustworthy systems that can communicate effectively
  with people and improve over time through interaction.
  I broadly identify with the
  machine learning (ICML, NeurIPS) and
  natural language processing (ACL, NAACL, EMNLP) communities.
  &lt;/p&gt;

  &lt;p&gt;
  Computers can do a lot, but tapping into their full power requires the rather non-trivial ability to program.
  I'm interested in building systems that learn to translate natural language descriptions (e.g., in English or Chinese) into programs (e.g., in Python or C++).
  Such systems would unlock the full power of computing to a much wider audience.
  A while back, I wrote a friendly introduction to natural language interfaces (&lt;a href="https://cs.stanford.edu/~pliang/papers/talking-xrds2014.pdf"&gt;XRDS magazine 2014&lt;/a&gt;)
  and a slightly more technical survey article on executable semantic parsing (&lt;a href="https://cs.stanford.edu/~pliang/papers/executable-cacm2016.pdf"&gt;CACM 2016&lt;/a&gt;).
  One idea we've explored is to "naturalize" a programming language gradually into a natural language (&lt;a href="https://arxiv.org/pdf/1704.06956.pdf"&gt;ACL 2017&lt;/a&gt;).
  One can also use natural language to describe classifiers directly rather than requiring labeled data (&lt;a href="https://arxiv.org/pdf/1805.03818.pdf"&gt;ACL 2018&lt;/a&gt;).
  The tension between the fuzziness of machine learning and the crispness of logic also fascinates me.
  On this note, we showed that neural networks can solve SAT problems with
  surprising accuracy despite not being told explicitly what a SAT problem is
  (&lt;a href="https://arxiv.org/pdf/1802.03685.pdf"&gt;ICLR 2019&lt;/a&gt;).
  &lt;/p&gt;

  &lt;p&gt;
  Despite the successes of machine learning,
  otherwise high-performing models are still difficult to debug and fail catastrophically in the presence
  of changing data distributions and adversaries.
  For example, on the &lt;a href="http://stanford-qa.com/"&gt;SQuAD&lt;/a&gt; reading comprehension dataset we created (&lt;a href="https://arxiv.org/pdf/1606.05250.pdf"&gt;EMNLP 2016&lt;/a&gt;),
  we showed that state-of-the-art systems,
  despite reaching human-level benchmark performance,
  are easily fooled by distracting sentences in a way that no human would be (&lt;a href="http://arxiv.org/pdf/1707.07328.pdf"&gt;EMNLP 2017&lt;/a&gt;).
  Given society's increasing reliance on machine learning,
  it is critical to build tools to make machine learning more reliable in the wild.
  We've worked on using influence functions to understand black-box models (&lt;a href="http://arxiv.org/pdf/1703.04730.pdf"&gt;ICML 2017&lt;/a&gt;),
  semidefinite programming to provide certificates a neural network is safe from a class of adversaries (&lt;a href="https://arxiv.org/pdf/1811.01057.pdf"&gt;NeurIPS 2018&lt;/a&gt;),
  and distributionally robust optimization to ensure the fairness of machine learning models over time (&lt;a href="https://arxiv.org/pdf/1806.08010.pdf"&gt;ICML 2018&lt;/a&gt;).
  &lt;/p&gt;

  &lt;p&gt;
  Finally, I am a strong proponent of efficient and reproducible research.
  We have been developing &lt;b&gt;&lt;a href="https://worksheets.codalab.org/"&gt;CodaLab Worksheets&lt;/a&gt;&lt;/b&gt;,
  a platform that allows researchers to run and manage their experiments by maintaining the full provenance
  of an experiment from raw data to final results.
  Most of our recent papers have been published on CodaLab as &lt;a href="https://worksheets.codalab.org/worksheets/0x9b6bb6fdd4aa4bf1b120300fd95f944a"&gt;executable
  papers&lt;/a&gt;.
  We are actively looking for contributors,
  so please contact me if you're interested!
  &lt;/p&gt;

  &lt;p&gt;Here is some &lt;a href="https://cs.stanford.edu/~pliang/software"&gt;code for older projects&lt;/a&gt;.&lt;/p&gt;

&lt;/div&gt;&lt;/div&gt;&lt;a href="https://cs.stanford.edu/~pliang/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sun, 29 Nov 2020 11:11:44 UT
      </pubDate>
      <guid>
        https://cs.stanford.edu/~pliang/
      </guid>
    </item>
    <item>
      <title>
        He He - NYU
      </title>
      <link>
        https://hhexiy.github.io/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;
        &lt;div&gt;
            &lt;p&gt;&lt;img height="250px" src="https://hhexiy.github.io/figures/me2016-lo.jpg"&gt;
            &lt;/p&gt;
            &lt;div&gt;
                &lt;div&gt;
					&lt;ul&gt;
					  &lt;li&gt;&lt;h2&gt;He He&lt;/h2&gt;&lt;/li&gt;
					  &lt;li&gt;&lt;img height="40" src="https://hhexiy.github.io/figures/name.png"&gt;&lt;/li&gt;
					  &lt;li&gt;&lt;small&gt;(&lt;a&gt;How to pronounce?&lt;/a&gt;)&lt;/small&gt;&lt;/li&gt;
                      
                       
					&lt;/ul&gt;
                &lt;/div&gt;
                &lt;div&gt;
					&lt;ul&gt;
                        &lt;li&gt;Assistant Professor of
                            &lt;a href="https://cs.nyu.edu/home/index.html"&gt;Computer Science&lt;/a&gt; and
                            &lt;a href="https://cds.nyu.edu/"&gt;Data Science&lt;/a&gt;
                        &lt;/li&gt;
                        &lt;li&gt;&lt;a href="https://wp.nyu.edu/cilvr/"&gt;CILVR&lt;/a&gt; / &lt;a href="https://wp.nyu.edu/ml2/"&gt;ML&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;
                        &lt;/li&gt;
                    &lt;/ul&gt;
                &lt;/div&gt;
                &lt;div&gt;
                    &lt;ul&gt;
                        &lt;li&gt;60 Fifth Ave 605&lt;/li&gt;
                        &lt;li&gt;hehe@cs.nyu.edu&lt;/li&gt;
                    &lt;/ul&gt;
                &lt;/div&gt;
                &lt;div&gt;
                    &lt;ul&gt;
                        &lt;li&gt;
                            [&lt;a href="https://hhexiy.github.io/docs/cv/cv.pdf"&gt;CV&lt;/a&gt;]
                            [&lt;a href="https://scholar.google.com/citations?hl=en&amp;amp;user=K-isjagAAAAJ&amp;amp;view_op=list_works&amp;amp;sortby=pubdate"&gt;&lt;span size="3"&gt;Google Scholar&lt;/span&gt;&lt;/a&gt;]
                        &lt;/li&gt;
                    &lt;/ul&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;p&gt;
            My goal is to enable reliable communication in natural langauge between machines and humans. 
            Recent research directions include:
            (1) &lt;strong&gt;Text generation&lt;/strong&gt;: 
            How do we ensure that the generated text are not just coheret, but also &lt;a href="https://arxiv.org/abs/2005.03754"&gt;factually correct&lt;/a&gt;? 
            Beyond factuality, how do we generate &lt;a href="https://arxiv.org/abs/1804.06437"&gt;novel&lt;/a&gt;, &lt;a href="https://arxiv.org/abs/1904.06828"&gt;creative&lt;/a&gt; text in a controllable way? 
            (2) &lt;strong&gt;Robust language understanding&lt;/strong&gt;:
            Statistical machine learning systems suffer from spurious correlations in the data,
            resulting in biased prediction and catastrophic errors.
            How can we &lt;a href="https://arxiv.org/abs/1908.10763"&gt;learn&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2007.06778"&gt;models&lt;/a&gt; that are robust to dataset biases?
            (3) &lt;strong&gt;Dialogue systems&lt;/strong&gt;:
            Building an effective dialogue agent requires understanding in a broad sense, e.g.,
            how to &lt;a href="https://arxiv.org/abs/1704.07130"&gt;reason&lt;/a&gt; about structured knowledge and learn efficient &lt;a href="https://arxiv.org/abs/1808.09637"&gt;strategies&lt;/a&gt; for a specific task?
            &lt;/p&gt;

        &lt;p&gt;
            &lt;strong&gt;Prospective students:&lt;/strong&gt;
            If you are interested in working with me, please apply to either the
            &lt;a href="https://cs.nyu.edu/home/phd/admission.html"&gt;PhD program in Computer Science&lt;/a&gt; or
            &lt;a href="https://cds.nyu.edu/academics/phd-in-data-science/"&gt;PhD program in Data Science&lt;/a&gt;
            and mention my name in your application.
            If you are a student at NYU, please drop me an email. 
            &lt;/p&gt;

        &lt;hr&gt;

        &lt;p&gt;
            &lt;h4&gt;PhD students&lt;/h4&gt;
        &lt;/p&gt;
        &lt;div&gt;
            &lt;ul&gt;
                &lt;li&gt;
                    &lt;a href="https://joshinh.github.io/"&gt;Nitish Joshi&lt;/a&gt;
                &lt;/li&gt;
                &lt;li&gt;
                    &lt;a href="https://vishakhpk.github.io/"&gt;Vishakh Padmakumar&lt;/a&gt;
                &lt;/li&gt;
                &lt;li&gt;
                    &lt;a href="https://yzpang.github.io/"&gt;Richard Pang&lt;/a&gt; (co-advised with Kyunghyun Cho)
                &lt;/li&gt;
            &lt;/ul&gt;
        &lt;/div&gt;

        &lt;p&gt;
            &lt;h4&gt;Visitors and MS students&lt;/h4&gt;
        &lt;/p&gt;
        &lt;div&gt;
            &lt;ul&gt;
                &lt;li&gt;
                    &lt;a href="https://uditarora.com/"&gt;Udit Arora&lt;/a&gt;
                &lt;/li&gt;
                &lt;li&gt;
                    Aniket Bhatnagar 
                &lt;/li&gt;
                &lt;li&gt;
                    &lt;a href="http://johnnyma.info/"&gt;Johnny Ma&lt;/a&gt;
                &lt;/li&gt;
                &lt;li&gt;
                    Zhiliang Tian
                &lt;/li&gt;
                &lt;li&gt;
                    Saranya Venkatraman
                &lt;/li&gt;
            &lt;/ul&gt;
        &lt;/div&gt;

        &lt;p&gt;
            &lt;h4&gt;Teaching&lt;/h4&gt;
        &lt;/p&gt;
        &lt;div&gt;
            &lt;ul&gt;
                &lt;li&gt;
                    &lt;a href="https://hhexiy.github.io/nlp/index.html"&gt;CSCI-GA.2590 Natural Language Processing&lt;/a&gt;
                    [&lt;a href="https://cs.nyu.edu/courses/fall20/CSCI-GA.2590-001/"&gt;fall20&lt;/a&gt;]
                &lt;/li&gt;
                &lt;li&gt;
                    &lt;a href="https://nyu-ds1003.github.io/spring2021/#home"&gt;DS-GA.1003 Machine Learning&lt;/a&gt;
                    [spring19]
                    [&lt;a href="https://nyu-ds1003.github.io/spring2021/#home"&gt;spring20&lt;/a&gt;]
                &lt;/li&gt;
            &lt;/ul&gt;
        &lt;/div&gt;

        &lt;p&gt;
            &lt;h4&gt;Publications&lt;/h4&gt;
        &lt;/p&gt;
        
    &lt;/div&gt;&lt;/div&gt;&lt;a href="https://hhexiy.github.io/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sun, 29 Nov 2020 11:11:50 UT
      </pubDate>
      <guid>
        https://hhexiy.github.io/
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://users.umiacs.umd.edu/~resnik/writing_advice.html
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;My former grad student Chris Dyer wrote to me recently to ask if I could remind him of some of the useful editorial advice I'd given him while he was writing his dissertation. Made me feel all warm and fuzzy to think it was valuable enough that he wants to pass it on to his own students.

A lot of my process for helping students improve their writing happens in the moment, very much on a case by case basis.  But here are a few principles that I think are worth noting.

&lt;h2&gt;Strong writing&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt; &lt;strong&gt;Feeling/thinking verbs.&lt;/strong&gt;  Avoid "we think", "we believe", etc.  If you're putting it in your paper, it's because you believe it or think it's true, and these do nothing but weaken or hedge.
&lt;/li&gt;&lt;li&gt; &lt;strong&gt;"Present" verbs.&lt;/strong&gt;  If I &lt;em&gt;present&lt;/em&gt; an algorithm to you, am I presenting someone else's work that existed before, or my own novel contribution?  Avoid wording that is ambiguous and aim for strong verbs that emphasize your particular contribution.  
&lt;/li&gt;&lt;li&gt; &lt;strong&gt;Using strong verbs.&lt;/strong&gt;  For algorithms, models, etc., it's must stronger to &lt;em&gt;introduce&lt;/em&gt; something new than simply to &lt;em&gt;propose&lt;/em&gt; it, although &lt;em&gt;propose&lt;/em&gt; is good early in the paper for a hypothesis that you then &lt;em&gt;support&lt;/em&gt; with results, allowing you to claim that you have &lt;em&gt;validated&lt;/em&gt;, &lt;em&gt;verified&lt;/em&gt;, or &lt;em&gt;demonstrated&lt;/em&gt;. In general for results, it's strong to &lt;em&gt;demonstrate&lt;/em&gt; and &lt;em&gt;show&lt;/em&gt;, although there are also appropriate places for, say, having &lt;em&gt;found&lt;/em&gt; something to be true or, in the context of something more exploratory or inductive, having &lt;em&gt;seen&lt;/em&gt; some behavior or pattern.   Unless it's an actual proof, avoid &lt;em&gt;prove&lt;/em&gt;, and unless you're Columbus, avoid transitive &lt;em&gt;discover&lt;/em&gt; &lt;em&gt;NP&lt;/em&gt;, although with a sentential complement &lt;em&gt;discovered that [clause]&lt;/em&gt; is similar to &lt;em&gt;having seen&lt;/em&gt;.
&lt;/li&gt;&lt;li&gt; &lt;strong&gt;Passive voice.&lt;/strong&gt;  There is nothing the least bit wrong with passive voice when it is used appropriately.  (For example, there is no reason whatsoever for me to modify the previous sentence to say "when one uses it appropriately".)   For chapter and verse on this, see Pullum, &lt;a href="http://www.lel.ed.ac.uk/grammar/passives.html"&gt;"Confusion over avoiding the passive"&lt;/a&gt;, http://www.lel.ed.ac.uk/grammar/passives.html; it's a must-read.
&lt;/li&gt;&lt;li&gt; &lt;strong&gt;Academic "we".&lt;/strong&gt;  This is somewhere between a matter of taste and a religious issue, so your mileage may vary.  However, if you're doing a practice presentation or defense (or sometimes even the real thing) and a certain colleague of mine is in the audience, and you use "we", you can expect a question about which pieces of the contribution are yours and which should be attributed to your advisor.  Personally, I prefer "I" for dissertations and in single-authored papers I tend to avoid the issue when possible by using alternative phrasing, e.g. passive ("a corpus of 200M words was obtained by..."), non-animate subjects ("The results of Experiment 1 demonstrate..."), nominalizations ("After sentence-breaking and tokenization..."), etc.  That said, I do think it's fine to use an inclusive "we" to provide an informal tone that brings together author and audience, e.g. "When we take a look at the output of Algorithm 1, ...".  (Notice that if past tense &lt;em&gt;took&lt;/em&gt; had been used instead of present tense &lt;em&gt;take&lt;/em&gt;, this would have been an academic rather than inclusive "we".)
&lt;/li&gt;&lt;li&gt; &lt;strong&gt;The "story" in a paper should be organized logically, not chronologically.&lt;/strong&gt;  Nobody needs to know that you actually executed Experiment 1 a month after Experiment 3.  The logic of the argument in the paper should dictate the structure.  There are exceptions, e.g. perhaps analysis of Experiment 2 led to some new or expanded ideas that were then tested in Experiment 3, but notice that in this case the logical progression and the chronological progression coincide.
&lt;/li&gt;&lt;li&gt; &lt;strong&gt;Nobody cares about debugging or implementation.&lt;/strong&gt;  Implementation details belong in documentation or, if they're really salient for the paper, in an appendix.  Unless the paper is about data structures, programming language choice, etc., go with &lt;a href="http://en.wikipedia.org/wiki/David_Marr_(neuroscientist)#Levels_of_analysis"&gt;Marr&lt;/a&gt;'s computational or algorithmic levels in your description, not the physical/implementation level.
&lt;/li&gt;&lt;li&gt; &lt;strong&gt;Be generous in your citations.&lt;/strong&gt;  People who have done related work might well be your reviewers.  Plus it's the right thing to do.  'Nuff said.
&lt;/li&gt;&lt;li&gt; &lt;strong&gt;Eschew obfuscation.&lt;/strong&gt;  Yes, you can save a whole lot of space by condensing a ton in between \begin{algorithm} and \end{algorithm}.  But not everyone (read: not every reviewer) enjoys having to work through the line-by-line details of an algorithm.  Make sure the text has plenty of plain language and be generous with your prose explanation of what's going on.  And try to avoid any Greek letters that people might not know how to pronounce.
&lt;/li&gt;&lt;li&gt; &lt;strong&gt;Be explicit about having separated training and test data.&lt;/strong&gt;  This is a pet peeve of mine.  Yes, everyone is supposed to remember this.  But make sure your description makes it clear that you did.
&lt;/li&gt;&lt;li&gt; &lt;strong&gt;Explain why you chose the parameters you chose.&lt;/strong&gt;  You used 50 topics for LDA?  Why not 20 or 100?  Oh, and if the answer is not that you either decided a priori or tuned on held-out data, but rather that it gave you the best results on your test data, you'd better see the previous point: you are reporting a tainted experiment.  You can un-taint it somewhat by reporting the results for the other values you tried also -- but then you should be prepared for a reviewer to ask why we should believe 50 will be the best value on the next, previously unseen dataset.  (Better yet, do the next experiment fixing 50 in advance and show that the choice generalized to another case.)  If all else fails, appeal to previous literature and choose parameter values that can be described as typical in prior work.
&lt;/li&gt;&lt;/ul&gt;

At this point I realized I was veering into "grumpy old man" territory and decided to stop...



&lt;/div&gt;&lt;a href="https://users.umiacs.umd.edu/~resnik/writing_advice.html"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sun, 29 Nov 2020 11:11:54 UT
      </pubDate>
      <guid>
        https://users.umiacs.umd.edu/~resnik/writing_advice.html
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://ideolalia.com/2018/08/28/artifex.html
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;
		&lt;article&gt;
			&lt;p&gt;&lt;img alt="" src="https://ideolalia.com/images/artifex-set-operations.png"&gt;&lt;/p&gt;

&lt;h3 id="how-i-spent-my-summer"&gt;how I spent my summer&lt;/h3&gt;

&lt;p&gt;A few months ago, I decided to implement set operations on curved regions.  I had the &lt;a href="https://www.springer.com/us/book/9783540779735"&gt;the canonical textbook on computational geometry&lt;/a&gt;, which described approaches for polygons comprised of straight lines, and it seemed like &lt;a href="http://paperjs.org/"&gt;other projects&lt;/a&gt; had extended these techniques to &lt;a href="https://en.wikipedia.org/wiki/B%C3%A9zier_curve"&gt;parametric curves&lt;/a&gt;.  I figured it would take a couple of weeks.&lt;/p&gt;

&lt;p&gt;Unfortunately, the field of computational geometry embodies a fundamental contradiction.  In geometry, the angles of a triangle add up to exactly π radians, and if &lt;em&gt;u&lt;/em&gt; is clockwise from &lt;em&gt;v&lt;/em&gt; then &lt;em&gt;v&lt;/em&gt; must be counter-clockwise from &lt;em&gt;u&lt;/em&gt;.  Computers, on the other hand, use floating point representations which make a mockery of these simple Euclidean truths.&lt;/p&gt;

&lt;p&gt;The academic literature largely ignores this.  Algorithms are proven to be geometrically sound, and robust implementations are left as an exercise for the reader.  This is akin to a world in which hash collisions caused unavoidable data loss, and the academic response was to implicitly assume the existence of a perfect hash function.  If a paper is predicated on unrealistic assumptions, we cannot evaluate it on its own terms; we must understand, empirically, how well it functions when these assumptions are broken.&lt;/p&gt;

&lt;p&gt;With this in mind, we can now look at the existing algorithms for &lt;a href="https://en.wikipedia.org/wiki/Clipping_(computer_graphics)"&gt;polygon clipping&lt;/a&gt;, which is the term of art for polygon set operations.  Every technique is a variation on a common theme:&lt;/p&gt;

&lt;p&gt;&lt;img alt="" src="https://ideolalia.com/images/artifex-clipping.png"&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Given two or more rings, find every point of intersection&lt;/li&gt;
  &lt;li&gt;Segment the rings at the points of intersection&lt;/li&gt;
  &lt;li&gt;Decide whether each segment should be included, based on the operation being performed&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The dozen or so papers on this subject differ only in the third step.  Since our decision to include a segment typically inverts at an intersection point, they describe a variety of approaches for using our decision to about one segment to inform our decision about adjacent segments.&lt;/p&gt;

&lt;p&gt;My textbook described a method using &lt;a href="https://en.wikipedia.org/wiki/Doubly_connected_edge_list"&gt;doubly-connected edge lists&lt;/a&gt;, which is a generic geometric data structure.  I assumed that meant it could be reused for other problems, so I started my implementation.&lt;/p&gt;

&lt;p&gt;A month went by.&lt;/p&gt;

&lt;p&gt;I had finished the implementation my first week, but it wasn’t reliable.  A DCEL is a collection of linked loops, which can be incrementally updated.  When performing a set operation, we incrementally bisect the original set of loops, and then determine which should and shouldn’t be included.  Despite my best efforts, I kept finding new shapes that caused adjacent faces to get tangled together, creating a Möbius strip that is simultaneously inside and outside the expected result.&lt;/p&gt;

&lt;p&gt;Slowly, I realized the problem wasn’t the data structure, it was the first step that every paper glossed over: finding all the intersections.  The DCEL assumes the edges at a vertex have a total ordering: the previous edge is directly clockwise, and the next one is directly counter-clockwise.  If we miss an intersection, we might conclude two curves are both clockwise relative to the other, causing everything to fall apart.&lt;/p&gt;

&lt;p&gt;I began to look for better ways to find intersections, hoping that if I found an approach that was sufficiently accurate, my work on the DCEL could be salvaged.  Unfortunately, the approaches I found in the literature and implemented in the wild were no better than what I had been using.  My data structure demanded precise inputs, without internal contradictions, and I couldn’t deliver.&lt;/p&gt;

&lt;p&gt;At that point, I began to wonder if I had missed something fundamental.  I thought maybe if I dissected how other, more mature, libraries handled my pathological shapes, I could work backwards to see where I had gone wrong.  But when I began to feed these shapes into well-established projects like paper.js, I found they failed just as badly.&lt;/p&gt;

&lt;p&gt;To find my pathological inputs, I had been using property-based testing.  Given a random combination of shapes, I would perform a point-in-region test and compare it to a reference result, generated by querying each shape individually and combining the results according to the operation.  Most inputs worked fine, but after a few hundred thousand inputs it would inevitably find some failure.&lt;/p&gt;

&lt;p&gt;Other projects, it turned out, had been a little less eager to find their own failure modes.  Some only had a handful of example-based tests, others had a static suite of a few thousand inputs they used to validate their changes.  If I had missed something, it appeared to be that no one else expected these operations to be particularly robust.&lt;/p&gt;

&lt;hr&gt;

&lt;h3 id="why-is-this-so-hard"&gt;why is this so hard?&lt;/h3&gt;

&lt;p&gt;Floating point arithmetic is best understood through a simple, maddening fact: &lt;code&gt;a + (b - a)&lt;/code&gt; does not necessarily equal &lt;code&gt;b&lt;/code&gt;.  It might be equal, or it might be off by just a little, where “little” is relative to the larger of the two numbers.  This means that when we compare two floating point numbers, we cannot do a precise comparison, we have to ask whether they differ by less than some &lt;em&gt;epsilon&lt;/em&gt; value.&lt;/p&gt;

&lt;p&gt;This epsilon represents the level of numerical uncertainty to which we’ve resigned ourselves.  There is vast folk wisdom around how to minimize this uncertainty, but the fact remains that every arithmetic operation injects a bit of uncertainty, and it grows cumulatively with each successive operation.  When dealing with small numbers, this uncertainty may dwarf the values themselves.&lt;/p&gt;

&lt;p&gt;An intersection, in a precise mathematical sense, occurs wherever the distance between the curves is exactly zero:&lt;/p&gt;

&lt;p&gt;&lt;img alt="" src="https://ideolalia.com/images/artifex-precise-intersection.png"&gt;&lt;/p&gt;

&lt;p&gt;But in a practical sense, it is wherever the distance between the curves is close enough to zero:&lt;/p&gt;

&lt;p&gt;&lt;img alt="" src="https://ideolalia.com/images/artifex-fuzzy-intersection.png"&gt;&lt;/p&gt;

&lt;p&gt;This has at least one intersection, but we could just as easily return three or ten within that overlapping range.  This uncertainty is anathema to the published techniques, which rely on counting these intersections to determine whether we’re inside or outside the other shape.  A single spurious intersection may cause the entire result to vanish.  If two objects with similar curvature move across each other, the result will tend to flicker in and out of existence.&lt;/p&gt;

&lt;p&gt;These techniques may suffice for straight lines, which require smaller epsilons, but they are wholly unsuited to the relative imprecision of parametric curves.&lt;/p&gt;

&lt;hr&gt;

&lt;h3 id="embracing-the-uncertainty"&gt;embracing the uncertainty&lt;/h3&gt;

&lt;p&gt;As the weeks passed, the errors uncovered by my tests went from feeling random to feeling malicious.  Floating point arithmetic may be deterministic, but as I watched my screen, waiting for the tests to fail, I imagined a demon in the FPU nudging the values as they flowed past, trying to move them beyond the threshold of self-consistency.&lt;/p&gt;

&lt;p&gt;One day, I realized this was exactly the narrative behind &lt;a href="https://en.wikipedia.org/wiki/Error_detection_and_correction"&gt;error-correcting codes&lt;/a&gt;; we assume our data has been randomly altered en route, and we want to return it to a consistent state.  It didn’t seem like I could get it right the first time, so why not just fix it afterwards?&lt;/p&gt;

&lt;p&gt;Consider the union of two ellipses:&lt;/p&gt;

&lt;p&gt;&lt;img alt="" src="https://ideolalia.com/images/artifex-two-ellipses.png"&gt;&lt;/p&gt;

&lt;p&gt;Ostensibly, there should only be three points of intersection, one on the left and two on the right.  But for the reasons described above, any intersection routine will likely find multiple points of intersection on the left as the curves converge on each other:&lt;/p&gt;

&lt;p&gt;&lt;img alt="" src="https://ideolalia.com/images/artifex-ellipses-intersections.png"&gt;&lt;/p&gt;

&lt;p&gt;The segments on the left are small enough, and thus imprecise enough, that our spatial intuition for the problem will just mislead us.  For this reason, it’s better to think of it as a graph:&lt;/p&gt;

&lt;p&gt;&lt;img alt="" src="https://ideolalia.com/images/artifex-ellipses-graph.png"&gt;&lt;/p&gt;

&lt;p&gt;Now we have to decide which edges to include, and which to exclude.  Since we’re trying to find the union, we want to keep any segments that are outside the other shape:&lt;/p&gt;

&lt;p&gt;&lt;img alt="" src="https://ideolalia.com/images/artifex-ellipses-valid-result.png"&gt;&lt;/p&gt;

&lt;p&gt;This is a well-formed result; there is a single cycle, and once we remove that cycle there are no leftover edges.  But we can’t rely on getting this lucky; the edges on the left might have succumbed to floating point error and believed they were both inside the other:&lt;/p&gt;

&lt;p&gt;&lt;img alt="" src="https://ideolalia.com/images/artifex-ellipses-incomplete.png"&gt;&lt;/p&gt;

&lt;p&gt;This is not a well-formed result; there are no cycles, and a bunch of leftover edges.  To make this consistent, we need to either close the loop, or remove the leftovers.  The cost of these changes is measured by the aggregate length of the edges we are adding or removing.&lt;/p&gt;

&lt;p&gt;The minimal set of changes is equivalent to the shortest path between the dangling vertices.  Having found the path, we then invert the inclusion of every edge it passes through.  In this case, it passes through one of the edges we originally excluded, so we add that edge back in, and return the cycle we just created.&lt;/p&gt;

&lt;p&gt;Alternately, both edges might think they are outside the other:&lt;/p&gt;

&lt;p&gt;&lt;img alt="" src="https://ideolalia.com/images/artifex-ellipses-redundant.png"&gt;&lt;/p&gt;

&lt;p&gt;In this case, we have a complete cycle, but once we’ve extracted it there’s a single leftover edge:&lt;/p&gt;

&lt;p&gt;&lt;img alt="" src="https://ideolalia.com/images/artifex-ellipses-leftover.png"&gt;&lt;/p&gt;

&lt;p&gt;Here again, we search through all the remaining edges for the shortest path between the two dangling vertices.  Since it passes through our leftover edge, we remove it.&lt;/p&gt;

&lt;p&gt;Every floating point inconsistency will surface as one of these two cases, or some combination thereof.  By searching for the shortest path between the dangling edges, we find the smallest possible edit that will yield a consistent result.  Of course, a consistent result is not necessarily the &lt;em&gt;correct&lt;/em&gt; one, but the fact that floating point errors tend to cluster around the smallest edges makes this a reasonable heuristic.  More importantly, it has weathered tens of millions of generative test cases without any issues.&lt;/p&gt;

&lt;p&gt;A complete implementation of this algorithm can be found &lt;a href="https://github.com/lacuna/artifex/blob/master/src/io/lacuna/artifex/utils/regions/Clip.java"&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;I’m not sure if this is a novel approach, but at the very least it represents a meaningful improvement on the state of the art in open source.  Intuitively, it feels like this might be a means to avoid epsilon hell in a wide range of geometric and numerical algorithms.  If anyone is aware of prior art in this vein, I’d be very interested to see it.&lt;/p&gt;

&lt;p&gt;My work on the &lt;a href="https://github.com/lacuna/artifex"&gt;Artifex&lt;/a&gt; library is ongoing, but I hope it proves useful to others, and look forward to sharing my own projects that it will enable in the near future.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;em&gt;Thanks to Alex Engelberg, Elana Hashman, Angus Fletcher, Reid McKenzie, and Zack Maril for feedback on early drafts of this post.&lt;/em&gt;&lt;/p&gt;

		&lt;/article&gt;
	&lt;/div&gt;&lt;/div&gt;&lt;a href="https://ideolalia.com/2018/08/28/artifex.html"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sun, 6 Dec 2020 18:48:40 UT
      </pubDate>
      <guid>
        https://ideolalia.com/2018/08/28/artifex.html
      </guid>
    </item>
    <item>
      <title>
        Amazon.com : Anthony Thomas, Award Winning Peanut Butter &amp;amp; Milk Chocolate Buckeyes in Ohio State Buckeyes Box, Deliciously Delightful Snacks (24 Count) : Grocery &amp;amp; Gourmet Food
      </title>
      <link>
        https://www.amazon.com/Anthony-Thomas-Chocolate-Deliciously-Delightful/dp/B076B15VRJ/ref=sr_1_2?crid=1V9DVYCKTSDNI&amp;dchild=1&amp;keywords=ohio+state+buckeyes+chocolate&amp;qid=1607894720&amp;sprefix=ohio+state+buckeyes+choc%2Caps%2C176&amp;sr=8-2
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;&lt;p&gt;&lt;span data-hook="cr-widget-MedleyCustomerImages"&gt;
      &lt;div data-hook="customer-images-widget" data-asin="B076B15VRJ" id="reviews-image-gallery-container"&gt;&lt;p&gt;&lt;h3&gt;Customer images&lt;/h3&gt;&lt;/p&gt;

  &lt;/div&gt;&lt;/span&gt;
  &lt;span data-widget-name="cr-summarization-lighthut"&gt;
&lt;/span&gt;&lt;span data-hook="cr-widget-FocalReviews"&gt;
      &lt;div&gt;
    &lt;p id="cm-cr-local-reviews-title"&gt;&lt;h3 data-hook="dp-local-reviews-header"&gt;










  Top reviews from the United States
&lt;/h3&gt;&lt;/p&gt;&lt;div&gt;&lt;div role="alert" aria-live="assertive"&gt;&lt;h4&gt;There was a problem filtering reviews right now. Please try again later.&lt;/h4&gt;&lt;/div&gt;&lt;div data-hook="top-customer-reviews-widget" id="cm-cr-dp-review-list"&gt;&lt;div id="R1KQRQ84NDKDQQ" data-hook="review"&gt;&lt;p&gt;&lt;span data-hook="review-date"&gt;Reviewed in the United States on April 2, 2020&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-hook="format-strip-linkless"&gt;Size: 7.23 Ounce (Pack of 12)&lt;/span&gt;&lt;i aria-label="|" role="img"&gt;&lt;/i&gt;&lt;span data-hook="avp-badge-linkless"&gt;Verified Purchase&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-hook="review-body"&gt;&lt;div data-a-expander-collapsed-height="300" data-a-expander-name="review_text_read_more" aria-live="polite"&gt;&lt;p&gt;&lt;span&gt;
  I remember having buckeye candy as a kid and loving it. So when my mom and I saw these featured on the Kelly Clarkson show, we decided to give them a try. Price was a bit steep, but worth it if delicious. They aren’t bad by any means, they just were not great or special in our opinion. To each their own though.
&lt;/span&gt;
  
&lt;/p&gt;&lt;/div&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;div id="RDUFFO40YZ3LG" data-hook="review"&gt;&lt;p&gt;&lt;span data-hook="review-date"&gt;Reviewed in the United States on November 17, 2018&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-hook="format-strip-linkless"&gt;Size: 7.23 Ounce (Pack of 12)&lt;/span&gt;&lt;i aria-label="|" role="img"&gt;&lt;/i&gt;&lt;span data-hook="avp-badge-linkless"&gt;Verified Purchase&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-hook="review-body"&gt;&lt;div data-a-expander-collapsed-height="300" data-a-expander-name="review_text_read_more" aria-live="polite"&gt;&lt;p&gt;&lt;span&gt;
  Sent as a gift out of state to a buckeye fan. Was told they had a film of white/grey on them and she bit into one and it crumbled it was so stale.  The box had no exp date. Very disappointed and embarrassed. They were expensive and I thought I could count on the brand alone.
&lt;/span&gt;
  
&lt;/p&gt;&lt;/div&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;div id="RIRLHGMGYC33Q" data-hook="review"&gt;&lt;p&gt;&lt;span data-hook="review-date"&gt;Reviewed in the United States on July 12, 2020&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-hook="format-strip-linkless"&gt;Size: 60 Count (Pack of 1)&lt;/span&gt;&lt;i aria-label="|" role="img"&gt;&lt;/i&gt;&lt;span data-hook="avp-badge-linkless"&gt;Verified Purchase&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-hook="review-body"&gt;&lt;div data-a-expander-collapsed-height="300" data-a-expander-name="review_text_read_more" aria-live="polite"&gt;&lt;p&gt;&lt;span&gt;
  Not the real versions of chocolate Buckeyes, but WAY better! Package comes plastic wrapped and inside the display box are the 60 individually wrapped chocolates... PLUS the chocolatier is based out of the home of the Buckeyes, Columbus Ohio. A great gift for anyone who’s an alumnus not able to get a taste of “home”.
&lt;/span&gt;
  
&lt;/p&gt;&lt;/div&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;div id="RZZQJ8C3PYG2K" data-hook="review"&gt;&lt;p&gt;&lt;span data-hook="review-date"&gt;Reviewed in the United States on February 9, 2020&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-hook="format-strip-linkless"&gt;Size: 7.23 Ounce (Pack of 12)&lt;/span&gt;&lt;i aria-label="|" role="img"&gt;&lt;/i&gt;&lt;span data-hook="avp-badge-linkless"&gt;Verified Purchase&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-hook="review-body"&gt;&lt;div data-a-expander-collapsed-height="300" data-a-expander-name="review_text_read_more" aria-live="polite"&gt;&lt;p&gt;&lt;span&gt;
  I purchased these for our OSU/Clemson football party.  The candies arrived quickly.  But I was very disappointed in their "flavor".  Maybe next time I'll make my own.
&lt;/span&gt;
  
&lt;/p&gt;&lt;/div&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;div id="RXY3HQCLBNTDM" data-hook="review"&gt;&lt;p&gt;&lt;span data-hook="review-date"&gt;Reviewed in the United States on October 14, 2018&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-hook="format-strip-linkless"&gt;Size: 60 Count (Pack of 1)&lt;/span&gt;&lt;i aria-label="|" role="img"&gt;&lt;/i&gt;&lt;span data-hook="avp-badge-linkless"&gt;Verified Purchase&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-hook="review-body"&gt;&lt;div data-a-expander-collapsed-height="300" data-a-expander-name="review_text_read_more" aria-live="polite"&gt;&lt;p&gt;&lt;span&gt;
  Unfortunately they arrived totally melted, which would look bad to use in our wedding welcome bags. The listing says “Ships in insulated packaging and cold packs to keep from melting,” but that was apparently not the case.
&lt;/span&gt;
  
&lt;/p&gt;&lt;/div&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;div id="R2AXSFPVY6OWJZ" data-hook="review"&gt;&lt;p&gt;&lt;span data-hook="review-date"&gt;Reviewed in the United States on January 20, 2021&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-hook="format-strip-linkless"&gt;Size: 7.23 Ounce (Pack of 12)&lt;/span&gt;&lt;i aria-label="|" role="img"&gt;&lt;/i&gt;&lt;span data-hook="avp-badge-linkless"&gt;Verified Purchase&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-hook="review-body"&gt;&lt;div data-a-expander-collapsed-height="300" data-a-expander-name="review_text_read_more" aria-live="polite"&gt;&lt;p&gt;&lt;span&gt;
  I was really hopeful for these based on the reviews but the ones I got were just not that good. I'd say they were average quality, definitely not something I'd buy again.
&lt;/span&gt;
  
&lt;/p&gt;&lt;/div&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;div id="R1KMEZXQJQK18Q" data-hook="review"&gt;&lt;p&gt;&lt;span data-hook="review-date"&gt;Reviewed in the United States on January 21, 2020&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-hook="format-strip-linkless"&gt;Size: 14.5 Ounce (Pack of 1)&lt;/span&gt;&lt;i aria-label="|" role="img"&gt;&lt;/i&gt;&lt;span data-hook="avp-badge-linkless"&gt;Verified Purchase&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-hook="review-body"&gt;&lt;div data-a-expander-collapsed-height="300" data-a-expander-name="review_text_read_more" aria-live="polite"&gt;&lt;p&gt;&lt;span&gt;
  These buckeyes do no justice to homemade. Tasted like wax. Never again.
&lt;/span&gt;
  
&lt;/p&gt;&lt;/div&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;div id="R1XKAB454JAXA7" data-hook="review"&gt;&lt;p&gt;&lt;span data-hook="review-date"&gt;Reviewed in the United States on November 17, 2019&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-hook="format-strip-linkless"&gt;Size: 14.5 Ounce (Pack of 1)&lt;/span&gt;&lt;i aria-label="|" role="img"&gt;&lt;/i&gt;&lt;span data-hook="avp-badge-linkless"&gt;Verified Purchase&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-hook="review-body"&gt;&lt;div data-a-expander-collapsed-height="300" data-a-expander-name="review_text_read_more" aria-live="polite"&gt;&lt;p&gt;&lt;span&gt;
  This is my third purchase.  2 boxes for us, and a box that I am taking over to a family gathering.  Great conversation  as well as great tasting candy.  I am originally from Ohio, moved to NC, so I am so delighted that I can buy once again!!!
&lt;/span&gt;
  
&lt;/p&gt;&lt;/div&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/span&gt;
  &lt;span data-hook="cr-widget-DesktopGlobalReviews"&gt;&lt;/span&gt;
  &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;a href="https://www.amazon.com/Anthony-Thomas-Chocolate-Deliciously-Delightful/dp/B076B15VRJ/ref=sr_1_2?crid=1V9DVYCKTSDNI&amp;dchild=1&amp;keywords=ohio+state+buckeyes+chocolate&amp;qid=1607894720&amp;sprefix=ohio+state+buckeyes+choc%2Caps%2C176&amp;sr=8-2"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sun, 13 Dec 2020 16:45:59 UT
      </pubDate>
      <guid>
        https://www.amazon.com/Anthony-Thomas-Chocolate-Deliciously-Delightful/dp/B076B15VRJ/ref=sr_1_2?crid=1V9DVYCKTSDNI&amp;dchild=1&amp;keywords=ohio+state+buckeyes+chocolate&amp;qid=1607894720&amp;sprefix=ohio+state+buckeyes+choc%2Caps%2C176&amp;sr=8-2
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://wiki.nikitavoloboev.xyz/macos
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div data-gramm="false" spellcheck="true" data-key="b8dd78bb42ad430499c6d8579ca76a54" data-slate-editor="true" data-editioncontainer="true"&gt;&lt;p data-key="9abb780acedc41acbd0127cda0e4306d"&gt;&lt;span&gt;&lt;span data-key="0978a0492e0149a59222a67329074b60"&gt;&lt;span data-offset-key="0978a0492e0149a59222a67329074b60:0"&gt;macOS is my &lt;/span&gt;&lt;/span&gt;&lt;a data-key="0cc87b9de3024f1aa80338dbd1991c1a" rel="noopener noreferrer" href="https://github.com/nikitavoloboev/my-mac-os"&gt;&lt;span data-key="f62696f6514d421d832f7a3a9a924a57"&gt;&lt;span data-offset-key="f62696f6514d421d832f7a3a9a924a57:0"&gt;favorite desktop operating system&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="cf624afa0d2b403daeac8ad1e42cda20"&gt;&lt;span data-offset-key="cf624afa0d2b403daeac8ad1e42cda20:0"&gt;.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-key="8b2c22c7e2514f1d8a48323f56928f9e"&gt;&lt;span&gt;&lt;span data-key="650c5b7c0ad9426db28197f7b0895041"&gt;&lt;span data-offset-key="650c5b7c0ad9426db28197f7b0895041:0"&gt;I do wish to expand my horizons and try out Linux more. I doubt I will ever be able to move to another operating system as I have too much invested in optimizing and using macOS but I do want to take the best of all worlds. Linux is open source, has an increasingly large community of users and developers and one thing that I love about UNIX systems is that by using these systems you effectively become a developer. Because otherwise you are simply missing out on the &lt;/span&gt;&lt;span data-offset-key="650c5b7c0ad9426db28197f7b0895041:1"&gt;&lt;em data-slate-leaf="true"&gt;full experience&lt;/em&gt;&lt;/span&gt;&lt;span data-offset-key="650c5b7c0ad9426db28197f7b0895041:2"&gt;.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2 data-key="ce1e097b736c4830a94c76980b2f67d5" id="clean-install"&gt;&lt;p&gt;&lt;span&gt;&lt;span data-key="da8b4229a3394b6b945b849df696b536"&gt;&lt;span data-offset-key="da8b4229a3394b6b945b849df696b536:0"&gt;Clean install&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href="#clean-install"&gt;&lt;span&gt;&lt;svg stroke="currentColor" stroke-linejoin="round" stroke-linecap="round" stroke-width="2" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" fill="none" width="1em" height="1em" preserveAspectRatio="xMidYMid meet"&gt;&lt;g&gt;&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"&gt;&lt;/path&gt;&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"&gt;&lt;/path&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/h2&gt;&lt;p data-key="7b41113d4df142519fc852cefa687dc6"&gt;&lt;span&gt;&lt;span data-key="af7add3b75af4ff4aa71b55afafce892"&gt;&lt;span data-offset-key="af7add3b75af4ff4aa71b55afafce892:0"&gt;You can clean install by going to Recovery mode (restart with &lt;/span&gt;&lt;span data-offset-key="af7add3b75af4ff4aa71b55afafce892:1"&gt;&lt;code data-slate-leaf="true" spellcheck="false"&gt;cmd+r&lt;/code&gt;&lt;/span&gt;&lt;span data-offset-key="af7add3b75af4ff4aa71b55afafce892:2"&gt; pressed). Then Disk Utility &amp;gt; Select disk &amp;gt; Erase (Format it) &amp;gt; Close Disk Utility &amp;gt; Select option Reinstall MacOS (Choose macOS ver. to install).&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2 data-key="7cd024ab43224c5b8d723502971a5b10" id="notes"&gt;&lt;p&gt;&lt;span&gt;&lt;span data-key="c25aa894e09c4e0895313ed5fb4b03c0"&gt;&lt;span data-offset-key="c25aa894e09c4e0895313ed5fb4b03c0:0"&gt;Notes&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href="#notes"&gt;&lt;span&gt;&lt;svg stroke="currentColor" stroke-linejoin="round" stroke-linecap="round" stroke-width="2" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" fill="none" width="1em" height="1em" preserveAspectRatio="xMidYMid meet"&gt;&lt;g&gt;&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"&gt;&lt;/path&gt;&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"&gt;&lt;/path&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/h2&gt;&lt;ul data-key="682cbfc9601f46aa800e17f3bc5e86be"&gt;&lt;li&gt;&lt;div data-key="c242b45d794648248a82ffbaf6804543"&gt;&lt;p data-key="8eca849f779342409bad0e6b21e209c5"&gt;&lt;span&gt;&lt;span data-key="45809fe1f28644e2854892ae013881ff"&gt;&lt;span data-offset-key="45809fe1f28644e2854892ae013881ff:0"&gt;In save dialogues I can press these keys:&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul data-key="187351d795f845548cf4e0485bd33647"&gt;&lt;li&gt;&lt;p data-key="523d2c5ad984489a8de53b8d2005b68e"&gt;&lt;span&gt;&lt;span data-key="77acb1876d1249e0988d46cccbc06cff"&gt;&lt;span data-offset-key="77acb1876d1249e0988d46cccbc06cff:0"&gt;&lt;code data-slate-leaf="true" spellcheck="false"&gt;Return&lt;/code&gt;&lt;/span&gt;&lt;span data-offset-key="77acb1876d1249e0988d46cccbc06cff:1"&gt; or &lt;/span&gt;&lt;span data-offset-key="77acb1876d1249e0988d46cccbc06cff:2"&gt;&lt;code data-slate-leaf="true" spellcheck="false"&gt;⌘ + S&lt;/code&gt;&lt;/span&gt;&lt;span data-offset-key="77acb1876d1249e0988d46cccbc06cff:3"&gt; = Save&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="9c3f6b422acb4808a573ad8f6b53320f"&gt;&lt;span&gt;&lt;span data-key="ab1e9f3efafc4193890d51b380ad40f9"&gt;&lt;span data-offset-key="ab1e9f3efafc4193890d51b380ad40f9:0"&gt;&lt;code data-slate-leaf="true" spellcheck="false"&gt;ESC&lt;/code&gt;&lt;/span&gt;&lt;span data-offset-key="ab1e9f3efafc4193890d51b380ad40f9:1"&gt; = Cancel&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="a75d5a8b76f3420aba51991b6dafa1cf"&gt;&lt;span&gt;&lt;span data-key="e933bf89421d4c9a958989dad87a6858"&gt;&lt;span data-offset-key="e933bf89421d4c9a958989dad87a6858:0"&gt;I can also press &lt;/span&gt;&lt;span data-offset-key="e933bf89421d4c9a958989dad87a6858:1"&gt;&lt;code data-slate-leaf="true" spellcheck="false"&gt;/&lt;/code&gt;&lt;/span&gt;&lt;span data-offset-key="e933bf89421d4c9a958989dad87a6858:2"&gt; or &lt;/span&gt;&lt;span data-offset-key="e933bf89421d4c9a958989dad87a6858:3"&gt;&lt;code data-slate-leaf="true" spellcheck="false"&gt;~&lt;/code&gt;&lt;/span&gt;&lt;span data-offset-key="e933bf89421d4c9a958989dad87a6858:4"&gt; to quickly go to some directory from a save dialogue. And I can press &lt;/span&gt;&lt;span data-offset-key="e933bf89421d4c9a958989dad87a6858:5"&gt;&lt;code data-slate-leaf="true" spellcheck="false"&gt;⌘ + ↑&lt;/code&gt;&lt;/span&gt;&lt;span data-offset-key="e933bf89421d4c9a958989dad87a6858:6"&gt; to go to &lt;/span&gt;&lt;span data-offset-key="e933bf89421d4c9a958989dad87a6858:7"&gt;&lt;code data-slate-leaf="true" spellcheck="false"&gt;parent directory&lt;/code&gt;&lt;/span&gt;&lt;span data-offset-key="e933bf89421d4c9a958989dad87a6858:8"&gt;.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="4bd1bfea76e04206b935e7d0ec21a2bc"&gt;&lt;span&gt;&lt;span data-key="96744dd9f41f48c793bda3a52abe9cb5"&gt;&lt;span data-offset-key="96744dd9f41f48c793bda3a52abe9cb5:0"&gt;Recovery mode: Power off the machine, press the power button and immediately hold Cmd-R.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;div data-key="a1bf258c7f5243f1ac4974d2175399b4"&gt;&lt;p data-key="270205d0367a4bdbb90ff4951e18992d"&gt;&lt;span&gt;&lt;span data-key="9a2d46b7ab5d42d5890bbece12d6727a"&gt;&lt;span data-offset-key="9a2d46b7ab5d42d5890bbece12d6727a:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="8fbc562435f34fba81bbb5c298509fb9" rel="noopener noreferrer" href="https://www.reddit.com/r/MacOS/comments/90g4h9/is_it_worth_the_effort_to_do_a_clean_install_of/"&gt;&lt;span data-key="3f6b4e1b0572401b984503d8a8bcb520"&gt;&lt;span data-offset-key="3f6b4e1b0572401b984503d8a8bcb520:0"&gt;Both Windows and MacOS are at a point where clean installs are unnecessary.&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="387bce47993a448896cdb60cd8477acf"&gt;&lt;span data-offset-key="387bce47993a448896cdb60cd8477acf:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul data-key="e69ead81a82c4f2b824fcf8fce48d372"&gt;&lt;li&gt;&lt;p data-key="15d13c7824904e408d2e14aaabd77b2f"&gt;&lt;span&gt;&lt;span data-key="8a564ce521da4e979ab938423ea42602"&gt;&lt;span data-offset-key="8a564ce521da4e979ab938423ea42602:0"&gt;I can appreciate someone wanting to do a clean install if they've installed and removed many apps and just want to clear out everything spread around all the system and hidden folders, even if it doesn't really affect performance and won't save a ton of disk space. There is something cathartic about a clean install.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="833bf521241142d683f8ef13a5f0a695"&gt;&lt;span&gt;&lt;span data-key="72e8ae733c464399922bd02180a3290a"&gt;&lt;span data-offset-key="72e8ae733c464399922bd02180a3290a:0"&gt;&lt;code data-slate-leaf="true" spellcheck="false"&gt;/usr/local/bin&lt;/code&gt;&lt;/span&gt;&lt;span data-offset-key="72e8ae733c464399922bd02180a3290a:1"&gt; is a good place to put raw binaries available in the path, that are not installed with Nix.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;div data-key="c9cf3f6dade349f095359c03a6785cdb"&gt;&lt;p data-key="d2bdd2c1b4e4468c89c0fac45c284c6c"&gt;&lt;span&gt;&lt;span data-key="24341ab6c4844d40b78faa49d09262ba"&gt;&lt;span data-offset-key="24341ab6c4844d40b78faa49d09262ba:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="e3cdc0ac97e140199961e6fda242bb6b" rel="noopener noreferrer" href="https://github.com/golang/go/issues/42684"&gt;&lt;span data-key="03b01a5ba1af4f83925ce070c115bae6"&gt;&lt;span data-offset-key="03b01a5ba1af4f83925ce070c115bae6:0"&gt;To code sign binaries ad hoc, run &lt;/span&gt;&lt;span data-offset-key="03b01a5ba1af4f83925ce070c115bae6:1"&gt;&lt;code data-slate-leaf="true" spellcheck="false"&gt;codesign -s - &amp;lt;path_to_binary&amp;gt;&lt;/code&gt;&lt;/span&gt;&lt;span data-offset-key="03b01a5ba1af4f83925ce070c115bae6:2"&gt;.&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="704c9482a4a8445a8dc0f8e0cb2b838b"&gt;&lt;span data-offset-key="704c9482a4a8445a8dc0f8e0cb2b838b:0"&gt; This will give users a gatekeeper warning but they could still run the binary. To sign so users can run binary without warning, you need Apple developer account.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-key="a5ad2fdd33834de28ab148738886602e"&gt;&lt;p&gt;&lt;span&gt;&lt;span data-key="09103d09aa7f412f80352622da650fed"&gt;&lt;span data-offset-key="09103d09aa7f412f80352622da650fed:0"&gt;Links&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href="#links"&gt;&lt;span&gt;&lt;svg stroke="currentColor" stroke-linejoin="round" stroke-linecap="round" stroke-width="2" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" fill="none" width="1em" height="1em" preserveAspectRatio="xMidYMid meet"&gt;&lt;g&gt;&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"&gt;&lt;/path&gt;&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"&gt;&lt;/path&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/h2&gt;&lt;ul data-key="e98c7330d2c947698ff527c95c1edb0d"&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;div data-key="e5dcce7e950141f892e740e8d90f8c95"&gt;&lt;p data-key="f3222cfae84e4077a9e6dbcfaa4204cc"&gt;&lt;span&gt;&lt;span data-key="17c8e534e36643f79043433e2d0eaff3"&gt;&lt;span data-offset-key="17c8e534e36643f79043433e2d0eaff3:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="75fae9412cde47cd90574c629daf7b75" rel="noopener noreferrer" href="https://github.com/pirate/mac-keyboard-brightness"&gt;&lt;span data-key="593dfacca4dc4c6b80e27eae585293ba"&gt;&lt;span data-offset-key="593dfacca4dc4c6b80e27eae585293ba:0"&gt;Control Mac Keyboard Brightness&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="d20d92f75b2140e88b37d711332d5004"&gt;&lt;span data-offset-key="d20d92f75b2140e88b37d711332d5004:0"&gt; - Programmatically flash the keyboard lights and control display brightness on Macs.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li&gt;&lt;div data-key="25832aa0634145109369d231373885d4"&gt;&lt;p data-key="6212e5b9f69c411f910bef6730c1f57c"&gt;&lt;span&gt;&lt;span data-key="7f23e9dac820411eb7689096aec7684d"&gt;&lt;span data-offset-key="7f23e9dac820411eb7689096aec7684d:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="8858546c26d44bd5b221aafe17ba7c0e" rel="noopener noreferrer" href="https://github.com/HazCod/maclaunch"&gt;&lt;span data-key="20526e6564a249b18a4441bcb93afeae"&gt;&lt;span data-offset-key="20526e6564a249b18a4441bcb93afeae:0"&gt;maclaunchmaclaunch&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="de2f7f00843740ff899721d9578c74ec"&gt;&lt;span data-offset-key="de2f7f00843740ff899721d9578c74ec:0"&gt; - Manage your macOS startup items.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="751c6c59cc3947898b9259cdeae9894d"&gt;&lt;span&gt;&lt;span data-key="a66a21488ffd4f9a89570098a4978146"&gt;&lt;span data-offset-key="a66a21488ffd4f9a89570098a4978146:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="c19f340a6f3c4b6e940c6635bb41fb07" rel="noopener noreferrer" href="https://www.objective-see.com/"&gt;&lt;span data-key="8941afed543040ecb9d07f889b9f5408"&gt;&lt;span data-offset-key="8941afed543040ecb9d07f889b9f5408:0"&gt;Objective-See&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="bb4b468b457e4323b1092b7bc6fa23bb"&gt;&lt;span data-offset-key="bb4b468b457e4323b1092b7bc6fa23bb:0"&gt; - Simple, yet effective macOS security tools.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="07a67dae675f46e4b8b7409c24c0b004"&gt;&lt;span&gt;&lt;span data-key="c7899735fdd2451396aa25bb1f1c4859"&gt;&lt;span data-offset-key="c7899735fdd2451396aa25bb1f1c4859:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="670ffa3d11ad4c1ea2d1d4779be4d0df" rel="noopener noreferrer" href="https://github.com/mxcl/AppUpdater"&gt;&lt;span data-key="169c5bdf22074effbe3b579baed0a6d3"&gt;&lt;span data-offset-key="169c5bdf22074effbe3b579baed0a6d3:0"&gt;AppUpdater&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="edcaa04a258f47839dad65f3829310b8"&gt;&lt;span data-offset-key="edcaa04a258f47839dad65f3829310b8:0"&gt; - Simple app-updater for macOS, checks your GitHub releases for a binary asset once a day and silently updates your app.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="2e174fa0754b4a9789f275b7c901f36d"&gt;&lt;span&gt;&lt;span data-key="e2196b35145b4012a2f04e349aeaa6c9"&gt;&lt;span data-offset-key="e2196b35145b4012a2f04e349aeaa6c9:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="87ec384af6a648fe9f445a3a0438b8b2" rel="noopener noreferrer" href="https://github.com/pedrommcarrasco/Brooklyn"&gt;&lt;span data-key="8c7fc946dae440899c356773f3eacb8c"&gt;&lt;span data-offset-key="8c7fc946dae440899c356773f3eacb8c:0"&gt;Brooklyn&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="f983786ca0bc4ea180304e83b232f689"&gt;&lt;span data-offset-key="f983786ca0bc4ea180304e83b232f689:0"&gt; - Screensaver inspired by Apple's Event on October 30, 2018.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="59b8373dc1774724871559d1e0865cf2"&gt;&lt;span&gt;&lt;span data-key="1332ef3d32804d9a9eedc7eebcdb540b"&gt;&lt;span data-offset-key="1332ef3d32804d9a9eedc7eebcdb540b:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="e48dc5a1532b4e9e82eabf6c133dddcb" rel="noopener noreferrer" href="https://github.com/PureDarwin/PureDarwin"&gt;&lt;span data-key="c34c56c814bc4e40a28df2717e48ce39"&gt;&lt;span data-offset-key="c34c56c814bc4e40a28df2717e48ce39:0"&gt;PureDarwin&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="12ef5f441d6d49699e84e83ed524dc3a"&gt;&lt;span data-offset-key="12ef5f441d6d49699e84e83ed524dc3a:0"&gt; - Community project to make Darwin more usable. (&lt;/span&gt;&lt;/span&gt;&lt;a data-key="bb93e3b0b4604bfeb60d6af85c5b9b41" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=23799331"&gt;&lt;span data-key="7256d0c05e234247965417601ec223b8"&gt;&lt;span data-offset-key="7256d0c05e234247965417601ec223b8:0"&gt;HN&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="ba9bac2c7be84ac48d52c4eadea5fcf3"&gt;&lt;span data-offset-key="ba9bac2c7be84ac48d52c4eadea5fcf3:0"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="502d568e204748e6a724108e4491416b"&gt;&lt;span&gt;&lt;span data-key="8b59871226944d9aa14fa9f85180d89b"&gt;&lt;span data-offset-key="8b59871226944d9aa14fa9f85180d89b:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="cf2cd66a6f9e43fbb6fdba989d872c97" rel="noopener noreferrer" href="https://www.objective-see.com/products/blockblock.html"&gt;&lt;span data-key="854cc2dd78d64957875cbc26cde79eea"&gt;&lt;span data-offset-key="854cc2dd78d64957875cbc26cde79eea:0"&gt;BlockBlock&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="ec4c8e46d65d486390b3c83f48bd7bfd"&gt;&lt;span data-offset-key="ec4c8e46d65d486390b3c83f48bd7bfd:0"&gt; - Continually monitors common persistence locations and displays an alert whenever a persistent component is added to the OS.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="464128fcb7694778b0ae58bfc02bd226"&gt;&lt;span&gt;&lt;span data-key="2de4dc56d53441c594630ee3ae0b60fd"&gt;&lt;span data-offset-key="2de4dc56d53441c594630ee3ae0b60fd:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="f17d055d2fb642a3ad089d205e14992b" rel="noopener noreferrer" href="https://github.com/ChimeHQ/Impact"&gt;&lt;span data-key="3ea0f4d4174143aa95e37a4f9b62ae06"&gt;&lt;span data-offset-key="3ea0f4d4174143aa95e37a4f9b62ae06:0"&gt;Impact&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="e19e4f385409428180387c9775476636"&gt;&lt;span data-offset-key="e19e4f385409428180387c9775476636:0"&gt; - Crash detection and recording library for Apple platforms.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="b1971e65cd56435195d9ccd898c2371f"&gt;&lt;span&gt;&lt;span data-key="2fcb3b6518824a1781e8574f302eaa13"&gt;&lt;span data-offset-key="2fcb3b6518824a1781e8574f302eaa13:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="ba5e258d7fa94cfa97a011603352c510" rel="noopener noreferrer" href="https://github.com/mitchellh/gon"&gt;&lt;span data-key="04b1c57dcc08461a920a7867e64296fb"&gt;&lt;span data-offset-key="04b1c57dcc08461a920a7867e64296fb:0"&gt;gon&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="f587bd00c26d474baad6d36a2ce9bfd3"&gt;&lt;span data-offset-key="f587bd00c26d474baad6d36a2ce9bfd3:0"&gt; - CLI and Go Library for macOS Notarization.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="39c2270a4dd24fc1b0293b1a623119d8"&gt;&lt;span&gt;&lt;span data-key="635d47af88ab4e96a2c47c8c5e03a5bd"&gt;&lt;span data-offset-key="635d47af88ab4e96a2c47c8c5e03a5bd:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="ba56cc2a6dfd4fcc9d3027cab3500d64" rel="noopener noreferrer" href="https://github.com/w0lfschild/macOS_headers"&gt;&lt;span data-key="3341b6681c5642058f6a1a6bb34f7756"&gt;&lt;span data-offset-key="3341b6681c5642058f6a1a6bb34f7756:0"&gt;macOS Headers&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="ab9e7def4150490f800448b8d9c96de4"&gt;&lt;span data-offset-key="ab9e7def4150490f800448b8d9c96de4:0"&gt; - Consistently maintained dump of most macOS Headers.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="ac23ddecc5774cf7af19ab03dc92a2f9"&gt;&lt;span&gt;&lt;span data-key="c238ff1535fd4b8ba32c8825aa4f7603"&gt;&lt;span data-offset-key="c238ff1535fd4b8ba32c8825aa4f7603:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="a63a0ad4e84243659e15fb20b83b40b2" rel="noopener noreferrer" href="https://github.com/OskarGroth/AppMover"&gt;&lt;span data-key="427db72dd97a42d78fd03f93a8346e89"&gt;&lt;span data-offset-key="427db72dd97a42d78fd03f93a8346e89:0"&gt;AppMover&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="16fa412a105d41d1821ee4b1639f3a8a"&gt;&lt;span data-offset-key="16fa412a105d41d1821ee4b1639f3a8a:0"&gt; - Framework for moving your application bundle to Applications folder on launch.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="f617d368fc4b401d8db738979be05011"&gt;&lt;span&gt;&lt;span data-key="52e6d033eeed448ba3145bbff7309f9f"&gt;&lt;span data-offset-key="52e6d033eeed448ba3145bbff7309f9f:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="3f2691827bbc43dba3d91c48fe7ede8c" rel="noopener noreferrer" href="https://github.com/acidanthera/Lilu"&gt;&lt;span data-key="ba64f67def804838baf2e746436ae093"&gt;&lt;span data-offset-key="ba64f67def804838baf2e746436ae093:0"&gt;Lilu&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="1c93624b557c4b88a236f704026650d6"&gt;&lt;span data-offset-key="1c93624b557c4b88a236f704026650d6:0"&gt; - Arbitrary kext and process patching on macOS.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="3f37840bf14e40509556f541e521367d"&gt;&lt;span&gt;&lt;span data-key="af1fbafe371040c98157a08725ae9c50"&gt;&lt;span data-offset-key="af1fbafe371040c98157a08725ae9c50:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="876f48a5b5d24e64a5ca71d3bb8406f5" rel="noopener noreferrer" href="https://github.com/pqrs-org/osx-hid-inspector"&gt;&lt;span data-key="b6fe527305de44b1a27f08ba761a55cf"&gt;&lt;span data-offset-key="b6fe527305de44b1a27f08ba761a55cf:0"&gt;osx-hid-inspector&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="4d16ed435a5e49c19e00cf88ba6febaf"&gt;&lt;span data-offset-key="4d16ed435a5e49c19e00cf88ba6febaf:0"&gt; - Command line tool for macOS for inspecting human input devices (HID).&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="45f595b1339a45e18d48a792476ecc83"&gt;&lt;span&gt;&lt;span data-key="be6e978c83f343b59daf007c1ebdf788"&gt;&lt;span data-offset-key="be6e978c83f343b59daf007c1ebdf788:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="29c00da3b3de4cf29810e0ad66b34445" rel="noopener noreferrer" href="https://github.com/mas-cli/mas"&gt;&lt;span data-key="a197094e11604c78ace7ecc35cbf4e17"&gt;&lt;span data-offset-key="a197094e11604c78ace7ecc35cbf4e17:0"&gt;mas-cli&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="545a7b5d45a449e1980b18d4d1006285"&gt;&lt;span data-offset-key="545a7b5d45a449e1980b18d4d1006285:0"&gt; - Simple command line interface for the Mac App Store. Designed for scripting and automation.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="1ec03eb4b40b4b859bea34d93a0036b0"&gt;&lt;span&gt;&lt;span data-key="7fbbf0f12db14983b1e85cf20b375bc6"&gt;&lt;span data-offset-key="7fbbf0f12db14983b1e85cf20b375bc6:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="22c8f45180da4584b0aae984aa07f6c0" rel="noopener noreferrer" href="https://github.com/zero-sh/apply-user-defaults"&gt;&lt;span data-key="0c4695d4cf8047e482e9173294040fad"&gt;&lt;span data-offset-key="0c4695d4cf8047e482e9173294040fad:0"&gt;apply-user-defaults&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="f5ee742242bf4b65bfe4588c682f5ee9"&gt;&lt;span data-offset-key="f5ee742242bf4b65bfe4588c682f5ee9:0"&gt; - Small utility to set macOS user defaults declaratively from a YAML file.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="c696962a41f645daa8a64e12dfa27ab5"&gt;&lt;span&gt;&lt;span data-key="aaf6be9d64774c0b8dc3af240dc90e6b"&gt;&lt;span data-offset-key="aaf6be9d64774c0b8dc3af240dc90e6b:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="68b237d76a104160bfd21b9f1e4c3816" rel="noopener noreferrer" href="https://github.com/zero-sh/zero.sh"&gt;&lt;span data-key="a4617cea256449c799d3a1572dd6af6a"&gt;&lt;span data-offset-key="a4617cea256449c799d3a1572dd6af6a:0"&gt;Zero.sh&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="26988ca5d4014da9ae6cf38ce38cbfdf"&gt;&lt;span data-offset-key="26988ca5d4014da9ae6cf38ce38cbfdf:0"&gt; - Radically simple personal bootstrapping tool for macOS.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;div data-key="459b74a43f2f494886de3c6c879f0bfe"&gt;&lt;p data-key="100f35a7917d44708eca105a255480c8"&gt;&lt;span&gt;&lt;span data-key="cf40bf5a17354f1d8e843314a2b98f25"&gt;&lt;span data-offset-key="cf40bf5a17354f1d8e843314a2b98f25:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="cafef58452de48f8a5139bba1b8c54c8" rel="noopener noreferrer" href="https://tyler.io/default-app-for-mac-ios/"&gt;&lt;span data-key="720595da417f4d17ae1197127ad24077"&gt;&lt;span data-offset-key="720595da417f4d17ae1197127ad24077:0"&gt;DefaultApp&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="f8129525038d4470ae85d07af8dc5e97"&gt;&lt;span data-offset-key="f8129525038d4470ae85d07af8dc5e97:0"&gt; - Template for starting macOS projects. (&lt;/span&gt;&lt;/span&gt;&lt;a data-key="7279da119b0542929fec036cb8dc8d3a" rel="noopener noreferrer" href="https://github.com/tylerhall/DefaultApp"&gt;&lt;span data-key="10a672e839cc405bb60b85ddcdbc7ba7"&gt;&lt;span data-offset-key="10a672e839cc405bb60b85ddcdbc7ba7:0"&gt;Code&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="16c7b5a6b0304eb08270640202549b4c"&gt;&lt;span data-offset-key="16c7b5a6b0304eb08270640202549b4c:0"&gt;) (&lt;/span&gt;&lt;/span&gt;&lt;a data-key="01a07ce9480844d7b316823c48102094" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=22582456"&gt;&lt;span data-key="5fa0987d8e924555b1aea7593064a527"&gt;&lt;span data-offset-key="5fa0987d8e924555b1aea7593064a527:0"&gt;HN&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="60527a3cfd9d4c89a5217211fcee6d55"&gt;&lt;span data-offset-key="60527a3cfd9d4c89a5217211fcee6d55:0"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="becc4d066635495d97ecc9c3c49a1854"&gt;&lt;span&gt;&lt;span data-key="c77ef4a2f84b4606b4cfb56b42399a75"&gt;&lt;span data-offset-key="c77ef4a2f84b4606b4cfb56b42399a75:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="0e0301b87d8840638adb17fced548b6f" rel="noopener noreferrer" href="https://github.com/ExistentialAudio/BlackHole"&gt;&lt;span data-key="52681622b53a4884a46255aea33f64a2"&gt;&lt;span data-offset-key="52681622b53a4884a46255aea33f64a2:0"&gt;BlackHole&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="8897bb1ae2de4b6c891bd5207138065d"&gt;&lt;span data-offset-key="8897bb1ae2de4b6c891bd5207138065d:0"&gt; - Modern MacOS virtual audio driver that allows applications to pass audio to other applications with zero additional latency.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="5803336a926142f682f5736fdd3b67ae"&gt;&lt;span&gt;&lt;span data-key="8e69f275bb654800910360f3b3706e22"&gt;&lt;span data-offset-key="8e69f275bb654800910360f3b3706e22:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="849d3f4e8ebd47ed9751848fd1b32e8c" rel="noopener noreferrer" href="https://github.com/akeru-inc/xcnotary"&gt;&lt;span data-key="ea43018b9920477a8bf1e5e216af4fb9"&gt;&lt;span data-offset-key="ea43018b9920477a8bf1e5e216af4fb9:0"&gt;xcnotary&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="f7c6edd797554aac8d930f7870684958"&gt;&lt;span data-offset-key="f7c6edd797554aac8d930f7870684958:0"&gt; - Missing macOS app notarization helper, built with Rust. (&lt;/span&gt;&lt;/span&gt;&lt;a data-key="934d5d52d89e438a9733f0716ea35e92" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=22743659"&gt;&lt;span data-key="aef4b8565a894035808a64e959d5e42e"&gt;&lt;span data-offset-key="aef4b8565a894035808a64e959d5e42e:0"&gt;HN&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="4e5fc0da0fd24277be62e2a6a5718fc6"&gt;&lt;span data-offset-key="4e5fc0da0fd24277be62e2a6a5718fc6:0"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="ff7b5a2f7b9249f1a0d8926d939440ff"&gt;&lt;span&gt;&lt;span data-key="e8198f57e4a244d5a55f2ae01a797f35"&gt;&lt;span data-offset-key="e8198f57e4a244d5a55f2ae01a797f35:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="bc755b63483f46668583f9dafdae5ff1" rel="noopener noreferrer" href="https://github.com/koekeishiya/skhd"&gt;&lt;span data-key="e3d734aec6644895b4ba89e34b3d3454"&gt;&lt;span data-offset-key="e3d734aec6644895b4ba89e34b3d3454:0"&gt;skhd&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="791c3f58f9a948dfb7452f8d1fd53318"&gt;&lt;span data-offset-key="791c3f58f9a948dfb7452f8d1fd53318:0"&gt; - Simple hotkey daemon for macOS.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="1271416b6df9424fbbc7be95a641dc18"&gt;&lt;span&gt;&lt;span data-key="1d370ee98cc0464ca9978e067de4abc1"&gt;&lt;span data-offset-key="1d370ee98cc0464ca9978e067de4abc1:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="3d6279920f1842b5968d675b95e9c43a" rel="noopener noreferrer" href="https://github.com/briankendall/proxy-audio-device"&gt;&lt;span data-key="a21d9df327fa4385bdcc83eda7494d42"&gt;&lt;span data-offset-key="a21d9df327fa4385bdcc83eda7494d42:0"&gt;Proxy Audio Driver&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="2ab1c9a87f484364b55aa3efb31f7de9"&gt;&lt;span data-offset-key="2ab1c9a87f484364b55aa3efb31f7de9:0"&gt; - Virtual audio driver for macOS to sends all audio to another output.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="291c6a4113de43409a68bc71924f9985"&gt;&lt;span&gt;&lt;span data-key="15b75b0b2df04d44b1ab5edbe60a12aa"&gt;&lt;span data-offset-key="15b75b0b2df04d44b1ab5edbe60a12aa:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="206b929a7a7d4622951804171c3e8bc4" rel="noopener noreferrer" href="https://github.com/SAP/macOS-icon-generator"&gt;&lt;span data-key="138aaaa44da44b4bacba4c9e8e4ed067"&gt;&lt;span data-offset-key="138aaaa44da44b4bacba4c9e8e4ed067:0"&gt;Icons.app&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="4358de398d484759b6a92f53ab002d39"&gt;&lt;span data-offset-key="4358de398d484759b6a92f53ab002d39:0"&gt; - App for macOS which is designed to generate consistent sized icons of an existing application in various states, jiggling (shaking) etc.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="3153e5f6b0024b44a3f5458885b0f498"&gt;&lt;span&gt;&lt;span data-key="d0fc7bbffa7a47e9a2466e9e7e716254"&gt;&lt;span data-offset-key="d0fc7bbffa7a47e9a2466e9e7e716254:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="c22d1724a3274d5495b702b447117f66" rel="noopener noreferrer" href="https://dortania.github.io/OpenCore-Desktop-Guide/"&gt;&lt;span data-key="af45621066194b38822bb954e46232c1"&gt;&lt;span data-offset-key="af45621066194b38822bb954e46232c1:0"&gt;OpenCore&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="27f689dacb1948549714a47523420eb7"&gt;&lt;span data-offset-key="27f689dacb1948549714a47523420eb7:0"&gt; - Open-source, unconventional, first-in-class piece of software designed to intercept kernel loading to insert a highly advanced rootkit, designed to be an alternative to Clover. (&lt;/span&gt;&lt;/span&gt;&lt;a data-key="9b58a9646a464d079b2709cb34990450" rel="noopener noreferrer" href="https://github.com/dortania/OpenCore-Desktop-Guide"&gt;&lt;span data-key="1b5d1227d19649c6a5cda7b69f3cdad9"&gt;&lt;span data-offset-key="1b5d1227d19649c6a5cda7b69f3cdad9:0"&gt;Code&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="47f354a9eeb044a6bf91d281c926061e"&gt;&lt;span data-offset-key="47f354a9eeb044a6bf91d281c926061e:0"&gt;) (&lt;/span&gt;&lt;/span&gt;&lt;a data-key="f81687ddd38e4e4aafffe2214dcdc1b8" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=22916281"&gt;&lt;span data-key="3483ae6fbdf84199ace4e435197b66b5"&gt;&lt;span data-offset-key="3483ae6fbdf84199ace4e435197b66b5:0"&gt;HN&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="a5bc205010854cee804b252133946d61"&gt;&lt;span data-offset-key="a5bc205010854cee804b252133946d61:0"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="21e27bd6c0fd46a3b959ba657da745e1"&gt;&lt;span&gt;&lt;span data-key="355e1c5810dd481ebb25e379fb84755d"&gt;&lt;span data-offset-key="355e1c5810dd481ebb25e379fb84755d:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="26806f53c2c34114ac65211ad84be847" rel="noopener noreferrer" href="https://github.com/Syphon/Syphon-Framework"&gt;&lt;span data-key="fd226f2ba2fc406bbd17c507e4076910"&gt;&lt;span data-offset-key="fd226f2ba2fc406bbd17c507e4076910:0"&gt;Syphon&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="0013fb0badcd44e889c9bd77bad51ffc"&gt;&lt;span data-offset-key="0013fb0badcd44e889c9bd77bad51ffc:0"&gt; - macOS technology to allow applications to share video and still images with one another in realtime, instantly.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;div data-key="c2fb6fbcb407491cb329b6bb38215f5c"&gt;&lt;p data-key="ef8d069a77c04e75b9c69513fef9892d"&gt;&lt;span&gt;&lt;span data-key="a127c97100da40acaacad9fce480a6c4"&gt;&lt;span data-offset-key="a127c97100da40acaacad9fce480a6c4:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="556166cfac3c496e9a7f97cc7c5360fa" rel="noopener noreferrer" href="https://flow.swiss/mac-bare-metal"&gt;&lt;span data-key="c05b7dfdec7f4becb4e7a4759500151c"&gt;&lt;span data-offset-key="c05b7dfdec7f4becb4e7a4759500151c:0"&gt;Mac Bare Metal&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="133f43db4bd146fd93a08a4d483e0fcd"&gt;&lt;span data-offset-key="133f43db4bd146fd93a08a4d483e0fcd:0"&gt; - Enterprise-class IaaS for macOS.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li&gt;&lt;div data-key="32cbaec8535448af912f3ead810f0f8d"&gt;&lt;p data-key="03bf0bd16c2b44818d8abed668bdaab4"&gt;&lt;span&gt;&lt;span data-key="e62496b644a84fae84648d7165137703"&gt;&lt;span data-offset-key="e62496b644a84fae84648d7165137703:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="09c8b9dc009c406ba73d8e421fbcd1e9" rel="noopener noreferrer" href="https://github.com/microsoft/react-native-macos"&gt;&lt;span data-key="ae71cebd6fd9407ca65e0faef32095ed"&gt;&lt;span data-offset-key="ae71cebd6fd9407ca65e0faef32095ed:0"&gt;React Native for macOS&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="7ec337e8576644eabe16d6202ec2a58b"&gt;&lt;span data-offset-key="7ec337e8576644eabe16d6202ec2a58b:0"&gt; - Build native macOS apps with React. (&lt;/span&gt;&lt;/span&gt;&lt;a data-key="d371cdf68e6d409cbadcebd55e6d55d5" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=23160075"&gt;&lt;span data-key="cb208bf216814664ad8f00db72d60c41"&gt;&lt;span data-offset-key="cb208bf216814664ad8f00db72d60c41:0"&gt;HN&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="c5b242c90f8c4c76b3933dcbcd9d1a4f"&gt;&lt;span data-offset-key="c5b242c90f8c4c76b3933dcbcd9d1a4f:0"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="48597c021710495ab40d9c354d95b01a"&gt;&lt;span&gt;&lt;span data-key="48b4570e3340497181c3e8b124ae9f73"&gt;&lt;span data-offset-key="48b4570e3340497181c3e8b124ae9f73:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="0645f77bf00845829ed9ef925c3103e4" rel="noopener noreferrer" href="https://github.com/grahamc/netboot.nix"&gt;&lt;span data-key="495a9395574746bbb0ea9e9d36f2d622"&gt;&lt;span data-offset-key="495a9395574746bbb0ea9e9d36f2d622:0"&gt;netboot.nix&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="dd605def255245cbb78c406e8c2f03c2"&gt;&lt;span data-offset-key="dd605def255245cbb78c406e8c2f03c2:0"&gt; - Create full netboot images in 15 seconds.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="863341fc21214c0b8e67632ca2e1ba29"&gt;&lt;span&gt;&lt;span data-key="23b104c222034f2d9cba01f3e2628f9b"&gt;&lt;span data-offset-key="23b104c222034f2d9cba01f3e2628f9b:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="6eaf8eaa72a44aa2ae8757566fc1b81c" rel="noopener noreferrer" href="https://github.com/NSExceptional/Swizzle"&gt;&lt;span data-key="d6b658ccca864936b1273e801587df1e"&gt;&lt;span data-offset-key="d6b658ccca864936b1273e801587df1e:0"&gt;Swizzle&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="f9b42658d1ad49f4abe99b4bb9b7d42e"&gt;&lt;span data-offset-key="f9b42658d1ad49f4abe99b4bb9b7d42e:0"&gt; - Extensible tweak to create simple tweaks for any app, from within any app.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="50f319ec1af247adb5a3758995005eed"&gt;&lt;span&gt;&lt;span data-key="e18ec7328a874c83b2b2d339897de4fd"&gt;&lt;span data-offset-key="e18ec7328a874c83b2b2d339897de4fd:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="07d06f8778e84d139879ecd8400b7636" rel="noopener noreferrer" href="https://github.com/bdrister/AquaticPrime"&gt;&lt;span data-key="bdce9d425e5d49f48e45050b13ed73e9"&gt;&lt;span data-offset-key="bdce9d425e5d49f48e45050b13ed73e9:0"&gt;AquaticPrime&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="0133919ac45b4bdcb1f08a115ec5887f"&gt;&lt;span data-offset-key="0133919ac45b4bdcb1f08a115ec5887f:0"&gt; - Mac software licensing code using cryptographically signed license files.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="d636242915664a21b044336768a91974"&gt;&lt;span&gt;&lt;span data-key="62a16593aa8d48b78345a814e2c07e02"&gt;&lt;span data-offset-key="62a16593aa8d48b78345a814e2c07e02:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="73f92b71dd1b497699fec943075042e7" rel="noopener noreferrer" href="https://github.com/KhaosT/SimpleVM"&gt;&lt;span data-key="a395379bec5c40fdad766b5838fbffcd"&gt;&lt;span data-offset-key="a395379bec5c40fdad766b5838fbffcd:0"&gt;SimpleVM&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="bacc23a5cf2243d6b46872989030590a"&gt;&lt;span data-offset-key="bacc23a5cf2243d6b46872989030590a:0"&gt; - Sample code for Virtualization framework. (&lt;/span&gt;&lt;/span&gt;&lt;a data-key="9941fc602a6342ac9cb381f8b1072a94" rel="noopener noreferrer" href="https://github.com/danczar/SimpleVM"&gt;&lt;span data-key="ce734dfbfcba45da8b8563e008fbf418"&gt;&lt;span data-offset-key="ce734dfbfcba45da8b8563e008fbf418:0"&gt;Fork&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="cb6af157727c4619a1b80fc1cec0fd9c"&gt;&lt;span data-offset-key="cb6af157727c4619a1b80fc1cec0fd9c:0"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="dff9e48f264f4a7baeb43a4557ef2b9b"&gt;&lt;span&gt;&lt;span data-key="1750c6a2651a4f7bab11eb79827de9aa"&gt;&lt;span data-offset-key="1750c6a2651a4f7bab11eb79827de9aa:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="f45f092937464c4d9a7ec364bd430661" rel="noopener noreferrer" href="https://github.com/trailofbits/sinter"&gt;&lt;span data-key="6bd51be7551a43f28ea7b65d773e770a"&gt;&lt;span data-offset-key="6bd51be7551a43f28ea7b65d773e770a:0"&gt;Sinter&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="db2b0ca3be5f435297eb7526c9ec6fec"&gt;&lt;span data-offset-key="db2b0ca3be5f435297eb7526c9ec6fec:0"&gt; - User-mode application authorization system for MacOS written in Swift. (&lt;/span&gt;&lt;/span&gt;&lt;a data-key="8e3f18d0036f423e8306e23bba94b64b" rel="noopener noreferrer" href="https://blog.trailofbits.com/2020/08/12/sinter-new-user-mode-security-enforcement-for-macos/"&gt;&lt;span data-key="4dbeb20613184e9482bfd7600565ea50"&gt;&lt;span data-offset-key="4dbeb20613184e9482bfd7600565ea50:0"&gt;Article&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="27858d2b71d2447d8dd0ad1f77cb3070"&gt;&lt;span data-offset-key="27858d2b71d2447d8dd0ad1f77cb3070:0"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;div data-key="565556a96d564b3b8d6f920198f406f3"&gt;&lt;p data-key="ad8c2681c73d43cbbeea3dc65fd47d8d"&gt;&lt;span&gt;&lt;span data-key="03681a3ae49b4961b85bd2e05663f9cd"&gt;&lt;span data-offset-key="03681a3ae49b4961b85bd2e05663f9cd:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="4a5fdaffa42c44458c350b50b110da6b" rel="noopener noreferrer" href="https://macosicons.com/"&gt;&lt;span data-key="2bd23e044893418a9b572f9fc4148f18"&gt;&lt;span data-offset-key="2bd23e044893418a9b572f9fc4148f18:0"&gt;macOS icon pack&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="28d62e036ef24ea588a6cf4e90a7ed26"&gt;&lt;span data-offset-key="28d62e036ef24ea588a6cf4e90a7ed26:0"&gt; - Beautiful open source icons for Big Sur. (&lt;/span&gt;&lt;/span&gt;&lt;a data-key="098c928610d748e3aeea7aa1c95660b3" rel="noopener noreferrer" href="https://github.com/elrumo/macOS_Big_Sur_icons_replacements"&gt;&lt;span data-key="f286862cc431408687042158076a22cb"&gt;&lt;span data-offset-key="f286862cc431408687042158076a22cb:0"&gt;Code&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="42472a3043554ea58a994adb3fd5cecd"&gt;&lt;span data-offset-key="42472a3043554ea58a994adb3fd5cecd:0"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="92b0e23f27e845c4b4b2ae8a39f03f04"&gt;&lt;span&gt;&lt;span data-key="0aa66ffe3dfc4be1914fc435282b78db"&gt;&lt;span data-offset-key="0aa66ffe3dfc4be1914fc435282b78db:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="5d0f903f202c45a0baf7813ef20823d0" rel="noopener noreferrer" href="https://github.com/sparkle-project/Sparkle"&gt;&lt;span data-key="7c740a76b93d43eea69d6698a9c19d5c"&gt;&lt;span data-offset-key="7c740a76b93d43eea69d6698a9c19d5c:0"&gt;Sparkle&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="cd3912edbe2648b9b4ecb2eb39bf890d"&gt;&lt;span data-offset-key="cd3912edbe2648b9b4ecb2eb39bf890d:0"&gt; - Software update framework for macOS. (&lt;/span&gt;&lt;/span&gt;&lt;a data-key="12703b505e11488fbc86ff7065465e9f" rel="noopener noreferrer" href="https://sparkle-project.org/"&gt;&lt;span data-key="a0ffba6885bf46e6886d1cab5bb9fb59"&gt;&lt;span data-offset-key="a0ffba6885bf46e6886d1cab5bb9fb59:0"&gt;Web&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="b8525cc811014ecbb9dbff22b484fb63"&gt;&lt;span data-offset-key="b8525cc811014ecbb9dbff22b484fb63:0"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="f67976a1ab9940729960a02905afaca1"&gt;&lt;span&gt;&lt;span data-key="610ae922096444b9bff749095b19e751"&gt;&lt;span data-offset-key="610ae922096444b9bff749095b19e751:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="2ea75b5c43814199a389c23ebe5635dc" rel="noopener noreferrer" href="https://github.com/fastai/fastmac/"&gt;&lt;span data-key="6365cb4b47cc4ad38759f5d13ad03c07"&gt;&lt;span data-offset-key="6365cb4b47cc4ad38759f5d13ad03c07:0"&gt;fastmac&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="555bac6456404e7f822c0aaeb8607ee4"&gt;&lt;span data-offset-key="555bac6456404e7f822c0aaeb8607ee4:0"&gt; - MacOS instance or Linux shell. (&lt;/span&gt;&lt;/span&gt;&lt;a data-key="79889722f21444d59f82dc101c47d629" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=24452384"&gt;&lt;span data-key="f3c99ef1288a4321adc3c05c8b43be3c"&gt;&lt;span data-offset-key="f3c99ef1288a4321adc3c05c8b43be3c:0"&gt;HN&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="20f0a95493d54b3a92fe93fcb69ddbb3"&gt;&lt;span data-offset-key="20f0a95493d54b3a92fe93fcb69ddbb3:0"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="eff33dfd67984f7b80d423502de740f3"&gt;&lt;span&gt;&lt;span data-key="f4a2abd0cdbb4474a9835192e63ce456"&gt;&lt;span data-offset-key="f4a2abd0cdbb4474a9835192e63ce456:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="a4c73536e94b4260b91eb288c01737e1" rel="noopener noreferrer" href="https://github.com/foxlet/macOS-Simple-KVM"&gt;&lt;span data-key="5d6ee50a4da048f19ed4f3b5548ff50e"&gt;&lt;span data-offset-key="5d6ee50a4da048f19ed4f3b5548ff50e:0"&gt;macOS Simple KVM&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="4057cb697f934f0d8a2b40022c20d20e"&gt;&lt;span data-offset-key="4057cb697f934f0d8a2b40022c20d20e:0"&gt; - Tools to set up a quick macOS VM in QEMU, accelerated by KVM.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="3c15a3e8df4d4774b1c5495298325178"&gt;&lt;span&gt;&lt;span data-key="04d62cb70b1640a6b32a13ae2a7ce310"&gt;&lt;span data-offset-key="04d62cb70b1640a6b32a13ae2a7ce310:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="4dec6f86640341cda905cab074966679" rel="noopener noreferrer" href="https://github.com/phatblat/ApplePlatformVersions"&gt;&lt;span data-key="406e152342f14a0da29aec4133d99b76"&gt;&lt;span data-offset-key="406e152342f14a0da29aec4133d99b76:0"&gt;Apple Platform Versions&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="57b171fbb9204b61911aa275a7c10336"&gt;&lt;span data-offset-key="57b171fbb9204b61911aa275a7c10336:0"&gt; - Recent history of platforms developed by Apple, including Apple-managed build tools for these platforms.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;div data-key="28c0f4f4179e40dda865fb99a455295a"&gt;&lt;p data-key="ac60066e45cc4421ade1d92a321f6d7e"&gt;&lt;span&gt;&lt;span data-key="6e59f386579c40428af6121f93125301"&gt;&lt;span data-offset-key="6e59f386579c40428af6121f93125301:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="b00b0220199f470a8658e36ba961b9b9" rel="noopener noreferrer" href="https://macos-defaults.com/"&gt;&lt;span data-key="fcc502a993d644168ee27aeeddb9cace"&gt;&lt;span data-offset-key="fcc502a993d644168ee27aeeddb9cace:0"&gt;macOS defaults&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="878a9477dbd247f3bd0a564bcec71628"&gt;&lt;span data-offset-key="878a9477dbd247f3bd0a564bcec71628:0"&gt; - List of macOS defaults commands with demos. (&lt;/span&gt;&lt;/span&gt;&lt;a data-key="a06eaf4354314aec9c6bfd70a0563eff" rel="noopener noreferrer" href="https://github.com/yannbertrand/macos-defaults"&gt;&lt;span data-key="d33ee0c04f6e4230b2f5bd31da76b2ef"&gt;&lt;span data-offset-key="d33ee0c04f6e4230b2f5bd31da76b2ef:0"&gt;Code&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="05a753201ea049e1a2d8e5825dc41bce"&gt;&lt;span data-offset-key="05a753201ea049e1a2d8e5825dc41bce:0"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="b93f5e3d3cbd4f9f98030454f20034f8"&gt;&lt;span&gt;&lt;span data-key="91988c82583f475d9e62ed3bbccf04db"&gt;&lt;span data-offset-key="91988c82583f475d9e62ed3bbccf04db:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="e1e3f98cecc64bd58d55474ffef13901" rel="noopener noreferrer" href="https://doesitarm.com/"&gt;&lt;span data-key="974d3c42e06d4605919abc8029be2cdc"&gt;&lt;span data-offset-key="974d3c42e06d4605919abc8029be2cdc:0"&gt;Does it ARM&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="3c5aff3cff16417386c5e4db9ad727f1"&gt;&lt;span data-offset-key="3c5aff3cff16417386c5e4db9ad727f1:0"&gt; - Apps that are reported to support Apple Silicon. (&lt;/span&gt;&lt;/span&gt;&lt;a data-key="b60f2058a4fe416a83416135888ee206" rel="noopener noreferrer" href="https://github.com/ThatGuySam/doesitarm"&gt;&lt;span data-key="53903ddfa7b34480afb04e5e419eca75"&gt;&lt;span data-offset-key="53903ddfa7b34480afb04e5e419eca75:0"&gt;Code&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="400db609db0f4679a8114af3f818c145"&gt;&lt;span data-offset-key="400db609db0f4679a8114af3f818c145:0"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="f7967a98ff044e3f8d568104bf79e166"&gt;&lt;span&gt;&lt;span data-key="30f449c4d0024e13b545d3ab77cc1456"&gt;&lt;span data-offset-key="30f449c4d0024e13b545d3ab77cc1456:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="dde897dc3da04d23860225dab761eb6a" rel="noopener noreferrer" href="https://github.com/create-dmg/create-dmg"&gt;&lt;span data-key="b36ac3d8098f4543a497cf0396b970cd"&gt;&lt;span data-offset-key="b36ac3d8098f4543a497cf0396b970cd:0"&gt;create-dmg&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="0470a70a30364e279c373d92d4f16a8d"&gt;&lt;span data-offset-key="0470a70a30364e279c373d92d4f16a8d:0"&gt; - Shell script to build fancy DMGs.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;div data-key="07a86922602e476baecab708345a3469"&gt;&lt;p data-key="74e400827a5b4869bd005a951aea2514"&gt;&lt;span&gt;&lt;span data-key="9a51763e05ce4c4fbf41b15ea48ad43e"&gt;&lt;span data-offset-key="9a51763e05ce4c4fbf41b15ea48ad43e:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="fdda8727f7024c3d9604943c3e3d9bae" rel="noopener noreferrer" href="https://github.com/nico/lssym"&gt;&lt;span data-key="5402b36400d4429a8d97b6b661e1494c"&gt;&lt;span data-offset-key="5402b36400d4429a8d97b6b661e1494c:0"&gt;Mach-O learning tool&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="2baf737a4fe64bb687090e6081185308"&gt;&lt;span data-offset-key="2baf737a4fe64bb687090e6081185308:0"&gt; - Toy program to learn more about the mach-o file format.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="25058d54a63443119db578eae68c61e5"&gt;&lt;span&gt;&lt;span data-key="ff622f9d0450410ba0a3bcec528321d7"&gt;&lt;span data-offset-key="ff622f9d0450410ba0a3bcec528321d7:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="c432574b919e4e0fa725163e3c4e8470" rel="noopener noreferrer" href="https://github.com/iSapozhnik/Popover"&gt;&lt;span data-key="c07bc28773094ca78f83d8088aed2319"&gt;&lt;span data-offset-key="c07bc28773094ca78f83d8088aed2319:0"&gt;Popover&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="eedd3fd68c4f445dba658794f15fcd30"&gt;&lt;span data-offset-key="eedd3fd68c4f445dba658794f15fcd30:0"&gt; - Custom macOS Popover.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;div data-key="31ce0bc29f43498c86cef8f90669a677"&gt;&lt;p data-key="a35beb41932b4821979c221da92682fd"&gt;&lt;span&gt;&lt;span data-key="b1b3353019d04ac69bdcd2b6f0d034b4"&gt;&lt;span data-offset-key="b1b3353019d04ac69bdcd2b6f0d034b4:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="39a39c083c244bc2931656fc1eb1b694" rel="noopener noreferrer" href="https://github.com/evansm7/vftool"&gt;&lt;span data-key="701729d34f524d3d9fc4e4fe9624f930"&gt;&lt;span data-offset-key="701729d34f524d3d9fc4e4fe9624f930:0"&gt;Virtualization.framework tool (vftool)&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="e1b864dc359c46c394e8b1ddbe660ad1"&gt;&lt;span data-offset-key="e1b864dc359c46c394e8b1ddbe660ad1:0"&gt; - Runs Linux virtual machines in macOS. (&lt;/span&gt;&lt;/span&gt;&lt;a data-key="7e3ee0bdfb20452bb26e3f08f85a58fe" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=25382529"&gt;&lt;span data-key="fa4ee824a0394aa4aa02ea59b216c4dd"&gt;&lt;span data-offset-key="fa4ee824a0394aa4aa02ea59b216c4dd:0"&gt;HN&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="68c4393ed7464acf83bffca0c03c6977"&gt;&lt;span data-offset-key="68c4393ed7464acf83bffca0c03c6977:0"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="1bcacd1558d04821842610bc1b17bcb2"&gt;&lt;span&gt;&lt;span data-key="7aa4cdca53c54ec89b08bd575a683291"&gt;&lt;span data-offset-key="7aa4cdca53c54ec89b08bd575a683291:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="843e94918c954d8183027c730ed644ac" rel="noopener noreferrer" href="https://github.com/PraneetNeuro/Project-Mendacius"&gt;&lt;span data-key="4a930f6cd2ff47038ef1c23f9d08b855"&gt;&lt;span data-offset-key="4a930f6cd2ff47038ef1c23f9d08b855:0"&gt;Project Mendacius&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="fed5befb44424da4b720c81c8729e3b6"&gt;&lt;span data-offset-key="fed5befb44424da4b720c81c8729e3b6:0"&gt; - GUI based virtualization tool for running Linux on macOS Big Sur.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="525e79ee1f52470f88b5da68f5fc107b"&gt;&lt;span&gt;&lt;span data-key="1a20780c7d8e4785a2ade288efb82311"&gt;&lt;span data-offset-key="1a20780c7d8e4785a2ade288efb82311:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="4c9088b8e4354fb597c87232f68e71df" rel="noopener noreferrer" href="https://github.com/insidegui/dmgdist"&gt;&lt;span data-key="16417ccd5e9a473591970207b380cd1c"&gt;&lt;span data-offset-key="16417ccd5e9a473591970207b380cd1c:0"&gt;dmgdist&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="d5eab4994c30425da3eb6a3419417d5a"&gt;&lt;span data-offset-key="d5eab4994c30425da3eb6a3419417d5a:0"&gt; - Automate the process of creating, uploading and notarizing the DMG of a Mac app.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="d3bebfc0c535412ca5258664f89498e7"&gt;&lt;span&gt;&lt;span data-key="8dfac1d274ca46f1b218ceb42e5415fb"&gt;&lt;span data-offset-key="8dfac1d274ca46f1b218ceb42e5415fb:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="a05b7b6d12f6453d85b1e0bf5cb03dd7" rel="noopener noreferrer" href="https://github.com/kendfinger/MacHack"&gt;&lt;span data-key="7dd37608eb2741bc8fe2738788258d7f"&gt;&lt;span data-offset-key="7dd37608eb2741bc8fe2738788258d7f:0"&gt;MacHack&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="f3553dba8ffa4546b91694404afbbe2c"&gt;&lt;span data-offset-key="f3553dba8ffa4546b91694404afbbe2c:0"&gt; - List of built-in tools in macOS that you probably didn't know about.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="6bd1cebd0d524361bc55fff8c1f99a46"&gt;&lt;span&gt;&lt;span data-key="95ab20948c4c4a6187bf0fe5bea9a8bc"&gt;&lt;span data-offset-key="95ab20948c4c4a6187bf0fe5bea9a8bc:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="ff15a5e802044f269d8a2ae5e278b01b" rel="noopener noreferrer" href="https://github.com/theevilbit/Shield"&gt;&lt;span data-key="564c9dc09bb14d43b4eb0c7116475c45"&gt;&lt;span data-offset-key="564c9dc09bb14d43b4eb0c7116475c45:0"&gt;Shield&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="ec68cff0541546079b09551a6eeedc42"&gt;&lt;span data-offset-key="ec68cff0541546079b09551a6eeedc42:0"&gt; - App to protect against process injection on macOS. (&lt;/span&gt;&lt;/span&gt;&lt;a data-key="190630fdcdb64c43a78209c2cd88e177" rel="noopener noreferrer" href="https://theevilbit.github.io/shield/"&gt;&lt;span data-key="c2dbc27009da4557b5f601154d5bc56c"&gt;&lt;span data-offset-key="c2dbc27009da4557b5f601154d5bc56c:0"&gt;Article&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="7007ed1fb5244598bb04cff439f51919"&gt;&lt;span data-offset-key="7007ed1fb5244598bb04cff439f51919:0"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="7e5e493e5b734b42ab61d2cef68a57c1"&gt;&lt;span&gt;&lt;span data-key="791cadc903ca4962984093df59ff43bb"&gt;&lt;span data-offset-key="791cadc903ca4962984093df59ff43bb:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="3edafac492f34bb1aaeeb0850d7ea464" rel="noopener noreferrer" href="https://github.com/gyf304/vmcli"&gt;&lt;span data-key="4efe1c9caa49424fb5a50b3bb0aa6657"&gt;&lt;span data-offset-key="4efe1c9caa49424fb5a50b3bb0aa6657:0"&gt;VMCLI&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="0ba04a4335e348e9acde7e1209653dc5"&gt;&lt;span data-offset-key="0ba04a4335e348e9acde7e1209653dc5:0"&gt; - Set of utilities to help you manage VMs with Virtualization.framework. (&lt;/span&gt;&lt;/span&gt;&lt;a data-key="8fdb4f3d803b4db1bc593f38a3778721" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=25786640"&gt;&lt;span data-key="93088b69865743faba46d9b2ecd24084"&gt;&lt;span data-offset-key="93088b69865743faba46d9b2ecd24084:0"&gt;HN&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="4e6d418379a4480daafdc069cf8a7df1"&gt;&lt;span data-offset-key="4e6d418379a4480daafdc069cf8a7df1:0"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="162c18d523c640e4b38ee03e7cb12df4"&gt;&lt;span&gt;&lt;span data-key="c221e89a6bc443cbbbee69a3ade87d8a"&gt;&lt;span data-offset-key="c221e89a6bc443cbbbee69a3ade87d8a:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="53a41c2944b44cc08a0b34e1e8ca2ee3" rel="noopener noreferrer" href="https://github.com/KevinGutowski/SplitConfigurations"&gt;&lt;span data-key="805d1dfd3c034fcba9fc3f784fd5719a"&gt;&lt;span data-offset-key="805d1dfd3c034fcba9fc3f784fd5719a:0"&gt;SplitConfigurations&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="fcdf2b4f1b27451facfd9b16ca3c8245"&gt;&lt;span data-offset-key="fcdf2b4f1b27451facfd9b16ca3c8245:0"&gt; - Up the basics of a Big Sur app layout. Includes splitview and toolbarItems.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="68712ad283124206929a2fbfa24b035f"&gt;&lt;span&gt;&lt;span data-key="011a3c62e7d44414be15262816040c37"&gt;&lt;span data-offset-key="011a3c62e7d44414be15262816040c37:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="eefec5b5cf844838913ba0b17747458d" rel="noopener noreferrer" href="https://github.com/niw/TinyLinux"&gt;&lt;span data-key="dbfb716868c34d4084b6afd6bc12caa9"&gt;&lt;span data-offset-key="dbfb716868c34d4084b6afd6bc12caa9:0"&gt;TinyLinux&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="5f5bfb750ef84f18bc9a1faa6944dd3d"&gt;&lt;span data-offset-key="5f5bfb750ef84f18bc9a1faa6944dd3d:0"&gt; - Tiny minimum implementation of Virtualization framework to boot Linux.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="f1bf6dcf5e564b18871ab9f451cd8ea3"&gt;&lt;span&gt;&lt;span data-key="cf3d954dc98e47f2bb796562297ceed0"&gt;&lt;span data-offset-key="cf3d954dc98e47f2bb796562297ceed0:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="0c5b6f7f54d9451c9d3e5fdff93ec8d3" rel="noopener noreferrer" href="https://github.com/arandomdev/DyldExtractor"&gt;&lt;span data-key="5be2389763bb48c494e8b07033368068"&gt;&lt;span data-offset-key="5be2389763bb48c494e8b07033368068:0"&gt;DyldExtractor&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="df7e24f7ff074f4aac57a38b74c13b40"&gt;&lt;span data-offset-key="df7e24f7ff074f4aac57a38b74c13b40:0"&gt; - Extract Binaries from Apple's Dyld Shared Cache.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="93618d7ac82a444ba499d9c6b80d4b95"&gt;&lt;span&gt;&lt;span data-key="0df2f4072dda4ae2a7e89c183afa25b0"&gt;&lt;span data-offset-key="0df2f4072dda4ae2a7e89c183afa25b0:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="a022236a550f4ad9ba994f0a3b9dab9b" rel="noopener noreferrer" href="https://github.com/blacktop/ipsw"&gt;&lt;span data-key="e73156f8b376403c84d841eb2b42a512"&gt;&lt;span data-offset-key="e73156f8b376403c84d841eb2b42a512:0"&gt;ipsw&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="45b64c51107340f098b800c8a4929ccf"&gt;&lt;span data-offset-key="45b64c51107340f098b800c8a4929ccf:0"&gt; - iOS/macOS Research Swiss Army Knife. (&lt;/span&gt;&lt;/span&gt;&lt;a data-key="6d696c87b54443fa8ef0a3da6d9b4fe3" rel="noopener noreferrer" href="https://blacktop.github.io/ipsw/"&gt;&lt;span data-key="de72f222003d46cc9e68e5755827813c"&gt;&lt;span data-offset-key="de72f222003d46cc9e68e5755827813c:0"&gt;Web&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="6bbdcfb9b3a841c3a011952a04b2e1f1"&gt;&lt;span data-offset-key="6bbdcfb9b3a841c3a011952a04b2e1f1:0"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;a href="https://wiki.nikitavoloboev.xyz/macos"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Mon, 25 Jan 2021 13:47:29 UT
      </pubDate>
      <guid>
        https://wiki.nikitavoloboev.xyz/macos
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://arxiv.org/pdf/2012.02943.pdf
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;��Q(�o㙍����]h!A DEtS�)
+�ᒎ���A+*�����@ i����p!���1�O	���T{Q#�OR�?����q��!�;�4FN���`�&amp;lt;�3���_�����Lѯ��䳔���ɩ�9*�\�p�7$�&amp;amp;|v�k�E�s}��g���[v����`��sig���Kc��eQy���g0o�e"h��b+�@ ��,��7����ոH�F��~���F{�Op&amp;amp;EC9���9�/އk�y��c�N�b�YXH��%�&amp;amp;k��ܣm�f�i��^Ȅ�k PSwε��O�#h_C�gA��l�����s�&amp;gt;�S�ض-�|��ݻ�ڼ���3�Q���?h`n'JVVv�ԉ:Zԧ"��g����[�w����}�vk�/��s��&amp;amp;�GX���	pA�FÐۯ&amp;gt;��5^Ef�r�9��_u���@�w���K�X����A4o
�Sr�A D���
|��톱�y/g�=���ݥ�0*������Ȕ&amp;lt;�7�[�������u���?'d��M�tuUY�#EB�wm�3�g0��a.6O�5�ںw��œ�\��ekV��l�P��jc�����걽J;���uY��@�0.���x�g�K�B^&amp;gt;ֹ�|t��
��6��9�B�NQB����mR��M5hl-�2Q��Ι���l����(ߨ��)��#L��B����v)ۈBhF�A D���fa��"���'}.V���&amp;lt;�&amp;gt;%Τ�
K�9x�
�%�W�Բ�{��!:'"�4!�����F�!!�22��'&amp;amp;��c�-�ϛ����b�-�O��0R
5�uq������+�hK�)���pZ����a@��������s����&amp;amp;��`�s�gD6�L��7+��H������U2�!�2�#���@���p�`^v���q�q���+Fy~�Ϳ	&amp;gt;:�~
gR���{��"���t��&amp;gt;��m�K�?���9�l���Ֆ�?t����$�����w�S�\a������++�3�4�Tg)O�\�p�g0������{�^�t�K��g��d���k�S
�`T�X��;t�&amp;lt;�����RAEݑ��x���4&amp;gt;��F� ����&amp;lt;�-�ī$Z-.&amp;amp;���`'�����p#&amp;gt;�PLf��G�|���p�E�g��I��0*㔂jsϘ�W,X����P�?�s��!��{+��ުO�D�O"\�cfU)�g0�g�:���`���P/-�wDy�~Jn��Ohb�ڍ[9����|���o�M.ki7��ٺ~y)(OL)�\1���8^��~d��3�k��	H,��l����DG�f)����K��/���`&amp;lt;	�@ �S��7�Fq)���Unw	õ3+K�L
���
S/4VG#m���r`�`Q9!����H����ʏ]+�j�����6̑'X.�:���r����}�?��?�оo^�ya����Έ�zi~������T����-6��cX�=�Z��#��l2��f۽�OLD^ʽ�ƘR��Ť:��x�{ۮ��;��������}�l�����v��Ni+���!%��������������uq��������L
��ھ;����2w�
�����V��5�m�l��K���(�!+��
�&amp;lt;]�~�3����qQ����w��ݿ~���5K���|F�:w
*�E���Oq(�F^-8���Y����0t�ܴ���QSdm��V}�RQC�Q%H`�7Ѓ�����X}&lt;/div&gt;&lt;a href="https://arxiv.org/pdf/2012.02943.pdf"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Mon, 25 Jan 2021 13:57:02 UT
      </pubDate>
      <guid>
        https://arxiv.org/pdf/2012.02943.pdf
      </guid>
    </item>
    <item>
      <title>
        Null References: The Billion Dollar Mistake
      </title>
      <link>
        https://www.infoq.com/presentations/Null-References-The-Billion-Dollar-Mistake-Tony-Hoare/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;
                &lt;article data-type="presentation"&gt;
                    








&lt;p&gt;
	&lt;span&gt;&lt;a title="InfoQ Homepage" href="https://www.infoq.com/?itm_source=infoq&amp;amp;itm_medium=breadcrumbs_feature&amp;amp;itm_campaign=breadcrumbs"&gt;InfoQ Homepage&lt;/a&gt;&lt;/span&gt;
	
		
			
			
                &lt;span&gt;&lt;a title="Presentations" href="https://www.infoq.com/presentations?itm_source=infoq&amp;amp;itm_medium=breadcrumbs_feature&amp;amp;itm_campaign=breadcrumbs"&gt;Presentations&lt;/a&gt;&lt;/span&gt;
            
		
		&lt;span&gt;Null References: The Billion Dollar Mistake&lt;/span&gt;
	
	
    
        
    
&lt;/p&gt;

                    







    

                    










	

                    

                    

                    




                    
                    

                    

                    

                    &lt;div&gt;
                        &lt;h2&gt;Summary&lt;/h2&gt;
                        &lt;p&gt;Tony Hoare introduced Null references in ALGOL W back in 1965 "simply because it was so easy to implement", says Mr. Hoare. He talks about that decision considering it "my billion-dollar mistake".&lt;/p&gt;
                    &lt;/div&gt;

                    &lt;div&gt;
                        &lt;h2&gt;Bio&lt;/h2&gt;
                        &lt;p&gt;Sir Charles Antony Richard Hoare, commonly known as Tony Hoare, is a British computer scientist, probably best known for the development in 1960, at age 26, of Quicksort. He also developed Hoare logic, the formal language Communicating Sequential Processes (CSP), and inspired the Occam programming language.&lt;/p&gt;
                    &lt;/div&gt;
                    &lt;div&gt;
                        &lt;h2&gt;About the conference&lt;/h2&gt;
                        &lt;p&gt;QCon is a conference that is organized by the community, for the community.The result is a high quality conference experience where a tremendous amount of attention and investment has gone into having the best content on the most important topics presented by the leaders in our community. QCon is designed with the technical depth and enterprise focus of interest to technical team leads, architects, and project managers.&lt;/p&gt;
                    &lt;/div&gt;
                    
                        








	&lt;div&gt;
		&lt;h3&gt;INFOQ EVENTS&lt;/h3&gt;
        &lt;ul&gt;
            &lt;li data-col="1/1" data-type="webinar" data-id="infoqLive_transcripts_box"&gt;&lt;a href="https://live.infoq.com/conference/2021/february/?utm_source=infoq&amp;amp;utm_medium=boxwithtranscripts&amp;amp;utm_campaign=infoqlivefebboxtranscripts"&gt;&lt;img alt="Deep-dive into practical ways you can use and integrate observability into your distributed system architecture." src="https://cdn.infoq.com/statics_s1_20210201062907/images/enhancements/eventNotice/infoqlive-btr.jpg"&gt;&lt;/a&gt;
                &lt;span&gt;Feb 16th, 9AM EDT / 3PM CET&lt;/span&gt;
                
                
                &lt;h4&gt;&lt;a href="https://live.infoq.com/conference/2021/february/?utm_source=infoq&amp;amp;utm_medium=boxwithtranscripts&amp;amp;utm_campaign=infoqlivefebboxtranscripts"&gt;Deep-dive into practical ways you can use and integrate observability into your distributed system architecture.&lt;/a&gt;&lt;/h4&gt;
                
                
                
            &lt;/li&gt;
        &lt;/ul&gt;

        
			
			
			
			
            &lt;ul&gt;
                &lt;li data-col="1/1" data-type="webinar"&gt;
                    &lt;a href="https://infoq.link/LD-Webinar-Box-Transcripts"&gt;
                        &lt;img alt="InfoQ Webinar Image" src="https://cdn.infoq.com/statics_s1_20210201062907/images/enhancements/eventNotice/LaunchD-transcripts.jpg"&gt;
                    &lt;/a&gt;
                    &lt;span&gt;February 11th, 2021, 10:00AM PST&lt;/span&gt;
                    
                    
                    &lt;h4&gt;&lt;a href="https://infoq.link/LD-Webinar-Box-Transcripts"&gt;Safe and Sane: Deployment and Launch with Reduced Risks.&lt;/a&gt;&lt;/h4&gt;
                    
                    &lt;p&gt;&lt;a href="https://infoq.link/LD-Webinar-Box-Transcripts"&gt;Presented by: Heidi Waterhouse - Principal Developer Advocate&lt;/a&gt;&lt;/p&gt;

                    
                &lt;/li&gt;
            &lt;/ul&gt;
			
			
			
        
		
				
				
				
				
				
				
			
				
					
						
					
					
					
					
					
					
					
					
						
							
						
						
						
						
					
				
			
		

	&lt;/div&gt;
                    

                    &lt;div id="presentationNotes"&gt;
                                    &lt;h2&gt;Key Takeaways&lt;/h2&gt;

&lt;ul&gt;
	&lt;li&gt;Null references have historically been a bad idea&lt;/li&gt;
	&lt;li&gt;Early compilers provided opt-out switches for run-time checks, at the expense of correctness&lt;/li&gt;
	&lt;li&gt;Programming language designers should be responsible for the errors in programs written in that language&lt;/li&gt;
	&lt;li&gt;Customer requests and markets may not ask for what's good for them; they may need regulation to build the market&lt;/li&gt;
	&lt;li&gt;If the billion dollar mistake was the null pointer, the C gets function is a multi-billion dollar mistake that created the opportunity for malware and viruses to thrive&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Show notes&lt;/h2&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a&gt;00:45&lt;/a&gt; Thesis: historically, null references have been a bad idea.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;02:15&lt;/a&gt; Null references were created in 1964 - how much have they cost? Less or more than a billion dollars?&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;03:20&lt;/a&gt; Whilst we don't know, the amount is probably in the order of an (American) billion - more than a tenth of a billon, less than ten billion.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;History of programming languages&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a&gt;03:35&lt;/a&gt; A little on the history of the idea. Tony started as a programmer with Elliot's [Ed: Elliot Brothers, London Ltd] in 1960, and was asked to design a new programming language.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;04:10&lt;/a&gt; In the library was a 23-page booklet entitled "Report on the international language ALGOL60";, edited by Peter Naur.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;04:30&lt;/a&gt; Used as a basis for the new language, but left out the complicated parts such as "if"; and "then";.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;05:00&lt;/a&gt; Most software was still written in machine code (including the complier).&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;05:25&lt;/a&gt; Most assembly was simple enough to understand that when it went wrong, it could be diagnosed by following through to find out what the fault was.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Towards a high level language&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a&gt;05:40&lt;/a&gt; Using a high level language meant you couldn't step through the machine code.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;05:50&lt;/a&gt; The Elliot's machine had 4096 locations, with a length of 4 7/8 bytes long (39 bits), although other machines had different sizes (IBM's had 36 bits.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;06:30&lt;/a&gt; To shield customers from implementation details, customers were told the errors in terms of the high level programming language, instead of a hexadecimal core dump.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;07:10&lt;/a&gt; In order to implement error messages, an array had a check to verify whether its reference was in the bounds.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;08:00&lt;/a&gt; Adding checks to arrays added space and time to the program; on Tony's first machine it ran at less than 2k operations per second (500 micro seconds per operation, and two such tests for each array bounds).&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;08:40&lt;/a&gt; No undetected array errors, and customers didn't know they could trade off safety for speed.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;09:30&lt;/a&gt; The Java language has, after 30 years, decided to replicate the decision to bounds checking arrays. [Ed: other languages, like Python, handle this as well].&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Record oriented programming&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a&gt;10:20&lt;/a&gt; Introduced the concept of an object, which could be referred to with a pointer.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;10:30&lt;/a&gt; With pointers, it is possible to wreak havoc with the program you are trying to test [Ed: this is the single biggest cause of security failures in modern day code].&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;10:55&lt;/a&gt; If a floating point value or integer is used as a pointer accidentally, and the value it is pointing to is updated, then it will just as likely update the program which may then crash or cause problems now or in the future. [Ed: these days, virtual memory and page mapping takes away some of the problems about editing program code, but these weren't present in the computers of that era.]&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;12:00&lt;/a&gt; As a given, when invoking a function with a pointer required the type of the pointer to be declared.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;13:30&lt;/a&gt; The type of the program can be compile time checked from the static types.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;13:45&lt;/a&gt; Many years later Tony discovered that some of these ideas had been integrated for the first time, although previous examples came from both Doug Rossier's Plex and Simula.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Records avoid subscript errors&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a&gt;14:35&lt;/a&gt; The great thing about record handling is that you don't need to have a subscript error, because you cannot construct a pointer that points to something that doesn't exist, and a whole set of errors cannot occur and do not need to be checked at run-time.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;15:50&lt;/a&gt; Later, we asked the customers whether they wanted the option to be able turn off the type checking in production. It's a bit like wearing a life jacket when you are practicing drills, but then taking it off the ship was sinking. The customers decided to not switch off the type checking.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;17:00&lt;/a&gt; We produced a compiler that would translate Fortran programs to Algol programs. It was a disaster, and no Fortran user would use it.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;18:00&lt;/a&gt; The reason that they couldn't use it was because they couldn't use any of their programs. Within a few milliseconds of running it would come up with a subscript error. The error wasn't wanted as they just wanted the code to run.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Type checking as standard&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a&gt;19:00&lt;/a&gt; Things have changed a bit - mainstream programming languages like Java now have subscript checking as standard, type-checked object oriented programming.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;19:30&lt;/a&gt; And then I went and invented the null pointer. You either have to check every reference, or you risk disaster.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;19:45&lt;/a&gt; Fortran programmers preferred to risk disaster; in fact, experience disaster, rather than check subscripts.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;20:00&lt;/a&gt; I didn't know it a the time, but my friend Edsger Dijkstra thought the null reference was a bad idea. He said:&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;20:20&lt;/a&gt; "If you have a null reference, then every bachelor who you represent in your object structure will seem to be married polyamocursly to the same person Null".&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;20:55&lt;/a&gt; It brings back the same question whether you want to run your code quickly (without checks) or safely (with checks).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Disjoint unions and discrimination test&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a&gt;21:10&lt;/a&gt; I did know there was a solution based on the idea of discrimination of objects belong to a disjoint union class; that is, two sets in which there are no members in common. For example a Vehicle class that has subtypes Car and Bus; the Car may have a luggage carrying capacity property while the Bus has a person carrying capacity. You would then have a discrimination test and do different operations based on whether it was a Bus or a Car.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;23:40&lt;/a&gt; The size of the program grows with the number of discrimination clauses and number of types. This allows null to be represented as a different class, which can then be passed in to functions.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;24:30&lt;/a&gt; The types of the pointer could then be implemented as a union of either a pointer to the null type, or a pointer to the type.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;25:20&lt;/a&gt; This leads to implementation problems; what happens if you assume that a pointer is a Bus but change that pointer to a Car instead?&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;25:55&lt;/a&gt; One of the things you want is to be able to know in a high level language is that when it is created, all of its data structure is initialised. In this case, a null reference can be used to indicate that the data is missing or not known at this time. In fact, it's the only thing that can be assigned if you have a pointer to a particular type.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;26:35&lt;/a&gt; If you don't want to use null, you have to implement a sublanguage for representing how to initialise objects of the right type. If the data structure is a tree-based representation, this is achievable if you create the leaves first because they can be fully created.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;27:10&lt;/a&gt; It isn't possible to create a cyclic structure using this technique; if there's a cycle in the data structure you can start with a null pointer and then assign it once the rest of the cycle has been completed.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Introducing null&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a&gt;27:40&lt;/a&gt; This led me to suggest that the null value is a member of every type, and a null check is required on every use of that reference variable, and it may be perhaps a billion dollar mistake.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;28:00&lt;/a&gt; Modern languages such as C# or Spec# and even Java are introducing the idea of non-null reference parameters, and compile time checking which verifies that they cannot possibly have null values.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;28:50&lt;/a&gt; The issues of overloading and inheritance make it a lot more difficult to do these when null references were originally created.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;29:20&lt;/a&gt; The movement must have been made based on the fact that null references were an expensive mistake.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Programming languages should be responsible for their users&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a&gt;30:20&lt;/a&gt; A programming language designer should be responsible for the mistakes made by programmers using the language. It is a serious activity; not one that should be given to programmers with 9 months experience with assembly; they should have a strong scientific basis, a good deal of ingenuity and invention and control of detail, and a clear objective that the programs written by people using the language would be correct. free of obvious errors and free of syntactical traps.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;31:40&lt;/a&gt; This was the idea that led me to the idea of using proof and formal verification of programs as logical and mathematical models, is a method of conducting research into the design of good programming languages. I wasn't too optimistic in 1969 would actually be using proofs to guarantee correctness of programs.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;32:20&lt;/a&gt; By looking at the programming language and whether programs written would be possible to prove the programs written in the language gives an objective measure of how easy it would be to verify the program later. If the understanding of applying a rule locally has to depend on global knowledge of the program then you haven't done a good job in creating the programming language, and you don't need your customers to tell you that.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;33:30&lt;/a&gt; In fact customers don't tell you - it's very easy to persuade your customers that anything that goes wrong is their fault rather than yours.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;33:40&lt;/a&gt; I rejected that - programming language design is a serious scientific engineering activity, and we should begin to take responsibility for the mistakes that our users make.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Designing for safety&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a&gt;33:55&lt;/a&gt; It's beginning to happen again - the Java programming language and its successors have all used avoidance of error as one of the criteria in the detail ed design of new features of the language, and I'm delighted to give them a great deal of credit for that - but it is only one criteria, and it is only one.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;34:35&lt;/a&gt; The most important criteria is backwards compatibility of everything that has gone before, with the millions or billions lines of code that have been written.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;34:55&lt;/a&gt; Every commercial language has to make concessions for commercial and historical reasons; but gradually, ideas change, programmers get more interested in provable correctness; production techniques, languages, checkers, analytic tools, test case generators and so on that are going to help them get their programs correct.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Safe at any speed?&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a&gt;35:40&lt;/a&gt; The analogy that I draw is with agricultural pollution and vehicle security. When Ralph Nader first started publishing "Unsafe at any speed", what he was saying had no connection with the marketplace - customers were not asking for reliability or safety as one of their vehicles.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;36:20&lt;/a&gt; But gradually, customers started to demand reliability and safety, with the aid of law making and legal constraints requiring basic levels of safety to be included in every vehicle sold.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;36:50&lt;/a&gt; There is a possibility that the marketplace will move the reliability of programs and the language in which they&amp;amp;'re expressed.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;37:15 &lt;/a&gt;For many professional engineers, they do have ideals and do pursue them in preference to not pursuing them whenever the opportunity arises. The commercial imperative that requires greater attention paid to the formal correctness of the programs is the virus.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;37:50&lt;/a&gt; The virus (or malware, or worm) does dreadful things by reaching the parts of the program that it doesn't usually reach. It is no longer applicable to test the cases that are likely to arise, the virus will attack the places that are not likely to arise, and so need just the same level of testing.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;38:35&lt;/a&gt; It forces you to get the while program correct, not just the ones that will be used by customers, the code that will be used by viruses needs to be checked too.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;38:45&lt;/a&gt; And that can't be done by testing, it has to be done by analysis.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;38:55&lt;/a&gt; Analysis of the source code, type-checking techniques are the simplest, but more sophisticated reasoning techniques are being used to high volume code to check that it doesn't contain any naughty things like null reference dereferencing.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Introduction of the virus&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a&gt;39:30&lt;/a&gt; So if I am responsible for a billion dollar mistake; and I bring it up because other designers are much more responsible.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;39:40&lt;/a&gt; The designers of C - one can definitely quantify. The buffer overflow is a direct result of the C language gets fnction that doesn't check the bounds of the string input. That allowed the early viruses to get in by overwriting the return values of the code.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;40:10&lt;/a&gt; These simple viruses taught the world how to write malware. Without this very simple entry point, it is quite possible that nobody would ever have thought to look for the more subtle kind of thing which are now being exploited every day by people who are now motivated, skilled, and whose profession and income it is to write botware, malware.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;40:45&lt;/a&gt; If it hadn't been for the gets routine in C, we might have had no malware.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;40:55&lt;/a&gt; Now one virus - the CodeRed virus - was estimated to have cost the world economy 4 billion dollars, because it brought down all the networks, and the interruption to business and all the ordinary banking, other business was estimated to cost that amount. There was another one later as well.&lt;/li&gt;
	&lt;li&gt;&lt;a&gt;41:30&lt;/a&gt; And that was more than the Millennium bug, which was estimated a little less than 4 billion dollars.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Companies mentioned&lt;/h2&gt;

&lt;ul&gt;
	&lt;li&gt;Elliot Brothers (London) Ltd&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;People mentioned&lt;/h2&gt;

&lt;ul&gt;
	&lt;li&gt;Peter Naur&lt;/li&gt;
	&lt;li&gt;Doug Rossier&lt;/li&gt;
	&lt;li&gt;Edsger Dijkstra&lt;/li&gt;
	&lt;li&gt;Ralph Nader&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Languages mentioned&lt;/h2&gt;

&lt;ul&gt;
	&lt;li&gt;Algol60&lt;/li&gt;
	&lt;li&gt;Occam&lt;/li&gt;
	&lt;li&gt;Plex&lt;/li&gt;
	&lt;li&gt;Simula&lt;/li&gt;
	&lt;li&gt;Fortran&lt;/li&gt;
	&lt;li&gt;C#&lt;/li&gt;
	&lt;li&gt;Spec#&lt;/li&gt;
	&lt;li&gt;C&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Products mentioned&lt;/h2&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href="http://www.webcitation.org/65BW96PjQ"&gt;ACM Turing Award speech&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;See more presentations with show notes&lt;/h2&gt;



                                &lt;/div&gt;

                    &lt;div&gt;
                        &lt;div&gt;
                            &lt;p&gt;Recorded at:&lt;/p&gt;
                            &lt;p&gt;&lt;a href="http://qconsf.com/sf2009/?utm_source=infoq&amp;amp;utm_medium=listing&amp;amp;utm_campaign=listingpresentations"&gt;
                                &lt;img src="https://res.infoq.com/presentations/Null-References-The-Billion-Dollar-Mistake-Tony-Hoare/en/promoimage/qcon_logo3.jpg" alt=""&gt;
                            &lt;/a&gt;
                        &lt;/p&gt;&lt;/div&gt;
                        &lt;p&gt;Aug 25, 2009&lt;/p&gt;
                        
                        
                            
                        
                    &lt;/div&gt;

                    
                    









                    

                    
                    
                    
                    
                    
                        













&lt;ul&gt;
    &lt;li&gt;
        
    &lt;/li&gt;
    
        &lt;li&gt;
            
        &lt;/li&gt;
    
&lt;/ul&gt;

                    
                  &lt;/article&gt;
            &lt;/div&gt;&lt;/div&gt;&lt;a href="https://www.infoq.com/presentations/Null-References-The-Billion-Dollar-Mistake-Tony-Hoare/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 26 Jan 2021 15:36:46 UT
      </pubDate>
      <guid>
        https://www.infoq.com/presentations/Null-References-The-Billion-Dollar-Mistake-Tony-Hoare/
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://www.kalzumeus.com/greatest-hits/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;
            
&lt;p&gt;I’ve written for 16 years, 570 essays, and 2.9 million words and &lt;a href="https://www.kalzumeus.com/wc/"&gt;counting&lt;/a&gt;. You can read a &lt;a href="https://www.kalzumeus.com/start-here-if-youre-new/"&gt;quick intro&lt;/a&gt; or my best work, which I curate below.&lt;/p&gt;

&lt;h2 id="most-popular"&gt;Most Popular&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2012/01/23/salary-negotiation/"&gt;Salary Negotiation&lt;/a&gt; Instrumentally probably the most useful thing I have ever written. Salary negotiation advice, originally written for engineers in a good market but I’m told broadly applicable. According to reports from people this is responsible for ~$9 million a year in marginal improvement to compensation. &lt;strong&gt;Personal favorite.&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2011/10/28/dont-call-yourself-a-programmer/"&gt;Don’t Call Yourself A Programmer, And Other Career Advice&lt;/a&gt;. &amp;nbsp;Career advice for engineers, but widely applicable, or so I’m told. &amp;nbsp;&lt;strong&gt;Personal favorite.&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2011/03/13/some-perspective-on-the-japan-earthquake/"&gt;Some Perspective On The Japanese Earthquake&lt;/a&gt;. &amp;nbsp;My (very personal) take on Japan’s response to disaster management after the Touhoku earthquake in 2011. &amp;nbsp;Got covered in the NYT, Australian ABC, BBC, etc.&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2010/06/17/falsehoods-programmers-believe-about-names/"&gt;Falsehoods Programmers Believe About Names&lt;/a&gt;.&amp;nbsp;I identified a common class of bugs in the design of applications. This spawned something of a &lt;a href="https://github.com/kdeldycke/awesome-falsehood"&gt;genre&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2010/03/20/running-a-software-business-on-5-hours-a-week/"&gt;Running A Software Business on 5 Hours A Week&lt;/a&gt;. &amp;nbsp;Time management and productivity tips. &amp;nbsp;&lt;strong&gt;Personal favorite.&lt;/strong&gt; See also about using &lt;a href="https://www.kalzumeus.com/2009/10/04/work-smarter-not-harder/"&gt;metrics for personal productivity&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2009/09/05/desktop-aps-versus-web-apps/"&gt;Why I’m Done Making Desktop Applications&lt;/a&gt;. &amp;nbsp;&lt;strong&gt;Personal favorite.&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2009/03/07/how-to-successfully-compete-with-open-source-software/"&gt;How To Compete With Open Source&lt;/a&gt;. &amp;nbsp;(&lt;a href="https://www.kalzumeus.com/2009/03/18/competing-with-oss-japanese/"&gt;日本語版&lt;/a&gt;もあります！）&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2009/10/23/the-ie-css-bug-which-cost-me-a-months-salary/"&gt;The IE7 CSS Bug Which Cost Me A Month’s Salary&lt;/a&gt;. &amp;nbsp;It was a learning experience… a very expensive learning experience.&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2010/01/24/startup-seo/"&gt;Strategic SEO for Startups&lt;/a&gt;. &amp;nbsp;&lt;strong&gt;Personal favorite&lt;/strong&gt;, and probably my best “high level” take on SEO strategy for businesses which are not mine. &amp;nbsp;See also &lt;a href="https://www.kalzumeus.com/2010/01/25/followup-questions-for-strategic-seo-for-startups/"&gt;follow-up discussion&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2010/08/25/the-hardest-adjustment-to-self-employment/"&gt;The Hardest Adjustment To Self Employment&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2010/04/20/building-highly-reliable-websites-for-small-companies/"&gt;Building Highly Reliable Websites&lt;/a&gt;. &amp;nbsp;&lt;strong&gt;Personal favorite&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;



&lt;h2 id="marketing"&gt;Marketing&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;In a nutshell:&lt;/strong&gt; Every software company should assign full-time engineers to working on their marketing funnel. Virtually no one does. Most of my largest career wins are shipping relatively simple engineering artifacts (like e.g. automated drip email campaigns) which directly affect funnel math by 3~15%.&lt;/p&gt;

&lt;h3 id="drip-email-campaigns"&gt;Drip email campaigns:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;My most common consulting engagement was delivering a lifecycle email campaign, often for first-time users of the software. This was because it routinely increased conversion by ~15%. Due to &lt;a href="https://stripe.com/atlas/guides/business-of-saas"&gt;SaaS math&lt;/a&gt; that rounds to a 15% increase in enterprise value for one to two weeks of work. (I have a &lt;a href="https://training.kalzumeus.com/lifecycle-emails/"&gt;video course&lt;/a&gt; on this.)&lt;/li&gt;
  &lt;li&gt;Only enough time to write one email? Send all customers on a month-to-month SaaS plan an email offering to upgrade them to the annual plan for a modest discount (10% off or one month free). You can do this in an hour; it routinely gets 20%+ uptake and is great for your cash flow and churn rate. Here’s one &lt;a href="https://gist.github.com/patio11/479cb824173e5458b91b"&gt;annotated example&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id="conversion-optimization"&gt;Conversion Optimization:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;I wrote the book on A/B testing in Rails (if by book one means OSS software). It &lt;a href="https://bjk5.com/post/10171483254/abingo-split-testing-now-on-app-engine-built-for"&gt;was adapted&lt;/a&gt; for Khan Academy’s metrics infrastructure. I used this extensively for testing marketing copy, landing pages, design tweaks, the purchasing page, and in-app funnels.&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2006/07/29/10-minute-tweaks-to-boost-your-conversion/"&gt;Minor tactical conversion tweaks with big results&lt;/a&gt;. &amp;nbsp;Four years later I’m paid to consult with companies you’ve heard of and it is &lt;em&gt;disgusting&lt;/em&gt; how many need to be told some of them. &amp;nbsp;(Big buttons!)&lt;/li&gt;
  &lt;li&gt;How to&amp;nbsp;&lt;a href="https://www.kalzumeus.com/2007/05/14/increase-your-software-sales/"&gt;sell more software&lt;/a&gt;. &amp;nbsp;&lt;strong&gt;Personal favorite&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2009/07/26/practical-conversion-tips-for-selling-software/"&gt;Practical Conversion Tips for Selling Software&lt;/a&gt;. &amp;nbsp;&lt;strong&gt;Personal favorite&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;The importance of always giving the user &lt;a href="https://www.kalzumeus.com/2009/08/01/keeping-the-user-moving-towards-conversion/"&gt;prominent options which advance them towards conversion&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Tips for &lt;a href="https://www.kalzumeus.com/2009/08/06/landing-page-design-tips/"&gt;landing page design&lt;/a&gt;. &amp;nbsp;They worked &lt;a href="https://www.kalzumeus.com/2009/08/09/update-landing-page-redesign-successful/"&gt;pretty decently&lt;/a&gt; for me.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id="adwords"&gt;AdWords:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Early impressions on &lt;a href="https://www.kalzumeus.com/2006/07/19/making-adwords-work-for-you/"&gt;how to be successful with AdWords&lt;/a&gt;. &amp;nbsp;Hilariously, at the time I was very opposed to the Content Network, which is now 90% of my AdWords business.&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2006/07/24/its-ok-to-be-second-best/"&gt;Using Placement Preference to decrease costs&lt;/a&gt;. &amp;nbsp;I don’t do it anymore — Conversion Optimizer is far superior for cost performance.&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2006/08/05/fie-upon-you-ysm/"&gt;Why I don’t use Yahoo Search Marketing&lt;/a&gt;, or whatever it is called these days. &amp;nbsp;Fool me once, bad on you, fool me twice…&lt;/li&gt;
  &lt;li&gt;After being an &lt;a href="https://www.kalzumeus.com/2007/09/25/new-adwords-feature/"&gt;early adopter&lt;/a&gt; of Conversion Optimizer with &lt;a href="https://www.kalzumeus.com/2007/09/28/googles-conversion-optimizer-rocks/"&gt;significant success&lt;/a&gt; I was &lt;a href="https://www.kalzumeus.com/2007/11/24/exploiting-new-niches/"&gt;ranking #3 for it&lt;/a&gt; (under Google itself), which might have been why they &lt;a href="https://www.kalzumeus.com/2008/01/24/google-features-bingo-card-creator/"&gt;did&lt;/a&gt; a &lt;a href="http://www.google.com/adwords/conversionoptimizer/bingocard.html"&gt;case study&lt;/a&gt; with me. &amp;nbsp;It remains my &lt;a href="https://www.kalzumeus.com/2007/11/10/conversion-optimizer-adwords-done-right/"&gt;favorite AdWords feature&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id="measurement"&gt;Measurement:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2006/08/05/peeking-over-your-customers-shoulders/"&gt;Instrumenting a downloadable free trial&lt;/a&gt; to tell what is causing conversions.&lt;/li&gt;
  &lt;li&gt;Using Google Analytics to &lt;a href="https://www.kalzumeus.com/2006/11/16/using-analytics-to-improve-your-web-design/"&gt;see what people are clicking on&lt;/a&gt;. &amp;nbsp;(&lt;a href="http://www.crazyegg.com/"&gt;CrazyEgg &lt;/a&gt;is a &lt;a href="https://www.kalzumeus.com/2007/04/20/crazyegg-vs-google-analytics/"&gt;much better option&lt;/a&gt; in every way.)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id="miscellaneous"&gt;Miscellaneous:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2009/12/31/engineering-your-way-to-marketing-success/"&gt;Engineering Your Way To Marketing Success&lt;/a&gt;. &amp;nbsp;Partially practical tips, partially part of my ongoing campaign to convince programmers that marketing is a worthwhile skill they can’t afford to reflexively dismiss or be terrible at.&lt;/li&gt;
  &lt;li&gt;Why posting on forums to move product at retail is probably a &lt;a href="https://www.kalzumeus.com/2007/05/26/community-oriented-marketing-forums-usenet-mailing-lists-etc/"&gt;waste of your time&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2008/02/06/blogging-as-personal-marketing/"&gt;Blogging as personal marketing&lt;/a&gt;. &amp;nbsp;(I was starting to be the go-to guy for SEO a year and change into my business, when I was 25.)&lt;/li&gt;
  &lt;li&gt;Using &lt;a href="https://www.kalzumeus.com/2010/01/17/wufoo-free-incentivization-cheap-effective-user-surveys/"&gt;incentivized surveys&lt;/a&gt; to get customer feedback. &amp;nbsp;&lt;strong&gt;Personal favorite&lt;/strong&gt;. &amp;nbsp;It taught me &lt;a href="https://www.kalzumeus.com/2010/02/07/what-my-user-survey-taught-me/"&gt;some interesting things&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;



&lt;h2 id="career-advice"&gt;Career Advice&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2011/10/28/dont-call-yourself-a-programmer/"&gt;Don’t Call Yourself A Programmer&lt;/a&gt;. &amp;nbsp;&lt;strong&gt;Personal favorite. &amp;nbsp;&lt;/strong&gt;My advice to young engineers on positioning themselves for current and future career growth.&lt;/li&gt;
  &lt;li&gt;My thoughts on &lt;a href="https://www.kalzumeus.com/2012/01/23/salary-negotiation/"&gt;salary negotiation&lt;/a&gt;, particularly useful for engineers. &lt;strong&gt;Personal favorite.&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;For freelancers/consultants: &lt;a href="https://www.kalzumeus.com/2012/09/17/ramit-sethi-and-patrick-mckenzie-on-getting-your-first-consulting-client/"&gt;how to get your first client&lt;/a&gt; and &lt;a href="https://www.kalzumeus.com/2012/09/21/ramit-sethi-and-patrick-mckenzie-on-why-your-customers-would-be-happier-if-you-charged-more/"&gt;how to set prices&lt;/a&gt; (interviews conducted with Ramit Sethi).&lt;/li&gt;
&lt;/ul&gt;



&lt;h2 id="weird-hobbies"&gt;Weird Hobbies&lt;/h2&gt;

&lt;p&gt;I have some weird hobbies. Some people have, probably justly, accused me of having a hobby of having weird hobbies. Occasionally I write what I learn from them:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;I used to ghostwrite letters to banks to resolve consumer credit problems, which prepared me very well for when Equifax had their data security breach. Writeup: &lt;a href="https://www.kalzumeus.com/2017/09/09/identity-theft-credit-reports/"&gt;Identity, Credit Reports, and You&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;I researched and wrote about the economics of the discount brokerage industry. &lt;a href="https://www.kalzumeus.com/2019/6/26/how-brokerages-make-money/"&gt;How Discount Brokerages Make Money&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;



&lt;h2 id="conference-talks"&gt;Conference Talks&lt;/h2&gt;

&lt;p&gt;I present at conferences about 4~5 times a year, and generally request that the talk be made available after the conference.&lt;/p&gt;

&lt;p&gt;I’ve spoken at &lt;a href="https://www.microconf.com/"&gt;Microconf&lt;/a&gt; almost every year and consider that community my home-away-from-home. You should absolutely attend if you are at all interested in running a software business.&lt;/p&gt;

&lt;p&gt;MicroConf recommends my talks in &lt;a href="https://www.youtube.com/watch?v=acVvumkWVLU&amp;amp;list=PLwcQbu9cKWclhn8JCryvm3GHpK8w7fb2q"&gt;this order&lt;/a&gt;, but chronologically works best for some people so:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;2011: A Software Business on 5 Hours a Week (not recorded, but I have &lt;a href="https://speakerdeck.com/patio11/a-software-business-on-5-hours-a-week"&gt;the slides&lt;/a&gt;)&lt;/li&gt;
  &lt;li&gt;2012: &lt;a href="https://www.youtube.com/watch?v=N6V-cytrvvQ"&gt;How to Engineer Marketing Success&lt;/a&gt;. Explains some of my common tactics, and broader mindset, on building engineering artifacts to influence marketing / sales outcomes.&lt;/li&gt;
  &lt;li&gt;2013: &lt;a href="https://www.youtube.com/watch?v=acVvumkWVLU"&gt;Building Things to Help You Sell the Things You Build&lt;/a&gt;, again on the mechanics of engineering sales and marketing.&lt;/li&gt;
  &lt;li&gt;2014: I’ve always said that the only thing that could keep me away from Microconf was the birth of a child. In 2014, we were blessed by the birth of our daughter Lillian.&lt;/li&gt;
  &lt;li&gt;2015: &lt;a href="https://www.youtube.com/watch?v=-Tg48MVnBeQ"&gt;Leveling Up&lt;/a&gt;, on how entrepreneurship effectively has a career ladder, where what you learn doing one company can be used to help jumpstart the next. &lt;a href="https://speakerdeck.com/patio11/leveling-up"&gt;Slides&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;2016: I attended Microconf but was hip-deep in Starfighter and didn’t present.&lt;/li&gt;
  &lt;li&gt;2017: &lt;a href="https://www.youtube.com/watch?v=_h8IhbR2Iqk"&gt;Paint by Numbers: From Productized Consulting to SaaS&lt;/a&gt;. This is the glide path for bootstrapping a software business off of a consulting/infoproduct sort of offering, and helps you avoid the long slow SaaS ramp of death. &lt;a href="https://speakerdeck.com/patio11/paint-by-numbers-from-productized-service-to-saas"&gt;Slides&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;2018: &lt;a href="https://www.youtube.com/watch?v=PtmUJye7t4c"&gt;Your First 60 Days&lt;/a&gt;, on booting up a new Internet business. Covers marketing from a cold start, how to prioritize product development and other tasks, and what the minimum viable backoffice work is. &lt;a href="https://speakerdeck.com/patio11/your-first-60-days"&gt;Slides&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;2019: &lt;a href="https://www.youtube.com/watch?v=cIoC97CJGtw"&gt;The Ethos of MicroConf&lt;/a&gt;, a bit of a personal reflection on life and business. &lt;a href=""&gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I also periodically speak at other conferences, on a potpurri of topics. You can find many of my presentations on &lt;a href="https://www.slideshare.com/patio11"&gt;Slideshare&lt;/a&gt; or &lt;a href="https://speakerdeck.com/patio11"&gt;SpeakerDeck&lt;/a&gt;.&lt;/p&gt;



&lt;h2 id="podcast"&gt;Podcast&lt;/h2&gt;

&lt;p&gt;I am a frequent &lt;a href="https://www.listennotes.com/search/?q=%22patrick%20mckenzie%22&amp;amp;sort_by_date=0&amp;amp;scope=episode&amp;amp;offset=0&amp;amp;language=Any%20language&amp;amp;len_min=0"&gt;guest&lt;/a&gt; on podcasts.&lt;/p&gt;

&lt;p&gt;I also occasionally host &lt;a href="https://www.kalzumeus.com/podcast/"&gt;my own podcast&lt;/a&gt;. Some recent episodes:&lt;/p&gt;

&lt;ul&gt;
  
    &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2017/05/10/kalzumeus-podcast-episode-14-running-a-business-portfolio-with-jonathan-siegel/"&gt;Kalzumeus Podcast Episode 14: Running A Business Portfolio with Jonathan Siegel&lt;/a&gt;&lt;/li&gt;
  
    &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2016/08/26/kalzumeus-podcast-episode-13-selling-online-businesses-with-thomas-smale/"&gt;Kalzumeus Podcast Episode 13: Selling Online Businesses With Thomas Smale&lt;/a&gt;&lt;/li&gt;
  
    &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2016/06/03/kalzumeus-podcast-episode-12-salary-negotiation-with-josh-doody/"&gt;Kalzumeus Podcast Episode 12: Salary Negotiation with Josh Doody&lt;/a&gt;&lt;/li&gt;
  
&lt;/ul&gt;



&lt;h2 id="videos"&gt;Videos&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Andrew Warner &lt;a href="http://mixergy.com/patrick-mckenzie-interview/"&gt;interviewed me&lt;/a&gt; on &lt;a href="http://www.mixergy.com/"&gt;Mixergy&lt;/a&gt;. &amp;nbsp;(About one hour, comes with transcript half-written by me.) &amp;nbsp;Andrew is, by the way, the best interviewer in technology today. &amp;nbsp;You cannot do better than some of the insights he teases out of guests, and he has a wonderful way of making people so comfortable they forget to not answer the tough questions he slides in there.&lt;/li&gt;
  &lt;li&gt;Gabriel Weinberg &lt;a href="http://www.gabrielweinberg.com/blog/2010/04/patrick-mckenzie-on-seo-adwords-for-bingo-card-creator.html"&gt;interviewed me&lt;/a&gt; with specific regards to SEO, mini-sites, and conversion optimization. &amp;nbsp;(About one hour, comes with transcript written by me.)&lt;/li&gt;
  &lt;li&gt;I did a 7.5 minute lightning talk on &lt;a href="https://www.kalzumeus.com/2011/03/26/software-for-underserved-markets/"&gt;selling software to underserved markets&lt;/a&gt; at Business of Software 2010.&lt;/li&gt;
  &lt;li&gt;I spoke on &lt;a href="https://www.kalzumeus.com/2011/12/19/productizing-twilio-applications/"&gt;Productizing Twilio Applications&lt;/a&gt; at TwilioConf 2011.&lt;/li&gt;
  &lt;li&gt;Google brought me in to do a tech talk about &lt;a href="http://www.youtube.com/watch?v=sFWlmEO6eg0"&gt;What Engineers Don’t Know We Know About Marketing&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;



&lt;h2 id="seo"&gt;SEO&lt;/h2&gt;

&lt;h3 id="content-creation"&gt;Content Creation:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Before launch (July 1, 2006) I had a &lt;a href="https://www.kalzumeus.com/2006/06/29/from-visitor-to-downloader-to-purchaser/"&gt;rough cut&lt;/a&gt; of my content creation strategy and figured out there would be &lt;a href="https://www.kalzumeus.com/2006/06/30/unexpected-expenditure-great-marketing-idea/"&gt;seasonal elements to it&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Right after launch, I stumbled on what turned into my &lt;a href="https://www.kalzumeus.com/2006/07/04/optimized-landing-page-1/"&gt;first major SEO opportunity&lt;/a&gt;: Dolch Sight Words. &amp;nbsp;This &lt;a href="https://www.kalzumeus.com/2006/08/31/how-much-content-does-your-website-have/"&gt;started working&lt;/a&gt; rather quickly (was my main source of sales for almost a year), both for traffic and for &lt;a href="https://www.kalzumeus.com/2007/02/07/google-finally-lets-you-see-backlinks/"&gt;backlinks&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Optimizing your website for &lt;a href="https://www.kalzumeus.com/2007/05/30/ranking-for-an-arbitrary-organic-search-query/"&gt;snowflake queries&lt;/a&gt;: the ones Google only sees once. &amp;nbsp;This eventually formed the core of my content creation strategy: as many pages as possible, each targeted at one specific, narrow interest.&lt;/li&gt;
  &lt;li&gt;&lt;span&gt;&lt;strong&gt;Most recommended series&lt;/strong&gt;&lt;/span&gt;: After seeing the results of doing content creation by hand in notepad, I started trying to &lt;a href="https://www.kalzumeus.com/2007/10/21/developing-linkbait-for-a-non-technical-audience/"&gt;scale it up&lt;/a&gt; using Rails and get the content &lt;a href="https://www.kalzumeus.com/2007/10/03/before-i-try-rentacoder/"&gt;written by freelancers&lt;/a&gt;. &amp;nbsp;This ended up getting &lt;a href="https://www.kalzumeus.com/2007/11/05/october-2007-stats-2000-in-sales/"&gt;early positive results&lt;/a&gt; and eventually virtually taking over the business (now accounting for some 50% of sales and 75% of profits, give or take). &amp;nbsp;I eventually distilled this strategy into a &lt;a href="https://www.kalzumeus.com/2010/07/17/seo-for-software-companies/"&gt;presentation on SEO for software companies&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2007/11/18/putting-the-green-in-evergreen/"&gt;Using evergreen content&lt;/a&gt; (that which is perpetually useful to consistent, unchanging needs of your customers) to make sales. &amp;nbsp;(Note: anti-pattern of a 10 year old blog post outranking product site happens frequently in consulting!) &amp;nbsp;My little brother busy trying to break into &lt;a href="http://www.superheronation.com/"&gt;comic book writing advice&lt;/a&gt; also has &lt;a href="https://www.kalzumeus.com/2008/03/20/insights-on-blog-optimization/"&gt;thoughts&lt;/a&gt; on this &lt;a href="http://www.superheronation.com/2008/03/20/new-years-resolution-madness-assessing-bounce-rates-in-online-novels/#more-574"&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id="mini-sites"&gt;Mini-sites:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;I had a variety of &lt;a href="https://www.kalzumeus.com/2008/12/13/learning-from-a-specific-example-of-failure/"&gt;mini-sites&lt;/a&gt; focused on my best performing single pieces of content, beginning with an &lt;a href="https://www.kalzumeus.com/2008/11/24/christmas-bingo-boards/"&gt;experimental one&lt;/a&gt; for Christmas back in 2008. They tended to work &lt;em&gt;exceptionally well&lt;/em&gt; in their second and third years. This is &lt;strong&gt;probably not&lt;/strong&gt; worth doing anymore since SEO changes over time.&lt;/li&gt;
  &lt;li&gt;Relatedly, I wrote up some tips on &lt;a href="https://www.kalzumeus.com/2009/10/14/holiday-promotion/"&gt;how to do holiday promotions&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id="link-building"&gt;Link Building:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;See everything I write about content creation, as they’re deeply entwined for me.&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2008/04/08/linkbuilding-for-small-businesses/"&gt;Tactics and strategy&lt;/a&gt; for more effective link building.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id="on-page-seo"&gt;On Page SEO:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;An early take on &lt;a href="https://www.kalzumeus.com/2006/07/29/on-page-seo-for-small-companies/"&gt;on-page optimizations&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id="miscellaneous-1"&gt;Miscellaneous&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;It took &lt;a href="https://www.kalzumeus.com/2006/07/04/day-11-first-page-of-google/"&gt;11 days&lt;/a&gt; to rank for my product name and &lt;a href="https://www.kalzumeus.com/2006/07/29/legitimate-organic-searches-eclipse-ppc/"&gt;a month&lt;/a&gt; until organic SEO eclipsed PPC as a source of traffic for me.&lt;/li&gt;
  &lt;li&gt;Coding for &lt;a href="http://www.bingocardcreator.com/articles/rails-seo-tips.htm"&gt;SEO on Rails&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;I tried &lt;a href="https://www.kalzumeus.com/2006/09/23/text-link-ads/"&gt;buying links&lt;/a&gt; when I was young and stupid (slightly before Google came down hard on the practice). &amp;nbsp;It didn’t work out well.&lt;/li&gt;
  &lt;li&gt;Put your blog in a &lt;a href="https://www.kalzumeus.com/2006/10/02/object-lesson-on-blogging-for-your-business/"&gt;subdirectory of the product domain&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;The right way to do a &lt;a href="https://www.kalzumeus.com/2007/05/27/how-to-rename-a-web-page/"&gt;301 redirect&lt;/a&gt; in Apache.&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2008/01/28/why-you-shouldnt-pay-any-seo-you-can-afford/"&gt;Why I don’t recommend hiring SEO consultants&lt;/a&gt;. &amp;nbsp;&lt;strong&gt;Personal favorite&lt;/strong&gt;. &amp;nbsp;(Ironic, since I have worked as one.)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id="tough-to-categorize-but-still-useful"&gt;Tough To Categorize But Still Useful&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Why I don’t write any &lt;a href="https://www.kalzumeus.com/2006/08/13/ten-reasons-why-most-internet-writing-is-terrible/"&gt;Top Ten Ways To Sell A Widget&lt;/a&gt; articles. &amp;nbsp;&lt;strong&gt;Personal favorite.&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2010/08/19/dealing-with-market-seasonality/"&gt;Dealing with market seasonality&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;



&lt;ul&gt;
  &lt;li&gt;Year in Review Posts: &lt;a href="https://www.kalzumeus.com/2006/12/26/merry-christmas-part-2/"&gt;2006&lt;/a&gt;, &lt;a href="https://www.kalzumeus.com/2008/01/13/year-2007-stats-and-year-2008-goals/"&gt;2007&lt;/a&gt;, &lt;a href="https://www.kalzumeus.com/2008/12/21/bingo-card-creator-year-2008-in-review/"&gt;2008&lt;/a&gt;, &lt;a href="https://www.kalzumeus.com/2009/12/18/bingo-card-creator-year-in-review-2009/"&gt;2009&lt;/a&gt;, &lt;a href="https://www.kalzumeus.com/2010/12/17/bingo-card-creator-etc-year-in-review-2010/"&gt;2010&lt;/a&gt;, &lt;a href="https://www.kalzumeus.com/2011/12/21/bingo-card-creator-etc-year-in-review-2011/"&gt;2011&lt;/a&gt;, &lt;a href="https://www.kalzumeus.com/2012/12/29/bingo-card-creator-and-other-stuff-year-in-review-2012/"&gt;2012&lt;/a&gt;, &lt;a href="https://www.kalzumeus.com/2014/01/06/kalzumeus-software-year-in-review-2013/"&gt;2013&lt;/a&gt;, &lt;a href="https://www.kalzumeus.com/2014/12/22/kalzumeus-software-year-in-review-2014/"&gt;2014&lt;/a&gt;, 2015 (skipped), and &lt;a href="https://www.kalzumeus.com/2016/12/30/kalzumeus-software-year-in-review-2016/"&gt;2016&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Since late 2016 I’ve been &lt;a href="https://www.kalzumeus.com/2019/3/18/two-years-at-stripe/"&gt;working at Stripe&lt;/a&gt;. (I can’t show you our stats unless you &lt;a href="https://stripe.com/jobs"&gt;come work with us on growing the GDP of the Internet.&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;


          &lt;/div&gt;&lt;/div&gt;&lt;a href="https://www.kalzumeus.com/greatest-hits/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Mon, 1 Feb 2021 12:19:32 UT
      </pubDate>
      <guid>
        https://www.kalzumeus.com/greatest-hits/
      </guid>
    </item>
    <item>
      <title>
        mtlynch.io
      </title>
      <link>
        https://mtlynch.io/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;
    &lt;p&gt;I'm Michael Lynch, software developer and blogger. I used to work as a software engineer at large companies, but now I run small software businesses of my own and blog about the process.&lt;/p&gt;

    &lt;div&gt;
      &lt;div&gt;
        &lt;h2&gt;Most Popular Articles&lt;/h2&gt;

        &lt;ul&gt;
          &lt;li&gt;&lt;a href="https://mtlynch.io/why-i-quit-google/"&gt;Why I Quit Google to Work for Myself&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href="https://mtlynch.io/tinypilot/"&gt;TinyPilot: Build a KVM Over IP for Under $100&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href="https://mtlynch.io/stole-siacoins/"&gt;How I Stole Your Siacoin&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href="https://mtlynch.io/solo-developer-year-2/"&gt;My Second Year as a Solo Developer&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/div&gt;

      &lt;div&gt;
        &lt;h2&gt;Articles about Software Development&lt;/h2&gt;

        &lt;ul&gt;
          &lt;li&gt;&lt;a href="https://mtlynch.io/code-review-love/"&gt;How to Make Your Code Reviewer Fall in Love with You&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href="https://mtlynch.io/human-code-reviews-1/"&gt;How to Do Code Reviews Like a Human&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href="https://mtlynch.io/good-developers-bad-tests/"&gt;Why Good Developers Write Bad Unit Tests&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href="https://mtlynch.io/painless-web-app-testing/"&gt;End-to-End Testing Web Apps: The Painless Way&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/div&gt;

      &lt;div&gt;
        &lt;h2&gt;Articles about Blogging&lt;/h2&gt;

        &lt;ul&gt;
          &lt;li&gt;&lt;a href="https://mtlynch.io/editor/"&gt;How I Hired a Freelance Editor for My Blog&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href="https://mtlynch.io/how-to-hire-a-cartoonist/"&gt;How to Hire a Cartoonist to Make Your Blog Less Boring&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href="https://mtlynch.io/hiring-content-writers/"&gt;Hiring Content Writers: A Guide for Small Businesses&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/div&gt;

      

    &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;&lt;a href="https://mtlynch.io/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Mon, 1 Feb 2021 12:22:45 UT
      </pubDate>
      <guid>
        https://mtlynch.io/
      </guid>
    </item>
    <item>
      <title>
        Structured Procrastination
      </title>
      <link>
        https://jblevins.org/log/structured-procrastination
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div id="content"&gt;
  &lt;article&gt;

    &lt;header&gt;
      &lt;h2&gt;&lt;a title="Permanent link to 'Structured Procrastination'" href="https://jblevins.org/log/structured-procrastination"&gt;Structured Procrastination&lt;/a&gt;&lt;/h2&gt;
      &lt;p&gt;February 10, 2007&lt;/p&gt;
    &lt;/header&gt;

&lt;p&gt;Every professional procrastinator knows that when a big project deadline
looms in the near future, the time is ripe to work on some &lt;em&gt;other&lt;/em&gt; project
instead. It usually involves something at least marginally productive, such
as cleaning the house, or it might involve starting some entirely new
project. My bouts of procrastination usually result in the latter and then I
have yet another open project that lingers unfinished.&lt;/p&gt;



&lt;p&gt;I used to try to fight the urge to procrastinate directly, but I am beginning
to believe that the key is not to combat it outright, but to harness it. I
know many very bright and productive people who procrastinate just as much as
anyone else. In fact, academia is rife with procrastinators yet still
manages to plod along somehow. For example, a 1980 article by Gary W. Yohe
figures the average time to publication of an article submitted to
&lt;em&gt;Econometrica&lt;/em&gt;, a top Economics journal, to be 25.9 months. One explanation
is that top journals simply examine submitted articles more carefully.
Another perhaps more likely reason is that journal referees and editors are
procrastinators.&lt;/p&gt;

&lt;p&gt;The key to harnessing one’s procrastination is to recognize it and channel it
away from the marginally productive activities into more highly productive
ones. This is the essence of &lt;a href="http://www.structuredprocrastination.com/"&gt;Structured Procrastination&lt;/a&gt;, as described in
an essay by by John Perry. His first paragraph is an excellent summary:&lt;/p&gt;

&lt;blockquote title="John Perry, Structured Procrastination" cite="http://www.structuredprocrastination.com"&gt;
&lt;p&gt;I have been intending to write this essay for months. Why am I finally doing
it? Because I finally found some uncommitted time? Wrong. I have papers to
grade, textbook orders to fill out, an NSF proposal to referee, dissertation
drafts to read. I am working on this essay as a way of not doing all of those
things. This is the essence of what I call structured procrastination, an
amazing strategy I have discovered that converts procrastinators into effective
human beings, respected and admired for all that they can accomplish and the
good use they make of time.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3&gt;References&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Perry, John. “Structured Procrastination”,
 &lt;code&gt;&lt;a href="http://www.structuredprocrastination.com/"&gt;
 http://www.structuredprocrastination.com&lt;/a&gt;&lt;/code&gt;,
 April 25 1995, retrieved on February 10, 2007.&lt;/li&gt;
&lt;li&gt;Yohe, Gary W. (1980): “Current Publication Lags in Economics Journals”,
 &lt;em&gt;Journal of Economic Literature&lt;/em&gt;, 18, 1050–1055.&lt;/li&gt;
&lt;/ul&gt;


    

  &lt;/article&gt;

&lt;/div&gt;&lt;/div&gt;&lt;a href="https://jblevins.org/log/structured-procrastination"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 2 Feb 2021 13:33:33 UT
      </pubDate>
      <guid>
        https://jblevins.org/log/structured-procrastination
      </guid>
    </item>
    <item>
      <title>
        In Praise of Low-Fidelity
      </title>
      <link>
        https://jblevins.org/log/lofi
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div id="content"&gt;
  &lt;article&gt;

    &lt;header&gt;
      &lt;h2&gt;&lt;a title="Permanent link to 'In Praise of Low-Fidelity'" href="https://jblevins.org/log/lofi"&gt;In Praise of Low-Fidelity&lt;/a&gt;&lt;/h2&gt;
      &lt;p&gt;February 5, 2006&lt;/p&gt;
    &lt;/header&gt;

&lt;p&gt;I believe in simplification. I strongly support technology and
innovation, but I believe more strongly in choosing the best tool for any
task. Simplicity can of course result from the application of technology but
many times, the best tool happens to be the “low-fidelity” one. Expensive
high-tech gadgets that promise to make you more efficient will probably do
the opposite. Most of the time a notebook and pen will do. For example,
those nifty special effects in PowerPoint that took an hour of tweaking only
serve to detract your audience from your content in the end. On the other
hand, my razor, my iPod, and my compact, lightweight titanium-frame umbrella,
all very simple, elegant, and useful, were all possible only because of
technology.&lt;/p&gt;

&lt;p&gt;I think that technology has a tendency to overstimulate and overextend us,
but I am by no means a Luddite. Innovation is essential, even if only to help
us realize that some previous solution worked better. Word processors with
lots of bells and whistles are great for certain tasks, but despite 40 years
of advances in computer technology, the plain text file has survived. It is
used for its own purposes, it constitutes the source code of complicated
computer programs, and supports the publication of the most thought-provoking
new books. Windows was a major catalyst to the computer revolution, but it’s
complexity, bulkiness, and closed nature was in turn a catalyst to a Unix
revolution in favor of openness, flexibility, and simplicity.&lt;/p&gt;

&lt;p&gt;I believe that if you’re not pushing your limits, you’re wasting time, but if
you push through the present without enjoying what you’ve done, there will be
no time left to waste. This is where the low-fidelity approach is useful.
There is a certain pleasure in listening to the radio instead of watching
television, in writing a letter instead of an email, or in taking a walk
instead of driving, and it helps keep you grounded in the present while keeping your
mind clear for looking ahead. There are also possible efficiency gains. I
can listen to NPR while driving or making breakfast, and I spare myself from
an onslaught of advertisements in the process.&lt;/p&gt;

&lt;p&gt;Thus, the low-fidelity approach is the selective application of the simplest,
most efficient tool available, whether it involves the newest technology on
the market or just some old-fashioned practicality.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I wasted time, and now doth time waste me.&lt;/p&gt;

&lt;p&gt;&lt;cite&gt;William Shakespeare, Richard II&lt;/cite&gt;&lt;/p&gt;
&lt;/blockquote&gt;






    

  &lt;/article&gt;

&lt;/div&gt;&lt;/div&gt;&lt;a href="https://jblevins.org/log/lofi"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 2 Feb 2021 13:33:39 UT
      </pubDate>
      <guid>
        https://jblevins.org/log/lofi
      </guid>
    </item>
    <item>
      <title>
        cron is dead, long live launchd! - Selected Thoughts
      </title>
      <link>
        https://blog.jan-ahrens.eu/2017/01/13/cron-is-dead-long-live-launchd.html
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div role="main" id="main"&gt;
  
  



  &lt;article class="page"&gt;
    
    
    
    

    &lt;div&gt;
      
        &lt;header&gt;
          
          

  &lt;p&gt;
    

    

    
      
      

      &lt;span&gt;
        
        
          1 minute read
        
      &lt;/span&gt;
    
  &lt;/p&gt;


        &lt;/header&gt;
      

      &lt;section&gt;
        
        &lt;p&gt;Now that I finally created my &lt;a href="https://tarsnap.com/"&gt;tarsnap&lt;/a&gt; backup script, how
do I execute it regularly? Oh, I know: My Mac is just an Unix system, I’ll use
cron!&lt;/p&gt;

&lt;p&gt;At least that’s what I thought I’ll do. After a few attempts to get cron to do
the job, I learned that there’s a better way on macOS:
&lt;a href="https://en.wikipedia.org/wiki/Launchd"&gt;launchd&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;launchd does a lot more than executing scripts cron-style. Like
&lt;a href="https://en.wikipedia.org/wiki/Systemd"&gt;systemd&lt;/a&gt; on Linux, launchd is a
replacement for a lot of old school Unix tools, like cron, inetd, init,
&lt;a href="https://en.wikipedia.org/wiki/Launchd#History"&gt;etc&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;At it’s core, launchd distincts daemons and agents. Dameons are processes that
always run in the background, while agents describe regular jobs that are to be
executed on certain events. There are a lot of different events to choose from.
For example you can trigger an agent, when a device gets mounted, when a file
gets created, or when a certain time arrives.&lt;/p&gt;

&lt;p&gt;What really helped me in learning how to write my first launchd agent was
&lt;a href="http://www.launchd.info/"&gt;launchd.info&lt;/a&gt;. Unlike the &lt;a href="https://developer.apple.com/library/content/documentation/MacOSX/Conceptual/BPSystemStartup/Chapters/CreatingLaunchdJobs.html"&gt;Apple
documentation&lt;/a&gt;,
it contains useful snippets and concise explanations. I highly recommend that
you also have a look at the launchd agents that some of your applications put into
&lt;code&gt;~/Library/LaunchAgents&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Below you can see the agent that I ended up creating. You can learn how to
load/unload agents and about the meaning of the different options at
&lt;a href="http://www.launchd.info/"&gt;launchd.info&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;If you’re testing your script and you don’t want to wait for the next hour to
arrive, you can start it immediately with &lt;code&gt;launchctl start
eu.jan-ahrens.tarsnap&lt;/code&gt;.&lt;/p&gt;

&lt;div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;?xml version="1.0" encoding="UTF-8"?&amp;gt;
&amp;lt;!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd"&amp;gt;
&amp;lt;plist version="1.0"&amp;gt;
&amp;lt;dict&amp;gt;
    &amp;lt;key&amp;gt;Label&amp;lt;/key&amp;gt;
    &amp;lt;string&amp;gt;eu.jan-ahrens.tarsnap&amp;lt;/string&amp;gt;
	&amp;lt;key&amp;gt;EnvironmentVariables&amp;lt;/key&amp;gt;
	&amp;lt;dict&amp;gt;
		&amp;lt;key&amp;gt;PATH&amp;lt;/key&amp;gt;
		&amp;lt;string&amp;gt;/bin:/usr/bin:/usr/local/bin&amp;lt;/string&amp;gt;
	&amp;lt;/dict&amp;gt;
    &amp;lt;key&amp;gt;ProgramArguments&amp;lt;/key&amp;gt;
    &amp;lt;array&amp;gt;
	&amp;lt;string&amp;gt;/bin/bash&amp;lt;/string&amp;gt;
	&amp;lt;string&amp;gt;/Users/jan/bin/run-tarsnap-backup&amp;lt;/string&amp;gt;
    &amp;lt;/array&amp;gt;
    &amp;lt;key&amp;gt;StartInterval&amp;lt;/key&amp;gt;
    &amp;lt;integer&amp;gt;3600&amp;lt;/integer&amp;gt;
    &amp;lt;key&amp;gt;StandardOutPath&amp;lt;/key&amp;gt;
    &amp;lt;string&amp;gt;/Users/jan/.tarsnap.log&amp;lt;/string&amp;gt;
    &amp;lt;key&amp;gt;StandardErrorPath&amp;lt;/key&amp;gt;
    &amp;lt;string&amp;gt;/Users/jan/.tarsnap.log&amp;lt;/string&amp;gt;
    &amp;lt;key&amp;gt;KeepAlive&amp;lt;/key&amp;gt;
    &amp;lt;dict&amp;gt;
	&amp;lt;key&amp;gt;NetworkState&amp;lt;/key&amp;gt;
	&amp;lt;true/&amp;gt;
     &amp;lt;/dict&amp;gt;
    &amp;lt;key&amp;gt;ExitTimeout&amp;lt;/key&amp;gt;
    &amp;lt;integer&amp;gt;900&amp;lt;/integer&amp;gt;
    &amp;lt;key&amp;gt;Nice&amp;lt;/key&amp;gt;
    &amp;lt;integer&amp;gt;10&amp;lt;/integer&amp;gt;
&amp;lt;/dict&amp;gt;
&amp;lt;/plist&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;P.S.: cron itself is implemented as a launchd daemon. You can find it at &lt;code&gt;/System/Library/LaunchDaemons/com.vix.cron.plist&lt;/code&gt;.&lt;/p&gt;

        
      &lt;/section&gt;

      

      

      
  

    &lt;/div&gt;

    
  &lt;/article&gt;

  
  
&lt;/div&gt;&lt;/div&gt;&lt;a href="https://blog.jan-ahrens.eu/2017/01/13/cron-is-dead-long-live-launchd.html"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Wed, 3 Feb 2021 10:12:31 UT
      </pubDate>
      <guid>
        https://blog.jan-ahrens.eu/2017/01/13/cron-is-dead-long-live-launchd.html
      </guid>
    </item>
  </channel>
</rss>