
<rss version="2.0">
  <channel>
    <title>
      Reading List
    </title>
    <link>
      https://samuelstevens.me/readinglist.xml
    </link>
    <description>
      My personal reading list
    </description>
    <language>
      en-us
    </language>
    <pubDate>
      Wed, 10 Feb 2021 10:15:04 UT
    </pubDate>
    <lastBuildDate>
      Wed, 10 Feb 2021 10:15:04 UT
    </lastBuildDate>
    <docs>
      https://cyber.harvard.edu/rss/rss.html
    </docs>
    <generator>
      samuelstevens/racket-rss
    </generator>
    <managingEditor>
      samuel.robert.stevens@gmail.com
    </managingEditor>
    <webMaster>
      samuel.robert.stevens@gmail.com
    </webMaster>
    <item>
      <title>
        Execute Program
      </title>
      <link>
        https://www.executeprogram.com/
      </link>
      <description>
        &lt;a href="https://www.executeprogram.com/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:18:12 UT
      </pubDate>
      <guid>
        https://www.executeprogram.com/
      </guid>
    </item>
    <item>
      <title>
        Markov Chains
      </title>
      <link>
        https://setosa.io/blog/2014/07/26/markov-chains/index.html
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt; &lt;p&gt;Markov chains, named after &lt;a href="https://en.wikipedia.org/wiki/Andrey_Markov"&gt;Andrey Markov&lt;/a&gt;, are mathematical systems that hop from one "state" (a situation or set of values) to another. For example, if you made a Markov chain model of a baby's behavior, you might include "playing," "eating", "sleeping," and "crying" as states, which together with other behaviors could form a 'state space': a list of all possible states. In addition, on top of the state space, a Markov chain tells you the probabilitiy of hopping, or "transitioning," from one state to any other state---e.g., the chance that a baby currently playing will fall asleep in the next five minutes without crying first.&lt;/p&gt; &lt;p&gt;A simple, two-state Markov chain is shown below.&lt;/p&gt; &lt;p&gt;With two states (A and B) in our state space, there are 4 possible transitions (not 2, because a state can transition back into itself). If we're at 'A' we could transition to 'B' or stay at 'A'. If we're at 'B' we could transition to 'A' or stay at 'B'. In this two state diagram, the probability of transitioning from any state to any other state is 0.5.&lt;/p&gt; &lt;p&gt;Of course, real modelers don't always draw out Markov chain diagrams. Instead they use a "transition matrix" to tally the transition probabilities. Every state in the state space is included once as a row and again as a column, and each cell in the matrix tells you the probability of transitioning from its row's state to its column's state. So, in the matrix, the cells do the same job that the arrows do in the diagram.&lt;/p&gt; &lt;p&gt;If the state space adds one state, we add one row and one column, adding one cell to every existing column and row. This means the number of cells grows quadratically as we add states to our Markov chain. Thus, a transition matrix comes in handy pretty quickly, unless you want to draw a jungle gym Markov chain diagram.&lt;/p&gt; &lt;p&gt;One use of Markov chains is to include real-world phenomena in computer simulations. For example, we might want to check how frequently a new dam will overflow, which depends on the number of rainy days in a row. To build this model, we start out with the following pattern of rainy (R) and sunny (S) days:&lt;/p&gt; &lt;p&gt;One way to simulate this weather would be to just say "Half of the days are rainy. Therefore, every day in our simulation will have a fifty percent chance of rain." This rule would generate the following sequence in simulation:&lt;/p&gt; &lt;p&gt;Did you notice how the above sequence doesn't look quite like the original? The second sequence seems to jump around, while the first one (the real data) seems to have a "stickyness". In the real data, if it's sunny (S) one day, then the next day is also much more likely to be sunny.&lt;/p&gt; &lt;p&gt;We can minic this "stickyness" with a two-state Markov chain. When the Markov chain is in state "R", it has a 0.9 probability of staying put and a 0.1 chance of leaving for the "S" state. Likewise, "S" state has 0.9 probability of staying put and a 0.1 chance of transitioning to the "R" state.&lt;/p&gt; &lt;p&gt;In the hands of metereologists, ecologists, computer scientists, financial engineers and other people who need to model big phenomena, Markov chains can get to be quite large and powerful. For example, the algorithm Google uses to determine the order of search results, called &lt;a href="https://en.wikipedia.org/wiki/PageRank"&gt;PageRank&lt;/a&gt;, is a type of Markov chain.&lt;/p&gt; &lt;p&gt;Above, we've included a Markov chain "playground", where you can make your own Markov chains by messing around with a transition matrix. Here's a few to work from as an example: &lt;a&gt;ex1&lt;/a&gt;, &lt;a&gt;ex2&lt;/a&gt;, &lt;a&gt;ex3&lt;/a&gt; or generate one &lt;a&gt;randomly&lt;/a&gt;. The transition matrix text will turn red if the provided matrix isn't a valid transition matrix. The rows of the transition matrix must total to 1. There also has to be the same number of rows as columns.&lt;/p&gt; &lt;p&gt;You can also access a fullscreen version at &lt;a href="https://setosa.io/markov/index.html"&gt;setosa.io/markov&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://setosa.io/blog/2014/07/26/markov-chains/index.html"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:18:48 UT
      </pubDate>
      <guid>
        https://setosa.io/blog/2014/07/26/markov-chains/index.html
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://www.lesswrong.com/posts/FCXCXigp7byv2dM8D/how-to-make-billions-of-dollars-reducing-loneliness
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;&lt;h2 id="Loneliness_Is_a_Big_Problem"&gt;Loneliness Is a Big Problem&lt;/h2&gt; &lt;p&gt;On Facebook, my friend Tyler &lt;a href="https://www.facebook.com/tyleralterman/posts/10214636828938815"&gt;writes&lt;/a&gt;:&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;Lately, I've been having an alarming amount of conversations arise about the burdens of loneliness, alienation, rootlessness, and a lack of belonging that many of my peers feel, especially in the Bay Area. I feel it too. Everyone has a gazillion friends and events to attend. But there's a palpable lack of social fabric. I worry that this atomization is becoming a world-wide phenomenon – that we might be some of the first generations without the sort of community that it's in &lt;em&gt;human nature&lt;/em&gt; to rely on.&lt;/p&gt; &lt;/blockquote&gt; &lt;blockquote&gt; &lt;p&gt;And that the result is a worsening epidemic of mental illness...&lt;/p&gt; &lt;/blockquote&gt; &lt;blockquote&gt; &lt;p&gt;Without the framework of a uniting religion, ethnicity, or purpose, it's hard to get people to truly commit to a given community. Especially when it's so easy to swipe left and opt for things that offer the fleeting &lt;em&gt;feeling&lt;/em&gt; of community without being the real thing: the parties, the once-a-month lecture series, the Facebook threads, the workshops, the New Age ceremonies. We often use these as "community porn" – they're easier than the real thing and they satisfy enough of the craving. But they don't make you whole.&lt;/p&gt; &lt;/blockquote&gt; &lt;blockquote&gt; &lt;p&gt;I've had some thoughts about experiments to try. But then I think about how hard it is (especially in this geographic area) to get people to show up to something on at least a weekly basis. Even if it's for something really great. I see many great attempts at community slowly peter out.&lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt;&lt;a href="https://today.yougov.com/topics/lifestyle/articles-reports/2019/07/30/loneliness-friendship-new-friends-poll-survey"&gt;Young people are lonely&lt;/a&gt;. &lt;a href="https://www.washingtonpost.com/national/health-science/theres-a-serious-problem-plaguing-some-older-people-loneliness/2019/04/05/338aac8e-5648-11e9-8ef3-fbd41a2ce4d5_story.html"&gt;Old people are lonely&lt;/a&gt;. &lt;a href="https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1000316"&gt;Loneliness is bad for your health&lt;/a&gt;. It's bad for &lt;a href="https://www.ft.com/content/89f16688-fb15-11e7-a492-2c9be7f3120a"&gt;society's&lt;/a&gt; &lt;a href="https://www.nytimes.com/2018/11/23/opinion/loneliness-political-polarization.html"&gt;health&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Having a smartphone that keeps you entertained all day, and enough money to live by yourself, might sound like first world problems. But they are likely contributors to loneliness. And as developing countries get richer, they'll start having first world problems too. So I think addressing loneliness could be very high-leverage for the world.&lt;/p&gt; &lt;p&gt;People are starting businesses to address loneliness: you can pay someone to &lt;a href="https://www.kcrw.com/news/shows/greater-la/have-a-friend-call-you-regularly-for-a-fee/effective-cure-for-loneliness-pay-a-monthly-fee-to-rent-a-friend"&gt;call you periodically&lt;/a&gt; or &lt;a href="https://www.latimes.com/local/lanow/la-me-city-beat-people-walker-loneliness-20190516-story.html"&gt;take you for a walk&lt;/a&gt;. But I'd argue these services are a band-aid in the same sense that parties, workshops, and ceremonies are. They don't solve the underlying problem: You're still alone by default instead of together by default.&lt;/p&gt; &lt;h2 id="Roommates_Could_Be_a_Great_Solution"&gt;Roommates Could Be a Great Solution&lt;/h2&gt; &lt;p&gt;Sociologists &lt;a href="https://www.nytimes.com/2012/07/15/fashion/the-challenge-of-making-friends-as-an-adult.html"&gt;think&lt;/a&gt; there are three conditions necessary for making friends: proximity; repeated, unplanned interactions; and a setting that encourages people to let their guard down and confide in each other. These conditions tend to be present during college for many people, but not afterwards.&lt;/p&gt; &lt;p&gt;Why do people find it easier to make friends in college? Maybe it's because college students don't usually live alone.&lt;/p&gt; &lt;p&gt;Going to events doesn't work because (a) you don't typically get repeated interactions with the same person and (b) events take place at a scheduled time. Which may or may not be a time you're feeling lonely.&lt;/p&gt; &lt;p&gt;If you have a lot of roommates, all you have to do is step outside your room and find someone to chat with. No transportation CO2 emissions needed. But more important, you know your roommates are always gonna be around.&lt;/p&gt; &lt;h2 id="But_I_Already_Have_Roommates"&gt;But I Already Have Roommates&lt;/h2&gt; &lt;p&gt;Even if you already have roommates, I think there's a good chance your roommate situation is under-optimized. Given that you spend so much time with them, there's a lot of value in living with people you really connect with. (Finding great coworkers makes sense for similar reasons.)&lt;/p&gt; &lt;p&gt;The layout of your house and the number of roommates you have can also make a big difference. I used to have friends living in a 4-bedroom place where all the bedrooms opened directly into a single large common area. If anyone else was outside their room, you'd immediately know it and have an opportunity for interaction. Later I lived in an 8-bedroom place which felt far lonelier, even with every room occupied. The house was laid out so it was easy to go about your day without ever running into a fellow roommate. I also lived in a house with over 50 bedrooms for a while, which was wild &amp;amp; a lot of fun.&lt;/p&gt; &lt;h2 id="But_I_Don_t_Want_Roommates"&gt;But I Don't Want Roommates&lt;/h2&gt; &lt;p&gt;One reason you might not want roommates is because you're worried you might have conflicting preferences for what living together should be like. For example, my philosophy towards dirty dishes is to let them pile up on the counter and periodically stuff them all in the dishwasher, to be as time-efficient as possible. Surprisingly, some people dislike this approach.&lt;/p&gt; &lt;p&gt;&lt;a href="https://www.roomiematch.com/"&gt;RoomieMatch.com&lt;/a&gt; is a website which tries to solve the roommate compatibility problem. You create a profile by answering questions about dishes, food in the fridge, housecleaning, social events, noise, overnight guests, shared household items, walking around in your underwear, TV, etc. In addition, there are questions to help predict how you well you will connect as people.&lt;/p&gt; &lt;h2 id="You_Could_Make_a_Lot_of_Money"&gt;You Could Make a Lot of Money&lt;/h2&gt; &lt;p&gt;RoomieMatch has two search options: free and cheap. Cheap costs $20/year.&lt;/p&gt; &lt;p&gt;The problem with RoomieMatch is they're leaving a massive amount of money on the table.&lt;/p&gt; &lt;p&gt;A few years ago, a friend of mine was jobless &amp;amp; struggling financially. He was living in a 4-bedroom house at the time, and he was the primary contact with the landlord. My friend took responsibility for vetting folks from Craigslist in order to fill the remaining rooms in the house. He found that folks from Craigslist were willing to pay enough rent for the remaining 3 rooms that he was able to live rent-free until he found a job.&lt;/p&gt; &lt;p&gt;I acknowledge this is murky ethical territory, and I'm not condoning my friend's actions. (I don't believe anyone ever found out or got upset, for whatever that's worth.) The point I'm trying to make is that property management is way more lucrative than roommate matching. RoomieMatch makes $20 per user per year at best. My friend was making $100+ per user per &lt;em&gt;month&lt;/em&gt;.&lt;/p&gt; &lt;p&gt;What I'm suggesting is that you take the &lt;a href="https://a16z.com/2015/01/22/the-full-stack-startup/"&gt;full-stack startup&lt;/a&gt; playbook which has been successful in Silicon Valley recently, and apply it to online roommate matching + property management.&lt;/p&gt; &lt;p&gt;The extreme full-stack approach is to own your own properties. Apparently the US has a &lt;a href="https://www.wsj.com/articles/a-growing-problem-in-real-estate-too-many-too-big-houses-11553181782"&gt;surplus of big houses&lt;/a&gt; right now.&lt;/p&gt; &lt;p&gt;There are already &lt;a href="https://techcrunch.com/2018/05/19/shared-housing-startups-are-taking-off/"&gt;players in this space&lt;/a&gt; such as &lt;a href="https://www.roam.co/"&gt;Roam&lt;/a&gt; which are proving that people will pay for community. (As if people paying extra to live in hip cities like SF &amp;amp; NYC didn't prove that already. BTW, I found that the &lt;a href="https://forum.effectivealtruism.org/posts/sigun924gsxN4oZq2/the-case-for-the-ea-hotel"&gt;awesome community&lt;/a&gt; at the &lt;a href="https://slatestarcodex.com/2018/08/20/practically-a-book-review-ea-hotel/"&gt;Athena Hotel&lt;/a&gt; more than made up for the fact that it's in a non-hip city.) Anyway, I think existing players are mostly pursuing the extreme full-stack option. I actually think this is the wrong play. You want to be a marketplace, like Airbnb (valued at over $30 billion). The more people who are using &lt;em&gt;your&lt;/em&gt; tool, the finer-grained roommate matching services you can provide. It's hard to achieve massive scale if you have to own every property. You want to be playing matchmaker for individuals with common interests who all happen to be looking for rooms around the same time, plus landlords with empty houses. Maybe you'll want to undercut RoomieMatch, and provide free matching services for people who live in their properties, in order to achieve the necessary scale. (RoomieMatch's existing scale is impressive by the way--I quickly got 100+ active, vetted matches in a midsize US city when I tried the tool. If you have the money you might want to just buy it.)&lt;/p&gt; &lt;p&gt;So instead of buying properties, maybe you just want to contact people selling large homes &amp;amp; see if you can convince them to let you manage their property.&lt;/p&gt; &lt;p&gt;Note that this is a good company to start if a recession happens, since people who currently live alone will be thinking about how to save on rent.&lt;/p&gt; &lt;h2 id="This_Could_Be_Really_Great"&gt;This Could Be Really Great&lt;/h2&gt; &lt;p&gt;Most roommate search tools, like Craigslist, don't make it easy to figure out if a future roommate is someone you'd actually want to live with. Imagine reaching a scale where you could match people based on factors like:&lt;/p&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;They love to play board games, or pool, or Super Smash Bros.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;They want a compost pile and a garden in their backyard.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;One has a pet, and the other likes animals but isn't yet ready to make a lifetime commitment.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;They want a squat rack in the basement to save time &amp;amp; money going to the gym.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;They want to continue partying like college students after graduation.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;They want to be part of an intentional community devoted to mutual improvement and life optimization, or spirituality, or whatever.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;They want to &lt;a href="https://www.lesswrong.com/posts/4esQ684vtR9zcjHgW/i-want-to-live-in-a-baugruppe"&gt;share childcare responsibilities&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;They're all fans of the same sports team.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;They enjoy reading and discussing the same genre of novels, or watching the same movies.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;They're musicians looking for people to jam with.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;They want to live near hiking trails and go on group hikes together.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;They want to do independent study of the same topic.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;They're trying to eat a healthier diet.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;They just moved to a new city and want friends they can explore the city with.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;They have the same unusual work schedule.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;One needs a caretaker, and the other wants to make extra money.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;They like the idea of having a couch or two listed on &lt;a href="https://www.couchsurfing.com/"&gt;CouchSurfing&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;One knows a language the other wants to learn.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;They work close together in the same expensive metropolitan area and want save on housing. So they live in the outskirts of the city and commute together every day using the diamond lane. One drives and the other pays for gas.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;I also see opportunities to reduce friction in the current roommate matching process:&lt;/p&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Automatically find times when everyone is available for a meet &amp;amp; greet video call.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Let people take virtual tours of the houses on offer to minimize driving.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;No need to worry about breaking a lease if someone moves to a different house in your company's network. Let people try out a few communities &amp;amp; see what works for them. Use machine learning to improve your matching as you gather more data.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Provide external mediation in the event of roommate disputes, and have a reputation system to encourage good behavior.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;You aren't providing &lt;em&gt;housing&lt;/em&gt; as a service (like Airbnb), or &lt;em&gt;companionship&lt;/em&gt; as a service (like the people-walking startup). You're providing &lt;em&gt;community&lt;/em&gt; as a service. You could even organize mixers across your houses.&lt;/p&gt; &lt;h2 id="Conclusion"&gt;Conclusion&lt;/h2&gt; &lt;p&gt;Technology has been blamed for the loneliness epidemic, but I think we can use technology to cure the loneliness epidemic as well.&lt;/p&gt; &lt;p&gt;I'm too busy being obsessed with machine learning to start any company which isn't mostly about that. But I think this is a product the world needs, and I want you to build it. I encourage you to sign the &lt;a href="https://founderspledge.com/"&gt;Founders Pledge&lt;/a&gt; and donate the money to &lt;a href="https://www.effectivealtruism.org/"&gt;effective charities&lt;/a&gt; in case you actually end up making billions of dollars as a result of reading this.&lt;/p&gt; &lt;p&gt;I apologize if you found the tone of this post overly sales-y. My goal was to light a spark in the right person. (Feel free to steal phrases from this post when pitching investors!)&lt;/p&gt; &lt;p&gt;Some folks in the rationalist community might be a little underwhelmed by this idea, since people in the rationalist community have been living together in group houses for a long time. The thing is, finding roommates by connecting based on mutual interests via the internet is still kind of weird in the eyes of the general public. As Paul Graham &lt;a href="http://www.paulgraham.com/startupideas.html"&gt;put it&lt;/a&gt;: "Live in the future, then build what's missing." The existence of so many lonely people proves that this option is still missing for most people.&lt;/p&gt; &lt;p&gt;Anyway, if you're interested in building/investing in this, please comment below, or send me a private message via my &lt;a href="https://www.lesswrong.com/users/john_maxwell"&gt;user page&lt;/a&gt; with the country you're in and I'll put you in contact with others who message me. (Edit: I might be slow to reply, sorry)&lt;/p&gt; &lt;p&gt;&lt;em&gt;Cross-posted from the &lt;a href="https://forum.effectivealtruism.org/posts/YNnG86WS8z8aYdBES/how-to-make-billions-of-dollars-reducing-loneliness"&gt;Effective Altruism Forum&lt;/a&gt;. See also discussion on &lt;a href="https://news.ycombinator.com/item?id=20847752"&gt;Hacker News&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://www.lesswrong.com/posts/FCXCXigp7byv2dM8D/how-to-make-billions-of-dollars-reducing-loneliness"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:22:01 UT
      </pubDate>
      <guid>
        https://www.lesswrong.com/posts/FCXCXigp7byv2dM8D/how-to-make-billions-of-dollars-reducing-loneliness
      </guid>
    </item>
    <item>
      <title>
        Understanding SAT by Implementing a Simple SAT Solver in Python
      </title>
      <link>
        https://sahandsaba.com/understanding-sat-by-implementing-a-simple-sat-solver-in-python.html
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;section id="content"&gt; &lt;header&gt; &lt;h2&gt; &lt;span&gt;Understanding SAT by Implementing a Simple SAT Solver in Python&lt;/span&gt; &lt;/h2&gt; &lt;/header&gt; &lt;div id="article-content"&gt; &lt;div id="introduction"&gt; &lt;h2&gt;Introduction&lt;/h2&gt; &lt;p&gt;SAT is short for "satisfiability". Chances are you have heard of it or one of its variants like 3-SAT in passing, especially in discussions of complexity and NP-completeness. In this post, we will go into details of what it is all about, why it is of such importance from both a theoretical and practical perspective, and how to approach solving it by developing a simple Python SAT solver. By the end of this post, we will have a working SAT solver with a command-line interface. The code for it is on GitHub: &lt;a href="https://github.com/sahands/simple-sat"&gt;https://github.com/sahands/simple-sat&lt;/a&gt;. Feel free to fork and contribute improvements. Of course, our implementation will not be anywhere close to more complicated SAT solvers implemented in C or C++, such as &lt;a href="https://github.com/niklasso/minisat"&gt;miniSAT&lt;/a&gt;. The focus here is on simplicity since the code is to be an introduction to SAT and SAT solvers.&lt;/p&gt; &lt;p&gt;Sections marked with &lt;sup&gt;*&lt;/sup&gt; are more theoretical and not required for understanding the algorithm we will use. On the other hand, the rest of the introduction section below can be skipped if you already know the problem definition and relevant technical terms.&lt;/p&gt; &lt;div id="non-technical-definitions-example"&gt; &lt;h3&gt;Non-Technical Definitions &amp;amp; Example&lt;/h3&gt; &lt;p&gt;Before we start with the definitions, you might be asking why SAT is written in all capitals if it is not an acronym. Well, great question. SAT happens to fall under what are called &lt;em&gt;decision problems&lt;/em&gt; in computer science. What that means is that the answer to a particular instance of the problem is either "yes" or "no". Decision problems are often simply identified with the set of inputs for which the answer is "yes", and that set is given a capitalized name. For example, SAT is the set of all satisfiable CNF expressions, and PRIMES is the set of all prime numbers (the decision problem in the latter is that of primality; i.e. given the binary representation of number &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; , decide if it is a prime or not). To go on a bit of a tangent, this is also the reason that the title of the paper that introduced the AKS primality test (&lt;a href="https://www.cse.iitk.ac.in/users/manindra/algebra/primality_v6.pdf"&gt;"PRIMES is in P"&lt;/a&gt;) is not a silly grammar mistake; PRIMES is a set and the paper shows that it is in P, which is the set of decision problems solvable in polynomial-time. This naming style, as far as I know, is mainly due to Garey and Johnson's classic &lt;a href="https://en.wikipedia.org/wiki/Computers_and_Intractability:_A_Guide_to_the_Theory_of_NP-Completeness"&gt;textbook on complexity theory&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;So, back to SAT. So far we mentioned that SAT is a decision problem, and something about mysterious sounding "CNF expressions". Now, if you happen to know your Boolean logic and already know all about satisfiability and CNF expressions, then feel free to skip ahead to next section. The rest of this section assumes no prior knowledge of logic. Like many other interesting problems, there are a variety of ways of describing SAT, some more technical and some less. Here I will provide a very non-technical description of the problem that nonetheless is an accurate description.&lt;/p&gt; &lt;p&gt;Assume you are in charge of elections in a society. Elections in this society work as follows: there are &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; candidates, and any number of them, from &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;0&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; (nobody) to &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; (everybody) can be elected as the result of the elections. Each voter provides a list of candidates they want elected and candidates they want not elected. For example, if we call the candidates A, B and C, then one vote might be "A, B, not C". We say a voter will be &lt;em&gt;satisfied&lt;/em&gt; with the results of the election if at least one of his/her preferences is met. For example, the voter with the "A, B, not C" vote will be satisfied if either A or B is elected, or if C is not elected. To be clear, that voter will be happy even if nobody is elected (anarchy!) because one of the preferences is "not C" which is met if we do not pick anyone. It's also possible to receive an empty vote. We take this to mean that the voter will not be satisfied regardless of who is elected.&lt;/p&gt; &lt;p&gt;You are given all the votes, and your job is to determine if all the voters can be satisfied or not, and if yes, provide at least one possible pick of candidates that would satisfy everybody.&lt;/p&gt; &lt;p&gt;We assume that each candidate is represented by a unique identifier that will be a string in the input. For the votes, we will write just the string representing candidate &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;x&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; to indicate the voter wants the candidate elected, and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;∼&lt;/mo&gt;&lt;mrow&gt;&lt;/mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;\sim{}x&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; to indicate the voter wants &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;x&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; not elected.&lt;/p&gt; &lt;p&gt;Let's look at an example. Assume the list of votes is given as follows, one per line:&lt;/p&gt; &lt;p&gt;Then choosing to elect just candidates &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;/mrow&gt;A&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;/mrow&gt;C&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; but not &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;/mrow&gt;B&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; will satisfy all the voters. Take a moment to convince yourself that no other choice of candidates (there are a total of &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/msup&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;8&lt;/mn&gt;&lt;/mrow&gt;2^3 = 8&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; possibilities) can satisfy everyone. It is easy to see that in general the search-space is of size &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/msup&gt;&lt;/mrow&gt;2^n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; where &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; is the number of candidates.&lt;/p&gt; &lt;/div&gt; &lt;div id="technical-terminology"&gt; &lt;h3&gt;Technical Terminology&lt;/h3&gt; &lt;p&gt;Now that the problem makes sense, let's define the technical vocabulary. First, what we called "candidates" are called &lt;em&gt;variables&lt;/em&gt;. The variables in the above example are &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;/mrow&gt;A&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; , &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;/mrow&gt;B&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;/mrow&gt;C&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; . A variable can be assigned true or false. A &lt;em&gt;literal&lt;/em&gt; is a variable or its negation. For example &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;/mrow&gt;A&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;∼&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;/mrow&gt;\sim A&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; are literals. Literals without the &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;∼&lt;/mo&gt;&lt;/mrow&gt;\sim&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; are called positive, pure, or unnegated literals. Literals with &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;∼&lt;/mo&gt;&lt;/mrow&gt;\sim&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; are called negated literals. A set of literals is called a &lt;em&gt;clause&lt;/em&gt;. An &lt;em&gt;assignment&lt;/em&gt; is a mapping of variables to true or false. For example, the assignment that satisfied the clauses in the previous example was given by &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;/mrow&gt;A = true&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; , &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;/mrow&gt;B = false&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;/mrow&gt;C = true&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; . A clause is &lt;em&gt;satisfied&lt;/em&gt; by an assignment if at least one of its unnegated literals is assigned true by the assignment, or one of its negated literals is assigned false in the assignment. It is customary, in logic notation, to separate the literals in a clause using the &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;∨&lt;/mo&gt;&lt;/mrow&gt;\vee&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; symbol, read "or". For example, the first clause above is written as &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;∨&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mtext&gt;&amp;nbsp;&lt;/mtext&gt;&lt;mo&gt;∨&lt;/mo&gt;&lt;mo&gt;∼&lt;/mo&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;/mrow&gt;A \vee B ~ \vee \sim C&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; in mathematical notation.&lt;/p&gt; &lt;p&gt;So SAT can be summarized as follows: given a list of clauses, determine if there exists an assignment that satisfies all of them simultaneously.&lt;/p&gt; &lt;p&gt;It is also worthy of mention that there is a variation of SAT called 3-SAT with the restriction that each clause consists of at most 3 (distinct) literals. It can be shown with relative ease that SAT is in fact reducible to 3-SAT.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id="a-simple-sat-solver-in-python"&gt; &lt;h2&gt;A Simple SAT Solver In Python&lt;/h2&gt; &lt;p&gt;Even though SAT is NP-complete and therefore no known polynomial-time algorithm for it is (yet) known, many improvements over the basic backtracking algorithms have been made over the last few decades. However, here we will look at one of the most basic yet relatively efficient algorithms for solving SAT. The encoding and the algorithm are based on Knuth's SAT0W program which you can download from his &lt;a href="https://www-cs-faculty.stanford.edu/~uno/programs.html"&gt;programs page&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;The algorithm is a watch-list based backtracking algorithm. What makes the watch-list based algorithms particularly simple, as we will see, is that very little (practically nothing) needs to be done to "undo" steps taken when we need to backtrack.&lt;/p&gt; &lt;div id="parsing-encoding-the-input"&gt; &lt;h3&gt;Parsing &amp;amp; Encoding The Input&lt;/h3&gt; &lt;p&gt;Before we can approach solving a SAT instance, we need to be able to represent the instance in memory. Let's remember that a SAT instance is a set of clauses, and each clause is a set of literals. Finally, a literal is a variable that is either negated or not. Of course, we can just store the instance as a list of clauses, with each clause being a list of strings that are the literals. The problem with this approach is that we will not be able to quickly look up variables, and checking to see if a literal is negated or not, and negating it if not, would be rather slow string operations.&lt;/p&gt; &lt;p&gt;Instead, we will first assign a unique number, starting from &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;0&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; and counting up, to each variable as we encounter them, using a dictionary to keep track of the mapping. So variables will be encoded as numbers &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;0&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; to &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;n-1&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; where &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; is the number of variables. Then for an unnegated literal with variable encoded as number &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;x&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; we will encode the literal as &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;2x&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; , and the negated one will be &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;2x + 1&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; . Then a clause will simply be a list of numbers that are the encoded literals, and&lt;/p&gt; &lt;p&gt;Let's look at an example first. For this, let's see how the code that we will look at in a minute behaves:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span&gt;from&lt;/span&gt; &lt;span&gt;satinstance&lt;/span&gt; &lt;span&gt;import&lt;/span&gt; &lt;span&gt;SATInstance&lt;/span&gt; &lt;span&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span&gt;s&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;SATInstance&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span&gt;s&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;parse_and_add_clause&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;'A B ~C'&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span&gt;s&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;variables&lt;/span&gt; &lt;span&gt;['A', 'B', 'C']&lt;/span&gt; &lt;span&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span&gt;s&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;variable_table&lt;/span&gt; &lt;span&gt;{'A': 0, 'C': 2, 'B': 1}&lt;/span&gt; &lt;span&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span&gt;s&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;clauses&lt;/span&gt; &lt;span&gt;[(0, 2, 5)]&lt;/span&gt; &lt;/pre&gt;&lt;/div&gt; &lt;p&gt;So as you see, the clause &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;∨&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mo&gt;∨&lt;/mo&gt;&lt;mo&gt;∼&lt;/mo&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;/mrow&gt;A \vee B \vee \sim C&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; is encoded as the tuple &lt;tt&gt;(0, 2, 5)&lt;/tt&gt; since variable &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;/mrow&gt;A&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; is assigned number &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;0&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; , and hence literal &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;/mrow&gt;A&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; is &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo&gt;⋅&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;2 \cdot 0 =0&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; . On the other hand, &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;∼&lt;/mo&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;/mrow&gt;\sim C&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; is encoded as &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;5&lt;/mn&gt;&lt;/mrow&gt;5&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; since &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;/mrow&gt;C&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; is assigned &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mrow&gt;2&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; and hence &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;∼&lt;/mo&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;/mrow&gt;\sim C&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; is encoded as &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo&gt;⋅&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;5&lt;/mn&gt;&lt;/mrow&gt;2 \cdot 2 + 1 = 5&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; .&lt;/p&gt; &lt;p&gt;Why the funny encoding, you ask? Because it has a few advantages:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;we can keep track of variables by keeping a list of length &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; , and of literals by keeping a list of length &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;2n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; ,&lt;/li&gt; &lt;li&gt;checking to see if a literal is negated or not is simple: just do a bit-wise AND with &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;1&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; , that is &lt;tt&gt;x &amp;amp; 1 == 0&lt;/tt&gt;,&lt;/li&gt; &lt;li&gt;looking up the variable in a literal is a matter of dividing by two, which is the same as a bit-wise shift to the right, that is &lt;tt&gt;v = x &amp;gt;&amp;gt; 1&lt;/tt&gt;,&lt;/li&gt; &lt;li&gt;switching a literal from negated to unnegated and back can be done by doing a bit-wise XOR with the number one, that is &lt;tt&gt;negate(x) = x ^ 1&lt;/tt&gt;,&lt;/li&gt; &lt;li&gt;and finally going from a variable to a literal can be done by doing a bit-wise shift to the right (and a bit-wise OR with 1 if negated), that is &lt;tt&gt;x = v &amp;lt;&amp;lt; 1&lt;/tt&gt; or &lt;tt&gt;x = v &amp;lt;&amp;lt; 1 | 1&lt;/tt&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Notice that all of the above can be done using bit-wise operations which are generally very fast to do. And since these operations will be happening an exponential number of times, we will take any performance boost we can get.&lt;/p&gt; &lt;p&gt;With this, we are ready to write the code that takes care of reading an input file and encoding the clauses. Here it is:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;SATInstance&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;object&lt;/span&gt;&lt;span&gt;):&lt;/span&gt; &lt;span&gt;def&lt;/span&gt; &lt;span&gt;parse_and_add_clause&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;self&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;line&lt;/span&gt;&lt;span&gt;):&lt;/span&gt; &lt;span&gt;clause&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;[]&lt;/span&gt; &lt;span&gt;for&lt;/span&gt; &lt;span&gt;literal&lt;/span&gt; &lt;span&gt;in&lt;/span&gt; &lt;span&gt;line&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;split&lt;/span&gt;&lt;span&gt;():&lt;/span&gt; &lt;span&gt;negated&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;1&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;literal&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;startswith&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;'~'&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;else&lt;/span&gt; &lt;span&gt;0&lt;/span&gt; &lt;span&gt;variable&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;literal&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;negated&lt;/span&gt;&lt;span&gt;:]&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;variable&lt;/span&gt; &lt;span&gt;not&lt;/span&gt; &lt;span&gt;in&lt;/span&gt; &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;variable_table&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;variable_table&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;variable&lt;/span&gt;&lt;span&gt;]&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;len&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;variables&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;variables&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;variable&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;encoded_literal&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;variable_table&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;variable&lt;/span&gt;&lt;span&gt;]&lt;/span&gt; &lt;span&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span&gt;1&lt;/span&gt; &lt;span&gt;|&lt;/span&gt; &lt;span&gt;negated&lt;/span&gt; &lt;span&gt;clause&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;encoded_literal&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;clauses&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;tuple&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;set&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;clause&lt;/span&gt;&lt;span&gt;)))&lt;/span&gt; &lt;span&gt;def&lt;/span&gt; &lt;span&gt;__init__&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;self&lt;/span&gt;&lt;span&gt;):&lt;/span&gt; &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;variables&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;[]&lt;/span&gt; &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;variable_table&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;dict&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;clauses&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;[]&lt;/span&gt; &lt;span&gt;@classmethod&lt;/span&gt; &lt;span&gt;def&lt;/span&gt; &lt;span&gt;from_file&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;cls&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;file&lt;/span&gt;&lt;span&gt;):&lt;/span&gt; &lt;span&gt;instance&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;cls&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;for&lt;/span&gt; &lt;span&gt;line&lt;/span&gt; &lt;span&gt;in&lt;/span&gt; &lt;span&gt;file&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;line&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;line&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;strip&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;len&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;line&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;0&lt;/span&gt; &lt;span&gt;and&lt;/span&gt; &lt;span&gt;not&lt;/span&gt; &lt;span&gt;line&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;startswith&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;'#'&lt;/span&gt;&lt;span&gt;):&lt;/span&gt; &lt;span&gt;instance&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;parse_and_add_clause&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;line&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;instance&lt;/span&gt; &lt;span&gt;def&lt;/span&gt; &lt;span&gt;literal_to_string&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;self&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;literal&lt;/span&gt;&lt;span&gt;):&lt;/span&gt; &lt;span&gt;s&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'~'&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;literal&lt;/span&gt; &lt;span&gt;&amp;amp;&lt;/span&gt; &lt;span&gt;1&lt;/span&gt; &lt;span&gt;else&lt;/span&gt; &lt;span&gt;''&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;s&lt;/span&gt; &lt;span&gt;+&lt;/span&gt; &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;variables&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;literal&lt;/span&gt; &lt;span&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;]&lt;/span&gt; &lt;span&gt;def&lt;/span&gt; &lt;span&gt;clause_to_string&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;self&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;clause&lt;/span&gt;&lt;span&gt;):&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;' '&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;join&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;literal_to_string&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;l&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;for&lt;/span&gt; &lt;span&gt;l&lt;/span&gt; &lt;span&gt;in&lt;/span&gt; &lt;span&gt;clause&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;def&lt;/span&gt; &lt;span&gt;assignment_to_string&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;self&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;assignment&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;brief&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;False&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;starting_with&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;''&lt;/span&gt;&lt;span&gt;):&lt;/span&gt; &lt;span&gt;literals&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;[]&lt;/span&gt; &lt;span&gt;for&lt;/span&gt; &lt;span&gt;a&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;v&lt;/span&gt; &lt;span&gt;in&lt;/span&gt; &lt;span&gt;((&lt;/span&gt;&lt;span&gt;a&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;v&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;for&lt;/span&gt; &lt;span&gt;a&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;v&lt;/span&gt; &lt;span&gt;in&lt;/span&gt; &lt;span&gt;zip&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;assignment&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;variables&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;v&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;startswith&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;starting_with&lt;/span&gt;&lt;span&gt;)):&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;a&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;0&lt;/span&gt; &lt;span&gt;and&lt;/span&gt; &lt;span&gt;not&lt;/span&gt; &lt;span&gt;brief&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;literals&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;'~'&lt;/span&gt; &lt;span&gt;+&lt;/span&gt; &lt;span&gt;v&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;elif&lt;/span&gt; &lt;span&gt;a&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;literals&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;v&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;' '&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;join&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;literals&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;/pre&gt;&lt;/div&gt; &lt;p&gt;As you can see, we also include methods here to decode variables, literals, clauses, and assignments. These are used for outputting logging messages as well as the final solutions.&lt;/p&gt; &lt;/div&gt; &lt;div id="keeping-track-of-the-assignment"&gt; &lt;h3&gt;Keeping Track Of The Assignment&lt;/h3&gt; &lt;p&gt;Our algorithm will be a backtracking algorithm, in which we will assign true or false to all the variables, starting from variable &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;0&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; and going in order to variable &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;n-1&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; . Of course, the basic search space is of size &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/msup&gt;&lt;/mrow&gt;2^n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; but by pruning, we will not explore the whole space (usually anyway). The assignment will be kept as a list of length &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; , with item at index &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/mrow&gt;i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; being &lt;tt&gt;None&lt;/tt&gt; if neither true or false has been assigned variable &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/mrow&gt;i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; , and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;0&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; (false) or &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;1&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; (true) otherwise, depending on the assignment. When we backtrack, we set the corresponding item in the assignment list back to &lt;tt&gt;None&lt;/tt&gt; to indicate it is no longer assigned.&lt;/p&gt; &lt;/div&gt; &lt;div id="watch-lists"&gt; &lt;h3&gt;Watch-lists&lt;/h3&gt; &lt;p&gt;Now that we have the encoding in place, and know how to keep track of the assignment, let's look at the key idea of our algorithm. For each clause to be satisfied, it needs to have at least one of its literals satisfied. As such, we can make each clause &lt;em&gt;watch&lt;/em&gt; one of its literals, and ensure that the following invariant is maintained throughout our algorithm:&lt;/p&gt; &lt;dl&gt; &lt;dt&gt;Invariant&lt;/dt&gt; &lt;dd&gt;All watched literals are either not assigned yet, or they have been assigned true.&lt;/dd&gt; &lt;/dl&gt; &lt;p&gt;We then proceed to assign true or false to variables, starting from &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;0&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; to &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;n-1&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; . If we successfully assign true or false to every variable while maintaining the above variant, then we have an assignment that satisfies every clause.&lt;/p&gt; &lt;p&gt;To maintain this invariant, any time we assign true or false to a variable, we ensure to update the watch-list accordingly. To do this efficiently, we need to keep a list of clauses that are currently watching a given literal. This is done in the code below using a list of length &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;2n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; of double-ended queue (&lt;tt&gt;collections.deque&lt;/tt&gt;), with each clause initially watching the first literal in it. The function below takes care of this setting up of the watch-list:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;def&lt;/span&gt; &lt;span&gt;setup_watchlist&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;instance&lt;/span&gt;&lt;span&gt;):&lt;/span&gt; &lt;span&gt;watchlist&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;deque&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;for&lt;/span&gt; &lt;span&gt;__&lt;/span&gt; &lt;span&gt;in&lt;/span&gt; &lt;span&gt;range&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; &lt;span&gt;len&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;instance&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;variables&lt;/span&gt;&lt;span&gt;))]&lt;/span&gt; &lt;span&gt;for&lt;/span&gt; &lt;span&gt;clause&lt;/span&gt; &lt;span&gt;in&lt;/span&gt; &lt;span&gt;instance&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;clauses&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;# Make the clause watch its first literal&lt;/span&gt; &lt;span&gt;watchlist&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;clause&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;]]&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;clause&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;watchlist&lt;/span&gt; &lt;/pre&gt;&lt;/div&gt; &lt;p&gt;Why double-ended queues instead of just a list? Short answer is that after experimenting, I found out that double-ended queues provided the best performance.&lt;/p&gt; &lt;p&gt;Back to the algorithm, whenever we assign true to a variable &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;x&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; we must make clauses watching &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;∼&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;\sim x&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; watch something else. And similarly, whenever we assign false to a variable &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;x&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; we make clauses watching &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;x&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; watch something else. If we can not make a clause watch something, which happens when all the other literals in a clause have already been assigned false, then we know that the current assignment contradicts the clause, and we stop and backtrack. We only need one clause to be contradicted to know not to go any further. As such, the heart of our algorithm will be where we update the watch-list after an assignment has been made. The Python function below, which is in (&lt;tt&gt;watchlist.py&lt;/tt&gt;), implements this part of the algorithm:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;def&lt;/span&gt; &lt;span&gt;update_watchlist&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;instance&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;watchlist&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;false_literal&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;assignment&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;verbose&lt;/span&gt;&lt;span&gt;):&lt;/span&gt; &lt;span&gt;"""&lt;/span&gt; &lt;span&gt; Updates the watch list after literal 'false_literal' was just assigned&lt;/span&gt; &lt;span&gt; False, by making any clause watching false_literal watch something else.&lt;/span&gt; &lt;span&gt; Returns False it is impossible to do so, meaning a clause is contradicted&lt;/span&gt; &lt;span&gt; by the current assignment.&lt;/span&gt; &lt;span&gt; """&lt;/span&gt; &lt;span&gt;while&lt;/span&gt; &lt;span&gt;watchlist&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;false_literal&lt;/span&gt;&lt;span&gt;]:&lt;/span&gt; &lt;span&gt;clause&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;watchlist&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;false_literal&lt;/span&gt;&lt;span&gt;][&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;]&lt;/span&gt; &lt;span&gt;found_alternative&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;False&lt;/span&gt; &lt;span&gt;for&lt;/span&gt; &lt;span&gt;alternative&lt;/span&gt; &lt;span&gt;in&lt;/span&gt; &lt;span&gt;clause&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;v&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;alternative&lt;/span&gt; &lt;span&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span&gt;1&lt;/span&gt; &lt;span&gt;a&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;alternative&lt;/span&gt; &lt;span&gt;&amp;amp;&lt;/span&gt; &lt;span&gt;1&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;assignment&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;v&lt;/span&gt;&lt;span&gt;]&lt;/span&gt; &lt;span&gt;is&lt;/span&gt; &lt;span&gt;None&lt;/span&gt; &lt;span&gt;or&lt;/span&gt; &lt;span&gt;assignment&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;v&lt;/span&gt;&lt;span&gt;]&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;a&lt;/span&gt; &lt;span&gt;^&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;found_alternative&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;True&lt;/span&gt; &lt;span&gt;del&lt;/span&gt; &lt;span&gt;watchlist&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;false_literal&lt;/span&gt;&lt;span&gt;][&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;]&lt;/span&gt; &lt;span&gt;watchlist&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;alternative&lt;/span&gt;&lt;span&gt;]&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;clause&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;break&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;not&lt;/span&gt; &lt;span&gt;found_alternative&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;verbose&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;dump_watchlist&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;instance&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;watchlist&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;print&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;'Current assignment: {}'&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;format&lt;/span&gt;&lt;span&gt;(&lt;/span&gt; &lt;span&gt;instance&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;assignment_to_string&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;assignment&lt;/span&gt;&lt;span&gt;)),&lt;/span&gt; &lt;span&gt;file&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;stderr&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;print&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;'Clause {} contradicted.'&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;format&lt;/span&gt;&lt;span&gt;(&lt;/span&gt; &lt;span&gt;instance&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;clause_to_string&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;clause&lt;/span&gt;&lt;span&gt;)),&lt;/span&gt; &lt;span&gt;file&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;stderr&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;False&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;True&lt;/span&gt; &lt;/pre&gt;&lt;/div&gt; &lt;p&gt;So why the watch-list based approach? The main reason is the simplicity it affords us. Since during a backtracking step, assignments only go from &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;0&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; or &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;1&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; to &lt;tt&gt;None&lt;/tt&gt;, the watch-list does not need to be updated at all to maintain the invariant. This means the backtracking step will simply be changing the assignment of a variable back to &lt;tt&gt;None&lt;/tt&gt; and that's it.&lt;/p&gt; &lt;/div&gt; &lt;div id="putting-it-all-together"&gt; &lt;h3&gt;Putting It All Together&lt;/h3&gt; &lt;p&gt;We are now ready to put it all together to get a simple recursive algorithm for solving SAT. The steps are simple: try assigning &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;0&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; to variable &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;/mrow&gt;d&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; , update the watch-list, if successful, move on to variable &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;d+1&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; . If not successful, try assigning &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;1&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; to variable &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;/mrow&gt;d&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; and update the watch-list and continue to variable &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;d+1&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; . If neither succeed, assign &lt;tt&gt;None&lt;/tt&gt; to variable &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;/mrow&gt;d&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; and backtrack. Here is the code:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;def&lt;/span&gt; &lt;span&gt;solve&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;instance&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;watchlist&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;assignment&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;d&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;verbose&lt;/span&gt;&lt;span&gt;):&lt;/span&gt; &lt;span&gt;"""&lt;/span&gt; &lt;span&gt; Recursively solve SAT by assigning to variables d, d+1, ..., n-1. Assumes&lt;/span&gt; &lt;span&gt; variables 0, ..., d-1 are assigned so far. A generator for all the&lt;/span&gt; &lt;span&gt; satisfying assignments is returned.&lt;/span&gt; &lt;span&gt; """&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;d&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;len&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;instance&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;variables&lt;/span&gt;&lt;span&gt;):&lt;/span&gt; &lt;span&gt;yield&lt;/span&gt; &lt;span&gt;assignment&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;for&lt;/span&gt; &lt;span&gt;a&lt;/span&gt; &lt;span&gt;in&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;]:&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;verbose&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;print&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;'Trying {} = {}'&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;format&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;instance&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;variables&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;d&lt;/span&gt;&lt;span&gt;],&lt;/span&gt; &lt;span&gt;a&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;file&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;stderr&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;assignment&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;d&lt;/span&gt;&lt;span&gt;]&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;a&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;update_watchlist&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;instance&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;watchlist&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;d&lt;/span&gt; &lt;span&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;|&lt;/span&gt; &lt;span&gt;a&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;assignment&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;verbose&lt;/span&gt;&lt;span&gt;):&lt;/span&gt; &lt;span&gt;for&lt;/span&gt; &lt;span&gt;a&lt;/span&gt; &lt;span&gt;in&lt;/span&gt; &lt;span&gt;solve&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;instance&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;watchlist&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;assignment&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;d&lt;/span&gt; &lt;span&gt;+&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;verbose&lt;/span&gt;&lt;span&gt;):&lt;/span&gt; &lt;span&gt;yield&lt;/span&gt; &lt;span&gt;a&lt;/span&gt; &lt;span&gt;assignment&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;d&lt;/span&gt;&lt;span&gt;]&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;None&lt;/span&gt; &lt;/pre&gt;&lt;/div&gt; &lt;/div&gt; &lt;div id="making-it-iterative"&gt; &lt;h3&gt;Making It Iterative &lt;sup&gt;*&lt;/sup&gt;&lt;/h3&gt; &lt;p&gt;For fun, let's see if we can implement the above algorithm without recursion. This is in fact how Knuth implements the algorithm. (He seems to dislike recursion, see for example &lt;a href="https://www.quora.com/Stanford-University/What-is-it-like-to-be-in-a-class-taught-by-Donald-Knuth"&gt;this story on Quora&lt;/a&gt;.)&lt;/p&gt; &lt;p&gt;The basic idea here is to manually keep track of the current state of the backtrack tree. When we use recursion, the state is kept implicitly using the stack and which instruction is executing in each of the function calls. In the iterative case, we will store the state using &lt;tt&gt;d&lt;/tt&gt; which is the current depth of the backtrack tree we are currently in, and also the variable we are to assign to currently, and the &lt;tt&gt;state&lt;/tt&gt; list which keeps track of which assignments for each variable have been tried so far. Here is the code:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;def&lt;/span&gt; &lt;span&gt;solve&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;instance&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;watchlist&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;assignment&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;d&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;verbose&lt;/span&gt;&lt;span&gt;):&lt;/span&gt; &lt;span&gt;"""&lt;/span&gt; &lt;span&gt; Iteratively solve SAT by assigning to variables d, d+1, ..., n-1. Assumes&lt;/span&gt; &lt;span&gt; variables 0, ..., d-1 are assigned so far. A generator for all the&lt;/span&gt; &lt;span&gt; satisfying assignments is returned.&lt;/span&gt; &lt;span&gt; """&lt;/span&gt; &lt;span&gt;# The state list wil keep track of what values for which variables&lt;/span&gt; &lt;span&gt;# we have tried so far. A value of 0 means nothing has been tried yet,&lt;/span&gt; &lt;span&gt;# a value of 1 means False has been tried but not True, 2 means True but&lt;/span&gt; &lt;span&gt;# not False, and 3 means both have been tried.&lt;/span&gt; &lt;span&gt;n&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;len&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;instance&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;variables&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;state&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;]&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; &lt;span&gt;n&lt;/span&gt; &lt;span&gt;while&lt;/span&gt; &lt;span&gt;True&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;d&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;n&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;yield&lt;/span&gt; &lt;span&gt;assignment&lt;/span&gt; &lt;span&gt;d&lt;/span&gt; &lt;span&gt;-=&lt;/span&gt; &lt;span&gt;1&lt;/span&gt; &lt;span&gt;continue&lt;/span&gt; &lt;span&gt;# Let's try assigning a value to v. Here would be the place to insert&lt;/span&gt; &lt;span&gt;# heuristics of which value to try first.&lt;/span&gt; &lt;span&gt;tried_something&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;False&lt;/span&gt; &lt;span&gt;for&lt;/span&gt; &lt;span&gt;a&lt;/span&gt; &lt;span&gt;in&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;]:&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;state&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;d&lt;/span&gt;&lt;span&gt;]&lt;/span&gt; &lt;span&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span&gt;a&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;&amp;amp;&lt;/span&gt; &lt;span&gt;1&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;verbose&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;print&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;'Trying {} = {}'&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;format&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;instance&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;variables&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;d&lt;/span&gt;&lt;span&gt;],&lt;/span&gt; &lt;span&gt;a&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;file&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;stderr&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;tried_something&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;True&lt;/span&gt; &lt;span&gt;# Set the bit indicating a has been tried for d&lt;/span&gt; &lt;span&gt;state&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;d&lt;/span&gt;&lt;span&gt;]&lt;/span&gt; &lt;span&gt;|=&lt;/span&gt; &lt;span&gt;1&lt;/span&gt; &lt;span&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span&gt;a&lt;/span&gt; &lt;span&gt;assignment&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;d&lt;/span&gt;&lt;span&gt;]&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;a&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;not&lt;/span&gt; &lt;span&gt;update_watchlist&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;instance&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;watchlist&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;d&lt;/span&gt; &lt;span&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span&gt;1&lt;/span&gt; &lt;span&gt;|&lt;/span&gt; &lt;span&gt;a&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;assignment&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;verbose&lt;/span&gt;&lt;span&gt;):&lt;/span&gt; &lt;span&gt;assignment&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;d&lt;/span&gt;&lt;span&gt;]&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;None&lt;/span&gt; &lt;span&gt;else&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;d&lt;/span&gt; &lt;span&gt;+=&lt;/span&gt; &lt;span&gt;1&lt;/span&gt; &lt;span&gt;break&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;not&lt;/span&gt; &lt;span&gt;tried_something&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;d&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;# Can't backtrack further. No solutions.&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;else&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;# Backtrack&lt;/span&gt; &lt;span&gt;state&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;d&lt;/span&gt;&lt;span&gt;]&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;0&lt;/span&gt; &lt;span&gt;assignment&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;d&lt;/span&gt;&lt;span&gt;]&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;None&lt;/span&gt; &lt;span&gt;d&lt;/span&gt; &lt;span&gt;-=&lt;/span&gt; &lt;span&gt;1&lt;/span&gt; &lt;/pre&gt;&lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id="theoretical-and-practical-significance"&gt; &lt;h2&gt;Theoretical and Practical Significance &lt;sup&gt;*&lt;/sup&gt;&lt;/h2&gt; &lt;p&gt;All right, so SAT is a cool problem, sure; possibly even useful. But why is it given so much importance? The short answer is that many other problems, often "difficult" problems, can be reduced to SAT. Let's consider an example first, and then look at Stephen Cook's result that established SAT as the first NP-complete problem, to get a sense of both practical applications of SAT, and its theoretical importance.&lt;/p&gt; &lt;div id="four-colouring"&gt; &lt;h3&gt;Four Colouring &lt;sup&gt;*&lt;/sup&gt;&lt;/h3&gt; &lt;p&gt;You might have heard of the "four colour theorem". In simplest terms, it states that the regions in any map can be coloured using at most four colours such that no two neighbouring regions are coloured the same. See the &lt;a href="https://en.wikipedia.org/wiki/Four_colour_theorem"&gt;Wikipedia page&lt;/a&gt; on it for more details.&lt;/p&gt; &lt;p&gt;This lends itself to a simple decision problem: given a map, is it possible to colour it using 4 or less colours such that no two neighbouring regions are the same colour? The four colour theorem is then true if and only if the answer to this decision problem is always true (provided the input map meets the requirements of a planar graph, a detail we are not too concerned with here). As input, we will take the number of regions &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; , and assume the regions are labelled using numbers &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;1&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; to &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; , and a list of neighbouring regions of the form &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;{&lt;/mo&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo separator="true"&gt;,&lt;/mo&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;mo&gt;}&lt;/mo&gt;&lt;/mrow&gt;\{i, j\}&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; with &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;̸&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/mrow&gt;i \ne j&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; , indicating regions &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/mrow&gt;i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/mrow&gt;j&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; are neighbours. Let us use colours red (R), blue (B), green (G), and yellow (Y) to colour the regions. Our variables are going to be &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;R_i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; , &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;B_i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; , &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;G&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;G_i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;Y_i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; , for &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;1 \le i \le n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; , indicating that region &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/mrow&gt;i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; is coloured red, blue, green, or yellow, respectively.&lt;/p&gt; &lt;p&gt;Next, we need to construct the right set of clauses such that if all of them are satisfied, then we have a proper colouring of the map. Specifically, we need every region to be coloured, and we need no two neighbouring regions to be the same colour. First, let us construct the clauses that will make sure every region has one and only one colour assigned to it. For this, we need to make sure only one of &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;R_i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; , &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;B_i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; , &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;G&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;G_i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; or &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;Y_i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; is picked for our assignment at a time. We can express this in terms of &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;/mrow&gt;K&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; clauses for each region &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/mrow&gt;i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; . First, we add &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;∨&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;∨&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;G&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;∨&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;R_i \vee B_i \vee G_i \vee Y_i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; as a clause, which ensures that region &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/mrow&gt;i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; gets at least one colour assigned to it. Then for pair of colours, say &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;/mrow&gt;R&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;/mrow&gt;B&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; , we add the clause &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;∼&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;∨&lt;/mo&gt;&lt;mo&gt;∼&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;\sim R_i \vee \sim B_i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; which basically says "not both of &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;R_i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;B_i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; can be picked at the same time", effectively making sure that exactly one colour is assigned to each region. Finally, for any two neighbouring regions, say &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/mrow&gt;i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/mrow&gt;j&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; , and each colour, say &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;/mrow&gt;R&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; , we add the clause &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;∼&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;∨&lt;/mo&gt;&lt;mo&gt;∼&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;\sim R_i \vee \sim R_j&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; which says not both of &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/mrow&gt;i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/mrow&gt;j&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; can be coloured red.&lt;/p&gt; &lt;p&gt;Let's look at a very simple example. Suppose our map has only two regions, regions &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;1&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mrow&gt;2&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; and that they are neighbours. Then our SAT input would be:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;# Assign at least one colour to region 1&lt;/span&gt; R1 B1 G1 Y1 &lt;span&gt;# But no more than one colour&lt;/span&gt; ~R1 ~B1 ~R1 ~G1 ~R1 ~Y1 ~B1 ~G1 ~B1 ~Y1 ~G1 ~Y1 &lt;span&gt;# Similarly for region 2&lt;/span&gt; R2 B2 G2 Y2 ~R2 ~B2 ~R2 ~G2 ~R2 ~Y2 ~B2 ~G2 ~B2 ~Y2 ~G2 ~Y2 &lt;span&gt;# Make sure regions 1 and 2 are not coloured the same since they are neighbours&lt;/span&gt; ~R1 ~R2 ~B1 ~B2 ~G1 ~G2 ~Y1 ~Y2 &lt;/pre&gt;&lt;/div&gt; &lt;p&gt;Running this through our SAT solver gives:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ python sat.py --brief --all &amp;lt; tests/colouring/01.in Y1 G2 Y1 B2 Y1 R2 G1 Y2 G1 B2 G1 R2 B1 Y2 B1 G2 B1 R2 R1 Y2 R1 G2 R1 B2 &lt;/pre&gt;&lt;/div&gt; &lt;p&gt;As you can see, there are many possible solutions, since in such a simple case we have a valid colouring as long as we assign a different colour to each region, which can be done in &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;mo&gt;⋅&lt;/mo&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;12&lt;/mn&gt;&lt;/mrow&gt;4 \cdot 3 = 12&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; ways, corresponding precisely to the &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;12&lt;/mn&gt;&lt;/mrow&gt;12&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; solutions given by our SAT solver.&lt;/p&gt; &lt;p&gt;In the next section, we see that a much broader set of problems can be reduced to SAT.&lt;/p&gt; &lt;p&gt;In general, the decision problem of the above example is known as graph colouring, or GT4 in Garey-Johnson's naming, where given a graph and a number &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/mrow&gt;k&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; the decision problem is to determine if a &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/mrow&gt;k&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; -colouring for the graph exists. In the above, we had &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;4.&lt;/mn&gt;&lt;/mrow&gt;k=4.&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; In this more general definition, with &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; regions, our reduction to SAT involves introducing &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;⋅&lt;/mo&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;k\cdot n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; variables and&lt;/p&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;⋅&lt;/mo&gt;&lt;mrow&gt;&lt;mo fence="true"&gt;(&lt;/mo&gt;&lt;mfrac linethickness="0px"&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mfrac&gt;&lt;mo fence="true"&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;⋅&lt;/mo&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;/mrow&gt; 1 + n \cdot \binom{k}{2} + k \cdot e &lt;/math&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;clauses, where &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;/mrow&gt;e&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; is the number of edges. Since &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;e = O(n^2)&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; (in fact, &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;e = O(n)&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; for planar graphs), the number of variables and clauses in our construction above are polynomials in &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/mrow&gt;k&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; . Hence we have a polynomial-time reduction to SAT. The significance of this is discussed further in the next section.&lt;/p&gt; &lt;/div&gt; &lt;div id="np-completeness-of-sat"&gt; &lt;h3&gt;NP-Completeness Of SAT &lt;sup&gt;*&lt;/sup&gt;&lt;/h3&gt; &lt;p&gt;In previous section we saw how a problem regarding colouring of regions in a map can be reduced to SAT. This can be further generalized to much larger class of problems: any decision problem that can be decided in polynomial time using a non-deterministic Turing machine can be reduced in polynomial time to SAT. This was first proved in Stephen Cook's paper &lt;a href="http://4mhz.de/cook.html"&gt;"The Complexity of Theorem-Proving Procedures"&lt;/a&gt;, which is the paper that introduced the famous P = NP question as well. Let's go over the basic idea in the paper very briefly here. If you are interested in more details, make sure you have a look at the paper, as it is rather short and a pleasure to read.&lt;/p&gt; &lt;p&gt;But before we go into detail, let us take a moment to discuss why it is of such importance. First, nobody has yet come up with an efficient (polynomial time) algorithm to solve SAT in its generality. (SAT with some restrictions, e.g. 2-SAT, can be solved efficiently though.) Showing that a problem can be reduced to SAT means that if we find an efficient algorithm for SAT then we have found an efficient algorithm for that problem as well. For example, if we find a polynomial-time algorithm for SAT then we immediately have a polynomial-time algorithm for the graph colouring problem given above.&lt;/p&gt; &lt;p&gt;Now, the class of decision problems that can be solved in polynomial-time using a non-deterministic Turing machine is known as NP (which stands for Non-deterministic Polynomial). This is a very large class of problems, since Turing machines are one of the most general computational models we have, and even though we are limited to polynomial-time Turing machines, the fact that the Turing machine does not have to be deterministic allows us much more freedom. Some examples of problems that are in NP are:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;all problems in P, e.g. determining if a number is prime or not (PRIMES), and decision versions of shortest path, network flow, etc.,&lt;/li&gt; &lt;li&gt;integer factorization,&lt;/li&gt; &lt;li&gt;graph colouring,&lt;/li&gt; &lt;li&gt;SAT,&lt;/li&gt; &lt;li&gt;and all NP-complete problems (see &lt;a href="https://en.wikipedia.org/wiki/List_of_NP-complete_problems"&gt;here&lt;/a&gt; for a rather large list of examples).&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;A problem is said to be NP-complete if it, in addition to being in NP, also has the property that any other problem in NP can be reduced to it in polynomial-time. Cook's paper proved SAT to be NP-complete. In fact, since that paper introduced the concept of NP-completeness, SAT was the first problem to be proved NP-complete. Since then, many other problems have been shown to be NP-complete, often by showing that SAT (or 3-SAT) can be reduced in polynomial-time to those problems (converse of what we proved earlier for graph colouring).&lt;/p&gt; &lt;p&gt;Now, as promised, let's briefly look at why SAT is NP-complete. For this, we need to know more precisely what a Turing machine is. Unfortunately, this would involve a bit more detail than I want to include in this section. So instead, I am going to show that if a problem can be solved using a finite-state machine (FSM) then it be reduced in polynomial-time to SAT. The case for Turing machines, which are a generalizations of finite-state machines (Turing machines are basically FSM's with the addition of a tape that they can read from and write to), is quite similar, just more complicated. I encourage you to read Cook's original paper for details of the proof with Turing machines.&lt;/p&gt; &lt;p&gt;First, let's define what an FSM is. In simplest terms, an FSM is a program that has a finite number of states, and that when fed an input character, moves to another state (or possibly stays in the same state) based on a fixed set of rules. Also, some states are taken as "accepting" states. Given an input string, we feed the string character by character into the FSM, and if at the end the FSM is in an accepting state, the answer to our decision problem is yes. If not, the answer is no.&lt;/p&gt; &lt;p&gt;The below code shows how an FSM could can be implemented in Python. Note that in this implementation, we are forced to have a &lt;em&gt;deterministic&lt;/em&gt; FSM. Let's ignore this detail for now though. This particular example implements an FSM that accepts input strings that contain an even number of ones.&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;from&lt;/span&gt; &lt;span&gt;__future__&lt;/span&gt; &lt;span&gt;import&lt;/span&gt; &lt;span&gt;print_function&lt;/span&gt; &lt;span&gt;def&lt;/span&gt; &lt;span&gt;even_ones&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;s&lt;/span&gt;&lt;span&gt;):&lt;/span&gt; &lt;span&gt;# Two states:&lt;/span&gt; &lt;span&gt;# - 0 (even number of ones seen so far)&lt;/span&gt; &lt;span&gt;# - 1 (odd number of ones seen so far)&lt;/span&gt; &lt;span&gt;rules&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;{(&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;'0'&lt;/span&gt;&lt;span&gt;):&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;'1'&lt;/span&gt;&lt;span&gt;):&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;'0'&lt;/span&gt;&lt;span&gt;):&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;'1'&lt;/span&gt;&lt;span&gt;):&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;}&lt;/span&gt; &lt;span&gt;# There are 0 (which is an even number) ones in the empty&lt;/span&gt; &lt;span&gt;# string so we start with state = 0.&lt;/span&gt; &lt;span&gt;state&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;0&lt;/span&gt; &lt;span&gt;for&lt;/span&gt; &lt;span&gt;c&lt;/span&gt; &lt;span&gt;in&lt;/span&gt; &lt;span&gt;s&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;state&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;rules&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;state&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;c&lt;/span&gt;&lt;span&gt;]&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;state&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;0&lt;/span&gt; &lt;span&gt;# Example usage:&lt;/span&gt; &lt;span&gt;s&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;"001100110"&lt;/span&gt; &lt;span&gt;print&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;'Output for {} = {}'&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;format&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;s&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;even_ones&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;s&lt;/span&gt;&lt;span&gt;)))&lt;/span&gt; &lt;/pre&gt;&lt;/div&gt; &lt;p&gt;So the core of an FSM is a list of rules of the form &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mo separator="true"&gt;,&lt;/mo&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;→&lt;/mo&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/mrow&gt;(S, c) \rightarrow T&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; which says if the FSM is in state &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;/mrow&gt;S&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; and receives input character &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;/mrow&gt;c&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; then it goes to state &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/mrow&gt;T&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; . If for any unique pair of &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mo separator="true"&gt;,&lt;/mo&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;(S, c)&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; there is only one rule &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mo separator="true"&gt;,&lt;/mo&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;→&lt;/mo&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/mrow&gt;(S, c) \rightarrow T&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; then the FSM is said to be deterministic. This is because the FSM will never need to make a "choice" as to which of the rules to apply. With non-deterministic FSM's, the definition of acceptance needs to be modified a bit: if &lt;em&gt;any&lt;/em&gt; set of choices of rules would get us to an accepting state given an input then the input is said to be accepted. It is a well-established result in Automata theory that deterministic and non-deterministic FSM's are computationally equally powerful, because any non-deterministic FSM can be translated to an equivalent deterministic one by the &lt;a href="https://en.wikipedia.org/wiki/Powerset_construction"&gt;"powerset construction" method&lt;/a&gt;. The equivalent deterministic FSM might have an exponentially larger number of states compared to the non-deterministic one, however.&lt;/p&gt; &lt;p&gt;It is also well-known that FSM's can solve a class of problems known as "regular" problems. What this means, in very simple terms, is that if you can write a regular expression that would accept the "yes" instances of your decision problem, then you can solve the problem using an FSM. In fact, regular expressions are often implemented using FSM-like structures. The "compile" phase of using regular expression is precisely when the regular expression engine builds the FSM-like structure from your regular expression. (Exercise: Find a regular expression that accepts the above language, namely binary strings with an even number of ones.)&lt;/p&gt; &lt;p&gt;All right, so let's say a decision problem can be solved using an FSM with states numbered &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;1&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; to &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; . For simplicity, let's assume that our input will be binary (character set is &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;{&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo separator="true"&gt;,&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;}&lt;/mo&gt;&lt;/mrow&gt;\{0, 1\}&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; ). Suppose the FSM has &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/mrow&gt;k&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; rules given by &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo separator="true"&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;→&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;(S_i, c_i) \rightarrow T_i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; , for &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/mrow&gt;1 \le i \le k&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; . And assume the input characters are given by &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;/mrow&gt;s_1&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; to &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;s_m&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; . So our input is of length &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mrow&gt;m&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; . Finally, assume that the initial state is &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;1&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; and accepting states are &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;/mrow&gt;a_1&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; to &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;a_q&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; , where &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;/mrow&gt;q&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; is the number of accepting states.&lt;/p&gt; &lt;p&gt;Following Cook's footsteps, we will introduce the following variables for our SAT reduction:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;P_t&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; which is true iff &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;s_t = 1&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; ,&lt;/li&gt; &lt;li&gt;and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msubsup&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msubsup&gt;&lt;/mrow&gt;Q^i_t&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; which is true iff the FSM is in state &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/mrow&gt;i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; after input character &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;s_t&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; has been fed into the FSM, for &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;&amp;lt;&lt;/mo&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;1 \le i &amp;lt; j \le n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mrow&gt;0 \le t \le m&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; . We will take &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;t=0&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; to be the starting step, before anything has been fed into the FSM.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;With these definitions, we proceed to translate the question of whether the input is accepted by the FSM into an instance of SAT. The goal is to produce a set of clauses that are satisfiable iff the FSM ends in an accepting state given the particular input. The clauses that will accomplish this are:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;P_t&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; for &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mrow&gt;0 \le t \le m&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; such that &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;s_t = 1&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;∼&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;\sim P_t&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; for all other &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mrow&gt;1 \le t \le m&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; . These will be the first &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mrow&gt;m&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; clauses, each consisting of a single literal.&lt;/li&gt; &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msubsup&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/msub&gt;&lt;/msubsup&gt;&lt;/mrow&gt;Q^{a_j}_{m}&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; for &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;/mrow&gt;1 \le j \le q&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; . This says that after the last character is fed into the FSM, we want to be in one of the accepting states.&lt;/li&gt; &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;∼&lt;/mo&gt;&lt;msubsup&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msubsup&gt;&lt;mo&gt;∨&lt;/mo&gt;&lt;mo&gt;∼&lt;/mo&gt;&lt;msubsup&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/msubsup&gt;&lt;/mrow&gt;\sim Q^i_t \vee \sim Q^j_t&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; for any &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;&amp;lt;&lt;/mo&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;1 \le i &amp;lt; j \le n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mrow&gt;1 \le t \le m&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; , which effectively says that the FSM can not be in both states &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/mrow&gt;i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/mrow&gt;j&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; at step &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;t&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; . Collectively, these clauses will ensure that the FSM is not in more than one state at a time.&lt;/li&gt; &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msubsup&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msubsup&gt;&lt;mo&gt;∨&lt;/mo&gt;&lt;mo&gt;…&lt;/mo&gt;&lt;mo&gt;∨&lt;/mo&gt;&lt;msubsup&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/msubsup&gt;&lt;/mrow&gt;Q^1_t \vee \ldots \vee Q^n_t&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; for &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mrow&gt;1 \le t \le m&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; . This says that the FSM needs to be in at least one state at any step. Together with the last set of clauses, we ensure that the FSM is in exactly one state at any step.&lt;/li&gt; &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;∼&lt;/mo&gt;&lt;msubsup&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;msub&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/msubsup&gt;&lt;mo&gt;∨&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;∨&lt;/mo&gt;&lt;msubsup&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/msubsup&gt;&lt;/mrow&gt;\sim Q^{S_i}_{t-1} \vee P_t \vee Q^{T_i}_{t}&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; for all rules &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo separator="true"&gt;,&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;→&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;(S_i, 0) \rightarrow T_i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;∼&lt;/mo&gt;&lt;msubsup&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;msub&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/msubsup&gt;&lt;mo&gt;∨&lt;/mo&gt;&lt;mo&gt;∼&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;∨&lt;/mo&gt;&lt;msubsup&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/msubsup&gt;&lt;/mrow&gt;\sim Q^{S_i}_{t-1} \vee \sim P_t \vee Q^{T_i}_{t}&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; for all rules &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo separator="true"&gt;,&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;→&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;(S_i, 1) \rightarrow T_i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; , for &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mrow&gt;1 \le t \le m&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; . These clauses are logically equivalent to "&lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msubsup&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;msub&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/msubsup&gt;&lt;/mrow&gt;Q^{S_i}_{t-1}&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;P_t&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; implies &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msubsup&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/msubsup&gt;&lt;/mrow&gt;Q^{T_i}_{t}&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; " which is equivalent to &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo separator="true"&gt;,&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;→&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;(S_i, 1) \rightarrow T_i&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; . In other words, they ensure proper transition between states based on the input.&lt;/li&gt; &lt;li&gt;Finally, we want to start in the initial state so we add the clause &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msubsup&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msubsup&gt;&lt;/mrow&gt;Q^1_0&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; .&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Let's see this in action for the above FSM which accepts strings with an even number of ones in them. First, we have two states, so &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mrow&gt;n=2&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; . Let's build the SAT instance to handle inputs of length &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;t&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; . Also note that we can leave out the first set of clauses (the &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;P_t&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;∼&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;\sim P_t&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; ones), in which case any SAT assignment will give us some accepted input. Which means we can list all the strings accepted by the FSM by looking at all the satisfying assignments of the above set of clauses.&lt;/p&gt; &lt;p&gt;Here is an example for &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/mrow&gt;t=3&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; . In this input &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;msubsup&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msubsup&gt;&lt;/mrow&gt;Q^i_t&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; is written as &lt;cite&gt;Qi-t&lt;/cite&gt;. The states are also labelled &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;0&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;1&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; instead of &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;1&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; to &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;n&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; in the above.&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;# No more than one state at each step&lt;/span&gt; ~Q0-0 ~Q1-0 ~Q0-1 ~Q1-1 ~Q0-2 ~Q1-2 ~Q0-3 ~Q1-3 &lt;span&gt;# At least one state in each step&lt;/span&gt; Q0-0 Q1-0 Q0-1 Q1-1 Q0-2 Q1-2 Q0-3 Q1-3 &lt;span&gt;# Add the rules&lt;/span&gt; &lt;span&gt;# (EVEN, 1) -&amp;gt; ODD&lt;/span&gt; ~Q0-0 ~P1 Q1-1 ~Q0-1 ~P2 Q1-2 ~Q0-2 ~P3 Q1-3 &lt;span&gt;# (ODD, 1) -&amp;gt; EVEN&lt;/span&gt; ~Q1-0 ~P1 Q0-1 ~Q1-1 ~P2 Q0-2 ~Q1-2 ~P3 Q0-3 &lt;span&gt;# (EVEN, 0) -&amp;gt; EVEN&lt;/span&gt; ~Q0-0 P1 Q0-1 ~Q0-1 P2 Q0-2 ~Q0-2 P3 Q0-3 &lt;span&gt;# (ODD, 0) -&amp;gt; ODD&lt;/span&gt; ~Q1-0 P1 Q1-1 ~Q1-1 P2 Q1-2 ~Q1-2 P3 Q1-3 &lt;span&gt;# Start in state 0&lt;/span&gt; Q0-0 &lt;span&gt;# End in an accepting state&lt;/span&gt; Q0-3 &lt;/pre&gt;&lt;/div&gt; &lt;p&gt;Let's see the output of running a SAT solver on this, and another file for &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/mrow&gt;t=3&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; and &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;/mrow&gt;t=4&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; :&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ python sat.py --all --starting_with P --brief &amp;lt; tests/fsm/even-ones-3.in P1 P3 P1 P2 P2 P3 $ python sat.py --all --starting_with P --brief &amp;lt; tests/fsm/even-ones-4.in P1 P4 P1 P3 P1 P2 P3 P4 P1 P2 P2 P4 P2 P3 P3 P4 &lt;/pre&gt;&lt;/div&gt; &lt;p&gt;As expected, all the possible ways of picking a subset of &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;{&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo separator="true"&gt;,&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo separator="true"&gt;,&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;mo&gt;}&lt;/mo&gt;&lt;/mrow&gt;\{P1, P2, P3 \}&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; with an even number of elements in them are listed above, and similarly for &lt;span&gt;&lt;span&gt;&lt;math&gt;&lt;mrow&gt;&lt;mo&gt;{&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo separator="true"&gt;,&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo separator="true"&gt;,&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;mo separator="true"&gt;,&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;mo&gt;}&lt;/mo&gt;&lt;/mrow&gt;\{P1, P2, P3, P4 \}&lt;/math&gt;&lt;/span&gt;&lt;/span&gt; , although not necessarily in any meaningful order. (Notice that the empty lines are the empty subsets, which also have even numbers of ones.)&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/section&gt; &lt;/div&gt;&lt;a href="https://sahandsaba.com/understanding-sat-by-implementing-a-simple-sat-solver-in-python.html"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:22:09 UT
      </pubDate>
      <guid>
        https://sahandsaba.com/understanding-sat-by-implementing-a-simple-sat-solver-in-python.html
      </guid>
    </item>
    <item>
      <title>
        Clever Functional Design
      </title>
      <link>
        https://ferd.ca/clever-functional-design.html
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;article&gt; &lt;span&gt;2019/08/24&lt;/span&gt; &lt;h2&gt;Clever Functional Design&lt;/h2&gt; &lt;p&gt;One of the best bits of software design I recall participating in was something done a few years ago at Heroku. It's been long enough since then that I feel comfortable boasting about it here. It's one small piece of data-centred functional design, where thinking a bit harder about the problem at hand greatly simplified what would have been a more straightforward and obvious implementation choice in a mutable language.&lt;/p&gt; &lt;h3&gt;The Feature&lt;/h3&gt; &lt;p&gt;Heroku's routing stack had one very interesting feature it provided to all users: a router log. The router log contains fields such as the overall request time, the time it took to send the request, the time it took to send the body, &lt;a href="https://devcenter.heroku.com/articles/error-codes"&gt;heroku-specific error codes&lt;/a&gt; and so on. They're broader categories of interesting time span.&lt;/p&gt; &lt;p&gt;At the same time, Heroku engineers had internal logs for all the requests for which users had public logs. These internal logs contained more detailed information that more often made sense to display during specific debugging activities. They included information such as time spent parsing headers from the client, time to first response packet (calculating what would essentially be the time after which the whole request was sent, but before which the back-end application would respond), POSIX statuses detected by the proxy on socket issues, and so on.&lt;/p&gt; &lt;p&gt;During more intricate debugging, other values could be required from the logs, but adding them would need code changes. This information was maintained in what was essentially a monolithic proxy that contained both the business logic (what logs to create, which servers to route to, and so on) and the proxying logic (how to shuttle HTTP from point A to point B).&lt;/p&gt; &lt;p&gt;At some point during my Heroku days, we rewrote the entire routing stack to clearly divide the business concerns (routing and features for Heroku apps) and the proxying logic. The idea was to clean up deeply intertwined code, &lt;a href="https://devcenter.heroku.com/articles/http-routing"&gt;clarify and properly specify the proxying behaviour&lt;/a&gt;, and allow to reason about and change what we offered to customers without having to know all the innards of HTTP proxying logic to do so. This divide was successful, and eventually allowed us to open source the proxying logic: since it was no longer business related and was commodity infrastructure, &lt;a href="https://github.com/heroku/vegur"&gt;vegur&lt;/a&gt; became public.&lt;/p&gt; &lt;p&gt;This division came with a few challenges though, and one of them was with the logs: how were we to take a Heroku feature, such as the router logs we had, with their own specific needs that could change according to business requirements, and bake them into a generic proxy library, where all the interesting measurements and samplings were to take place?&lt;/p&gt; &lt;h3&gt;The Straightforward Design&lt;/h3&gt; &lt;p&gt;The approach we took in the original router was to just take all the samples as we needed them, mostly as spans. You essentially just intersperse the logging and observational needs with the actual business end of the code, and do what you must.&lt;/p&gt; &lt;p&gt;One straightforward way to do this is with timestamps and might look something like this:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;T1&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;stamp&lt;/span&gt;&lt;span&gt;(),&lt;/span&gt; &lt;span&gt;do_something&lt;/span&gt;&lt;span&gt;(),&lt;/span&gt; &lt;span&gt;T2&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;stamp&lt;/span&gt;&lt;span&gt;(),&lt;/span&gt; &lt;span&gt;report_duration&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"some label"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;T2&lt;/span&gt;&lt;span&gt;-&lt;/span&gt;&lt;span&gt;T1&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;/pre&gt;&lt;/div&gt; &lt;p&gt;You take a timestamp, do the thing, take a second timestamp, and report the difference as the duration of the operation. Eventually you get tired of doing this, and you might wrap them up in a helper that takes a closure (or wraps some object in OO design) and hides the reporting:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;with_timestamp&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"some label"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;fun&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&amp;gt;&lt;/span&gt; &lt;span&gt;do_something&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;end&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;/pre&gt;&lt;/div&gt; &lt;p&gt;Both approaches work fine. The latter offers slightly more encapsulation, and also prevents having overlapping timestamps where two measurements intersect. The logic is always set at the call-site, and things can be a bit tricky with error handling, but that's generally how you do it. The same kind of approach is still rather broadly used in &lt;a href="https://opensource.com/article/18/9/distributed-tracing-microservices-world"&gt;distributed tracing&lt;/a&gt; with the addition of a &lt;em&gt;context&lt;/em&gt;, which lets you define some lineage or nesting of operations:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;%% approach 1&lt;/span&gt; &lt;span&gt;Ctx&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;new_span&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"some label"&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;T1&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;stamp&lt;/span&gt;&lt;span&gt;(),&lt;/span&gt; &lt;span&gt;NewCtx&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;do_something&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Ctx&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;T2&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;stamp&lt;/span&gt;&lt;span&gt;(),&lt;/span&gt; &lt;span&gt;close_span&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;NewCtx&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;%% approach 2&lt;/span&gt; &lt;span&gt;with_span&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"some_label"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;fun&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Ctx&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&amp;gt;&lt;/span&gt; &lt;span&gt;do_something&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Ctx&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;end&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;/pre&gt;&lt;/div&gt; &lt;p&gt;Of course if you've got mutability going on and some global scope available, you'll cheat a bit and hide the span context within the program's state differently.&lt;/p&gt; &lt;p&gt;In any case, the old approach was based on these kinds of mechanism. When time came to split them up into their business and general parts, the tools used for logging needed to be decoupled as well. The general and straightforward approach to that is to do it through dependency injection. Our new approaches might now look something like this:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;f&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Logger&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&amp;gt;&lt;/span&gt; &lt;span&gt;T1&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;stamp&lt;/span&gt;&lt;span&gt;(),&lt;/span&gt; &lt;span&gt;do_something&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Logger&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;T2&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;stamp&lt;/span&gt;&lt;span&gt;(),&lt;/span&gt; &lt;span&gt;Logger&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"some label"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;T2&lt;/span&gt;&lt;span&gt;-&lt;/span&gt;&lt;span&gt;T1&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;/pre&gt;&lt;/div&gt; &lt;p&gt;Kind of similarly to passing the context or a span in the distributed tracing approach, you now parametrize each contract of dependent functions to take some contextual cues that explain how to do things. It would have become a bit cumbersome to do it through all involved components of a proxying library, but it would have been possible to do it, and even more easily with tool or IDE support.&lt;/p&gt; &lt;p&gt;This, however, was the road we decided not to take.&lt;/p&gt; &lt;h3&gt;The Weakness of the Straightforward Approach&lt;/h3&gt; &lt;p&gt;The problem with the dependency injection approach, aside from its cumbersomeness, is that it did not sufficiently decouple what was a business concern from what was a generic library. Sure, we would hide and abstract away the tools chosen—which logging or tracing library would be used—but in no way would it really de-couple the design.&lt;/p&gt; &lt;p&gt;It would be tricky, for example, to properly track the concerns of "public user logs" and "internal engineer logs". The biggest design issue was something we uncovered by simply asking ourselves this question: if some other project were to use this library, would &lt;em&gt;their&lt;/em&gt; reporting need to change every time Heroku decided to log new metrics?&lt;/p&gt; &lt;p&gt;Sure, the implementation could be independent. But the straightforward design only de-coupled the technical dependencies and which code was used. It did not get rid of the logical coupling that still existed between Heroku's business logic and the proxy's need to just shuttle HTTP. If we went with that approach, there was still a very deep dependency between both code bases. Heroku would unsurprisingly rely on the proxy, but it &lt;em&gt;felt&lt;/em&gt; weird that the proxy's instrumentation would have to be defined by the Heroku product requirements.&lt;/p&gt; &lt;p&gt;Another slightly less important issue came from implementation details. I mention it not because it was a huge blocker to logical decoupling, but because this implementation detail ended up providing the key to the nicer design. The Vegur proxy had been written to use &lt;a href="https://stackoverflow.com/a/51376869/35344"&gt;&lt;code&gt;passive&lt;/code&gt; TCP sockets&lt;/a&gt; used in a blocking mode, because those were faster back in the day (implementation changes and optimizations within the BEAM VM have since then made this unnecessary). This, and other earlier design choices, made it so the proxy itself had 3 major moving parts:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;an HTTP server parsing module, which would listen to incoming requests from the public Internet and parse them&lt;/li&gt; &lt;li&gt;an HTTP client parsing module, which would forward the traffic to a customer's back-end and listen to the responses&lt;/li&gt; &lt;li&gt;an inner loop that would use both the client and server bits and would handle the data transfer across both of them as a bridge.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;This meant that some concerns we had in terms of metrics would sometimes reside all within one bit of code (i.e. the time it takes to parse headers is self-contained to any of the components), but sometimes it would cross boundaries. For example, knowing the time it took to parse the request body required taking measurements in the HTTP server, but which could be intertwined with operations taking place both in the inner loop and the HTTP client. It had no clear structural hierarchy.&lt;/p&gt; &lt;p&gt;Worse, some debugging scenarios required taking some measurements that started in the HTTP server, and finished in the HTTP client. That made it particularly difficult to localize and isolate concerns well, and the overall requirements of Heroku's reporting risked having a huge impact on the structure of the proxy.&lt;/p&gt; &lt;p&gt;Dependency injection would not be enough to fix this, we needed to think about the problem differently.&lt;/p&gt; &lt;h3&gt;A Functional Design&lt;/h3&gt; &lt;p&gt;Even in today's modern distributed tracing ecosystem, the design of most tracing libraries is deeply centered on the concept of a span: a pre-defined point A to point B period of time, which is written and instrumented as such in the code.&lt;/p&gt; &lt;p&gt;The big &lt;em&gt;Eureka!&lt;/em&gt; moment for our approach in Vegur was in realizing that what when debugging, what we care about is picking arbitrary points on a timeline. Spans let you represent things a bit like this:&lt;/p&gt; &lt;pre&gt;|------------------- Request --------------------| |--- Header Parsing ---|-- Body parsing --| ... |-- Cookie --| | ... | &lt;/pre&gt; &lt;p&gt;Those are contiguous subdivisions of the whole timeline. What we wanted, instead, was a flat timeline on which we could pick arbitrary intervals:&lt;/p&gt; &lt;pre&gt;request start end of request | | | start header parsing | | | first packet sent ... | | | | | | |-x--x--x------x---x----x------------------x-----x---...| | | | | | | | ... start body parsing | | end cookie end body parsing start cookie &lt;/pre&gt; &lt;p&gt;All these things happen in a continuum. The divisions of what we wanted to report were not structural to this timeline, they were views or selections of various points of interests, and a measurement between them. The "first packet sent" event is something that could be useful to multiple metrics:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;time between the first packet received and the first packet sent ("how long we took to process the headers"&lt;/li&gt; &lt;li&gt;time between header parsing being done and sending the first packet ("how long we took to make a routing decision")&lt;/li&gt; &lt;li&gt;time between the first packet sent and the last header packet sent ("time to send the request headers")&lt;/li&gt; &lt;li&gt;time between the first packet sent and the last request packet sent ("time to send the full request")&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;and so on. Being able to report on all of these was context-dependent for the consumer, meaning that's usually a business concern. But the proxying library itself only cared about specific arbitrary points we thought could be useful to its technical users.&lt;/p&gt; &lt;p&gt;&lt;em&gt;That&lt;/em&gt; distinction and approach as a timeline was the pivotal point we needed in the design. What the proxying library needed to do was not provide all the metrics and spans Heroku expected. What it needed to provide was the list of all important points on a timeline, whether they represented a singular event, or a duration. It would then be up to the consumer to report things however they wanted, whenever they wanted.&lt;/p&gt; &lt;p&gt;The flat timeline was particularly interesting for this because it is easily representable as an immutable data structure. If all you have is a bunch of local &lt;em&gt;monotonic&lt;/em&gt; timestamps, all you need to do is maintain a local data structure that maintains sequences of labelled points in time: &lt;code&gt;[{Label1, T1}, {Label2, T2}, ...]&lt;/code&gt;&lt;/p&gt; &lt;p&gt;Since timestamps are generally sortable locally—you need some fancy cheats to make it work in a distributed setting—then all the local timelines between the HTTP client, server, and inner loop modules could be maintained independently, but merged reliably: just sort by timestamp.&lt;/p&gt; &lt;pre&gt;|-x----------------x---------------------------------...| |--x--x------x--------x------------------| |—---------------------------x---...| | | | v v v |-x--x--x------x---x----x------------------x----x----...| &lt;/pre&gt; &lt;p&gt;This would let us write one generic well-defined data structure, use it wherever and whenever we needed it, and just merge them near the end of each timeline. No need to coordinate context-passing around, just a fetch and a merge once per item.&lt;/p&gt; &lt;p&gt;Then, the business end of code in Heroku's router could ask for that timeline once the request was ready to be logged, get one well-known data structure, and do as many selections for as many debugging reports as it required. If you wanted to send 15 logs out of there, it did not matter to the proxy library. Just analyze the timeline, generate what you need, and that's it.&lt;/p&gt; &lt;p&gt;Interestingly, since the final data structure could be represented easily in the base types of the language, Heroku's router was able to create its own compatible timeline that itself could be cast and merged with the proxy's timeline, without having them actually share the implementation (which would also have been fine). This would later let us augment the proxying logs with all the routing and business decisions for all kinds of debugging purposes (how much time would we spend queued to find an available back-end to route to?). This turned into app-specific routing flags that could allow to do deeper introspection of routing logic for specific applications, at nearly no overhead in code.&lt;/p&gt; &lt;h3&gt;Lesson Learned&lt;/h3&gt; &lt;p&gt;The approach itself here is mildly interesting. It has some intriguing implications in the context of designing implementations of distributed tracing libraries. The implementation is so straightforward in Vegur that I didn't spend the time to describe it here.&lt;/p&gt; &lt;p&gt;The true bigger lesson here is in systems design. It relates to functional, immutable, and declarative approaches to structuring communication flows.&lt;/p&gt; &lt;p&gt;The straightforward answer to our decoupling issue was to respond to the technical concern: just make it so the dependency does not know about the libraries used by its parent. I think it would have strictly speaking solved the most blocking problem in getting the code to build. This would have been easy to do, and the only thing that made it annoying was the fact we were using a functional programming language with no mutable data structures nor global shared context. But satisfying the compiler is not enough to make for good design. This approach would have made it hard to get maintainable code given implementation details, and did not remove any logical coupling.&lt;/p&gt; &lt;p&gt;Rather than dismissing this challenge as "a bad fit for functional programming", it is what led to a better solution: re-think the data structure, gain better insights in the distinction between &lt;em&gt;how the data is produced&lt;/em&gt; and &lt;em&gt;how the data is consumed&lt;/em&gt;. Take that separation, and make it explicit. Build around it. Turn it into a data contract. This, in turn, lets you more transparently change either ends. You might need to add new measurement points in the producer-side when the consumer needs it, but the properly declared abstraction makes it so the other consumers will not be effected by the change.&lt;/p&gt; &lt;p&gt;The end result was a purely functional data structure that was mergeable, testable, and in line with functional design, but that's just a technical aspect of the result: it was the structural constraint of already being in an immutable context that prompted the cleaner design. Most challenges of working in a functional, declarative, or immutable language are not necessarily due to the language itself. They come from being thrown in a context where easier shortcuts are not as practical as we are used for them to be, and having to re-think both our problem and our solutions.&lt;/p&gt; &lt;/article&gt;&lt;/div&gt;&lt;a href="https://ferd.ca/clever-functional-design.html"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:22:15 UT
      </pubDate>
      <guid>
        https://ferd.ca/clever-functional-design.html
      </guid>
    </item>
    <item>
      <title>
        Natural Language Processing: the age of Transformers
      </title>
      <link>
        https://blog.scaleway.com/2019/building-a-machine-reading-comprehension-system-using-the-latest-advances-in-deep-learning-for-nlp/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div id="site-main"&gt; &lt;article&gt; &lt;figure&gt; &lt;/figure&gt; &lt;div&gt; &lt;p&gt;&lt;em&gt;This article is the first installment of a two-post series on &lt;strong&gt;Building a machine reading comprehension system using the latest advances in deep learning for NLP&lt;/strong&gt;. Stay tuned for the second part, where we'll introduce a pre-trained model called BERT that will take your NLP projects to the next level!&lt;/em&gt;&lt;/p&gt;&lt;p&gt;In the recent past, if you specialized in natural language processing (NLP), there may have been times when you felt a little jealous of your colleagues working in computer vision. It seemed as if they had all the fun: the annual &lt;a href="https://machinelearningmastery.com/introduction-to-the-imagenet-large-scale-visual-recognition-challenge-ilsvrc/"&gt;ImageNet classification challenge&lt;/a&gt;, &lt;a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Gatys_Image_Style_Transfer_CVPR_2016_paper.html"&gt;Neural Style Transfer&lt;/a&gt;, &lt;a href="https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf"&gt;Generative Adversarial Networks&lt;/a&gt;, to name a few. At last, the dry spell is over, and the NLP revolution is well underway! It would be fair to say that the turning point was 2017, when the Transformer network was introduced in Google's &lt;em&gt;&lt;a href="https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf"&gt;Attention is all you need&lt;/a&gt;&lt;/em&gt; paper. Multiple further advances followed since then, one of the most important ones being BERT - the subject of our next article.&lt;/p&gt;&lt;p&gt;To lay the groundwork for the Transformer discussion, let's start by looking at one of the common categories of NLP tasks: the &lt;strong&gt;sequence to sequence (seq2seq)&lt;/strong&gt; problems. They are pretty much exactly what their name suggests: both the inputs and the outputs of a seq2seq task are &lt;em&gt;sequences&lt;/em&gt;. In the context of NLP, there are typicaly additional restrictions put in place:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The elements of the sequence are tokens corresponding to some set vocabulary (often including an &lt;em&gt;Unknown&lt;/em&gt; token for the out-of-vocabulary words)&lt;/li&gt; &lt;li&gt;The &lt;strong&gt;order&lt;/strong&gt; inside the sequence &lt;strong&gt;matters&lt;/strong&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Next we shall take a moment to remember the fallen heros, without whom we would not be where we are today. I am, of course, referring to the RNNs - Recurrent Neural Networks, a concept that became almost synonymous with NLP in the deep learning field.&lt;/p&gt; &lt;h2 id="1thepredecessortotransformersthernnencoderdecoder"&gt;1. The predecessor to Transformers: the RNN Encoder-Decoder&lt;/h2&gt; &lt;figure&gt;&lt;img alt="" src="https://blog.scaleway.com/content/images/2019/08/galaxy-2.jpg"&gt;&lt;/figure&gt;&lt;p&gt;This story takes us all the way back to 2014 (&lt;a href="https://www.aclweb.org/anthology/D14-1179"&gt;Ref&lt;/a&gt;, another &lt;a href="https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf"&gt;Ref&lt;/a&gt;), when the idea of approaching seq2seq problems via two Recurrent Neural Networks combined into an Encoder-Decoder model, was born. Let's demonstrate this architecture on a simple example from the Machine Translation task. Take a French-English sentence pair, where the input is &lt;em&gt;"je suis étudiant"&lt;/em&gt; and the output &lt;em&gt;"I am a student"&lt;/em&gt;. First, &lt;em&gt;"je"&lt;/em&gt; (or, most likely, a &lt;a href="http://hunterheidenreich.com/blog/intro-to-word-embeddings/"&gt;word embedding&lt;/a&gt; for the token representing &lt;em&gt;"je"&lt;/em&gt;), often accompanied by a constant vector &lt;em&gt;h&lt;sub&gt;E0&lt;/sub&gt;&lt;/em&gt; which could be either learned or fixed, gets fed into the Encoder RNN. This results in the output vector &lt;em&gt;h&lt;sub&gt;E1&lt;/sub&gt;&lt;/em&gt; (hidden state 1), which serves as the next input for the Encoder RNN, together with the second element in the input sequence &lt;em&gt;"suis"&lt;/em&gt;. The output of this operation, &lt;em&gt;h&lt;sub&gt;E2&lt;/sub&gt;&lt;/em&gt;, and &lt;em&gt;"étudiant"&lt;/em&gt; are again fed into the Encoder, producing the last &lt;em&gt;Encoded&lt;/em&gt; hidden state for this training sample, &lt;em&gt;h&lt;sub&gt;E3&lt;/sub&gt;&lt;/em&gt;. The &lt;em&gt;h&lt;sub&gt;E3&lt;/sub&gt;&lt;/em&gt; vector is dependent on all of the tokens inside the input sequence, so the idea is that it should represent the meaning of the entire phrase. For this reason it is also referred to as the &lt;em&gt;context vector&lt;/em&gt;. The &lt;em&gt;context vector&lt;/em&gt; is the first input to the Decoder RNN, which should then generate the first element of the output sequence &lt;em&gt;"I"&lt;/em&gt; (in reality, the last layer of the Decoder is typically a &lt;a href="https://medium.com/data-science-bootcamp/understand-the-softmax-function-in-minutes-f3a59641e86d"&gt;softmax&lt;/a&gt;, but for simplicity we can just keep the most likely element at the end of every Decoder step). Additionally, the Decoder RNN produces a hidden state &lt;em&gt;h&lt;sub&gt;D1&lt;/sub&gt;&lt;/em&gt;. We feed &lt;em&gt;h&lt;sub&gt;D1&lt;/sub&gt;&lt;/em&gt; and the previous output &lt;em&gt;I&lt;/em&gt; back into the Decoder to hopefully get &lt;em&gt;"am"&lt;/em&gt; as our second output. This process of generating and feeding outputs back into the Decoder continues until we produce an &lt;em&gt;&amp;lt;EOS&amp;gt;&lt;/em&gt; - the end of the sentence token, which signifies that our job here is done.&lt;/p&gt; &lt;figure&gt;&lt;img alt="" src="https://blog.scaleway.com/content/images/2019/08/RNN.jpg"&gt;&lt;figcaption&gt;The RNN Encoder-Decoder model in action. To avoid any confusion, there is something that I would like to draw your attention to. The multiple RNN blocks appear in the Figure because of the multiple elements of the sequence that get fed into / generated by the networks, but make no mistake - there is only one Encoder RNN and one Decoder RNN at play here. It may help to think of the repeated blocks as the same RNN at different timesteps, or as multiple RNNs with shared weights, that are envoked one after another.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;This architecture may seem simple (especially until we sit down to actually write the code with &lt;a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/"&gt;LSTMs&lt;/a&gt; or &lt;a href="https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be"&gt;GRUs&lt;/a&gt; thrown in for good measure), but it actually turns out to be remarkably effective for many NLP tasks. In fact, Google Translate has been using it under the hood since 2016. However, the RNN Encoder-Decoder models do suffer from certain drawbacks:&lt;/p&gt;&lt;h3 id="1a-first-problem-with-rnns-attention-to-the-rescue"&gt;1a. First problem with RNNs: Attention to the rescue&lt;/h3&gt;&lt;p&gt;The RNN approach as described above does not work particularly well for longer sentences. Think about it: the meaning of the entire input sequence is expected to be captured by a single &lt;em&gt;context vector&lt;/em&gt; with fixed dimensionality. This could work well enough for &lt;em&gt;"Je suis étudiant"&lt;/em&gt;, but what if your input looks more like this:&lt;/p&gt;&lt;p&gt;&lt;em&gt;"It was a wrong number that started it, the telephone ringing three times in the dead of night, and the voice on the other end asking for someone he was not."&lt;/em&gt;&lt;/p&gt;&lt;p&gt;Good luck encoding &lt;strong&gt;that&lt;/strong&gt; into a &lt;em&gt;context vector&lt;/em&gt;! However, there turns out to be a solution, known as &lt;strong&gt;the Attention mechanism&lt;/strong&gt;.&lt;/p&gt;&lt;figure&gt;&lt;img alt="" src="https://blog.scaleway.com/content/images/2019/08/RNNattention.jpg"&gt;&lt;figcaption&gt;Schematics of (left) a conventional RNN Encoder-Decoder and (right) an RNN Encoder-Decoder with Attention&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;The basic idea behind Attention is simple: instead of passing only the last hidden state (the &lt;em&gt;context vector&lt;/em&gt;) to the Decoder, we give it &lt;strong&gt;all&lt;/strong&gt; the hidden states that come out of the Encoder. In our example that would mean &lt;em&gt;h&lt;sub&gt;E1&lt;/sub&gt;&lt;/em&gt;, &lt;em&gt;h&lt;sub&gt;E2&lt;/sub&gt;&lt;/em&gt; and &lt;em&gt;h&lt;sub&gt;E3&lt;/sub&gt;&lt;/em&gt;. The Decoder will determine which of them gets attended to (i.e., where to pay attention) via a softmax layer. Apart from adding this additional structure, the basic RNN Encoder-Decoder architecture remains the same, yet the resulting model performs much better when it comes to longer input sequences.&lt;/p&gt; &lt;h3 id="1bsecondproblemwithrecurrentnnstheyaresurpriserecurrent"&gt;1b. Second problem with Recurrent NNs: they are (surprise!) Recurrent&lt;/h3&gt; &lt;p&gt;The other problem plaguing RNNs has to do with the R inside the name: the computation in a &lt;em&gt;Recurrent&lt;/em&gt; neural network is, by definition, sequential. What does this property entail? A sequential computation cannot be parallelized, since we have to wait for the previous step to finish before we move on to the next one. This lengthens both the training time, and the time it takes to run inference.&lt;/p&gt; &lt;p&gt;One of the ways around the sequential dilemma is to use Convolutional neural networks (CNNs) instead of RNNs. This approach has seen its share of success, until it got outshone by the &amp;lt;drumroll&amp;gt; ...&lt;/p&gt; &lt;figure&gt;&lt;img alt="" src="https://blog.scaleway.com/content/images/2019/08/transformer.jpg"&gt;&lt;/figure&gt;&lt;h2 id="2attentionisallyouneedcgoogle2017"&gt;2. Attention is All You Need (c) Google, 2017&lt;/h2&gt; &lt;p&gt;The &lt;strong&gt;Transformer&lt;/strong&gt; architecture was introduced in the paper whose title is worthy of that of a self-help book: &lt;a href="https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf"&gt;&lt;em&gt;Attention is All You Need&lt;/em&gt;&lt;/a&gt;. Again, another self-descriptive heading: the authors literally take the RNN Encoder-Decoder model with Attention, and throw away the RNN. Attention is all you need! Well, it ends up being quite a bit more complicated than that in practice, but that is the basic premise.&lt;/p&gt; &lt;p&gt;How does this work? To start with, each pre-processed (more on that later) element of the input sequence &lt;em&gt;w&lt;sub&gt;i&lt;/sub&gt;&lt;/em&gt; gets fed as input to the Encoder network - this is done in parallel, unlike the RNNs. The Encoder has multiple layers (e.g. in the &lt;a href="https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf"&gt;original Transformer paper&lt;/a&gt; their number is six). Let us use &lt;em&gt;h&lt;sub&gt;i&lt;/sub&gt;&lt;/em&gt; to label the final hidden state of the last Encoder layer for each &lt;em&gt;w&lt;sub&gt;i&lt;/sub&gt;&lt;/em&gt;. The Decoder also contains multiple layers - typically, the number is equal to that of the Encoder. All of the hidden states &lt;em&gt;h&lt;sub&gt;i&lt;/sub&gt;&lt;/em&gt; will now be fed as inputs to &lt;em&gt;each&lt;/em&gt; of the six layers of the Decoder. If this looks familiar to you, it is for a good reason: this is the Transformer's &lt;strong&gt;Encoder-Decoder Attention&lt;/strong&gt;, which is rather similar in spirit to the Attention mechanism that we discussed above. Before we move on to how the Transformer's Attention is implemented, let's discuss the &lt;em&gt;preprocessing&lt;/em&gt; layers (present in both the Encoder and the Decoder as we'll see later).&lt;/p&gt; &lt;p&gt;There are two parts to preprocessing: first, there is the familiar &lt;a href="http://hunterheidenreich.com/blog/intro-to-word-embeddings/"&gt;word embedding&lt;/a&gt;, a staple in most modern NLP models. These word embeddings could be learned during training, or one could use one of the existing pre-trained embeddings. There is, however, a second part that is specific to the Transformer architecture. So far, no where have we provided any information on the &lt;strong&gt;order&lt;/strong&gt; of the elements inside the sequence. How can this be done in the absence of the sequential RNN architecture? Well, we have the positions, let's encode them inside vectors, just as we embedded the meaning of the word tokens with word embeddings. The resulting post-processed vectors, carrying information about both the word's meaning and its position in the sentence, are passed on to the Encoder and Decoder layers.&lt;/p&gt; &lt;figure&gt;&lt;img alt="" src="https://blog.scaleway.com/content/images/2019/08/transformer_encoder.jpg"&gt;&lt;figcaption&gt;An Encoder with two layers, processing a three element input sequence (w1, w2, and w3) in parallel. Each input element's Encoder also receives information about the other elements via its &lt;strong&gt;Self-Attention&lt;/strong&gt; sublayers, allowing the relationships between words in the sentence to be captured.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3 id="2aattentionthelinearalgebraprospective"&gt;2a. Attention, the linear algebra prospective&lt;/h3&gt; &lt;p&gt;&lt;em&gt;I come from a quantum physics background, where vectors are a person's best friend (at times, quite literally), but if you prefer a non linear algebra explanation of the Attention mechanism, I highly recommend checking out &lt;a href="https://jalammar.github.io/illustrated-transformer/"&gt;The Illustrated Transformer&lt;/a&gt; by Jay Alammar.&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Let's use &lt;strong&gt;X&lt;/strong&gt; to label the vector space of our inputs to the Attention layer. What we want to learn during training are three embedding matrices, &lt;strong&gt;W&lt;sub&gt;K&lt;/sub&gt;&lt;/strong&gt;, &lt;strong&gt;W&lt;sub&gt;V&lt;/sub&gt;&lt;/strong&gt; and &lt;strong&gt;W&lt;sub&gt;Q&lt;/sub&gt;&lt;/strong&gt;, which will permit us to go from &lt;strong&gt;X&lt;/strong&gt; to three new spaces: &lt;strong&gt;K&lt;/strong&gt; (keys), &lt;strong&gt;V&lt;/strong&gt; (values) and &lt;strong&gt;Q&lt;/strong&gt; (queries):&lt;/p&gt; &lt;p&gt;&lt;strong&gt;K = X W&lt;sub&gt;K&lt;/sub&gt;&lt;/strong&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;strong&gt;V = X W&lt;sub&gt;V&lt;/sub&gt;&lt;/strong&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;strong&gt;Q = X W&lt;sub&gt;Q&lt;/sub&gt;&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;The way that these embedded vectors are then used in the Encoder-Decoder Attention is the following. We take a &lt;strong&gt;Q&lt;/strong&gt; vector (a &lt;em&gt;query&lt;/em&gt;, i.e., we specify the kind of information that we want to attend to) from the Decoder. Additionally, we take vectors &lt;strong&gt;V&lt;/strong&gt; (&lt;em&gt;values&lt;/em&gt;) that we can think of as something similar to linear combinations of vectors &lt;strong&gt;X&lt;/strong&gt; coming from the Encoder (do not take "linear combination" literally however, as the dimensionality of &lt;strong&gt;X&lt;/strong&gt; and &lt;strong&gt;V&lt;/strong&gt; is, in general, different). Vectors &lt;strong&gt;K&lt;/strong&gt; are also taken from the Encoder: each &lt;em&gt;key&lt;/em&gt; &lt;strong&gt;K&lt;/strong&gt;&lt;sub&gt;n&lt;/sub&gt; indexes the kind of information that is captured by the value &lt;strong&gt;V&lt;/strong&gt;&lt;sub&gt;n&lt;/sub&gt;.&lt;/p&gt; &lt;p&gt;To determine which values should get the most attention, we take the dot product of the Decoder's query &lt;strong&gt;Q&lt;/strong&gt; with all of the Encoder's keys &lt;strong&gt;K&lt;/strong&gt;. The softmax of the result will give the weights of the respective values &lt;strong&gt;V&lt;/strong&gt; (the larger the weight, the greater the attention). Such mechanism is known as the &lt;strong&gt;Dot-product attention&lt;/strong&gt;, given by the following formula:&lt;/p&gt; &lt;figure&gt;&lt;img alt="" src="https://blog.scaleway.com/content/images/2019/08/atteq.jpeg"&gt;&lt;/figure&gt;&lt;p&gt;where one can optionally divide the dot product of &lt;strong&gt;Q&lt;/strong&gt; and &lt;strong&gt;K&lt;/strong&gt; by the dimensionality of key vectors &lt;em&gt;d&lt;sub&gt;k&lt;/sub&gt;&lt;/em&gt;. To give you an idea for the kind of dimensions used in practice, the Transformer introduced in &lt;em&gt;&lt;a href="https://arxiv.org/pdf/1706.03762.pdf"&gt;Attention is all you need&lt;/a&gt;&lt;/em&gt; has &lt;em&gt;d&lt;sub&gt;q&lt;/sub&gt;=d&lt;sub&gt;k&lt;/sub&gt;=d&lt;sub&gt;v&lt;/sub&gt;=64&lt;/em&gt; whereas what I refer to as &lt;strong&gt;X&lt;/strong&gt; is 512-dimensional.&lt;/p&gt; &lt;h3 id="2bwhatisnewselfattention"&gt;2b. What is new: Self-Attention&lt;/h3&gt; &lt;p&gt;In addition to the &lt;strong&gt;Encoder-Decoder Attention&lt;/strong&gt;, the Transformer architecture includes the &lt;strong&gt;Encoder Self-Attention&lt;/strong&gt; and the &lt;strong&gt;Decoder Self-Attention&lt;/strong&gt;. These are calculated in the same dot-product manner as discussed above, with one crucial difference: for self-attention, all three types of vectors (&lt;strong&gt;K&lt;/strong&gt;, &lt;strong&gt;V&lt;/strong&gt;, and &lt;strong&gt;Q&lt;/strong&gt;) come from the same network. This also means that all three are associated with the elements of the same sequence (input for the Encoder and output for the Decoder). The purpose of introducing self-attention is to learn the relationships between different words in the sentence (this function used to be fulfilled by the sequential RNN). One way of looking at it is a representation of each element of the sequence as a weighted sum of the other elements in the sequence. Why bother? Consider the following two phrases:&lt;/p&gt; &lt;p&gt;&lt;em&gt;1.&lt;/em&gt; &lt;strong&gt;The animal&lt;/strong&gt; &lt;em&gt;did not cross the road because&lt;/em&gt; &lt;strong&gt;it&lt;/strong&gt; &lt;em&gt;was too tired.&lt;/em&gt;&lt;/p&gt; &lt;p&gt;&lt;em&gt;2. The animal did not cross&lt;/em&gt; &lt;strong&gt;the road&lt;/strong&gt; &lt;em&gt;because&lt;/em&gt; &lt;strong&gt;it&lt;/strong&gt; &lt;em&gt;was too wide.&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Clearly, &lt;strong&gt;it&lt;/strong&gt; is most closely related to &lt;strong&gt;the animal&lt;/strong&gt; in the first phrase and &lt;strong&gt;the road&lt;/strong&gt; in the second one: information that would be missing if we were to use a uni-directional forward RNN! In fact, the &lt;strong&gt;Encoder Self-Attention&lt;/strong&gt;, that is bi-directional by design, is a crucial part of &lt;a href="https://arxiv.org/abs/1810.04805"&gt;BERT&lt;/a&gt;, the pre-trained contextual word embeddings, that we shall discuss later on.&lt;/p&gt; &lt;p&gt;Where are the calculations for the &lt;strong&gt;Encoder Self-Attention&lt;/strong&gt; carried out? Turns out, inside every Encoder layer. This permits the network to pay attention to relevant parts of the input sequence at different levels of abstraction: the values &lt;strong&gt;V&lt;/strong&gt; of the lower Encoder layers will be closest to the original input tokens, whereas Self-Attention of the deeper layers will involve more abstract constructions.&lt;/p&gt; &lt;h3 id="2cputtingitalltogether"&gt;2c. Putting it all together&lt;/h3&gt; &lt;p&gt;By now we have established that Transformers discard the sequential nature of RNNs and process the sequence elements in parallel instead. We saw how the &lt;strong&gt;Encoder Self-Attention&lt;/strong&gt; allows the elements of the input sequence to be processed separately while retaining each other's context, whereas the &lt;strong&gt;Encoder-Decoder Attention&lt;/strong&gt; passes all of them to the next step: generating the output sequence with the Decoder. What happens at this stage may not be so clear. As you recall, the RNN Encoder-Decoder generates the output sequence one element at a time. The previously generated output gets fed into the Decoder at the subsequent timestep. Do Transformers really find a way to free us from the sequential nature of this process and somehow generate the whole output sequence at once? Well - yes and no. More precisely, the answer is [roughly] yes when training, and no at inference time.&lt;/p&gt; &lt;figure&gt;&lt;img alt="" src="https://blog.scaleway.com/content/images/2019/08/transformer2.jpg"&gt;&lt;figcaption&gt;The Transformer architecture featuting a two-layer Encoder / Decoder. The Encoder processes all three elements of the input sequence (w1, w2, and w3) in parallel, whereas the Decoder generates each element sequentially (only timesteps 0 and 1, where the output sequence elements v1 and v2 are generated, are depicted). Output token generation continues until an end of the sentence token &amp;lt;EOS&amp;gt; appears.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;The inputs to the Decoder come in two varieties: the hidden states that are outputs of the Encoder (these are used for the &lt;strong&gt;Encoder-Decoder Attention&lt;/strong&gt; within each Decoder layer) and the previously generated tokens of the output sequence (for the &lt;strong&gt;Decoder Self-Attention&lt;/strong&gt;, also computed at each Decoder layer). Since during the training phase, the output sequences are already available, one can perform all the different timesteps of the Decoding process in parallel by masking (replacing with zeroes) the appropriate parts of the "previously generated" output sequences. This masking results in the &lt;strong&gt;Decoder Self-Attention&lt;/strong&gt; being uni-directional, as opposed to the Encoder one. Finally, at inference time, the output elements are generated one by one in a sequential manner.&lt;/p&gt; &lt;p&gt;Some final remarks before we call it a day:&lt;/p&gt; &lt;p&gt;The part of the Decoder that I refer to as &lt;em&gt;postprocessing&lt;/em&gt; in the Figure above is similar to what one would typically find in the RNN Decoder for an NLP task: a fully connected (FC) layer, which follows the RNN that extracted certain features from the network's inputs, and a softmax layer on top of the FC one that will assign probabilities to each of the tokens in the model's vocabularly being the next element in the output sequence. At that point, we could use a &lt;a href="https://machinelearningmastery.com/beam-search-decoder-natural-language-processing/"&gt;beam search&lt;/a&gt; algorithm to keep the top few predictions at each step and choose the most likely output sequence at the end, or simply keep the top choice each time.&lt;/p&gt; &lt;p&gt;The Transformer architecture is the driving force behind many of the recent &amp;nbsp;breakthroughs in the field of NLP. To put some hard numbers on that statement, lets turn to a metric called &lt;a href="https://en.wikipedia.org/wiki/BLEU"&gt;BLEU&lt;/a&gt;, commongly used to evaluate the quality of machine translations. The &lt;a href="https://arxiv.org/abs/1706.03762"&gt;original Transformer&lt;/a&gt; achieved a score of 28.4 BLEU on an English-to-German translation task, and if that does not tell you much, suffices to say that it was better than the exisiting best result by over 2 BLEU!&lt;/p&gt;&lt;p&gt;Next, in the coming blog post we will discuss &lt;a href="https://arxiv.org/abs/1810.04805"&gt;BERT (Bidirectional Encoder Representations from Transformers)&lt;/a&gt;: contextualized word embeddings based on the Transformer (more precisely, Transformer's Encoder), and how to train a BERT-based machine reading comprehension model on the &lt;a href="https://www.scaleway.com/en/gpu-instances/"&gt;Scaleway GPU instances&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://blog.scaleway.com/2019/building-a-machine-reading-comprehension-system-using-the-latest-advances-in-deep-learning-for-nlp/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:22:26 UT
      </pubDate>
      <guid>
        https://blog.scaleway.com/2019/building-a-machine-reading-comprehension-system-using-the-latest-advances-in-deep-learning-for-nlp/
      </guid>
    </item>
    <item>
      <title>
        Write Fuzzable Code &amp;#8211; Embedded in Academia
      </title>
      <link>
        https://blog.regehr.org/archives/1687
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div id="content"&gt; &lt;main id="main"&gt; &lt;article id="post-1687"&gt; &lt;div&gt; &lt;p&gt;Fuzzing is sort of a superpower for locating vulnerabilities and other software defects, but it is often used to find problems baked deeply into already-deployed code. Fuzzing should be done earlier, and moreover developers should spend some effort making their code more amenable to being fuzzed. &lt;/p&gt; &lt;p&gt;This post is a non-comprehensive, non-orthogonal list of ways that you can write code that fuzzes better. Throughout, I’ll use “fuzzer” to refer to basically any kind of randomized test-case generator, whether mutation-based (afl, libFuzzer, etc.) or generative (jsfunfuzz, Csmith, etc.). Not all advice will apply to every situation, but a lot of it is sound software engineering advice in general. I’ve bold-faced a few points that I think are particularly important.&lt;/p&gt; &lt;h2&gt;Invest in Oracles&lt;/h2&gt; &lt;p&gt;A test oracle decides whether a test case triggered a bug or not. By default, the only oracle available to a fuzzer like afl is provided by the OS’s page protection mechanism. In other words, it detects only crashes. We can do much better than this.&lt;/p&gt; &lt;p&gt;&lt;a href="https://blog.regehr.org/archives/1091"&gt;Assertions&lt;/a&gt; and their compiler-inserted friends — sanitizer checks — are another excellent kind of oracle. You should fuzz using as many of these checks as possible. Beyond these easy oracles, many more possibilities exist, such as: &lt;/p&gt; &lt;ul&gt; &lt;li&gt;function-inverse pairs: does a parse-print loop, compress-decompress loop, encrypt-decrypt loop, or similar, work as expected? &lt;/li&gt;&lt;li&gt;differential: do two different implementations, or modes of the same implementation, show the same behavior? &lt;/li&gt;&lt;li&gt;metamorphic: does the system show the same behavior when a test case is modified in a semantics-preserving way, such as adding a layer of parentheses to an expression? &lt;/li&gt;&lt;li&gt;resource: does the system consume a reasonable amount of time, memory, etc. when processing an input? &lt;/li&gt;&lt;li&gt;domain specific: for example, is a lossily-compressed image sufficiently visually similar to its uncompressed version? &lt;/li&gt;&lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Strong oracles are worth their weight in gold, since they tend to find application-level logic errors rather than the lower-level bugs that are typically caught by looking for things like array bounds violations.&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;I &lt;a href="https://blog.regehr.org/archives/856"&gt;wrote a bit more about this topic&lt;/a&gt; a few years ago. Finally, a twitter user suggested “If you’re testing a parser, poke at the object it returns, don’t just check if it parses.” This is good advice.&lt;/p&gt; &lt;h2&gt;Interpose on I/O and State&lt;/h2&gt; &lt;p&gt;Stateless code is easier to fuzz. Beyond that, you will want APIs for taking control of state and for interposing on I/O. For example, if your program asks the OS for the number of cores, the current date, or the amount of disk space remaining, you should provide a documented method for setting these values. It’s not that we necessarily want to randomly change the number of cores, but rather that we might want to fuzz our code when set to single-core mode and then separately fuzz it in 128-core mode. Important special cases of taking control of state and I/O include making it easy to reset the state (to support persistent-mode fuzzing) and avoiding hidden inputs that lead to non-deterministic execution. &lt;strong&gt;We want as much determinism as possible while fuzzing our code.&lt;/strong&gt;&lt;/p&gt; &lt;h2&gt;Avoid or Control Fuzzer Blockers&lt;/h2&gt; &lt;p&gt;Fuzzer blockers are things that make fuzzing gratuitously difficult. The canonical fuzzer blocker is a checksum included somewhere in the input: the random changes made to the input by a mutation-based fuzzer will tend to cause the checksum to not validate, resulting in very poor code coverage. There are basically two solutions. First, turn off checksum validation in builds intended for fuzzing. Second, have the fuzzer generate inputs with valid checksums. A generation-based fuzzer will have this built in; with a mutation-based fuzzer we would write a little utility to patch up the test case with a valid checksum after it is generated and before it is passed to the program being fuzzed. &lt;a href="https://github.com/mirrorer/afl/blob/master/experimental/post_library/post_library.so.c"&gt;afl has support for this&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Beyond checksums, hard-to-satisfy validity properties over the input can be a serious problem. For example, if you are fuzzing a compiler for a strongly typed programming language, blind mutation of compiler inputs may not result in valid compiler inputs very often. I like to think of validity constraints as being either soft (invalid inputs waste time, but are otherwise harmless) or hard (the system behaves arbitrarily when processing an invalid input, so they must be avoided for fuzzing to work at all). When we fuzz a C++ compiler to look for wrong code bugs, we face a hard validity constraint because compiler inputs that have UB will look like wrong code bugs. There is no simple, general-purpose solution to this kind of problem, but rather a family of techniques for explicitly taking validity properties into account. The most obvious solution — but often not the right one — is to write a new generational fuzzer. The problem is that if you do this, you cannot take advantage of modern coverage-driven fuzzing techniques, which are amazing. To fit into a coverage-driven fuzzing framework you have a couple of options. First, write a custom mutator that respects your validity constraints. &lt;strong&gt;Second, &lt;a href="https://github.com/google/fuzzer-test-suite/blob/master/tutorial/structure-aware-fuzzing.md"&gt;structure-aware fuzzing&lt;/a&gt;, which basically means taking the mutated data from the fuzzer and translating it into something like what the program being fuzzed expects to see.&lt;/strong&gt; There’s a lot of research left to be done in making coverage-driven fuzzers work well in the presence of validity constraints without requiring a lot of manual effort. There are some significant subtleties here, maybe I’ll go into them another time. Putting something like a SAT solver into the fuzzer is not, generally speaking, the answer here, first because some validity constraints like checksums are specifically difficult for solvers, and second because some validity constraints (such as UB-freedom in a C++ program) are implicit and cannot be inferred, even in principle, by looking at the system being fuzzed.&lt;/p&gt; &lt;p&gt;A lot of code in a typical system cannot be fuzzed effectively by feeding input to public APIs because access is blocked by other code in the system. For example, if you use a custom memory allocator or hash table implementation, then fuzzing at the application level probably does not result in especially effective fuzzing of the allocator or hash table. These kinds of APIs should be exposed to direct fuzzing. &lt;strong&gt;There is a strong synergy between unit testing and fuzzing: if one of these is possible and desirable, then the other one probably is too. You typically want to do both.&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Sanitizers and fuzzers often require tweaks or even significant changes to the build process. To make this easier, keep the build process as clean and simple as possible. Make it easy to switch out the compiler and modify the compiler options. Depend on specific tools (and versions of tools) as little as possible. Routinely build and test your code with multiple compilers. Document special build system requirements.&lt;/p&gt; &lt;p&gt;Finally, some fuzzer blockers are sort of silly and easy to avoid. If your code leaks memory or terminates its process with a deep call stack, it will be painful to test using a persistent-mode fuzzer, so don’t do these things. Avoid handling SIGSEGV or, if you really must do this, have a way to disable the handler for fuzzer builds. If your code is not compatible with ASan or UBSan, then these extremely useful oracles are harder to use. In particular, if your code uses a custom memory allocator you should consider turning it off for fuzzer builds, or else &lt;a href="https://github.com/google/sanitizers/wiki/AddressSanitizerManualPoisoning"&gt;adapting it to work with ASan&lt;/a&gt;, or else you’ll miss important bugs.&lt;/p&gt; &lt;h2&gt;Unblock Coverage-Driven Fuzzers&lt;/h2&gt; &lt;p&gt;Because coverage-driven fuzzers refocus their effort to try to hit uncovered branches, they can be blocked in certain specific ways. For example, if a coverage-driven fuzzer is presented with too many uncoverable branches, it can spend so much time on them that it becomes less likely to hit more interesting branches elsewhere in the program. For example, one time I compared afl’s coverage on a program compiled with and without UBSan, and found that (in whatever time limit I used) it covered quite a lot less of the sanitized program, compared to the unsanitized build. On the other hand, we definitely want our fuzzer to look for sanitizer failures. My advice is to fuzz both sanitized and unsanitized builds of your program. I don’t know how to budget fuzzing resources for these different activities and don’t know of any principled work on that problem. It may not matter that much, since fuzzing is all about overkill.&lt;/p&gt; &lt;p&gt;Sometimes your program will call branchy, already-heavily-fuzzed code early in its execution. For example, you might decompress or decrypt input before processing it. This is likely to distract the coverage-driven fuzzer, causing it to spend a lot of time trying to fuzz the crypto or compression library. If you don’t want to do this, provide a way to disable crypto or compression during fuzzing.&lt;/p&gt; &lt;p&gt;Any interpreter in your program is likely to make life difficult for a coverage-driven fuzzer, since the relevant program paths are now encoded in the data being interpreted, which is generally opaque to the fuzzer. If you want maximum mileage out of coverage-driven fuzzers, you may want to try to avoid writing interpreters, or at least keep them extremely simple. An obvious way to deal with embedded interpreters — which someone must have thought of and tried, but I don’t have any pointers — would be to have an API for teaching the fuzzer how to see coverage of the language being interpreted.&lt;/p&gt; &lt;h2&gt;Enable High Fuzzing Throughput&lt;/h2&gt; &lt;p&gt;Fuzzing is most effective when throughput is very high; this seems particularly the case for feedback-driven fuzzers that may take a while to learn how to hit difficult coverage targets. An easy throughput hack is to make it possible to disable slow code (detailed logging, for example) when it is not germane to the fuzzing task. Similarly, interposing on I/O can help us avoid speed hacks such as running the fuzzer in a ramdisk.&lt;/p&gt; &lt;h2&gt;“But I Want Fuzzing My Code to be Harder, Not Easier”&lt;/h2&gt; &lt;p&gt;I don’t have a lot of sympathy for this point of view. Instead of aiming for security through obscurity, we would do better to:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;fuzz early and thoroughly, eliminating fuzzable defects before releasing code into the wild &lt;/li&gt;&lt;li&gt;write code in a programming language with as strong of a type system as we are willing to tolerate — this will statically eliminate classes of bad program behaviors, for example by stopping us from putting the wrong kind of thing into a hashmap &lt;/li&gt;&lt;li&gt;aggressively use assertions and sanitizers to get dynamic checking for properties that the type system can’t enforce statically &lt;/li&gt;&lt;/ul&gt; &lt;p&gt;Anti-fuzzing techniques are a thing, but I don’t think it represents a useful kind of progress towards better software. &lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;Randomized testing is incredibly powerful and there’s no point avoiding it: if you don’t fuzz your code, someone else will. This piece has described some ways for you, the software developer, to make fuzzing work better. Of course there are plenty of other aspects, such as choosing a good corpus and writing a good fuzzer driver, that are not covered here.&lt;/p&gt; &lt;p&gt;&lt;b&gt;Acknowledgments:&lt;/b&gt; Pascal Cuoq and Alex Groce provided feedback on a draft of this piece, and it also benefited from suggestions I received on Twitter. You can &lt;a href="https://twitter.com/johnregehr/status/1154888675810934784"&gt;read the conversation here&lt;/a&gt;; it contains some suggestions and nuances that I did not manage to capture.&lt;/p&gt; &lt;/div&gt; &lt;/article&gt; &lt;/main&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://blog.regehr.org/archives/1687"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:24:29 UT
      </pubDate>
      <guid>
        https://blog.regehr.org/archives/1687
      </guid>
    </item>
    <item>
      <title>
        Full Page Reload
      </title>
      <link>
        https://spectrum.ieee.org/the-institute/ieee-member-news/educational-resources-that-get-students-up-to-speed-on-advanced-manufacturing-and-programming-languages
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;header id="header"&gt; &lt;div id="ieee-metanav"&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://spectrum.ieee.org/static/enhance-your-spectrum-experience-become-an-ieee-member"&gt;Join IEEE&lt;/a&gt;&lt;/li&gt; &lt;li&gt;|&lt;/li&gt; &lt;li&gt;&lt;a href="http://www.ieee.org/"&gt;IEEE.org&lt;/a&gt;&lt;/li&gt; &lt;li&gt;|&lt;/li&gt; &lt;li&gt;&lt;a href="http://ieeexplore.ieee.org/"&gt;IEEE &lt;em&gt;Xplore&lt;/em&gt; Digital Library&lt;/a&gt;&lt;/li&gt; &lt;li&gt;|&lt;/li&gt; &lt;li&gt;&lt;a href="http://standards.ieee.org/"&gt;IEEE Standards&lt;/a&gt;&lt;/li&gt; &lt;li&gt;|&lt;/li&gt; &lt;li&gt;&lt;a href="https://spectrum.ieee.org/"&gt;&lt;span&gt;IEEE Spectrum&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li&gt;|&lt;/li&gt; &lt;li&gt;&lt;a href="http://www.ieee.org/sitemap"&gt;More Sites&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;div&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://www.ieee.org/profile/public/createwebaccount/showCreateAccount.html?ShowMGAMarkeatbilityOptIn=true&amp;amp;sourceCode=spectrum&amp;amp;signinurl=https://spectrum.ieee.org/user/login&amp;amp;url=https://spectrum.ieee.org/the-institute/ieee-member-news/educational-resources-that-get-students-up-to-speed-on-advanced-manufacturing-and-programming-languages&amp;amp;autoSignin=Y&amp;amp;car=IEEE-Spectrum"&gt;Create Account&lt;/a&gt;&lt;/li&gt; &lt;li&gt;|&lt;/li&gt; &lt;li&gt;&lt;a href="https://spectrum.ieee.org/user/login"&gt;Sign In&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/header&gt; &lt;/div&gt;&lt;a href="https://spectrum.ieee.org/the-institute/ieee-member-news/educational-resources-that-get-students-up-to-speed-on-advanced-manufacturing-and-programming-languages"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:27:19 UT
      </pubDate>
      <guid>
        https://spectrum.ieee.org/the-institute/ieee-member-news/educational-resources-that-get-students-up-to-speed-on-advanced-manufacturing-and-programming-languages
      </guid>
    </item>
    <item>
      <title>
        How we reduced deployment times by 95% | Plaid
      </title>
      <link>
        https://blog.plaid.com/how-we-reduced-deployment-times-by-95/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div data-testid="blogPostTemplate"&gt;&lt;p&gt;As Plaid grows, so does the scale of our infrastructure. We currently run over 20 internal services and deploy over 50 code commits per day across our core services. Minimizing deployment time is therefore of vital importance to maximizing our iteration velocity. A fast deployment process allows us to rapidly ship bug fixes and run a smooth &lt;a href="http://timothyfitz.com/2009/02/10/continuous-deployment-at-imvu-doing-the-impossible-fifty-times-a-day/"&gt;continuously deployed&lt;/a&gt; system.&lt;/p&gt;&lt;p&gt;A couple months ago, we noticed that slow deploys of our bank integration service were affecting our team's ability to ship code. Engineers would spend at least 30 minutes building, deploying, and monitoring their changes through multiple staging and production environments, which consumed a lot of valuable engineering time. This became increasingly unacceptable as the team grew larger and we shipped more code daily.&lt;/p&gt;&lt;p&gt;While we had plans to implement long-term improvements like moving our Amazon ECS-based service infrastructure onto Kubernetes, a fix was warranted to increase our iteration speed in the short-term. We set out to score a quick win by implementing a custom "fast deployments" mechanism.&lt;/p&gt;&lt;h2&gt;High latency in Amazon ECS deploys&lt;/h2&gt;&lt;p&gt;Our bank integration service consists of 4,000 Node.js processes running on dedicated docker containers managed and deployed on &lt;a href="https://aws.amazon.com/ecs/"&gt;ECS&lt;/a&gt;, Amazon’s container orchestration service. After profiling our deployment process, we narrowed down the increased deployment latencies to three distinct components:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Starting up tasks incurs latency. In addition to application startup time, there is also latency from the ECS &lt;a href="https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_HealthCheck.html"&gt;health check&lt;/a&gt;, which determines when containers are ready to start handling traffic. The three parameters that control this process are &lt;b&gt;interval, retries, &lt;/b&gt;and&lt;b&gt; startPeriod&lt;/b&gt;. Without careful health check tuning, containers can be stuck in the "starting" state even after they're ready to serve traffic.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Shutting down tasks incurs latency. When we run an &lt;a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/update-service.html"&gt;ECS Service Update&lt;/a&gt;, a &lt;code&gt;SIGTERM&lt;/code&gt; signal is sent to all our running containers. To handle this, we have some logic in our application code to drain any extant resources before completely shutting down the service.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The rate at which we can start tasks restricts the parallelism of our deploy. Despite us setting the &lt;a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service_definition_parameters.html"&gt;MaximumPercent&lt;/a&gt; parameter to 200%, the ECS &lt;b&gt;start-task&lt;/b&gt; API call has a hard limit of 10 tasks per call, and it is rate-limited. We need to call it 400 times to place all our containers in production.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;Approaches explored&lt;/h2&gt;&lt;p&gt;We considered and experimented with a few different potential solutions to chip away at the global objective:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Reduce the total number of containers running in production. This was certainly feasible, but it involved a significant overhaul of our service architecture in order for it to handle the same request throughput, and more research needed to be done before such a change could be made.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Tweak our ECS configuration by modifying the health check parameters. We experimented with tightening the health check by reducing the &lt;b&gt;interval&lt;/b&gt; and &lt;b&gt;startPeriod &lt;/b&gt;values, but ECS would then erroneously mark healthy containers as unhealthy when they started, causing our service to never fully stabilize at 100% health. Iterating on these parameters was a slow and arduous process due to the root issue, slow ECS deployments.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Spin up more instances in the ECS cluster so that we can start more tasks simultaneously during a deployment. This worked to reduce deploy times, but not by very much. It also isn’t cost-effective in the long run.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Optimize service restart time by refactoring initialization and shutdown logic. We were able to shave around 5 seconds per container with a few minor changes.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Although these changes improved the overall deploy time by a few minutes, we still needed to improve the timing by at least an order of magnitude for us to consider the problem solved. This would require a fundamentally different solution.&lt;/p&gt;&lt;h2&gt;Preliminary solution: utilizing the node require cache to “hot reload” application code&lt;/h2&gt;&lt;p&gt;The Node &lt;a href="https://nodejs.org/api/modules.html#modules_require_cache"&gt;require cache&lt;/a&gt; is a JavaScript object that caches modules when they are &lt;code&gt;require&lt;/code&gt;d. This means that executing &lt;code&gt;require('foo')&lt;/code&gt; or &lt;code&gt;import * as foo from 'foo'&lt;/code&gt; multiple times will only &lt;code&gt;require&lt;/code&gt; the &lt;code&gt;foo&lt;/code&gt; module the first time. Magically, deleting an entry in the require cache (which we can access using the global &lt;code&gt;require.cache&lt;/code&gt; object) will force Node to re-read the module from disk when it’s next imported.&lt;/p&gt;&lt;p&gt;To circumvent the ECS deployment process, we experimented with utilizing Node’s require cache to perform a “hot reload” of application code at runtime. On receiving an external trigger — we implemented this as a &lt;a href="https://grpc.io/"&gt;gRPC&lt;/a&gt; endpoint on the bank integration service — the application would download new code to replace the existing build, clear the require cache, and thereby force all relevant modules to be re-imported. With this approach, we were able to eliminate much of the latency present in ECS deploys and fine-tune our entire deployment process.&lt;/p&gt;&lt;p&gt;Over &lt;a href="https://blog.plaid.com/plaiderdays/"&gt;Plaiderdays&lt;/a&gt; — our internal hackathon — a group of engineers across various teams got together to implement an end-to-end proof of concept for what we termed "Fast Deploys". As we hacked a prototype together, one thing seemed amiss: if the Node code that downloaded new builds also tried to invalidate the cache, it wasn’t clear how the downloader code itself would be reloaded. (There is a way around this with the Node &lt;a href="https://nodejs.org/api/events.html#events_class_eventemitter"&gt;EventEmitter&lt;/a&gt;, but it would add considerable complexity to the code). More importantly, there was also some risk of running versions of code that were not in sync, which could cause our application to fail unexpectedly. &lt;/p&gt;&lt;p&gt;As we weren’t willing to compromise on the reliability of our bank integration service, this complication warranted rethinking our “hot reloading” approach.&lt;/p&gt;&lt;h2&gt;Final solution: reloading the process&lt;/h2&gt;&lt;p&gt;In the past, in order to run a series of uniform initialization tasks across all our services, we wrote our own process wrapper, which is aptly named Bootloader. At its core, Bootloader contains logic to setup logging pipes, forward signals, and read ECS metadata. Every service is started by passing the application executable’s path to Bootloader, along with a series of flags, which Bootloader then executes as a subprocess after performing the initialization steps.&lt;/p&gt;&lt;p&gt;Instead of clearing Node's require cache, we updated our service to call &lt;code&gt;process.exit&lt;/code&gt; with a special exit code after downloading the intended deployment build. We also implemented custom logic in Bootloader to trigger a process reload of any child process that exits with this code. Similar to the “hot reload” approach, this enables us to bypass the cost of ECS deploys and quickly boostrap new code, while avoiding the pitfalls of “hot reloading”. Furthermore, having this "Fast Deploy" logic at the Bootloader layer allows us to generalize it to any other service we run at Plaid.&lt;/p&gt;&lt;p&gt;Here's what the final approach looks like:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Our Jenkins deployments pipeline sends an RPC request to all instances of our bank integration service, instructing them to "Fast Deploy" a specific commit hash&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The application receives a gRPC request for a fast deployment and downloads a tarball of the build from &lt;a href="https://aws.amazon.com/s3/"&gt;Amazon S3&lt;/a&gt;, keyed on the received commit hash. It then replaces the existing build on the file system and exits with the special exit code that Bootloader recognizes.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Bootloader sees that the application exited with this special "Reload" exit code, and restarts the application.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Lo and Behold, the service now runs new code!&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Here’s a very simplified diagram of what happens during this process.&lt;/p&gt;&lt;figure&gt;&lt;img alt="jenkings-process.png" src="https://images.ctfassets.net/zucqsg1ttqqy/6ENIiXx1AKjyiKw1KCOpJv/1859206d7259253b41855d7099ce2f2c/jenkings-process.png?q=70"&gt;&lt;/figure&gt;&lt;h2&gt;Results&lt;/h2&gt;&lt;p&gt;We were able to ship this “Fast Deployments” project within 3 weeks and reduce our deployment times from more than 30 minutes to 1.5 minutes across 90% of our containers in production.&lt;/p&gt;&lt;figure&gt;&lt;img alt="deployment-status.png" src="https://images.ctfassets.net/zucqsg1ttqqy/1asq8ej2O4KtFs4C8mb1aL/5d4bf9c119fab277de78b775fc2088fc/deployment-status.png?q=70"&gt;&lt;/figure&gt;&lt;p&gt;The graph above shows the number of deployed containers for our bank integration service, color-coded by their commits. If you focus on the yellow line graph, you can observe a leveling off in the increase at around 12:15, which represents the long tail of our containers which are still draining their resources.&lt;/p&gt;&lt;p&gt;This project has greatly increased the velocity of Plaid's integrations work, allowing us to ship features and bug fixes more quickly, and minimize engineering time wasted context switching and monitoring dashboards. It is also a testament to our engineering culture of shipping materially impactful projects, embodied by ideas that come out of hackathons.&lt;/p&gt;&lt;p&gt;Want to work on impactful projects like Fast Deployments? &lt;a href="https://plaid.com/careers"&gt;We're hiring!&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;a href="https://blog.plaid.com/how-we-reduced-deployment-times-by-95/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:27:27 UT
      </pubDate>
      <guid>
        https://blog.plaid.com/how-we-reduced-deployment-times-by-95/
      </guid>
    </item>
    <item>
      <title>
        Most software companies ignore user behavior
      </title>
      <link>
        https://www.reifyworks.com/writing/2019-08-26-a-most-software-companies
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div id="wrapper"&gt; &lt;main id="main"&gt; &lt;div&gt; &lt;p&gt;One of the most important skills to build as a marketer is &lt;em&gt;follow through&lt;/em&gt;. In marketing that means taking every opportunity to gather data in order to &lt;em&gt;understand&lt;/em&gt; your users and &lt;em&gt;improve&lt;/em&gt; your process.&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;Understanding your users doesn’t end when they purchase your product.&lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt;One deficiency we’ve consistently seen inside companies small and large alike is that they don’t have ready access to information about what users are doing with their product. Marketers are incentivized to instrument the hell of out lead generation and a section of the funnel, sales religiously updates CRMs to track prospects and potential revenue expansion opportunities, but noone is tying it all together by looking to information that &lt;em&gt;you own&lt;/em&gt; about what users are doing with your product.&lt;/p&gt; &lt;p&gt;The reason why this is so important to get right early is that it will deeply inform decisions that you’ll need to make later on … if you’re around that long. Decisions about pricing and packaging, feature development, marketing spending, hiring, strategic investment of all sorts, etc., are more intelligently made when they’re backed by data that is enriched by how &lt;em&gt;users are actually using your product.&lt;/em&gt;&lt;/p&gt; &lt;p&gt;There are myriad technical approaches to gathering the data necessary for this method, but an ideal setup should contain the following, regardless of how it is implemented:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;A “User table” which rolls up all useful usage information into one easy to query data source. You likely have some version of this powering either a homegrown “admin dashboard” or feeding into one or more external systems.&lt;/li&gt; &lt;li&gt;A time-bounded data source which is amenable to more complex queries, including historical queries, and can be used to generate reports. Amazon Redshift is a popular solution for this component.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Here’s an example row:&lt;/p&gt; &lt;table id="usertable"&gt; &lt;tbody&gt;&lt;tr&gt; &lt;th&gt;ID&lt;/th&gt; &lt;th&gt;name&lt;/th&gt; &lt;th&gt;score&lt;/th&gt; &lt;th&gt;feature1&lt;/th&gt; &lt;th&gt;feature2&lt;/th&gt; &lt;th&gt;plan&lt;/th&gt; &lt;th&gt;monthly&lt;/th&gt; &lt;th&gt;seats&lt;/th&gt; &lt;th&gt;last_seen&lt;/th&gt; &lt;th&gt;user_since&lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;Reify&lt;/td&gt; &lt;td&gt;87&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;0&lt;/td&gt; &lt;td&gt;small&lt;/td&gt; &lt;td&gt;99&lt;/td&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;019-08-29&lt;/td&gt; &lt;td&gt;019-01-02&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt;&lt;/table&gt; &lt;p&gt;Maintaining and curating this date over time will allow you to answer crucial questions about your trial users, customes, ex-customers, and so on. Recording and maintaining this data is &lt;em&gt;so simple&lt;/em&gt; that it’s becoming table stakes for good marketers – don’t get left behind.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Bonus Implementation Tips&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Track feature usage in your user table with columns denoting whether or not a user has or has not used this feature&lt;/li&gt; &lt;li&gt;Associate plan and payment information with your user table rows so that you can easily segment your user data by important revenue based facets&lt;/li&gt; &lt;li&gt;Create an “engagement metric” number which takes core features of your product into account and rolls them up into a 0-100 score that can be tracked over time.&lt;/li&gt; &lt;li&gt;Use the data in your users table to power all kinds of interesting customer communication. Want to communicate with users who have or haven’t used a specific feature and ask them why? Now you can. Want to segment trial users into those who haven’t used that one killer feature and those who have? Go for it.&lt;/li&gt; &lt;/ul&gt; &lt;hr&gt; &lt;br&gt; &lt;/div&gt; &lt;/main&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://www.reifyworks.com/writing/2019-08-26-a-most-software-companies"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:27:34 UT
      </pubDate>
      <guid>
        https://www.reifyworks.com/writing/2019-08-26-a-most-software-companies
      </guid>
    </item>
    <item>
      <title>
        How Gerald Ratner lost $10B in 10 seconds
      </title>
      <link>
        https://thehustle.co/gerald-ratners-billion-dollar-speech
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt; &lt;p&gt;&lt;span&gt;When Gerald Ratner took the stage before 6k high-powered businesspeople, journalists, and dignitaries at London’s Royal Albert Hall in April 1991, he had no idea his speech would be a professional death sentence.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;His incredible success had led him to this moment. He’d inherited a struggling chain of jewelry stores and turned it into a £1B enterprise in less than a decade. He’d flipped an elitist industry on its head by making earrings and rings for the working class. And in the process, he’d built his company, Ratners Group, into the UK’s &lt;/span&gt;&lt;a href="https://www.nytimes.com/1987/07/04/business/company-news-ratners-group-buying-sterling.html"&gt;&lt;span&gt;biggest&lt;/span&gt;&lt;/a&gt;&lt;span&gt;, and most recognizable, jewelry chain.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;But in a matter of seconds on that fateful night in April, a few jokes would destroy it all.&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;&lt;b&gt;The rise of a populist jeweler&lt;/b&gt;&lt;/h2&gt; &lt;p&gt;&lt;span&gt;Gerald Ratner joined his father’s small, fledgling jewelry business in 1965, at the age of 15, after being expelled from grammar school for “being too stupid.” He spent his youth cleaning up the shop, running errands, and getting to know the “grass roots of the business.” &lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;When he inherited the company, Ratners Group (AKA “Ratners”), in 1984, it consisted of 120 bland, traditional storefronts, and was posting annual losses of £350k (US$459k).&lt;/span&gt;&lt;/p&gt; &lt;figure aria-describedby="caption-attachment-9728" id="attachment_9728"&gt;&lt;img data-sizes="(max-width: 600px) 100vw, 600px" data-src="https://thehustle.co/wp-content/uploads/2018/08/ratners-store.jpg" data-srcset="https://thehustle.co/wp-content/uploads/2018/08/ratners-store.jpg 600w, https://thehustle.co/wp-content/uploads/2018/08/ratners-store-300x225.jpg 300w" height="100%" width="2500" alt="" loading="lazy" src="https://thehustle.co/wp-content/uploads/2018/08/ratners-store.jpg" srcset="https://thehustle.co/wp-content/uploads/2018/08/ratners-store.jpg 600w, https://thehustle.co/wp-content/uploads/2018/08/ratners-store-300x225.jpg 300w"&gt;&lt;figcaption id="caption-attachment-9728"&gt;A Ratners jewelry store in 1991, complete with garish advertisements (via Getty Images)&lt;/figcaption&gt;&lt;/figure&gt; &lt;p&gt;&lt;span&gt;In his youth, Ratner had learned a valuable lesson by observing London’s street shops: the &lt;/span&gt;&lt;a href="http://www.todayifoundout.com/index.php/2014/04/speech-cost-nearly-billion-dollars/"&gt;&lt;span&gt;vendors&lt;/span&gt;&lt;/a&gt;&lt;span&gt; who “yelled the loudest and had the most garish, eye-catching displays” landed the most sales. He decided to employ the same strategy at Ratners.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;Within months, all Ratners locations were plastered with vibrant orange and red posters with all-caps pitches like “LAST CHANCE — MEGA RED STAR SALE!” and “SALE SALE SALE: HALF PRICE!” Everything in the window was clearly marked with a price tag.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;Prior to the 1980s, jewelry had largely been elitist. The average item cost over £300 (about US$950 in today’s dollars) — and jewelers thrived on an aura of exclusivity and prestige.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;Ratner made a decision to market his chain toward a wider working class demographic, offering earrings, bracelets, and rings for an average price of just £20, and as low as £1. “I put the earrings and chains in the front of the window and diamond rings at the back, and played pop music,” he later told the &lt;/span&gt;&lt;a href="https://www.ft.com/content/b138e81a-29cd-11e3-9bc6-00144feab7de"&gt;&lt;i&gt;&lt;span&gt;Financial Times&lt;/span&gt;&lt;/i&gt;&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;This approach came at a cost: other jewelers (and the press) constantly berated Ratners for selling “cheap” and “tacky” products.&lt;/span&gt;&lt;/p&gt; &lt;figure aria-describedby="caption-attachment-9729" id="attachment_9729"&gt;&lt;img data-sizes="(max-width: 600px) 100vw, 600px" data-src="https://thehustle.co/wp-content/uploads/2018/08/ratner-pose-1.jpg" data-srcset="https://thehustle.co/wp-content/uploads/2018/08/ratner-pose-1.jpg 600w, https://thehustle.co/wp-content/uploads/2018/08/ratner-pose-1-300x244.jpg 300w" height="100%" width="2500" alt="" loading="lazy" src="https://thehustle.co/wp-content/uploads/2018/08/ratner-pose-1.jpg" srcset="https://thehustle.co/wp-content/uploads/2018/08/ratner-pose-1.jpg 600w, https://thehustle.co/wp-content/uploads/2018/08/ratner-pose-1-300x244.jpg 300w"&gt;&lt;figcaption id="caption-attachment-9729"&gt;Top: Ratner surveying his goods; Bottom: Ratner proudly displaying his wares shortly after he took over as CEO of Ratners Group (via The Telegraph)&lt;/figcaption&gt;&lt;/figure&gt; &lt;p&gt;&lt;span&gt;But Ratner’s strategy paid off: by 1990, he grew Ratners from 120 to more than 2k stores, captured 50% of the UK’s jewelry market, and had annual sales of £1.2B (US$1.57B) — £125m of which was profit. They bought up competing chains like Jared and Kay Jewelers.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;In quick order, Ratners became a household name and the great democratizer of a previously stuffy industry.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;“[I] just felt [I] could not fail,” &lt;/span&gt;&lt;a href="https://www.ft.com/content/b138e81a-29cd-11e3-9bc6-00144feab7de"&gt;&lt;span&gt;said&lt;/span&gt;&lt;/a&gt;&lt;span&gt; Ratner. Until, of course, he did.&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;&lt;b&gt;The speech that broke the businessman’s back&lt;/b&gt;&lt;/h2&gt; &lt;p&gt;&lt;span&gt;In 1991, Ratner’s success earned him an invitation to speak at the prestigious &lt;/span&gt;&lt;a href="https://en.wikipedia.org/wiki/Institute_of_Directors"&gt;&lt;span&gt;Institute of Directors&lt;/span&gt;&lt;/a&gt;&lt;span&gt; annual convention.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;Leading up to his speech, Ratner passed a draft by a public speaking consultant, and was given some advice: “I think you should put in a couple of jokes,” the man &lt;/span&gt;&lt;a href="https://www.thejc.com/business/features/interview-gerald-ratner-1.1929"&gt;&lt;span&gt;told him&lt;/span&gt;&lt;/a&gt;&lt;span&gt;. “People like your jokes.” Unfortunately, Ratner took it to an extreme.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;On the night of April 23, 1991, Ratner began his speech (&lt;/span&gt;&lt;a href="https://www.youtube.com/watch?v=Nj9BZz71yQE"&gt;&lt;span&gt;in full here&lt;/span&gt;&lt;/a&gt;&lt;span&gt;) innocently enough, harping on the event’s thematic values of quality, choice, and prosperity. Then, about 3 minutes in, he dropped several brutally honest jokes.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;“Ratners doesn’t represent prosperity — and come to think of it, it has very little to do with quality as well,” he began. “We do cut-glass sherry decanters complete with six glasses on a silver-plated tray that your butler can serve you drinks on, all for £4.95. People say, ‘How can you sell this for such a low price?’ I say, because it’s total crap.”&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;Then, several minutes later, just for good measure: “We even sell a pair of [gold] earrings for under £1,” he said. “Some people say, ‘That’s cheaper than a prawn sandwich!’…I have to say, the sandwich will probably last longer than the earrings.”&lt;/span&gt;&lt;/p&gt; &lt;figure aria-describedby="caption-attachment-9730" id="attachment_9730"&gt;&lt;img data-sizes="(max-width: 600px) 100vw, 600px" data-src="https://thehustle.co/wp-content/uploads/2018/08/ratnerspeech.jpg" data-srcset="https://thehustle.co/wp-content/uploads/2018/08/ratnerspeech.jpg 600w, https://thehustle.co/wp-content/uploads/2018/08/ratnerspeech-300x219.jpg 300w" height="100%" width="2500" alt="" loading="lazy" src="https://thehustle.co/wp-content/uploads/2018/08/ratnerspeech.jpg" srcset="https://thehustle.co/wp-content/uploads/2018/08/ratnerspeech.jpg 600w, https://thehustle.co/wp-content/uploads/2018/08/ratnerspeech-300x219.jpg 300w"&gt;&lt;figcaption id="caption-attachment-9730"&gt;Gerald Ratner’s ill-fated jokes (&lt;a href="https://thehustle.co/"&gt;The Hustle&lt;/a&gt;)&lt;/figcaption&gt;&lt;/figure&gt; &lt;p&gt;&lt;span&gt;The next morning, Ratner awoke to terrifying news: his comments had made national headlines to the effect of: “JEWELRY CEO CALLS HIS OWN PRODUCTS ‘CRAP.’” The &lt;/span&gt;&lt;i&gt;&lt;span&gt;Sunday Times&lt;/span&gt;&lt;/i&gt;&lt;span&gt; dubbed him “Gerald Crapner” — a nickname that caught on with disgruntled ex-customers.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;Initially, Ratner tried to play it off by featuring special in-store promotions that put a “humorous twist” on his remarks — but within a few weeks, it was clear that what he’d said had taken an irreparable toll on his business.&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;&lt;b&gt;The downfall &lt;/b&gt;&lt;/h2&gt; &lt;p&gt;&lt;span&gt;Within a few days of the speech, Ratners Group shares dropped by £500 million (US$1.8B today); by the end of 1991, its stock &lt;/span&gt;&lt;a href="https://timesmachine.nytimes.com/timesmachine/1991/12/08/307091.html?action=click&amp;amp;contentCollection=Archives&amp;amp;module=LedeAsset&amp;amp;region=ArchiveBody&amp;amp;pgtype=article&amp;amp;pageNumber=202"&gt;&lt;span&gt;was down 80%&lt;/span&gt;&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;One-time enthusiastic customers boycotted the brand and Ratners, which was quickly losing sales volume, was forced to close down hundreds of stores and lay off a hefty percentage of its 25k-person workforce.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;The company claimed there had been a “shift in consumer spending habits,” and that the &lt;/span&gt;&lt;a href="https://www.telegraph.co.uk/finance/9891085/From-the-archive-Ratner-says-recession-to-blame-for-17.7m-loss-not-controversial-comments.html"&gt;&lt;span&gt;ongoing recession&lt;/span&gt;&lt;/a&gt;&lt;span&gt; had finally caught up to its bottom line. But stock charts show the company suffered clear consequences from Ratner’s speech.&lt;/span&gt;&lt;/p&gt; &lt;figure aria-describedby="caption-attachment-9731" id="attachment_9731"&gt;&lt;img data-sizes="(max-width: 600px) 100vw, 600px" data-src="https://thehustle.co/wp-content/uploads/2018/08/ratners-share.jpg" data-srcset="https://thehustle.co/wp-content/uploads/2018/08/ratners-share.jpg 600w, https://thehustle.co/wp-content/uploads/2018/08/ratners-share-300x219.jpg 300w" height="100%" width="2500" alt="" loading="lazy" src="https://thehustle.co/wp-content/uploads/2018/08/ratners-share.jpg" srcset="https://thehustle.co/wp-content/uploads/2018/08/ratners-share.jpg 600w, https://thehustle.co/wp-content/uploads/2018/08/ratners-share-300x219.jpg 300w"&gt;&lt;figcaption id="caption-attachment-9731"&gt;Ratners stock declined by as much as 80% within 10 months of Ratner’s comments (Zachary Crockett/The Hustle)&lt;/figcaption&gt;&lt;/figure&gt; &lt;p&gt;&lt;span&gt;In November of 1992, Ratner was let go as CEO of Ratners Group. The day he left, he sold his shares for “pittance” to pay off the £1B (US$1.3B) he owed the bank, and walked away with nothing.&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;&lt;b&gt;The Ratner effect&lt;/b&gt;&lt;/h2&gt; &lt;p&gt;&lt;span&gt;In an age where tweet-happy CEOs are empowered with large digital audiences they can instantly broadcast to, Ratner’s story is a worthy parable.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;Today, the phrase “Doing a Ratner” is British &lt;/span&gt;&lt;a href="https://www.theguardian.com/business/2009/mar/07/gerald-ratner-interview"&gt;&lt;span&gt;parlance&lt;/span&gt;&lt;/a&gt;&lt;span&gt; for any time someone says something stupid that undermines his or her own product or customers — something that tends to play out more often than it should.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;We’ve seen many similarly high-profile stumbles in recent years:&lt;/span&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://www.telegraph.co.uk/news/2017/08/02/helen-mirren-admits-loreal-moisturiser-probably-does-f/"&gt;&lt;span&gt;Helen Mirren&lt;/span&gt;&lt;/a&gt;&lt;span&gt;, actress and paid brand ambassador of L’Oreal, said that using the company’s products “probably does f*ck all.”&lt;/span&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.theguardian.com/politics/2003/oct/17/uk.creditcards"&gt;&lt;span&gt;Matt Barrett&lt;/span&gt;&lt;/a&gt;&lt;span&gt;, ex-CEO of Barclays, insinuated that customers shouldn’t use the bank’s credit card products because they could “pile up debts.”&lt;/span&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.theguardian.com/business/nils-pratley-on-finance/2011/nov/15/john-pluthero-cww-ceo-quits"&gt;&lt;span&gt;John Pluthero&lt;/span&gt;&lt;/a&gt;&lt;span&gt;, then-CEO of the telecom giant Cable &amp;amp; Wireless, sent out a memo calling his company an “underperforming business in a crappy industry.”&lt;/span&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="http://business.time.com/2012/09/11/thats-some-quirky-marketing-strategy-ceo-calls-his-customers-idiots/"&gt;&lt;span&gt;Michael O’Leary&lt;/span&gt;&lt;/a&gt;&lt;span&gt;, CEO of Ryanair, called his passengers “idiots;” on another occasion, he said customers who ask for a refund should “f**k off.”&lt;/span&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://mashable.com/2015/10/08/lululemon-ceo-apologizes/"&gt;&lt;span&gt;Chip Wilson&lt;/span&gt;&lt;/a&gt;&lt;span&gt;, founder of lululemon, told customers his products “don’t work for certain women’s bodies.”&lt;/span&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;span&gt;A &lt;/span&gt;&lt;a href="https://hbr.org/2016/06/we-studied-38-incidents-of-ceo-bad-behavior-and-measured-their-consequences"&gt;&lt;span&gt;Harvard Business School study&lt;/span&gt;&lt;/a&gt;&lt;span&gt; that analyzed instances of CEO misbehavior between 200 and 2015 found that the average comment (or action) resulted in 250 negative news stories (some of which were cited up to 5 years later), and a 3.1% decline in company stock price.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;Though not true “Doing a Ratner” situations, we’ve also seen a number of business leaders say incredibly stupid things in a very public way, with very real financial consequences: twice this year, Tesla stock has fallen 4-5% after &lt;/span&gt;&lt;a href="https://www.cnbc.com/2018/07/16/tesla-sinks-after-elon-musk-tweets-again.html"&gt;&lt;span&gt;Elon Musk&lt;/span&gt;&lt;/a&gt;&lt;span&gt; spoke — once in &lt;/span&gt;&lt;a href="https://markets.businessinsider.com/news/stocks/tesla-stock-price-is-falling-after-elon-musk-jokes-about-the-company-going-bankrupt-2018-4-1020247710"&gt;&lt;span&gt;April&lt;/span&gt;&lt;/a&gt;&lt;span&gt;, when he joked about going “bankrupt,” and again in &lt;/span&gt;&lt;a href="https://www.cnbc.com/2018/07/16/tesla-sinks-after-elon-musk-tweets-again.html"&gt;&lt;span&gt;July&lt;/span&gt;&lt;/a&gt;&lt;span&gt;, when he called a Thai cave rescuer a “pedo guy.”&lt;/span&gt;&lt;/p&gt; &lt;figure aria-describedby="caption-attachment-9732" id="attachment_9732"&gt;&lt;img data-sizes="(max-width: 600px) 100vw, 600px" data-src="https://thehustle.co/wp-content/uploads/2018/08/share-musk.jpg" data-srcset="https://thehustle.co/wp-content/uploads/2018/08/share-musk.jpg 600w, https://thehustle.co/wp-content/uploads/2018/08/share-musk-300x165.jpg 300w" height="100%" width="2500" alt="" loading="lazy" src="https://thehustle.co/wp-content/uploads/2018/08/share-musk.jpg" srcset="https://thehustle.co/wp-content/uploads/2018/08/share-musk.jpg 600w, https://thehustle.co/wp-content/uploads/2018/08/share-musk-300x165.jpg 300w"&gt;&lt;figcaption id="caption-attachment-9732"&gt;Elon Musk (right) has drawn comparisons to Gerald Ratner in recent years, in part for his constant barrage of controversial tweets that impact Tesla’s stock (via Daily Express, SpaceX)&lt;/figcaption&gt;&lt;/figure&gt; &lt;p&gt;&lt;span&gt;As for Ratner?&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;After losing everything, he toiled in misery for years — but he eventually made an improbable comeback. In 1997, he took out a £155k (US$203k) loan on his house, built up a health club business, and sold it for £3.9m (US$5.1m). He then used the profits to start an online jewelry company. (The Ratners Group rebranded as &lt;/span&gt;&lt;a href="https://en.wikipedia.org/wiki/Signet_Jewelers"&gt;&lt;span&gt;Signet&lt;/span&gt;&lt;/a&gt;&lt;span&gt; in 1993; today, it is the largest diamond retailer in the world.)&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;But Ratner is unlikely to ever live down his ill-timed remarks nearly 3 decades ago.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;‘It doesn’t seem to matter that in the ‘80s I was Britain’s largest jeweler, with over 50% of the UK market,” he &lt;/span&gt;&lt;a href="http://www.thisismoney.co.uk/money/markets/article-2371730/GERALD-RATNER-INTERVIEW-How-I-cut-cr-p--The-return-UKs-biggest-online-jeweller.html"&gt;&lt;span&gt;told&lt;/span&gt;&lt;/a&gt; &lt;i&gt;&lt;span&gt;This Is Money&lt;/span&gt;&lt;/i&gt;&lt;span&gt;.&lt;/span&gt; &lt;span&gt;“My obituary will be all about being a disaster.”&lt;/span&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://thehustle.co/gerald-ratners-billion-dollar-speech"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:28:17 UT
      </pubDate>
      <guid>
        https://thehustle.co/gerald-ratners-billion-dollar-speech
      </guid>
    </item>
    <item>
      <title>
        App-pocalypse Now
      </title>
      <link>
        https://blog.codinghorror.com/app-pocalypse-now/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;section&gt; &lt;p&gt; I'm getting pretty sick of being nagged to install your damn apps. &lt;/p&gt; &lt;p&gt; &lt;img height="279" width="669" src="https://blog.codinghorror.com/content/images/uploads/2014/02/6a0120a85dcdae970b01a3fcc4a231970b-pi.jpg" title="This-website-has-an-ipad-app" alt="This-website-has-an-ipad-app"&gt;&lt;br&gt; &lt;/p&gt; &lt;p&gt; XKCD helpfully &lt;a href="http://xkcd.com/1174/"&gt;translates&lt;/a&gt;: &lt;/p&gt; &lt;p&gt; &lt;a href="http://xkcd.com/1174/"&gt;&lt;img height="318" width="474" src="https://blog.codinghorror.com/content/images/uploads/2014/02/6a0120a85dcdae970b01a73d7faa6b970d-pi.png" title="Xkcd-download-our-app" alt="Xkcd-download-our-app"&gt;&lt;/a&gt; &lt;/p&gt; &lt;p&gt; Yeah, there are &lt;a href="https://developer.apple.com/library/ios/documentation/AppleApplications/Reference/SafariWebContent/PromotingAppswithAppBanners/PromotingAppswithAppBanners.html"&gt;smart app banners&lt;/a&gt;, which are marginally less annoying, but it's amazing how quickly we went from "Cool! Phone apps that &lt;a href="http://www.codinghorror.com/blog/2009/06/the-iphone-software-revolution.html"&gt;finally don't suck!&lt;/a&gt;" to this sad, eye rolling, oh-great-of-&lt;i&gt;course&lt;/i&gt;-you-have-an-app-too state of affairs. &lt;/p&gt; &lt;blockquote lang="en"&gt;&lt;p&gt;"Would you like to install our free app?!?" is the new "It looks like you're writing a letter!"&lt;/p&gt;— Jeff Atwood (@codinghorror) &lt;a href="https://twitter.com/codinghorror/statuses/288918388141617152"&gt;January 9, 2013&lt;/a&gt;&lt;/blockquote&gt; &lt;p&gt; Four years, give or take a few months, if you were counting. So what happened? &lt;/p&gt; &lt;h2&gt;Millions of pointless apps&lt;/h2&gt; &lt;p&gt;Your platform now has a &lt;i&gt;million&lt;/i&gt; apps? Amazing! Wonderful! What they don't tell you is that 99% of them are awful junk that nobody would ever want. &lt;/p&gt; &lt;p&gt; Let's start with the basics. How do you know which apps you need? How do you get them installed? How do you keep them updated? How many apps can you reasonably keep track of on a phone? On a tablet? Just the home screen? A few screens? A dozen screens? When you have millions of apps out there, this rapidly becomes less of a "slap a few icons on the page" problem and more of a search problem like the greater web. My son's iPad has more than 10 pages of apps now, we don't even bother with the pretense of scrolling through pages of icons, we just go straight to search every time. &lt;/p&gt; &lt;p&gt; &lt;a href="http://solveforinteresting.com/facebooks-rocks-and-hard-places/"&gt;&lt;img height="251" width="610" src="https://blog.codinghorror.com/content/images/uploads/2014/02/6a0120a85dcdae970b01a73d7fadee970d-pi.jpg" title="Walledgarden-cover" alt="Walledgarden-cover"&gt;&lt;/a&gt; &lt;/p&gt; &lt;p&gt; The more apps out there, the more the app stores are clogged with mediocre junk, the more the overall noise level keeps going up, which leads directly to this profligate nagging. Companies keep asking &lt;i&gt;how can we get people to find and install our amazing app&lt;/i&gt; instead of the one question they really should have asked. &lt;/p&gt; &lt;p&gt; &lt;i&gt;Why the hell are we building an app in the first place?&lt;/i&gt;&lt;/p&gt; &lt;p&gt; I want to know who exactly is going to all the trouble of installing the McDonalds app on their device instead of simply visiting the McDonalds website in the browser as needed. What problem does that app solve for &lt;a href="http://aht.seriouseats.com/archives/2010/05/the-burger-lab-how-to-make-perfect-mcdonalds-style-french-fries.html"&gt;french fry enthusiasts&lt;/a&gt; that it needs to be permanently installed on your device? Why are they &lt;a href="http://slickdeals.net/f/5437442-free-mcdonald-s-sandwich-with-app"&gt;giving away free Big Macs&lt;/a&gt; just to get people to install this thing? &lt;/p&gt; &lt;h2&gt;Fragmentation into parallel and incompatible app worlds&lt;/h2&gt; &lt;p&gt;It was so much easier when iOS was totally dominant and the iPhone was the only player. Before the iPad and tablets. Before Android got decent in 4.0 and Google standardized the Play store. Now there are, at minimum, &lt;i&gt;four&lt;/i&gt; radically different mobile platforms that every serious app player has to support: &lt;/p&gt; &lt;ol&gt; &lt;li&gt;Android phone &lt;/li&gt;&lt;li&gt;iOS phone &lt;/li&gt;&lt;li&gt;iOS tablet &lt;/li&gt;&lt;li&gt;Android tablet &lt;/li&gt;&lt;/ol&gt; &lt;p&gt;(For extra credit: how many of these are actually "mobile"?)&lt;/p&gt; &lt;p&gt; Unless you're careful to build equivalent apps in all those places, it's like having multiple parallel Internets. "No, sorry, it's not available on that Internet, only the iOS phone Internet." Or even worse, only on the United States iOS phone Internet.&lt;/p&gt; &lt;p&gt; If you're feeling generous, we should technically include Windows 8 and Windows Phone in here too. All with different screen dimensions, development stacks, UI guidelines, and usage patterns. Oh and by the way, that's assuming no other players emerge as serious contenders in the computing device market. &lt;i&gt;Ever.&lt;/i&gt;&lt;/p&gt; &lt;p&gt;At the point where you find yourself praying for a duopoly as one of the better possible outcomes, that's … not a good sign.&lt;/p&gt; &lt;h2&gt;Paying for apps became a race to the bottom&lt;/h2&gt; &lt;p&gt;Buying an app is the modern &lt;a href="http://www.codinghorror.com/blog/2006/12/today-is-support-your-favorite-small-software-vendor-day.html"&gt;Support Your Favorite Small Software Vendor Day&lt;/a&gt;. I was always fine with dropping ten or twenty bucks on software I loved. I'm a software engineer by profession; apps are cheaper so I can buy even more of them.&lt;/p&gt; &lt;p&gt;Have you ever noticed that the people complaining about apps that cost $3.99 are the same people dropping five bucks on a cup of fancy coffee without batting an eyelash? Me too, and &lt;a href="http://www.joshlehman.com/thoughts/stop-using-the-cup-of-coffee-vs-0-99-cent-app-analogy/"&gt;I'm with the coffee people&lt;/a&gt;. $3.99 for your app? &lt;i&gt;Outraaageous!&lt;/i&gt;&lt;/p&gt; &lt;blockquote&gt; Now, contrast this with your app, Mr. Developer. I don’t know you from Adam. You’re pitching digital Instant Refresher Juice 1.0 to me in the form of a new app. The return I’m going to get is questionable at best. I already have 30 apps on my phone, some of them very good. Do I need another one? I don’t use the 30 I have. The experience I’m going to get from adding one more app is not trustable. I’m assured of nothing. Last week I bought an app for 99 cents and it was terrible. I used it once, for 15 seconds. I could be shoving $1 straight down the toilet again for all I know. Your app, good sir, is a total gamble. Sure, it’s only a $1 gamble… but it’s a gamble and that fact matters more than any price you might place on it. &lt;/blockquote&gt; &lt;p&gt;For some reason I don't completely understand, mobile app review systems are frequently of questionable value, so all you really have to go on are the screenshots and a bit of text provided by the developer.&lt;/p&gt; &lt;p&gt;Imagine you bought your coffee, only to open the lid and find it was only half full, or that it wasn't coffee at all but lemonade. If only 1 in 5 cups of coffee you bought actually contained coffee, a $3.99 price for that coffee starts to seem &lt;a href="http://struct.ca/2010/how-to-price-your-game/"&gt;unreasonably high&lt;/a&gt;. &lt;b&gt;When you buy an app, you don't really know what you're going to get.&lt;/b&gt;&lt;/p&gt; &lt;p&gt;Turns out, the precious resource here isn't the money after all. &lt;i&gt;It's your time.&lt;/i&gt; In a world of millions of apps, free is the correct and only price for most apps except those rare few of extreme, easily demonstrable value – probably from well known brands of websites you already use daily. So hey, everything is &lt;i&gt;free!&lt;/i&gt; Awesome! Right? Well… &lt;/p&gt;&lt;h2&gt;When apps are free, you're the product&lt;/h2&gt; &lt;p&gt;I know, I know, I'm sick of this trite phrase too. But if the market is emphatically proving that free is the only sustainable model for apps, then this is the new reality we have to acknowledge.&lt;/p&gt; &lt;p&gt; &lt;a href="http://geekandpoke.typepad.com/geekandpoke/2010/12/the-free-model.html"&gt;&lt;img height="454" width="521" src="https://blog.codinghorror.com/content/images/uploads/2014/02/6a0120a85dcdae970b01a3fcc55683970b-800wi.png" title="Geek-and-poke-pigs-free" alt="Geek-and-poke-pigs-free"&gt;&lt;/a&gt; &lt;/p&gt; &lt;p&gt;Nothing terrifies me more than an app with no moral conscience in the desperate pursuit of revenue that has full access to everything on my phone: contacts, address book, pictures, email, auth tokens, you name it. I'm not excited by the prospect of installing an app on my phone these days. It's more like a vague sense of impending dread, with my finger shakily hovering over the uninstall button the whole time. All I can think is &lt;b&gt;what shitty thing is this "free" app going to do to me so they can satisfy their investors?&lt;/b&gt;&lt;/p&gt; &lt;p&gt;For the sake of argument, let's say the app is free, and the developers are ethical, so you trust that they won't do anything sketchy with the personal information on your device to make ends meet. Great! But they still have to make a living, don't they? Which means doing anything &lt;i&gt;useful&lt;/i&gt; in the app requires buying three "optional" add-ons that cost $2.99 each. Or there are special fees for performing certain actions. Isn't this stuff you would want to know before installing the app? You betcha. Maybe the app is properly tagged as "offering in-app purchases" but &lt;b&gt;the entire burden of discovering exactly what "in-app purchases" means, and how much the app will ultimately cost you, is placed completely on your shoulders.&lt;/b&gt; You, the poor, bedraggled user. &lt;/p&gt; &lt;h2&gt;The app user experience is wildly inconsistent&lt;/h2&gt; &lt;p&gt;Have you ever tried actually &lt;i&gt;using&lt;/i&gt; the Amazon app on iOS, Android, and Windows? iOS does the best, mostly because it's been an app platform for longer than the others, but even there, the Amazon app is a frustrating morass of missing and incomplete functions from the website. Sure, maybe you don't need the full breadth of Amazon functions on your phone, though that's debatable on a tablet. But natural web conveniences like opening links in new tabs, sharing links, the back button, searching within the page, and zooming in and out are available inconsistently, if at all. &lt;/p&gt; &lt;p&gt;The minute you begin switching between platforms – say you use an iOS tablet and an Android phone and a Windows 8 touch laptop, like I do – you'll find there are &lt;i&gt;massive&lt;/i&gt; differences between the Amazon apps (and the eBay apps, and the Netflix apps, and the..) on these different platforms. At some point, you just get fed up with all the inconsistencies and oddities and quirks and say to hell with these apps, &lt;b&gt;can I please just use the website instead?&lt;/b&gt;&lt;/p&gt; &lt;p&gt; Now, if your website is an awful calcified throwback to 2003, like eBay, then the &lt;a href="http://www.codinghorror.com/blog/2012/04/will-apps-kill-websites.html"&gt;mobile apps can be a valuable opportunity to reinvent your user interface&lt;/a&gt; without alienating all your existing users. If there's one thing I love about tablet and phone design it's that their small screens and touch interfaces force people to &lt;a href="http://www.codinghorror.com/blog/2006/03/in-pursuit-of-simplicity.html"&gt;think simpler&lt;/a&gt;. This is a good thing. But if you don't eventually take those improvements home to the mothership, you're creating two totally different and incompatible UIs for doing the same things. &lt;/p&gt; &lt;p&gt;It seems like a fool's errand to dump millions of dollars of development time into these radically different, siloed app platforms when Amazon could have spent it improving their website and making that experience scale a bit better to every device out there. &lt;/p&gt; &lt;h2&gt;The World Wide App&lt;/h2&gt; &lt;p&gt;But that's not an option, because apparently &lt;a href="https://twitter.com/rabois/status/406519032624320512"&gt;the web is dead&lt;/a&gt;, and mobile apps are the future. I'm doing my best to resist a sudden uncontrollable urge to use my Ledge Finder app to find the nearest ledge to jump from right now.&lt;/p&gt; &lt;p&gt;The tablet and phone app ecosystem is slowly, painstakingly reinventing everything I hated about the computer software industry before the web blew it all up. Even fans &lt;a href="http://parislemon.com/post/77357979234/a-new-glue-for-a-new-kingdom"&gt;are concerned&lt;/a&gt;:&lt;/p&gt; &lt;blockquote&gt; I’m waiting for something that will unify the world of apps and make manually going to an App Store to find a new app as weird as typing in a URL to find a new website. My bet is that this won’t be Facebook. Instead, I would not bet against some young upstart, perhaps one inspired upon reading about a $19 billion deal, to go heads-down and come up with something crazy. &lt;/blockquote&gt; &lt;p&gt; I'll have more to say about this soon, but I expect there to be an explosion of new computing devices all over the world in the next few decades, not a contraction. Sometimes the craziest solution is the one that's been right there in front of you the whole time. &lt;/p&gt; &lt;/section&gt;&lt;/div&gt;&lt;a href="https://blog.codinghorror.com/app-pocalypse-now/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:28:28 UT
      </pubDate>
      <guid>
        https://blog.codinghorror.com/app-pocalypse-now/
      </guid>
    </item>
    <item>
      <title>
        Erlang &amp;middot; How I Start.
      </title>
      <link>
        https://howistart.org/posts/erlang/1/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt; &lt;p&gt;&lt;span&gt;Written by&lt;/span&gt; Fred Hebert &lt;br&gt; &lt;span&gt;on&amp;nbsp;&lt;/span&gt;&lt;time datetime="2015-06-22 00:00:00 +0000 UTC"&gt;June 22, 2015&lt;/time&gt; &lt;/p&gt; &lt;h2&gt;Erlang&lt;/h2&gt; &lt;h2 id="intro"&gt;Intro&lt;/h2&gt; &lt;p&gt;Erlang releases are a bit like magnets. Everyone who thinks about them shares the same thought: f**king releases, how do they work?&lt;/p&gt; &lt;p&gt;Fortunately, since the years of Emakefiles, reltool and systools, the Erlang community has stood up and improved its tooling continuously.&lt;/p&gt; &lt;p&gt;Rebar has been improving non-stop and keeps getting better for many functions. The newest generation, Rebar3, tries to provide an end-to-end experience to building Erlang projects.&lt;/p&gt; &lt;p&gt;Along with &lt;a href="https://www.erlang-solutions.com/downloads"&gt;installing Erlang&lt;/a&gt; (version R16B03-1 at least), getting a hold of Rebar3 is all you’re gonna need.&lt;/p&gt; &lt;p&gt;For rebar, just &lt;a href="http://www.rebar3.org/v3.0/docs/getting-started"&gt;download it and follow the instructions&lt;/a&gt;. Rebar3 will basically generate a self-executable that you can store in your repository, or install globally on your computer. This tutorial expects that you have installed it in your system and made it available in your &lt;code&gt;$PATH&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Once they’re all installed somewhere in your system, arm yourself with the text editor or IDE of your choice (mine is Vim, because I’m a terrible person) and get ready to write a few things.&lt;/p&gt; &lt;h2 id="my-environment"&gt;My Environment&lt;/h2&gt; &lt;p&gt;&lt;img alt="" src="https://howistart.org/posts/erlang/1/images/env.png"&gt;&lt;/p&gt; &lt;p&gt;Despite you being free to develop on whatever you want, I’m gonna go through whatever my setup is.&lt;/p&gt; &lt;p&gt;I use zsh with &lt;a href="https://github.com/robbyrussell/oh-my-zsh"&gt;oh-my-zsh&lt;/a&gt;, using a &lt;a href="https://gist.github.com/ferd/9905862"&gt;custom theme&lt;/a&gt; (depends on &lt;a href="https://bitbucket.org/sjl/hg-prompt/src"&gt;hg-prompt&lt;/a&gt; as a script), and stuck in vi-mode, because vim vim vim.&lt;/p&gt; &lt;p&gt;For vim itself, to work with Erlang, I use these two lines in my .vimrc file:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="VimL"&gt;&lt;span&gt;autocmd&lt;/span&gt; &lt;span&gt;BufRead&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;BufNewFile&lt;/span&gt; *.&lt;span&gt;erl&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;*.&lt;span&gt;es&lt;/span&gt;.*.&lt;span&gt;hrl&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;*.&lt;span&gt;yaws&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;*.&lt;span&gt;xrl&lt;/span&gt; &lt;span&gt;set&lt;/span&gt; &lt;span&gt;expandtab&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;au&lt;/span&gt; &lt;span&gt;BufNewFile&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;BufRead&lt;/span&gt; *.&lt;span&gt;erl&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;*.&lt;span&gt;es&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;*.&lt;span&gt;hrl&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;*.&lt;span&gt;yaws&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;*.&lt;span&gt;xrl&lt;/span&gt; &lt;span&gt;setf&lt;/span&gt; &lt;span&gt;erlang&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;And I depend on these two plugins:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;a href="https://github.com/jimenezrick/vimerl"&gt;vimerl&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/edkolev/erlang-motions.vim"&gt;erlang-motions&lt;/a&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;I don’t use a lot of material outside of that, and the OS will tend to be my IDE – for projects that I tend to work on a lot, I will use tmux scripts (see &lt;a href="http://blog.htbaa.com/news/tmux-scripting"&gt;this blog post for an example&lt;/a&gt;) – to get everything going early.&lt;/p&gt; &lt;h2 id="the-project"&gt;The Project&lt;/h2&gt; &lt;p&gt;To avoid the usual Hello World stuff, this tutorial will use a somewhat more fun application to get up and running from a basic Erlang app that can be run within a module, to a proper OTP library that can be included by other projects, to a release than can be self-executing and distributed to client’s computer, or on a server.&lt;/p&gt; &lt;p&gt;Our project will be the replication of one of the most well-known software programs in popular history, used in life-critical situations: Homer Simpson’s console in the episode where he’s so fat he can work at home.&lt;/p&gt; &lt;p&gt;&lt;img alt="" src="https://howistart.org/posts/erlang/1/images/homer-computer.gif"&gt;&lt;/p&gt; &lt;p&gt;From this episode we can infer the following about the software:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;When the program boots, it asks you to press any key.&lt;/li&gt; &lt;li&gt;The program will ask you questions that can be answered by &lt;code&gt;yes/no&lt;/code&gt;, but also &lt;code&gt;Y/N&lt;/code&gt; or &lt;code&gt;y/n&lt;/code&gt;&lt;/li&gt; &lt;li&gt;Most questions can be turned into commands. Each assertion is equivalent to answering a given question positively. For example, &lt;code&gt;Vent radioactive gas? Yes/No&lt;/code&gt; can be turned into the &lt;code&gt;Vent gas&lt;/code&gt; command.&lt;/li&gt; &lt;li&gt;Nothing should go wrong if you keep pressing &lt;code&gt;Y&lt;/code&gt; all the time&lt;/li&gt; &lt;li&gt;After a given delay, a new question is asked&lt;/li&gt; &lt;li&gt;Too many times without venting radioactive gas risks exploding everything&lt;/li&gt; &lt;li&gt;Some behaviours aren’t defined by the TV show, so we go somewhat anyway we feel like&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Out of this, a finite-state machine can be created. The one that follows explains what I understood as possible, but you’ll notice I’m not really good at having a consistent notation for events, states, and so on:&lt;/p&gt; &lt;pre&gt;&lt;code&gt; [press any key] | (key pressed) | [check core temperature (first)] \________,________/ | (yes/no) | [venting radioactive gases (first)] | | (yes) ,-&amp;lt;-, (no) | | | | [gas blows away crop] | [venting prevents explosions] | | | | | '--&amp;lt;-(yes) (no) \ / \______________,_____________/ V | [wait for command]&amp;lt;--------, / \ | (get data) (timeout) | | | | | [ask question] | | / \ | | (Yes) (No) | | / | | +----' '-----+ | | [show result] --&amp;gt;-------' &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Based on this, we’ll be able to draw up a first prototype with all the required state transitions. I’ve also looked for transcripts of the show and extracted the following questions and consequences:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;Check core temperature. yes/no:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;yes&lt;/code&gt;: Core temperature normal.&lt;/li&gt; &lt;li&gt;&lt;code&gt;no&lt;/code&gt;: –&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;Vent radioactive gas?&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;yes&lt;/code&gt;: *gas blows away corn crop*&lt;/li&gt; &lt;li&gt;&lt;code&gt;no&lt;/code&gt;: venting prevents explosion (allow &lt;code&gt;yes&lt;/code&gt;, show only the first time?)&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;Sound alertness horn?&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;yes&lt;/code&gt;: *horn sounds in the distance*&lt;/li&gt; &lt;li&gt;&lt;code&gt;no&lt;/code&gt;: –&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;Decalcify calcium ducts?&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;yes&lt;/code&gt;: –&lt;/li&gt; &lt;li&gt;&lt;code&gt;no&lt;/code&gt;: –&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;Special case: after denying venting too many times, the valve must be disabled manually.&lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;The simplest way to write a basic FSM for this one is to use a bunch of function calls. Given Erlang has last call optimization (a call that happens as a return value does not leave a stack trace, and therefore can happen infinitely many times), this is more than adequate.&lt;/p&gt; &lt;p&gt;The sequence of states &lt;code&gt;a -&amp;gt; b -&amp;gt; c&lt;/code&gt; can be programmed as:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="erlang"&gt;&lt;span&gt;a&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;b&lt;/span&gt;&lt;span&gt;().&lt;/span&gt; &lt;span&gt;b&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;c&lt;/span&gt;&lt;span&gt;().&lt;/span&gt; &lt;span&gt;c&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;done&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;Of course, there’s going to be more data in our case.&lt;/p&gt; &lt;h2 id="the-prototype"&gt;The Prototype&lt;/h2&gt; &lt;p&gt;Our glorious application will be called ‘muumuu’. Whenever I don’t exactly know where I’m going, I decide to prototype stuff. And here I stress the importance of &lt;em&gt;prototype&lt;/em&gt;. Despite this fact, it will often end up being in production, but yeah – that’s to be avoided.&lt;/p&gt; &lt;p&gt;I decide to start with the basic stuff to prototype, state transitions. I go for them in a fairly simple manner, top-down:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="erlang"&gt;&lt;span&gt;-&lt;/span&gt;&lt;span&gt;module&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;muumuu_fsm&lt;/span&gt;&lt;span&gt;).&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;export&lt;/span&gt;&lt;span&gt;([&lt;/span&gt;&lt;span&gt;start&lt;/span&gt;&lt;span&gt;/&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;]).&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;define&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;MAX_NO_VENT&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;5&lt;/span&gt;&lt;span&gt;).&lt;/span&gt; &lt;span&gt;start&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; %% S&lt;/span&gt;&lt;span&gt;eed&lt;/span&gt; &lt;span&gt;PRNG&lt;/span&gt; &lt;span&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span&gt;A&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;32&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;B&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;32&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;C&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;32&lt;/span&gt;&lt;span&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;crypto&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;rand_bytes&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;random&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;seed&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;A&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;B&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;C&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;wait_any_key&lt;/span&gt;&lt;span&gt;().&lt;/span&gt; &lt;span&gt;%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% &lt;/span&gt;&lt;span&gt;%%% States and Transitions %%% &lt;/span&gt;&lt;span&gt;%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% &lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;wait_any_key&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;io&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;get_line&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"To Start, Press Any Key.&lt;/span&gt;&lt;span&gt;\n&lt;/span&gt;&lt;span&gt;&amp;gt; "&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;first_core_check&lt;/span&gt;&lt;span&gt;().&lt;/span&gt; &lt;span&gt;first_core_check&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;case&lt;/span&gt; &lt;span&gt;option&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"Check core temperature?"&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;of&lt;/span&gt; &lt;span&gt;yes&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;core_temperature&lt;/span&gt;&lt;span&gt;();&lt;/span&gt; &lt;span&gt;no&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;noop&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;end&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;first_gas_vent&lt;/span&gt;&lt;span&gt;().&lt;/span&gt; &lt;span&gt;first_gas_vent&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;case&lt;/span&gt; &lt;span&gt;option&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"Vent radioactive gas?"&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;of&lt;/span&gt; &lt;span&gt;yes&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;blow_crops_away&lt;/span&gt;&lt;span&gt;();&lt;/span&gt; &lt;span&gt;no&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;venting_prevents_explosions&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;end&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;wait_for_command&lt;/span&gt;&lt;span&gt;().&lt;/span&gt; &lt;span&gt;wait_for_command&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;case&lt;/span&gt; &lt;span&gt;wait_cmd&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;10000&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;of&lt;/span&gt; &lt;span&gt;timeout&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; {O&lt;/span&gt;&lt;span&gt;pt&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Yes&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;No&lt;/span&gt;&lt;span&gt;}&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;random_option&lt;/span&gt;&lt;span&gt;(),&lt;/span&gt; &lt;span&gt;case&lt;/span&gt; &lt;span&gt;option&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Opt&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;of&lt;/span&gt; &lt;span&gt;yes&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; Y&lt;/span&gt;&lt;span&gt;es&lt;/span&gt;&lt;span&gt;();&lt;/span&gt; &lt;span&gt;no&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; N&lt;/span&gt;&lt;span&gt;o&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;end&lt;/span&gt;&lt;span&gt;;&lt;/span&gt; &lt;span&gt;Cmd&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;case&lt;/span&gt; &lt;span&gt;match_option&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Cmd&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;of&lt;/span&gt; &lt;span&gt;{_,&lt;/span&gt; &lt;span&gt;Yes&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;_}&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; Y&lt;/span&gt;&lt;span&gt;es&lt;/span&gt;&lt;span&gt;();&lt;/span&gt; &lt;span&gt;_&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;noop&lt;/span&gt; &lt;span&gt;end&lt;/span&gt; &lt;span&gt;end&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;wait_for_command&lt;/span&gt;&lt;span&gt;().&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;In this bit of code, we can see our 4 main states:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;code&gt;wait_any_key&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;first_core_check&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;first_gas_event&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;wait_for_command&lt;/code&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;The rest of the code is more or less going to be events and input management to check the transitions:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;printing questions and getting responses (&lt;code&gt;option/1&lt;/code&gt;)&lt;/li&gt; &lt;li&gt;eventually waiting for a command (&lt;code&gt;wait_cmd/1&lt;/code&gt; and &lt;code&gt;match_option/1&lt;/code&gt;)&lt;/li&gt; &lt;li&gt;or, if it takes too long, generate an option randomly (&lt;code&gt;random_option/1&lt;/code&gt;)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;You can look at the code, find whatever you want about it disgusting. So that’s the general idea I want in the code. Time to add all that option management stuff:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="erlang"&gt;&lt;span&gt;%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% &lt;/span&gt;&lt;span&gt;%%% Options and Response Handling %%% &lt;/span&gt;&lt;span&gt;%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% &lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;option&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Prompt&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;show_option&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Prompt&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;Data&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;io&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;get_line&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;""&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;case&lt;/span&gt; &lt;span&gt;iolist_to_binary&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Data&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;of&lt;/span&gt; &lt;span&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span&gt;"Y"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;_&lt;/span&gt;&lt;span&gt;/&lt;/span&gt;&lt;span&gt;binary&lt;/span&gt;&lt;span&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;yes&lt;/span&gt;&lt;span&gt;;&lt;/span&gt; &lt;span&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span&gt;"y"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;_&lt;/span&gt;&lt;span&gt;/&lt;/span&gt;&lt;span&gt;binary&lt;/span&gt;&lt;span&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;yes&lt;/span&gt;&lt;span&gt;;&lt;/span&gt; &lt;span&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span&gt;"N"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;_&lt;/span&gt;&lt;span&gt;/&lt;/span&gt;&lt;span&gt;binary&lt;/span&gt;&lt;span&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;no&lt;/span&gt;&lt;span&gt;;&lt;/span&gt; &lt;span&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span&gt;"n"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;_&lt;/span&gt;&lt;span&gt;/&lt;/span&gt;&lt;span&gt;binary&lt;/span&gt;&lt;span&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;no&lt;/span&gt;&lt;span&gt;;&lt;/span&gt; &lt;span&gt;_&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;ambiguous&lt;/span&gt; &lt;span&gt;end&lt;/span&gt;&lt;span&gt;.&lt;/span&gt; &lt;span&gt;show_option&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Str&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;io&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;format&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"&lt;/span&gt;&lt;span&gt;~s&lt;/span&gt;&lt;span&gt; (Y/N)&lt;/span&gt;&lt;span&gt;~n&lt;/span&gt;&lt;span&gt;&amp;gt; "&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;Str&lt;/span&gt;&lt;span&gt;]).&lt;/span&gt; &lt;span&gt;wait_cmd&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Timeout&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; P&lt;/span&gt;&lt;span&gt;arent&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;self&lt;/span&gt;&lt;span&gt;(),&lt;/span&gt; &lt;span&gt;Pid&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;spawn&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;fun&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; P&lt;/span&gt;&lt;span&gt;arent&lt;/span&gt; &lt;span&gt;!&lt;/span&gt; &lt;span&gt;io&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;get_line&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;""&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;end&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;receive&lt;/span&gt; &lt;span&gt;Data&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; D&lt;/span&gt;&lt;span&gt;ata&lt;/span&gt; &lt;span&gt;after&lt;/span&gt; &lt;span&gt;Timeout&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;exit&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Pid&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;kill&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;timeout&lt;/span&gt; &lt;span&gt;end&lt;/span&gt;&lt;span&gt;.&lt;/span&gt; &lt;span&gt;random_option&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; P&lt;/span&gt;&lt;span&gt;os&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;random&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;uniform&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;tuple_size&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;opts&lt;/span&gt;&lt;span&gt;())),&lt;/span&gt; &lt;span&gt;{_,&lt;/span&gt; &lt;span&gt;Val&lt;/span&gt;&lt;span&gt;}&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;element&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Pos&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;opts&lt;/span&gt;&lt;span&gt;()),&lt;/span&gt; &lt;span&gt;Val&lt;/span&gt;&lt;span&gt;.&lt;/span&gt; &lt;span&gt;match_option&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Data&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;case&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;Vals&lt;/span&gt; &lt;span&gt;||&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;Pattern&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Vals&lt;/span&gt;&lt;span&gt;}&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;-&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;tuple_to_list&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;opts&lt;/span&gt;&lt;span&gt;()),&lt;/span&gt; &lt;span&gt;nomatch&lt;/span&gt; &lt;span&gt;=/=&lt;/span&gt; &lt;span&gt;re&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;run&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Data&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Pattern&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;caseless&lt;/span&gt;&lt;span&gt;])]&lt;/span&gt; &lt;span&gt;of&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;Opt&lt;/span&gt;&lt;span&gt;|_]&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; O&lt;/span&gt;&lt;span&gt;pt&lt;/span&gt;&lt;span&gt;;&lt;/span&gt; &lt;span&gt;[]&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;invalid_opt&lt;/span&gt; &lt;span&gt;end&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;Cool. Not fantastic looking yet. Basically, an option will only fetch a line of text entered by the user, look at the first response, and return what it is. Showing the options just wraps things up so they look like a prompt.&lt;/p&gt; &lt;p&gt;Interestingly enough, the command has to be waited for in a different process. The problem with this it that Erlang’s standard library doesn’t support a timeout mode for &lt;code&gt;io&lt;/code&gt; operations, which would tell us “wait 10 seconds for input or quit”. Therefore, there is a need to move this to a process.&lt;/p&gt; &lt;p&gt;The rest relies on an elusive &lt;code&gt;opts()&lt;/code&gt; function that apparently returns all questions and options offered to the user:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="erlang"&gt;&lt;span&gt;%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% &lt;/span&gt;&lt;span&gt;%%% Defining Options/Events %%% &lt;/span&gt;&lt;span&gt;%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% &lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;opts&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; {{"(&lt;/span&gt;&lt;span&gt;check&lt;/span&gt;&lt;span&gt;|&lt;/span&gt;&lt;span&gt;core&lt;/span&gt;&lt;span&gt;|&lt;/span&gt;&lt;span&gt;temp&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;", &lt;/span&gt;&lt;span&gt; {"&lt;/span&gt;&lt;span&gt;Check&lt;/span&gt; &lt;span&gt;core&lt;/span&gt; &lt;span&gt;temperature&lt;/span&gt;&lt;span&gt;?&lt;/span&gt;&lt;span&gt;", &lt;/span&gt;&lt;span&gt; fun core_temperature/0, &lt;/span&gt;&lt;span&gt; fun noop/0}}, &lt;/span&gt;&lt;span&gt; {"&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;vent&lt;/span&gt;&lt;span&gt;|&lt;/span&gt;&lt;span&gt;rad&lt;/span&gt;&lt;span&gt;|&lt;/span&gt;&lt;span&gt;gas&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;", &lt;/span&gt;&lt;span&gt; {"&lt;/span&gt;&lt;span&gt;Vent&lt;/span&gt; &lt;span&gt;radioactive&lt;/span&gt; &lt;span&gt;gas&lt;/span&gt;&lt;span&gt;?&lt;/span&gt;&lt;span&gt;", &lt;/span&gt;&lt;span&gt; fun vent_gas/0, &lt;/span&gt;&lt;span&gt; fun no_venting/0}}, &lt;/span&gt;&lt;span&gt; {"&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;sound&lt;/span&gt;&lt;span&gt;|&lt;/span&gt;&lt;span&gt;alert&lt;/span&gt;&lt;span&gt;|&lt;/span&gt;&lt;span&gt;horn&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;", &lt;/span&gt;&lt;span&gt; {"&lt;/span&gt;&lt;span&gt;Sound&lt;/span&gt; &lt;span&gt;alertness&lt;/span&gt; &lt;span&gt;horn&lt;/span&gt;&lt;span&gt;?&lt;/span&gt;&lt;span&gt;", &lt;/span&gt;&lt;span&gt; fun sound_horn/0, &lt;/span&gt;&lt;span&gt; fun noop/0}}, &lt;/span&gt;&lt;span&gt; {"&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;calc&lt;/span&gt;&lt;span&gt;|&lt;/span&gt;&lt;span&gt;duct&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;", &lt;/span&gt;&lt;span&gt; {"&lt;/span&gt;&lt;span&gt;Decalcify&lt;/span&gt; &lt;span&gt;calcium&lt;/span&gt; &lt;span&gt;ducts&lt;/span&gt;&lt;span&gt;?&lt;/span&gt;&lt;span&gt;", &lt;/span&gt;&lt;span&gt; fun noop/0, &lt;/span&gt;&lt;span&gt; fun noop/0}}}.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;This basically is a tuple (I use a tuple because it makes random selection with a fixed position more efficient) of all questions, positive and negative response and consequences, paired up with a regular expression that represents fuzzy matching – for example, someone typing it &lt;code&gt;check temperature&lt;/code&gt; should match &lt;code&gt;Check core temperature?&lt;/code&gt; as a question, and return both options. The code back in &lt;code&gt;wait_for_command/0&lt;/code&gt; will only execute the &lt;code&gt;core_temperature/0&lt;/code&gt; function.&lt;/p&gt; &lt;p&gt;Finally, all actions and consequences can be implemented:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="erlang"&gt;&lt;span&gt;noop&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;ok&lt;/span&gt;&lt;span&gt;.&lt;/span&gt; &lt;span&gt;venting_prevents_explosions&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;case&lt;/span&gt; &lt;span&gt;option&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"Venting prevents explosion."&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;of&lt;/span&gt; &lt;span&gt;yes&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;blow_crops_away&lt;/span&gt;&lt;span&gt;();&lt;/span&gt; &lt;span&gt;no&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;noop&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;end&lt;/span&gt;&lt;span&gt;.&lt;/span&gt; &lt;span&gt;core_temperature&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;io&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;format&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"Core temperature normal.&lt;/span&gt;&lt;span&gt;~n&lt;/span&gt;&lt;span&gt;"&lt;/span&gt;&lt;span&gt;).&lt;/span&gt; &lt;span&gt;blow_crops_away&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;io&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;format&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"*Gas blows away corn crop*&lt;/span&gt;&lt;span&gt;~n&lt;/span&gt;&lt;span&gt;"&lt;/span&gt;&lt;span&gt;).&lt;/span&gt; &lt;span&gt;sound_horn&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;io&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;format&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"*horn sounds in the distance*&lt;/span&gt;&lt;span&gt;~n&lt;/span&gt;&lt;span&gt;"&lt;/span&gt;&lt;span&gt;).&lt;/span&gt; &lt;span&gt;pressure_too_high&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;io&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;format&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"Pressure too high. Tank must be shut down manually.&lt;/span&gt;&lt;span&gt;~n&lt;/span&gt;&lt;span&gt;"&lt;/span&gt;&lt;span&gt;).&lt;/span&gt; &lt;span&gt;vent_gas&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; %% A&lt;/span&gt;&lt;span&gt;fter&lt;/span&gt; &lt;span&gt;?&lt;/span&gt;&lt;span&gt;MAX_NO_VENT&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;pressure&lt;/span&gt; &lt;span&gt;has&lt;/span&gt; &lt;span&gt;to&lt;/span&gt; &lt;span&gt;be&lt;/span&gt; &lt;span&gt;shut&lt;/span&gt; &lt;span&gt;down&lt;/span&gt; &lt;span&gt;%% manually -- unsupported in this here program! &lt;/span&gt;&lt;span&gt;&lt;/span&gt; &lt;span&gt;case&lt;/span&gt; &lt;span&gt;get&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;missed&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;of&lt;/span&gt; &lt;span&gt;?&lt;/span&gt;&lt;span&gt;MAX_NO_VENT&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;pressure_too_high&lt;/span&gt;&lt;span&gt;();&lt;/span&gt; &lt;span&gt;_&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;put&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;missed&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;blow_crops_away&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;end&lt;/span&gt;&lt;span&gt;.&lt;/span&gt; &lt;span&gt;no_venting&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;case&lt;/span&gt; &lt;span&gt;get&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;missed&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;of&lt;/span&gt; &lt;span&gt;undefined&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;put&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;missed&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;);&lt;/span&gt; &lt;span&gt;N&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt;put&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;missed&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;N&lt;/span&gt;&lt;span&gt;+&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;end&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;Here the two last functions implement the special last requirement: after denying venting too many times, the valve must be disabled manually.&lt;/p&gt; &lt;p&gt;Here we use a dirty ugly counter for prototyping’s sake. In fact I had forgotten about that requirement at the time and just bolted it on that way. The prototype helped figure that requirement out, and the final version can now be designed with this in mind.&lt;/p&gt; &lt;p&gt;You can run the code and try it from a shell:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;λ → erlc src/muumuu_fsm.erl &amp;amp;&amp;amp; erl -s muumuu_fsm -noshell To Start, Press Any Key. &amp;gt; . Check core temperature? (Y/N) &amp;gt; N Vent radioactive gas? (Y/N) &amp;gt; No Venting prevents explosion. (Y/N) &amp;gt; yes *Gas blows away corn crop* Sound alertness horn? (Y/N) &amp;gt; Y *horn sounds in the distance* &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;That works. Using &lt;code&gt;-s &amp;lt;module&amp;gt;&lt;/code&gt; runs the &lt;code&gt;start/0&lt;/code&gt; function from that module, and using &lt;code&gt;-noshell&lt;/code&gt; makes it so that the Erlang VM won’t fight with all the &lt;code&gt;io&lt;/code&gt; calls I’m doing for user input ownership.&lt;/p&gt; &lt;p&gt;Sadly, the implementation is kind of ugly and shouldn’t go in production.&lt;/p&gt; &lt;p&gt;&lt;img alt="" src="https://howistart.org/posts/erlang/1/images/muumuu.gif"&gt;&lt;/p&gt; &lt;h2 id="making-it-a-library"&gt;Making it a library&lt;/h2&gt; &lt;p&gt;There are two ways to make something reach production: distributing yourself, or distributing it as a library other Erlang developers can use.&lt;/p&gt; &lt;p&gt;The latter can be a prerequisite for the former, so we’re going to start there. By default, everyone using Erlang in the open source community uses &lt;a href="http://learnyousomeerlang.com/building-otp-applications"&gt;OTP applications&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;OTP is kind of often treated as a super advanced topic, so what I’m gonna show here is how to take any non-OTP compliant code and turn it into an OTP application. Fun fun.&lt;/p&gt; &lt;p&gt;First, the directory structure:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;src/ - muumuu_fsm.erl &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;That’s all you need in terms of structure if you have rebar3 installed in your system.&lt;/p&gt; &lt;p&gt;Add a file in &lt;code&gt;src/&lt;/code&gt; called &lt;code&gt;muumuu.app.src&lt;/code&gt;. This file is basically telling Erlang (and rebar3) what the library is:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="erlang"&gt;&lt;span&gt;{&lt;/span&gt;&lt;span&gt;application&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;muumuu&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;description&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;"Too fat to go to the power plant app"&lt;/span&gt;&lt;span&gt;},&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;vsn&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;"0.1.0"&lt;/span&gt;&lt;span&gt;},&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;registered&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[]},&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;applications&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;kernel&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;stdlib&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;crypto&lt;/span&gt;&lt;span&gt;]},&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;mod&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;muumuu_app&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[]}},&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;env&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[]}&lt;/span&gt; &lt;span&gt;]}.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;The &lt;code&gt;registered&lt;/code&gt; entry specifies what processes are going to be globally registered on the node. In this case, none. The &lt;code&gt;applications&lt;/code&gt; tuple is a list of all applications we depend on. All applications depend on both &lt;code&gt;kernel&lt;/code&gt; and &lt;code&gt;stdlib&lt;/code&gt;. These entries have to always be in there. On the other hand, &lt;code&gt;crypto&lt;/code&gt; is optional to most apps, but we need it because we use it to seed our pseudo-random number generator in &lt;code&gt;start/0&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;env&lt;/code&gt; tuple can contain &lt;a href="http://erlang.org/doc/man/app.html"&gt;configuration values&lt;/a&gt;, but we need none right now.&lt;/p&gt; &lt;p&gt;The other option considered here is &lt;code&gt;mod&lt;/code&gt;. If your library requires no process to be started and you’re just shipping code around, you’re done. In our case however, we’re starting a process (or we want to), and therefore we specify an application module named &lt;code&gt;muumuu_app&lt;/code&gt;. This module is also in &lt;code&gt;src/&lt;/code&gt;:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="erlang"&gt;&lt;span&gt;-&lt;/span&gt;&lt;span&gt;module&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;muumuu_app&lt;/span&gt;&lt;span&gt;).&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;behaviour&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;application&lt;/span&gt;&lt;span&gt;).&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;export&lt;/span&gt;&lt;span&gt;([&lt;/span&gt;&lt;span&gt;start&lt;/span&gt;&lt;span&gt;/&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;stop&lt;/span&gt;&lt;span&gt;/&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;]).&lt;/span&gt; &lt;span&gt;start&lt;/span&gt;&lt;span&gt;(_&lt;/span&gt;&lt;span&gt;Type&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;_&lt;/span&gt;&lt;span&gt;Args&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;muumuu_sup&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;start_link&lt;/span&gt;&lt;span&gt;().&lt;/span&gt; &lt;span&gt;stop&lt;/span&gt;&lt;span&gt;(_)&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;ok&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;That module is basically giving callbacks to the Erlang VM. See it a bit as the &lt;code&gt;main&lt;/code&gt; function in C, except you also have to provide a &lt;code&gt;stop&lt;/code&gt; function that will clean up once the process exits. In this case we need nothing.&lt;/p&gt; &lt;p&gt;What’s the &lt;code&gt;muumuu_sup&lt;/code&gt; module? That’s the final step to be glued in OTP. OTP has a concept called &lt;a href="http://learnyousomeerlang.com/supervisors"&gt;&lt;code&gt;supervisors&lt;/code&gt;&lt;/a&gt;. Supervisors are in charge of checking OTP-compliant processes, to start them, stop them, and &lt;a href="http://ferd.ca/it-s-about-the-guarantees.html"&gt;provide guarantees regarding their state&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Unfortunately, our process isn’t OTP-compliant. The guys at Ericsson have long ago hit that problem and developed a &lt;a href="http://www.erlang.org/doc/man/supervisor_bridge.html"&gt;supervisor bridge&lt;/a&gt;, which basically acts as a wrapper. This is what we could use if I were not the kind of person to want my OTP processes done correctly everywhere.&lt;/p&gt; &lt;p&gt;For the time being, I’ll stick with a regular supervisor and will rewrite the FSM right after:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="erlang"&gt;&lt;span&gt;-&lt;/span&gt;&lt;span&gt;module&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;muumuu_sup&lt;/span&gt;&lt;span&gt;).&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;behaviour&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;supervisor&lt;/span&gt;&lt;span&gt;).&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;export&lt;/span&gt;&lt;span&gt;([&lt;/span&gt;&lt;span&gt;start_link&lt;/span&gt;&lt;span&gt;/&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;]).&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;export&lt;/span&gt;&lt;span&gt;([&lt;/span&gt;&lt;span&gt;init&lt;/span&gt;&lt;span&gt;/&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;]).&lt;/span&gt; &lt;span&gt;start_link&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;supervisor&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;start_link&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;?&lt;/span&gt;&lt;span&gt;MODULE&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[]).&lt;/span&gt; &lt;span&gt;init&lt;/span&gt;&lt;span&gt;([])&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; {&lt;/span&gt;&lt;span&gt;ok&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;{{&lt;/span&gt;&lt;span&gt;one_for_one&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;5&lt;/span&gt;&lt;span&gt;},&lt;/span&gt; &lt;span&gt;[{&lt;/span&gt;&lt;span&gt;console&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;muumuu_fsm&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;start_link&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[]},&lt;/span&gt; &lt;span&gt;permanent&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;5000&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;worker&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;muumuu_fsm&lt;/span&gt;&lt;span&gt;]}]}}.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;This will start &lt;code&gt;muumuu_fsm&lt;/code&gt; as a permanent worker that can die once every 5 seconds before the entire system crashes. I don’t have a good way to pick frequencies, but 1 in 5 seconds sounds like something reasonable for someone to mash keys in ways bad enough it causes errors.&lt;/p&gt; &lt;p&gt;So then comes the rewrite from prototype to &lt;a href="http://learnyousomeerlang.com/finite-state-machines"&gt;&lt;code&gt;gen_fsm&lt;/code&gt;&lt;/a&gt;. This is stuff that has been covered in multiple tutorials before, so I’m going to skip most of it. You can instead look at books and docs for &lt;code&gt;gen_fsm&lt;/code&gt;, follow along the final module, &lt;a href="https://github.com/ferd/howistart-erlang1-code/blob/master/library/src/muumuu_fsm.erl"&gt;muumuu_fsm.erl&lt;/a&gt;, and see for yourself.&lt;/p&gt; &lt;p&gt;The biggest changes there, outside of providing the &lt;code&gt;gen_fsm&lt;/code&gt; callbacks required by the OTP behavior, are related to the general information flow. Rather than being really direct sequences of functions doing whatever they want, the OTP version of the module becomes a lot more declarative.&lt;/p&gt; &lt;p&gt;We no longer enter a state function, ask a question, and wait for the response within the same context. The logic has moved so that an event in a state (say &lt;code&gt;first_gas_vent&lt;/code&gt;) causes a question to be asked before transitioning to the state that will handle that response.&lt;/p&gt; &lt;p&gt;This doesn’t make the code particulalry harder to read, just different:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="erlang"&gt;&lt;span&gt;init&lt;/span&gt;&lt;span&gt;([])&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; &amp;lt;&amp;lt;A:32, B:32, C:32&amp;gt;&amp;gt; = &lt;/span&gt;&lt;span&gt;crypto&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;rand_bytes&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;random&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;seed&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;A&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;B&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;C&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;ok&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;wait_any_key&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;prompt&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;wait_any_key&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;#state&lt;/span&gt;&lt;span&gt;{})}.&lt;/span&gt; &lt;span&gt;%% [...] &lt;/span&gt;&lt;span&gt;&lt;/span&gt; &lt;span&gt;wait_any_key&lt;/span&gt;&lt;span&gt;(_,&lt;/span&gt; &lt;span&gt;State&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; {&lt;/span&gt;&lt;span&gt;next_state&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;first_core_check&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;prompt&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;first_core_check&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;State&lt;/span&gt;&lt;span&gt;)}.&lt;/span&gt; &lt;span&gt;first_core_check&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;no&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;State&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; {&lt;/span&gt;&lt;span&gt;next_state&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;first_gas_vent&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;prompt&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;first_gas_vent&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;State&lt;/span&gt;&lt;span&gt;)};&lt;/span&gt; &lt;span&gt;first_core_check&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;yes&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;State&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;show_core_temperature&lt;/span&gt;&lt;span&gt;(),&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;next_state&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;first_gas_vent&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;prompt&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;first_gas_vent&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;State&lt;/span&gt;&lt;span&gt;)}.&lt;/span&gt; &lt;span&gt;first_gas_vent&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;no&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;State&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; S&lt;/span&gt;&lt;span&gt;tateName&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;venting_prevents_explosions&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;next_state&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;StateName&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;prompt&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;StateName&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;State&lt;/span&gt;&lt;span&gt;)};&lt;/span&gt; &lt;span&gt;first_gas_vent&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;yes&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;State&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;show_blow_crops_away&lt;/span&gt;&lt;span&gt;(),&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;next_state&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;wait_for_command&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;prompt&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;wait_for_command&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;State&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;10000&lt;/span&gt;&lt;span&gt;}.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;This form, along with the experience gained in the prototype, allows for simpler state management via the &lt;code&gt;State&lt;/code&gt; variable, which allows us to be more transparent about our usage of venting limits, for example. We also instantly benefit from everything OTP gives us in terms of transparency: tracing, logging, statistics, and so on (see &lt;a href="http://www.erlang.org/doc/man/sys.html"&gt;the &lt;code&gt;sys&lt;/code&gt; module&lt;/a&gt;)&lt;/p&gt; &lt;p&gt;With that code in place, we can compile and run the entire application:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;λ → rebar3 compile ===&amp;gt; Verifying dependencies... ===&amp;gt; Compiling muumuu &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;With this compiled we can run it, with a funky command:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;λ → erl -env ERL_LIBS _build/default/lib -eval 'application:ensure_all_started(muumuu).' -noshell To Start, Press Any Key. &amp;gt; any Check core temperature? (Y/N) &amp;gt; y Core temperature normal. Vent radioactive gas? (Y/N) &amp;gt; y *Gas blows away corn crop* &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;That’s kind of an ugly command to run the app, but the app is now something other people can use to pull it within their own systems.&lt;/p&gt; &lt;p&gt;In order to run it ourselves and actually ship it to customers, we will need to build a release. In any other case, though, you may want to &lt;a href="http://www.rebar3.org/v3.0/docs/publishing-packages"&gt;publish your library as a Hex package&lt;/a&gt; with the help of the &lt;a href="http://www.rebar3.org/v3.0/docs/using-available-plugins#hex-package-management"&gt;proper rebar3 plugin&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;img alt="" src="https://howistart.org/posts/erlang/1/images/y-y-y.gif"&gt;&lt;/p&gt; &lt;h2 id="releases"&gt;Releases&lt;/h2&gt; &lt;p&gt;The directory structure we’ve been using was for an application and turns out looking like:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;src/ ebin/ &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;At the simplest level. A release is basically a group of applications put together. For this reason, we’ll change the directory structure a bit:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;apps/ - muumuu/ - src/ - ebin/ rebar.config &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;All applications you need will go into &lt;code&gt;apps/&lt;/code&gt;. Here I just moved &lt;code&gt;src/&lt;/code&gt; to &lt;code&gt;apps/muumuu/&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;The rebar.config file looks like this:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="erlang"&gt;&lt;span&gt;{&lt;/span&gt;&lt;span&gt;relx&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;release&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;muumuu&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;"1.0.0"&lt;/span&gt;&lt;span&gt;},&lt;/span&gt; &lt;span&gt;%% list of apps to include &lt;/span&gt;&lt;span&gt;&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;muumuu&lt;/span&gt;&lt;span&gt;]},&lt;/span&gt; &lt;span&gt;%% Don't ship an Erlang VM by default &lt;/span&gt;&lt;span&gt;&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;include_erts&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;false&lt;/span&gt;&lt;span&gt;}&lt;/span&gt; &lt;span&gt;]}.&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;profiles&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt; &lt;span&gt;%% called as `rebar3 as prod &amp;lt;command&amp;gt;` &lt;/span&gt;&lt;span&gt;&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;prod&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;relx&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt; &lt;span&gt;% override relx specifically &lt;/span&gt;&lt;span&gt;&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;include_src&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;false&lt;/span&gt;&lt;span&gt;},&lt;/span&gt; &lt;span&gt;% don't include source code &lt;/span&gt;&lt;span&gt;&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;include_erts&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;true&lt;/span&gt;&lt;span&gt;}&lt;/span&gt; &lt;span&gt;% include the VM in the release &lt;/span&gt;&lt;span&gt;&lt;/span&gt; &lt;span&gt;]}&lt;/span&gt; &lt;span&gt;]}&lt;/span&gt; &lt;span&gt;]}.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;This basically just tells rebar3 what the release-building tool it includes (relx) should do to give us our release. The release will only include our custom Erlang code, and use the currently installed Erlang VM to run things rather than installing a fully self-contianed program. Then the magic happens:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;λ → rebar3 release ===&amp;gt; Verifying dependencies... ===&amp;gt; Compiling muumuu ===&amp;gt; Starting relx build process ... ===&amp;gt; Resolving OTP Applications from directories: /Users/ferd/code/self/howistart-erlang1-code/release/_build/default/lib /Users/ferd/code/self/howistart-erlang1-code/release/apps /Users/ferd/.kerl/builds/17.4/release_17.4/lib ===&amp;gt; Resolved muumuu-1.0.0 ===&amp;gt; release successfully created! &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;And a release is born! To run it:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;λ → ./_build/default/rel/muumuu/bin/muumuu -noshell To Start, Press Any Key. &amp;gt; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Pretty cool. This can now be shipped and distributed to people.&lt;/p&gt; &lt;p&gt;I want to make the release a bit fancier though. As you’ve just seen, we still need to put the &lt;code&gt;-noshell&lt;/code&gt; by hand, which is totally unacceptable.&lt;/p&gt; &lt;p&gt;To fix this, add a &lt;code&gt;config/&lt;/code&gt; repository, and I open the &lt;code&gt;vm.args&lt;/code&gt; file in vim in there:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="bash"&gt;&lt;span&gt;# only show the programmed prompt&lt;/span&gt; -noshell &lt;span&gt;# for remote access &amp;amp; debugging&lt;/span&gt; -name &lt;a data-cfemail="dcb2a9bfa9b0bdae83acb0bdb2a89cedeeebf2ecf2ecf2ed" href="https://howistart.org/cdn-cgi/l/email-protection"&gt;[email&amp;nbsp;protected]&lt;/a&gt; &lt;span&gt;# not needed&lt;/span&gt; -smp disable +A &lt;span&gt;1&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;Arguments in there I merged into one. A good practice for any Erlang system is to give it a name, which will let you connect to it while it’s running. In this case I could go in and debug the console as the user is maintaining the powerplant.&lt;/p&gt; &lt;p&gt;The last arguments (&lt;code&gt;-smp disable +A 1&lt;/code&gt;) are basically optimizations for this very app: they remove Erlang parallelism (I’m running a single active process for the thing, so why bother?) and removes the number of asynchronous threads for IO to a single one (for the same reason – one active process, why bother?).&lt;/p&gt; &lt;p&gt;In more serious apps, tweaking your VM options can be worthwhile, but outside of this text’s scope.&lt;/p&gt; &lt;p&gt;The rebar3 config file needs an update too:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="erlang"&gt;&lt;span&gt;{&lt;/span&gt;&lt;span&gt;relx&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;release&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;muumuu&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;"1.0.0"&lt;/span&gt;&lt;span&gt;},&lt;/span&gt; &lt;span&gt;%% list of apps to include &lt;/span&gt;&lt;span&gt;&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;muumuu&lt;/span&gt;&lt;span&gt;]},&lt;/span&gt; &lt;span&gt;%% Don't ship an Erlang VM by default &lt;/span&gt;&lt;span&gt;&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;include_erts&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;false&lt;/span&gt;&lt;span&gt;},&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;vm_args&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;"./config/vm.args"&lt;/span&gt;&lt;span&gt;}&lt;/span&gt; &lt;span&gt;]}.&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;profiles&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt; &lt;span&gt;%% called as `rebar3 as prod &amp;lt;command&amp;gt;` &lt;/span&gt;&lt;span&gt;&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;prod&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;relx&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt; &lt;span&gt;% override relx specifically &lt;/span&gt;&lt;span&gt;&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;include_src&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;false&lt;/span&gt;&lt;span&gt;},&lt;/span&gt; &lt;span&gt;% don't include source code &lt;/span&gt;&lt;span&gt;&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;include_erts&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;true&lt;/span&gt;&lt;span&gt;}&lt;/span&gt; &lt;span&gt;% include the VM in the release &lt;/span&gt;&lt;span&gt;&lt;/span&gt; &lt;span&gt;]}&lt;/span&gt; &lt;span&gt;]}&lt;/span&gt; &lt;span&gt;]}.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;The last line above the profiles is the new one. Compile again and the arguments should implicitly be passed to the node:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;λ → rebar3 release ===&amp;gt; Verifying dependencies... ===&amp;gt; Compiling muumuu ===&amp;gt; Starting relx build process ... ===&amp;gt; Resolving OTP Applications from directories: /Users/ferd/code/self/howistart-erlang1-code/release/_build/default/lib /Users/ferd/code/self/howistart-erlang1-code/release/apps /Users/ferd/.kerl/builds/17.4/release_17.4/lib /Users/ferd/code/self/howistart-erlang1-code/release/_build/default/rel ===&amp;gt; Resolved muumuu-1.0.0 ===&amp;gt; release successfully created! λ → ./_build/default/rel/muumuu/bin/muumuu To Start, Press Any Key. &amp;gt; &amp;lt;Tab&amp;gt; Check core temperature? (Y/N) &amp;gt; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Cool, everything works. I now have a binary executable I can link to from anywhere in the system and will require no magical arguments to work!&lt;/p&gt; &lt;h2 id="tests"&gt;Tests&lt;/h2&gt; &lt;p&gt;As much as I like to try and get testing done ahead of time – it’s the only time it’s not super terrible and crappy – I often end up adding it after the fact when I know I’ll have to maintain it.&lt;/p&gt; &lt;p&gt;For this, each app should have its tests, so I’ll have to add a &lt;code&gt;test/&lt;/code&gt; directory in &lt;code&gt;apps/muumuu/&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;My tool of choice is &lt;a href="http://learnyousomeerlang.com/common-test-for-uncommon-tests"&gt;Common Test&lt;/a&gt;, which while it is kind of full of annoying overheads for unit testing and is mostly useless for shell output (you gotta deal with HTML files), it scales fairly well for integration and system tests.&lt;/p&gt; &lt;p&gt;The test suite in there is going to be &lt;code&gt;muumuu_SUITE.erl&lt;/code&gt;:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="erlang"&gt;&lt;span&gt;-&lt;/span&gt;&lt;span&gt;module&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;muumuu_SUITE&lt;/span&gt;&lt;span&gt;).&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;include_lib&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"common_test/include/ct.hrl"&lt;/span&gt;&lt;span&gt;).&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;compile&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;export_all&lt;/span&gt;&lt;span&gt;).&lt;/span&gt; &lt;span&gt;%% Copy/pasting from the suite &lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;-&lt;/span&gt;&lt;span&gt;record&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;state&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;no_vent_count&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;pid&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;yes&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;no&lt;/span&gt;&lt;span&gt;}).&lt;/span&gt; &lt;span&gt;all&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; [&lt;/span&gt;&lt;span&gt;demo_session&lt;/span&gt;&lt;span&gt;].&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;So at first I’m just gonna make one run-through test. Testing &lt;code&gt;muumuu&lt;/code&gt; is going to be hard because it’s purely a side-effectful application.&lt;/p&gt; &lt;p&gt;Before going further, I’ll say that the trick to getting this working is to use &lt;code&gt;meck&lt;/code&gt;, which is pretty much the best code-mocking application around.&lt;/p&gt; &lt;p&gt;Adding &lt;code&gt;meck&lt;/code&gt; can be done by declaring &lt;code&gt;rebar.config&lt;/code&gt; dependencies:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="erlang"&gt;&lt;span&gt;{&lt;/span&gt;&lt;span&gt;profiles&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;test&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;deps&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;meck&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;"0.8.2"&lt;/span&gt;&lt;span&gt;}&lt;/span&gt; &lt;span&gt;]}&lt;/span&gt; &lt;span&gt;]},&lt;/span&gt; &lt;span&gt;%% called as `rebar3 as prod &amp;lt;command&amp;gt;` &lt;/span&gt;&lt;span&gt;&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;prod&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt; &lt;span&gt;...&lt;/span&gt; &lt;span&gt;]}&lt;/span&gt; &lt;span&gt;]}&lt;/span&gt; &lt;span&gt;]}.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;Note that rather than having a top-level &lt;code&gt;deps&lt;/code&gt; entry as we usually would, we define this one to be into the &lt;code&gt;test&lt;/code&gt; profile. This will allow the dependency to only be fetched and used when running tests, and to avoid bundling it when shipping the application.&lt;/p&gt; &lt;p&gt;Rebar3 pulls stuff from a package repository for this one (&lt;a href="http://www.rebar3.org/v3.0/docs/dependencies"&gt;github dependencies&lt;/a&gt; are also an option). Rebar3 will add it to a lock file when it fetches and compiles it later.&lt;/p&gt; &lt;p&gt;Now back to &lt;code&gt;muumuu_SUITE&lt;/code&gt;. Time to set up the state:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="erlang"&gt;&lt;span&gt;init_per_testcase&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;demo_session&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Config&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;mock_io&lt;/span&gt;&lt;span&gt;(),&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;ok&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Pid&lt;/span&gt;&lt;span&gt;}&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;muumuu_fsm&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;start_link&lt;/span&gt;&lt;span&gt;(),&lt;/span&gt; &lt;span&gt;[{&lt;/span&gt;&lt;span&gt;pid&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Pid&lt;/span&gt;&lt;span&gt;}&lt;/span&gt; &lt;span&gt;|&lt;/span&gt; &lt;span&gt;Config&lt;/span&gt;&lt;span&gt;].&lt;/span&gt; &lt;span&gt;end_per_testcase&lt;/span&gt;&lt;span&gt;(_,&lt;/span&gt; &lt;span&gt;Config&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;meck&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;unload&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;io&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;Pid&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;?&lt;/span&gt;&lt;span&gt;config&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;pid&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Config&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;unlink&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Pid&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;exit&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Pid&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;shutdown&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;wait_for_death&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Pid&lt;/span&gt;&lt;span&gt;).&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;Mocking the &lt;code&gt;io&lt;/code&gt; system is a fun way to basically take it and make it return messages we can look at. That all takes place in &lt;code&gt;mock_io()&lt;/code&gt;, and after that’s in place, we start a &lt;code&gt;muumuu&lt;/code&gt; instance directly (no application needed):&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="erlang"&gt;&lt;span&gt;mock_io&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; %% F&lt;/span&gt;&lt;span&gt;or&lt;/span&gt; &lt;span&gt;this&lt;/span&gt; &lt;span&gt;one&lt;/span&gt; &lt;span&gt;we&lt;/span&gt; &lt;span&gt;mock&lt;/span&gt; &lt;span&gt;the&lt;/span&gt; &lt;span&gt;IO&lt;/span&gt; &lt;span&gt;system&lt;/span&gt; &lt;span&gt;so&lt;/span&gt; &lt;span&gt;that&lt;/span&gt; &lt;span&gt;instead&lt;/span&gt; &lt;span&gt;of&lt;/span&gt; &lt;span&gt;%% printing messages and getting input to and from the user, &lt;/span&gt;&lt;span&gt;&lt;/span&gt; &lt;span&gt;%% we instead have a message-passing interface that will &lt;/span&gt;&lt;span&gt;&lt;/span&gt; &lt;span&gt;%% be inspectable. &lt;/span&gt;&lt;span&gt;&lt;/span&gt; &lt;span&gt;%% &lt;/span&gt;&lt;span&gt;&lt;/span&gt; &lt;span&gt;%% Note that because the `io` module is pre-compiled by the &lt;/span&gt;&lt;span&gt;&lt;/span&gt; &lt;span&gt;%% VM, we have to 'unstick' it first, and be careful to keep &lt;/span&gt;&lt;span&gt;&lt;/span&gt; &lt;span&gt;%% it mocked as little as possible. &lt;/span&gt;&lt;span&gt;&lt;/span&gt; &lt;span&gt;Parent&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;self&lt;/span&gt;&lt;span&gt;(),&lt;/span&gt; &lt;span&gt;code&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;unstick_dir&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;filename&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;dirname&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;code&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;where_is_file&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"io.beam"&lt;/span&gt;&lt;span&gt;))),&lt;/span&gt; &lt;span&gt;meck&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;io&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;passthrough&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;no_link&lt;/span&gt;&lt;span&gt;]),&lt;/span&gt; &lt;span&gt;meck&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;expect&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;io&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;format&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;fun&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Str&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; P&lt;/span&gt;&lt;span&gt;arent&lt;/span&gt; &lt;span&gt;!&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;out&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Str&lt;/span&gt;&lt;span&gt;},&lt;/span&gt; &lt;span&gt;ok&lt;/span&gt; &lt;span&gt;end&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;meck&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;expect&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;io&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;format&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;fun&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Str&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Args&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; P&lt;/span&gt;&lt;span&gt;arent&lt;/span&gt; &lt;span&gt;!&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;out&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;io_lib&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;format&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Str&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;Args&lt;/span&gt;&lt;span&gt;)},&lt;/span&gt; &lt;span&gt;ok&lt;/span&gt; &lt;span&gt;end&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;meck&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;expect&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;io&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;get_line&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;fun&lt;/span&gt;&lt;span&gt;(_&lt;/span&gt;&lt;span&gt;Prompt&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; P&lt;/span&gt;&lt;span&gt;arent&lt;/span&gt; &lt;span&gt;!&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;in&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;self&lt;/span&gt;&lt;span&gt;()},&lt;/span&gt; &lt;span&gt;receive&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;Parent&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;In&lt;/span&gt;&lt;span&gt;}&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; I&lt;/span&gt;&lt;span&gt;n&lt;/span&gt; &lt;span&gt;end&lt;/span&gt; &lt;span&gt;end&lt;/span&gt;&lt;span&gt;).&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;Ugly. The first step is unstickying the directory for Erlang code. Most modules don’t require that, only those in Erlang’s standard library. Unstickying allows to load new versions of code at run time, which &lt;code&gt;meck&lt;/code&gt; dynamically does.&lt;/p&gt; &lt;p&gt;Here what I’m doing is mocking the functions &lt;code&gt;io:format/1&lt;/code&gt;, &lt;code&gt;io:format/2&lt;/code&gt; and &lt;code&gt;io:get_line/1&lt;/code&gt; to send messages of the form &lt;code&gt;{in, Msg}&lt;/code&gt; and &lt;code&gt;{out, Msg}&lt;/code&gt; from input and output, respectively. &lt;code&gt;meck:unload(io)&lt;/code&gt; will undo that.&lt;/p&gt; &lt;p&gt;We also had the &lt;code&gt;wait_for_death/1&lt;/code&gt; call. I’m using these &lt;em&gt;everywhere&lt;/em&gt; in tests. Timers are the enemy of good concurrent testing, and if you rely on a &lt;code&gt;timer:sleep(1000)&lt;/code&gt; of some sort to make sure everything is clean, you’re doing it wrong.&lt;/p&gt; &lt;p&gt;Here the function polls to return ASAP, with a tiny sleep to not heat up your room too much via the CPU:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="erlang"&gt;&lt;span&gt;wait_for_death&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Pid&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;case&lt;/span&gt; &lt;span&gt;is_process_alive&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Pid&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;of&lt;/span&gt; &lt;span&gt;true&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;timer&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;sleep&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;wait_for_death&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Pid&lt;/span&gt;&lt;span&gt;);&lt;/span&gt; &lt;span&gt;false&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;ok&lt;/span&gt; &lt;span&gt;end&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;With this done, I can start planning more for the test. This here is something I always want to write a library for, and maybe some day I will, but right now I re-do that crap by hand every time:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="erlang"&gt;&lt;span&gt;%%%%%%%%%%%%%%%%%% &lt;/span&gt;&lt;span&gt;%%% TEST CASES %%% &lt;/span&gt;&lt;span&gt;%%%%%%%%%%%%%%%%%% &lt;/span&gt;&lt;span&gt;&lt;/span&gt; &lt;span&gt;%% Pressing a given key through the message-passing interface &lt;/span&gt;&lt;span&gt;%% will yield expected output. There should be a prompt waiting &lt;/span&gt;&lt;span&gt;%% for a key. &lt;/span&gt;&lt;span&gt;%% All states can be cycled through using only Y/N answers. &lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;demo_session&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Config&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; P&lt;/span&gt;&lt;span&gt;id&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;?&lt;/span&gt;&lt;span&gt;config&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;pid&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Config&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;out&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"press.*any.*key.*&amp;gt;"&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;in&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"&amp;lt;tab&amp;gt;"&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;% the characters shouldn't matter &lt;/span&gt;&lt;span&gt;&lt;/span&gt; &lt;span&gt;out&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"check.*core.*temp.*&amp;gt;"&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;in&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"Y"&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;out&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"temperature.*normal"&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;out&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"vent.*radioactive.*gas.*&amp;gt;"&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;in&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"no"&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;out&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"venting.*prevents.*explosion.*&amp;gt;"&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;in&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"yES"&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;out&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"gas.*blows.*crop.*"&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;gen_fsm&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;send_event&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Pid&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;timeout&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;% force a timeout faster &lt;/span&gt;&lt;span&gt;&lt;/span&gt; &lt;span&gt;out&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;".*Y/N.*&amp;gt;"&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;% some question &lt;/span&gt;&lt;span&gt;&lt;/span&gt; &lt;span&gt;in&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"No"&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;% who cares &lt;/span&gt;&lt;span&gt;&lt;/span&gt; &lt;span&gt;in&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"vent gAs"&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;% force a command &lt;/span&gt;&lt;span&gt;&lt;/span&gt; &lt;span&gt;out&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"gas.*blows.*crop.*"&lt;/span&gt;&lt;span&gt;).&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;I basically just write the test the way I want it to look like. I will start expecting messages that will match the regex &lt;code&gt;"press.*any.*key.*&amp;gt;"&lt;/code&gt; being output, after which I’ll insert &lt;code&gt;&amp;lt;tab&amp;gt;&lt;/code&gt;. Rinse and repeat.&lt;/p&gt; &lt;p&gt;Here, my desire is pretty much to turn the interactions I’d write in the shell into a bunch of function calls and matches.&lt;/p&gt; &lt;p&gt;That’s why I planned having a message-passing interface. I can now write functions to wrap that functionality:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="erlang"&gt;&lt;span&gt;%%%%%%%%%%%%%%% &lt;/span&gt;&lt;span&gt;%%% HELPERS %%% &lt;/span&gt;&lt;span&gt;%%%%%%%%%%%%%%% &lt;/span&gt;&lt;span&gt;&lt;/span&gt; &lt;span&gt;in&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Input&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;receive&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;in&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Pid&lt;/span&gt;&lt;span&gt;}&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; P&lt;/span&gt;&lt;span&gt;id&lt;/span&gt; &lt;span&gt;!&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;self&lt;/span&gt;&lt;span&gt;(),&lt;/span&gt; &lt;span&gt;Input&lt;/span&gt;&lt;span&gt;}&lt;/span&gt; &lt;span&gt;after&lt;/span&gt; &lt;span&gt;1000&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;ct&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;pal&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"MBOX: &lt;/span&gt;&lt;span&gt;~p&lt;/span&gt;&lt;span&gt;"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;process_info&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;self&lt;/span&gt;&lt;span&gt;(),&lt;/span&gt; &lt;span&gt;messages&lt;/span&gt;&lt;span&gt;)]),&lt;/span&gt; &lt;span&gt;error&lt;/span&gt;&lt;span&gt;({&lt;/span&gt;&lt;span&gt;too_long&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;in&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Input&lt;/span&gt;&lt;span&gt;}})&lt;/span&gt; &lt;span&gt;end&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;If we look back into the mocked function, the mocked function sends us &lt;code&gt;{in, ProcessThatWaitsForInput}&lt;/code&gt;. We take the &lt;code&gt;Input&lt;/code&gt; argument, and send it back to the mocked function (which runs in its own process).&lt;/p&gt; &lt;p&gt;If we never receive the &lt;code&gt;in&lt;/code&gt; message, we crash, but printing the debugging information. Interestingly here the function I use is &lt;code&gt;ct:pal&lt;/code&gt;. It works exactly like &lt;code&gt;io:format&lt;/code&gt;, except:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;It outputs to both the shell and HTML logs for Common Test&lt;/li&gt; &lt;li&gt;It’s not gonna be used in production systems and it’s surely never going to be mocked (unlike &lt;code&gt;io&lt;/code&gt;).&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;The &lt;code&gt;out/1&lt;/code&gt; helper is slightly more complex:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="erlang"&gt;&lt;span&gt;%% fuzzily match the input string, waiting 1s at most &lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;out&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Expected&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;receive&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;out&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Prompt&lt;/span&gt;&lt;span&gt;}&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;ct&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;pal&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"Expected: &lt;/span&gt;&lt;span&gt;~p~n&lt;/span&gt;&lt;span&gt;Prompt: &lt;/span&gt;&lt;span&gt;~p&lt;/span&gt;&lt;span&gt;"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;Expected&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Prompt&lt;/span&gt;&lt;span&gt;]),&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;match&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;_}&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;re&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;run&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Prompt&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Expected&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;dotall&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;caseless&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;global&lt;/span&gt;&lt;span&gt;])&lt;/span&gt; &lt;span&gt;after&lt;/span&gt; &lt;span&gt;1000&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;&amp;gt; &lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;ct&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;pal&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"MBOX: &lt;/span&gt;&lt;span&gt;~p&lt;/span&gt;&lt;span&gt;"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;process_info&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;self&lt;/span&gt;&lt;span&gt;(),&lt;/span&gt; &lt;span&gt;messages&lt;/span&gt;&lt;span&gt;)]),&lt;/span&gt; &lt;span&gt;error&lt;/span&gt;&lt;span&gt;({&lt;/span&gt;&lt;span&gt;too_long&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;out&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Expected&lt;/span&gt;&lt;span&gt;}})&lt;/span&gt; &lt;span&gt;end&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;That one makes an assertion on a regular expression with &lt;code&gt;re:run/3&lt;/code&gt;, and the rest is similar to what we did in &lt;code&gt;in/1&lt;/code&gt;. We receive the output, match it, and that’s it.&lt;/p&gt; &lt;p&gt;And there we go, we can run the tests:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;λ → rebar3 ct → rebar3 ct ===&amp;gt; Verifying dependencies... ===&amp;gt; Fetching meck ({pkg,&amp;lt;&amp;lt;"meck"&amp;gt;&amp;gt;,&amp;lt;&amp;lt;"0.8.2"&amp;gt;&amp;gt;}) ===&amp;gt; Compiling meck ===&amp;gt; Compiling muumuu ===&amp;gt; Running Common Test suites... &amp;lt;test output omitted&amp;gt; All 1 tests passed. &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;After this, I check in the rebar lock files into version control, and I go do something else because I’m pretty much done. You can see all the &lt;a href="https://github.com/ferd/howistart-erlang1-code"&gt;code here&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;img alt="" src="https://howistart.org/posts/erlang/1/images/outdoors.gif"&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://howistart.org/posts/erlang/1/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:29:55 UT
      </pubDate>
      <guid>
        https://howistart.org/posts/erlang/1/
      </guid>
    </item>
    <item>
      <title>
        Some things that might help you make better software | David R. MacIver
      </title>
      <link>
        https://www.drmaciver.com/2016/10/some-things-that-might-help-you-write-better-software/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt; &lt;p&gt;&lt;a href="https://www.drmaciver.com/2016/10/static-typing-will-not-save-us-from-broken-software/"&gt;I’ve argued before&lt;/a&gt;&amp;nbsp;that most software is broken because of economic reasons. Software which is broken because there is no incentive&amp;nbsp;to ship good software is going to stay broken until we manage to change those incentives.&amp;nbsp;Without that &amp;nbsp;there will be no budget for quality, and nothing you can do is going to fix it.&lt;/p&gt; &lt;p&gt;But suppose you’re in the slightly happier place where you&amp;nbsp;&lt;em&gt;do&lt;/em&gt; have budget for quality? What then? What can you do to make sure you’re actually spending that budget effectively and getting the best software you could be getting out of it?&lt;/p&gt; &lt;p&gt;I don’t have an easy answer to that, and I suspect none exists, but I’ve been doing this software thing for&amp;nbsp;long enough now that I’ve picked up some things&amp;nbsp;that seem to help quality without hurting (and ideally helping) productivity. I thought it would be worth writing them down.&lt;/p&gt; &lt;p&gt;Many of them will be obvious or uncontroversial, but if you’re already doing all of them then your team is probably doing very well.&lt;/p&gt; &lt;p&gt;This is all based somewhat on anecdote and conjecture, and it’s all coloured by my personal focuses and biases, so some of it is bound to be wrong. However I’m pretty sure it’s more right than wrong and that the net effect would be strongly positive.&lt;/p&gt; &lt;p&gt;Without further ado, here is my advice.&lt;/p&gt; &lt;h3&gt;Attitude&lt;/h3&gt; &lt;p&gt;If you do not care about developing quality software you will not get quality software no matter what your tools and processes are designed to give you.&lt;/p&gt; &lt;p&gt;This isn’t just about your developers either. If you do not reward the behaviour that is required to produce quality software, you will not get quality software. &lt;a href="http://yosefk.com/blog/people-can-read-their-managers-mind.html"&gt;People can read their managers’ minds&lt;/a&gt;, and if you&amp;nbsp;&lt;em&gt;say&lt;/em&gt; you want quality software but reward people for pushing out barely functioning&amp;nbsp;rubbish, people are smart enough to figure out you don’t really mean that.&lt;/p&gt; &lt;p&gt;Estimated cost: Impossible to buy, but hopefully if you’re reading this article you’re already there. If you’re embedded in a larger context that isn’t, try creating little islands of good behaviour and see if you can bring other people around to your way of thinking.&lt;/p&gt; &lt;p&gt;Estimated benefit: On it’s own, only low to moderate – intent doesn’t do much without the ability to act – but it is the necessary precursor to everything else.&lt;/p&gt; &lt;p&gt;Controversy level: Probably most people agree with this, although equally it doesn’t feel like most people implement this. I imagine there are some people who think they can fix this problem if they just find the right process. Maybe they’re right, but I’ve never seen something even approaching such a process.&lt;/p&gt; &lt;h3&gt;Automated Testing&lt;/h3&gt; &lt;p&gt;Obviously &lt;a href="https://www.drmaciver.com/2015/04/some-empirically-derived-testing-principles/"&gt;I have quite a few thoughts about automated testing&lt;/a&gt;, so this section gets a lot of sub headings.&lt;/p&gt; &lt;h4&gt;Continuous Integration&lt;/h4&gt; &lt;p&gt;You need to be running automated tests in some sort of CI server that checks every ostensibly releasable piece of software and checks whether it passes the tests.&lt;/p&gt; &lt;p&gt;If you’re not doing this, just&amp;nbsp;stop reading this article and go set it up right now, because it’s fundamental.&amp;nbsp;Add &lt;a href="http://blog.doismellburning.co.uk/the-most-efficient-django-test/"&gt;a test that just fires up your website and requests the home page&lt;/a&gt;&amp;nbsp;(or some equivalent if you’re not writing a website). You’ve just taken the first and most important step on the road from throwing some crap over the wall and seeing if anyone on the other side complains about it landing on them to actual functional software development.&lt;/p&gt; &lt;p&gt;Estimated cost: Hopefully at worst a couple days&amp;nbsp;initial outlay to get this set up, then small to none ongoing.&lt;/p&gt; &lt;p&gt;Estimated benefit: Look, just go do this already. It will give you a significant quality and productivity boost.&lt;/p&gt; &lt;p&gt;Controversy level: It would be nice to think this was uncontroversial. It’s certainly well established best practice, but I’ve worked at companies that don’t do it (a while ago), and a friend basically had to ramrod through getting this implemented at the company they’d joined recently.&lt;/p&gt; &lt;h4&gt;Local Automated Testing&lt;/h4&gt; &lt;p&gt;You need to be able to run a specific test (and ideally the whole test suite) against your local changes.&lt;/p&gt; &lt;p&gt;It doesn’t really matter if it runs actually on your local computer, but it does matter that it runs fast. Fast feedback loops while you work are&amp;nbsp;&lt;em&gt;incredibly&lt;/em&gt; important. In many ways the length of time to run a single test against my local changes is the biggest predictor of my productivity on a project.&lt;/p&gt; &lt;p&gt;Ideally you need to&amp;nbsp;&amp;nbsp;be able to select a coherent group of tests (all tests in this file, all tests with this tag) and run just those tests. Even better, you should be able to run just the subset of whatever tests you ask to run that failed last time.&amp;nbsp;If you’re using Python, I recommend &lt;a href="http://docs.pytest.org/en/latest/"&gt;py.test&lt;/a&gt; as supporting these features. If you’re currently using unittest you can probably just start using it as an external runner without any changes to your code.&lt;/p&gt; &lt;p&gt;Estimated cost: Depends&amp;nbsp;on available tooling and project. For some projects it may be prohibitively difficult (e.g. if your project requires an entire hadoop cluster to run the code you’re working on), but for most it should be cheap to free.&lt;/p&gt; &lt;p&gt;Estimated benefit: Similarly “look, just go do this already” if you can’t run a single test locally. More specific improvements will give you a modest improvement in productivity and maybe some improvement in quality if they make you more likely to write good tests, which they probably will.&lt;/p&gt; &lt;p&gt;Controversy level: Not very. I’ve only worked at one company where running tests locally&amp;nbsp;wasn’t a supported workflow, and I fixed that, but workflows which support my slightly obsessive focus on speed of running a single test are rarely as good as I’d like them to be.&lt;/p&gt; &lt;h4&gt;Regression Testing&lt;/h4&gt; &lt;p&gt;The only specific type&amp;nbsp;of automated testing that I believe that absolutely everybody should be doing is regression testing: If you find a bug in production, write a test that detects that bug before you try to fix the bug. Ideally write two tests: One that is as general as possible, one that is as specific as possible. Call them an integration and a unit test if that’s your thing.&lt;/p&gt; &lt;p&gt;This isn’t just a quality improvement, it’s a productivity improvement. Trying to fix bugs without a reproducible example of that bug is just going to waste your time, and writing a test is the best way to get a reproducible example.&lt;/p&gt; &lt;p&gt;Estimated cost: Zero, assuming you have local testing set up. This is just what you should be doing when fixing bugs because it’s better than the other ways of fixing bugs – it will result in faster development and actually fixed bugs.&lt;/p&gt; &lt;p&gt;Estimated benefit: Depends how much time you spend fixing bugs already, but it will make that process faster and will help ensure you don’t have to repeat the process. It will probably improve quality somewhat by virtue of preventing regressions and also ensuring that buggier areas of the code are better tested.&lt;/p&gt; &lt;p&gt;Controversy level: In theory, not at all. In practice, I’ve found many to most developers need continual reminders that this is a thing you have to do.&lt;/p&gt; &lt;h4&gt;Code Coverage&lt;/h4&gt; &lt;p&gt;You should be tracking&amp;nbsp;code coverage. Code coverage is how you know code is tested. Code being tested is how you know that it is maybe not completely broken.&lt;/p&gt; &lt;p&gt;It’s OK to have untested code. A lot of code isn’t very important, or is difficult enough to test that it’s not worth the effort, or some combination of the two.&lt;/p&gt; &lt;p&gt;But if you’re not tracking&amp;nbsp;code coverage then you don’t know which parts of your code you have decided you are OK with being broken.&lt;/p&gt; &lt;p&gt;People obsess a lot about code coverage as a percentage, and that’s understandable given that’s the easiest thing to get out of it, but in many ways it’s the least important part of code coverage. Even the percentage broken down by file is more interesting that, but really&amp;nbsp;the annotated view of your code is the most important part because it tells you which parts of your system are not tested.&lt;/p&gt; &lt;p&gt;My favourite way to use code coverage is to insist on 100% code coverage for anything that is not explicitly annotated as not requiring coverage, which makes it very visible in the code if something is untested. Ideally every pragma to skip coverage would also have a comment with it explaining why, but I’m not very good about that.&lt;/p&gt; &lt;p&gt;As a transitional step to get there, I recommend using something like &lt;a href="https://pypi.python.org/pypi/diff_cover"&gt;diff-cover&lt;/a&gt;&amp;nbsp;or &lt;a href="https://coveralls.io/"&gt;coveralls&lt;/a&gt;&amp;nbsp;which let you set up a ratcheting rule in your build that prevents you from decreasing the amount of code coverage.&lt;/p&gt; &lt;p&gt;Estimated cost: If your language has good tooling for coverage, maybe&amp;nbsp;a&amp;nbsp;couple hours to set up. Long-term,&amp;nbsp;essentially free.&lt;/p&gt; &lt;p&gt;Estimated benefit: On its own, small, but it can be a large part of shifting to a culture of good testing, which will have a modest to large effect.&lt;/p&gt; &lt;p&gt;Controversy level: Surprisingly high. Of the companies I’ve worked at precisely zero have tracked code coverage (in one case there was a push for it but younger me argued against it. My opinions on testing have changed a lot over the years).&lt;/p&gt; &lt;h4&gt;Property-based Testing&lt;/h4&gt; &lt;p&gt;Property-based testing is very good at shifting the cost-benefit ratio of testing, because it somewhat&amp;nbsp;reduces the effort to write what is effectively a larger number&amp;nbsp;of tests and increases the number of defects those tests will find.&lt;/p&gt; &lt;p&gt;I won’t write too much about this here because I have &lt;a href="http://hypothesis.works/"&gt;an entire separate site about this&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Estimated cost: If you’re using a language with a good property based testing tool, about 15 minutes to install the package and write your first test. After that, free to negative. If you’re not, estimated cost to pay me &lt;a href="http://hypothesis.works/services/#ports-to-new-languages"&gt;to port Hypothesis&amp;nbsp;to a new language&lt;/a&gt;&amp;nbsp;is around £15-20k.&lt;/p&gt; &lt;p&gt;Estimated benefit: You will find a lot more bugs. Whether this results in a quality&amp;nbsp;improvement depends on whether you actually care about fixing those bugs. If you do, you’ll see a modest to large quality improvement. You should also see a small to modest productivity improvement if you’re spending a lot of time on testing already.&lt;/p&gt; &lt;p&gt;Controversy level: Not very high, but niche enough that most people haven’t formed an opinion on it. Most people think property based testing is amazing when they encounter it. Some push back on test speed and non-determinism (both of which have partial to complete workarounds in Hypothesis at least)&lt;/p&gt; &lt;h3&gt;Manual Testing&lt;/h3&gt; &lt;p&gt;At a previous job I found a bug in almost every piece of code I reviewed. I used a shocking and complicated advanced technique to do this: I fired up the application with the code change and tried out the feature.&lt;/p&gt; &lt;p&gt;Manual testing is very underrated. You don’t have to have a dedicated QA professional on your team to do it (though I suspect it helps a lot if you do), but new features should have a certain amount of exploratory manual testing done by someone who didn’t develop them – whether it’s another developer, a customer service person, whatever. This will find both actual bugs and also give you a better idea of its usability.&lt;/p&gt; &lt;p&gt;And then if they do find bugs those bugs should turn into automated regression tests.&lt;/p&gt; &lt;p&gt;Estimated cost: It involves people doing stuff on an ongoing basis, so it’s on the high side because people are expensive, but it doesn’t have to be&amp;nbsp;&lt;em&gt;that&amp;nbsp;&lt;/em&gt;high to get a significant benefit to it. You can probably do quite well with half an hour of testing of a feature that took days to develop. This may also require &lt;a href="https://alexgaynor.net/2016/jan/19/dont-have-environments/"&gt;infrastructure changes&lt;/a&gt; to make it easy to do that can have varying levels of cost and difficulty, but worst case scenario you can do it on the live system.&lt;/p&gt; &lt;p&gt;Estimated benefit: You will almost certainly get a moderate quality improvement out of doing this.&lt;/p&gt; &lt;p&gt;Controversy level: Having QA professionals seems to be entirely against the accepted best practice in startups. The rest, similar to regression testing: Doing a bit of manual testing seems to be one of those things where people say “Of course we do that” and then don’t do it.&lt;/p&gt; &lt;h3&gt;Version Control&lt;/h3&gt; &lt;p&gt;You need to be using a version control system with good branching and merging.&amp;nbsp;This is one of the few pieces of advice where my recommendation&amp;nbsp;requires making a really large change to your existing workflow.&lt;/p&gt; &lt;p&gt;I hope that it’s relatively uncontroversial&amp;nbsp;that you should be using version control (not everybody is!). Ideally you should be using&amp;nbsp;&lt;em&gt;good&lt;/em&gt;&amp;nbsp;version control.&amp;nbsp;I don’t really care if you use git, mercurial, fossil, darcs, whatever. We could get into a heated argument about which is better but it’s mostly narcissism of small differences at this point.&lt;/p&gt; &lt;p&gt;But you should probably move off SVN if you’re still on it and you should&amp;nbsp;&lt;em&gt;definitely&lt;/em&gt; move off CVS if you’re still on it. If you’re using visual source safe you have my sympathies.&lt;/p&gt; &lt;p&gt;The reason is simple: If you’re working on a team of more than one person, you need to be able to incorporate each other’s changes easily, and you need to be able to do that without trashing your own work. If you can’t, you’re going to end up wasting a lot of your time.&lt;/p&gt; &lt;p&gt;Estimated cost: Too project dependent to say. Importer tools are pretty good, but the real obstacle is always going to be the ecosystem you’ve built around the tools. At best you’re going to have a bad few weeks or months while people get used to the new system.&lt;/p&gt; &lt;p&gt;Estimated benefit: Moderate to large. Many&amp;nbsp;classes of problems will just go away and you will end up with a much more productive team who find it much easier to collaborate.&lt;/p&gt; &lt;p&gt;Controversy level: Basically uncontroversial. Not as widespread as you might imagine, but not controversial. Once git started becoming popular basically everywhere I’ve worked used it (with one exception for mercurial and one exception for Google’s interesting&amp;nbsp;perforce ish based&amp;nbsp;system).&lt;/p&gt; &lt;h3&gt;Monorepos&lt;/h3&gt; &lt;p&gt;&lt;a href="https://danluu.com/monorepo/"&gt;Use a single repository for all your code&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;It’s tempting to split your projects into lots of small repos for libraries and services, but it’s almost always a bad idea. It significantly constrains your ability to refactor across the boundary and makes coordinating changes to different parts of the code much harder in almost every way, especially with most standard&amp;nbsp;tooling.&lt;/p&gt; &lt;p&gt;If you’re already doing this, this is easy. Just don’t change.&lt;/p&gt; &lt;p&gt;If you’re not, just start by either creating or designating an existing repository as the monorepo and gradually move the contents of other repos&amp;nbsp;into it as and when convenient.&lt;/p&gt; &lt;p&gt;The only exception where you probably need to avoid this is specific projects you’re open sourcing, but even then it might be worth developing them in the monorepo with some sort of external repo.&lt;/p&gt; &lt;p&gt;This point has proved controversial, so if you’re still unconvinced &lt;a href="https://www.drmaciver.com/2016/10/why-you-should-use-a-single-repository-for-all-your-companys-projects/"&gt;I have written a longer advocacy piece on why you should use a monorepo&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Estimated costs: Too project dependent to say, but can be easily amortised over time.&lt;/p&gt; &lt;p&gt;Estimated benefits: Every time you do something that would have required touching two repos at once, your life will be slightly easier because you are not paying coordination costs. Depends on how frequent that is, but experience suggests it’s at least a modest improvement.&lt;/p&gt; &lt;p&gt;Controversy level: High. This piece of advice is extremely&amp;nbsp;love/hate. I think most of the people who love it are the ones who have tried it at least once and most of the people who hate it are those who haven’t, but that might be my biases speaking. It’s been pretty popular&amp;nbsp;where I’ve seen it implemented.&lt;/p&gt; &lt;h3&gt;Static Analysis&lt;/h3&gt; &lt;p&gt;I do not know what the right amount of static analysis is, but I’m essentially certain that it’s not none. I would not be surprised to learn that the right amount was quite high and includes a type system of some sort, but I don’t know (I also would not be surprised to discover that it was not). However even very dynamic languages admit some amount of static analysis and there are usually tools for it that are worth using.&lt;/p&gt; &lt;p&gt;I largely don’t think of this as a quality thing though. It’s much more a productivity improvement. &amp;nbsp;Unless you are using a language that actively tries to sabotage you (e.g. C, JavaScript), or you have a really atypically good static analysis system that does much more work than the ones I’m used to (I’m actually not aware of any of these that aren’t for C and/or C++ except for languages with actual advanced type systems), static analysis is probably not going to catch bugs much more effectively than a similar level of good testing.&lt;/p&gt; &lt;p&gt;But what it does do is catch those bugs sooner and localise them better. This significantly improves the feedback loop of development and stops you wasting time debugging silly mistakes.&lt;/p&gt; &lt;p&gt;There are two places that static analysis is particularly useful:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;In your editor. I use &lt;a href="https://github.com/scrooloose/syntastic"&gt;syntastic&lt;/a&gt;&amp;nbsp;because I started using vim a decade ago and haven’t figured out how to quit yet, but your favourite editor and/or IDE will likely have something similar (e.g. The Other Text Editor has &lt;a href="http://www.flycheck.org/en/latest/"&gt;flycheck&lt;/a&gt;). This is a really good way of integrating lightweight static analysis into your workflow without having to make any major changes.&lt;/li&gt; &lt;li&gt;In CI. The ideal number of static analysis errors in your project is zero (this is true even when the static analysis system has false positives in my opinion, with the occasional judicious use of ‘ignore this line’ pragmas), but you can use the same tricks as with code coverage to ratchet them down to zero from wherever you’re starting.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Most languages will have at least a basic linting tool you can use, and with compiled languages the compiler probably has warning flags you can turn on. Both are good sources of static analysis that shouldn’t require too much effort to get started with.&lt;/p&gt; &lt;p&gt;Estimated cost: To use it in your editor, low (you can probably get it set up in 10 minutes). To use it in your CI, higher but still not substantial. However depending on the tool it may &lt;a href="https://codewithoutrules.com/2016/10/19/pylint/"&gt;require some tuning to get it usable&lt;/a&gt;, which can take longer.&lt;/p&gt; &lt;p&gt;Estimated benefit: Depends on the tool and the language, but I think you’ll get a modest productivity boost from incorporating static analysis and may get a modest to large quality boost depending on the language (in Python I don’t think you’ll get much of a quality benefit. In C I think you’ll get a huge one even with just compiler warnings).&lt;/p&gt; &lt;p&gt;Controversy level: Varies entirely depending on level of static analysis. Things that you could reasonably describe as “linting” are low. Things that require something closer to a type system much higher. Tools with a high level of false positives also high. You can definitely find an uncontroversial but still useful level of static analysis. I’ve seen it at a moderate subset of the companies I worked for.&lt;/p&gt; &lt;h3&gt;Production Error Monitoring&lt;/h3&gt; &lt;p&gt;You should have some sort of system that logs all errors in production to something more interactive than a log file sitting on a server somewhere. If you’re running software locally on end users’ computers this may be a bit more involved and should require end user consent, but if you’re writing a web application we’re all used to being pervasively spied on in everything we do anyway so who cares?&lt;/p&gt; &lt;p&gt;I’ve used and like &lt;a href="https://sentry.io/welcome/"&gt;Sentry&lt;/a&gt; for this. There are other options, but I don’t have a strong opinion about it.&lt;/p&gt; &lt;p&gt;Estimated cost: Depends on setup, but getting started with sentry is easy and it doesn’t cost a particularly large amount per month (or you can host the open source version for the cost of a server).&lt;/p&gt; &lt;p&gt;Estimated benefit: Much better visibility of how broken your software is in production is the best thing for making your software less broken in production. It will also speed up your debugging process a lot when you do have production errors to fix, so it’s probably a net win in productivity too if you spend much time debugging production errors (and you probably do).&lt;/p&gt; &lt;p&gt;Controversy level: Low but surprisingly it’s not nearly as widely implemented as you might expect. Another thing that is becoming more common though I think.&lt;/p&gt; &lt;h3&gt;Assertions&lt;/h3&gt; &lt;p&gt;I am a big fan of widespread use of assertions, and of leaving them on in production code.&lt;/p&gt; &lt;p&gt;The main reason for this is simple: The single biggest factor in ease of debugging is making sure that the point at which the error is reported&amp;nbsp;is as close as possible to the point at which the error occurs. Assertions are a very good way to do this because they turn a failure of understanding into a runtime error: If your code is not behaving in a way you’d expect, that becomes an error immediately, and it is much easier to debug than finding the downstream thing that actually went wrong at some point later.&lt;/p&gt; &lt;p&gt;It also has a huge benefit when doing property-based testing, because they greatly increase the scope of properties tested – problems that might not have been noticed by the explicit test become much more visible if they trigger an assertion failure.&lt;/p&gt; &lt;p&gt;Input validation while technically not an assertion also has the same effect – a function which checks its arguments rather than silently doing the wrong thing when given a wrong argument will be significantly easier to debug.&lt;/p&gt; &lt;p&gt;John Regehr has &lt;a href="http://blog.regehr.org/archives/1091"&gt;a good post on the care and feeding of assertions&lt;/a&gt;&amp;nbsp;that I recommend reading further.&lt;/p&gt; &lt;p&gt;Estimated cost: Low if you just start adding them in as you develop and edit code. Requires a bit of careful thinking about what the code is doing, but that’s no bad thing.&lt;/p&gt; &lt;p&gt;Estimated benefit: Modest. This won’t be life changingly good, but I have frequently been grateful for a well placed assertion in my code preventing what would otherwise be a much more confusing bug.&lt;/p&gt; &lt;p&gt;Controversy level: People don’t really seem to have an opinion on this one way or another, but it’s not a common habit at all. I’ve not seen it be widespread at any company I’ve worked for.&lt;/p&gt; &lt;h3&gt;Code Review&lt;/h3&gt; &lt;p&gt;I think all projects with &amp;gt; 1 person on them should put all code changes through code review.&lt;/p&gt; &lt;p&gt;Code review seems to be a fairly cost effective&amp;nbsp;defect finding&amp;nbsp;tool according to the literature. I previously believed this not to be the case, but &lt;a href="https://www.drmaciver.com/2016/11/review-of-a-book-that-reviews-reviewing/"&gt;I’ve done some reading and I changed my mind&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;But regardless of whether you find defects,&amp;nbsp;it &lt;em&gt;will&lt;/em&gt;&amp;nbsp;ensure two &amp;nbsp;very important things:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;At least one other person understands this code. This is useful both for bus factor and because it ensures that you have written code that at least one other person&amp;nbsp;&lt;em&gt;can&lt;/em&gt; understand.&lt;/li&gt; &lt;li&gt;At least one other person thinks that shipping this code is a good idea. This is good both for cross checking but also because it forces you to sit down and think about what you ship. This is quite important: Fast feedback loops are good for development, but slow feedback loops for shipping make you pause and think about it.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Over time this will lead to a significantly more maintainable and well designed piece of software.&lt;/p&gt; &lt;p&gt;Estimated cost: You need to get a code review system set up, which is a modest investment and may be trivial. I can’t really recommend anything in this space as the only things I’ve used for this are Github and proprietary internal systems. Once you’ve got that, the ongoing cost is actually quite high because it requires the intervention of an actual human being on each change.&lt;/p&gt; &lt;p&gt;Estimated benefit: It’s hard to say. I have never been part of a code review process that I didn’t think was worth it, but I don’t have a good way of backing that up with measurements. It also depends a lot on the team – this is a good way of dealing with people with different levels of experience and conscientiousness.&lt;/p&gt; &lt;p&gt;Controversy level: Fairly uncontroversial, though at least amongst small companies it used to be weird and unusual. At some point in my career it went from “nobody does this” to “everybody does this”. I think&amp;nbsp;a&amp;nbsp;combination of GitHub pull requests&amp;nbsp;and acknowledgement that most of the cool big companies do it seems to have taken this from a niche opinion to widespread practice in a remarkably short number of years.&lt;/p&gt; &lt;h3&gt;Continuous Delivery&lt;/h3&gt; &lt;p&gt;Another part of localising things to when they went wrong is that ideally once something has passed code review it will&amp;nbsp;ship as soon as possible. Ideally you would ship each change as its own separate release, but that isn’t always practical if you’re e.g. shipping client side software.&lt;/p&gt; &lt;p&gt;This helps ensure that when something goes wrong you&amp;nbsp;have a very good idea of what caused it because not that much changed.&lt;/p&gt; &lt;p&gt;Another important part of this is that when a release goes out you should always be able to roll it back easily. This is essential if you want to make releasing low cost, which is in turn essential for having this sort of frequent release.&lt;/p&gt; &lt;p&gt;A thing I have never worked with personally but have regarded with envy is staged roll out systems which first roll out to a small fraction of the customer base and then gradually ratchet up until it reaches 100%, rolling back automatically or semi-automatically if anything seems to have gone wrong in the process.&lt;/p&gt; &lt;p&gt;Estimated&amp;nbsp;cost: The transitional period from infrequent to frequent deliveries can be a bit rough – you’ll need to spend time automating manual steps, looking for inefficiencies, etc. Take baby steps and gradually try to improve your frequency over time and you can spread this out fairly easily though.&lt;/p&gt; &lt;p&gt;Estimated benefit: A modest quality improvement, and quite a large improvement in debugging time if you currently end up with a lot of broken releases. The release process changes you have to make to make this work will probably also be a significant net time saver.&lt;/p&gt; &lt;p&gt;Controversy level: I’m not sure. It hasn’t seemed that controversial where I’ve seen it implemented, but I think larger companies are more likely to hate it.&lt;/p&gt; &lt;h3&gt;Auto formatting and style checking&lt;/h3&gt; &lt;p&gt;Code review is great, but it has one massive failure mode. Consider &lt;a href="https://wiki.haskell.org/Wadler's_Law"&gt;Wadler’s law&lt;/a&gt;:&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;In any language design, the total time spent discussing&amp;nbsp;a feature in this list is proportional to two raised to&amp;nbsp;the power of its position.&lt;br&gt; 0. Semantics&lt;br&gt; 1. Syntax&lt;br&gt; 2. Lexical syntax&lt;br&gt; 3. Lexical syntax of comments&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;Basically the same thing will happen with code review. People will spend endless time arguing about style checking, layout, etc.&lt;/p&gt; &lt;p&gt;This stuff matters a bit, but it doesn’t matter a lot, and the back and forth of code review is relatively expensive.&lt;/p&gt; &lt;p&gt;Fortunately computers are good at handling it. Just use an auto-formatter plus a style checker. Enforce that these are applied (style checking is technically a subset of static analysis but it’s a really boring subset and there’s not that much overlap in tools).&lt;/p&gt; &lt;p&gt;In Python land I currently use &lt;a href="https://pypi.python.org/pypi/pyformat"&gt;pyformat&lt;/a&gt; and &lt;a href="https://pypi.python.org/pypi/isort"&gt;isort&lt;/a&gt; for auto-formatting and&amp;nbsp;&lt;a href="https://pypi.python.org/pypi/flake8"&gt;flake8&lt;/a&gt; for style checking. I would like to use something stronger for formatting – pyformat is quite light touch in terms of how much it formats your code. clang-format is extremely good and is just about the only thing I miss about writing C++. I look forward to &lt;a href="https://github.com/google/yapf"&gt;yapf&lt;/a&gt; being as good, but don’t currently find it to be there yet (I need to rerun a variant on &lt;a href="https://www.drmaciver.com/2015/03/27-bugs-in-24-hours/"&gt;my bug finding mission I did for it last year&lt;/a&gt;&amp;nbsp;at some point). &lt;a href="https://golang.org/cmd/gofmt/"&gt;gofmt&lt;/a&gt; is nearly the only thing about Go I am genuinely envious of.&lt;/p&gt; &lt;p&gt;Ideally you would have your entire project be a fixed point of the code formatter. That’s what I do for Hypothesis. If you haven’t historically done that it can be a pain though. Many formatting tools can be applied based on only the edited subset of the code. If you’re lucky enough to have one of those, make that part of your build process and have it automatically enforced.&lt;/p&gt; &lt;p&gt;Once you have this, you can now institute a rule that there should be no formatting discussion in code review because that’s the computer’s job.&lt;/p&gt; &lt;p&gt;&lt;a href="https://gdstechnology.blog.gov.uk/2016/09/30/easing-the-process-of-pull-request-reviews/"&gt;Here’s a great post from GDS about this technique and how it’s helped them&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Estimated cost: Mostly&amp;nbsp;tool dependent, but if you’re lucky it’s basically free. Also some social cost – some&amp;nbsp;people&amp;nbsp;&lt;em&gt;really&lt;/em&gt; dislike using style checkers (and to a lesser degree auto-formatters) for reasons that don’t make much sense to me. I personally think the solution is for them to get over it, but it may not be worth the effort of fighting over it.&lt;/p&gt; &lt;p&gt;Estimated benefit: From the increased consistency of your code, small but noticeable. The effect on code review is moderate to large, both in terms of time taken and quality of review.&lt;/p&gt; &lt;p&gt;Controversy level: Surprisingly high. Some people really hate this advice. Even more people hate this advice if you’re not running a formatter that guarantees style conforming code (e.g. I’m not on Hypothesis because none of the Python code formatters &lt;em&gt;can&lt;/em&gt; yet). I’ve only really seen this applied successfully at work once.&lt;/p&gt; &lt;h3&gt;Documentation in the Repository&lt;/h3&gt; &lt;p&gt;You should have a docs section in your repository with prose written about your code. It doesn’t go in a wiki. &lt;a href="http://blog.doismellburning.co.uk/document-all-the-things/"&gt;Wikis are the RCS of documentation&lt;/a&gt;. We’ve already established you should be using good version control and a monorepo, so why would you put your documentation in RCS?&lt;/p&gt; &lt;p&gt;Ideally your docs should use something like &lt;a href="https://www.sphinx-doc.org/en/1.4.8/"&gt;sphinx&lt;/a&gt; so that they compile to a (possibly internally hosted) site you can just access.&lt;/p&gt; &lt;p&gt;It’s hard to keep documentation up to date, I know, but it’s really worth it. At a bare minimum I think your documentation should include:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Up to date instructions for how to get started developing with your code&lt;/li&gt; &lt;li&gt;Detailed answers to questions you find yourselves answering a lot&lt;/li&gt; &lt;li&gt;Detailed post-mortems of major incidents with your product&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;For most projects they should also include a change log which is updated as part of each pull request/change list/whatever.&lt;/p&gt; &lt;p&gt;It may also be worth using the documentation as a form of “internal blogging” where people write essays about things they’ve discovered about the problem domain, the tools you’re using or the local style of work.&lt;/p&gt; &lt;p&gt;Estimated&amp;nbsp;cost: Low initial setup. Writing documentation does take a fair bit of time though, so it’s not cheap.&lt;/p&gt; &lt;p&gt;Estimated&amp;nbsp;benefit: This has a huge robustness benefit, especially every time your team changes structure or someone needs to work on a new area of the code base. How much benefit you’ll derive varies depending on that, but it’s never none – if nothing else, everybody forgets things they don’t do often, but also the process of writing the documentation can hugely help the author’s understanding.&lt;/p&gt; &lt;p&gt;Controversy level: Another case of “most people probably&amp;nbsp;agree this is a good idea but&amp;nbsp;don’t&amp;nbsp;do it”. Unless you’ve got someone pushing for it a lot, documentation tends to be allowed to slide. I’ve never really seen this work at any of the company’s I’ve worked for.&lt;/p&gt; &lt;h3&gt;Plan to always have more capacity than work&lt;/h3&gt; &lt;p&gt;Nick Stenning &lt;a href="https://twitter.com/nickstenning/status/786908316928708608"&gt;made an excellent point on this recently&lt;/a&gt;: If your team is always working at full capacity then delays in responding to changes will sky rocket, even if they’re coming in at a rate you can handle.&lt;/p&gt; &lt;p&gt;As well as that, it tends to mean that maintenance tasks that can greatly improve your productivity will never get done – almost every project has a back log of things that are really annoying the developers that they’d like to fix at some point and never get around to. Downtime is an opportunity to work on that.&lt;/p&gt; &lt;p&gt;This doesn’t require some sort of formal 20% time arrangement, it just requires not trying to fit &lt;a href="https://idioms.thefreedictionary.com/put+a+quart+into+a+pint+pot"&gt;a quart into a pint pot&lt;/a&gt;.&amp;nbsp;In particular, if you find you’ve scheduled more work than got done, that’s not a sign that you slightly over estimated the amount you could get done that’s a sign that you&amp;nbsp;scheduled &lt;em&gt;significantly&lt;/em&gt; too much work.&lt;/p&gt; &lt;p&gt;Estimated&amp;nbsp;Cost: Quite expensive. Even if you don’t formally have 20% time, you’re probably still going to want to spend about 20% of your engineering capacity this way. It may also require significant experimentation to get your planning process good enough to stop overestimating your capabilities.&lt;/p&gt; &lt;p&gt;Estimated&amp;nbsp;Benefit: You will be better able to respond to changes quickly and your team will almost certainly get more done than they were previously getting done in their 100% time.&lt;/p&gt; &lt;p&gt;Controversy level: Fairly high. Almost everywhere I’ve worked the team has consistently planned more work than they have capacity for.&lt;/p&gt; &lt;h3&gt;Projects should be structured as collections of libraries&lt;/h3&gt; &lt;p&gt;Modularity is somewhat overrated, but it’s not&amp;nbsp;&lt;em&gt;very&lt;/em&gt; overrated, and the best way of getting it is to structure things as libraries. The best way to organise your project is not as a big pot of code, but as a large number of small libraries with explicit dependencies between them.&lt;/p&gt; &lt;p&gt;This works really well, is easy to do, and helps keep things clean and easy to understand while providing push back against it all collapsing into a tangled mess.&lt;/p&gt; &lt;p&gt;There are systems like &lt;a href="https://www.bazel.io/"&gt;bazel&lt;/a&gt; that are specifically designed around structuring your project this way. I don’t have &lt;em&gt;very&lt;/em&gt; fond memories of its origin system, and I’ve not used the open source version yet, but it is a good way of enforcing a good build structure. Otherwise the best way to do this is probably just to create subdirectories and use your language’s standard packing tools (which probably include a development mode for local development. e.g. pip install -e if you’re using Python).&lt;/p&gt; &lt;p&gt;Some people may be tempted to do this as &lt;a href="https://www.drmaciver.com/2014/03/write-libraries-not-services/"&gt;microservices&lt;/a&gt; instead, which is a great way to get all the benefits of libraries alongside all the benefits of having an unreliable network and a complicated and fragile deployment system. &amp;nbsp;There&amp;nbsp;&lt;em&gt;are&lt;/em&gt; some good reasons to use microservices in some situations, but using them purely as a way to achieve modularity is just a bad idea.&lt;/p&gt; &lt;p&gt;Estimated cost: Quite low. Just start small – factor out bits of code and start new code in its own library. Evolve it over time.&lt;/p&gt; &lt;p&gt;Estimated benefit: Small to moderate productivity enhancement. Not likely to have a&amp;nbsp;&lt;em&gt;massive&lt;/em&gt; impact on quality, but it does make testing easier so it should have some.&lt;/p&gt; &lt;p&gt;Controversy level: Fairly low. I’m not sure people have an opinion on this one way or the other.&lt;/p&gt; &lt;h3&gt;Ubiquitous working&amp;nbsp;from home&lt;/h3&gt; &lt;p&gt;I’m actually not a huge fan of massively distributed teams, mostly because of time zones. It tends to make late or early meetings a regular feature of peoples’ lives. I could pretend to be altruistic and claim that I disapprove of that because it’s bad for people with kids, which it is, but I also just really hate having to do those myself.&lt;/p&gt; &lt;p&gt;&lt;em&gt;But&lt;/em&gt; the ability to work from home is absolutely&amp;nbsp;essential to a productive work environment, for a number of reasons:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Open plan offices are terrible. They are noisy distraction zones that make it impossible to get productive work done. Unfortunately, this battle is lost. For whatever reason the consensus is that it’s more cost effective&amp;nbsp;to cram developers in at 50% efficiency than it is to pay for office space. This may even be true. But working from home generally solves this by giving people a better work environment that the company doesn’t have to pay for.&lt;/li&gt; &lt;li&gt;Requiring physical presence is a great way for your work force to be constantly sick! People can and should take sick days, but if people cannot work from home then they will inevitably come in when they feel well enough to work but are nevertheless contagious. This will result in other people becoming ill, which will either result in them coming and spreading more disease or staying home and getting nothing done. Being able to work from home significantly reduces the incentive to come in while sick.&lt;/li&gt; &lt;li&gt;Not having physical access to people will tend to improve your communication patterns to be lower interrupt and more documentation driven, which makes them work better for everyone both in the office and not.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;I do not know what the ideal fraction of work from home to work in the office is, but I’d bet money that if most people are not spending at least two days per week working from home then they would benefit from spending more. Also, things will tend to work better as the fraction increases: If you only have a few people working from home at any given point, the office culture will tend to exclude them. As you shift to it being more normal, work patterns will adapt to accommodate them better.&lt;/p&gt; &lt;p&gt;Estimated&amp;nbsp;cost:&amp;nbsp;There may be some technical cost to set this up – e.g. you might need to start running a VPN – but otherwise fairly low. However there may be quite a lot of political and social push back on this one, so you’re going to need a fair bit of buy in to get it done.&lt;/p&gt; &lt;p&gt;Estimated&amp;nbsp;benefit: Depends on team size and current environment, but potentially very large productivity increase.&lt;/p&gt; &lt;p&gt;Controversy level: Fairly low amongst developers, fairly high amongst the non-developers who you’ll probably need to get sign off on it.&lt;/p&gt; &lt;h3&gt;No Long Working Hours&lt;/h3&gt; &lt;p&gt;Working longer work weeks does not make for&amp;nbsp;more productive employees, it just results in&amp;nbsp;burning out,&amp;nbsp;less effective work and spending more time in the office failing to get anything done. Don’t&amp;nbsp;have&amp;nbsp;work environments that encourage&amp;nbsp;it.&lt;/p&gt; &lt;p&gt;In fact, it’s better if you don’t have work environments that&amp;nbsp;&lt;em&gt;allow&lt;/em&gt; it, because it will tend to result in environments where it goes from optional to implicitly mandatory due to who gets rewarded. It’s that reading managers’ minds thing again.&lt;/p&gt; &lt;p&gt;Estimated&amp;nbsp;cost: Same as working from home: Low, but may require difficult to obtain buy in. Will probably also result in a transitional period of lower productivity while people are still burned out but less able to paper over it.&lt;/p&gt; &lt;p&gt;Estimated&amp;nbsp;benefit: High productivity benefits, high quality benefits. Exhausted people do worse work.&lt;/p&gt; &lt;p&gt;Controversy level: High. Depending on who you’re talking to this is either obviously the correct thing to do or basically communism (there may also be some people who think it’s basically communism and that’s why they like it).&lt;/p&gt; &lt;h3&gt;Good&amp;nbsp;Work Culture&lt;/h3&gt; &lt;p&gt;Or the “don’t work with jerks” rule.&lt;/p&gt; &lt;p&gt;People need to be able to ask questions without being afraid. People need to be able to give and receive feedback without being condescending or worrying that the other side will blow up at them or belittle them. People need to be able to take risks and be seen to fail without being afraid of how much it will cost them.&lt;/p&gt; &lt;p&gt;There are two major components to this:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Everyone needs to be on board with it and work towards it. You don’t need everyone to be exquisitely polite with everyone else at all times – a certain amount of directness is usually quite beneficial – but you do need to be helpful, constructive and not make things personal.&lt;/li&gt; &lt;li&gt;Some people are jerks and you should fire them if they don’t fix their ways.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;It is&amp;nbsp;&lt;em&gt;really&lt;/em&gt; hard to do the second one, and most people don’t manage, but it’s also really important. Try to help them fix their ways first, but be prepared to let them go if you can’t, because if you’ve got a high performing jerk on the team it might be that they’re only or in large part high performing because they’re making everyone else perform worse. Even if they really are that good, they’re probably not good enough to justify the reduced productivity from everyone else.&lt;/p&gt; &lt;p&gt;Note: This includes not just developers but also everyone else in the company.&lt;/p&gt; &lt;p&gt;Estimated cost: High. Changing culture is hard. Firing people is hard, especially if they’re people who as individual performers might look like your best employees.&lt;/p&gt; &lt;p&gt;Estimated benefit: Depending on how bad things are currently, potentially extremely high. It will bring everyone’s productivity up and it will improve employee retention.&lt;/p&gt; &lt;p&gt;Controversy level: Another “Not controversial but people don’t actually do it”. I’ve mostly seen the end result of jerks leaving under their own volition and everyone breathing a sigh of relief and experiencing a productivity boost.&lt;/p&gt; &lt;h3&gt;Good Skill Set Mixing&lt;/h3&gt; &lt;p&gt;You generally want to avoid both silos and low bus factors.&lt;/p&gt; &lt;p&gt;In order to do that, it’s important to have both overlapping and complementary skills on your team: A good rule of thumb is that any task should have at least two people who can do it, and any two people should have a number of significant tasks where one would obviously be better suited to work on it than another. The former is much more important than the latter, but both are important.&lt;/p&gt; &lt;p&gt;Having overlapping skills is important because it increases your resilience and capacity significantly: If someone is out sick or on holiday you may be at reduced capacity but there’s nothing you&amp;nbsp;&lt;em&gt;can’t&lt;/em&gt; do. It also means there is always a second perspective you can get on any problem you’re stuck with.&lt;/p&gt; &lt;p&gt;Having complementary skills&amp;nbsp;is important because that’s how you expand capabilities: Two people with overlapping skills are much better able to work together than two people with nothing in common, but two people with identical skills will not be&amp;nbsp;&lt;em&gt;much&lt;/em&gt; better working together than either of them individually. On the other hand two people working together who have different skill sets can cover the full range of either of their skills.&lt;/p&gt; &lt;p&gt;This is a hard one to achieve, but it will tend to develop over time if you’re documenting things well and doing code review. It’s also important to bear in mind while hiring.&lt;/p&gt; &lt;p&gt;Estimated cost: Hard to say because what you need to do to achieve it is so variable, but it will probably require you to hire more people than you otherwise would to get the redundant skill sets you need, so it’s not cheap.&lt;/p&gt; &lt;p&gt;Estimated benefit: Huge improvement in both total team and individual productivity.&lt;/p&gt; &lt;p&gt;Controversy level: Not exactly controversial, but tends not to happen in smaller companies due to people not seeing the benefit. Where it happens it tends to happen by accident.&lt;/p&gt; &lt;h3&gt;Hire me to come take a look at what might be wrong&lt;/h3&gt; &lt;p&gt;I &lt;em&gt;do &lt;/em&gt;do&amp;nbsp;software consulting after all. This isn’t what I normally consult on (I’m pretty focused on &lt;a href="http://hypothesis.works/"&gt;Hypothesis&lt;/a&gt;), but if you’d like the help I’d be happy to branch out, and after accidentally writing 5000 words on the subject I guess I clearly have a few things to say on the subject.&lt;/p&gt; &lt;p&gt;&lt;a href="https://www.drmaciver.com/cdn-cgi/l/email-protection#abcfcaddc2cfebcfd9c6cac8c2ddced985c8c4c6"&gt;Drop me an email if you’re interested&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Estimated cost: My rates are very reasonable.&lt;/p&gt; &lt;p&gt;Estimated benefit: You’re probably better placed to answer this one than I am, but if this document sounds reasonable to you but you’re struggling to get it implemented or want some other things to try, probably quite high.&lt;/p&gt; &lt;p&gt;Controversy level: Not at all controversial. Everyone thinks this is a great idea and you should do it. Honest.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://www.drmaciver.com/2016/10/some-things-that-might-help-you-write-better-software/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:31:01 UT
      </pubDate>
      <guid>
        https://www.drmaciver.com/2016/10/some-things-that-might-help-you-write-better-software/
      </guid>
    </item>
    <item>
      <title>
        How I became a machine learning practitioner
      </title>
      <link>
        https://blog.gregbrockman.com/how-i-became-a-machine-learning-practitioner
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;article id="u5TReR2cWsQifoMYSHMtAg"&gt; &lt;time datetime="2019-07-30"&gt;July 30, 2019&lt;/time&gt; &lt;h2&gt; &lt;a href="https://blog.gregbrockman.com/how-i-became-a-machine-learning-practitioner"&gt;How I became a machine learning practitioner&lt;/a&gt; &lt;/h2&gt; &lt;p&gt;For the first three years of OpenAI, I dreamed of becoming a machine learning expert but made little progress towards that goal. Over the past nine months, I’ve finally made the transition to being a machine learning practitioner. It was hard but not impossible, and I think most people who are good programmers and know (or are willing to learn) the &lt;a href="https://www.deeplearningbook.org/"&gt;math&lt;/a&gt; can do it too. There are many online courses to &lt;a href="https://course.fast.ai/"&gt;self-study&lt;/a&gt; &lt;a href="https://github.com/openai/spinningup"&gt;the&lt;/a&gt; &lt;a href="http://cs231n.stanford.edu/"&gt;technical&lt;/a&gt; &lt;a href="http://rll.berkeley.edu/deeprlcoursesp17/"&gt;side&lt;/a&gt;, and what turned out to be my biggest blocker was a mental barrier — getting ok with being a &lt;a href="https://www.goodreads.com/quotes/309485-nobody-tells-this-to-people-who-are-beginners-i-wish"&gt;beginner&lt;/a&gt; again.&lt;/p&gt; &lt;p&gt;&lt;img alt="gdb-ml1.png" src="https://svbtleusercontent.com/dvwQxNxkr6FKLVsDTBoqwm0xspap_small.png"&gt; &lt;em&gt;Studying machine learning during the 2018 holiday season.&lt;/em&gt;&lt;/p&gt; &lt;h2 id="early-days_1"&gt;Early days &lt;a href="#early-days_1"&gt;#&lt;/a&gt; &lt;/h2&gt; &lt;p&gt;A founding principle of OpenAI is that we value research and engineering equally&amp;nbsp;—&amp;nbsp;our goal is to build working systems that solve previously impossible tasks, so we need both. (In fact, our team is comprised of 25% people primarily using software skills, 25% primarily using machine learning skills, and 50% doing a hybrid of the two.) So from day one of OpenAI, my software skills were always &lt;a href="https://blog.gregbrockman.com/define-cto-openai#gym_1"&gt;in demand&lt;/a&gt;, and I kept procrastinating on picking up the machine learning skills I wanted.&lt;/p&gt; &lt;p&gt;After helping build &lt;a href="https://openai.com/blog/openai-gym-beta/"&gt;OpenAI Gym&lt;/a&gt;, I was called to work on &lt;a href="https://openai.com/blog/universe/"&gt;Universe&lt;/a&gt;. And as Universe was winding down, we decided to start working on &lt;a href="https://openai.com/five/#timeline"&gt;Dota&lt;/a&gt; — and we needed someone to turn the game into a reinforcement learning environment before any machine learning could begin.&lt;/p&gt; &lt;h2 id="dota_1"&gt;Dota &lt;a href="#dota_1"&gt;#&lt;/a&gt; &lt;/h2&gt; &lt;p&gt;Turning such a complex game into a research environment without source code access was &lt;a href="https://www.youtube.com/watch?v=UdIPveR__jw"&gt;awesome&lt;/a&gt; &lt;a href="https://openai.com/blog/more-on-dota-2/#infrastructure"&gt;work&lt;/a&gt;, and the team’s excitement every time I overcame a new obstacle was deeply validating. I figured out how to break out of the game’s Lua sandbox, &lt;a href="https://stackoverflow.com/a/426260"&gt;LD_PRELOAD&lt;/a&gt; in a Go GRPC server to programmatically control the game, incrementally dump the whole game state into a Protobuf, and build a Python library and abstractions with future compatibility for the many different multiagent configurations we might want to use.&lt;/p&gt; &lt;p&gt;But I felt half blind. At &lt;a href="https://blog.gregbrockman.com/figuring-out-the-cto-role-at-stripe"&gt;Stripe&lt;/a&gt;, though I gravitated towards infrastructure solutions, I could make changes anywhere in the stack since I knew the product code intimately. In Dota, I was constrained to looking at all problems through a software lens, which sometimes meant I tried to solve hard problems that could be avoided by just doing the machine learning slightly differently.&lt;/p&gt; &lt;p&gt;I wanted to be like my teammates Jakub Pachocki and Szymon Sidor, who had made the core breakthrough that powered our Dota bot. They had questioned the common wisdom within OpenAI that reinforcement algorithms didn’t scale. They wrote a distributed reinforcement learning framework called Rapid and scaled it exponentially every two weeks or so, and we never hit a wall with it. I wanted to be able to make critical contributions like that which combined software and machine learning skills.&lt;/p&gt; &lt;p&gt;&lt;img alt="jakub-szymon-gdb.jpg" src="https://svbtleusercontent.com/pKEBrnXKw7dzHBrccoTvZF0xspap_small.jpg"&gt; &lt;em&gt;Szymon on the left; Jakub on the right.&lt;/em&gt;&lt;/p&gt; &lt;p&gt;In July 2017, it looked like I might have my chance. The software infrastructure was stable, and I began work on a machine learning project. My goal was to use behavioral cloning to teach a neural network from human training data. But I wasn’t quite prepared for just how much I would feel like a beginner.&lt;/p&gt; &lt;p&gt;I kept being frustrated by small workflow details which made me uncertain if I was making progress, such as not being certain which code a given experiment had used or realizing I needed to compare against a result from last week that I hadn’t properly archived. To make things worse, I kept discovering small bugs that had been corrupting my results the whole time.&lt;/p&gt; &lt;p&gt;I didn’t feel confident in my work, but to make it worse, other people did. People would mention how how hard behavioral cloning from human data is. I always made sure to correct them by pointing out that I was a newbie, and this probably said more about my abilities than the problem.&lt;/p&gt; &lt;p&gt;It all briefly felt worth it when my code made it into the bot, as Jie Tang used it as the starting point for creep blocking which he then fine-tuned with reinforcement learning. But soon Jie figured out how to get better results without using my code, and I had nothing to show for my efforts.&lt;/p&gt; &lt;p&gt;I never tried machine learning on the Dota project again.&lt;/p&gt; &lt;h2 id="time-out_1"&gt;Time out &lt;a href="#time-out_1"&gt;#&lt;/a&gt; &lt;/h2&gt; &lt;p&gt;After we lost two games in The International in 2018, most observers thought we’d &lt;a href="https://twitter.com/polynoamial/status/1032988066967965696"&gt;topped out&lt;/a&gt; what our approach could do. But we knew from our metrics that we were right on the edge of success and mostly needed more training. This meant the demands on my time had relented, and in November 2018, I felt I had an opening to take a gamble with three months of my time.&lt;/p&gt; &lt;p&gt;&lt;img alt="ti-elevator.png" src="https://svbtleusercontent.com/xeofo3DevLKYRqsiq7D5yR0xspap_small.png"&gt; &lt;em&gt;Team members in high spirits after losing our first game at The International.&lt;/em&gt;&lt;/p&gt; &lt;p&gt;I learn best when I have something specific in mind to build. I decided to try building a chatbot. I started self-studying the curriculum we developed for our &lt;a href="https://openai.com/blog/openai-fellows/"&gt;Fellows&lt;/a&gt; program, selecting only the NLP-relevant modules. For example, I wrote and trained an LSTM language model and then a Transformer-based one. I also read up on topics like &lt;a href="https://colah.github.io/posts/2015-09-Visual-Information/"&gt;information theory&lt;/a&gt; and read many papers, poring over each line until I fully absorbed it.&lt;/p&gt; &lt;p&gt;It was slow going, but this time I expected it. I didn’t experience flow state. I was reminded of how I’d felt when I just started programming, and I kept thinking of how many years it had taken to achieve a feeling of mastery. I honestly wasn’t confident that I would ever become good at machine learning. But I kept pushing because… well, honestly because I didn’t want to be constrained to only understanding one part of my projects. I wanted to see the whole picture clearly.&lt;/p&gt; &lt;p&gt;My personal life was also an important factor in keeping me going. I’d begun a relationship with someone who made me feel it was ok if I failed. I spent our first holiday season together beating my head against the machine learning wall, but she was there with me no matter how many planned activities it meant skipping.&lt;/p&gt; &lt;p&gt;One important conceptual step was overcoming a barrier I’d been too timid to do with Dota: make substantive changes to someone else’s machine learning code. I fine-tuned &lt;a href="https://github.com/openai/finetune-transformer-lm"&gt;GPT-1&lt;/a&gt; on chat datasets I’d found, and made a small change to add my own naive sampling code. But it became so painfully slow as I tried to generate longer messages that my frustration overwhelmed my fear, and I implemented GPU caching — a change which touched the entire model.&lt;/p&gt; &lt;p&gt;I had to try a few times, throwing out my changes as they exceeded the complexity I could hold in my head. By the time I got it working a few days later, I realized I’d learned something that I would have previously thought impossible: I now understood how the whole model was put together, down to small stylistic details like how the codebase elegantly handles TensorFlow variable scopes.&lt;/p&gt; &lt;p&gt;After three months of self-study, I felt ready to work on an actual project. This was also the first point where I felt I could benefit from the many experts we have at OpenAI, and I was delighted when Jakub and my co-founder Ilya Sutskever agreed to advise me.&lt;/p&gt; &lt;p&gt;&lt;img alt="ilya.png" src="https://svbtleusercontent.com/4EsPtaedTxAUj3GCBLBvNe0xspap_small.png"&gt; &lt;em&gt;Ilya singing karaoke at our company offsite.&lt;/em&gt;&lt;/p&gt; &lt;p&gt;We started to get very exciting results, and Jakub and Szymon joined the project full-time. I feel proud every time I see a commit from them in the machine learning codebase I’d started.&lt;/p&gt; &lt;p&gt;I’m starting to feel competent, though I haven’t yet achieved mastery. I’m seeing this reflected in the number of hours I can motivate myself to spend focused on doing machine learning work — I’m now around 75% of the number of coding hours from where I’ve &lt;a href="https://twitter.com/sama/status/792898456650076160?lang=en"&gt;been historically&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;But for the first time, I feel that I’m on trajectory. At first, I was overwhelmed by the seemingly endless stream of new machine learning concepts. Within the first six months, I realized that I could make progress without constantly learning entirely new primitives. I still need to get more experience with many skills, such as initializing a network or setting a learning rate schedule, but now the work feels incremental rather than potentially impossible.&lt;/p&gt; &lt;hr&gt; &lt;p&gt;From our Fellows and Scholars programs, I’d known that software engineers with solid fundamentals in linear algebra and probability can become machine learning engineers with just a few months of self study. But somehow I’d convinced myself that I was the exception and couldn’t learn. But I was wrong — even embedded in the middle of OpenAI, I couldn’t make the transition because I was unwilling to become a beginner again.&lt;/p&gt; &lt;p&gt;You’re probably not an exception either. If you’d like to become a deep learning practitioner, you can. You need to give yourself the space and time to fail. If you learn from enough failures, you’ll succeed —&amp;nbsp;and it’ll probably take much less time than you expect.&lt;/p&gt; &lt;p&gt;At some point, it does become important to surround yourself by existing experts. And that is one place where I’m incredibly lucky. If you’re a great software engineer who reaches that point, keep in mind there’s a way you can be surrounded by the same people as I am — &lt;a href="https://openai.com/jobs/"&gt;apply&lt;/a&gt; to OpenAI!&lt;/p&gt; &lt;figure id="kudo_u5TReR2cWsQifoMYSHMtAg"&gt; &lt;a href="#kudo"&gt; &lt;/a&gt; &lt;p&gt;1,074&lt;/p&gt; &lt;p&gt;Kudos&lt;/p&gt; &lt;/figure&gt; &lt;figure id="kudo_side_u5TReR2cWsQifoMYSHMtAg"&gt; &lt;a href="#kudo"&gt; &lt;/a&gt; &lt;p&gt;1,074&lt;/p&gt; &lt;p&gt;Kudos&lt;/p&gt; &lt;/figure&gt; &lt;/article&gt;&lt;/div&gt;&lt;a href="https://blog.gregbrockman.com/how-i-became-a-machine-learning-practitioner"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:31:08 UT
      </pubDate>
      <guid>
        https://blog.gregbrockman.com/how-i-became-a-machine-learning-practitioner
      </guid>
    </item>
    <item>
      <title>
        The Coming Automation of Propaganda - War on the Rocks
      </title>
      <link>
        https://warontherocks.com/2019/08/the-coming-automation-of-propaganda/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div id="post-20662"&gt; &lt;p&gt;If you want a vision of the future, imagine a thousand bots screaming from a human face – forever (apologies to George Orwell). As U.S.&amp;nbsp;policymakers remain indecisive over how to prevent a repeat of the 2016 election interference, the threat is looming ever more ominous on the horizon.&amp;nbsp;The public has unfortunately settled on the term&amp;nbsp;“bots”&amp;nbsp;to describe the social media manipulation activities of foreign actors,&amp;nbsp;invoking an image of neat rows of metal automatons hunched over keyboards, when in reality&amp;nbsp;&lt;a href="https://intelligence.house.gov/social-media-content/"&gt;live humans&lt;/a&gt; are methodically at work. While the 2016 election&amp;nbsp;mythologized the power of these influence-actors, such work is slow, costly, and labor-intensive. Humans must manually create and manage accounts, hand-write posts and comments, and spend countless hours reading content online to&amp;nbsp;&lt;a href="https://faculty.washington.edu/kstarbi/BLM-IRA-Camera-Ready.pdf"&gt;signal-boost particular narratives&lt;/a&gt;. However, recent advances in artificial intelligence (AI) may soon enable the automation of much of this work, massively amplifying the disruptive potential of online influence operations.&lt;/p&gt; &lt;p&gt;This emerging threat draws its power from vulnerabilities&amp;nbsp;in our society: an unaware public, an underprepared legal system, and social media companies not sufficiently concerned with their exploitability by malign actors. Addressing these vulnerabilities requires immediate attention from lawmakers to inform the public, address legal blind spots, and hold social media companies to account.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Characterizing the Threat&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;What the American public has called AI, for lack of a better term, is better thought of as a cluster of emerging technologies capable of constructing convincing false realities. In line with the&amp;nbsp;&lt;a href="https://intelligence.house.gov/news/documentsingle.aspx?DocumentID=657"&gt;terms policymakers use&lt;/a&gt;, we will refer to the falsified media (pictures, audio, and video) these technologies generate as “deepfakes,” though we also suggest a new term, “machine persona,” to refer to AI that mimics the behavior of live users in the service of driving narratives.&lt;/p&gt; &lt;p&gt;Improvements in AI bots, up to this point, have mostly manifested in relatively harmless areas like customer service. But these thus far modest improvements build upon breakthroughs in speech recognition and generation that are &lt;a href="https://www.theatlantic.com/technology/archive/2018/05/humans-acting-like-robots-vs-robots-acting-like-humans/559955/"&gt;nothing short of profound&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;OpenAI,&amp;nbsp;a project Elon Musk founded, made headlines this year for its GPT-2, a&amp;nbsp;&lt;a href="https://openai.com/blog/better-language-models/"&gt;text generation language model&lt;/a&gt;&amp;nbsp;the organization deemed “&lt;a href="https://slate.com/technology/2019/02/openai-gpt2-text-generating-algorithm-ai-dangerous.html"&gt;too dangerous to release.&lt;/a&gt;” This framing was perhaps an exaggeration, but OpenAI’s work was impressive nonetheless. Testers gave the algorithm 40GB of seed text from links aggregated across the Internet, which it studied with the aid of a&amp;nbsp;&lt;a href="https://blogs.nvidia.com/blog/2016/08/15/first-ai-supercomputer-openai-elon-musk-deep-learning/"&gt;supercomputer&lt;/a&gt;, producing a lightweight output that a&amp;nbsp;&lt;a href="https://github.com/openai/gpt-2"&gt;regular desktop could run&lt;/a&gt;. OpenAI released a toned-down version of the algorithm to the public, but the products the organization revealed of the full version were remarkable. Though OpenAI&amp;nbsp;&lt;a href="https://openai.com/blog/better-language-models/#sample1"&gt;admits to taking a few tries to get a good sample&lt;/a&gt;, given the first line of Orwell’s 1984, “It was a bright cold day in April, and the clocks were striking thirteen,” it eventually&amp;nbsp;&lt;a href="https://www.theguardian.com/technology/2019/feb/14/elon-musk-backed-ai-writes-convincing-news-fiction"&gt;produced a coherent opening&lt;/a&gt;&amp;nbsp;to a near-future novel set in Seattle. With an opening line about the discovery of unicorns in the Andes, an article GPT-2 produced wouldn’t look at all out of place in a pop-science website. That is, apart from the subject. The “&lt;a href="https://openai.com/blog/better-language-models/#sample2"&gt;fake news&lt;/a&gt;” applications require little imagination. &lt;a href="https://www.foreignaffairs.com/articles/2019-08-02/not-your-fathers-bots"&gt;One study&lt;/a&gt; explored this exact scenario, showing that GPT-2 was able to generate foreign policy news that subjects rated on average only marginally less credible than the &lt;em&gt;New York Times&lt;/em&gt; seed text.&lt;/p&gt; &lt;p&gt;These developments aren’t mere science projects either, but beneficiaries of market forces. Companies have used natural language processing (NLP) and generalized text generation to automate a growing share of the customer service and information technology workforce, cutting labor costs and freeing skilled labor from menial tasks.&amp;nbsp;Advances in text generation have greatly benefited &lt;a href="https://automatedinsights.com/customer-stories/associated-press/"&gt;journalism in particular&lt;/a&gt;, driving media companies to invest in generating ever more believable content. However, NLP is just one facet of the AI revolution.&lt;/p&gt; &lt;p&gt;Advancements in image recognition and generation can now produce faces that are almost entirely &lt;a href="https://thispersondoesnotexist.com/"&gt;indistinguishable from those of real humans&lt;/a&gt;. Intelligence organizations have already used this technology to&amp;nbsp;&lt;a href="https://www.apnews.com/bc2f19097a4c4fffaa00de6770b8a60d"&gt;solicit unwitting contacts&lt;/a&gt;&amp;nbsp;through social media. The same underlying technologies have also led to a recent spike in deepfake videos, now letting anyone with&amp;nbsp;&lt;a href="https://github.com/iperov/DeepFaceLab"&gt;at-home software&lt;/a&gt; blend real footage almost seamlessly with &lt;a href="https://www.youtube.com/watch?v=bPhUhypV27w"&gt;generated content&lt;/a&gt;.&amp;nbsp;And you don’t have to take our word for it,&amp;nbsp;&lt;a href="https://www.youtube.com/watch?v=cQ54GDm1eL0"&gt;trust former president Barack Obama&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;AI technology also has less flashy, but no less substantial applications in influencing what users see online. Social media platforms work by identifying trending content and boosting it into the feeds of other users. While the case varies from platform to platform, these trend algorithms tend to be a function of ‘likes,’ ‘retweets,’ or ‘upvotes’ over time, but they weight early interaction most strongly. This means that a small,&amp;nbsp;&lt;a href="https://www.forbes.com/sites/jaymcgregor/2016/12/14/how-we-bought-reddit-for-200/#5fd60b7544a8"&gt;concentrated burst of interaction&lt;/a&gt;&amp;nbsp;at the birth of new content is often&amp;nbsp;&lt;a href="https://summercon.org/presentations.html#rain-drop-drop-top"&gt;all that is necessary&lt;/a&gt;&amp;nbsp;to send it trending, pushing it into the feeds of thousands of legitimate users.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Understanding the Impact&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;To appreciate the threat at the intersection of deepfakes and machine personas, consider your daily diet of online information. You probably know enough to avoid following small, suspicious accounts on Twitter or browsing links to sites of which you’ve never heard. You probably don’t accept Facebook friend requests from people you’ve never met and generally stay out of the seedier parts of Reddit. However, the Internet is an ecosystem built for virality. A disruption somewhere can have &lt;a href="https://arxiv.org/abs/1805.12512"&gt;impacts almost anywhere&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Imagine an influence-actor posts a&amp;nbsp;&lt;a href="https://www.vice.com/en_us/article/ywyxex/deepfake-of-mark-zuckerberg-facebook-fake-video-policy"&gt;deepfake video&lt;/a&gt;&amp;nbsp;of the NYPD beating a young minority man to death in an alley. The alley in the background is real. The faces of the police doing the beating are real. The face of the man beaten to death is real, taken from a list of missing persons. The video need only be dropped in a forum somewhere for the Internet to do the rest. Machine personas can then set about controlling the dialogue, goading opposition, reinforcing extremists, and generally shaping the conversation in the most confrontational direction possible. In popular forums such as Reddit, they automatically identify and &lt;a href="https://www.forbes.com/sites/jaymcgregor/2016/12/14/how-we-bought-reddit-for-200/#5fd60b7544a8"&gt;signal-boost comments&lt;/a&gt; about the incident that threaten violence against the police and government. Users claiming the footage is deepfaked are targeted by these same machine personas with downvotes and accusations of supporting a cover up. The omnipresent machine personas fake a public consensus and make dissenters feel they are an unwelcome minority. Posts about the incident reach the front page of Reddit where real users pick up and&amp;nbsp;&lt;a href="http://ide.mit.edu/sites/default/files/publications/2017%20IDE%20Research%20Brief%20False%20News.pdf"&gt;spread the “news” across Facebook and Twitter&lt;/a&gt;, reaching an audience of millions in just a few hours.&lt;/p&gt; &lt;p&gt;As the NYPD struggles to evaluate the video and debunk it, an operative &lt;a href="https://medium.com/huia/live-deep-fakes-you-can-now-change-your-face-to-someone-elses-in-real-time-video-applications-a4727e06612f"&gt;assuming the identity&lt;/a&gt;&amp;nbsp;of a concerned NYPD officer sends a&amp;nbsp;&lt;a href="https://www.vice.com/en_us/article/3k7mgn/baidu-deep-voice-software-can-clone-anyones-voice-with-just-37-seconds-of-audio"&gt;deepfake audio file&lt;/a&gt; to a major U.S. news publication. The file contains the supervisor of the framed officers engaging in a racial epithet-laden rant about the alleged cover-up. The deceived news organization vouches for its credibility, lending its authority to the outrage. Machine personas &lt;a href="https://towardsdatascience.com/automated-text-classification-using-machine-learning-3df4f4f9570b"&gt;automatically identify&lt;/a&gt;&amp;nbsp;and signal-boost tweets and comments advocating for&amp;nbsp;&lt;a href="https://thehill.com/policy/technology/358025-thousands-attended-protest-organized-by-russians-on-facebook"&gt;protest marches&lt;/a&gt;. In the following days, a video surfaces on&amp;nbsp;&lt;a href="https://www.amazon.com/Kill-All-Normies-Culture-Alt-Right/dp/1785355430"&gt;4chan&lt;/a&gt;&amp;nbsp;of immigrants kidnapping and sexually assaulting a young girl, though nobody in the video actually exists to undermine its authenticity. Machine personas then begin advocating on 4chan and 8chan for&amp;nbsp;&lt;a href="https://www.thedailybeast.com/new-zealand-shooting-who-was-ebba-akerlund-whose-death-mosque-shooter-used-as-pretext-for-revenge"&gt;acts of revenge&lt;/a&gt;&amp;nbsp;against the planned protesters, who the machine personas label politically responsible for advocating pro-immigration policies.&lt;/p&gt; &lt;p&gt;Whether a malicious group would engage in such an overtly provocative act or merely&amp;nbsp;&lt;a href="https://www.theguardian.com/world/2018/dec/24/race-russian-election-interference-senate-reports"&gt;patiently stoke the same resentments&lt;/a&gt;&amp;nbsp;is debatable. The danger is that these technologies exist now. Though they may only be prototypes, it is ill-advised to bet against technological progress. In a world where the above scenario is possible, curating your social media contacts is insufficient to insulate yourself from the effects of malign actors. If you are American, you also may have imagined Russia behind this fictional attack, but we ask you to think more broadly. While the resources of a state actor made possible the interference into the 2016 U.S. presidential campaign, AI technologies could put this power into the hands of minor state or even non-state actors.&amp;nbsp;In fact, nothing about this vignette couldn’t be done by a talented lone wolf&amp;nbsp;lacking any intelligence footprint whatsoever.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Countering the Effects&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;There are no easy solutions&amp;nbsp;to the informational challenges&amp;nbsp;AI presents.&amp;nbsp;Each challenge warrants a deeper discussion than we can deliver&amp;nbsp;here, and many of these challenges will have consequences that will require considerable reflection. Rather than proposing solutions in a vacuum, this conversation is best framed in terms of&amp;nbsp;the&amp;nbsp;vulnerabilities that any solution would need to address.&lt;/p&gt; &lt;p&gt;The first vulnerability is a lack of public&amp;nbsp;awareness or skepticism towards content that users view online. A concerted effort should be made by U.S. legislators and Silicon Valley to bring public attention to AI-enabled disinformation. The June 13&amp;nbsp;&lt;a href="https://www.c-span.org/video/?461679-1/house-intelligence-committee-hearing-deepfake-videos"&gt;congressional hearing&lt;/a&gt;&amp;nbsp;on AI-enabled influence operations was an important first step, and it is encouraging to hear bipartisan consensus on the threat. However, awareness has limitations. The public is fortunate that deepfakes and text generators still have a somewhat identifiable “&lt;a href="https://www.lexalytics.com/lexablog/deepfakes-explained-what-why-how-to-spot"&gt;off” quality&lt;/a&gt;&amp;nbsp;to them. Yet the technology is unlikely to plateau here.&amp;nbsp;&lt;a href="https://engineering.purdue.edu/~dgueraco/content/deepfake.pdf"&gt;Technical solutions&lt;/a&gt;&amp;nbsp;also&amp;nbsp;exist in identifying machine-generated content. However, there is no inherent quality of “realness” to a real image that more sophisticated software couldn’t eventually recreate. In a world where malign actors can generate pixel-by-pixel accurate content in the comfort of their own basements,&amp;nbsp;distinguishing fake content from a grainy cell phone video could conceivably become&amp;nbsp;impossible. Everyone should already have an untrusting eye turned towards what they see online, but we ourselves can’t claim to always abide by this virtue. Still, the public should be continuously confronted with the ease with which&amp;nbsp;machine personas will soon be manufacturing provocative and disgusting content. To mitigate this vulnerability, our first impulse when we see members of a different political persuasion engaging in outrageous behavior should not be to share it, but to question its veracity.&lt;/p&gt; &lt;p&gt;The second vulnerability is a legal system with numerous blind spots that lawmakers should close. Reddit is the third-most-popular social media site on the Internet, &lt;a href="https://www.digitaltrends.com/computing/reddit-more-popular-than-facebook-in-2018/"&gt;surpassing Facebook&lt;/a&gt; among American Internet users. It is also shockingly vulnerable, requiring only an e-mail address to register an account. Consequently, anyone could theoretically register an unlimited number of accounts and, being careful not to stand out to system administrators,&amp;nbsp;&lt;a href="https://www.forbes.com/sites/jaymcgregor/2016/12/14/how-we-bought-reddit-for-200/#5fd60b7544a8"&gt;effectively control conversations&lt;/a&gt;&amp;nbsp;on whatever topics they want. This is no hypothetical — you can pay for&amp;nbsp;&lt;a href="https://reddit-marketing.pro/"&gt;this service&lt;/a&gt;&amp;nbsp;right now. (Please don’t.) It’s hard to imagine a real-life analogy, but would Americans defend the right of the local felon to march on city hall with a thousand androids masquerading as fellow citizens? This drives to the heart of an&amp;nbsp;&lt;a href="https://www.city-journal.org/html/platform-or-publisher-15888.html"&gt;ongoing legal debate&lt;/a&gt;&amp;nbsp;on what exactly social media is and how regulators should treat it. However, to accept the status quo is to accept that such behavior is no more serious than a terms of service violation. This unsettled status that regards social media as no more than the footprint of its company is insufficient to capture the scope and impact that users who abuse social platforms have on American society.&lt;/p&gt; &lt;p&gt;The third vulnerability is online anonymity. While we absolutely do not advocate for de-anonymizing the Internet, it is now so influential over American society that legislators should not leave regulation to social media platforms alone. Congress should put more pressure on social media companies to ensure their users are, at a minimum, who they say they are. That said, it is still important to remember that anonymity is both a bug and a feature, and not something regulators should crush out of hand. The Internet’s capacity to act as a platform for dissidents is not something lawmakers should root out, though any attempts are &lt;a href="https://tempophone.com/"&gt;likely to fail anyway&lt;/a&gt;. Still, wherever a microphone appears before a crowd online, there should be no question that malicious actors will seek to place themselves before it. When they can do so with anonymity, tracing the origins of deepfaked media and rooting them out becomes a nearly impossible task. There is a middle ground between anarchy and government-issued Facebook accounts. That middle ground likely involves a far better vetting process for account creation at major sites. A modified&amp;nbsp;&lt;a href="https://www.ics.uci.edu/~kobsa/papers/2003-TOIT-kobsa.pdf"&gt;pseudonymity&amp;nbsp;&lt;/a&gt;system is one possibility, whereby a third party cryptographically verifies an individual can hold an account, then ties the account to that identity without disclosing the name of the holder. This is also not without its faults, both technical and otherwise, not least of which is who the third party should be.&amp;nbsp;Though the government is one clear answer, for a public so enamored with conspiracy theories, Americans shouldn’t expect federally managed Internet identity tracking to be popular with any demographic except federal officials. Platforms also&amp;nbsp;come and go,&amp;nbsp;meaning that companies and regulators would have to continuously renegotiate such a solution. The&amp;nbsp;&lt;a href="https://www.cfr.org/blog/preventing-balkanization-internet"&gt;Internet is&amp;nbsp;also&amp;nbsp;international&lt;/a&gt;&amp;nbsp;— forcing sites to navigate the myriad of requirements various states impose on them. However, no solution needs to be 100% effective. Nor could it, in the face of well-resourced state actors. It should only make reaching&amp;nbsp;&lt;a href="https://fs.blog/2017/07/critical-mass/"&gt;critical mass&lt;/a&gt;&amp;nbsp;in public spaces prohibitively expensive.&lt;/p&gt; &lt;p&gt;Every solution will be painful. Consequently, we don’t expect that regulators will take any significant steps in the directions outlined above until the effects of machine personas become undeniable. It is the responsibility of both the U.S. government and Silicon Valley to ensure that the American public is aware of this threat so that policymakers have the necessary political capital to take action. The public should also be prepared for the possibility that malign actors will put their thumbs on the scale to the&amp;nbsp;&lt;a href="https://www.dw.com/en/frances-yellow-vests-and-the-russian-trolls-that-encourage-them/a-46753388"&gt;benefit of one political entity&lt;/a&gt;&amp;nbsp;over another, so they should have a united voice in rejecting anti-democratic interference. The Internet may already be past the era of speculation about the problem and in the age of persistent machine interference. To protect both it and democracy, the American public needs to begin these conversations in earnest.&lt;/p&gt; &lt;p&gt;&lt;em&gt;Capt. Frank Adkins and Capt. Shawn Hibbard are both active duty Air Force cyber officers and graduates of the U.S. Air Force Academy. They’ve worked at Cyber Command in various positions as operators, red teamers, and planners on the leading edge of the U.S. cyber mission. Capt. Adkins received his Master’s in computer science from Northeastern University with a focus in cyber vulnerability assessment, and Capt. Hibbard received his in strategic intelligence from the National Intelligence University, studying the strategic implications of next-generation supercomputing technology. The views expressed are those of the authors and do not necessarily reflect the official policy or position of the U.S. Air Force, Cyber Command, or the U.S. government.&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Image: &lt;a href="https://www.flickr.com/photos/dcarlbom/3468358859"&gt;Daniel Carlbom&lt;/a&gt; and &lt;a href="https://pixabay.com/illustrations/matrix-code-data-networking-1735640/"&gt;Johnny Lindner&lt;/a&gt;, adapted by War on the Rocks&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://warontherocks.com/2019/08/the-coming-automation-of-propaganda/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:31:16 UT
      </pubDate>
      <guid>
        https://warontherocks.com/2019/08/the-coming-automation-of-propaganda/
      </guid>
    </item>
    <item>
      <title>
        Every productivity thought I&amp;#39;ve ever had, as concisely as possible - Alexey Guzey
      </title>
      <link>
        https://guzey.com/productivity/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;article&gt; &lt;h2&gt;Every productivity thought I've ever had, as concisely as possible&lt;/h2&gt; &lt;span&gt; created: &lt;i&gt;&lt;time&gt;2018-08-07&lt;/time&gt;;&lt;/i&gt; modified: &lt;i&gt;&lt;time&gt;2020-06-15&lt;/time&gt;&lt;/i&gt; &lt;/span&gt; &lt;p&gt;See discussion on &lt;a href="https://news.ycombinator.com/item?id=20737304"&gt;Hacker News&lt;/a&gt; (&lt;a href="https://perma.cc/LJN5-EVQ4"&gt;a&lt;/a&gt;) (610 points, 156 comments)&lt;/p&gt; &lt;hr&gt; &lt;p&gt;I combed through several years of my private notes and through everything I published on productivity before and tried to summarize all of it in this post.&lt;/p&gt; &lt;h2 id="if-youre-unproductive-right-now"&gt;If you’re unproductive right now&lt;/h2&gt; &lt;p&gt;Here’s what you should do if you’ve been procrastinating for an entire day:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Accept that you won’t do anything today and try not to get angry at yourself&lt;/li&gt; &lt;li&gt;Set the alarm for the time you will be preparing to go to bed today&lt;/li&gt; &lt;li&gt;No, really. Do it. It will take 20 seconds&lt;/li&gt; &lt;li&gt;Procrastinate for the rest of the day&lt;/li&gt; &lt;li&gt;When the alarm rings, put your laptop and everything you need for work in your backpack&lt;/li&gt; &lt;li&gt;When you wake up, try to not check social media, email or anything else. Do not take anything out of your backpack&lt;/li&gt; &lt;li&gt;Get dressed, take your stuff, and go to a library, cafe, whatever else where you either &lt;ul&gt; &lt;li&gt;never been to&lt;/li&gt; &lt;li&gt;have been to but never procrastinated within the last 6 months&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;While getting to that place, figure out what you want to be doing today&lt;/li&gt; &lt;li&gt;Do it&lt;/li&gt; &lt;li&gt;Return home in the evening. Don’t take anything (especially your laptop) out of your backpack. Repeat steps 6-10&lt;/li&gt; &lt;/ol&gt; &lt;h2 id="every-productivity-system-stops-working-eventually-and-theres-nothing-you-can-do-about-it"&gt;Every productivity system stops working eventually and there’s nothing you can do about it&lt;/h2&gt; &lt;p&gt;You’ve most likely tried the pomodoro technique. You set the timer for 25 minutes, then take a 5 minute break, then set the timer for 25 minutes again, then at some point you take a longer break and so on. I predict that pomodoro technique eventually broke down for the following reasons:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;you stopped adhering strictly to 5 minute breaks and they started turning into 6-7-10-15-20-or-more minute breaks&lt;/li&gt; &lt;li&gt;you’ve gained an aversion towards 25 minute timers, even while remembering that you should set them, and started finding excuses like “oh this task is too short”, “oh i don’t need a pomo right now”, “i will wait till round time (:00 or :30) and start the pomo then” and these excuses started happening more and more frequently&lt;/li&gt; &lt;li&gt;you started to outright forget about pomodoros, instead just doing your stuff the old way and once in a while realizing that you should’ve been running a pomodoro&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;It seems that every productivity trick / system stops working in exactly the same way I described above. Most productivity tricks develop aversion around them. All of them lose salience.&lt;/p&gt; &lt;p&gt;The only way to avoid encountering problems with productivity is to make the stuff you want to be doing in the long-term to be the most exciting stuff you can do at any moment in time, which is perhaps possible if you, e.g. work at a startup, but is untenable in almost every situation.&lt;/p&gt; &lt;h2 id="context-intentionality-as-the-key-difference-between-home-and-every-other-place-on-planet-earth"&gt;Context intentionality as the key difference between home and every other place on planet earth&lt;/h2&gt; &lt;p&gt;You never wake up at work having forgotten to fill out to dos for the day and feeling slightly depressed.&lt;/p&gt; &lt;p&gt;However awesome you feel you are, this &lt;em&gt;does&lt;/em&gt; occasionally happen at home.&lt;/p&gt; &lt;p&gt;Home is the default place. Home lacks intentionality, which means that sometimes you will feel that “I need to do something” rather than “I will do something something specific right now”. As Kaj Sotala puts it: &lt;a href="https://www.facebook.com/Xuenay/posts/10153513535798662"&gt;“I’m starting to suspect that I may have MASSIVELY underestimated the negative motivational impact of not having a clear sense of one’s next action in a project. …"&lt;/a&gt; (&lt;a href="https://perma.cc/H7QD-9CDH"&gt;a&lt;/a&gt;).&lt;/p&gt; &lt;p&gt;Having no clear idea what to do next increases the probability that you won’t feel like following all the rules you came up with massively. The only solution I know is to avoid working from home as much as you can.&lt;/p&gt; &lt;p&gt;If you aren’t working from home, your workplace should be at least a couple of minutes away (better: an hour away), so that you would not fall into the same trap with it and &lt;em&gt;always&lt;/em&gt; had the time to think on what specifically you’re going to do once there. &lt;label for="sn-2"&gt; &lt;/label&gt; &lt;span&gt; This is also why designating a special room at home as an “office” is probably a bad idea: you will frequently enter it on autopilot, without intentionality. &lt;/span&gt;&lt;/p&gt; &lt;p&gt;Thus, even if you can work at home, you probably shouldn’t. I personally try leave home as early as possible, go to the university, and return home as late as possible.&lt;/p&gt; &lt;p&gt;A trick to aid leaving home and going to work someplace else is to try explicitly forbidding doing anything productive at home. This way, you can no longer tell yourself you’ll start working “soon” and then proceed to waste the entire day procrastinating.&lt;/p&gt; &lt;h2 id="interlude-eliminate-the-distractions-is-the-worst-productivity-advice-ive-ever-seen"&gt;Interlude: “eliminate the distractions” is the worst productivity advice I’ve ever seen&lt;/h2&gt; &lt;p&gt;With my present system, YouTube, reddit, agar.io, etc. are always just two clicks away, but it doesn’t seem to matter at all. And yet, when I had StayFocusd installed with Nuclear Option turned on (forbidding to visit any sites that aren’t on the white list), I picked up Windows Minesweeper and Solitaire, would often literally bang on the keyboard staring at the monitor wanting to scream and eventually found out a way to uninstall StayFocusd even when I purposely made it — as I thought — impossible to do so.&lt;/p&gt; &lt;p&gt;The very fact that your to do list feels ughy means you’re doing something wrong. The very fact that you need to fight the urges to procrastinate means you’re doing it wrong. The utility function itself is warped in fucked up contexts.&lt;/p&gt; &lt;h2 id="how-i-work-and-rest-how-my-system-is-different-from-all-the-others-and-why-i-like-it-so-much"&gt;How I work and rest, how my system is different from all the others, and why I like it so much&lt;/h2&gt; &lt;p&gt;For the last several years, &lt;em&gt;all&lt;/em&gt; &lt;label for="sn-3"&gt; &lt;/label&gt; &lt;span&gt; Did I hear somebody say “preference for routine”? &lt;/span&gt; my working time has been structured as follows:&lt;/p&gt; &lt;figure&gt; &lt;img src="https://guzey.com/pomos.png"&gt; &lt;/figure&gt; &lt;ul&gt; &lt;li&gt;work for 25 minutes from :05 to :30&lt;/li&gt; &lt;li&gt;take a 5 minute break from :30 to :35&lt;/li&gt; &lt;li&gt;work for 25 minutes from :35 to :00&lt;/li&gt; &lt;li&gt;take a 5 minute break from :00 to :05&lt;/li&gt; &lt;li&gt;every three hours (at 12-3-6-9) the :05-:30 work cycle is substituted for a break, which lasts 35 minutes.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;For example&lt;/p&gt; &lt;ul&gt; &lt;li&gt;work: 9:35-10:00&lt;/li&gt; &lt;li&gt;break: 10:00-10:05&lt;/li&gt; &lt;li&gt;work: 10:05-10:30&lt;/li&gt; &lt;li&gt;break: 10:30-10:35&lt;/li&gt; &lt;li&gt;work: 10:35-11:00&lt;/li&gt; &lt;li&gt;break: 11:00-11:05&lt;/li&gt; &lt;li&gt;work: 11:05-11:30&lt;/li&gt; &lt;li&gt;break: 11:30-11:35&lt;/li&gt; &lt;li&gt;work: 11:35-12:00&lt;/li&gt; &lt;li&gt;break: 12:00-12:35&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;It’s important for me my clock shows seconds, therefore I could know the start/end of pomos/breaks precisely, instead of constantly trying to guess them. On Windows I use &lt;a href="https://github.com/White-Tiger/T-Clock"&gt;T-Clock&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;But didn’t I just write that every productivity system breaks down eventually? Yep, this one breaks down as well. However, I found that this arrangement:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;prolongs the period during which the system works.&lt;/li&gt; &lt;li&gt;provides me with 625 minutes of work, interspersed with 275 minutes of breaks (provided my workday is 15 hours). This ratio of work / breaks means that I &lt;ul&gt; &lt;li&gt;have a relatively easy time convincing myself to put off impulsive things (because the maximum waiting time is less than 2.5 hours — until the next long break)&lt;/li&gt; &lt;li&gt;don’t burn out, since such a large portion of my day is specifically dedicated to doing pleasurable, rewarding in the short-term stuff&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;is impossible to forget. Frequently, we simply forget about productivity tricks. Once whole life is built around one, it becomes pretty difficult to forget about it.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;You may say, “but isn’t this basically Pomodoro Technique TM?” Kind of. There are several important differences.&lt;/p&gt; &lt;ol&gt; &lt;li&gt;I don’t care about doing only full pomodoros: suppose, I got home at 20:15. Do I dick around and wait till 20:35 to start a pomo? No. 20:15 is time during which I’m working, so I get to work, and then round this pomo up or down , depending on the circumstances.&lt;/li&gt; &lt;li&gt;I don’t care about pomos being “distraction-free”: suppose, I got distracted in the middle of a pomo. Do I start over? No, I just get back to work, and round this pomo up or down, depending on the circumstances.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;The fact that I &lt;em&gt;never&lt;/em&gt; have to think “do I work right now or do I take a break right now?” removes most of the friction of the pomodoro technique and means I no longer have to &lt;em&gt;actively&lt;/em&gt; think about starting pomodoros. &lt;label for="sn-4"&gt; &lt;/label&gt; &lt;span&gt; Complice’s &lt;a href="https://complice.co/room/lesswrong"&gt;LessWrong Study Hall&lt;/a&gt; served as an inspiration for me. &lt;/span&gt; Given these modifications, it seems that I was able to make my system somewhat of a natural equilibrium.&lt;/p&gt; &lt;p&gt;Some additional rules / heuristics that I follow:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;if I’m in the flow and don’t notice that it’s a break right now, then I skip it. This happens regularly to short breaks; occasionally, e.g. if I’m writing a really exciting post, to long breaks&lt;/li&gt; &lt;li&gt;I usually divide the stuff I work on in 3 hour chunks. For example, my today’s to do list is: &lt;ul&gt; &lt;li&gt;-9 work on the most exciting thing about site&lt;/li&gt; &lt;li&gt;9-12 productivity post&lt;/li&gt; &lt;li&gt;12-13:30 &lt;a href="https://guzey.com/personal/college"&gt;retrospective on college post&lt;/a&gt;&lt;/li&gt; &lt;li&gt;13:30-15 clean up OneNote&lt;/li&gt; &lt;li&gt;15-18 data post&lt;/li&gt; &lt;li&gt;18-21 clean up incoming information&lt;/li&gt; &lt;li&gt;21- figure out site’s todos&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;if I’m obsessed with something, e.g. very exciting research, I usually fill the entire day with it&lt;/li&gt; &lt;li&gt;if I finish my task in the middle of a pomo, then I move on to the next task immediately&lt;/li&gt; &lt;li&gt;if I decide that I don’t want to finish the pomo on the task I planned, e.g. after realizing that the textbook I picked is bad, I try to finish the pomo doing as similar to the original task as possible, e.g. starting to read another textbook on the topic&lt;/li&gt; &lt;li&gt;if I have a thought pop up in my head during a pomo, I write it down to an “Incoming.md” file always open in Notepad. I clean this file up during the breaks and on Sunday&lt;/li&gt; &lt;li&gt;during the short breaks I’m only allowed non-distractive stuff, i.e. social media, email, most of reddit, slack are prohibited &lt;strong&gt;but&lt;/strong&gt; &lt;ol&gt; &lt;li&gt;if I have an ongoing conversation with someone, then during the next short break I’m allowed to check if the person wrote anything and reply to them &lt;ol&gt; &lt;li&gt;if I think the conversation does not wait, then set the phone timer for 5 minutes, and open the conversation then&lt;/li&gt; &lt;/ol&gt; &lt;/li&gt; &lt;li&gt;if I need to open a specific email conversation, I go to &lt;a href="https://mail.google.com/mail/u/0/#search/NAMELASTNAMEORTOPIC,"&gt;https://mail.google.com/mail/u/0/#search/NAMELASTNAMEORTOPIC,&lt;/a&gt; which, along with &lt;a href="https://chrome.google.com/webstore/detail/unread-message-count-hide/jpcbhpcbhlmpnifidfhkomaaeifhiklk"&gt;hidden number of unread messages&lt;/a&gt;, means I don’t get distracted&lt;/li&gt; &lt;li&gt;if I need to open my email inbox, I think if I can wait till the long break &lt;ol&gt; &lt;li&gt;if I can’t, set the phone timer for 5 minutes, and open email then&lt;/li&gt; &lt;li&gt;if I can, open the “Incoming.md” file and write the thing I want to check there, so I don’t forget about it&lt;/li&gt; &lt;/ol&gt; &lt;/li&gt; &lt;li&gt;if I need to open Twitter / FB for some reason &lt;ol&gt; &lt;li&gt;open it incognito, so that I don’t see my timeline, notifications, and DMs&lt;/li&gt; &lt;li&gt;if I need to use my account, e.g. to tweet something or to write someone &lt;ol&gt; &lt;li&gt;write the tweet down and wait till the long break&lt;/li&gt; &lt;li&gt;set the phone timer for 5 minutes, and open Twitter then&lt;/li&gt; &lt;/ol&gt; &lt;/li&gt; &lt;/ol&gt; &lt;/li&gt; &lt;/ol&gt; &lt;/li&gt; &lt;li&gt;Chrome &lt;ol&gt; &lt;li&gt;if I need to open a webpage for something, I’m only allowed to get one page away from what is immediately needed for the task, e.g. I’m writing this post and I want to see what Wikipedia writes about GTD, so I’m allowed to go to GTD, then from GTD to David Allen (and to any other page linked at GTD) but I’m not allowed to open any pages from David Allen. This is the exploration / exploitation tradeoff I enjoy&lt;/li&gt; &lt;li&gt;if I’m researching something, I’m only allowed to open one page at a time, e.g. when I’m doing a literature review, I open the page, read it, close it, and then open the next one. This prevents me from accumulating a unread tabs too fast&lt;/li&gt; &lt;/ol&gt; &lt;/li&gt; &lt;li&gt;if I have an ongoing real-time conversation with someone during the long break, I can continue it&lt;/li&gt; &lt;li&gt;if I’m chatting with someone IRL and I need to open social media because of this, e.g. to send the person I’m chatting with a tweet, I’m allowed to open social media anytime, but only for that specific thing&lt;/li&gt; &lt;li&gt;if I want to listen to a music, 5 minute timer (because music is somewhat distracting and starting listening to it impulsively is dangerous)&lt;/li&gt; &lt;li&gt;If I just published a post, I can check social media whenever for the next 6 hours.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;I have similar rules for all the other stuff, key being that I must either ensure that I don’t get distracted (incognito) or to make sure I’m not doing anything impulsive (5 minute timer, other person as a trigger). If I don’t follow this, it may be impossible to distinguish between opening, e.g. Twitter because I really needed it or because I really wanted to check my notifications. And if I can’t distinguish between these two, then the simplest explanation is the impulsive one, which means that I’m losing control. Which is really, really bad.&lt;/p&gt; &lt;p&gt;My model of the brain is the following: if it believes that you will do as you planned to do, it will occasionally probe you with impulses, but nothing major, and you will be able to do what your “system 2” &lt;label for="sn-5"&gt; &lt;/label&gt; &lt;span&gt; Where system 1 is “fast” and system 2 is “slow”. &lt;/span&gt; wants to do. But if you start to give in to these impulses, the brain increases their power and their frequency, and naturally, you start to give in more and more, right until the point when you do nothing but what your impulsive brain wants you to do in the moment.&lt;/p&gt; &lt;p&gt;Note that being aware of doing something on impulse doesn’t magically remove the adverse consequences of the action on rules you’re breaking, i.e. being aware of breaking a rule does not make it ok to break it.&lt;/p&gt; &lt;h2 id="rules-are-about-exceptions"&gt;Rules are about exceptions&lt;/h2&gt; &lt;p&gt;Why the hell does my “some additional rules” list look like the table of contents for War and Peace? Why don’t I just say “distractive stuff allowed only during long breaks”? Because &lt;em&gt;rules are about exceptions&lt;/em&gt;. Exceptions are inevitable. Sometimes I will have to open a social network or check email during pomos. If I didn’t have exceptions explicitly written down, then I would break my rules, thereby decreasing their future strength. &lt;label for="sn-6"&gt; &lt;/label&gt; &lt;span&gt; I wrote up a formal model of this process in my &lt;a href="https://guzey.com/files/bachelors-thesis/guzey-commitments.pdf"&gt;Bachelor’s thesis&lt;/a&gt;. &lt;/span&gt;&lt;/p&gt; &lt;p&gt;Still, it’s impossible to write down &lt;em&gt;all&lt;/em&gt; exceptions, which means that sometimes I still break my rules and sometimes the rules break down completely. Thus, I need a way to reinstitute them.&lt;/p&gt; &lt;h2 id="interlude-guilt"&gt;Interlude: guilt&lt;/h2&gt; &lt;p&gt;When a rule / productivity system breaks and you start wasting your time, don’t take it too personally and try not to blame yourself. The only thing you can do now is write your observations down, think about how to improve them for the future, and then try to implement them.&lt;/p&gt; &lt;h2 id="rules-stopped-working-what-next"&gt;Rules stopped working. What next?&lt;/h2&gt; &lt;p&gt;First of all, an important qualification: rules don’t just stop working. They stop working in specific contexts, e.g. if you go to a novel location, you will find that the old patterns of behavior — whether productive or destructive — are much weakened there. This suggests a natural solution to the problem of reinstating broken rules: go to an unexplored coffee shop or library and work there until the new location breaks down.&lt;label for="sn-7"&gt; &lt;/label&gt; &lt;span&gt; Often, people work in libraries and coffee shops precisely for this reason — because these locations allow to create a &lt;a href="https://twitter.com/The_Lagrangian/status/670332250089762816"&gt;novel self-pattern&lt;/a&gt; specifically for them. &lt;/span&gt; The problem with this is that if there are too many possible locations, there’s no incentive to maintain the rules structure in them, so they break down too fast.&lt;/p&gt; &lt;p&gt;I found that I have 3-4 places in town I especially like and rotate my work between those in which rules work at the moment (the rule following ability seems to reset naturally within several days-weeks-months for each location). I have one specific place in which the rules are extra strict, meaning, upon entering this place I turn off mobile internet on the phone and can only turn it on after a 5 minute timer.&lt;/p&gt; &lt;p&gt;Pro tip: you don’t usually go from 0 procrastination to 100 in an instant. If you learn to recognize when you’re at 20 and switch the location preemptively you will save yourself a lot of time.&lt;/p&gt; &lt;p&gt;Physical place is not the only context that can be broken. For example, if you have trouble playing games on your phone everywhere, buying a new one and committing not to play any games on it from the very start can work very well (at least for some time).&lt;/p&gt; &lt;h2 id="bullshit-test-for-the-previous-section"&gt;Bullshit test for the previous section&lt;/h2&gt; &lt;p&gt;The previous section is exceptional in that you can test whether what I wrote there is bullshit rather easily (this is basically the same thing as in the beginning of this post):&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Think of a task you’re currently putting off, even though you shouldn’t.&lt;/li&gt; &lt;li&gt;Open Google Maps and find a particular coffee shop/library/etc. you’ve never been to.&lt;/li&gt; &lt;li&gt;Go to that place strongly committing to only doing the particular thing you decided to do there and not get distracted either physically or mentally on other things. This means as little chatting with people as possible; no checking email (unless it’s absolutely needed); no checking social media; not doing anything at all that is not directly related to the task at hand. Basically, maintaining the rule structure similar to the one I described in the beginning of the post.&lt;/li&gt; &lt;li&gt;Notice how easy or difficult the task was to work on and how easy or difficult it was to not let yourself be distracted, compared to your usual environment.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&lt;strong&gt;My prediction&lt;/strong&gt;: however off-putting and ughy the task is, there’s going to be close to none difficulty in concentrating on it and there will be no other issues that usually prevent you from accomplishing it.&lt;/p&gt; &lt;h2 id="break-rules-sometimes"&gt;Break rules sometimes&lt;/h2&gt; &lt;p&gt;Adhere to anything religiously enough and you start to forget why you decided on doing it in the first place. &lt;label for="sn-8"&gt; &lt;/label&gt; &lt;span&gt; With rules turning into &lt;a href="https://en.m.wikipedia.org/wiki/Wikipedia:Chesterton%27s_fence"&gt;Chesterton’s fences&lt;/a&gt;. &lt;/span&gt; Stoics suggest negative visualization and occasional intentional deprivation of things we take for granted, e.g. living off bread and milk for a few days; I suggest to occasionally forget all the rules you have for a while and see what happens. This will happen naturally at some rate, due to rules being gradually broken, but sometimes it might be worthwhile to explicitly let yourself not be bound by any rules designed to enhance productivity and see how it pans out. It seems that this kind of experience may serve as a sort of a springboard for the future.&lt;/p&gt; &lt;p&gt;For example, a couple of times per year I clear out several days, during which I play Civilization 5 for 16-18 hours a day. At some point, I become so nauseated and frustrated by the game that I naturally just can’t play it anymore. The realization of just how easily I just sent like 50 hours of my life down the drain helps to gain the perspective on a lot of stuff, including why I avoid video games so scrupulously at all other times.&lt;/p&gt; &lt;p&gt;Note that spending a day procrastinating / playing video games is equivalent to reading a book for an hour every day for two weeks.&lt;/p&gt; &lt;h2 id="a-couple-more-tips"&gt;A couple more tips&lt;/h2&gt; &lt;h3 id="how-to-not-forget-about-productivity-tricks"&gt;How to not forget about productivity tricks?&lt;/h3&gt; &lt;p&gt;You can literally just add a reminder a week / a month in the future which asks if the new productivity trick is used and, if not, why. I use &lt;a href="http://www.amazingmarvin.com/"&gt;Amazing Marvin&lt;/a&gt; as my todo list and add the reminders there.&lt;/p&gt; &lt;h3 id="podcasts-and-audiobooks"&gt;Podcasts and audiobooks&lt;/h3&gt; &lt;p&gt;&lt;a href="http://grognor.blogspot.com/2016/12/the-lifehack.html"&gt;If you think you can’t listen to podcasts and audiobooks, you’re probably wrong. Just speed them up and you’ll be able to concentrate on them just fine.&lt;/a&gt; You probably have at least 30-60 minutes of downtime every day available for audio content. That’s basically a free hour a day to read a book. The other possibility is that you’ve just tried to listen to a wrong book and gave up too early! I found that about half the books I can’t listen and need to actually read.&lt;/p&gt; &lt;p&gt;The way to highlight books while listening to them is to catch an identifying phrase near the segment you want to return to, write it down to a special file, and after having finished the book, open the written version of the book and find all the highlights there, using the identifying phrases.&lt;/p&gt; &lt;p&gt;See my audio content apps recommendations and headphones recommendations in my &lt;a href="https://guzey.com/tools-gear"&gt;Tools / Gear&lt;/a&gt; post.&lt;/p&gt; &lt;h3 id="browser-tab-management"&gt;Browser tab management&lt;/h3&gt; &lt;p&gt;Tabs have a tendency to blow up. However, there’s a natural upper limit for how much the can blow up, since at some point they overflow and you no longer have access to the rightmost tabs. This is so frustrating that we can naturally turn this to our advantage. So, create two soft rules: &lt;label for="sn-10"&gt; &lt;/label&gt; &lt;span&gt; à la &lt;a href="https://en.m.wikipedia.org/wiki/FIFO_and_LIFO_accounting"&gt;FIFO&lt;/a&gt;. &lt;/span&gt;&lt;/p&gt; &lt;ol&gt; &lt;li&gt;only close tabs from the left-hand side&lt;/li&gt; &lt;li&gt;only open tabs in the end (but can close just opened tabs).&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;These rules are pretty easy to maintain (since you can still do anything you need while following them) but they’re really frustrating to abide by, which creates a really good incentive to clean tabs up. The equilibrium is to have about 50-80 tabs (depending on the size of your monitor), just about to overflow. Note that you might need a lot of RAM (like 16gb) for this to work.&lt;/p&gt; &lt;h3 id="figuring-out-the-core-issues-behind-procrastination"&gt;Figuring out the core issues behind procrastination&lt;/h3&gt; &lt;p&gt;I will quote &lt;a href="https://www.facebook.com/marco.vega.925"&gt;Marco Vega&lt;/a&gt; of &lt;a href="https://sapien.co/"&gt;Sapien&lt;/a&gt; here:&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;99% of the time procrastination is not about you being lazy or lacking work-ethic. Your body/brain is sending your some important information about the tasks at hand, and it’s important that you listen to those signals empathetically.&lt;/p&gt; &lt;/blockquote&gt; &lt;blockquote&gt; &lt;p&gt;For example,&lt;/p&gt; &lt;/blockquote&gt; &lt;blockquote&gt; &lt;p&gt;A - &lt;strong&gt;The task requirements and goals might not be clear enough&lt;/strong&gt;. If you are trying to get yourself to “plan for a project” or “write a book” then it’s hard to identify the next actionable items. Put some time aside to figure out what physical things you can do to move the project forward. Try break down the larger tasks into the smallest pieces possible. The goal of the project might need identifying, or the requirements fleshed out from a supervisor.&lt;/p&gt; &lt;/blockquote&gt; &lt;blockquote&gt; &lt;p&gt;B - &lt;strong&gt;The task might exceed your current competency&lt;/strong&gt;. Sometimes we know what we have to do, but don’t know how to do it, and then we become avoidant rather than admitting this. In this case, it’s worth figuring out what you do know how to do and what you don’t know how to do, and be honest with that. Then slowly ask for help or read up on the things you don’t know.&lt;/p&gt; &lt;/blockquote&gt; &lt;blockquote&gt; &lt;p&gt;C - &lt;strong&gt;The tasks might really not be worth it&lt;/strong&gt;. Sometimes you are assigned tasks that don’t actually help you achieve your long-term goals, and so your brain demotivate you from doing them. Maybe the payoff is low, maybe you don’t learn anything new from them, or maybe a colleague you don’t like will gain credit for the tasks, or maybe you just wont be rewarded or appreciated for getting the tasks done.&lt;/p&gt; &lt;/blockquote&gt; &lt;blockquote&gt; &lt;p&gt;As a general rule of thumb. If you notice yourself procrastinating, don’t beat yourself up about it. Just notice the behaviour and put some time aside to have an honest conversation with yourself for why you might be unconsciously avoiding these tasks. There is no shame here. It’s very difficult to move forward without self-empathy and self-understanding. ‘Pushing yourself’ is OK in small doses, but if you make it a habit, you are increasing your chances of burnout!&lt;/p&gt; &lt;/blockquote&gt; &lt;h3 id="task-order"&gt;Task order&lt;/h3&gt; &lt;p&gt;If you just have a bunch of things to do for the day, try using &lt;a href="https://random.org/"&gt;random.org&lt;/a&gt; to decide on the order of your tasks. This both&lt;/p&gt; &lt;ol&gt; &lt;li&gt;doesn’t allow you to just do the easiest tasks first&lt;/li&gt; &lt;li&gt;makes the very act of choosing the next task pretty exciting&lt;/li&gt; &lt;/ol&gt; &lt;h2 id="help-me-make-this-post-better"&gt;Help me make this post better!&lt;/h2&gt; &lt;p&gt;If you’ve read to this point, I would guess you enjoyed the post. If you decide to try any of the tricks I describe — do let me know, so that I check back with you in 1, 3, and 12 months and see if this post is actually helpful in the long-term.&lt;/p&gt; &lt;h2 id="acknowledgements"&gt;Acknowledgements&lt;/h2&gt; &lt;p&gt;Thanks to &lt;a href="https://vk.com/ansty57"&gt;Anastasia Kuptsova&lt;/a&gt; for many helpful comments.&lt;/p&gt; &lt;h2 id="also-see"&gt;Also see&lt;/h2&gt; &lt;p&gt;&lt;a href="http://blog.samaltman.com/productivity"&gt;Productivity&lt;/a&gt; by Sam Altman&lt;/p&gt; &lt;h2 id="bibliography"&gt;Bibliography&lt;/h2&gt; &lt;p&gt;Many people influenced my thinking on productivity. In particular, I should note:&lt;/p&gt; &lt;p&gt;Scott Adams' &lt;a href="https://amzn.to/2B1qf4W"&gt;How to Fail at Almost Everything and Still Win Big&lt;/a&gt; (probably the most important book I’ve ever read)&lt;/p&gt; &lt;p&gt;Scott Alexander’s &lt;a href="http://slatestarcodex.com/2013/06/30/the-lottery-of-fascinations/"&gt;The Lottery of Fascinations&lt;/a&gt;&lt;/p&gt; &lt;p&gt;David Allen’s &lt;a href="https://amzn.to/2KEJYHm"&gt;Getting Things Done&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Tiago Forte’s &lt;a href="http://www.ribbonfarm.com/2016/03/24/the-holy-grail-of-self-improvement/"&gt;The Holy Grail of Self-Improvement&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Malcolm Ocean’s &lt;a href="http://malcolmocean.com/2016/03/face-personality-upgrade-ritual/"&gt;A ritual to upgrade my Face&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Roko’s &lt;a href="https://wiki.lesswrong.com/wiki/Ugh_field"&gt;Ugh fields&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Adam Strandberg’s &lt;a href="http://the-lagrangian.blogspot.com/2015/10/time-depletion.html"&gt;Time Depletion&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Between ages fourteen and sixteen I read a lot of &lt;a href="https://scotthyoung.com/"&gt;Scott H Young&lt;/a&gt; and &lt;a href="http://tynan.com/"&gt;Tynan&lt;/a&gt; and some &lt;a href="https://www.stevepavlina.com/"&gt;Steve Pavlina&lt;/a&gt;, so although I don’t remember almost anything they wrote, I’m pretty sure there are some traces of their ideas in me.&lt;/p&gt; &lt;h3 id="stuff-with-similar-thoughts-i-discovered-while-writing-this-post"&gt;Stuff with similar thoughts I discovered while writing this post&lt;/h3&gt; &lt;p&gt;Peter Hurford’s &lt;a href="https://www.lesswrong.com/posts/JTHe5oGvdj6T73o4o/how-i-am-productive"&gt;How I Am Productive&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Scott Alexander’s &lt;a href="https://www.lesswrong.com/posts/NjzBrtvDS4jXi5Krp/applied-picoeconomics"&gt;Applied Picoeconomics&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Eliezer Yudkowsky’s &lt;a href="https://www.lesswrong.com/posts/FHukyfMagq4HrBYNt/willpower-hax-487-execute-by-default"&gt;Execute by Default&lt;/a&gt;&lt;/p&gt; &lt;/article&gt;&lt;/div&gt;&lt;a href="https://guzey.com/productivity/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:31:28 UT
      </pubDate>
      <guid>
        https://guzey.com/productivity/
      </guid>
    </item>
    <item>
      <title>
        Deep Learning Illustrated: Building Natural Language Processing Models &amp;#8211; Data Science Blog by Domino
      </title>
      <link>
        https://blog.dominodatalab.com/deep-learning-illustrated-building-natural-language-processing-models/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt; &lt;p&gt;&lt;em&gt;&lt;small&gt;Many thanks to Addison-Wesley Professional for providing the permissions to excerpt “Natural Language Processing” from the book, &lt;a href="http://www.informit.com/store/deep-learning-illustrated-a-visual-interactive-guide-9780135116692?utm_source=Referral&amp;amp;utm_medium=DominoLabs&amp;amp;utm_campaign=Krohn&amp;amp;utm_term=DLBook"&gt;Deep Learning Illustrated&lt;/a&gt; by &lt;a href="https://www.linkedin.com/in/jonkrohn/"&gt;Krohn&lt;/a&gt;, &lt;a href="https://www.linkedin.com/in/grantbey/"&gt;Beyleveld&lt;/a&gt;, and &lt;a href="https://twitter.com/aglaebassens"&gt;Bassens&lt;/a&gt;. The excerpt covers how to create word vectors and utilize them as an input into a deep learning model. A complementary &lt;a href="https://try.dominodatalab.com/u/domino-andrealowe/Natural-Language-Processing/overview"&gt;Domino project is available&lt;/a&gt;.&lt;small&gt;&lt;/small&gt;&lt;/small&gt;&lt;/em&gt;&lt;/p&gt; &lt;h2&gt;Introduction&lt;/h2&gt; &lt;p&gt;While the field of computational linguistics, or Natural Language Processing (NLP), has been around for decades, the increased interest in and use of deep learning models has &lt;a href="https://arxiv.org/pdf/1807.10854.pdf"&gt;also propelled applications of NLP forward&lt;/a&gt; within industry. Data scientists and researchers require an extensive array of techniques, packages, and tools to accelerate core work flow tasks including prepping, processing, and analyzing data. Utilizing NLP helps researchers and data scientists complete core tasks faster. As &lt;a href="https://www.dominodatalab.com/?utm_source=blog&amp;amp;utm_campaign=referral&amp;amp;utm_medium=logo&amp;amp;utm_content="&gt;Domino&lt;/a&gt; is committed to accelerating data science work flows, we reached out to Addison-Wesley Professional (AWP) for permissions to excerpt the extensive “Natural Language Processing” chapter from the book, &lt;em&gt;&lt;a href="http://www.informit.com/store/deep-learning-illustrated-a-visual-interactive-guide-9780135116692?utm_source=Referral&amp;amp;utm_medium=DominoLabs&amp;amp;utm_campaign=Krohn&amp;amp;utm_term=DLBook"&gt;Deep Learning Illustrated&lt;/a&gt;.&lt;/em&gt; We appreciate &lt;a href="http://www.informit.com/imprint/series_detail.aspx?ser=4255387"&gt;AWP Pearson&lt;/a&gt; for providing the permissions to excerpt the work and enabling us to provide a complementary &lt;a href="https://try.dominodatalab.com/u/domino-andrealowe/Natural-Language-Processing/overview"&gt;Domino project&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;img sizes="(max-width: 947px) 100vw, 947px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/NLP-Workspace.png 979w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/NLP-Workspace-300x139.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/NLP-Workspace-768x357.png 768w" height="440" width="947" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/NLP-Workspace.png" loading="lazy"&gt;&lt;/p&gt; &lt;p&gt;&lt;img sizes="(max-width: 950px) 100vw, 950px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/NLP-files.png 1084w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/NLP-files-300x92.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/NLP-files-768x237.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/NLP-files-1024x316.png 1024w" height="293" width="950" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/NLP-files.png" loading="lazy"&gt;&lt;/p&gt; &lt;h2&gt;Chapter Introduction: Natural Language Processing&lt;/h2&gt; &lt;p&gt;In Chapter 2 [&lt;a href="http://www.informit.com/store/deep-learning-illustrated-a-visual-interactive-guide-9780135116692?utm_source=Referral&amp;amp;utm_medium=DominoLabs&amp;amp;utm_campaign=Krohn&amp;amp;utm_term=DLBook"&gt;in the book&lt;/a&gt;], we introduced computational representations of language, particularly highlighting word vectors as a potent approach for quantitatively capturing word meaning. In the present chapter [excerpt], we cover code that will enable you to create your own word vectors as well as to provide them as an input into a deep learning model.&lt;/p&gt; &lt;p&gt;The natural language processing models you build in this chapter will incorporate neural network layers we’ve applied already: dense layers from Chapters 5 through 9 [&lt;a href="http://www.informit.com/store/deep-learning-illustrated-a-visual-interactive-guide-9780135116692?utm_source=Referral&amp;amp;utm_medium=DominoLabs&amp;amp;utm_campaign=Krohn&amp;amp;utm_term=DLBook"&gt;in the book&lt;/a&gt;], and convolutional layers from Chapter 10 [&lt;a href="http://www.informit.com/store/deep-learning-illustrated-a-visual-interactive-guide-9780135116692?utm_source=Referral&amp;amp;utm_medium=DominoLabs&amp;amp;utm_campaign=Krohn&amp;amp;utm_term=DLBook"&gt;in the book&lt;/a&gt;]. Our NLP models will also incorporate new layer types—ones from the family of recurrent neural networks. RNNs natively handle information that occurs in sequences such as natural language, but they can, in fact, handle any sequential data—such as financial time series or temperatures at a given geographic location—so they’re quite versatile. The chapter concludes with a section on deep learning networks that process data via multiple parallel streams—a concept that dramatically widens the scope for creativity when you design your model architectures and, as you’ll see, can also improve model accuracy.&lt;/p&gt; &lt;h2&gt;Preprocessing Natural Language Data&lt;/h2&gt; &lt;p&gt;There are steps you can take to preprocess natural language data such that the modeling you carry out downstream may be more accurate. Common natural language preprocessing options include:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;em&gt;Tokenization:&lt;/em&gt; This is the splitting of a document (e.g., a book) into a list of discrete elements of language (e.g., words), which we call &lt;em&gt;tokens&lt;/em&gt;.&lt;/li&gt; &lt;li&gt;Converting all characters to &lt;em&gt;lowercase&lt;/em&gt;. A capitalized word at the beginning of a sentence (e.g., &lt;em&gt;She&lt;/em&gt;) has the same meaning as when it’s used later in a sentence (&lt;em&gt;She&lt;/em&gt;). By converting all characters in a corpus to lowercase, we disregard any use of capitalization.&lt;/li&gt; &lt;li&gt;Removing &lt;em&gt;stop words:&lt;/em&gt; These are frequently occurring words that tend to contain relatively little distinctive meaning, such as &lt;em&gt;the&lt;/em&gt;, &lt;em&gt;at,&lt;/em&gt; &lt;em&gt;which&lt;/em&gt;, and &lt;em&gt;of&lt;/em&gt;. There is no universal consensus on the precise list of stop words, but depending on your application it may be sensible to ensure that certain words are (or aren’t!) considered to be stop words. For example, in this chapter, we’ll build a model to classify movie reviews as positive or negative. Some lists of stop words include negations like &lt;em&gt;didn’t&lt;/em&gt;, &lt;em&gt;isn’t&lt;/em&gt;, and &lt;em&gt;wouldn’t&lt;/em&gt; that might be critical for our model to identify the sentiment of a movie review, so these words probably shouldn’t be removed.&lt;/li&gt; &lt;li&gt;Removing &lt;em&gt;punctuation&lt;/em&gt;: Punctuation marks generally don’t add much value to a natural language model and so are often removed.&lt;/li&gt; &lt;li&gt;&lt;em&gt;Stemming:&lt;/em&gt; Stemming is the truncation of words down to their stem. For example, the words house and housing both have the stem hous. With smaller datasets in particular, stemming can be productive because it pools words with similar meanings into a single token. There will be more examples of this stemmed token’s con- text, enabling techniques like word2vec or GloVe to more accurately identify an appropriate location for the token in word-vector space (see Figures 2.5 and 2.6) [&lt;a href="http://www.informit.com/store/deep-learning-illustrated-a-visual-interactive-guide-9780135116692?utm_source=Referral&amp;amp;utm_medium=DominoLabs&amp;amp;utm_campaign=Krohn&amp;amp;utm_term=DLBook"&gt;in the book]&lt;/a&gt;. [Note: Lemmatization, a more sophisticated alternative to stemming, requires the use of a reference vocabulary. For our purposes in this book, stemming is a sufficient approach for considering multiple related words as a single token.]&lt;/li&gt; &lt;li&gt;Handling &lt;em&gt;n-grams&lt;/em&gt;: Some words commonly co-occur in such a way that the combination of words is better suited to being considered a single concept than several separate concepts. As examples, &lt;em&gt;New York&lt;/em&gt; is a &lt;em&gt;bigram&lt;/em&gt; (an&lt;em&gt; n&lt;/em&gt;-gram of length two), and &lt;em&gt;New York City&lt;/em&gt; is a &lt;em&gt;trigram&lt;/em&gt; (an &lt;em&gt;n&lt;/em&gt;-gram of length three). When chained together, the words &lt;em&gt;new,&lt;/em&gt; &lt;em&gt;york&lt;/em&gt;, and&lt;em&gt; city&lt;/em&gt; have a specific meaning that might be better captured by a single token (and therefore a single location in word-vector space) than three separate ones.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Depending on the particular task that we’ve designed our model for, as well as the dataset that we’re feeding into it, we may use all, some, or none of these data preprocessing steps. As you consider applying any preprocessing step to your particular problem, you can use your intuition to weigh whether it might ultimately be valuable to your downstream task. We’ve already mentioned some examples of this:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Stemming may be helpful for a small corpus but unhelpful for a large one.&lt;/li&gt; &lt;li&gt;Likewise, converting all characters to lowercase is likely to be helpful when you’re working with a small corpus, but, in a larger corpus that has many more examples of individual uses of words, the distinction of, &lt;em&gt;say&lt;/em&gt;, &lt;em&gt;general&lt;/em&gt; (an adjective meaning “widespread”) versus &lt;em&gt;General&lt;/em&gt; (a noun meaning the commander of an army) may be valuable.&lt;/li&gt; &lt;li&gt;Removing punctuation would not be an advantage in all cases. Consider, for example, if you were building a question-answering algorithm, which could use question marks to help it identify questions.&lt;/li&gt; &lt;li&gt;Negations may be helpful as stop words for some classifiers but probably not for a sentiment classifier, for example. Which words you include in your list of stop words could be crucial to your particular application, so be careful with this one. In many instances, it will be best to remove only a limited number of stop words.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;If you’re unsure whether a given preprocessing step may be helpful or not, you can investigate the situation empirically by incorporating the step and observing whether it impacts the accuracy of your deep learning model downstream. As a general rule, the larger a corpus becomes, the fewer preprocessing steps that will be helpful. With a small corpus, you’re likely to be concerned about encountering words that are rare or that are outside the vocabulary of your training dataset. By pooling several rare words into a single common token, you’ll be more likely to train a model effectively on the meaning of the group of related words. As the corpus becomes larger, however, rare words and out-of-vocabulary words become less and less of an issue. With a very large corpus, then, it is likely to be helpful to &lt;em&gt;avoid&lt;/em&gt; pooling several words into a single common token. That’s because there will be enough instances of even the less-frequently-occurring words to effectively model their unique meaning as well as to model the relatively subtle nuances between related words (that might otherwise have been pooled together).&lt;/p&gt; &lt;p&gt;To provide practical examples of these preprocessing steps in action, we invite you to check out our &lt;em&gt;Natural Language Preprocessing&lt;/em&gt; Jupyter notebook [or the &lt;a href="https://try.dominodatalab.com/u/domino-andrealowe/Natural-Language-Processing/overview"&gt;complementary Domino project&lt;/a&gt;].&lt;/p&gt; &lt;p&gt;It begins by loading a number of dependencies:&lt;/p&gt; &lt;pre title=""&gt;import nltk from nltk import word_tokenize, sent_tokenize from nltk.corpus import stopwords from nltk.stem.porter import * nltk.download('gutenberg') nltk.download('punkt') nltk.download('stopwords') import string import gensim from gensim.models.phrases import Phraser, Phrases from gensim.models.word2vec import Word2Vec from sklearn.manifold import TSNE import pandas as pd from bokeh.io import output_notebook, output_file from bokeh.plotting import show, figure %matplotlib inline &lt;/pre&gt; &lt;p&gt;Most of these dependencies are from &lt;code&gt;nltk&lt;/code&gt; (the Natural Language Toolkit) and gensim (another natural language library for Python). We explain our use of each individual dependency when we apply it in the example code that follows.&lt;/p&gt; &lt;h2&gt;Tokenization&lt;/h2&gt; &lt;p&gt;The dataset we used in this notebook is a small corpus of out-of-copyright books from Project Gutenberg. [Note: Named after the printing-press inventor Johannes Gutenberg, Project Gutenberg is a source of tens of thousands of electronic books. These books are classic works of literature from across the globe whose copyright has now expired, making them freely available. See &lt;a href="https://www.gutenberg.org/"&gt;gutenberg.org&lt;/a&gt;.]&lt;/p&gt; &lt;p&gt;This corpus is available within nltk so it can be easily loaded using this code:&lt;/p&gt; &lt;pre title=""&gt;from nltk.corpus import gutenberg &lt;/pre&gt; &lt;p&gt;This wee corpus consists of a mere 18 literary works, including Jane Austen’s Emma, Lewis Carroll’s Alice in Wonderland, and three plays by a little-known fellow named William Shakespeare. (Execute &lt;code&gt;gutenberg.fileids()&lt;/code&gt; to print the names of all 18 documents.) By running &lt;code&gt;len(gutenberg.words())&lt;/code&gt;, you can see that the corpus comes out to 2.6 million words—a manageable quantity that means you’ll be able to run all of the code examples in this section on a laptop.&lt;/p&gt; &lt;p&gt;To tokenize the corpus into a list of sentences, one option is to use nltk’s &lt;code&gt;sent_tokenize()&lt;/code&gt; method:&lt;/p&gt; &lt;pre title=""&gt;gberg_sent_tokens = sent_tokenize(gutenberg.raw() &lt;/pre&gt; &lt;p&gt;Accessing the first element of the resulting list by running &lt;code&gt;gberg_sent_tokens[0]&lt;/code&gt;, you can see that the first book in the Project Gutenberg corpus is Emma, because this first element contains the book’s title page, chapter markers, and first sentence, all (erroneously) blended together with newline characters (\n):&lt;/p&gt; &lt;pre&gt;'[Emma by Jane Austen 1816]\n\nVOLUME I\n\nCHAPTER I\n\n\nEmma Wood- house, handsome, clever, and rich, with a comfortable home\nand happy disposition, seemed to unite some of the best blessings\nof existence; and had lived nearly twenty-one years in the world\nwith very little to distress or vex her.'&lt;/pre&gt; &lt;p&gt;A stand-alone sentence is found in the second element, which you can view by executing &lt;code&gt;gberg_sent_tokens[1]&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;"She was the youngest of the two daughters of a most affectionate, \nindulgent father; and had, in consequence of her sister's marriage,\nbeen mistress of his house from a very early period."&lt;/pre&gt; &lt;p&gt;You can further tokenize this sentence down to the word level using nltk’s &lt;code&gt;word_tokenize()&lt;/code&gt; method&lt;/p&gt; &lt;pre title=""&gt;word_tokenize(gberg_sent_tokens[1]) &lt;/pre&gt; &lt;p&gt;This prints a list of words with all whitespace, including newline characters, stripped out (see Figure 11.1). The word &lt;em&gt;father&lt;/em&gt;, for example, is the 15th word in the second sentence, as you can see by running this line of code:&lt;/p&gt; &lt;pre title=""&gt;word_tokenize(gberg_sent_tokens[1])[14] &lt;/pre&gt; &lt;p&gt;Although the &lt;code&gt;sent_tokenize()&lt;/code&gt; and &lt;code&gt;word_tokenize()&lt;/code&gt; methods may come in handy for working with your own natural language data, with this Project Gutenberg corpus, you can instead conveniently employ its built-in &lt;code&gt;sents()&lt;/code&gt; method to achieve the same aims in a single step:&lt;/p&gt; &lt;pre title=""&gt;gberg_sents = gutenberg.sents() &lt;/pre&gt; &lt;p&gt;This command produces &lt;code&gt;gberg_sents&lt;/code&gt;, a tokenized list of lists. The higher-level list consists of individual sentences, and each sentence contains a lower-level list of words within it. Appropriately, the &lt;code&gt;sents()&lt;/code&gt; method also separates the title page and chapter markers into their own individual elements, as you can observe with a call to &lt;code&gt;gberg_sents[0:2]:&lt;/code&gt;&lt;/p&gt; &lt;pre&gt; [['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']'], ['VOLUME', 'I'], ['CHAPTER', 'I']] &lt;/pre&gt; &lt;p&gt;Because of this, the first actual sentence of &lt;em&gt;Emma&lt;/em&gt; is now on its own as the fourth element of &lt;code&gt;gberg_sents&lt;/code&gt;, and so to access the 15th word (father) in the second actual sentence, we now use &lt;code&gt;gberg_sents[4][14]&lt;/code&gt;.&lt;/p&gt; &lt;h2&gt;Converting All Characters to Lowercase&lt;/h2&gt; &lt;p&gt;For the remaining natural language preprocessing steps, we begin by applying them iteratively to a single sentence. As we wrap up the section later on, we’ll apply the steps across the entire 18-document corpus.&lt;/p&gt; &lt;p&gt;Looking back at Figure 11.1, we see that this sentence begins with the capitalized word &lt;em&gt;She&lt;/em&gt;.&lt;/p&gt; &lt;p&gt;&lt;img sizes="(max-width: 790px) 100vw, 790px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_1.png 1160w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_1-300x272.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_1-768x696.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_1-1024x929.png 1024w" height="716" width="790" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_1.png" loading="lazy"&gt;&lt;/p&gt; &lt;p&gt;If we’d like to disregard capitalization so that this word is considered to be identical to &lt;em&gt;she&lt;/em&gt;, then we can use the Python &lt;code&gt;lower()&lt;/code&gt; method from the &lt;code&gt;string&lt;/code&gt; library, as shown in Example 11.1.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example 11.1 Converting a sentence to lowercase&lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt;[w.lower() for w in gberg_sents[4]] &lt;/pre&gt; &lt;p&gt;This line returns the same list as in Figure 11.1 with the exception that the first element in the list is now she instead of &lt;code&gt;She&lt;/code&gt;.&lt;/p&gt; &lt;h2&gt;Removing Stop Words and Punctuation&lt;/h2&gt; &lt;p&gt;Another potential inconvenience with the sentence in Figure 11.1 is that it’s littered with both stop words and punctuation. To handle these, let’s use the &lt;code&gt;+&lt;/code&gt; operator to concatenate together nltk’s list of English stop words with the &lt;code&gt;string&lt;/code&gt; library’s list of punctuation marks:&lt;/p&gt; &lt;pre title=""&gt;stpwrds = stopwords.words('english') + list(string.punctuation) &lt;/pre&gt; &lt;p&gt;If you examine the &lt;code&gt;stpwrds&lt;/code&gt; list that you’ve created, you’ll see that it contains many common words that often don’t contain much particular meaning, such as &lt;em&gt;a&lt;/em&gt;, &lt;em&gt;an&lt;/em&gt;, and &lt;em&gt;the&lt;/em&gt;. [Note These three particular words are called &lt;em&gt;articles&lt;/em&gt;, or &lt;em&gt;determiners&lt;/em&gt;. However, it also contains words like not and other negative words that could be critical if we were building a sentiment classifier, such as in the sentence, “This film was not good.”]&lt;/p&gt; &lt;p&gt;In any event, to remove all of the elements of stpwrds from a sentence we could use a &lt;a href="http://bit.ly/listComp"&gt;list comprehension &lt;/a&gt;as we do in Example 11.2, which incorporates the lowercasing we used in Example 11.1.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example 11.2 Removing stop words and punctuation with a list comprehension&lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt;[w.lower() for w in gberg_sents[4] if w.lower() not in stpwrds] &lt;/pre&gt; &lt;p&gt;Relative to Figure 11.1, running this line of code returns a much shorter list that now contains only words that each tend to convey a fair bit of meaning:&lt;/p&gt; &lt;pre&gt; ['youngest', 'two', 'daughters', 'affectionate', 'indulgent', 'father', 'consequence', 'sister', 'marriage', 'mistress', 'house', 'early', 'period'] &lt;/pre&gt; &lt;h2&gt;Stemming&lt;/h2&gt; &lt;p&gt;To stem words, you can use the Porter algorithm [Note: Porter, M. F. (1980). An algorithm for suffix stripping. Program, 14, 130–7.] provided by nltk. To do this, you create an instance of a &lt;code&gt;PorterStemmer()&lt;/code&gt; object and then add its &lt;code&gt;stem() method&lt;/code&gt; to the list comprehension you began in Example 11.2, as shown in Example 11.3.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example 11.3 Adding word stemming to our list comprehension&lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt;[stemmer.stem(w.lower()) for w in gberg_sents[4] if w.lower() not in stpwrds] &lt;/pre&gt; &lt;p&gt;This outputs the following:&lt;/p&gt; &lt;pre&gt; ['youngest', 'two', 'daughter', 'affection', 'indulg', 'father', 'consequ', 'sister', 'marriag', 'mistress', 'hous', 'earli', 'period'] &lt;/pre&gt; &lt;p&gt;This is similar to our previous output of the sentence except that many of the words have been stemmed:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;em&gt;daughters&lt;/em&gt; to &lt;em&gt;daughter&lt;/em&gt; (allowing the plural and singular terms to be treated identically)&lt;/li&gt; &lt;li&gt;&lt;em&gt;house&lt;/em&gt; to &lt;em&gt;hous&lt;/em&gt; (allowing related words like &lt;em&gt;house&lt;/em&gt; and &lt;em&gt;housing&lt;/em&gt; to be treated as the same)&lt;/li&gt; &lt;li&gt;&lt;em&gt;early&lt;/em&gt; to &lt;em&gt;earli&lt;/em&gt; (allowing differing tenses such as &lt;em&gt;early&lt;/em&gt;, &lt;em&gt;earlier&lt;/em&gt;, and &lt;em&gt;earliest&lt;/em&gt; to be treated as the same)&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;These stemming examples may be advantageous with a corpus as small as ours, because there are relatively few examples of any given word. By pooling similar words together, we obtain more occurrences of the pooled version, and so it may be assigned to a more accurate location in vector space (Figure 2.6). With a very large corpus, however, where you have many more examples of rarer words, there might be an advantage to treating plural and singular variations on a word differently, treating related words as unique, and retaining multiple tenses; the nuances could prove to convey valuable meaning.&lt;/p&gt; &lt;h2&gt;Handling &lt;em&gt;n&lt;/em&gt;-grams&lt;/h2&gt; &lt;p&gt;To treat a bigram like &lt;em&gt;New York&lt;/em&gt; as a single token instead of two, we can use the &lt;code&gt;Phrases()&lt;/code&gt; and &lt;code&gt;Phraser()&lt;/code&gt; methods from the gensim library. As demonstrated in Example 11.4, we use them in this way:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;code&gt;Phrases()&lt;/code&gt; to train a “detector” to identify how often any given pair of words occurs together in our corpus (the technical term for this is &lt;em&gt;bigram collocation&lt;/em&gt;) relative to how often each word in the pair occurs by itself&lt;/li&gt; &lt;li&gt;&lt;code&gt;Phraser()&lt;/code&gt;&lt;span&gt; to take the bigram collocations detected by the &lt;code&gt;Phrases()&lt;/code&gt; object and then use this information to create an object that can efficiently be passed over our corpus, converting all bigram collocations from two consecutive tokens into a single token&lt;/span&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&lt;strong&gt;Example 11.4 Detecting collocated bigrams&lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt;phrases = Phrases(gberg_sents) bigram = Phraser(phrases) &lt;/pre&gt; &lt;p&gt;By running &lt;code&gt;bigram.phrasegrams&lt;/code&gt;, we output a dictionary of the count and &lt;em&gt;score&lt;/em&gt; of each bigram. The topmost lines of this dictionary are provided in Figure 11.2.&lt;/p&gt; &lt;p&gt;Each bigram in Figure 11.2 has a count and a score associated with it. The bigram &lt;em&gt;two daughters&lt;/em&gt;, for example, occurs a mere 19 times across our Gutenberg corpus. This bigram has a fairly low score (12.0), meaning the terms &lt;em&gt;two&lt;/em&gt; and &lt;em&gt;daughters&lt;/em&gt; do not occur together very frequently relative to how often they occur apart. In contrast, the bigram Miss Taylor occurs more often (48 times), and the terms &lt;em&gt;Miss&lt;/em&gt; and &lt;em&gt;Taylor&lt;/em&gt; occur much more frequently together relative to how often they occur on their own (score of 453.8).&lt;/p&gt; &lt;p&gt;&lt;img sizes="(max-width: 635px) 100vw, 635px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_2.png 1002w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_2-300x189.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_2-768x484.png 768w" height="401" width="635" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_2.png" loading="lazy"&gt;Scanning over the bigrams in Figure 11.2, notice that they are marred by capitalized words and punctuation marks. We’ll resolve those issues in the next section, but in the meantime let’s explore how the &lt;code&gt;bigram&lt;/code&gt; object we’ve created can be used to convert bigrams from two consecutive tokens into one. Let’s tokenize a short sentence by using the &lt;code&gt;split()&lt;/code&gt; method on a string of characters wherever there’s a space, as follows:&lt;/p&gt; &lt;pre title=""&gt;tokenized_sentence = "Jon lives in New York City".split() &lt;/pre&gt; &lt;p&gt;If we print &lt;code&gt;tokenized_sentence&lt;/code&gt;, we output a list of unigrams only: &lt;code&gt;['Jon', 'lives', 'in', 'New', 'York', 'City']&lt;/code&gt;. If, however, we pass the list through our gensim bigram object by using &lt;code&gt;bigram[tokenized_sentence]&lt;/code&gt;, the list then contains the bigram &lt;em&gt;New York&lt;/em&gt;: &lt;code&gt;['Jon', 'lives', 'in', 'New_York', 'City']&lt;/code&gt;.&lt;/p&gt; &lt;pre&gt;After you’ve identified bigrams across your corpus by running it through the bigram object, you can detect trigrams (such as &lt;em&gt;New York Cit&lt;/em&gt;y) by passing this new, bigram-filled corpus through the &lt;code&gt;Phrases()&lt;/code&gt; and &lt;code&gt;Phraser()&lt;/code&gt; methods. This could be repeated again to identify 4-grams (and then again to identify 5-grams, and so on); however, there are diminishing returns from this. Bigrams (or at most trigrams) should suffice for the majority of applications. By the way, if you go ahead and detect trigrams with the Project Gutenberg corpus, &lt;em&gt;New York City&lt;/em&gt; is unlikely to be detected. Our corpus of classic literature doesn’t mention it often enough.&lt;/pre&gt; &lt;h2&gt;Preprocessing the Full Corpus&lt;/h2&gt; &lt;p&gt;Having run through some examples of preprocessing steps on individual sentences, we now compose some code to preprocess the entire Project Gutenberg corpus. This will also enable us to collocate bigrams on a cleaned-up corpus that no longer contains capital letters or punctuation.&lt;/p&gt; &lt;p&gt;Later on in this chapter, we’ll use a corpus of film reviews that was curated by Andrew Maas and his colleagues at Stanford University to predict the sentiment of the reviews with NLP models. [Note: Maas, A., et al. (2011). Learning word vectors for sentiment analysis. Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, 142–50.] During their data preprocessing steps, Maas and his coworkers decided to leave in stop words because they are “indicative of sentiment.” [Note: This is in line with our thinking, as we mentioned earlier in the chapter.] They also decided not to stem words because they felt their corpus was sufficiently large that their word-vector-based NLP model “learns similar representations of words of the same stem when the data suggest it.” Said another way, words that have a similar meaning should find their way to a similar location in word-vector space (Figure 2.6) [&lt;a href="http://www.informit.com/store/deep-learning-illustrated-a-visual-interactive-guide-9780135116692?utm_source=Referral&amp;amp;utm_medium=DominoLabs&amp;amp;utm_campaign=Krohn&amp;amp;utm_term=DLBook"&gt;in the book&lt;/a&gt;] during model training.&lt;/p&gt; &lt;p&gt;Following their lead, we’ll also forgo stop-word removal and stemming when preprocessing the Project Gutenberg corpus, as in Example 11.5.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example 11.5 Removing capitalization and punctuation from Project Gutenberg corpus&lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt;lower_sents = [] for s in gberg_sents: lower_sents.append([w.lower() for w in s if w.lower() not in list(string.punctuation)]) &lt;/pre&gt; &lt;p&gt;In this example, we begin with an empty list we call &lt;code&gt;lower_sents&lt;/code&gt;, and then we append preprocessed sentences to it using a for loop. [Note: If you’re preprocessing a large corpus, we’d recommend using optimizable and parallelizable functional program- ming techniques in place of our simple (and therefore simple-to-follow) for loop.] For preprocessing each sentence within the loop, we used a variation on the list comprehension from Example 11.2, in this case removing only punctuation marks while converting all characters to lowercase.&lt;/p&gt; &lt;p&gt;With punctuation and capitals removed, we can set about detecting collocated bigrams across the corpus afresh:&lt;/p&gt; &lt;pre title=""&gt;lower_bigram = Phraser(Phrases(lower_sents)) &lt;/pre&gt; &lt;p&gt;Relative to Example 11.4, this time we created our gensim lower_bigram object in a single line by chaining the &lt;code&gt;Phrases()&lt;/code&gt; and &lt;code&gt;Phraser()&lt;/code&gt; methods together. The top of the output of a call to &lt;code&gt;lower_bigram.phrasegrams&lt;/code&gt; is provided in Figure 11.3: Comparing these bigrams with those from Figure 11.2, we do indeed observe that they are all in lowercase (e.g., &lt;em&gt;miss taylor&lt;/em&gt;) and bigrams that included punctuation marks are nowhere to be seen.&lt;/p&gt; &lt;p&gt;&lt;img sizes="(max-width: 653px) 100vw, 653px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_3.png 1028w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_3-300x193.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_3-768x493.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_3-1024x657.png 1024w" height="420" width="653" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_3.png" loading="lazy"&gt;&lt;/p&gt; &lt;p&gt;Examining the results in Figure 11.3 further, however, it appears that the default minimum thresholds for both count and score are far too liberal. That is, word pairs like &lt;em&gt;two daughters&lt;/em&gt; and &lt;em&gt;her sister&lt;/em&gt; should not be considered bigrams. To attain bigrams that we thought were more sensible, we experimented with more conservative count and score thresholds by increasing them by powers of 2. Following this approach, we were generally satisfied by setting the optional &lt;code&gt;Phrases()&lt;/code&gt; arguments to a &lt;em&gt;min(imum) count&lt;/em&gt; of 32 and to a score &lt;em&gt;threshold&lt;/em&gt; of 64, as shown in Example 11.6.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example 11.6 Detecting collocated bigrams with more conservative thresholds&lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt;lower_bigram = Phraser(Phrases(lower_sents, min_count=32, threshold=64)) &lt;/pre&gt; &lt;p&gt;Although it’s not perfect, [Note: These are statistical approximations, of course!] because there are still a few questionable bigrams like &lt;em&gt;great deal&lt;/em&gt; and &lt;em&gt;few minutes&lt;/em&gt;, the output from a call to &lt;code&gt;lower_bigram.phrasegrams&lt;/code&gt; is now largely defensible, as shown in Figure 11.4.&lt;/p&gt; &lt;p&gt;&lt;img sizes="(max-width: 738px) 100vw, 738px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_4.png 1062w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_4-300x166.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_4-768x425.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_4-1024x567.png 1024w" height="408" width="738" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_4.png" loading="lazy"&gt;&lt;/p&gt; &lt;p&gt;Armed with our well-appointed &lt;code&gt;lower_bigram&lt;/code&gt; object from Example 11.6, we can at last use a for loop to iteratively append for ourselves a corpus of cleaned-up sentences, as in Example 11.7.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example 11.7 Creating a “clean” corpus that includes bigrams&lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt;clean_sents = [] for s in lower_sents: clean_sents.append(lower_bigram[s]) &lt;/pre&gt; &lt;p&gt;&lt;img sizes="(max-width: 808px) 100vw, 808px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_5.png 1074w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_5-300x212.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_5-768x542.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_5-1024x723.png 1024w" height="570" width="808" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_5.png" loading="lazy"&gt;&lt;/p&gt; &lt;p&gt;&lt;img sizes="(max-width: 710px) 100vw, 710px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_6.png 1070w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_6-300x133.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_6-768x342.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_6-1024x456.png 1024w" height="316" width="710" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_6.png" loading="lazy"&gt;&lt;/p&gt; &lt;h2&gt;Creating Word Embeddings with word2vec&lt;/h2&gt; &lt;p&gt;With the cleaned corpus of natural language clean_sents now available to us, we are well positioned to embed words from the corpus into word-vector space (Figure 2.6). As you’ll see in this section, such word embeddings can be produced with a single line of code. This single line of code, however, should not be executed blindly, and it has quite a few optional arguments to consider carefully. Given this, we’ll cover the essential theory behind word vectors before delving into example code.&lt;/p&gt; &lt;h2&gt;The Essential Theory Behind word2vec&lt;/h2&gt; &lt;p&gt;In Chapter 2, we provided an intuitive understanding of what word vectors are. We also discussed the underlying idea that because you can “know a word by the company it keeps” then a given word’s meaning can be well represented as the average of the words that tend to occur around it. word2vec is an unsupervised learning technique—that is, it is applied to a corpus of natural language without making use of any labels that may or may not happen to exist for the corpus. This means that any dataset of natural language could be appropriate as an input to word2vec. [Note: Mikolov, T., et al. (2013). Efficient estimation of word representations in vector space. arXiv:1301.3781]&lt;/p&gt; &lt;p&gt;When running word2vec, you can choose between two underlying model architectures—&lt;em&gt;skip-gram &lt;/em&gt;(SG) or continuous bag of words (CBOW; pronounced see-bo)— either of which will typically produce roughly comparable results despite maximizing probabilities from “opposite” perspectives. To make sense of this, reconsider our toy-sized corpus from Figure 2.5:&lt;/p&gt; &lt;pre&gt; you shall know a word by the company it keeps&lt;/pre&gt; &lt;p&gt;In it, we are considering word to be the &lt;em&gt;target&lt;/em&gt; word, and the three words to the right of it as well as the three words to the left of it are considered to be context words. (This corresponds to a window size of three words—one of the primary hyperparameters we must take into account when applying word2vec.) With the SG architecture, context words are predicted given the target word. [Note: In more technical machine learning terms, the cost function of the skip-gram architecture is to maximize the log probability of any possible context word from a corpus given the current target word.] With CBOW, it is the inverse: The target word is predicted based on the context words. [Note: Again, in technical ML jargon, the cost function for CBOW is maximizing the log probability of any possible target word from a corpus given the current context words. ]&lt;/p&gt; &lt;p&gt;To understand word2vec more concretely, let’s focus on the CBOW architecture in greater detail (although we equally could have focused on SG instead). With CBOW, the target word is predicted to be the average of all the context words considered &lt;em&gt;jointly&lt;/em&gt;. “Jointly” means “all at once”: The particular position of context words isn’t taken into consideration, nor whether the context word occurs before or after the target word. That the CBOW architecture has this attribute is right there in the “bag of words” part of its name:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;We take all the context words within the windows to the right and the left of the target word.&lt;/li&gt; &lt;li&gt;We (figuratively!) throw all of these context words into a bag. If it helps you remember that the sequence of words is irrelevant, you can even imagine shaking up the bag.&lt;/li&gt; &lt;li&gt;We calculate the average of all the context words contained in the bag, using this average to estimate what the target word could be.&lt;/li&gt; &lt;/ul&gt; &lt;pre&gt;If we were concerned about syntax—the grammar of language (see Figure 2.9 for a refresher on the elements of natural language)—then word order would matter. But because with word2vec we’re concerned only with semantics—the &lt;em&gt;meaning&lt;/em&gt; of words— it turns out that the order of context words is, on average, irrelevant.&lt;/pre&gt; &lt;p&gt;Having considered the intuitiveness of the “BOW” component of the CBOW moniker, let’s also consider the “continuous” part of it: The target word and context word windows slide &lt;em&gt;continuously&lt;/em&gt; one word at a time from the first word of the corpus all the way through to the final word. At each position along the way, the target word is estimated given the context words. Via stochastic gradient descent, the location of words within vector space can be shifted, and thereby these target-word estimates can gradually be improved.&lt;/p&gt; &lt;p&gt;&lt;img sizes="(max-width: 841px) 100vw, 841px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_1.png 1102w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_1-300x85.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_1-768x219.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_1-1024x292.png 1024w" height="240" width="841" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_1.png" loading="lazy"&gt;&lt;/p&gt; &lt;p&gt;In practice, and as summarized in Table 11.1, the SG architecture is a better choice when you’re working with a small corpus. It represents rare words in word-vector space well. In contrast, CBOW is much more computationally efficient, so it is the better option when you’re working with a very large corpus. Relative to SG, CBOW also represents frequently occurring words slightly better. [Note: Regardless of whether you use the SG or CBOW architecture, an additional option you have while running word2vec is the training method. For this, you have two different options: &lt;em&gt;hierarchical softmax&lt;/em&gt; and &lt;em&gt;negative sampling&lt;/em&gt;. The former involves normalization and is better suited to rare words. The latter, on the other hand, forgoes normalization, making it better suited to common words and low-dimensional word-vector spaces. For our purposes in this book, the differences between these two training methods are insignificant and we don’t cover them further.]&lt;/p&gt; &lt;pre&gt;Although word2vec is comfortably the most widely used approach for embedding words from a corpus of natural language into vector space, it is by no means the only approach. A major alternative to word2vec is GloVe—global vectors for word representation—which was introduced by the prominent natural language researchers Jeffrey Pennington, Richard Socher, and Christopher Manning. [Note: 15. Pennington, J., et al. (2014). GloVe: Global vectors for word representations. &lt;em&gt;Proceedings of the Conference on Empirical Methods in Natural Language Processing&lt;/em&gt;.] At the time—in 2014—the three were colleagues working together at Stanford University. GloVe and word2vec differ in their underlying methodology: word2vec uses predictive models, while GloVe is count based. Ultimately, both approaches tend to pro- duce vector-space embeddings that perform similarly in downstream NLP applications, with some research suggesting that word2vec may provide modestly better results in select cases. One potential advantage of GloVe is that it was designed to be parallelized over multiple processors or even multiple machines, so it might be a good option if you’re looking to create a word-vector space with many unique words and a very large corpus. The contemporary leading alternative to both word2vec and GloVe is fastText. [Note: The open-source fastText library is available at fasttext.cc. Joulin, A., et al. (2016). Bag of tricks for efficient text classification. arXiv: 1607.01759. Bojanowski, P., et al. (2016). Enriching word vectors with subword information. arXiv: 1607.04606. Note that the lead author of the landmark word2vec paper, Tomas Mikolov, is the final author of both of these landmark fastText papers.] This approach was developed by researchers at Facebook. A major benefit of fastText is that it operates on a subword level—its “word” vectors are actually subcomponents of words. This enables fastText to work around some of the issues related to rare words and out-of-vocabulary words addressed in the preprocessing section at the outset of this chapter.&lt;/pre&gt; &lt;h2&gt;Evaluating Word Vectors&lt;/h2&gt; &lt;p&gt;However you create your word vectors—be it with word2vec or an alternative approach—there are two broad perspectives you can consider when evaluating the quality of word vectors: &lt;em&gt;intrinsic&lt;/em&gt; and &lt;em&gt;extrinsic&lt;/em&gt; evaluations.&lt;/p&gt; &lt;p&gt;Extrinsic evaluations involve assessing the performance of your word vectors within whatever your downstream NLP application of interest is—your sentiment-analysis classifier, say, or perhaps your named-entity recognition tool. Although extrinsic evaluations can take longer to carry out because they require you to carry out all of your downstream processing steps—including perhaps training a computationally intensive deep learning model—you can be confident that it’s worthwhile to retain a change to your word vectors if they relate to an appreciable improvement in the accuracy of your NLP application.&lt;/p&gt; &lt;p&gt;In contrast, intrinsic evaluations involve assessing the performance of your word vectors not on your final NLP application, but rather on some specific intermediate sub- task. One common such task is assessing whether your word vectors correspond well to arithmetical analogies like those shown in Figure 2.7. For example, if you start at the word-vector location for king, subtract &lt;code&gt;man&lt;/code&gt;, and &lt;code&gt;add woman&lt;/code&gt;, do you end up near the word-vector location for queen? [Note: A test set of 19,500 such analogies was developed by Tomas Mikolov and his colleagues in their 2013 word2vec paper. This test set is available at &lt;a href="http://download.tensorflow.org/data/questions-words.txt"&gt;download.tensorflow.org/data/questions-words.txt&lt;/a&gt;.]&lt;/p&gt; &lt;p&gt;Relative to extrinsic evaluations, intrinsic tests are quick. They may also help you better understand (and therefore troubleshoot) intermediate steps within your broader NLP process. The limitation of intrinsic evaluations, however, is that they may not ultimately lead to improvements in the accuracy of your NLP application downstream unless you’ve identified a reliable, quantifiable relationship between performance on the intermediate test and your NLP application.&lt;/p&gt; &lt;h2&gt;Running word2vec&lt;/h2&gt; &lt;p&gt;As mentioned earlier, and as shown in Example 11.8, word2vec can be run in a single line of code—albeit with quite a few arguments.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example 11.8 Running word2vec&lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt; model = Word2Vec(sentences=clean_sents, size=64, sg=1, window=10, iter=5, min_count=10, workers=4) &lt;/pre&gt; &lt;p&gt;Here’s a breakdown of each of the arguments we passed into the Word2Vec() method&lt;br&gt; from the gensim library:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;sentences&lt;/code&gt;: Pass in a list of lists like clean_sents as a corpus. Elements in the higher-level list are sentences, whereas elements in the lower-level list can be word- level tokens.&lt;/li&gt; &lt;li&gt;&lt;code&gt;size&lt;/code&gt;: The number of dimensions in the word-vector space that will result from running word2vec. This is a hyperparameter that can be varied and evaluated extrinsically or intrinsically. Like other hyperparameters in this book, there is a Goldilocks sweet spot. You can home in on an optimal value by specifying, say, 32 dimensions and varying this value by powers of 2. Doubling the number of dimensions will double the computational complexity of your downstream deep learning model, but if doing this results in markedly higher model accuracy then this extrinsic evaluation suggests that the extra complexity could be worthwhile. On the other hand, halving the number of dimensions halves computational complexity downstream: If this can be done without appreciably decreasing your NLP model’s accuracy, then it should be. By performing a handful of intrinsic inspections (which we’ll go over shortly), we found 64 dimensions to provide more sensible word vectors than 32 dimensions for this particular case. Doubling this figure to 128, however, provided no noticeable improvement.&lt;/li&gt; &lt;li&gt;&lt;code&gt;sg&lt;/code&gt;: Set to 1 to choose the skip-gram architecture, or leave at the 0 default to choose CBOW. As summarized in Table 11.1, SG is generally better suited to small datasets like our Gutenberg corpus.&lt;/li&gt; &lt;li&gt;&lt;code&gt;window&lt;/code&gt;: For SG, a window size of 10 (for a total of 20 context words) is a good bet, so we set this hyperparameter to 10. If we were using CBOW, then a window size of 5 (for a total of 10 context words) could be near the optimal value. In either case, this hyperparameter can be experimented with and evaluated extrinsically or intrinsically. Small adjustments to this hyperparameter may not be perceptibly impactful, however.&lt;/li&gt; &lt;li&gt;&lt;code&gt;iter&lt;/code&gt;: By default, the gensim &lt;code&gt;Word2Vec()&lt;/code&gt; method iterates over the corpus fed into it (i.e., slides over all of the words) five times. Multiple iterations of word2vec is analogous to multiple epochs of training a deep learning model. With a small corpus like ours, the word vectors improve over several iterations. With a very large corpus, on the other hand, it might be cripplingly computationally expensive to run even two iterations—and, because there are so many examples of words in a very large corpus anyway, the word vectors might not be any better.&lt;/li&gt; &lt;li&gt;&lt;code&gt;min_count&lt;/code&gt;: This is the minimum number of times a word must occur across the corpus in order to fit it into word-vector space. If a given target word occurs only once or a few times, there are a limited number of examples of its contextual words to consider, and so its location in word-vector space may not be reliable. Because of this, a minimum count of about 10 is often reasonable. The higher the count, the smaller the vocabulary of words that will be available to your downstream NLP task. This is yet another hyperparameter that can be tuned, with extrinsic evaluations likely being more illuminating than intrinsic ones because the size of the vocabulary you have to work with could make a considerable impact on your downstream NLP application.&lt;/li&gt; &lt;li&gt;&lt;code&gt;workers&lt;/code&gt;: This is the number of processing cores you’d like to dedicate to training. If the CPU on your machine has, say, eight cores, then eight is the largest number of parallel worker threads you can have. In this case, if you choose to use fewer than eight cores, you’re leaving compute resources available for other tasks.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;In our GitHub repository, we saved our model using the save() method of word2vec objects:&lt;/p&gt; &lt;pre title=""&gt;model.save('clean_gutenberg_model.w2v') &lt;/pre&gt; &lt;p&gt;Instead of running word2vec yourself, then, you’re welcome to load up our word vectors&lt;br&gt; using this code:&lt;/p&gt; &lt;pre title=""&gt;model = gensim.models.Word2Vec.load('clean_gutenberg_model.w2v') &lt;/pre&gt; &lt;p&gt;If you do choose the word vectors we created, then the following examples will produce the same outputs. [Note: Every time word2vec is run, the initial locations of every word of the vocabulary within word-vector space are assigned randomly. Because of this, the same data and arguments provided to &lt;em&gt;Word2Vec()&lt;/em&gt; will nevertheless produce unique word vectors every time, but the semantic relationships should be similar.] We can see the size of our vocabulary by calling &lt;code&gt;len(model.wv.vocab)&lt;/code&gt;. This tells us that there are 10,329 words (well, more specifically, tokens) that occur at least 10 times within our clean_sents corpus. [Note: Vocabulary size is equal to the number of tokens from our corpus that had occurred at least 10 times, because we set &lt;code&gt;min_count=10&lt;/code&gt; when calling &lt;code&gt;Word2Vec()&lt;/code&gt; in Example 11.8.] One of the words in our vocabulary is dog. As shown in Figure 11.6, we can output its location in 64-dimensional word-vector space by running &lt;code&gt;model.wv['dog']&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;&lt;img sizes="(max-width: 793px) 100vw, 793px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_6-1.png 1070w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_6-1-300x133.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_6-1-768x342.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_6-1-1024x456.png 1024w" height="353" width="793" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_6-1.png" loading="lazy"&gt;&lt;/p&gt; &lt;p&gt;As a rudimentary intrinsic evaluation of the quality of our word vectors, we can use the most_similar() method to confirm that words with similar meanings are found in similar locations within our word-vector space. [Note: Technically speaking, the similarity between two given words is computed here by calculating the cosine similarity.] For example, to output the three words that are most similar to father in our word-vector space, we can run this code:&lt;/p&gt; &lt;pre title=""&gt;model.wv.most_similar('father', topn=3) &lt;/pre&gt; &lt;p&gt;This outputs the following:&lt;/p&gt; &lt;pre title=""&gt; [('mother', 0.8257375359535217), ('brother', 0.7275018692016602), ('sister', 0.7177823781967163)] &lt;/pre&gt; &lt;p&gt;This output indicates that &lt;em&gt;mother&lt;/em&gt;,&lt;em&gt; brother&lt;/em&gt;, and &lt;em&gt;sister&lt;/em&gt; are the most similar words to father in our word-vector space. In other words, within our 64-dimensional space, the word that is closest. [Note: That is, has the shortest Euclidean distance in that 64-dimensional vector space.] to father is the word mother. Table 11.2 provides some additional examples of the words most similar to (i.e., closest to) particular words that we’ve picked from our word- vector vocabulary, all five of which appear pretty reasonable given our small Gutenberg corpus. [Note that the final test word in Table 11.2—ma’am—is only available because of the bigram collocation (see Examples 11.6 and 11.7).]&lt;/p&gt; &lt;p&gt;Suppose we run the following line of code:&lt;/p&gt; &lt;pre title=""&gt; model.wv.doesnt_match("mother father sister brother dog".split()) &lt;/pre&gt; &lt;p&gt;We get the output dog, indicating that dog is the least similar relative to all the other possible word pairs. We can also use the following line to observe that the similarity score between father and dog is a mere 0.44:&lt;/p&gt; &lt;pre title=""&gt; model.wv.similarity('father', 'dog') &lt;/pre&gt; &lt;p&gt;&lt;img sizes="(max-width: 656px) 100vw, 656px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_2.png 994w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_2-300x109.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_2-768x280.png 768w" height="239" width="656" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_2.png" loading="lazy"&gt;&lt;/p&gt; &lt;p&gt;This similarity score of 0.44 is much lower than the similarity between &lt;em&gt;father&lt;/em&gt; and any of &lt;em&gt;mother, brother&lt;/em&gt;, or &lt;em&gt;sister,&lt;/em&gt; and so it’s unsurprising that &lt;em&gt;dog&lt;/em&gt; is relatively distant from the other four words within our word-vector space.&lt;/p&gt; &lt;p&gt;As a final little intrinsic test, we can compute word-vector analogies as in Figure 2.7. For example, to calculate&lt;/p&gt; &lt;p&gt;&lt;img height="54" width="227" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-EQ-1.png" loading="lazy"&gt;&lt;/p&gt; &lt;p&gt;we can execute this code:&lt;/p&gt; &lt;pre title=""&gt;model.wv.most_similar(positive=['father', 'woman'], negative=['man']) &lt;/pre&gt; &lt;p&gt;The top-scoring word comes out as mother, which is the correct answer to the analogy.&lt;/p&gt; &lt;p&gt;Suppose we likewise execute this code:&lt;/p&gt; &lt;pre title=""&gt;model.wv.most_similar(positive=['husband', 'woman'], negative=['man']) &lt;/pre&gt; &lt;p&gt;In this case, the top-scoring word comes out as wife, again the correct answer, thereby&lt;br&gt; suggesting that our word-vector space may generally be on the right track.&lt;/p&gt; &lt;pre&gt;A given dimension within an n-dimensional word-vector space does not necessarily represent any specific factor that relates words. For example, although the real-world differences in meaning of gender or verb tense are represented by some vector direction (i.e., some movement along some combination of dimensions) within the vector space, this meaningful vector direction may only by chance be aligned—or perhaps correlated—with a particular axis of the vector space. This contrasts with some other approaches that involve n-dimensional vector spaces, where the axes are intended to represent some specific explanatory variable. One such approach that many people are familiar with is principal component anal- ysis (PCA), a technique for identifying linearly uncorrelated (i.e., orthogonal) vectors that contribute to variance in a given dataset. A corollary of this difference between information stored as points in PCA versus in word-vector space is that in PCA, the first principal components contribute most of the variance, and so you can focus on them and ignore later principal components; but in a word-vector space, all of the dimensions may be important and need to be taken into consideration. In this way, approaches like PCA are useful for dimensionality reduction because we do not need to consider all of the dimensions. &lt;/pre&gt; &lt;h2&gt;Plotting Word Vectors&lt;/h2&gt; &lt;p&gt;Human brains are not well suited to visualizing anything in greater than three dimensions. Thus, plotting word vectors—which could have dozens or even hundreds of dimensions—in their native format is out of the question. Thankfully, we can use techniques for dimensionality reduction to approximately map the locations of words from high- dimensional word-vector space down to two or three dimensions. Our recommended approach for such dimensionality reduction is &lt;em&gt;t-distributed stochastic neighbor embedding&lt;/em&gt; (t-SNE; pronounced tee-snee), which was developed by Laurens van der Maaten in col- laboration with Geoff Hinton (Figure 1.16). [Note: van der Maaten, L., &amp;amp; Hinton, G. (2008). Visualizing data using t-SNE. Journal of Machine Learning Research, 9, 2579–605.]&lt;/p&gt; &lt;p&gt;Example 11.9 provides the code from our &lt;em&gt;Natural Language Preprocessing&lt;/em&gt; notebook for reducing our 64-dimensional Project Gutenberg-derived word-vector space down to two dimensions, and then storing the resulting &lt;em&gt;x&lt;/em&gt; and &lt;em&gt;y&lt;/em&gt; coordinates within a Pandas DataFrame. There are two arguments for the &lt;code&gt;TSNE()&lt;/code&gt; method (from the &lt;em&gt;scikit-learn &lt;/em&gt;library) that we need to focus on:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;n_components&lt;/code&gt; is the number of dimensions that should be returned, so setting this to 2 results in a two-dimensional output, whereas 3 would result in a three- dimensional output.&lt;/li&gt; &lt;li&gt;&lt;code&gt;n_iter &lt;/code&gt;is the number of iterations over the input data. As with word2vec (Example 11.8), iterations are analogous to the epochs associated with training a neural network. More iterations corresponds to a longer training time but may improve the results (although only up to a point).&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Example 11.9 t-SNE for dimensionality reduction&lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt; tsne = TSNE(n_components=2, n_iter=1000) X_2d = tsne.fit_transform(model.wv[model.wv.vocab]) coords_df = pd.DataFrame(X_2d, columns=['x','y']) coords_df['token'] = model.wv.vocab.keys() &lt;/pre&gt; &lt;p&gt;Running t-SNE as in Example 11.9 may take some time on your machine, so you’re welcome to use our results if you’re feeling impatient by running the following code:&lt;/p&gt; &lt;pre title=""&gt;coords_df = pd.read_csv('clean_gutenberg_tsne.csv') &lt;/pre&gt; &lt;p&gt;[Note: We created this CSV after running t-SNE on our word-vectors using this command: &lt;code&gt;coords_df.to_csv('clean_gutenberg_tsne.csv'&lt;/code&gt;, &lt;code&gt;index=False&lt;/code&gt;). Note that because t-SNE is stochastic, you will obtain a unique result every time you run it.]&lt;/p&gt; &lt;p&gt;Whether you ran t-SNE to produce &lt;code&gt;coords_df&lt;/code&gt; on your own or you loaded in ours, you can check out the first few lines of the DataFrame by using the &lt;code&gt;head() method&lt;/code&gt;:&lt;/p&gt; &lt;pre title=""&gt;coords_df.head() &lt;/pre&gt; &lt;p&gt;Our output from executing head() is shown in Figure 11.7. Example 11.10 provides code for creating a static scatterplot (Figure 11.8) of the two-dimensional data we created with t-SNE (in Example 11.9).&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example 11.10 Static two-dimensional scatterplot of word-vector space&lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt;_ = coords_df.plot.scatter('x', 'y', figsize=(12,12), marker='.', s=10, alpha=0.2) &lt;/pre&gt; &lt;p&gt;&lt;img sizes="(max-width: 692px) 100vw, 692px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_7.png 1054w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_7-300x129.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_7-768x329.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_7-1024x439.png 1024w" height="297" width="692" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_7.png" loading="lazy"&gt;&lt;/p&gt; &lt;p&gt;&lt;img sizes="(max-width: 583px) 100vw, 583px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_8.png 964w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_8-291x300.png 291w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_8-768x792.png 768w" height="602" width="583" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_8.png" loading="lazy"&gt;&lt;/p&gt; &lt;p&gt;On its own, the scatterplot displayed in Figure 11.8 may look interesting, but there’s little actionable information we can take away from it. Instead, we recommend using the &lt;em&gt;bokeh&lt;/em&gt; library to create a highly interactive—and actionable—plot, as with the code provided in Example 11.11. [Note: In Example 11.11, we used the Pandas sample() method to reduce the dataset down to 5,000 tokens, because we found that using more data than this corresponded to a clunky user experience when using the bokeh plot interactively.]&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example 11.11 Interactive bokeh plot of two-dimensional word-vector data&lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt; output_notebook() subset_df = coords_df.sample(n=5000) p = figure(plot_width=800, plot_height=800) _ = p.text(x=subset_df.x, y=subset_df.y, text=subset_df.token) show(p) &lt;/pre&gt; &lt;p&gt;The code in Example 11.11 produces the interactive scatterplot in Figure 11.9 using the &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; coordinates generated using t-SNE.&lt;/p&gt; &lt;p&gt;&lt;img sizes="(max-width: 610px) 100vw, 610px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_9.png 892w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_9-280x300.png 280w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_9-768x823.png 768w" height="655" width="610" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_9.png" loading="lazy"&gt;&lt;/p&gt; &lt;p&gt;&lt;img sizes="(max-width: 753px) 100vw, 753px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_10.png 1102w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_10-300x293.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_10-768x751.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_10-1024x1002.png 1024w" height="737" width="753" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_10.png" loading="lazy"&gt;&lt;/p&gt; &lt;p&gt;By toggling the &lt;em&gt;Wheel Zoom&lt;/em&gt; button in the top-right corner of the plot, you can use your mouse to zoom into locations within the cloud so that the words become legible. For example, as shown in Figure 11.10, we identified a region composed largely of items of clothing, with related clusters nearby, including parts of the human anatomy, colors, and fabric types. Exploring in this way provides a largely subjective intrinsic evaluation of whether related terms—and particularly synonyms—cluster together as you’d expect them to. Doing similar, you may also notice particular shortcomings of your natural-language preprocessing steps, such as the inclusion of punctuation marks, bigrams, or other tokens that you may prefer weren’t included within your word-vector vocabulary.&lt;/p&gt; &lt;h2&gt;The Area under the ROC Curve&lt;/h2&gt; &lt;p&gt;Our apologies for interrupting the fun, interactive plotting of word vectors. We need to take a brief break from natural language-specific content here to introduce a metric that will come in handy in the next section of the chapter, when we will evaluate the performance of deep learning NLP models.&lt;/p&gt; &lt;p&gt;Up to this point in the book, most of our models have involved multiclass outputs: When working with the MNIST digits, for example, we used 10 output neurons to rep- resent each of the 10 possible digits that an input image could represent. In the remaining sections of this chapter, however, our deep learning models will be &lt;em&gt;binary classifiers&lt;/em&gt;: They will distinguish between only two classes. More specifically, we will build binary classifiers to predict whether the natural language of film reviews corresponds to a favorable review or negative one.&lt;/p&gt; &lt;p&gt;Unlike artificial neural networks tasked with multiclass problems, which require as many output neurons as classes, ANNs that are acting as binary classifiers require only a single output neuron. This is because there is no extra information associated with having two output neurons. If a binary classifier is provided some input x and it calculates some output &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; for one of the classes, then the output for the other class is simply 1 – &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt;. As an example, if we feed a movie review into a binary classifier and it outputs that the probability that this review is a positive one is 0.85, then it must be the case that the probability of the review being negative is 1 − 0.85 = 0.15.&lt;/p&gt; &lt;p&gt;Because binary classifiers have a single output, we can take advantage of metrics for evaluating our model’s performance that are sophisticated relative to the excessively black-and-white accuracy metric that dominates multiclass problems. A typical accuracy calculation, for example, would contend that if &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; &amp;gt; 0.5 then the model is predicting that the input x belongs to one class, whereas if it outputs anything less than 0.5, it belongs to the other class. To illustrate why having a specific binary threshold like this is overly simplistic, consider a situation where inputting a movie review results in a binary classifier outputting &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; = 0.48: A typical accuracy calculation threshold would hold that—because this &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; is lower than 0.5–it is being classed as a negative review. If a second film review corresponds to an output of &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; = 0.51, the model has barely any more confidence that this review is positive relative to the first review. Yet, because 0.51 is greater than the 0.5 accuracy threshold, the second review is classed as a positive review.&lt;/p&gt; &lt;p&gt;The starkness of the accuracy metric threshold can hide a fair bit of nuance in the quality of our model’s output, and so when evaluating the performance of binary classifiers, we prefer a metric called the area under the curve of the receiver operating characteristic. The ROC AUC, as the metric is known for short, has its roots in the Second World War, when it was developed to assess the performance of radar engineers’ judgment as they attempted to identify the presence of enemy objects.&lt;/p&gt; &lt;p&gt;We like the ROC AUC for two reasons:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;It blends together two useful metrics—true positive rate and false positive rate—into a single summary value.&lt;/li&gt; &lt;li&gt;It enables us to evaluate the performance of our binary classifier’s output across the full range of &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt;, from 0.0 to 1.0. This contrasts with the accuracy metric, which evaluates the performance of a binary classifier at a single threshold value only— usually &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; = 0.50.&lt;/li&gt; &lt;/ol&gt; &lt;h2&gt;The Confusion Matrix&lt;/h2&gt; &lt;p&gt;The first step toward understanding how to calculate the ROC AUC metric is to under- stand the so-called &lt;em&gt;confusion matrix&lt;/em&gt;, which—as you’ll see—isn’t actually all that confusing. Rather, the matrix is a straightforward 2 × 2 table of how confused a model (or, as back in WWII, a person) is while attempting to act as a binary classifier. You can see an example of a confusion matrix in Table 11.3.&lt;/p&gt; &lt;p&gt;&lt;img sizes="(max-width: 553px) 100vw, 553px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_3.png 916w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_3-300x92.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_3-768x235.png 768w" height="169" width="553" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_3.png" loading="lazy"&gt;&lt;/p&gt; &lt;p&gt;To bring the confusion matrix to life with an example, let’s return to the hot dog / not hot dog binary classifier that we’ve used to construct silly examples over many of the preceding chapters:&lt;/p&gt; &lt;p&gt;When we provide some input x to a model and it &lt;em&gt;predicts&lt;/em&gt; that the input represents a hot dog, then we’re dealing with the first row of the table, because the &lt;em&gt;predicted&lt;/em&gt; y = 1. In that case,&lt;/p&gt; &lt;ul&gt; &lt;li&gt;True positive: If the input is&lt;em&gt; actually&lt;/em&gt; a hot dog (i.e., &lt;em&gt;actual&lt;/em&gt; y = 1), then the model correctly classified the input.&lt;/li&gt; &lt;li&gt;False positive: If the input is &lt;em&gt;actually&lt;/em&gt; not a hot dog (i.e., &lt;em&gt;actual&lt;/em&gt; y = 0), then the model is &lt;em&gt;confused.&lt;/em&gt;&lt;/li&gt; &lt;li&gt;False negative: If the input is actually a hot dog (i.e.,&lt;em&gt; actual&lt;/em&gt; y = 1), then the model is also confused in this circumstance.&lt;/li&gt; &lt;li&gt;True negative: If the input is actually not a hot dog (i.e., &lt;em&gt;actual&lt;/em&gt; y = 0), then the model correctly classified the input.When we provide some input x to a model and it predicts that the input does &lt;em&gt;not&lt;/em&gt; represent a hot dog, then we’re dealing with the second row of the table, because &lt;em&gt;predicted&lt;/em&gt; y = 0. In that case,&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Calculating the ROC AUC Metric&lt;/h2&gt; &lt;p&gt;Briefed on the confusion matrix, we can now move forward and calculate the ROC AUC metric itself, using a toy-sized example. Let’s say, as shown in Table 11.4, we provide four inputs to a binary-classification model.&lt;/p&gt; &lt;p&gt;&lt;img sizes="(max-width: 457px) 100vw, 457px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_4.png 690w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_4-300x136.png 300w" height="207" width="457" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_4.png" loading="lazy"&gt;&lt;/p&gt; &lt;p&gt;Two of these inputs are actually hot dogs (y = 1), and two of them are not hot dogs (y = 0). For each of these inputs, the model outputs some predicted &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt;, all four of which are provided in Table 11.4.&lt;/p&gt; &lt;p&gt;&lt;img sizes="(max-width: 672px) 100vw, 672px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_5.png 1034w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_5-300x134.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_5-768x343.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_5-1024x458.png 1024w" height="300" width="672" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_5.png" loading="lazy"&gt;&lt;/p&gt; &lt;p&gt;To calculate the ROC AUC metric, we consider each of the &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; values output by the model as the binary-classification threshold in turn. Let’s start with the lowest &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt;, which is 0.3 (see the “0.3 threshold” column in Table 11.5). At this threshold, only the first input is classed as not a hot dog, whereas the second through fourth inputs (all with &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; &amp;gt; 0.3) are all classed as hot dogs. We can compare each of these four predicted classifications with the confusion matrix in Table 11.3:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;True negative (TN): This is actually not a hot dog (y = 0) and was correctly predicted as such.&lt;/li&gt; &lt;li&gt;True positive (TP): This is actually a hot dog (y = 1) and was correctly predicted as such.&lt;/li&gt; &lt;li&gt;False positive (FP): This is actually not a hot dog (y = 0) but it was erroneously predicted to be one.&lt;/li&gt; &lt;li&gt;True positive (TP): Like input 2, this is actually a hot dog (y = 1) and was correctly predicted as such.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;The same process is repeated with the classification threshold set to 0.5 and yet again with the threshold set to 0.6, allowing us to populate the remaining columns of Table 11.5. As an exercise, it might be wise to work through these two columns, comparing the classifications at each threshold with the actual y values and the confusion matrix (Table 11.3) to ensure that you have a good handle on these concepts.Finally, note that the highest &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; value (in this case, .09) can be skipped as a potential threshold, because at such a high threshold we’d be considering all four instances to not be hot dogs, making it a ceiling instead of a classification boundary.&lt;/p&gt; &lt;p&gt;The next step toward computing the ROC AUC metric is to calculate both the true positive rate (TPR) and the false positive rate (FPR) at each of the three thresholds. Equations 11.1 and 11.2 use the “0.3 threshold” column to provide examples of how to calculate the true positive rate and false positive rate, respectively.&lt;/p&gt; &lt;p&gt;&lt;img sizes="(max-width: 564px) 100vw, 564px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-EQ2.png 486w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-EQ2-300x114.png 300w" height="214" width="564" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-EQ2.png" loading="lazy"&gt;&lt;/p&gt; &lt;p&gt;&lt;img sizes="(max-width: 596px) 100vw, 596px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-EQ3.png 550w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-EQ3-300x97.png 300w" height="193" width="596" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-EQ3.png" loading="lazy"&gt;&lt;/p&gt; &lt;p&gt;Shorthand versions of the arithmetic for calculating TPR and FPR for the thresholds 0.5 and 0.6 are also provided for your convenience at the bottom of Table 11.5. Again, perhaps you should test if you can compute these values yourself on your own time.&lt;/p&gt; &lt;p&gt;The final stage in calculating ROC AUC is to create a plot like the one we provide in Figure 11.11. The points that make up the shape of the receiver operating characteristic (ROC) curve are the false positive rate (horizontal, x-axis coordinate) and true positive rate (vertical, y-axis coordinate) at each of the available thresholds (which in this case is three) in Table 11.5, plus two extra points in the bottom-left and top-right corners of the plot. Specifically, these five points (shown as orange dots in Figure 11.11) are:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;(0, 0) for the bottom-left corner&lt;/li&gt; &lt;li&gt;(0, 0.5) from the 0.6 threshold&lt;/li&gt; &lt;li&gt;(0.5, 0.5) from the 0.5 threshold&lt;/li&gt; &lt;li&gt;(0.5, 1) from the 0.3 threshold&lt;/li&gt; &lt;li&gt;(1, 1) for the top-right corner&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;In this toy-sized example, we only used four distinct &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; values so there are only five points that determine the shape of the ROC curve, making the curve rather step shaped. When there are many available predictions providing many distinct &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; values—as is typically the case in real-world examples—the ROC curve has many more points, and so it’s much less step shaped and much more, well, curve shaped. The area under the curve (AUC) of the ROC curve is exactly what it sounds like: In Figure 11.11, we’ve shaded this area in orange and, in this example, the AUC constitutes 75 percent of all the possible area and so the ROC AUC metric comes out to 0.75.&lt;/p&gt; &lt;p&gt;A binary classifier that works as well as chance will generate a straight diagonal running from the bottom-left corner of the plot to its top-right corner, so an ROC AUC of 0.5 indicates that the classifier works as well as flipping a coin. A perfect ROC AUC is 1.0, which is attained by having FPR = 0 and TPR = 1 across all of the available &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; thresholds. When you’re designing a binary classifier to perform well on the ROC AUC metric, the goal is thus to minimize FPR and maximize TPR across the range of &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; thresholds. That said, for most problems you encounter, attaining a perfect ROC AUC of 1.0 is not possible: There is usually some noise—perhaps a lot of noise—in the data that makes perfection unattainable. Thus, when you’re working with any given dataset, there is some (typically unknown!) maximum ROC AUC score, such that no matter how ideally suited your model is to act as a binary classifier for the problem, there’s an ROC AUC ceiling that no model can crack through.&lt;/p&gt; &lt;p&gt;Over the remainder of this chapter we use the illuminating ROC AUC metric, alongside the simpler accuracy and cost metrics you are already acquainted with, to evaluate the performance of the binary-classifying deep learning models that we design and train.&lt;/p&gt; &lt;p&gt;&lt;img sizes="(max-width: 660px) 100vw, 660px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_11.png 1066w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_11-300x150.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_11-768x383.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_11-1024x511.png 1024w" height="329" width="660" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_11.png" loading="lazy"&gt;&lt;/p&gt; &lt;h2&gt;Natural Language Classification with Familiar Networks&lt;/h2&gt; &lt;p&gt;In this section, we tie together concepts that were introduced in this chapter—natural language preprocessing best practices, the creation of word vectors, and the ROC AUC metric—with the deep learning theory from previous chapters. As we already alluded to earlier, the natural language processing model you’ll experiment with over the remainder of the chapter will be a binary classifier that predicts whether a given film review is a positive one or a negative one. We begin by classifying natural language documents using types of neural networks that you’re already familiar with—dense and convolutional— before moving along to networks that are specialized to handle data that occur in a sequence.&lt;/p&gt; &lt;h2&gt;Loading the IMDb Film Reviews&lt;/h2&gt; &lt;p&gt;As a performance baseline, we’ll initially train and test a relatively simple dense network. All of the code for doing this is provided within our &lt;em&gt;Dense Sentiment Classifier&lt;/em&gt; Jupyter notebook [or the &lt;a href="https://try.dominodatalab.com/u/domino-andrealowe/Natural-Language-Processing/overview"&gt;complementary Domino project&lt;/a&gt;].&lt;/p&gt; &lt;p&gt;Example 11.12 provides the dependencies we need for our dense sentiment classifier. Many of these dependencies will be recognizable from previous chapters, but others (e.g., for loading a dataset of film reviews, saving model parameters as we train, calculating ROC AUC) are new. As usual, we cover the details of these dependencies as we apply them later on.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example 11.12 Loading sentiment classifier dependencies&lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt;import keras from keras.datasets import imdb # new! from keras.preprocessing.sequence import pad_sequences # new! from keras.models import Sequential from keras.layers import Dense, Flatten, Dropout from keras.layers import Embedding # new! from keras.callbacks import ModelCheckpoint # new! import os # new! from sklearn.metrics import roc_auc_score, roc_curve # new! import pandas as pd import matplotlib.pyplot as plt # new! %matplotlib inline &lt;/pre&gt; &lt;p&gt;It’s a good programming practice to put as many hyperparameters as you can at the top of your file. This makes it easier to experiment with these hyperparameters. It also makes it easier for you (or, indeed, your colleagues) to understand what you were doing in the file when you return to it (perhaps much) later. With this in mind, we place all of our hyperparameters together in a single cell within our Jupyter notebook. The code is provided in Example 11.13.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example 11.13 Setting dense sentiment classifier hyperparameters&lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt;# output directory name: output_dir = 'model_output/dense' # training: epochs = 4 batch_size = 128 # vector-space embedding: n_dim = 64 n_unique_words = 5000 n_words_to_skip = 50 max_review_length = 100 pad_type = trunc_type = 'pre' # neural network architecture: n_dense = 64 dropout = 0.5 &lt;/pre&gt; &lt;p&gt;Let’s break down the purpose of each of these variables:&lt;/p&gt; &lt;ul&gt; &lt;li&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;output_dir&lt;/code&gt;: A directory name (ideally, a unique one) in which to store our model’s parameters after each epoch, allowing us to return to the parameters from any epoch of our choice at a later time.&lt;/li&gt; &lt;li&gt;&lt;code&gt;epochs&lt;/code&gt;: The number of epochs that we’d like to train for, noting that NLP models often overfit to the training data in fewer epochs than machine vision models.&lt;/li&gt; &lt;li&gt;&lt;code&gt;batch_size&lt;/code&gt;: As before, the number of training examples used during each round of model training (see Figure 8.5).&lt;/li&gt; &lt;li&gt;&lt;code&gt;n_dim&lt;/code&gt;: The number of dimensions we’d like our word-vector space to have.&lt;/li&gt; &lt;li&gt;&lt;code&gt;n_unique_words&lt;/code&gt;: With word2vec earlier in this chapter, we included tokens in our word-vector vocabulary only if they occurred at least a certain number of times within our corpus. An alternative approach—the one we take here—is to sort all of the tokens in our corpus by the number of times they occur, and then only use a certain number of the most popular words. Andrew Maas and his coworkers [Note: We mentioned Maas et al. (2011) earlier in this chapter. They put together the movie-review corpus we’re using in this notebook.]&amp;nbsp;opted to use the 5,000 most popular words across their film-review corpus and so we’ll do the same.[Note: This 5,000-word threshold may not be optimal, but we didn’t take the time to test lower or higher values. You are most welcome to do so yourself!]&lt;/li&gt; &lt;li&gt;&lt;code&gt;n_words_to_skip&lt;/code&gt;: Instead of removing a manually curated list of stop words from their word-vector vocabulary, Maas et al. made the assumption that the 50 most frequently occurring words across their film-review corpus would serve as a decent list of stop words. We followed their lead and did the same.[Note: Note again that following Maas et al.’s lead may not be the optimal choice. Further, note that this means we’ll actually be including the 51st most popular word through to the 5050th most popular word in our word-vector vocabulary.]&lt;/li&gt; &lt;li&gt;&lt;code&gt;max_review_length&lt;/code&gt;: Each movie review must have the same length so that TensorFlow knows the shape of the input data that will be flowing through our deep learning model. For this model, we selected a review length of 100 words.[Note: You are free to experiment with lengthier or shorter reviews.] Any reviews longer than 100 are truncated. Any reviews shorter than 100 are padded with a special padding character (analogous to the zero padding that can be used in machine vision, as in Figure 10.3).&lt;/li&gt; &lt;li&gt;&lt;code&gt;pad_type&lt;/code&gt;: By selecting &lt;code&gt;'pre'&lt;/code&gt;, we add padding characters to the start of every review. The alternative is &lt;code&gt;'post'&lt;/code&gt;, which adds them to the end. With a dense network like the one in this notebook, it shouldn’t make much difference which of these options we pick. Later in this chapter, when we’re working with specialized, sequential-data layer types, [Note: For example, RNN, LSTM.] it’s generally best to use ‘pre’ because the content at the end of the document is more influential in the model and so we want the largely uninformative padding characters to be at the beginning of the document.&lt;/li&gt; &lt;li&gt;&lt;code&gt;trunc_type&lt;/code&gt;: As with &lt;code&gt;pad_type&lt;/code&gt;, our truncation options are &lt;code&gt;'pre'&lt;/code&gt; or &lt;code&gt;'post'&lt;/code&gt;. The former will remove words from the beginning of the review, whereas the latter will remove them from the end. By selecting &lt;code&gt;'pre'&lt;/code&gt;, we’re making (a bold!) assumption that the end of film reviews tend to include more information on review sentiment than the beginning.&lt;/li&gt; &lt;li&gt;&lt;code&gt;n_dense&lt;/code&gt;: The number of neurons to include in the dense layer of our neural network architecture. We waved our finger in the air to select 64, so some experimentation and optimization are warranted at your end if you feel like it. For simplicity’s sake, we also are using a single layer of dense neurons, but you could opt to have several.&lt;/li&gt; &lt;li&gt;&lt;code&gt;dropout&lt;/code&gt;: How much dropout to apply to the neurons in the dense layer. Again, we did not take the time to optimize this hyperparameter (set at 0.5) ourselves.&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Loading in the film review data is a one-liner, provided in Example 11.14.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example 11.14 Loading IMDb film review data&lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt;(x_train, y_train), (x_valid, y_valid) = \ imdb.load_data(num_words=n_unique_words, skip_top=n_words_to_skip) &lt;/pre&gt; &lt;p&gt;This dataset from Maas et al. (2011) is made up of the natural language of reviews from the publicly available Internet Movie Database (IMDb; &lt;a href="http://imdb.com/"&gt;imdb.com&lt;/a&gt;). It consists of 50,000 reviews, half of which are in the training dataset &lt;code&gt;(x_train)&lt;/code&gt;, and half of which are for model validation &lt;code&gt;(x_valid)&lt;/code&gt;. When submitting their review of a given film, users also provide a star rating, with a maximum of 10 stars. The labels &lt;code&gt;(y_train and y_valid)&lt;/code&gt; are binary, based on these star ratings:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Reviews with a score of four stars or fewer are considered to be a negative review (y = 0).&lt;/li&gt; &lt;li&gt;Reviews with a score of seven stars or more, meanwhile, are classed as a positive review (y = 1).&lt;/li&gt; &lt;li&gt;Moderate reviews—those with five or six stars—are not included in the dataset, making the binary classification task easier for any model.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;By specifying values for the &lt;code&gt;num_words&lt;/code&gt; and &lt;code&gt;skip_top&lt;/code&gt; arguments when calling &lt;code&gt;imdb.load_data()&lt;/code&gt;, we are limiting the size of our word-vector vocabulary and removing the most common (stop) words, respectively.&lt;/p&gt; &lt;pre&gt;In our Dense Sentiment Classifier notebook, we have the convenience of loading our IMDb film-review data via the Keras &lt;code&gt;imdb.load_data()&lt;/code&gt; method. When you’re working with your own natural language data, you’ll likely need to preprocess many aspects of the data yourself. In addition to the general preprocessing guidance we provided earlier in this chapter, Keras provides a number of convenient text preprocessing utilities, as documented online at keras.io/preprocessing/text. In particular, the &lt;code&gt;Tokenizer()&lt;/code&gt; class may enable you to carry out all of the preprocessing steps you need in a single line of code, including - Tokenizing a corpus to the word level (or even the character level) - Setting the size of your word-vector vocabulary (with num_words) - Filtering out punctuation Converting all characters to lowercase - Converting tokens into an integer index&lt;/pre&gt; &lt;h2&gt;Examining the IMDb Data&lt;/h2&gt; &lt;p&gt;Executing &lt;code&gt;x_train[0:6]&lt;/code&gt;, we can examine the first six reviews from the training dataset, the first two of which are shown in Figure 11.12. These reviews are natively in an integer-index format, where each unique token from the dataset is represented by an integer. The first few integers are special cases, following a general convention that is widely used in NLP:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;0: Reserved as the padding token (which we’ll soon add to the reviews that are shorter than &lt;code&gt;max_review_length&lt;/code&gt;).&lt;/li&gt; &lt;li&gt;1: Would be the starting token, which would indicate the beginning of a review. As per the next bullet point, however, the starting token is among the top 50 most common tokens and so is shown as “unknown.”&lt;/li&gt; &lt;li&gt;2: Any tokens that occur very frequently across the corpus (i.e., they’re in the top 50 most common words) or rarely (i.e., they’re below the top 5,050 most common words) will be outside of our word-vector vocabulary and so are replaced with this unknown token.&lt;/li&gt; &lt;li&gt;3: The most frequently occurring word in the corpus.&lt;/li&gt; &lt;li&gt;4: The second-most frequently occurring word.&lt;/li&gt; &lt;li&gt;5: The third-most frequently occurring, and so on.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Using the following code from Example 11.15, we can see the length of the first six reviews in the training dataset.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example 11.15 Printing the number of tokens in six reviews&lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt;for x in x_train[0:6]: print(len(x)) &lt;/pre&gt; &lt;p&gt;They are rather variable, ranging from 43 tokens up to 550 tokens. Shortly, we’ll handle these discrepancies, standardizing all reviews to the same length.&lt;/p&gt; &lt;p&gt;&lt;img sizes="(max-width: 677px) 100vw, 677px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_12.png 1090w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_12-300x170.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_12-768x435.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_12-1024x581.png 1024w" height="384" width="677" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_12.png" loading="lazy"&gt;&lt;/p&gt; &lt;p&gt;The film reviews are fed into our neural network model in the integer-index format of Figure 11.12 because this is a memory-efficient way to store the token information. It would require appreciably more memory to feed the tokens in as character strings, for example. For us humans, however, it is uninformative (and, frankly, uninteresting) to examine reviews in the integer-index format. To view the reviews as natural language, we create an index of words as follows, where &lt;code&gt;PAD&lt;/code&gt;, &lt;code&gt;START&lt;/code&gt;, and &lt;code&gt;UNK&lt;/code&gt; are customary for representing padding, starting, and unknown tokens, respectively:&lt;/p&gt; &lt;pre title=""&gt;word_index = keras.datasets.imdb.get_word_index() word_index = {k:(v+3) for k,v in word_index.items()} word_index["PAD"] = 0 word_index["START"] = 1 word_index["UNK"] = 2 index_word = {v:k for k,v in word_index.items()} &lt;/pre&gt; &lt;p&gt;Then we can use the code in Example 11.16 to view the film review of our choice—in this case, the first review from the training data.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example 11.16 Printing a review as a character string&lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt;' '.join(index_word[id] for id in x_train[0]) &lt;/pre&gt; &lt;p&gt;The resulting string should look identical to the output shown in Figure 11.13.&lt;/p&gt; &lt;p&gt;&lt;img sizes="(max-width: 788px) 100vw, 788px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_13.png 1082w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_13-300x135.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_13-768x346.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_13-1024x462.png 1024w" height="356" width="788" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_13.png" loading="lazy"&gt;&lt;/p&gt; &lt;p&gt;Remembering that the review in Figure 11.13 contains the tokens that are fed into our neural network, we might nevertheless find it enjoyable to read the full review without all of the &lt;code&gt;UNK&lt;/code&gt; tokens. In some cases of debugging model results, it might indeed even be practical to be able to view the full review. For example, if we’re being too aggressive or conservative with either our &lt;code&gt;n_unique_words&lt;/code&gt; or &lt;code&gt;n_words_to_skip&lt;/code&gt; thresholds, it might become apparent by comparing a review like the one in Figure 11.13 with a full one. With our index of words &lt;code&gt;(index_words)&lt;/code&gt; already available to us, we simply need to download the full reviews:&lt;/p&gt; &lt;pre title=""&gt;(all_x_train,_),(all_x_valid,_) = imdb.load_data() &lt;/pre&gt; &lt;p&gt;Then we modify Example 11.16 to execute &lt;code&gt;join()&lt;/code&gt; on the full-review list of our choice (i.e., &lt;code&gt;all_x_train&lt;/code&gt; or &lt;code&gt;all_x_valid&lt;/code&gt;), as provided in Example 11.17.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example 11.17 Print full review as character string&lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt;' '.join(index_word[id] for id in all_x_train[0]) &lt;/pre&gt; &lt;p&gt;Executing this outputs the full text of the review of our choice—again, in this case, the first training review—as shown in Figure 11.14.&lt;/p&gt; &lt;p&gt;&lt;img sizes="(max-width: 708px) 100vw, 708px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_14.png 1080w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_14-300x132.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_14-768x337.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_14-1024x449.png 1024w" height="311" width="708" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_14.png" loading="lazy"&gt;&lt;/p&gt; &lt;h2&gt;Standardizing the Length of the Reviews&lt;/h2&gt; &lt;p&gt;By executing Example 11.15 earlier, we discovered that there is variability in the length of the film reviews. In order for the Keras-created TensorFlow model to run, we need to specify the size of the inputs that will be flowing into the model during training. This enables TensorFlow to optimize the allocation of memory and compute resources. Keras provides a convenient &lt;code&gt;pad_sequences()&lt;/code&gt; method that enables us to both pad and truncate documents of text in a single line. Here we standardize our training and validation data in this way, as shown in Example 11.18.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example 11.18 Standardizing input length by padding and truncating&lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt; x_train = pad_sequences(x_train, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0) x_valid = pad_sequences(x_valid, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0) &lt;/pre&gt; &lt;p&gt;Now, when printing reviews (e.g., with &lt;code&gt;x_train[0:6]&lt;/code&gt;) or their lengths (e.g., with the code from Example 11.15), we see that all of the reviews have the same length of 100 (because we set &lt;code&gt;max_review_length = 100&lt;/code&gt;). Examining x_train[5]—which previously had a length of only 43 tokens—with code similar to Example 11.16, we can observe that the beginning of the review has been padded with 57 &lt;code&gt;PAD&lt;/code&gt; tokens (see Figure 11.15).&lt;/p&gt; &lt;p&gt;&lt;img sizes="(max-width: 687px) 100vw, 687px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_15.png 1096w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_15-300x79.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_15-768x202.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_15-1024x269.png 1024w" height="181" width="687" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_15.png" loading="lazy"&gt;&lt;/p&gt; &lt;h2&gt;Dense Network&lt;/h2&gt; &lt;p&gt;With sufficient NLP theory behind us, as well as our data loaded and preprocessed, we’re at long last prepared to make use of a neural network architecture to classify film reviews by their sentiment. A baseline dense network model for this task is shown in Example 11.19.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example 11.19 Dense sentiment classifier architecture&lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt;model = Sequential() model.add(Embedding(n_unique_words, n_dim, input_length=max_review_length)) model.add(Flatten()) model.add(Dense(n_dense, activation='relu')) model.add(Dropout(dropout)) # model.add(Dense(n_dense, activation='relu')) # model.add(Dropout(dropout)) model.add(Dense(1, activation='sigmoid')) &lt;/pre&gt; &lt;p&gt;Let’s break the architecture down line by line:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;We’re using a Keras &lt;code&gt;Sequential()&lt;/code&gt; method to invoke a sequential model, as we have for all of the models so far in this book.&lt;/li&gt; &lt;li&gt;As with word2vec, the &lt;code&gt;Embedding()&lt;/code&gt; layer enables us to create word vectors from a corpus of documents—in this case, the 25,000 movie reviews of the IMDb training dataset. Relative to independently creating word vectors with word2vec (or GloVe, etc.) as we did earlier in this chapter, training your word vectors via backpropagation as a component of your broader NLP model has a potential advantage: The locations that words are assigned to within the vector space reflect not only word similarity but also the relevance of the words to the ultimate, specific purpose of the model (e.g., binary classification of IMDb reviews by sentiment). The size of the word-vector vocabulary and the number of dimensions of the vector space are specified by n_unique_words and n_dim, respectively. Because the embedding layer is the first hidden layer in our network, we must also pass into it the shape of our input layer: We do this with the input_length argument.&lt;/li&gt; &lt;li&gt;As in Chapter 10, the &lt;code&gt;Flatten()&lt;/code&gt; layer enables us to pass a many-dimensional output (here, a two-dimensional output from the embedding layer) into a one- dimensional dense layer.&lt;/li&gt; &lt;li&gt;Speaking of &lt;code&gt;Dense()&lt;/code&gt; layers, we used a single one consisting of relu activations in this architecture, with applied to it.&lt;/li&gt; &lt;li&gt;We opted for a fairly shallow neural network architecture for our baseline model, but you can trivially deepen it by adding further &lt;code&gt;Dense()&lt;/code&gt;layers (see the lines that are commented out)./li&amp;gt;&lt;/li&gt; &lt;li&gt;Finally, because there are only two classes to classify, we require only a single output neuron (because, as discussed earlier in this chapter, if one class has the probability p then the other class has the probability 1 − p). This neuron is sigmoid because we’d like it to output probabilities between 0 and 1 (refer to Figure 6.9).&lt;/li&gt; &lt;/ul&gt; &lt;pre&gt;In addition to training word vectors on natural language data alone (e.g., with word2vec or GloVe) or training them with an embedding layer as part of a deep learning model, pretrained word vectors are also available online. As with using a ConvNet trained on the millions of images in ImageNet (Chapter 10), this natural language transfer learning is powerful, because these word vectors may have been trained on extremely large corpuses (e.g., all of Wikipedia, or the English-language Internet) that provide large, nuanced vocabularies that would be expensive to train yourself. Examples of pretrained word vectors are available at github .com/Kyubyong/wordvectors and nlp.stanford.edu/projects/glove. The fast- Text library also offers subword embeddings in 157 languages; these can be downloaded from fasttext.cc. In this book, we don’t cover substituting pretrained word vectors (be they down- loaded or trained separately from your deep learning model, as we did with &lt;code&gt;Word2Vec()&lt;/code&gt; earlier in this chapter) in place of the embedding layer, because there are many different permutations on how you might like to do this. For a neat tutorial from François Chollet, the creator of Keras, go to bit.ly/preTrained.&lt;/pre&gt; &lt;p&gt;Executing &lt;code&gt;model.summary()&lt;/code&gt;, we discover that our fairly simple NLP model has quite a few parameters, as shown in Figure 11.16:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;In the embedding layer, the 320,000 parameters come from having 5,000 words, each one with a location specified in a 64-dimensional word-vector space (64 × 5,000 = 320,000).&lt;/li&gt; &lt;li&gt;Flowing out of the embedding layer through the flatten layer and into the dense layer are 6,400 values: Each of our film-review inputs consists of 100 tokens, with each token specified by 64 word-vector-space coordinates (64 × 100 = 6,400).&lt;/li&gt; &lt;li&gt;Each of the 64 neurons in the dense hidden layer receives input from each of the 6,400 values flowing out of the flatten layer, for a total of 64 × 6,400 = 409,600 weights. And, of course, each of the 64 neurons has a bias, for a total of 409,664 parameters in the layer.&lt;/li&gt; &lt;li&gt;Finally, the single neuron of the output layer has 64 weights—one for the activation output by each of the neurons in the preceding layer—plus its bias, for a total of 65 parameters.&lt;/li&gt; &lt;li&gt;Summing up the parameters from each of the layers, we have a grand total of 730,000 of them.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;img sizes="(max-width: 547px) 100vw, 547px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_16.png 782w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_16-300x176.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_16-768x452.png 768w" height="322" width="547" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_16.png" loading="lazy"&gt;&lt;/p&gt; &lt;p&gt;As shown in Example 11.20, we compile our dense sentiment classifier with a line of code that should already be familiar from recent chapters, except that—because we have a single output neuron within a binary classifier—we use &lt;code&gt;binary_crossentropy&lt;/code&gt; cost in place of the &lt;code&gt;categorical_crossentropy&lt;/code&gt; cost we used for our multiclass MNIST classifiers.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example 11.20 Compiling our sentiment classifier&lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt;model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) &lt;/pre&gt; &lt;p&gt;With the code provided in Example 11.21, we create a &lt;code&gt;ModelCheckpoint()&lt;/code&gt; object that will allow us to save our model parameters after each epoch during training. By doing this, we can return to the parameters from our epoch of choice later on during model evaluation or to make inferences in a production system. If the &lt;code&gt;output_dir&lt;/code&gt; directory doesn’t already exist, we use the &lt;code&gt;makedirs()&lt;/code&gt; method to make it.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example 11.21 Creating an object and directory for checkpointing model parameters after each epoch&lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt;modelcheckpoint = ModelCheckpoint(filepath=output_dir+ "/weights.{epoch:02d}.hdf5") if not os.path.exists(output_dir): os.makedirs(output_dir) &lt;/pre&gt; &lt;p&gt;###Insert Figure&lt;/p&gt; &lt;p&gt;Like the compile step, the model-fitting step (Example 11.22) for our sentiment classifier should be familiar except, perhaps, for our use of the callbacks argument to pass in the &lt;code&gt;modelcheckpoint&lt;/code&gt; object. [Note: This isn’t our first use of the callbacks argument. We previously used this argument, which can take in a list of multiple different &lt;code&gt;callbacks&lt;/code&gt;, to provide data on model training progress to TensorBoard (see Chapter 9)].&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example 11.22 Fitting our sentiment classifier&lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt; model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_valid, y_valid), callbacks=[modelcheckpoint]) &lt;/pre&gt; &lt;p&gt;As shown in Figure 11.17, we achieve our lowest validation loss (0.349) and highest validation accuracy (84.5 percent) in the second epoch. In the third and fourth epochs, the model is heavily overfit, with accuracy on the training set considerably higher than on the validation set. By the fourth epoch, training accuracy stands at 99.6 percent while validation accuracy is much lower, at 83.4 percent.&lt;/p&gt; &lt;p&gt;&lt;img sizes="(max-width: 753px) 100vw, 753px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_17.png 1094w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_17-300x67.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_17-768x173.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_17-1024x230.png 1024w" height="169" width="753" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_17.png" loading="lazy"&gt;&lt;/p&gt; &lt;p&gt;To evaluate the results of the best epoch more thoroughly, we use the Keras &lt;code&gt;load_ weights()&lt;/code&gt; method to load the parameters from the second epoch (&lt;code&gt;weights.02.hdf5&lt;/code&gt;) back into our model, as in Example 11.23. [Note: Although the method is called &lt;code&gt;load_weights()&lt;/code&gt;, it loads in all model parameters, including biases. Because weights typically constitute the vast majority of parameters in a model, deep learning practitioners often call parameter files “weights” files. Earlier versions of Keras used zero indexing for epochs, but more recent versions index starting at 1.]&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example 11.23 Loading model parameters &lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt;model.load_weights(output_dir+"/weights.02.hdf5") &lt;/pre&gt; &lt;p&gt;We can then calculate validation set y_hat values for the best epoch by passing the &lt;code&gt;predict_proba()&lt;/code&gt; method on the &lt;code&gt;x_valid&lt;/code&gt; dataset, as shown in Example 11.24.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example 11.24 Predicting y_hat for all validation &lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt;y_hat = model.predict_proba(x_valid) &lt;/pre&gt; &lt;p&gt;With y_hat[0], for example, we can now see the model’s prediction of the sentiment of the first movie review in the validation set. For this review, &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; = 0.09, indicating the model estimates that there’s a 9 percent chance the review is positive and, therefore, a 91 percent chance it’s negative. Executing y_valid[0] informs us that &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; = 0 for this review—that is, it is in fact a negative review—so the model’s &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; is pretty good! If you’re curious about what the content of the negative review was, you can run a slight modification on Example 11.17 to access the full text of the &lt;code&gt;all_x_valid[0]&lt;/code&gt; list item, as shown in Example 11.25.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example 11.25 Printing a full validation review&lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt;' '.join(index_word[id] for id in all_x_valid[0]) &lt;/pre&gt; &lt;p&gt;Examining individual scores can be interesting, but we get a much better sense of our model’s performance by looking at all of the validation results together. We can plot a histogram of all the validation &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; values by running the code in Example 11.26.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example 11.26 Plotting a histogram of validation data &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; values &lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt;plt.hist(y_hat) _ = plt.axvline(x=0.5, color='orange') &lt;/pre&gt; &lt;p&gt;The histogram output is provided in Figure 11.18.&lt;/p&gt; &lt;p&gt;&lt;img sizes="(max-width: 718px) 100vw, 718px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_18.png 1094w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_18-300x131.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_18-768x336.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_18-1024x447.png 1024w" height="314" width="718" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_18.png" loading="lazy"&gt;&lt;/p&gt; &lt;p&gt;The plot shows that the model often has a strong opinion on the sentiment of a given review: Some 8,000 of the 25,000 re- views (~32 percent of them) are assigned a &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; of less than 0.1, and ~6,500 (~26 percent) are given a &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; greater than 0.9.&lt;/p&gt; &lt;p&gt;The vertical orange line in Figure 11.18 marks the 0.5 threshold above which reviews are considered by a simple accuracy calculation to be positive. As discussed earlier in the chapter, such a simple threshold can be misleading, because a review with a yˆ just be- low 0.5 is not predicted by the model to have much difference in sentiment relative to&lt;br&gt; a review with a &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; just above 0.5. To obtain a more nuanced assessment of our model’s performance as a binary classifier, we can use the &lt;code&gt;roc_auc_score()&lt;/code&gt; method from the &lt;em&gt;scikit-learn&lt;/em&gt; metrics library to straightforwardly calculate the ROC AUC score across the validation data, as shown in Example 11.27.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example 11.27 Calculating ROC AUC for validation data &lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt;pct_auc = roc_auc_score(y_valid, y_hat)*100.0 "{:0.2f}".format(pct_auc) &lt;/pre&gt; &lt;p&gt;Printing the output in an easy-to-read format with the &lt;code&gt;format()&lt;/code&gt; method, we see that the percentage of the area under the receiver operating characteristic curve is (a fairly high) 92.9 percent.&lt;/p&gt; &lt;p&gt;To get a sense of where the model breaks down, we can create a DataFrame of y and &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; validation set values, using the code in Example 11.28.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example 11.28 Creating a &lt;code&gt;ydf&lt;/code&gt; DataFrame of y and ˆy values&lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt;float_y_hat = [] for y in y_hat: float_y_hat.append(y[0]) ydf = pd.DataFrame(list(zip(float_y_hat, y_valid)), columns=['y_hat', 'y']) &lt;/pre&gt; &lt;p&gt;Printing the first 10 rows of the resulting &lt;code&gt;ydf&lt;/code&gt; DataFrame with &lt;code&gt;ydf.head(10)&lt;/code&gt;, we see the output shown in Figure 11.19.&lt;/p&gt; &lt;p&gt;&lt;img sizes="(max-width: 541px) 100vw, 541px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_19.png 970w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_19-300x206.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_19-768x527.png 768w" height="372" width="541" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_19.png" loading="lazy"&gt;&lt;/p&gt; &lt;p&gt;&lt;img sizes="(max-width: 690px) 100vw, 690px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_20.png 1096w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_20-300x117.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_20-768x299.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_20-1024x398.png 1024w" height="268" width="690" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_20.png" loading="lazy"&gt;&lt;/p&gt; &lt;p&gt;Querying the &lt;code&gt;ydf&lt;/code&gt; DataFrame as we do in Examples 11.29 and 11.30 and then examining the individual reviews these queries surface by varying the list index in Example 11.25, you can get a sense of the kinds of reviews that cause the model to make its largest errors.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example 11.29 Ten cases of negative validation reviews with high &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; scores &lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt;ydf[(ydf.y == 0) &amp;amp; (ydf.y_hat &amp;gt; 0.9)].head(10) &lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Example 11.30 Ten cases of positive validation reviews with low &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; scores&lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt;ydf[(ydf.y == 0) &amp;amp; (ydf.y_hat &amp;gt; 0.9)].head(10) &lt;/pre&gt; &lt;p&gt;An example of a false positive—a negative review (y = 0) with a very high model score (&lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; = 0.97)—that was identified by running the code in Example 11.29 is provided in Figure 11.20. [Note: We output this particular review—the 387th in the validation dataset—by running the following code: &lt;code&gt;' '.join(index_word[id]&lt;/code&gt; for &lt;code&gt;id in all_x_valid[386])&lt;/code&gt;.] And an example of a false negative—a positive review (y = 1) with a very low model score (&lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; = 0.06)—that was identified by running the code in Example 11.30 is provided in Figure 11.21. [Note: R&lt;code&gt;un ' '.join(index_word[id] for id in all_x_valid[224]&lt;/code&gt;) to print out this same review yourself.]&lt;/p&gt; &lt;p&gt;&lt;img sizes="(max-width: 705px) 100vw, 705px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_21.png 1080w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_21-300x106.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_21-768x272.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_21-1024x362.png 1024w" height="250" width="705" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_21.png" loading="lazy"&gt;&lt;/p&gt; &lt;p&gt;Carrying out this kind of post hoc analysis of our model, one potential shortcoming that surfaces is that our dense classifier is not specialized to detect patterns of multiple tokens occurring in a sequence that might predict film-review sentiment. For example, it might be handy for patterns like the token-pair not-good to be easily detected by the model as predictive of negative sentiment.&lt;/p&gt; &lt;h2&gt;Convolutional Networks&lt;/h2&gt; &lt;p&gt;As covered in Chapter 10, convolutional layers are particularly adept at detecting spatial patterns. In this section, we use them to detect spatial patterns among words—like the &lt;em&gt;not-good&lt;/em&gt; sequence—and see whether they can improve upon the performance of our dense network at classifying film reviews by their sentiment. All of the code for this ConvNet can be found in our &lt;em&gt;Convolutional Sentiment Classifier&lt;/em&gt; notebook.&lt;/p&gt; &lt;p&gt;The dependencies for this model are identical to those of our dense sentiment classifier (see Example 11.12), except that it has three new Keras layer types, as provided in Example 11.31.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example 11.31 Additional CNN dependencies&lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt;from keras.layers import Conv1D, GlobalMaxPooling1D from keras.layers import SpatialDropout1D &lt;/pre&gt; &lt;p&gt;The hyperparameters for our convolutional sentiment classifier are provided in Example 11.32.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example 11.32 Convolutional sentiment classifier hyperparameters &lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt;# output directory name: output_dir = 'model_output/conv' # training: epochs = 4 batch_size = 128 # vector-space embedding: n_dim = 64 n_unique_words = 5000 max_review_length = 400 pad_type = trunc_type = 'pre' drop_embed = 0.2 # new! # convolutional layer architecture: n_conv = 256 # filters, a.k.a. kernels k_conv = 3 # kernel length # dense layer architecture: n_dense = 256 dropout = 0.2 &lt;/pre&gt; &lt;p&gt;Relative to the hyperparameters from our dense sentiment classifier (see Example 11.13):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;We have a new, unique directory name (‘&lt;code&gt;conv&lt;/code&gt;‘) for storing model parameters after each epoch of training.&lt;/li&gt; &lt;li&gt;Our number of epochs and batch size remain the same.&lt;/li&gt; &lt;li&gt;Our vector-space embedding hyperparameters remain the same, except that &lt;ul&gt; &lt;li&gt;We quadrupled &lt;code&gt;max_review_length&lt;/code&gt; to 400. We did this because, despite the fairly dramatic increase in input volume as well as an increase in our number of hidden layers, our convolutional classifier will still have far fewer parameters relative to our dense sentiment classifier.&lt;/li&gt; &lt;li&gt;With &lt;code&gt;drop_embed&lt;/code&gt;, we’ll be adding dropout to our embedding layer.&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;Our convolutional sentiment classifier will have two hidden layers after the embedding layer: &lt;ul&gt; &lt;li&gt;A convolutional layer with 256 filters (&lt;code&gt;n_conv&lt;/code&gt;), each with a single dimension (a length) of 3 (&lt;code&gt;k_conv&lt;/code&gt;). When working with two-dimensional images in Chapter 10, our convolutional layers had filters with two dimensions. Natural language—be it written or spoken—has only one dimension associated with it (the dimension of time) and so the convolutional layers used in this chapter will have one-dimensional filters.&lt;/li&gt; &lt;li&gt;A dense layer with 256 neurons (&lt;code&gt;n_dense&lt;/code&gt;) and dropout of 20 percent.&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The steps for loading the IMDb data and standardizing the length of the reviews are identical to those in our &lt;em&gt;Dense Sentiment Classifier notebook&lt;/em&gt; (see Examples 11.14 and 11.18). The model architecture is of course rather different, and is provided in Example 11.33.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example 11.33 Convolutional sentiment classifier architecture&lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt;model = Sequential() # vector-space embedding: model.add(Embedding(n_unique_words, n_dim, input_length=max_review_length)) model.add(SpatialDropout1D(drop_embed)) # convolutional layer: model.add(Conv1D(n_conv, k_conv, activation='relu')) # model.add(Conv1D(n_conv, k_conv, activation='relu')) model.add(GlobalMaxPooling1D()) # dense layer: model.add(Dense(n_dense, activation='relu')) model.add(Dropout(dropout)) # output layer: model.add(Dense(1, activation='sigmoid')) &lt;/pre&gt; &lt;p&gt;Breaking the model down:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Our embedding layer is the same as before, except that it now has dropout applied to it.&lt;/li&gt; &lt;li&gt;We no longer require &lt;code&gt;Flatten()&lt;/code&gt;, because the &lt;code&gt;Conv1D()&lt;/code&gt;layer takes in both dimensions of the embedding layer output.&lt;/li&gt; &lt;li&gt;We use &lt;code&gt;relu&lt;/code&gt; activation within our one-dimensional convolutional layer. The layer has 256 unique filters, each of which is free to specialize in activating when it passes over a particular three-token sequence. The activation map for each of the 256 filters has a length of 398, for a 256×398 output shape. [Note: As described in Chapter 10, when a two-dimensional filter convolves over an image, we lose pixels around the perimeter if we don’t pad the image first. In this natural language model, our one-dimensional convolutional filter has a length of three, so, on the far left of the movie review, it begins centered on the second token and, on the far right, it ends centered on the second-to-last token. Because we didn’t pad the movie reviews at both ends before feeding them into the convolutional layer, we thus lose a token’s worth of information from each end: 400 − 1 − 1 = 398. We’re not upset about this loss.&lt;/li&gt; &lt;li&gt;If you fancy it, you’re welcome to add additional convolutional layers, by, for example, uncommenting the second &lt;code&gt;Conv1D()&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;em&gt;Global max-pooling&lt;/em&gt; is common for dimensionality reduction within deep learning NLP models. We use it here to squash the activation map from 256 × 398 to 256 × 1. By applying it, only the magnitude of largest activation for a given convolutional filter is retained by the maximum-calculating operation, and we lose any temporal-position-specific information the filter may have output to its 398-element-long activation map.&lt;/li&gt; &lt;li&gt;Because the activations output from the global max-pooling layer are one- dimensional, they can be fed directly into the dense layer, which consists (again) of relu neurons and dropout is applied.&lt;/li&gt; &lt;li&gt;The output layer remains the same.&lt;/li&gt; &lt;li&gt;The model has a grand total of 435,000 parameters (see Figure 11.22), several hundred thousand fewer than our dense sentiment classifier. Per epoch, this model will nevertheless take longer to train because the convolutional operation is relatively computationally expensive.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;img sizes="(max-width: 619px) 100vw, 619px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_22.png 872w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_22-300x180.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_22-768x460.png 768w" height="371" width="619" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_22.png" loading="lazy"&gt;&lt;/p&gt; &lt;p&gt;A critical item to note about this model architecture is that the convolutional filters are not detecting simply triplets of &lt;em&gt;words&lt;/em&gt;. Rather, they are detecting triplets of word vectors. Following from our discussion in Chapter 2, contrasting discrete, one-hot word representations with the word-vector representations that gently smear meaning across a high-dimensional space (see Table 2.1), all of the models in this chapter become specialized in associating word &lt;em&gt;meaning&lt;/em&gt; with review sentiment—as opposed to merely associating individual words with review sentiment. As an example, if the network learns that the token pair not-good is associated with a negative review, then it should also associate the pair not-great with negative reviews, because &lt;em&gt;good&lt;/em&gt; and &lt;em&gt;great&lt;/em&gt; have similar meanings (and thus should occupy a similar location in word-vector space).&lt;/p&gt; &lt;p&gt;The compile, checkpoint, and model-fitting steps are the same as for our dense sentiment classifier (see Examples 11.20, 11.21, and 11.22, respectively). Model-fitting progress is shown in Figure 11.23. The epoch with the lowest validation loss (0.258) and highest validation accuracy (89.6 percent) was the third epoch. Loading the model parameters from that epoch back in (with the code from Example 11.23 but specifying &lt;code&gt;weights.03.hdf5&lt;/code&gt;), we then predict &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; for all validation data (exactly as in Example 11.24). Creating a histogram (Figure 11.24) of these &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; values (with the same code as in Example 11.26), we can see visually that our CNN has a stronger opinion of review sentiment than our dense network did (refer to Figure 11.18): There are about a thousand more reviews with &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; &amp;lt; 0.1 and several thousand more with &lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; &amp;gt; 0.9. Calculating ROC AUC (with the code from Example 11.27), we output a very high score of 96.12 percent, indicating that the CNN’s confidence was not misplaced: It is a marked improvement over the already high ~93 percent score of the dense net.&lt;/p&gt; &lt;p&gt;&lt;img sizes="(max-width: 782px) 100vw, 782px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_23.png 1094w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_23-300x65.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_23-768x167.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_23-1024x223.png 1024w" height="171" width="782" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_23.png" loading="lazy"&gt;&lt;/p&gt; &lt;p&gt;&lt;img sizes="(max-width: 727px) 100vw, 727px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_24.png 1016w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_24-300x135.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_24-768x346.png 768w" height="328" width="727" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_24.png" loading="lazy"&gt;&lt;/p&gt; &lt;h2&gt;Networks Designed for Sequential Data&lt;/h2&gt; &lt;p&gt;Our ConvNet classifier outperformed our dense net—perhaps in large part because its convolutional layer is adept at learning patterns of words that predict some outcome, such as whether a film review is favorable or negative. The filters within convolutional layers tend to excel at learning short sequences like triplets of words (recall that we set &lt;code&gt;k = 3&lt;/code&gt; in Example 11.32), but a document of natural language like a movie review might contain much longer sequences of words that, when considered all together, would enable the model to accurately predict some outcome. To handle long sequences of data like this, there exists a family of deep learning models called recurrent neural networks (RNNs), which include specialized layer types like long short-term memory units (LSTMs) and &lt;em&gt;gated recurrent units&lt;/em&gt; (GRUs). In this section, we cover the essential theory of RNNs and apply several variants of them to our movie-review classification problem. We also introduce &lt;em&gt;attention&lt;/em&gt;—an especially sophisticated approach to modeling natural language data that is setting new benchmarks across NLP applications.&lt;/p&gt; &lt;pre&gt;As mentioned at the start of the chapter, the RNN family, including LSTMs and GRUs, is well suited to handling not only natural language data but also any input data that occur in a one-dimensional sequence. This includes price data (e.g., financial time series, stock prices), sales figures, temperatures, and disease rates (epidemiology). While RNN applications other than NLP are beyond the scope of this textbook, we collate resources for modeling quantitative data over time at jonkrohn.com/resources under the heading &lt;em&gt;Time Series Prediction&lt;/em&gt;. &lt;/pre&gt; &lt;h2&gt;Recurrent Neural Networks&lt;/h2&gt; &lt;p&gt;Consider the following sentences:&lt;/p&gt; &lt;p&gt;Jon and Grant are writing a book together. They have really enjoyed writing it.&lt;/p&gt; &lt;p&gt;The human mind can track the concepts in the second sentence quite easily. You already know that “they” in the second sentence refers to your authors, and “it” refers to the book we’re writing. Although this task is easy for you, however, it is not so trivial for a neural network.&lt;/p&gt; &lt;p&gt;The convolutional sentiment classifier we built in the previous section was able to consider a word only in the context of the two words on either side of it (&lt;code&gt;k_conv = 3&lt;/code&gt;, as in Example 11.32). With such a small window of text, that neural network had no capacity to assess what “they” or “it” might be referring to. Our human brains can do it because our thoughts loop around each other, and we revisit earlier ideas in order to in- form our understanding of the current context. In this section we introduce the concept of recurrent neural networks, which set out to do just that: They have loops built into their structure that allow information to persist over time.&lt;/p&gt; &lt;p&gt;The high-level structure of a recurrent neural network (RNN) is shown in Figure 11.25. On the left, the purple line indicates the loop that passes information between steps in the network. As in a dense network, where there is a neuron for each input, so too is there a neuron for each input here. We can observe this more easily on the right, where the schematic of the RNN is unpacked. There is a recurrent module for each word in the sentence (only the first four words are shown here for brevity).[Note: This is also why we have to pad shorter sentences during preprocessing: The RNN expects a sequence of a particular length, and so if the sequence is not long enough we add PAD tokens to make up the difference.] However, each module receives an additional input from the previous module, and in doing so the network is able to pass along information from earlier timesteps in the sequence. In the case of Figure 11.25, each word is represented by a distinct timestep in the RNN sequence, so the network might be able to learn that “Jon” and “Grant” were writing the book, thereby associating these terms with the word “they” that occurs later in the sequence.&lt;/p&gt; &lt;p&gt;&lt;img sizes="(max-width: 603px) 100vw, 603px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_25.png 1000w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_25-300x169.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_25-768x432.png 768w" height="340" width="603" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_25.png" loading="lazy"&gt;&lt;/p&gt; &lt;p&gt;Recurrent neural networks are, computationally, more complex to train than exclusively “feedforward” neural networks like the dense nets and CNNs we’ve used so far in the book. As depicted in Figure 8.6, feedforward networks involve backpropagating cost from the output layer back toward the input layer. If a network includes a recurrent layer (such as &lt;code&gt;SimpleRNN&lt;/code&gt;, &lt;code&gt;LSTM&lt;/code&gt;, or &lt;code&gt;GRU&lt;/code&gt;), then the cost must be backpropagated not only back toward the input layer, but back over the timesteps of the recurrent layer (from later timesteps back toward earlier timesteps), as well. Note that, in the same way that the gradient of learning vanishes as we backpropagate over later hidden layers toward earlier ones (see Figure 8.8), so, too, does the gradient vanish as we backpropagate over later timesteps within a recurrent layer toward earlier ones. Because of this, later timesteps in a sequence have more influence within the model than earlier ones do. [Note: If you suspect that the beginning of your sequences (e.g., the words at the beginning of a movie review) is generally more relevant to the problem you’re solving with your model (sentiment classification) than the end (the words at the end of the review), you can reverse the sequence before passing it as an input into your network. In that way, within your network’s recurrent layers, the beginning of the sequence will be backpropagated over before the end is.]&lt;/p&gt; &lt;h2&gt;Implementing an RNN in Keras&lt;/h2&gt; &lt;p&gt;Adding a recurrent layer to a neural network architecture to create an RNN is straightforward in Keras, as we illustrate in our &lt;em&gt;RNN Sentiment Classifier&lt;/em&gt; Jupyter notebook [or the &lt;a href="https://try.dominodatalab.com/u/domino-andrealowe/Natural-Language-Processing/overview"&gt;complementary Domino project&lt;/a&gt;]. For the sake of brevity and readability, please note that the following code cells are identical across all the Jupyter notebooks in this chapter, including the &lt;em&gt;Dense and Convolutional Sentiment Classifier&lt;/em&gt; notebooks that we’ve already covered:&lt;/p&gt; &lt;p&gt;The code cells that vary are those in which we:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Set hyperparameters&lt;/li&gt; &lt;li&gt;Design the neural network architecture&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;The hyperparameters for our RNN are as shown in Example 11.34.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example 11.34 RNN sentiment classifier hyperparameters&lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt;# output directory name: output_dir = 'model_output/rnn' # training: epochs = 16 # way more! batch_size = 128 # vector-space embedding: n_dim = 64 n_unique_words = 10000 max_review_length = 100 # lowered due to vanishing gradient over time pad_type = trunc_type = 'pre' drop_embed = 0.2 # RNN layer architecture: n_rnn = 256 drop_rnn = 0.2 &lt;/pre&gt; &lt;p&gt;Changes relative to our previous sentiment classifier notebooks are:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;We quadrupled epochs of training to 16 because overfitting didn’t occur in the early epochs.&lt;/li&gt; &lt;li&gt;We lowered &lt;code&gt;max_review_length&lt;/code&gt; back down to 100, although even this is excessive for a simple RNN. We can backpropagate over about 100 timesteps (i.e., 100 tokens or words in a natural language model) with an LSTM (covered in the next section) before the gradient of learning vanishes completely, but the gradient in a plain old RNN vanishes completely after about 10 timesteps. Thus, max_review_length could probably be lowered to less than 10 before we would notice a reduction in this model’s performance.&lt;/li&gt; &lt;li&gt;For all of the RNN-family architectures in this chapter, we experimented with doubling the word-vector vocabulary to 10000 tokens. This seemed to provide improved results for these architectures, although we didn’t test it rigorously.&lt;/li&gt; &lt;li&gt;We set &lt;code&gt;n_rnn = 256&lt;/code&gt;, so we could say that this recurrent layer has 256 &lt;em&gt;units&lt;/em&gt;, or, alternatively, we could say it has 256 &lt;em&gt;cells&lt;/em&gt;. In the same way that having 256 convolutional filters enabled our CNN model to specialize in detecting 256 unique triplets of word meaning,43 this setting enables our RNN to detect 256 unique sequences of word meaning that may be relevant to review sentiment. [Note: “Word meaning” here refers to a location in word-vector space]&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Our RNN model architecture is provided in Example 11.35.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example 11.35 RNN sentiment classifier architecture&lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt;from keras.layers import SimpleRNN model = Sequential() model.add(Embedding(n_unique_words, n_dim, input_length=max_review_length)) model.add(SpatialDropout1D(drop_embed)) model.add(SimpleRNN(n_rnn, dropout=drop_rnn)) model.add(Dense(1, activation='sigmoid')) &lt;/pre&gt; &lt;p&gt;In place of a convolutional layer or a dense layer (or both) within the hidden layers of this model, we have a Keras &lt;code&gt;SimpleRNN()&lt;/code&gt; layer, which has a dropout argument; as a result, we didn’t need to add dropout in a separate line of code. Unlike putting a dense layer after a convolutional layer, it is relatively uncommon to add a dense layer after a recurrent layer, because it provides little performance advantage. You’re welcome to try it by adding in a &lt;code&gt;Dense()&lt;/code&gt; hidden layer anyway.&lt;/p&gt; &lt;p&gt;The results of running this model (which are shown in full in our &lt;em&gt;RNN Sentiment Classifier&lt;/em&gt; notebook) were not encouraging. We found that the training loss, after going down steadily over the first half-dozen epochs, began to jump around after that. This indicates that the model is struggling to learn patterns even within the training data, which—relative to the validation data—it should be readily able to do. Indeed, all of the models fit so far in this book have had training losses that reliably attenuated epoch over epoch.&lt;/p&gt; &lt;p&gt;As the training loss bounced around, so too did the validation loss. We observed the lowest validation loss in the seventh epoch (0.504), which corresponded to a validation accuracy of 77.6 percent and an ROC AUC of 84.9 percent. All three of these metrics are our worst yet for a sentiment classifier model. This is because, as we mentioned earlier in this section, RNNs are only able to backpropagate through ~10 time steps before the gradient diminishes so much that parameter updates become negligibly small. Because of this, simple RNNs are rarely used in practice: More-sophisticated recurrent layer types like LSTMs, which can backpropagate through ~100 time steps, are far more common.[Note: The only situation we could think of where a simple RNN would be practical is one where your sequences only had 10 or fewer consecutive timesteps of information that are relevant to the problem you’re solving with your model. This might be the case with some time series forecasting models or if you only had very short strings of natural language in your dataset.]&lt;/p&gt; &lt;h2&gt;Long Short-Term Memory Units&lt;/h2&gt; &lt;p&gt;As stated at the end of the preceding section, simple RNNs are adequate if the space between the relevant information and the context where it’s needed is small (fewer than 10 timesteps); however, if the task requires a broader context (which is often the case in NLP tasks), there is another recurrent layer type that is well suited to it: long short-term memory units, or LSTMs.&lt;/p&gt; &lt;p&gt;LSTMs were introduced by Sepp Hochreiter and Jürgen Schmidhuber in 1997,[Note: Hochreiter, S., &amp;amp; Schmidhuber, J. (1997). Long short-term memory. Neural Computation, 9, 1735–80.] but they are more widely used in NLP deep learning applications today than ever before. The basic structure of an LSTM layer is the same as the simple recurrent layers captured in Figure 11.25.&lt;/p&gt; &lt;p&gt;LSTMs receive input from the sequence of data (e.g., a particular token from a natural language document), and they also receive input from the previous time point in the sequence. The difference is that inside each cell in a simple recurrent layer (e.g., &lt;code&gt;SimpleRNN()&lt;/code&gt; in Keras), you’ll find a single neural network activation function such as a tanh function, which transforms the RNN cell’s inputs to generate its output. In contrast, the cells of an LSTM layer contain a far more complex structure, as depicted in Figure 11.26.&lt;/p&gt; &lt;p&gt;&lt;img sizes="(max-width: 567px) 100vw, 567px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_26.png 1078w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_26-300x230.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_26-768x588.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_26-1024x785.png 1024w" height="434" width="567" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_26.png" loading="lazy"&gt;&lt;/p&gt; &lt;p&gt;This schematic can appear daunting, and, admittedly, we agree that a full step-by-step breakdown of each component inside of an LSTM cell is unnecessarily detailed for this book. [Note: For a thorough exposition of LSTM cells, we recommend Christopher Olah’s highly visual explainer, which is available at bit.ly/colahLSTM.] That said, there are a few key points that we should nevertheless touch on here. The first is the &lt;em&gt;cell state&lt;/em&gt; running across the top of the LSTM cell. Notice that the cell state does not pass through any nonlinear activation functions. In fact, the cell state only undergoes some minor linear transformations, but otherwise it simply passes through from cell to cell. Those two linear transformations (a multiplication and an addition operation) are points where a cell in an LSTM layer can add information to the cell state, information that will be passed onto the next cell in the layer. In either case, there is a sigmoid activation (represented by σ in the figure) &lt;em&gt;before&lt;/em&gt; the information is added to the cell state. Because a sigmoid activation produces values between 0 and 1, these sigmoids act as “gates” that decide whether new information (from the current timestep) is added to the cell state or not.&lt;/p&gt; &lt;p&gt;The new information at the current timestep is a simple concatenation of the current timestep’s input and the hidden state from the preceding timestep. This concatenation has two chances to be incorporated into the cell state—either linearly or following a nonlin- ear tanh activation—and in either case it’s those sigmoid gates that decide whether the information is combined.&lt;/p&gt; &lt;p&gt;After the LSTM has determined what information to add to the cell state, another sigmoid gate decides whether the information from the current input is added to the final cell state, and this results in the output for the current timestep. Notice that, under a different name (“hidden state”), the output is also sent into the next LSTM module (which represents the next timestep in the sequence), where it is combined with the next timestep’s input to begin the whole process again, and that (alongside the hidden state) the final cell state is also sent to the module representing the next timestep.&lt;/p&gt; &lt;p&gt;We know this might be a lot to come to grips with. Another way to distill this LSTM content is:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The cell state enables information to persist along the length of the sequence, through each timestep in a given LSTM cell. It is the &lt;em&gt;long&lt;/em&gt;-term memory of the LSTM.&lt;/li&gt; &lt;li&gt;The hidden state is analogous to the recurrent connections in a simple RNN and represents the short-term memory of the LSTM.&lt;/li&gt; &lt;li&gt;Each module represents a particular point in the sequence of data (e.g., a particular token from a natural language document).&lt;/li&gt; &lt;li&gt;At each timestep, several decisions are made (using those sigmoid gates) about whether the information at that particular timestep in the sequence is relevant to the local (hidden state) and global (cell state) contexts.&lt;/li&gt; &lt;li&gt;The first two sigmoid gates determine whether the information from the current timestep is relevant to the global context (the cell state) and how it will be com- bined into that stream.&lt;/li&gt; &lt;li&gt;The final sigmoid gate determines whether the information from the current timestep is relevant to the local context (i.e., whether it is added to the hidden state, which doubles as the output for the current timestep).&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;We recommend taking a moment to reconsider Figure 11.26 and see if you can follow how information moves through an LSTM cell. This task should be easier if you keep in mind that the sigmoid gates decide whether information is let through or not. Regardless, the primary take-aways from this section are:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Simple RNN cells pass only one type of information (the hidden state) between timesteps and contain only one activation function.&lt;/li&gt; &lt;li&gt;LSTM cells are markedly more complex: They pass two types of information between timesteps (hidden state and cell state) and contain five activation functions.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Implementing an LSTM with Keras&lt;/h2&gt; &lt;p&gt;Despite all of their additional computational complexity, as demonstrated within our &lt;em&gt;LSTM Sentiment Classifier&lt;/em&gt; notebook, implementing LSTMs with Keras is a breeze. As shown in Example 11.36, we selected the same hyperparameters for our LSTM as we did for our simple RNN, except:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;We changed the output directory name.&lt;/li&gt; &lt;li&gt;We updated variable names to &lt;code&gt;n_lstm&lt;/code&gt; and &lt;code&gt;drop_lstm&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;We reduced the number of epochs of training to 4 because the LSTM begins to overfit to the training data much earlier than the simple RNN.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Example 11.36 LSTM sentiment classifier hyperparameters&lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt;# output directory name: output_dir = 'model_output/LSTM' # training: epochs = 4 batch_size = 128 # vector-space embedding: n_dim = 64 n_unique_words = 10000 max_review_length = 100 pad_type = trunc_type = 'pre' drop_embed = 0.2 # LSTM layer architecture: n_lstm = 256 drop_lstm = 0.2 &lt;/pre&gt; &lt;p&gt;Our LSTM model architecture is also the same as our RNN architecture, except that we replaced the &lt;code&gt;SimpleRNN()&lt;/code&gt; layer with &lt;code&gt;LSTM()&lt;/code&gt;; see Example 11.37.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example 11.37 LSTM sentiment classifier architecture &lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt;from keras.layers import LSTM model = Sequential() model.add(Embedding(n_unique_words, n_dim, input_length=max_review_length)) model.add(SpatialDropout1D(drop_embed)) model.add(LSTM(n_lstm, dropout=drop_lstm)) model.add(Dense(1, activation='sigmoid')) &lt;/pre&gt; &lt;p&gt;The results of training the LSTM are provided in full in our &lt;em&gt;LSTM Sentiment Classifier&lt;/em&gt; notebook. To summarize, training loss decreased steadily epoch over epoch, suggesting that model-fitting proceeded more conventionally than with our simple RNN. The results are not a slam dunk, however. Despite its relative sophistication, our LSTM per- formed only as well as our baseline dense model. The LSTM’s epoch with the lowest validation loss is the second one (0.349); it had a validation accuracy of 84.8 percent and an ROC AUC of 92.8 percent.&lt;/p&gt; &lt;h2&gt;Bidirectional LSTMs&lt;/h2&gt; &lt;p&gt;Bidirectional LSTMs (or Bi-LSTMs, for short) are a clever variation on standard LSTMs. Whereas the latter involve backpropagation in only one direction (typically backward over timesteps, such as from the end of a movie review toward the beginning), bidirectional LSTMs involve backpropagation in both directions (backward &lt;em&gt;and forward&lt;/em&gt; over timesteps) across some one-dimensional input. This extra backpropagation doubles computational complexity, but if accuracy is paramount to your application, it is often worth it: Bi-LSTMs are a popular choice in modern NLP applications because their ability to learn patterns both before and after a given token within an input document facilitates high-performing models.&lt;/p&gt; &lt;p&gt;Converting our LSTM architecture (Example 11.37) into a Bi-LSTM architecture is painless. We need only wrap our &lt;code&gt;LSTM()&lt;/code&gt; layer within the &lt;code&gt;Bidirectional()&lt;/code&gt; wrapper, as shown in Example 11.38.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example 11.38 Bidirectional LSTM sentiment classifier architecture &lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt;from keras.layers import LSTM from keras.layers.wrappers import Bidirectional # new! model = Sequential() model.add(Embedding(n_unique_words, n_dim, input_length=max_review_length)) model.add(SpatialDropout1D(drop_embed)) model.add(Bidirectional(LSTM(n_lstm, dropout=drop_lstm))) model.add(Dense(1, activation='sigmoid')) &lt;/pre&gt; &lt;p&gt;The straightforward conversion from LSTM to Bi-LSTM yielded substantial performance gains, as the results of model-fitting show (provided in full in our &lt;em&gt;Bi LSTM Sentiment Classifier&lt;/em&gt; notebook). The epoch with the lowest validation loss (0.331) was the fourth, which had validation accuracy of 86.0 percent and an ROC AUC of 93.5 per- cent, making it our second-best model so far as it trails behind only our convolutional architecture.&lt;/p&gt; &lt;h2&gt;Stacked Recurrent Models&lt;/h2&gt; &lt;p&gt;Stacking multiple RNN-family layers (be they &lt;code&gt;SimpleRNN()&lt;/code&gt;, &lt;code&gt;LSTM&lt;/code&gt;, or another type) is not quite as straightforward as stacking dense or convolutional layers in Keras—although it certainly isn’t difficult: It requires only specifying an extra argument when the layer is defined.&lt;/p&gt; &lt;p&gt;As we’ve discussed, recurrent layers take in an ordered sequence of inputs. The recurrent nature of these layers comes from their processing each timestep in the sequence and passing along a hidden state as an input to the next timestep in the sequence. Upon reaching the &lt;em&gt;final&lt;/em&gt; timestep in the sequence, the output of a recurrent layer is the final hidden state.&lt;/p&gt; &lt;p&gt;So in order to stack recurrent layers, we use the argument &lt;code&gt;return_sequences=True&lt;/code&gt;. This asks the recurrent layer to return the hidden states for each step in the layer’s sequence. The resulting output now has three dimensions, matching the dimensions of the input sequence that was fed into it. The default behavior of a recurrent layer is to pass only the &lt;em&gt;final&lt;/em&gt; hidden state to the next layer. This works perfectly well if we’re passing this information to, say, a dense layer. If, however, we’d like the subsequent layer in our network to be another recurrent layer, that subsequent recurrent layer must receive a sequence as its input. Thus, to pass the array of hidden states from across all individual timesteps in the sequence (as opposed to only the single final hidden state value) to this subsequent recurrent layer, we set the optional &lt;code&gt;return_sequences&lt;/code&gt; argument to &lt;code&gt;True&lt;/code&gt;. [Note: There is also a return_state argument (which, like return_sequences, defaults to False) that asks the network to return the final cell state in addition to the final hidden state. This optional argument is not used as often, but it is useful when we’d like to initialize a recurrent layer’s cell state with that of another layer, as we do in “encoder-decoder” models (introduced in the next section)]&lt;/p&gt; &lt;p&gt;To observe this in action, check out the two-layer Bi-LSTM model shown in Example 11.39. (Notice that in this example we still leave the final recurrent layer with its default &lt;code&gt;return_sequences=False&lt;/code&gt; so that only the final hidden state of this final recurrent layer is returned for use further downstream in the network.)&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example 11.39 Stacked recurrent model architecture&lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt;from keras.layers import LSTM from keras.layers.wrappers import Bidirectional model = Sequential() model.add(Embedding(n_unique_words, n_dim, input_length=max_review_length)) model.add(SpatialDropout1D(drop_embed)) model.add(Bidirectional(LSTM(n_lstm_1, dropout=drop_lstm, return_sequences=True))) # new! model.add(Bidirectional(LSTM(n_lstm_2, dropout=drop_lstm))) model.add(Dense(1, activation='sigmoid')) &lt;/pre&gt; &lt;p&gt;As you’ve discovered a number of times since Chapter 1 of this book, additional layers within a neural network model can enable it to learn increasingly complex and abstract representations. In this case, the abstraction facilitated by the supplementary Bi-LSTM layer translated to performance gains. The stacked Bi-LSTM outperformed its unstacked cousin by a noteworthy margin, with an ROC AUC of 94.9 percent and validation accuracy of 87.8 percent in its best epoch (the second, with its validation loss of 0.296). The full results are provided in our &lt;em&gt;Stacked Bi LSTM Sentiment Classifier&lt;/em&gt; notebook.&lt;/p&gt; &lt;p&gt;The performance of our stacked Bi-LSTM architecture, despite being considerably more sophisticated than our convolutional architecture and despite being designed specifically to handle sequential data like natural language, nevertheless lags behind the accuracy of our ConvNet model. Perhaps some hyperparameter experimentation and fine-tuning would yield better results, but ultimately our hypothesis is that because the IMDb film review dataset is so small, our LSTM models don’t have an opportunity to demonstrate their potential. We opine that a much larger natural language dataset would facilitate effective backpropagation over the many timesteps associated with LSTM layers. [Note: If you’d like to test our hypothesis yourself, we provide appropriate sentiment analysis dataset suggestions in Chapter 14.]&lt;/p&gt; &lt;pre&gt;A relative of the LSTM within the family of RNNs is the gated recurrent unit (GRU). GRUs are slightly less computationally intensive than LSTMs because they involve only three activation functions, and yet their performance often approaches the performance of LSTMs. If a bit more compute isn’t a deal breaker for you, we see little advantage in choosing a GRU over an LSTM. If you’re interested in trying a GRU in Keras anyway, it’s as easy as importing the GRU() layer type and dropping it into a model architecture where you might otherwise place an LSTM() layer. Check out our &lt;em&gt;GRU Sentiment Classifier&lt;/em&gt; notebook for a hands-on example. [Note: Cho, K., et al. (2014). Learning phrase representations using RNN encoder-decoder for statistical machine translation. arXiv:1406.1078.] &lt;/pre&gt; &lt;h2&gt;Seq2seq and Attention&lt;/h2&gt; &lt;p&gt;Natural language techniques that involve so-called &lt;em&gt;sequence-to-sequence&lt;/em&gt; (seq2seq; pronounced “seek-to-seek”) models take in an input sequence and generate an output sequence as their product. &lt;em&gt;Neural machine translation&lt;/em&gt; (NMT) is a quintessential class of seq2seq models, with Google Translate’s machine-translation algorithm serving as an example of NMT being used in a production system. [Note: Google Translate has incorporated NMT since 2016. You can read more about it at bit.ly/translateNMT.]&lt;/p&gt; &lt;p&gt;NMTs consist of an &lt;em&gt;encoder-decoder&lt;/em&gt; structure, wherein the encoder processes the input sequence and the decoder generates the output sequence. The encoder and decoder are both RNNs, and so during the encoding step there exists a hidden state that is passed between units of the RNN. At the end of the encoding phase, the final hidden state is passed to the decoder; this final state can be referred to as the “context.” In this way, the decoder &lt;em&gt;starts&lt;/em&gt; with a context for what is happening in the input sequence. Although this idea is sound in theory, the context is often a bottleneck: It’s difficult for models to handle really long sequences, and so the context loses its punch.&lt;/p&gt; &lt;p&gt;&lt;em&gt;Attention&lt;/em&gt; was developed to overcome the computational bottleneck associated with context. [Note: Bahdanau, D., et al. (2014). Neural machine translation by jointly learning to align and translate. arXiv:1409.0473]. In a nutshell, instead of passing a single hidden state vector (the final one) from the encoder to the decoder, with attention we pass the full sequence of hidden states to the decoder. Each of these hidden states is associated with a single step in the input sequence, although the decoder might need the context from multiple steps in the input to inform its behavior at any given step during decoding. To achieve this, for each step in the sequence the decoder calculates a score for each of the hidden states from the encoder. Each encoder hidden state is multiplied by the softmax of its score. [Note: Recall from Chapter 6 that the softmax function takes a vector of real numbers and generates a probability distribution with the same number of classes as the input vector.]&lt;/p&gt; &lt;p&gt;This serves to amplify the most relevant contexts (they would have high scores, and thus higher softmax probabilities) while muting the ones that aren’t relevant; in essence, attention weights the available contexts for a given timestep. The weighted hidden states are summed, and this new context vector is used to predict the output for each timestep in the decoder sequence.&lt;/p&gt; &lt;p&gt;Following this approach, the model selectively reviews what it knows about the input sequence and uses only the relevant information where necessary to inform the output. It’s &lt;em&gt;paying attention&lt;/em&gt; to the most relevant elements of the whole sentence! If this book were dedicated solely to NLP, we’d have at least a chapter covering seq2seq and attention. As it stands, we’ll have to leave it to you to further explore these techniques, which are raising the bar of the performance of many NLP applications.&lt;/p&gt; &lt;h2&gt;Transfer Learning in NLP&lt;/h2&gt; &lt;p&gt;Machine vision practitioners have for a number of years been helped along by the ready availability of nuanced models that have been pretrained on large, rich datasets. As covered in the “Transfer Learning” section near the end of Chapter 10, casual users can download model architectures with pretrained weights and rapidly scale up their particular vision application to a state-of-the-art model. Well, more recently, such transfer learning has become readily available for NLP, too. [Note:When we introduced Keras Embedding() layers earlier in this chapter, we touched on transfer learning with word vectors. The transfer learning approaches covered in this section—ULMFiT, ELMo, and BERT—are closer in spirit to the transfer learning of machine vision, because (analogous to the hierarchical visual features that are represented by a deep CNN; see Figure 1.17) they allow for the hierarchical representation of the elements of natural language (e.g., subwords, words, and context, as in Figure 2.9). Word vectors, in contrast, have no hierarchy; they capture only the word level of language.]&lt;/p&gt; &lt;p&gt;First came ULMFiT (universal language model fine-tuning), wherein tools were described and open-sourced that enabled others to use a lot of what the model learns during pretraining. [Note: Howard, J., and Ruder, S. (2018). Universal language model fine-tuning for text classification. arXiv:1801.06146] In this way, models can be fine-tuned on task-specific data, thus requiring less training time and fewer data to attain high-accuracy results.&lt;/p&gt; &lt;p&gt;Shortly thereafter, ELMo (embeddings from language models) was revealed to the world. [Note: Peters, M.E., et al. (2018). Deep contextualized word representations. arXiv:1802.05365.] In this update to the standard word vectors we introduced in this chapter, the word embeddings are dependent not only on the word itself but also on the context in which the word occurs. In place of a fixed word embedding for each word in the dictionary, ELMo looks at each word in the sentence before assigning each word a specific embedding. The ELMo model is pretrained on a very large corpus; if you had to train it yourself, it would likely strain your compute resources, but you can now nevertheless use it as a component in your own NLP models.&lt;/p&gt; &lt;p&gt;The final transfer learning development we’ll mention is the release of BERT (bi-directional encoder representations from transformers) from Google. [Note: Devlin, J., et al. (2018). BERT: Pre-training of deep bidirectional transformers for language understanding. arXiv: 0810.04805.] Perhaps even more so than ULMFiT and ELMo, pretrained BERT models tuned to particular NLP tasks have been associated with the achievement of new state-of-the-art benchmarks across a broad range of applications, while requiring much less training time and fewer data to get there.&lt;/p&gt; &lt;h2&gt;Non-sequential Architectures: The Keras Functional API&lt;/h2&gt; &lt;p&gt;To solve a given problem, there are countless ways that the layer types we’ve already covered in this book can be recombined to form deep learning model architectures. For example, see our &lt;em&gt;Conv LSTM Stack Sentiment Classifier&lt;/em&gt; notebook, wherein we were extra creative in designing a model that involves a convolutional layer passing its activations into a Bi-LSTM layer.57 Thus far, however, our creativity has been con- strained by our use of the Keras &lt;code&gt;Sequential()&lt;/code&gt; model, which requires each layer to flow directly into a following one.&lt;/p&gt; &lt;p&gt;Although sequential models constitute the vast majority of deep learning models, there are times when non-sequential architectures—which permit infinite model-design possibilities and are often more complex—could be warranted.58 In such situations, we can take advantage of the Keras &lt;em&gt;functional API&lt;/em&gt;, which makes use of the Model class instead of the Sequential models we’ve worked with so far in this book.&lt;/p&gt; &lt;p&gt;As an example of a non-sequential architecture, we decided to riff on our highest- performing sentiment classifier, the convolutional model, to see if we could squeeze more juice out of the proverbial lemon. As diagrammed in Figure 11.27, our idea was to have three parallel streams of convolutional layers—each of which takes in word vectors from an &lt;code&gt;Embedding()&lt;/code&gt;layer.&lt;/p&gt; &lt;p&gt;&lt;img sizes="(max-width: 702px) 100vw, 702px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_27.png 1148w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_27-300x223.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_27-768x570.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_27-1024x760.png 1024w" height="521" width="702" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Figure-11_27.png" loading="lazy"&gt;&lt;/p&gt; &lt;p&gt;As in our &lt;em&gt;Convolutional Sentiment Classifier&lt;/em&gt; notebook, one of these streams would have a filter length of three tokens. One of the others will have a filter length of two—so it will specialize in learning word-vector pairs that appear to be relevant to classifying a film review as having positive or negative sentiment. The third convolutional stream will have a filter length of four tokens, so it will specialize in detecting relevant quadruplets of word meaning.&lt;/p&gt; &lt;p&gt;The hyperparameters for our three-convolutional-stream model are provided in Example 11.40 as well as in our &lt;em&gt;Multi ConvNet Sentiment Classifier&lt;/em&gt; Jupyter notebook [or the &lt;a href="https://try.dominodatalab.com/u/domino-andrealowe/Natural-Language-Processing/overview"&gt;complementary Domino project&lt;/a&gt;].&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example 11.40 Multi-ConvNet sentiment classifier hyperparameters &lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt;# output directory name: output_dir = 'model_output/multiconv' # training: epochs = 4 batch_size = 128 # vector-space embedding: n_dim = 64 n_unique_words = 5000 max_review_length = 400 pad_type = trunc_type = 'pre' drop_embed = 0.2 # convolutional layer architecture: n_conv_1 = n_conv_2 = n_conv_3 = 256 k_conv_1 = 3 k_conv_2 = 2 k_conv_3 = 4 # dense layer architecture: n_dense = 256 dropout = 0.2 &lt;/pre&gt; &lt;p&gt;The novel hyperparameters are associated with the three convolutional layers. All three convolutional layers have 256 filters, but mirroring the diagram in Figure 11.27, the layers form parallel streams—each with a unique filter length &lt;code&gt;(k)&lt;/code&gt; that ranges from 2 up to 4.&lt;/p&gt; &lt;p&gt;The Keras code for our multi-ConvNet model architecture is provided in Example 11.41.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example 11.41 Multi-ConvNet sentiment classifier architecture&lt;/strong&gt;&lt;/p&gt; &lt;pre title=""&gt;from keras.models import Model from keras.layers import Input, concatenate # input layer: input_layer = Input(shape=(max_review_length,), dtype='int16', name='input') # embedding: embedding_layer = Embedding(n_unique_words, n_dim, name='embedding')(input_layer) drop_embed_layer = SpatialDropout1D(drop_embed, name='drop_embed')(embedding_layer) # three parallel convolutional streams: conv_1 = Conv1D(n_conv_1, k_conv_1, activation='relu', name='conv_1')(drop_embed_layer) maxp_1 = GlobalMaxPooling1D(name='maxp_1')(conv_1) conv_2 = Conv1D(n_conv_2, k_conv_2, activation='relu', name='conv_2')(drop_embed_layer) maxp_2 = GlobalMaxPooling1D(name='maxp_2')(conv_2) conv_3 = Conv1D(n_conv_3, k_conv_3, activation='relu', name='conv_3')(drop_embed_layer) maxp_3 = GlobalMaxPooling1D(name='maxp_3')(conv_3) # concatenate the activations from the three streams: concat = concatenate([maxp_1, maxp_2, maxp_3]) # dense hidden layers: dense_layer = Dense(n_dense, activation='relu', name='dense')(concat) drop_dense_layer = Dropout(dropout, name='drop_dense')(dense_layer) dense_2 = Dense(int(n_dense/4), activation='relu', name='dense_2')(drop_dense_layer) dropout_2 = Dropout(dropout, name='drop_dense_2')(dense_2) # sigmoid output layer: predictions = Dense(1, activation='sigmoid', name='output')(dropout_2) # create model: model = Model(input_layer, predictions) &lt;/pre&gt; &lt;p&gt;This architecture may look a little alarming if you haven’t seen the Keras Model class used before, but as we break it down line-by-line here, it should lose any intimidating aspects it might have:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;With the &lt;code&gt;Model&lt;/code&gt; class, we specify the &lt;code&gt;Input()&lt;/code&gt; layer independently, as opposed to specifying it as the shape argument of the first hidden layer. We specified the data type (&lt;code&gt;dtype&lt;/code&gt;) explicitly: 16-bit integers (&lt;code&gt;int16&lt;/code&gt;) can range up to 32,767, which will accommodate the maximum index of the words we input.59 As with all of the layers in this model, we specify a recognizable name argument so that when we print the model later (using &lt;code&gt;model.summary()&lt;/code&gt;) it will be easy to make sense of everything.&lt;/li&gt; &lt;li&gt;Every layer is assigned to a unique variable name, such as &lt;code&gt;input_layer&lt;/code&gt;, &lt;code&gt;embedding_layer&lt;/code&gt;, and &lt;code&gt;conv_2&lt;/code&gt;. We will use these variable names to specify the flow of data within our model.&lt;/li&gt; &lt;li&gt;The most noteworthy aspect of using the Model class, which will be familiar to developers who have worked with functional programming languages, is the variable &lt;code&gt;name&lt;/code&gt; within the second set of parentheses following any layer call.&lt;/li&gt; &lt;li&gt;This specifies which layer’s outputs are flowing into a given layer. For example, (&lt;code&gt;input_layer&lt;/code&gt;) in the second set of parentheses of the &lt;code&gt;embedding_layer&lt;/code&gt; indicates that the output of the input layer flows into the embedding layer.&lt;/li&gt; &lt;li&gt;The &lt;code&gt;Embedding()&lt;/code&gt; and &lt;code&gt;SpatialDropout1D&lt;/code&gt; layers take the same arguments as before in this chapter.&lt;/li&gt; &lt;li&gt;The output of the &lt;code&gt;SpatialDropout1D&lt;/code&gt; layer (with a variable named &lt;code&gt;drop_embed_layer&lt;/code&gt;) is the input to three separate, parallel convolutional layers: &lt;code&gt;conv_1, conv_2, and conv_3&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;As per Figure 11.27, each of the three convolutional streams includes a Conv1D layer (with a unique &lt;code&gt;k_conv&lt;/code&gt; filter length) and a &lt;code&gt;GlobalMaxPooling1D&lt;/code&gt; layer.&lt;/li&gt; &lt;li&gt;The activations output by the &lt;code&gt;GlobalMaxPooling1D&lt;/code&gt; layer of each of the three convolutional streams are concatenated into a single array of activation values by the &lt;code&gt;concatenate()&lt;/code&gt; layer, which takes in a list of inputs ([&lt;code&gt;maxp_1, maxp_2, maxp_3&lt;/code&gt;]) as its only argument.&lt;/li&gt; &lt;li&gt;The concatenated convolutional-stream activations are provided as input to two &lt;code&gt;Dense()&lt;/code&gt; hidden layers, each of which has a &lt;code&gt;Dropout()&lt;/code&gt; layer associated with it. (The second dense layer has one-quarter as many neurons as the first, as specified by &lt;code&gt;n_dense/4&lt;/code&gt;.)&lt;/li&gt; &lt;li&gt;The activations output by the sigmoid output neuron (&lt;img title="\hat{y}" alt="\hat{y}" src="https://s0.wp.com/latex.php?latex=%5Chat%7By%7D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&amp;amp;c=20201002"&gt; ) are assigned to the variable name predictions.&lt;/li&gt; &lt;li&gt;Finally, the Model class ties all of the model’s layers together by taking two arguments: the variable name of the input layer (i.e., &lt;code&gt;input_layer&lt;/code&gt;) and the output layer (i.e., &lt;code&gt;predictions&lt;/code&gt;).&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Our elaborate parallel network architecture ultimately provided us with a modest bump in capability to give us the best-performing sentiment classifier in this chapter (see Table 11.6). As detailed in our &lt;em&gt;Multi ConvNet Sentiment Classifier&lt;/em&gt; notebook, the lowest validation loss was attained in the second epoch (0.262), and this epoch was associated with a validation accuracy of 89.4 percent and an ROC AUC of 96.2 percent—a tenth of a percent better than our &lt;code&gt;Sequential&lt;/code&gt; convolutional model.&lt;/p&gt; &lt;p&gt;&lt;img sizes="(max-width: 663px) 100vw, 663px" srcset="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_6.png 1050w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_6-300x151.png 300w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_6-768x386.png 768w, https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_6-1024x515.png 1024w" height="333" width="663" alt="" src="https://blog.dominodatalab.com/wp-content/uploads/2019/08/Krohn-Table-11_6.png" loading="lazy"&gt;&lt;/p&gt; &lt;h2&gt;Summary&lt;/h2&gt; &lt;p&gt;In this chapter, we discussed methods for preprocessing natural language data, ways to create word vectors from a corpus of natural language, and the procedure for calculating the area under the receiver operating characteristic curve. In the second half of the chapter, we applied this knowledge to experiment with a wide range of deep learning NLP models for classifying film reviews as favorable or negative. Some of these models involved layer types you were familiar with from earlier chapters (i.e., dense and convolutional layers), while later ones involved new layer types from the RNN family (LSTMs and GRUs) and, for the first time in this book, a non-sequential model architecture.&lt;/p&gt; &lt;p&gt;A summary of the results of our sentiment-classifier experiments are provided in Table 11.6. We hypothesize that, had our natural language dataset been much larger, the Bi-LSTM architectures might have outperformed the convolutional ones.&lt;/p&gt; &lt;p&gt;&lt;em&gt;&lt;sup&gt;Domino editorial note: we’ve moved the “footnotes” to be embedded in the narrative to increase online readability.&lt;/sup&gt;&lt;/em&gt;&lt;/p&gt; &lt;div&gt;&lt;h3&gt;Related posts:&lt;/h3&gt;&lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://blog.dominodatalab.com/deep-learning-illustrated-building-natural-language-processing-models/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:31:44 UT
      </pubDate>
      <guid>
        https://blog.dominodatalab.com/deep-learning-illustrated-building-natural-language-processing-models/
      </guid>
    </item>
    <item>
      <title>
        This 23-Year-Old Built and Sold His Startup While in School - Here’s How He Did It | First Round Review
      </title>
      <link>
        https://firstround.com/review/This-23-Year-Old-Built-and-Sold-His-Startup-While-In-School-Heres-What-Made-the-Difference/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;&lt;p id="text_8571c0301c70431b80a769c7f588a14a"&gt;From the moment&lt;a data-external="true" href="https://twitter.com/danshipper"&gt; Dan Shipper&lt;/a&gt;&amp;nbsp;stepped foot on the University of Pennsylvania’s campus, he knew he wanted to learn how to build a real software business with paying customers and steady revenue. He passed with flying colors last month when he both graduated from school and sold his company &lt;a data-external="true" href="http://usefirefly.com/"&gt;Firefly&lt;/a&gt; (the first company backed by &lt;a data-external="true" href="http://www.dormroomfund.com/"&gt;Dorm Room Fund&lt;/a&gt;) to&lt;a data-external="true" href="http://redeye.firstround.com/2014/06/graduationday.html"&gt; Pegasystems for multiple millions&lt;/a&gt;.&lt;/p&gt;&lt;p id="text_1a10415d48874a01a0ba742d983be012"&gt;Shipper’s success didn’t take anyone by surprise. Targeted early as a technology wunderkind, &lt;a data-external="true" href="http://www.businessinsider.com/startups-are-flinging-job-offers-at-dan-shipper-but-the-20-year-old-philosphy-major-rould-rather-stay-at-upenn-2012-5"&gt;he was receiving multiple job offers by his sophomore year&lt;/a&gt;. He chose to stay in school, he says, because he wasn’t done learning. Now, having seen his first company through an exit, he has a degree and perspective on what makes a real difference for young companies and entrepreneurs.&lt;/p&gt;&lt;p id="text_16e5685a597049f89afac3b3fbae80b0"&gt;In this exclusive First Round Review interview, Shipper shares the &lt;strong&gt;three tactics&lt;/strong&gt; that moved the needle the most for him and Firefly, and how beginning founders can get a head start on success.&lt;/p&gt;&lt;p id="text_da0b6fcf302e4e3da6e3818279a90b4d"&gt;&lt;strong&gt;Give Yourself Enough Time to Fail (or Succeed)&lt;/strong&gt;&lt;/p&gt;&lt;p id="text_e2827408554f4298a016f595574ba95e"&gt;In its first 10 months, Firefly brought in $11,000 in revenue — total. While Shipper and his co-founder &lt;a data-external="true" href="https://www.linkedin.com/pub/justin-meltzer/17/821/b"&gt;Justin Meltzer &lt;/a&gt;(pictured above, right) were sure the company solved a concrete problem — allowing two people to collaboratively browse the same webpage without any special software — sales weren’t promising. It would have been a valid decision to throw in the towel at that point, he says.&lt;/p&gt;&lt;p id="text_7b322ca351f6477c814fc740be007a69"&gt;“Because you have very limited information, it's easy to grab onto the data you have and spin a story about it,” Shipper says. “Like when you have a conversation with someone who really loves your product, you walk away thinking about how this is going to be the biggest thing ever. On the flipside, you see negative information, and you hit the lowest low, wondering why you’re even trying. Even though events like that make you feel very strong emotions, in both cases, the actual prospects for your company haven’t changed very much.”&lt;/p&gt;&lt;p id="text_6e462ae6504d4ace938657c775e85153"&gt;The human brain is not well equipped to handle uncertainty, so you anchor to whatever evidence seems solid. And if you happen to have the track record Firefly did 10 months in, you’d be hard pressed to forge on. But according to Shipper, “Knowing this is really helpful. Once you know where your brain is going to go, you can begin to see a way around things.”&lt;/p&gt;&lt;p id="text_90b7ae15657e4c08982a8a77ef2b08de"&gt;&lt;strong&gt;The other piece is to focus on what you’re learning — not just the numbers themselves&lt;/strong&gt;. “Instead of looking at who said what or how many customers are signing up, think about all the data you’re gathering,” he says. “So maybe you have this goal of getting 1,000 new customers a month, instead of looking at the past data thinking it’s impossible, think about what those bad months told you about customers, how you might do better, and how (or whether) what you’re building actually fits in to people’s lives and jobs.”&lt;/p&gt;&lt;p id="text_ccc9b5ab1e77492d88d799d6cc6eb850"&gt;For Firefly, Shipper and Meltzer made a big push to learn everything they could about the customer support industry — which they decided was the primary audience for their product. The key was to look at the last 10 months, and determine whether they needed to shift course based on the results. In their case, they stayed on the same path while making only small modifications to their approach. This allowed them to close big deals that paid off in the long run.&lt;/p&gt;&lt;p id="text_685c1433efbd47c5b99dc5edb9897700"&gt;“When you shift gears toward learning, you start thinking about whether what you’re doing really fits into the lives of the people who are buying your product,” he says. “It’s a good tool to help you manage your psychology because learning about your customers is much more immediate than something like monthly recurring revenue, which typically lags far behind.”&lt;/p&gt;&lt;p id="text_9f4ccfc69e414e898ba0d5faa8b39db3"&gt;A lot of entrepreneurs cite &lt;strong&gt;relentlessness&lt;/strong&gt; as a good quality to have. You want to be relentless about finding product market fit. You want to be relentless about building your product. There’s this idea that to succeed you can’t let up — you have to be driving hard toward your goal at all times. While Shipper agrees that this energy can be productive,&lt;strong&gt; it’s easy to be relentless about the wrong things&lt;/strong&gt;.&lt;/p&gt;&lt;p id="text_b620dac54e23436796728a92950fb937"&gt;“Being relentless is not enough,” he says. “It’s so easy to get trapped in these operant conditioning cycles where you have one good experience at a networking event, so you think you should go to every single one that’s similar even if that doesn’t directly serve the overall goals of your company.”&lt;/p&gt;&lt;blockquote id="text_06297e8db25b4be1af69293f16b59407"&gt;“You have to pair relentlessness with something else, and I think the best thing is being scrappy.”&lt;/blockquote&gt;&lt;p id="text_7f102fb5106b438eafe2f4432a45a176"&gt;As a tiny, bootstrapped company, Firefly had to make very deliberate decisions about what it could afford in terms of time and money. It had no choice but to be scrappy in its approach, which Shipper says helped him and the team execute against the right goals. “We set our sights on finding customers and trying to sell the product, and we didn’t think about anything else for a while,” he says. &lt;strong&gt;“&lt;/strong&gt;&lt;strong&gt;The best way to know if someone is going to buy a product is to actually try to sell it to them.&lt;/strong&gt;&lt;strong&gt;”&lt;/strong&gt;&lt;/p&gt;&lt;p id="text_3d1bb8bd59f045579931613ec5c5201b"&gt;Acting scrappy also makes you humble, and humility is sometimes the best sales tactic early on.&lt;/p&gt;&lt;p id="text_b2902a1cfed6492f941c25850a7ac228"&gt;“A lot of entrepreneurs — especially young entrepreneurs — enter markets without really knowing that much about them. When we started, we didn’t have a great sense of the customer service industry, but we were in a situation where we had to. You have to invest the time and energy in information gathering before you’re every going to have a good sales strategy.” Rather than try to gather information and then implement a sales strategy, in the early days Shipper and Meltzer used sales calls to actively collect data. “A lot of what we were doing was unsuccessfully pitching a lot of prospective customers and then humbly examining what had gone wrong so that we could do better next time.”&lt;/p&gt;&lt;blockquote id="text_ec4f9debefed4d5ab9f5c68261f1ba7c"&gt;“Going out there and selling is the best way to get the information you need.”&lt;/blockquote&gt;&lt;p id="text_f236050ca22c49d8904f898372782b3f"&gt;&lt;strong&gt;A lot of startups don’t give themselves enough time and runway to fail, so they never do find that coveted product-market fit. &lt;/strong&gt;As Shipper has observed, this outcome usually coincides with the belief that successful companies should see consistent, promising growth. But in his experience, startups go through long plateaus punctuated by a step change in growth. You have to wait for the step change.&lt;/p&gt;&lt;p id="text_205d741560af4d4da3bcff43d1c9ac02"&gt;“Induction doesn’t work with early stage startups. You can’t look at what’s happened in the past and project that you’ll be doing exactly the same amount of business in the future, or even along the same trajectory,” says Shipper. “Surface-level pattern recognition works very for many things, but it tends not to work well for startups. Simplistic pattern recognition says something like, ‘This company only made $1,000 in its first three months, therefore the team should pack up and go home.’ You have to understand why they only made $1,000 during those months to be able to say whether it’s because their business isn’t viable or for another reason. The psychology of running an early-stage company is difficult to manage partly because the emotional part of our brains uses surface-level pattern recognition to judge how we’re doing.”&lt;/p&gt;&lt;p id="text_a1ac9b0d73b442adb762fbf2ac6b364a"&gt;In evolutionary biology, there’s a theory called &lt;a data-external="true" href="http://en.wikipedia.org/wiki/Punctuated_equilibrium"&gt;punctuated equilibrium&lt;/a&gt;, the idea that species evolve almost imperceptibly for thousands if not millions of years, and then suddenly massive changes occur when there is a global catastrophe or the environment shifts radically. Suddenly, the rate of evolutionary change spikes.&lt;/p&gt;&lt;p id="text_657818d9ac124835962fb37fc89671c1"&gt;“Especially when you’re at the very early stages, startups behave a lot like this. One day you’re at the beginning level, and then you jump to the next, either when you get funding or land a huge customer or a big news story comes out that directly relates to your product. Something happens and you're dealing with a different situation right away. The thing is, it’s usually very hard to predict when or if that will happen to you, so you have to keep working. You can’t predict the future from the past. For example, take a look at &lt;a data-external="true" href="https://duckduckgo.com/"&gt;DuckDuckGo’s&lt;/a&gt; daily &lt;a data-external="true" href="https://duckduckgo.com/traffic.html"&gt;search queries graph&lt;/a&gt;, which is publicly available on their site. DDG was founded in 2008 as a search engine that doesn't track users' activity. The NSA scandal hit around July of 2013. Since that time, they’ve pretty much tripled the number of searches they were seeing per day.”&lt;/p&gt;&lt;p id="text_18480c9ca9814e5899d9565e71fcad95"&gt;In the case of Firefly, Shipper and Meltzer had a bunch of game-changing deals in the hopper for quite some time, with no clear sense of whether any would close. “If you’re trying to sell to larger organizations, they have a lot of priorities, a lot of people involved. You basically have to wait for the stars to align to get a green light on your product. Deals require very, very long leads," Shipper says.&lt;/p&gt;&lt;p id="text_9b96294a65f04fcfa446b919a98fc54a"&gt;“We’d have a full pipeline, but then one company would say they were going to push the deal back a quarter, others would just drop off, sometimes without us knowing why. In most cases, it was clear that larger businesses were hesitant to work with a startup, so they’d want to see how long they could keep us around, and how consistent we’d be in our service. The only thing to do was stick around and try to get people aligned around using this new technology.” Eventually Firefly’s pipeline started to produce.&lt;/p&gt;&lt;p id="text_f9c7c9e5d2e94dedb39a161b5bd60fc6"&gt;This isn’t to say that every startup should hang on to the very last straw. You simply don’t want to quit too early. “The best thing to do is nail down why things are not going well. Is it really clear that no one wants to buy what you’re selling because they don’t have the problems you’re trying to solve? Or is there evidence that your product could be useful eventually with enough feedback and traction?” You have to be brutally honest when you answer these questions, Shipper says. A lot of times things could improve if you only gave yourself more time and tried more things.&lt;/p&gt;&lt;figure id="image_6ec9612a35074d5e870ecc14941ab72d" data-zoomable="true" data-pinned="false" data-aspect_ratio="1.691" data-src_2560="https://s3.amazonaws.com/marquee-test-akiaisur2rgicbmpehea/BV3RmM6TkOercVhBHP27_founders.png" data-src_1280="https://s3.amazonaws.com/marquee-test-akiaisur2rgicbmpehea/8ZvRR619SnSIlhtIvtBk_founders.png" data-src_640="https://s3.amazonaws.com/marquee-test-akiaisur2rgicbmpehea/oMmkKu6SuWe58VGh7n8G_founders.png"&gt;&lt;p&gt;&lt;figcaption&gt;&lt;span&gt;Dan Shipper (L) and Justin Meltzer (R)&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/figcaption&gt;&lt;/p&gt;&lt;img src="https://s3.amazonaws.com/marquee-test-akiaisur2rgicbmpehea/BV3RmM6TkOercVhBHP27_founders.png"&gt;&lt;/figure&gt;&lt;p id="text_4a71a382920b4a9c885eecd5c3c5a2b7"&gt;&lt;strong&gt;Sell from the Very Beginning&lt;/strong&gt;&lt;/p&gt;&lt;p id="text_47bc3214bcc64dc59962460d2873df3c"&gt;Traditionally, companies build a product they feel good about and then try to sell it. Firefly started selling before its product was fully baked, and it turned out to be one of the best decisions they made. “We did a lot of outbound sales, cold calls, cold emails, and it was so much better from a learning perspective than using something like AdWords to sell the product,” Shipper says. “So many people say that to test an idea you should just throw up a landing page and buy some AdWords and see who you attract. Unless you have a lot of experience with AdWords that’s a bad idea. There’s this gigantic learning curve to doing online marketing right, so most likely you’re just going to buy ads that no one ever clicks on, or you’ll get people coming to your page who immediately leave when they see nothing real, and then they’ll never get converted. You could have the wrong keywords, bad ad copy, who knows?”&lt;/p&gt;&lt;p id="text_69c2df6eb6824833ae02b986c8c6ef8a"&gt;The Firefly team had a very different approach in mind — one that ended up paying off in big ways.&lt;/p&gt;&lt;p id="text_2300e743fc3348518a925c94b288a851"&gt;“We had the beginnings of the technology, and we knew which market would probably find it the most helpful — that was it. Then we started figuring out how to get it out there.”&lt;/p&gt;&lt;p id="text_9978143265a444158e0d10c1eb24cad2"&gt;Shipper and Meltzer started pitching customers who already had live customer service chat widgets that would pop up on their sites to help current visitors. They figured that being able to share a browser screen would be even better for companies to provide a higher level of service. They made a big list of those companies and emailed them to see if they were interested in what Firefly could do.&lt;/p&gt;&lt;p id="text_39660e7c4fd84acaaf529a747bc60e88"&gt;“The other thing we did was look for people within companies who had customer support or customer service roles and made appointments to talk to them. The tendency in these conversations is to do 100% of the talking, because you want to tell them everything your product can do — but you actually want the reverse. You want them to spend all the time talking. What do they not understand? Where do they keep getting stuck as you walk them through the demo? What do they ask the most questions about? That’s how you use your product as a catalyst to get information about how it should work.”&lt;/p&gt;&lt;p id="text_56653a4af94541adbca5ba602cc3b27b"&gt;Even though Firefly was still a work in progress at the time, Shipper and Meltzer were able to convert some of these early customers. They made it clear to the people they were talking to that they were specifically trying to improve their lives and jobs, and made them feel like they had a stake in the result.&lt;/p&gt;&lt;blockquote id="text_0541a19146d34fa19cd09dc059790e88"&gt;“You figure out what your product is only after selling it.”&lt;/blockquote&gt;&lt;p id="text_0acfc05ee0ea4b4496309934d80e4a6a"&gt;Of course the tactic of selling from the beginning only works if you’re prepared to immediately funnel the feedback you get into product development. Shipper and Meltzer made it a high priority to capture all of the data they gleaned from email replies and conversations to enter it into a feedback loop that yielded real, noticeable changes in how Firefly operated as software and a company.&lt;/p&gt;&lt;p id="text_7b9d1c2d0c06407897f0350d69c103b7"&gt;When asked how they managed to evolve both their product and sales process at the same time with a tiny team, Shipper says that it was critical for everyone involved to both understand the business and be able to ship code. This might sound like trying to build your own herd of unicorns, but it vastly accelerated their ability to land customers and deliver something to them on time. “Not only could everyone involved understand what was going on, but it was just easier to keep everyone in the know and on the same schedule. &lt;strong&gt;We’d all focus on sales during business hours and then switch to programming at night.&lt;/strong&gt;” At an early stage, this is feasible.&lt;/p&gt;&lt;p id="text_329a9262e1af4c04b2e4fb97822db11c"&gt;Notably, Shipper says, not all of the feedback they got through selling was about improving the product. A lot of what they learned improved their approach to sales too. “We had this initial idea of going to companies that used live chat customer service systems, but in doing so we realized how small most of them were. It occurred to us that we could sign up all of them individually and probably still not make that much. It was only after talking to them that we decided to go straight to the chat companies themselves that sell to the smaller businesses. They were bigger, making more money, looking for a competitive edge.” In their research, the Firefly team had discovered that the customer service chat sector was deeply fragmented, with upwards of 60 companies offering nearly identical products. In this environment, Firefly’s co-browsing capabilities would be a huge differentiator.&lt;/p&gt;&lt;p id="text_feedcf94061c4bd6adf7daf983eda602"&gt;This was the break the company needed to reach a much broader audience. It also led them down the path toward their current API model, allowing anyone to include their code on their platform for whatever purpose they wanted — not strictly customer support. “You can build any kind of collaborative app with our software," Shipper says. "Financial advisors can co-browse with their clients on an online portfolio, for example, without having to use straight screen sharing. We got there by seeing how we could sell to one company that would sell to many others.”&lt;/p&gt;&lt;p id="text_6eb1530a52774910a027e265ab18189d"&gt;&lt;strong&gt;Stay Small and Scrappy for as Long as Possible&lt;/strong&gt;&lt;/p&gt;&lt;p id="text_8f132dd886a44223b3591a93363e8e2a"&gt;“There are a lot of good things about not needing or even wanting to be a huge business immediately,” Shipper says. “You have time to really learn your industry and your customers, and how your product should change. It gives you time to concentrate on building the skills you’ll need to be successful instead of having your head in the clouds removed from the business on the ground.”&lt;/p&gt;&lt;p id="text_b5b4e585077c41f48a2f475b74847338"&gt;While small and scrappy can sound a lot like cash-strapped and vulnerable, Shipper argues that holding onto both can actually give you more control over your business. When you’re a small fish in a big pond, you’re immune to a lot of the problems larger and even mid-stage startups face (security issues, HR challenges, external pressure from a large pool of investors). “You end up having more flexibility to work on what you want on your own terms — and you can always reserve the option to go raise money or try to do something bigger.”&lt;/p&gt;&lt;p id="text_ceda616fabb248e6945c0f3ae8916a87"&gt;Shipper knows this on a personal level, having fielded some outrageous offers to drop out of school and join other companies. He steered Firefly the same way he steered his personal life — keeping things simple until he had all the information in hand and a clear idea of what he wanted.&lt;/p&gt;&lt;p id="text_67a7a939b29542e3a748d73db21b590b"&gt;“It’s hard to turn down a lot of money, but I kept asking myself and the team this big question:&lt;strong&gt; If we did bring in all this money, what did we actually need it for?&lt;/strong&gt; Money wasn’t really our bottleneck. Our bottleneck was figuring out a really good marketing strategy, how we could efficiently close customers, stuff like that," he says. "I think a lot of people get stuck in this mindset that if they have more employees then they’ll have more man hours and will be able to do more. They forget that more employees means more time spent hiring and more baggage. Not to mention all the time you spend raising money to pay these people.”&lt;/p&gt;&lt;p id="text_ad278f31111d439b8c5c2934afd3c4c5"&gt;Getting blinded by early millions and promises of rapid growth can actually make it harder to go fast, Shipper says. “If you’re at this early stage of discovery, where you’re doing your research and hammering out your strategy, you want a small team that doesn’t have the pressure that comes with taking a check. Once I understood that, I didn’t think about the money.”&lt;/p&gt;&lt;p id="text_fff42f54826e4c13a43f2638fc43adc9"&gt;One of the biggest problems early-stage startups that do take venture funding face is that they've sold a vision they can’t deliver on fast enough. “I think there’s a point for every startup where you have to decide if you want to go for it, and you think you can be huge, or whether you want to grow more slowly on your own. A lot of people think this point is the day you start building your product. My opinion is that it comes far down the line when you really know a lot more about your business.”&lt;/p&gt;&lt;blockquote id="text_bf7095f27dd54d9b9bff06ddada02122"&gt;“Funding can make you do things that you never would if you didn't feel like you had to.”&lt;/blockquote&gt;&lt;p id="text_a4020b90607d4538a2887a4582ca1fff"&gt;“The prevailing wisdom is that you should raise more money than you think you need, and I agree that’s probably true,” Shipper says. “It’s just that it should only happen when you’re confident in the fact that more money will allow you to grow much faster — when you’ve already found your trajectory and you just need to accelerate it. This isn’t always the case.” Until you feel this confidence, you should be building with as little money as possible. “Honestly, most products that get huge amounts of early funding could be built for something like $50,000," he says.&lt;/p&gt;&lt;p id="text_537ed0f1e14c4023b4d67bfab6ead950"&gt;Staving off large rounds can also give you more time to think about the type of backers and advisors you want to work with eventually. For Shipper, it gave him the space to cultivate relationships with people over email or through occasional dinners. He had the benefit of seeing who would maintain a longstanding interest in Firefly. “You want to look for people who will take the time themselves to really understand what’s going on not just in your business but in your industry. You want people who are in it for the long-term, and who are more interested in helping you succeed than in looking good.”&lt;/p&gt;&lt;p id="text_79be237ec08e433c8c107a424802960f"&gt;Incidentally, emphasizing this stay-small strategy also helped Firefly attract the right type of employees. “When you’re not raising any money and you’re building this thing on your own, you don’t oversell to people. I think this type of honesty resonates. Sure, there might be a chance that we’ll get big, but we’re not going to tell you that just so we can hire you or get you to work harder. You have to be here because you want to be, and you like the idea of being part of something self-sustaining, not just a big exit.”&lt;/p&gt;&lt;p id="text_3e283cdc1bad4da8bb998db543f313b4"&gt;All of this combined made Firefly an attractive acquisition target, Shipper says. By selling from the beginning and not being deterred by initial failure, their product gained so much momentum that customer support organizations were starting to demand co-browsing functionality.&lt;/p&gt;&lt;p id="text_03298643eb064d558c5b473b3b1a6d85"&gt;“More importantly, I think we gave ourselves a lot of options to choose what we wanted,” he says. “You can’t sell a company unless there’s a buyer first, and I think we found the right kind of buyer by running the company the way we wanted to for so long.”&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;a href="https://firstround.com/review/This-23-Year-Old-Built-and-Sold-His-Startup-While-In-School-Heres-What-Made-the-Difference/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:32:10 UT
      </pubDate>
      <guid>
        https://firstround.com/review/This-23-Year-Old-Built-and-Sold-His-Startup-While-In-School-Heres-What-Made-the-Difference/
      </guid>
    </item>
    <item>
      <title>
        How to get your first 10 customers
      </title>
      <link>
        http://danshipper.com/nothing-happens-until-the-sale-is-made
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt; &lt;h2&gt;&lt;a title="Permanent Link to How to get your first 10 customers" href="http://danshipper.com/nothing-happens-until-the-sale-is-made"&gt;How to get your first 10 customers&lt;/a&gt;&lt;/h2&gt; &lt;p&gt;&lt;em&gt;Preface: the assumption for this essay is that you’re building a B2B app, and you have something built but you’re having trouble getting people to pay for it&lt;/em&gt;&lt;/p&gt; &lt;p&gt;There are three problems with getting your first few customers:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;You (probably) don’t know how to sell things&lt;/li&gt; &lt;li&gt;You don’t know who you’re selling to&lt;/li&gt; &lt;li&gt;You don’t even really know &lt;em&gt;what&lt;/em&gt; you’re selling&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Nobody tells you how to answers these questions, and so most people go out to get initial traction in a haphazard way:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;They have a vague idea in mind for who wants their product&lt;/li&gt; &lt;li&gt;They’ve already built the product, so they put together a landing page which &lt;em&gt;which, like, totally speaks to the core value proposition&lt;/em&gt;&lt;/li&gt; &lt;li&gt;They write some combination of any of the following:&lt;br&gt; A few half-baked ads&lt;br&gt; A few forum posts&lt;br&gt; A few comments on relevant blogs&lt;br&gt; A few blog posts&lt;br&gt; A few cold emails to journalists (because, dude, we would BLOW UP if we could just get ‘Crunched)&lt;/li&gt; &lt;li&gt;They send these out into the wild, and (no surprise!), get very few responses&lt;/li&gt; &lt;li&gt;They conclude that the product must suck and that nobody wants it, because Mark Zuckerberg did exactly the same thing to launch Facebook at Harvard and look at how that worked out for him&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;If you try to get initial traction this way, it’s very difficult to untangle why it didn’t work:&lt;/p&gt; &lt;p&gt;Were the ads targeted to the wrong keyword?&lt;br&gt; Was the copy not compelling enough?&lt;br&gt; Was the sample size too small?&lt;br&gt; Or does no one want what I’m selling?&lt;/p&gt; &lt;p&gt;When they fail to get initial traction, most people conclude that the product is the problem. That no one wants what they’re selling.&lt;/p&gt; &lt;p&gt;They never consider that &lt;em&gt;the way they’re selling&lt;/em&gt; might be COMPLETELY wrong (either in the way the product is being pitched, who it’s being pitched to, or some combination of the two.)&lt;/p&gt; &lt;p&gt;I think most of us have been lulled into this sense that the second you post your new product to a listserve you should automatically get sucked into a 4 minute montage scene featuring dark ominous 9 Inch Nails background music only to be spat out at the end with enough money to buy that estate on the Amalfi Coast.&lt;/p&gt; &lt;p&gt;And when that doesn’t happen, our first response is always to blame the product.&lt;/p&gt; &lt;p&gt;Formally this is called the &lt;em&gt;actor observer bias&lt;/em&gt; which tells us that we tend to blame things that don’t go right in our lives to circumstances beyond our control:&lt;/p&gt; &lt;p&gt;“No one responded to my emails, so the product must suck. Nobody wants it, otherwise it would already be on TechCrunch.”&lt;/p&gt; &lt;p&gt;This is wrong. Here’s the truth:&lt;/p&gt; &lt;p&gt;You have learned nothing from spending $200 on Adwords, or writing a few comments, or sending cold emails to journalists.&lt;/p&gt; &lt;p&gt;Let me repeat: You have learned nothing. You get a big Zero. You have no actionable information.&lt;/p&gt; &lt;p&gt;Your product &lt;em&gt;could&lt;/em&gt; suck. But it could still also be completely your fault. Or it could be completely random that you didn’t get any responses. Maybe the journalists were having a bad day, or the three people who clicked on your ads were just bots.&lt;/p&gt; &lt;p&gt;The point is: buying a few ads, or sending a few emails, or writing a few blog posts is not enough to conclude anything.&lt;/p&gt; &lt;p&gt;Untangling why you’re not making sales seems like an almost insurmountable problem, especially when you realize that at the beginning you don’t even really know &lt;em&gt;what&lt;/em&gt; you’re selling.&lt;/p&gt; &lt;p&gt;The problem with startups is that you have to figure out WHAT you’re selling AS you’re selling it.&lt;/p&gt; &lt;p&gt;It’s like having a big black bag with a product inside it, and you have to run around selling it to people you see on the street. And worse, you’re not allowed to look into the bag to know what it is you’re selling. You can put your hands into it and feel around, but that’s the extent of it.&lt;/p&gt; &lt;p&gt;Ok, so how do you deal with this? How do you start to figure out what you’re selling, who you’re selling to, and how to sell? How do you get those first few customers?&lt;span id="more-182"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Find the value&lt;/strong&gt;&lt;br&gt; The most important question to answer when you’re starting out is this:&lt;/p&gt; &lt;p&gt;Where’s the value of my product? Who is it valuable for? And why is it valuable for them?&lt;/p&gt; &lt;p&gt;Everything else flows from that.&lt;/p&gt; &lt;p&gt;And it turns out that the best way to figure out these basic things out is BY selling your product.&lt;/p&gt; &lt;p&gt;Remember that Reid Hoffman quote about startups being like jumping off a cliff and building a plane on the way down? This is why:&lt;/p&gt; &lt;p&gt;You need to figure out what you’re doing as you’re doing it. You need to figure out how to sell and who you’re selling to and what you’re selling &lt;strong&gt;while&lt;/strong&gt; you’re selling it. And if you took VC money you have to do that in a very, very short time period.&lt;/p&gt; &lt;p&gt;At the beginning most people do things the opposite way: they assume that the product provides real value, they assume they know what that value is, and they combine these assumptions into a sales pitch. Then they run around and talk to a few people, get lukewarm responses, and conclude that the product sucks.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Don’t lie to yourself&lt;/strong&gt;&lt;br&gt; There are some times in life when you’re not going to get into trouble lying to yourself.&lt;/p&gt; &lt;p&gt;If your friend ditches you for dinner, you can always tell yourself: “Well I didn’t like him anyway.”&lt;/p&gt; &lt;p&gt;If you get a bad score on a math test, you can say: “The teacher sucks, it’s not my fault.”&lt;/p&gt; &lt;p&gt;We’re taught that this is an okay way to deal with the difficult situations that life throws at us. That these white lies are just harmless rationalizations that keep us sane.&lt;/p&gt; &lt;p&gt;There are at least two industries where you can’t do this:&lt;/p&gt; &lt;p&gt;Entrepreneurship and rocket science&lt;/p&gt; &lt;p&gt;If a SpaceX engineer lies to himself, the rocket blows up on the launch pad. If the entrepreneur lies to herself, her company will fail before it even gets started.&lt;/p&gt; &lt;p&gt;Telling yourself: I know what this product is, I know who wants this, and I know how to sell it, when you really don’t is only going to result in YOUR failure. Admitting to yourself that you need to find out what you don’t know is the first step in the right direction.&lt;/p&gt; &lt;p&gt;It’s important to recognize that if you’re just starting out you have no idea where the value of your product lies. And you should make it your goal, not to ram your vision down other people’s throats, but to &lt;em&gt;honestly&lt;/em&gt; find out whether your product is valuable, and if it is, who it’s valuable for.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Start with people first, not “hits”&lt;/strong&gt;&lt;br&gt; Most people start out by posting on forums or buying ads or writing blog posts because sitting behind a computer is a lot less scary than actually talking to people.&lt;/p&gt; &lt;p&gt;But in order to answer the questions that you need to answer at the beginning you’re going to need to talk to people, either on the phone or face to face. And you’re going to need to do that a lot.&lt;/p&gt; &lt;p&gt;This advice has been reiterated so many times that by now it’s pretty banal. But most blog posts say “talk to customers” and leave it at that.&lt;/p&gt; &lt;p&gt;Let’s talk more specifically about how to do it.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Identifying prospects&lt;/strong&gt;&lt;br&gt; Before you can go out and talk to people, you have to develop an idea of who you’re going to be talking to. Here’s a quick process for doing this:&lt;/p&gt; &lt;p&gt;(Note this advice is primarily targeted at B2B companies, but I believe, can be successfully applied to B2C companies as well)&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Develop a hypothesis about the target customer&lt;/li&gt; &lt;li&gt;Find companies that fit the bill&lt;/li&gt; &lt;li&gt;Think about: who at the company is going to want this?&lt;/li&gt; &lt;li&gt;Get their email and get in touch&lt;/li&gt; &lt;li&gt;Rinse and repeat&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;As an example of step one, our first hypothesis about potential customers for Firefly was that people who would find it useful would probably have installed a live chat program like Olark or SnapEngage on their site. So we started contacting their customers.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;How to find someone at a company&lt;/strong&gt;&lt;br&gt; Once you have a company in mind that you think will be relevant, now it’s time to actually find someone to talk to.&lt;/p&gt; &lt;p&gt;The lowest hanging fruit is reaching out to their catchall email like sales@ or &lt;a href="mailto:team@"&gt;team@&lt;/a&gt;. I wouldn’t recommend doing this, most of that stuff gets ignored.&lt;/p&gt; &lt;p&gt;There are really three options for doing this:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Look through LinkedIn&lt;/li&gt; &lt;li&gt;Look at something like Hoovers (if it’s a big company)&lt;/li&gt; &lt;li&gt;Look on their management team page&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&lt;strong&gt;How to find anyone’s email with just their name&lt;/strong&gt;&lt;br&gt; Once you find someone at a company, the next step is to actually get their email address. Most people don’t list their emails publicly so this requires some digging.&lt;/p&gt; &lt;p&gt;What I usually like to do is take their name e.g. Bob Smith and use an email address validator tool (like &lt;a href="http://network-tools.com/"&gt;this one&lt;/a&gt;) and do a little guess and check.&lt;/p&gt; &lt;p&gt;So if I was trying to find Bob Smith who works at XYZ company I would go to the email validator and try different combinations:&lt;/p&gt; &lt;p&gt;&lt;a href="mailto:bob.smith@xyzcompany.com"&gt;bob.smith@xyzcompany.com&lt;/a&gt;&lt;br&gt; &lt;a href="mailto:bsmith@xyzcompany.com"&gt;bsmith@xyzcompany.com&lt;/a&gt;&lt;br&gt; &lt;a href="mailto:bob@xyzcompany.com"&gt;bob@xyzcompany.com&lt;/a&gt;&lt;/p&gt; &lt;p&gt;And very often you’ll be able to guess their email after a few tries. Be careful though, some companies have catchall accounts that make any combination valid – so you’ll have to test at least one or two to verify that you’re getting a real result.&lt;/p&gt; &lt;p&gt;There are also other ways to do this:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Go to their Press page (many company list a press contact, and you can guess their company email format from the press contact’s email)&lt;/li&gt; &lt;li&gt;Use something like Jigsaw.com&lt;/li&gt; &lt;li&gt;Call their corporate number and ask to be transferred&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&lt;strong&gt;If you’re a student take advantage of it&lt;/strong&gt;&lt;br&gt; Being a student has certain advantages, and one of them is that fact that people will be more willing to talk to you, and more willing to help you out. Here’s an example cold email that you might send to someone that you want to talk to:&lt;/p&gt; &lt;p&gt;Subject: Hello from Philly!&lt;/p&gt; &lt;p&gt;Hi there,&lt;/p&gt; &lt;p&gt;I’m a student and I’m working on a project.&lt;/p&gt; &lt;p&gt;I know you work in Industry X and I’d love to get some advice. For reasons XYZ I feel like you would be really relevant for the problems I’m thinking about. Are you free to chat on X date next week?&lt;/p&gt; &lt;p&gt;By the way we both went to UPenn.&lt;/p&gt; &lt;p&gt;Go Quakers!&lt;/p&gt; &lt;p&gt;This is useful because it’s a low pressure way to start talking to people. You don’t even really have to be a student to do this – but in general, asking for advice in the beginning will be much lower stress than doing “cold sales emails.” It’s also more useful when you don’t know anything.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Be honest&lt;/strong&gt;&lt;br&gt; If you use the tactic above, be VERY careful to be honest about it. If you ask someone for advice and then go in and try to sell them they’re going to be angry. And rightfully so.&lt;/p&gt; &lt;p&gt;If you ask someone for advice, mean it. They might buy from you eventually, but remember that you’re still in the process of learning about your product, learning about your market, and learning how to sell. The sales will come eventually if you do enough outreach. Don’t rush it.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Shut up and listen to them&lt;/strong&gt;&lt;br&gt; When you’re on a sales call it’s very important to shut up and listen. Most people have a tendency to drone on and on about their product.&lt;/p&gt; &lt;p&gt;Don’t do this. If your call is successful, you’ll have talked way less than your prospect. (That’s advice &lt;a href="http://www.twitter.com/natsturner"&gt;Nat Turner&lt;/a&gt; gave me and it’s golden.)&lt;/p&gt; &lt;p&gt;Here are some questions you might want to ask:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;What’s your organizational focus in the near term? What are your priorities?&lt;/li&gt; &lt;li&gt;How frequently do you have X problem?&lt;/li&gt; &lt;li&gt;What’s your process like for buying software?&lt;/li&gt; &lt;li&gt;Who would be involved in the process?&lt;/li&gt; &lt;li&gt;How long does it normally take?&lt;/li&gt; &lt;li&gt;What other software are you currently using?&lt;/li&gt; &lt;li&gt;What do you do day-to-day?&lt;/li&gt; &lt;li&gt;What kind of tasks do you do repeatedly?&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&lt;strong&gt;Keep the chain going&lt;/strong&gt;&lt;br&gt; The biggest mistake you can make is letting someone who’s interested get off the phone without clear next steps. You want to know where you’re going before they hang up because people are busy, and unless they’re committed to something they’re unlikely to remember to do anything.&lt;/p&gt; &lt;p&gt;Feel free to ask: “So what are the next steps?”&lt;/p&gt; &lt;p&gt;&lt;strong&gt;To be clear, you only have to do the outbound stuff at the beginning&lt;/strong&gt;&lt;br&gt; I know that after I publish this article there’s going to be someone in the comments complaining about scale. “Doing this doesn’t scale,” they will say. “It doesn’t apply to a high growth business.”&lt;/p&gt; &lt;p&gt;To be clear, I’m not advocating doing this forever (unless your business model demands it). But I do think it’s &lt;em&gt;vastly&lt;/em&gt; more effective&amp;nbsp;than just spending a couple of hundred bucks on Adwords.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Nothing happens until the sale is made&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;If there’s one thing to take away from this post (practical tips aside) it’s this:&lt;/p&gt; &lt;p&gt;You should admit to yourself that you (probably) don’t know anything about your business. That you (likely) don’t know how to sell, who you’re selling to, or what you’re selling. That your product is inside of a black bag that you can’t look into. And that you should begin to deal with that uncertainty by selling your product anyway.&lt;/p&gt; &lt;p&gt;Something special happens every time you make a sale: a little piece of the product becomes visible. The product is still wrapped in its black bag, but when you make a sale you get to take a peak at it, only for a second.&lt;/p&gt; &lt;p&gt;And you have to pay attention to it, and write it down, and think about it, otherwise you’ll miss it completely.&lt;/p&gt; &lt;p&gt;The more sales you make, the more you’ll understand your product. And finally after about a year you’ll begin to know what it looks like. You’ll know every nook and cranny, every blemish and every beautiful curve. And you’ll know all of this even though you’ve never taken it out of its black bag.&lt;/p&gt; &lt;p&gt;And you won’t find out any of this by haphazardly sending emails to journalists, or posting on forums:&lt;/p&gt; &lt;p&gt;Nothing happens until the sale is made.&lt;/p&gt; &lt;p&gt;The sale is where you start to find the value, it’s where you start to learn how to sell, and it’s where you start to figure out &lt;em&gt;what&lt;/em&gt; you’re selling.&lt;/p&gt; &lt;p&gt;___&lt;/p&gt; &lt;p&gt;If you liked this post sign up to receive future &lt;a href="http://eepurl.com/qDl21"&gt;posts by email here&lt;/a&gt;. Or follow me on &lt;a href="http://www.twitter.com/danshipper"&gt;Twitter&lt;/a&gt;.&lt;/p&gt; &lt;p&gt; &lt;h3&gt;17 Jul 2013, 6:49pm | &lt;a href="http://danshipper.com/nothing-happens-until-the-sale-is-made#comments"&gt;&lt;span rel="182 http://danshipper.com/?p=182"&gt;80 comments&lt;/span&gt;&lt;/a&gt; &lt;/h3&gt; &lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="http://danshipper.com/nothing-happens-until-the-sale-is-made"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:32:13 UT
      </pubDate>
      <guid>
        http://danshipper.com/nothing-happens-until-the-sale-is-made
      </guid>
    </item>
    <item>
      <title>
        Charlie Munger On How To Build A $2 Trillion Startup
      </title>
      <link>
        http://danshipper.com/charlie-munger-on-how-to-build-a-2-trillion-startup
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt; &lt;h2&gt;&lt;a title="Permanent Link to Charlie Munger On How To Build A $2 Trillion Startup" href="http://danshipper.com/charlie-munger-on-how-to-build-a-2-trillion-startup"&gt;Charlie Munger On How To Build A $2 Trillion Startup&lt;/a&gt;&lt;/h2&gt; &lt;p&gt;&lt;a href="http://danshipper.com/wp-content/uploads/2015/01/Charlie-Munger.png"&gt;&lt;img sizes="(max-width: 600px) 100vw, 600px" srcset="http://danshipper.com/wp-content/uploads/2015/01/Charlie-Munger.png 600w, http://danshipper.com/wp-content/uploads/2015/01/Charlie-Munger-300x160.png 300w" height="319" width="600" alt="Charlie-Munger" src="http://danshipper.com/wp-content/uploads/2015/01/Charlie-Munger.png" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Imagine it’s January of 1884 in Atlanta, Georgia. Glotz, an affluent fellow citizen, has invited you to participate in a peculiar competition:&lt;/p&gt; &lt;p&gt;You and twenty others are invited to present a plan to start a business that will turn a $2 million investment into a business worth $2 trillion by the year 2034.&lt;/p&gt; &lt;p&gt;Glotz will personally give $2 million to the person who presents the most compelling pitch in exchange for half of the equity in the new venture. There are only a few stipulations:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;The new venture must exclusively sell beverages (specifically non-alcohol or “soft” beverages)&lt;/li&gt; &lt;li&gt;For reasons unknown Glotz has decided that company must be named Coca-Cola&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;You have 15 minutes. What would you say in your pitch?&lt;/p&gt; &lt;p&gt;That’s the question that billionaire Coca-Cola investor Charlie Munger posed to an audience at a talk in July of 1996.&lt;/p&gt; &lt;p&gt;What followed over the following few minutes was an entrancing exhibition of multi-disciplinary wisdom and business acumen. Munger’s main point is that the most complex questions often have basic answers rooted in elementary academic wisdom (mathematics, psychology, etc.) He wants to show that applying some of these ideas regularly can help us to better explain business success, and make better decisions.&lt;/p&gt; &lt;p&gt;To start his talk, Munger lays out five principles he will use in his pitch to Glotz:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Decide big no-brainer questions first&lt;/li&gt; &lt;li&gt;Use math to help explain the world&lt;/li&gt; &lt;li&gt;Think through problems in reverse&lt;/li&gt; &lt;li&gt;The best wisdom is elementary academic wisdom&lt;/li&gt; &lt;li&gt;Big (lollapalooza) results only come from a large combination of factors&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Munger then dives in to solving the problem with his first principle: the big no-brainer questions that can be answered first.&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;“Well, Glotz, the big “no-brainer” decisions that, to simplify our problem, should be made first are as follows: First, we are never going to create something worth $2 trillion by selling some generic beverage. Therefore, we must make your name, “Coca-Cola,” into a strong, legally protected trademark. Second, we can get to $2 trillion only by starting in Atlanta, then succeeding in the rest of the United States, then rapidly succeeding with our new beverage all over the world. This will require developing a product having universal appeal because it harnesses powerful elemental forces. And the right place to find such powerful elemental forces is in the subject matter of elementary academic courses.”&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;Off the bat, it’s interesting to note how his prescription for growth largely mirrors the conventional startup wisdom espoused by Peter Thiel and others: grow quickly in a small market that you can dominate and then expand from there.&lt;/p&gt; &lt;p&gt;In the case of software, that market is typically a small niche of consumers. In the case of Coca-Cola (especially in the 1800s) it’s a small concentration of consumers in a geographically circumscribed area.&lt;/p&gt; &lt;p&gt;Next Munger moves on to his second and third principles: numerical fluency and thinking in reverse.&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;“We will next use numerical fluency to ascertain what our target implies. We can guess reasonably that by 2034 there will be about eight billion beverage consumers in the world. On average, each of these consumers will be much more prosperous in real terms than the average consumer of 1884. Each consumer is composed mostly of water and must ingest about sixty-four ounces of water per day. This is eight, eight-ounce servings. Thus, if our new beverage, and other imitative beverages in our new market, can flavor and otherwise improve only twenty-five percent of ingested water worldwide, and we can occupy half of the new world market, we can sell 2.92 trillion eight-ounce servings in 2034. And if we can then net four cents per serving, we will earn $117 billion. This will be enough, if our business is still growing at a good rate, to make it easily worth $2 trillion.”&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;Munger continues:&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;“A big question, of course, is whether four cents per serving is a reasonable profit target for 2034. And the answer is yes if we can create a beverage with strong universal appeal. One hundred fifty years is a long time. The dollar, like the Roman drachma, will almost surely suffer monetary depreciation. Concurrently, real purchasing power of the average beverage consumer in the world will go way up. His proclivity to inexpensively improve his experience while ingesting water will go up considerably faster. Meanwhile, as technology improves, the cost of our simple product, in units of constant purchasing power, will go down. All four factors will work together in favor of our four-cent-per-serving profit target. Worldwide beverage-purchasing power in dollars will probably multiply by a factor of at least forty over 150 years. Thinking in reverse, this makes our profit-per-serving target, under 1884 conditions, a mere on fortieth of four cents or one tenth of a cent per serving. This is an easy-to-exceed target as we start out if our new product has universal appeal.”&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;In this section, Munger demonstrates the value of the basic math involved in a TAM (total addressable market) analysis as part of formulating a thesis for a business. Then he goes on to look at the basic cost structure of the business and ensures that the back-of-the-envelope math makes sense for him to reach his ultimate goal.&lt;/p&gt; &lt;p&gt;As part of this analysis he makes a lot of forward looking predictions with the benefit of hindsight (the depreciation of the dollar, the real purchasing power of the average consumer, worldwide beverage purchasing power etc.) but for now we can ignore those issues.&lt;/p&gt; &lt;p&gt;Munger continues on to the meat of his talk: the subject of creating a product compelling enough to be consumed daily by millions of people. This is where he’s going to bring out his fourth and fifth principles: the value of academic wisdom, and the forces that must be brought together to produce “lollapalooza” effects.&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;“We must next solve the problem of invention to create universal appeal. There are two intertwined challenges of large scale: First, over 150 years, we must cause a new-beverage market to assimilate about one-fourth of the world’s water ingestion. Second, we must so operate that half the new market is ours while all of our competitors combined are left to share the remaining half. These results are lollapalooza results. Accordingly we must attack our problem by causing every favorable factor we can think of to work for us. Plainly, only a powerful combination of many factors is likely to cause the lollapalooza consequences we desire. Fortunately, the solution to these intertwined problems turns out to be fairly easy if one has stayed awake in all the freshman [college] courses.&lt;/p&gt; &lt;p&gt;Let us start by exploring the consequences of our simplifying “no-brainer” decision that we must rely on a strong trademark. This conclusion automatically leads to an understanding of the essence of our business in proper elementary academic terms. We can see from the introductory course in psychology that, in essence, we are going into the business of creating and maintaining conditioned reflexes. The “Coca-Cola” trade name and trade dress will act as the stimuli, and the purchase and ingestion of our beverage will be the desired responses.&lt;/p&gt; &lt;p&gt;And how does one create and maintain conditioned reflexes? Well, the psychology text gives two answers: (1) by operant conditioning and (2) by classical conditioning, often called Pavlovian conditioning to honor the great Russian scientist. And, since we want a lollapalooza result, we must use both conditioning techniques – and all we can invent to enhance effects from each technique.”&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;Let’s take some time to define a few of the things that Munger is talking about here so that it’s easy to follow the rest of the argument. Munger is mostly interested in the psychology of consumer decision-making: how can we influence consumers to buy a lot of a certain type of product?&lt;/p&gt; &lt;p&gt;There are two that he’s going to talk about here: operant conditioning and classical conditioning.&lt;/p&gt; &lt;p&gt;Classical conditioning is the method by which a strong innate response can become invoked by a neutral stimulus.&lt;/p&gt; &lt;p&gt;The most famous demonstration of classical conditioning is the work the Russian physiologist Ivan Pavlov did with dogs: he conditioned dogs to salivate at the sound of a bell.&lt;/p&gt; &lt;p&gt;To do this, every time Pavlov fed his dogs he would ring a bell. After repeating this procedure a few times, Pavlov found that he could ring his bell and the dogs would salivate without any food being present! (It’s &lt;a href="http://www.cogsci.ecs.soton.ac.uk/cgi/psyc/newpsy?5.49"&gt;historically questionable&lt;/a&gt; whether Pavlov actually used a bell, but we’ll leave it in for simplicity.)&lt;/p&gt; &lt;p&gt;Getting back to the subject at hand, it’s probably clear why this concept is so powerful: it means that it’s possible to trigger an innate biological response with a stimulus of your choice. Like, for example, a logo.&lt;/p&gt; &lt;p&gt;Now let’s briefly talk about operant conditioning. B. F. Skinner, the famed Harvard behaviorist describes operant conditioning in this way:&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;“When a bit of behavior is followed by a certain kind of consequence, it is more likely to occur again, and a consequence having this effect is called a reinforcer.”&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;In case this is confusing, Skinner elaborates with an example:&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;“Food, for example, is a reinforcer to a hungry organism; anything the organism does that is followed by the receipt of food is more likely to be done again whenever the organism is hungry.”&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;There is also a distinction between different types of reinforcers: some are negative and some are positive:&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;“Some stimuli are called negative reinforcers; any response which reduces the intensity of such a stimulus – or ends it – is more likely to be emitted when the stimulus recurs. Thus, if a person escapes from a hot sun when he moves under cover, he is more likely to move under cover when the sun is again hot. The reduction in temperature reinforces the behavior it is ‘contingent upon’ – that is, the behavior it follows. Operant conditioning also occurs when a person simply avoids a hot sun – when, roughly speaking, he escapes from the threat of a hot sun.”&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;Now that we have a little bit more background, let’s get back to Munger. Right now he’s trying to figure out how to use operant conditioning to increase the consumption of his product:&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;“The operant conditioning part of our problem is easy to solve. We need only (1) maximize rewards of our beverage’s ingestion and (2) minimize possibilities that desired reflexes, once created by us, will be extinguished through operant conditioning by proprietors of competing products.&lt;/p&gt; &lt;p&gt;For operant conditioning rewards, there are only a few categories we will find practical:&lt;/p&gt; &lt;p&gt;(1) Food value in calories or other inputs;&lt;/p&gt; &lt;p&gt;(2) Flavor, texture, and aroma acting as stimuli to consumption under neural preprogramming of man through Darwinian natutal selection;&lt;/p&gt; &lt;p&gt;(3) Stimulus, as by sugar or caffeine;&lt;/p&gt; &lt;p&gt;(4) Cooling effect when man is too hot or warming effect when man is too cool.&lt;/p&gt; &lt;p&gt;Wanting a lollapalooza result, we will naturally include rewards in all the categories.&lt;/p&gt; &lt;p&gt;To start out, it is easy to decide to design our beverage for consumption cold. There is much less opportunity, without ingesting beverage, to counteract excessive heat, compared with excessive cold. Moreover, with excessive heat, much liquid must be consumed, and the reverse is not true. It also easy to decide to include both sugar and caffeine. After all, tea, coffee, and lemonade are already widely consumed. And, it is also clear that we must be fanatic about determining, through trial and error, flavor and other characteristics that will maximize human pleasure while taking in the sugared water and caffeine we will provide. And, to counteract possibilities that desired operant-conditioned reflexes, once created by us, will be extinguished by operant-conditioning-employing competing products, there is also an obvious answer: We will make it a permanent obsession in our company that our beverage, as fast as practicable, will at all times be available everywhere throughout the world. After all, a competing product, if it is never tried, can’t act as a reward creating a conflicting habit. Every spouse knows that.”&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;After talking through operant conditioning, Munger turns to classical conditioning:&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;“We must next consider the Pavlovian [classical] conditioning we must also use. In Pavlovian conditioning, powerful effects come from mere association. The neural system of Pavlov’s dog causes it to salivate at the bell it can’t eat. And the brain of man yearns for the type of beverage held by the pretty woman he can’t have. And so, Glotz, we must use every sort of decent, honorable Pavlovian conditioning we can think of. For as long as we are in business, our beverage and its promotion must be associated in consumer minds with all other things consumers like or admire.&lt;/p&gt; &lt;p&gt;Such extensive Pavlovian conditioning will cost a lot of money, particularly for advertising. We will spend big money as far ahead as we can imagine. But the money will be effectively spent. As we expand fast in our new beverage market, our competitors will face gross disadvantages of scale in buying advertising to create the Pavlovian conditioning they need. And this outcome, along with other volume-creates-power-effects, should help us gain and hold at least fifty percent of the new market everywhere. Indeed, provided buyers are scattered, our highest volumes will give us very extreme cost advantages in distribution.&lt;/p&gt; &lt;p&gt;Moreover, Pavlovian effects from mere association will help us choose the flavor, texture, and color of our new beverage. Considering Pavlovian effects, we will have wisely chosen the exotic and expensive-sounding name “Coca-Cola,” instead of a pedestrian name like “Glotz’s sugared, caffeinated water.” For similar Pavlovian reasons, it will be wise to have our beverage look pretty much like wine, instead of sugared water. And so we will artificially color our beverage if it comes out clear. And we will carbonate our water, making our product seem like champagne, or some other expensive beverage, while also making its flavor better and imitation harder to arrange for competing products. And, because we are going to attach so many expensive psychological effects to our flavor, that flavor should be different from any other standard flavor so that we maximize difficulties for competitors and give no accidental same-flavor benefit to any existing product.”&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;Having dealt with Pavlovian conditioning, Munger moves on to social proof:&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;“What else, from the psychology textbook, can help our new business? Well, there is that powerful ‘monkey-see, monkey-do’ aspect of human nature that psychologists often call ‘social proof.’ Social proof, imitative consumption triggered by mere sight of consumption, will not only help induce trial of our beverage. It will also bolster perceived rewards from consumption. We will always take this powerful social-proof factor into account as we design advertising and sales promotion and as we forego present profit to enhance present and future consumption. More than with most other products, increased selling power will come from each increase in sales.&lt;/p&gt; &lt;p&gt;We can now see, Glotz, that by combining (1) much Pavlovian conditioning, (2) powerful social-proof effects, and (3) wonderful-tasting, energy-giving, stimulating and desirably-cold beverage that causes much operant conditioning, we are going to get sales that speed up for a long time by reason of the huge mixture of factors we have chosen. Therefore, we are going to start something like an autocatalytic reaction in chemistry, precisely the sort of multi-factor-triggered lollapalooza effect we need.&lt;/p&gt; &lt;p&gt;The logistics and the distribution strategy of our business will be simple. There are only two practical ways to sell our beverage: (1) as a syrup to fountains and restaurants, and (2) as a complete carbonated-water product in containers. Wanting lollapalooza results, we will naturally do it both ways. And, wanting huge Pavlovian and social-proof effects we will always spend on advertising and sales promotion, per serving, over 40 percent of the fountain price for syrup needed to make the serving.&lt;/p&gt; &lt;p&gt;A few syrup-making plants can serve the world. However, to avoid needless shipping of mere space and water, we will need many bottling plants scattered over the world. We will maximize profits if (like early General Electric with light bulbs) we always set the first-sale price, either (1) for fountain syrup, or (2) for any container of our complete product. The best way to arrange this desirable profit-maximizing control is to make any independent bottler we need a subcontractor, not a vendee of syrup, and certainly not a vendee of syrup under a perpetual franchise specifying a syrup price frozen forever at its starting level.&lt;/p&gt; &lt;p&gt;Being unable to get a patent or copyright on our super important flavor, we will work obsessively to keep our formula secret. We will make a big hoopla over our secrecy, which will enhance Pavlovian effects. Eventually food-chemical engineering will advance so that our flavor can be copied with near exactitude. But, by that time, we will be so far ahead, with such strong trademarks and complete, “always available” worldwide distribution, that good flavor copying won’t bar us from our objective. Moreover, the advances in food chemistry that help competitors will almost surely be accompanied by technological advances that will help us, including refrigeration, better transportation, and, for dieters, ability to insert a sugar taste without inserting sugar’s calories. Also, there will be related beverage opportunities we will seize.&lt;/p&gt; &lt;p&gt;This brings us to a final reality check for our business plan. We will, once more, think in reverse like Jacobi. What must we avoid because we don’t want it? Four answers seem clear:&lt;/p&gt; &lt;p&gt;First, we must avoid the protective, cloying, stop-consumption effects of aftertaste that are a standard part of physiology, developed through Darwinian evolution to enhance the replication of man’s genes by forcing a generally helpful moderation on the gene carrier. To serve our ends, on hot days a consumer must be able to drink container after container of our product with almost no impediment from aftertaste. We will find a wonderful no-aftertaste flavor by trial and error and will thereby solve this problem.&lt;/p&gt; &lt;p&gt;Second, we must avoid ever losing even half of our powerful trademarked name. It will cost us mightily, for instance, if our sloppiness should ever allow sale of any other kind of “cola,” for instance, a “peppy cola.” If there is ever a “peppy cola,” we will be the proprietor of the brand.&lt;/p&gt; &lt;p&gt;Third, with so much success coming, we must avoid bad effects from envy, given a prominent place in the Ten Commandments because envy is so much a part of human nature. The best way to avoid envy, recognized by Aristotle, is to plainly deserve the success we get. We will be fanatic about product quality, quality of product presentation, and reasonableness of prices, considering the harmless pleasure it will provide.&lt;/p&gt; &lt;p&gt;Fourth, after our trademarked flavor dominates our new market, we must avoid making any huge and sudden change in our flavor. Even if a new flavor performs better in blind taste tests, changing to that new flavor would be a foolish thing to do. This follows because, under such conditions, our old flavor will be so entrenched in consumer preference by psychological effects that a big flavor change would do us little good. And it would do immense harm by triggering in consumers the standard deprival super-reaction syndrome that makes “take-aways” so hard to get in any type of negotiation and helps make most gamblers so irrational. Moreover, such a large flavor change would allow a competitor, by copying our old flavor, to take advantage of both (1) the hostile consumer super-reaction to deprival and (2) the huge love of our original flavor created by our previous work.&lt;/p&gt; &lt;p&gt;Well, that is my solution to my own problem of turning $2 million into $2 trillion, even after paying out billions of dollars in dividends. I think it would have won with Glotz in 1884 and should convince you more than you expected at the outset. After all, the correct strategies are clear after being related to elementary academic ideas brought into play by the helpful notions.”&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;During the rest of the piece, Munger discusses the parallels between his fictional business plan and Coca-Cola’s actual business (hint: they’re pretty much the same.) He then goes on to relate his story to the main purpose of the talk: our failure to use basic academic wisdom to make better decisions.&lt;/p&gt; &lt;p&gt;He chalks this up, in part, to a failure of academia to produce a useful synthesis of topics like psychology and behavioral economics. He thinks that academic departments are too narrowly focused, and the research of academics to circumscribed.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Is there bullshit to sniff out here?&lt;/strong&gt;&lt;br&gt; If you scan the shelves at an airport bookstore, you’re likely to find lots of books that, like Munger’s talk, purport to unveil some of the key attributes of successful companies. If you’ve ever been tempted to pick up a copy of &lt;em&gt;Think Like Zuck: The Five Business Secrets of Facebook’s Improbably Brilliant CEO Mark Zuckerberg&lt;/em&gt; you know what I mean.&lt;/p&gt; &lt;p&gt;Because this is a common trope in the business literature – and it’s one that we often swallow uncritically – I want to take a few paragraphs to instill in you a healthy dose of skepticism in any person that purports to unveil the hidden attributes of successful companies:&lt;/p&gt; &lt;p&gt;First, anything that attempts to reduce the success of a business to a few key principles misses out on the obscene complexity that underlies the growth of any kind of organization.&lt;/p&gt; &lt;p&gt;Second, it misses the fact that many (but not all) organizations are incentivized to hide the real story behind their growth in order to protect their image, their investors, their employees, or their (perceived or real) competitive advantages.&lt;/p&gt; &lt;p&gt;Third, these attributes are subject to interpretation via the halo effect: they are seen as good ONLY because the company is successful. Many times you’ll see a CEO characterized as a visionary perfectionist when the stock is up, and an micro-managing egoist when the stock is down.&lt;/p&gt; &lt;p&gt;Fourth, Munger’s talk is (knowingly) given with the benefit of hindsight. It’s easy to point to many of these things as sure signs of success – once the success has been achieved.&lt;/p&gt; &lt;p&gt;Fifth, the attributes you see are subject to selection bias: people generally only write books or give talks about successful companies. Just because a successful company has attribute A, doesn’t mean that there aren’t a thousand other companies with attribute A that went to the graveyard.&lt;/p&gt; &lt;p&gt;What we’re really looking for is evidence that a particular company attribute played a &lt;em&gt;causational&lt;/em&gt; role in their success – rather than just merely being associated with that success.&lt;/p&gt; &lt;p&gt;This is incredibly difficult, if not impossible, to do.&lt;/p&gt; &lt;p&gt;In the case of Munger’s talk I’m going to err on the side of believing him for two reasons:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;He puts his money where his mouth is. His very long investment track record provides some demonstration that his framework works at picking companies.&lt;/li&gt; &lt;li&gt;He doesn’t claim universal applicability. His goal isn’t to give you a foolproof way of predicting company success – it’s to give you a framework, based in basic ideas, to help you think about that success.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;So assuming we trust Munger, the next question we have to ask ourselves is: can we use what he’s saying?&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Is all of this useful?&lt;/strong&gt;&lt;br&gt; Clearly, if you’re running a big company this kind of framework could help you make better decisions. For example, had the executives at Coke who decided to introduce “New Coke” understood conditioning better they might have scrapped the plan before it became a disaster.&lt;/p&gt; &lt;p&gt;Similarly, if you’re an institutional investor evaluating a large consumer business like Coke he provides you an interesting framework to think about.&lt;/p&gt; &lt;p&gt;I think the argument can also be made that it provides a good framework for early-stage technology investors to think about – one that agrees with the startup-focused investors like Paul Graham, Peter Thiel, and others. (I think it’s always interesting when people who come from different backgrounds and work on different problems come to the similar conclusions about something, it usually means that there’s some truth to what they’re saying.)&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Applying Munger’s framework to technology investing&lt;/strong&gt;&lt;br&gt; If I had to summarize Munger’s advice in a few sentences (with the benefit of reading lots of other articles from him) it would be something like the following:&lt;/p&gt; &lt;p&gt;In order to get large (lollapalooza) effects like rapid growth you need to harness lots of different types of elementary forces. The forces to focus on create what we call positive feedback loops: they’re self-reinforcing. A causes B, B causes more A, which causes more B.&lt;/p&gt; &lt;p&gt;The forces of this type that Munger cites are psychological: operant conditioning and classical conditioning. All companies have to harness these kinds of psychological forces to grow. But there are other ones to look for as well:&lt;/p&gt; &lt;ul id="draft_check_box_list_3"&gt; &lt;li&gt;Economies of scale: the larger you are, the cheaper it is to produce your product, the more products you sell, the larger you get&lt;/li&gt; &lt;li&gt;Network effects: the larger the network becomes, the more valuable the network is, the larger the network gets&lt;/li&gt; &lt;li&gt;Word of mouth: the more of your product you sell, the more people talk about you, the more of your product you sell&lt;/li&gt; &lt;li&gt;Big data effects: the more data a search engine has the, the better search results it can return, the more data it gets&lt;/li&gt; &lt;li&gt;Incumbent advantages: the more large customers you have, the easier it gets to sign large customers, the more large customers you get&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Finding companies that harness these effects is important for technology investors because the venture investment model is predicated upon huge returns from companies that dominate large winner-take-all markets.&lt;/p&gt; &lt;p&gt;And how do you get a winner-take all market?&lt;/p&gt; &lt;p&gt;One company has to be able to build an ever-increasing advantage against its competitors. It needs to be able to achieve high enough velocity to escape the gravity of market competition.&lt;/p&gt; &lt;p&gt;But how do you build this kind of ever-increasing lead?&lt;/p&gt; &lt;p&gt;You effectively harness the self-reinforcing forces we’ve been discussing: conditioning, economies of scale, network effects, word of mouth, big data effects, and others.&lt;/p&gt; &lt;p&gt;But what if you’re not an investor. What if you’re thinking of starting your own company? Can you use these ideas to come up with a startup?&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Is this generative?&lt;/strong&gt;&lt;br&gt; The first question to ask about his framework is this: is it generative?&lt;/p&gt; &lt;p&gt;By this I mean, will it help me generate new ideas for businesses to start. The answer to this question is clearly: no.&lt;/p&gt; &lt;p&gt;Thinking to yourself, “What companies can I start that will have self-reinforcing feedback loops?” doesn’t make your brain generate new ideas. As always, the best way to generate these ideas is through experience.&lt;/p&gt; &lt;p&gt;Paul Graham writes, “The way to get startup ideas is not to try to think of startup ideas. It’s to look for problems, preferably problems you have yourself.”&lt;/p&gt; &lt;p&gt;Ok, so Munger’s framework isn’t generative. The next question we have to ask ourselves is: is it diagnostic? In other words, assuming that Munger has identified some key causational elements of successful companies, how valuable is it for helping us diagnose companies at the idea stage?&lt;/p&gt; &lt;p&gt;The answer to this question is: if you’re looking to build a billion dollar company, it’s at best a marginally helpful guide. And the fact that it’s not incredibly helpful isn’t really Munger’s fault. There’s just no framework of elements out there that would allow us to perfectly predict how well our ideas are going to turn out.&lt;/p&gt; &lt;p&gt;There are lots of reasons for this. Here are a couple:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Success is stochastic not deterministic&lt;/li&gt; &lt;li&gt;Execution is more important than mere idea&lt;/li&gt; &lt;li&gt;Your initial idea of what you’re building is often much different than what you actually build&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Because what you actually build is often much different than what you think you’re building at the beginning, exact analysis of this kind is difficult to do. At best, what it can help you with is a general “sniff” test:&lt;/p&gt; &lt;p&gt;In general, does my vision for this product seem like it has the potential to harness some of these forces?&lt;/p&gt; &lt;p&gt;If the answer is yes then it’s time to get on to the next step and build the damn thing.&lt;/p&gt; &lt;p&gt;–&lt;/p&gt; &lt;p&gt;&lt;em&gt;Works Cited:&lt;/em&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;Poor Charlie’s Almanack: The Wit and Wisdom of Charles T. Munger, Expanded Third Edition&lt;/span&gt;, Charlie Munger&lt;/p&gt; &lt;p&gt;&lt;span&gt;Beyond Freedom and Dignity&lt;/span&gt;, B.F. Skinner&lt;/p&gt; &lt;p&gt; &lt;h3&gt;19 Jan 2015, 4:45am | &lt;a href="http://danshipper.com/charlie-munger-on-how-to-build-a-2-trillion-startup#comments"&gt;&lt;span rel="224 http://danshipper.com/?p=224"&gt;2 comments&lt;/span&gt;&lt;/a&gt; &lt;/h3&gt; &lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="http://danshipper.com/charlie-munger-on-how-to-build-a-2-trillion-startup"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 12:32:43 UT
      </pubDate>
      <guid>
        http://danshipper.com/charlie-munger-on-how-to-build-a-2-trillion-startup
      </guid>
    </item>
    <item>
      <title>
        How I Became a Better Programmer
      </title>
      <link>
        https://jlongster.com/How-I-Became-Better-Programmer
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt; &lt;main&gt; &lt;div&gt; &lt;article&gt; &lt;div&gt; &lt;h2&gt;How I Became a Better Programmer&lt;/h2&gt; &lt;p&gt;March 20, 2017&lt;/p&gt; &lt;/div&gt; &lt;p id="p37"&gt;Several people at React Conf asked me for advice on becoming a better programmer. For some reason, people see me as a pretty advanced programmer worth listening to. I thought it would be worthwhile to write down my "mental model" for how I have approached programming over the years.&lt;/p&gt; &lt;p id="p38"&gt;Some details about me: I'm 32 years old and have over 10 years of solid experience. It probably wasn't until the last few years until I really felt confident in what I was doing. Even now, though, I continually doubt myself. The point is that this feeling doesn't go away, so just try to ignore it, keep hacking, and keep building experience.&lt;/p&gt; &lt;p id="p39"&gt;Let me be clear that these are only a few tips for improving your skills. Ultimately you need to figure out what works best for you. These are just things that I have found helpful.&lt;/p&gt; &lt;ul&gt; &lt;li id="li5"&gt;&lt;p id="p1"&gt;&lt;strong&gt;Find people who inspire you, but don't idolize them.&lt;/strong&gt;&lt;/p&gt; &lt;p id="p2"&gt;Over the years there have been many people that I looked up to and watched for new tech. I learned a lot by simply trusting they were right and digging into things they worked on. These people tend to be very productive, brilliant, and inspiring. Find them and let them inspire and teach you.&lt;/p&gt; &lt;p id="p3"&gt;However, make sure not to idolize them. It's easy to seem intimidating from a twitter feed, but if you look at how they work in real life, you'll see that they aren't that different. Hacks everywhere, etc. We're all just experimenting. Lastly, don't blindly trust them; if you disagree, engage them and learn from it. Some of my most productive conversations happened this way. &lt;/p&gt; &lt;p id="p4"&gt;My Emacs config is a mess. I don't know why my OCaml autocompletion is broken (it's been broken for over a month). I don't automate stuff and have to dig around in my shell history to find commands I need sometimes. I write the ugliest code at first. I stick things on the global object until I know what I'm doing. The most experienced programmer uses hacks all the time; the important part is that you're getting stuff done.&lt;/p&gt;&lt;/li&gt; &lt;li id="li9"&gt;&lt;p id="p6"&gt;&lt;strong&gt;Don't devalue your work.&lt;/strong&gt;&lt;/p&gt; &lt;p id="p7"&gt;Newer programmers tend to feel like their work isn't worth much because they are new. Or maybe you are an experienced programmer, but working in a new area that makes you uncomfortable. In my opinion, some of the best ideas come from newer programmers who see improvements to existing tech that those who have already-formed opinions don't see.&lt;/p&gt; &lt;p id="p8"&gt;Your work is worthwhile, no matter what. In the worst case, if your idea doesn't work out, the community will have learned better why that approach doesn't make sense. (A note to the community: it's up to us to execute on this and be welcoming to newcomers.)&lt;/p&gt;&lt;/li&gt; &lt;li id="li13"&gt;&lt;p id="p10"&gt;&lt;strong&gt;Don't feel pressured to work all the time.&lt;/strong&gt;&lt;/p&gt; &lt;p id="p11"&gt;With new tech coming out every day, it can feel like the world will move on without you if you take a night off. That's not true. In fact, you will do better work if you disengage a lot. Your perspective will be fresh, and I find myself subconsciously coming up with new ideas when I'm not working.&lt;/p&gt; &lt;p id="p12"&gt;The majority of the stuff being released every day is just a rehash of the same ideas. Truly revolutionary stuff only happens every few years. A good talk to watch on this subject is &lt;a href="https://www.youtube.com/watch?v=f84n5oFoZBc"&gt;Hammock Driven Development&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt; &lt;li id="li18"&gt;&lt;p id="p14"&gt;&lt;strong&gt;Ignore fluff.&lt;/strong&gt;&lt;/p&gt; &lt;p id="p15"&gt;One of the biggest ways you can objectively get better faster is by ignoring "fluff" that won't actually improve your skills very much. Another way to say this is "use your time wisely". You only have so many hours in the day and if you spend it on deeper things you will see a big difference over time.&lt;/p&gt; &lt;p id="p16"&gt;So what is "fluff"? It's up to you, but I can give you some examples of what I consider fluff: language syntax, library APIs, and configuring build tooling. Learning a new ES7 JS syntax won't make you a better programmer nearly as much as learning how compilers work, for example. Adopting a new library that implements the same idea but with a new API isn't that interesting. All of those things are important, of course, but I recommend spending &lt;em&gt;more&lt;/em&gt; time learning deeper concepts that will reward you for years.&lt;/p&gt; &lt;p id="p17"&gt;Here's a question I like to ask: do you spend most of your time making your code look "nice"? If so, I recommend not focusing on it so much. Your code is going to change a lot over time anyway. It's better to focus hard on the core problems you're trying to solve and think hard about your layers of abstractions. After you've nailed all of that you can spend a little time polishing your code. (This also applies to the DRY principle. Don't worry about it so much. Feel free to duplicate.)&lt;/p&gt;&lt;/li&gt; &lt;li id="li24"&gt;&lt;p id="p19"&gt;&lt;strong&gt;Dig into past research.&lt;/strong&gt;&lt;/p&gt; &lt;p id="p20"&gt;If you're excited about an idea, it's super tempting to sit down an immediately get going. But you shouldn't do that until you've done some cursory research about how people have solved it before. Spending a few days researching the topic &lt;em&gt;always&lt;/em&gt; completely changes how I am going to solve it.&lt;/p&gt; &lt;p id="p21"&gt;It's valuable to learn how to read academic papers. I don't know anything about denotational/operational/etc semantics so there are a lot of papers I can't read. But there are many that use code instead of math and aren't too hard to read. There is a &lt;em&gt;huge&lt;/em&gt; amount of knowledge sitting in papers from the last 30 years. If you get good at extracting this, you'll be a thought-leader in no time.&lt;/p&gt; &lt;p id="p22"&gt;&lt;a href="https://github.com/prettier/prettier"&gt;Prettier&lt;/a&gt; is a perfect example of this. I knew what I wanted but I had &lt;em&gt;no&lt;/em&gt; idea how to implement it. After a little research I found &lt;a href="http://homepages.inf.ed.ac.uk/wadler/papers/prettier/prettier.pdf"&gt;this paper&lt;/a&gt; and after a few days I knew exactly what I needed to do. I had something basic working in a week. If I ignored previous research it would have taken a lot longer.&lt;/p&gt; &lt;p id="p23"&gt;If you're looking for papers, the &lt;a href="https://github.com/papers-we-love/papers-we-love"&gt;Papers We Love&lt;/a&gt; GitHub repo is a great place to start.&lt;/p&gt;&lt;/li&gt; &lt;li id="li36"&gt;&lt;p id="p31"&gt;&lt;strong&gt;Take on big projects. Get uncomfortable.&lt;/strong&gt;&lt;/p&gt; &lt;p id="p32"&gt;There's nothing better than experience. Not everyone is in the position to experiment, but if you have time, try and take on some big projects. You don't even need to finish them. Just trying to tackle something like writing a compiler will teach you tons in the first few weeks.&lt;/p&gt; &lt;p id="p33"&gt;I honestly hate the feeling where I have no idea how to solve a complex problem. It's uncomfortable. I know I'll have to do a lot of research and learning before I'm even close to a solution. But I'm always a much better programmer afterwards.&lt;/p&gt; &lt;p id="p34"&gt;Start with learning a new language. It's the most effective way to force you out of your current habits and see things in a new light. For me, the best thing I did as a young programmer was learn &lt;a href="https://en.wikipedia.org/wiki/Scheme_(programming_language)"&gt;Scheme&lt;/a&gt;. It's an extremely simple language and forces you to do everything in a functional style, and really learn the fundamentals of how code works. The few years I spent in Scheme are &lt;em&gt;still&lt;/em&gt; paying off today; the way I see code is fundamentally changed. (I even named my company Shift Reset LLC after the &lt;a href="https://en.wikipedia.org/wiki/Delimited_continuation"&gt;shift/reset&lt;/a&gt; operators from Scheme.)&lt;/p&gt; &lt;p id="p35"&gt;Here's a list of a few things I would recommend doing. These are all things that had huge impacts on my programmer career. Most of them continue to pay off to this day in subtle ways and help me to deconstruct new ideas mentally. &lt;strong&gt;You don't need to do these to become a good programmer&lt;/strong&gt;, and there are many other things you can learn to improve yourself, but these are what helped me.&lt;/p&gt; &lt;ul&gt;&lt;li id="li25"&gt;&lt;strong&gt;Learn C&lt;/strong&gt; - Just the basics, if you don't already. I think it's valuable to understand why everyone complains about it.&lt;/li&gt; &lt;li id="li26"&gt;&lt;strong&gt;Write a compiler&lt;/strong&gt; - Perhaps the best way to get uncomfortable and learn. Check out &lt;a href="https://github.com/thejameskyle/the-super-tiny-compiler"&gt;the super tiny compiler&lt;/a&gt;.&lt;/li&gt; &lt;li id="li27"&gt;&lt;strong&gt;Learn macros&lt;/strong&gt; - See Scheme, Lisp, or Clojure(Script). Macros will really change how you see code.&lt;/li&gt; &lt;li id="li28"&gt;&lt;strong&gt;SICP&lt;/strong&gt; - &lt;a href="https://mitpress.mit.edu/sicp/full-text/book/book.html"&gt;SICP&lt;/a&gt; is an old book that I think is still relevant today (some people disagree). It assumes very little programming knowledge and walks you all the way up to implementing a meta-circular evaluator and compiler. Another book I really enjoyed and goes a lot deeper in compilers is &lt;a href="https://www.amazon.com/Lisp-Small-Pieces-Christian-Queinnec/dp/0521545668"&gt;Lisp In Small Pieces&lt;/a&gt;.&lt;/li&gt; &lt;li id="li29"&gt;&lt;strong&gt;Understand continuations&lt;/strong&gt; - &lt;a href="https://en.wikipedia.org/wiki/Continuation"&gt;Continuations&lt;/a&gt; are a low-level control flow mechanism. Scheme is the only language to implement them, and while you will never use them in production, they will change how you think about control flow. I wrote a &lt;a href="https://archive.jlongster.com/Whats-in-a-Continuation"&gt;blog post&lt;/a&gt; trying to explain them.&lt;/li&gt; &lt;li id="li30"&gt;&lt;strong&gt;If anything, just try a new language&lt;/strong&gt; - Regardless of what you do, you really should explore other languages. I would recommend any of the following: Clojure, Rust, Elm, OCaml/Reason, Go, or Scheme. All of them have unique features and will force you to learn a new way of thinking.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/article&gt; &lt;/div&gt; &lt;/main&gt; &lt;/div&gt;&lt;div&gt; &lt;p&gt;&lt;a href="https://jlongster.com/"&gt;&lt;img src="https://jlongster.com/img/logo2.svg"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt; James Long is a developer &amp;amp; designer with over a decade of experience building large-scale applications. &lt;a href="mailto:longster@gmail.com"&gt;Get in touch&lt;/a&gt; &lt;/p&gt; &lt;p&gt; © James Long 2020 &lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://jlongster.com/How-I-Became-Better-Programmer"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 19:25:55 UT
      </pubDate>
      <guid>
        https://jlongster.com/How-I-Became-Better-Programmer
      </guid>
    </item>
    <item>
      <title>
        Introduction &amp;#xB7; mostly-adequate-guide
      </title>
      <link>
        https://mostly-adequate.gitbooks.io/mostly-adequate-guide/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div id="book-search-results" role="main" tabindex="-1"&gt; &lt;section&gt; &lt;p&gt;&lt;a href="https://mostly-adequate.gitbooks.io/mostly-adequate-guide/SUMMARY.md"&gt;&lt;img alt="cover" src="https://mostly-adequate.gitbooks.io/mostly-adequate-guide/images/cover.png"&gt;&lt;/a&gt;&lt;/p&gt; &lt;h2 id="about-this-book"&gt;About this book&lt;/h2&gt; &lt;p&gt;This is a book on the functional paradigm in general. We'll use the world's most popular functional programming language: JavaScript. Some may feel this is a poor choice as it's against the grain of the current culture which, at the moment, feels predominately imperative. However, I believe it is the best way to learn FP for several reasons:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt;&lt;strong&gt;You likely use it every day at work.&lt;/strong&gt;&lt;/p&gt; &lt;p&gt; This makes it possible to practice and apply your acquired knowledge each day on real world programs rather than pet projects on nights and weekends in an esoteric FP language.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt;&lt;strong&gt;We don't have to learn everything up front to start writing programs.&lt;/strong&gt;&lt;/p&gt; &lt;p&gt; In a pure functional language, you cannot log a variable or read a DOM node without using monads. Here we can cheat a little as we learn to purify our codebase. It's also easier to get started in this language since it's mixed paradigm and you can fall back on your current practices while there are gaps in your knowledge.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt;&lt;strong&gt;The language is fully capable of writing top notch functional code.&lt;/strong&gt;&lt;/p&gt; &lt;p&gt; We have all the features we need to mimic a language like Scala or Haskell with the help of a tiny library or two. Object-oriented programming currently dominates the industry, but it's clearly awkward in JavaScript. It's akin to camping off of a highway or tap dancing in galoshes. We have to &lt;code&gt;bind&lt;/code&gt; all over the place lest &lt;code&gt;this&lt;/code&gt; change out from under us, we have various work arounds for the quirky behavior when the &lt;code&gt;new&lt;/code&gt; keyword is forgotten, private members are only available via closures. To a lot of us, FP feels more natural anyways.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;That said, typed functional languages will, without a doubt, be the best place to code in the style presented by this book. JavaScript will be our means of learning a paradigm, where you apply it is up to you. Luckily, the interfaces are mathematical and, as such, ubiquitous. You'll find yourself at home with Swiftz, Scalaz, Haskell, PureScript, and other mathematically inclined environments.&lt;/p&gt; &lt;h2 id="read-it-online"&gt;Read it Online&lt;/h2&gt; &lt;p&gt;For a best reading experience, &lt;a href="https://mostly-adequate.gitbooks.io/mostly-adequate-guide/"&gt;read it online via Gitbook&lt;/a&gt;.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Quick-access side-bar&lt;/li&gt; &lt;li&gt;In-browser exercises&lt;/li&gt; &lt;li&gt;In-depth examples&lt;/li&gt; &lt;/ul&gt; &lt;h2 id="play-around-with-code"&gt;Play Around with Code&lt;/h2&gt; &lt;p&gt;To make the training efficient and not get too bored while I am telling you another story, make sure to play around with the concepts introduced in this book. Some can be tricky to catch at first and are better understood by getting your hand dirty. All functions and algebraic data-structures presented in the book are gathered in the appendixes. The corresponding code is also available as an npm module:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;$ npm i @mostly-adequate/support &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Alternatively, exercises of each chapter are runnable and can be completed in your editor! For example, complete the &lt;code&gt;exercise_*.js&lt;/code&gt; in &lt;code&gt;exercises/ch04&lt;/code&gt; and then run:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;$ npm run ch04 &lt;/code&gt;&lt;/pre&gt; &lt;h2 id="download-it"&gt;Download it&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://www.gitbook.com/download/pdf/book/mostly-adequate/mostly-adequate-guide"&gt;Download PDF&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.gitbook.com/download/epub/book/mostly-adequate/mostly-adequate-guide"&gt;Download EPUB&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.gitbook.com/download/mobi/book/mostly-adequate/mostly-adequate-guide"&gt;Download Mobi (Kindle)&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h2 id="do-it-yourself"&gt;Do it yourself&lt;/h2&gt; &lt;pre&gt;&lt;code&gt;git clone https://github.com/MostlyAdequate/mostly-adequate-guide.git cd mostly-adequate-guide/ npm install npm run setup npm run generate-pdf npm run generate-epub &lt;/code&gt;&lt;/pre&gt;&lt;blockquote&gt; &lt;p&gt;Note! To generate the ebook version you will need to install &lt;code&gt;ebook-convert&lt;/code&gt;. &lt;a href="https://toolchain.gitbook.com/ebook.html#installing-ebook-convert"&gt;Installation instructions&lt;/a&gt;.&lt;/p&gt; &lt;/blockquote&gt; &lt;h2 id="table-of-contents"&gt;Table of Contents&lt;/h2&gt; &lt;p&gt;See &lt;a href="https://mostly-adequate.gitbooks.io/mostly-adequate-guide/SUMMARY.md"&gt;SUMMARY.md&lt;/a&gt;&lt;/p&gt; &lt;h3 id="contributing"&gt;Contributing&lt;/h3&gt; &lt;p&gt;See &lt;a href="https://mostly-adequate.gitbooks.io/mostly-adequate-guide/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/p&gt; &lt;h3 id="translations"&gt;Translations&lt;/h3&gt; &lt;p&gt;See &lt;a href="https://mostly-adequate.gitbooks.io/mostly-adequate-guide/TRANSLATIONS.md"&gt;TRANSLATIONS.md&lt;/a&gt;&lt;/p&gt; &lt;h3 id="faq"&gt;FAQ&lt;/h3&gt; &lt;p&gt;See &lt;a href="https://mostly-adequate.gitbooks.io/mostly-adequate-guide/FAQ.md"&gt;FAQ.md&lt;/a&gt;&lt;/p&gt; &lt;h2 id="plans-for-the-future"&gt;Plans for the future&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Part 1&lt;/strong&gt; (chapters 1-7) is a guide to the basics. I'm updating as I find errors since this is the initial draft. Feel free to help!&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Part 2&lt;/strong&gt; (chapters 8-13) address type classes like functors and monads all the way through to traversable. I hope to squeeze in transformers and a pure application.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Part 3&lt;/strong&gt; (chapters 14+) will start to dance the fine line between practical programming and academic absurdity. We'll look at comonads, f-algebras, free monads, yoneda, and other categorical constructs.&lt;/li&gt; &lt;/ul&gt; &lt;hr&gt; &lt;p&gt; &lt;a href="http://creativecommons.org/licenses/by-sa/4.0/" rel="license"&gt; &lt;img src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" alt="Creative Commons License"&gt; &lt;/a&gt; &lt;br&gt; This work is licensed under a &lt;a href="http://creativecommons.org/licenses/by-sa/4.0/" rel="license"&gt;Creative Commons Attribution-ShareAlike 4.0 International License&lt;/a&gt;. &lt;/p&gt; &lt;/section&gt; &lt;div&gt; &lt;div&gt; &lt;h2&gt;&lt;span&gt;&lt;/span&gt; results matching "&lt;span&gt;&lt;/span&gt;"&lt;/h2&gt; &lt;ul&gt;&lt;/ul&gt; &lt;/div&gt; &lt;p&gt; &lt;h2&gt;No results matching "&lt;span&gt;&lt;/span&gt;"&lt;/h2&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://mostly-adequate.gitbooks.io/mostly-adequate-guide/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 22:13:42 UT
      </pubDate>
      <guid>
        https://mostly-adequate.gitbooks.io/mostly-adequate-guide/
      </guid>
    </item>
    <item>
      <title>
        Cultivate the Skill of Undivided Attention, or “Deep Work” &amp;#8211; Letters To A New Developer
      </title>
      <link>
        https://letterstoanewdeveloper.com/2019/12/19/cultivate-the-skill-of-undivided-attention-or-deep-work/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt; &lt;p&gt;&lt;em&gt;This is a guest post from Josh Thompson. Enjoy.&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Dear New Developer,&lt;/p&gt; &lt;p&gt;You &lt;em&gt;know&lt;/em&gt; that there’s a chasm between your skill level and that of the mythical “senior software developer”.&lt;/p&gt; &lt;p&gt;If you build a list of topics you encounter on your job that, if learned to a deep enough level, would put you on the same level as a senior developer, you’ll end up even more demoralized than before compiling that list.&lt;/p&gt; &lt;p&gt;No need to assemble this list yourself! I’ve done it for you.&lt;/p&gt; &lt;p&gt;Here’s the list of topics that I’d need to dedicate significant time to, in order to close the gap between me and the senior developers on our team, that I’ve encountered in my last two days of work:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Breaking complex unknowns into simpler unknowns that can be further split into individual tickets&lt;/li&gt; &lt;li&gt;Adding tests to complex, legacy code, to guide further refactoring of said code.&lt;/li&gt; &lt;li&gt;Using `grep` to comb through server logs to diagnose a hard-to-identify-and-reproduce problem&lt;/li&gt; &lt;li&gt;Provisioning new servers&lt;/li&gt; &lt;li&gt;Building bash scripts to automate complex workflows&lt;/li&gt; &lt;li&gt;Digging into gem source code to can shed gem dependencies while maintaining certain features&lt;/li&gt; &lt;li&gt;Understanding indexing well enough to see that certain queries that we thought were using indexes were not, and fix this oversight index on the fly, without causing any blips in availability&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Each of these line-items has many books written about the topic.&lt;/p&gt; &lt;p&gt;It seems like you could fill a bookshelf with books that address knowledge senior developers have available to them inside their own heads.&lt;/p&gt; &lt;p&gt;It takes me long enough to work through a single book, so imagining a bookshelf of extra-curricular reading is quite daunting.&lt;/p&gt; &lt;p&gt;It might feel daunting for you, too.&lt;/p&gt; &lt;h2&gt;Leading vs. lagging indicators&lt;/h2&gt; &lt;p&gt;The above list of skills is a &lt;em&gt;lagging indicator&lt;/em&gt; of the underlying knowledge. We should not target improving &lt;em&gt;lagging&lt;/em&gt; indicators, we should improve &lt;em&gt;leading&lt;/em&gt; indicators.&lt;/p&gt; &lt;p&gt;Josh, what is this ‘lagging and leading indicator’ stuff?&lt;/p&gt; &lt;p&gt;Great question!&lt;/p&gt; &lt;p&gt;A lagging indicator is “evidence that something has already happened.”&lt;/p&gt; &lt;p&gt;If you got an A on a test, that is evidence that you learned the material.&lt;/p&gt; &lt;p&gt;A leading indicator is “evidence that something will likely happen”.&lt;/p&gt; &lt;p&gt;If you want to get an A on a test, you should study in a similar way as others who have gotten an A on that test. Maybe you need ten high-quality hours of study to get an A, so “number of high-quality study hours” would be a leading indicator of your grade.&lt;/p&gt; &lt;p&gt;We no longer take tests (phew. I hated taking tests.) but we get mini-tests of our knowledge, daily. We’re paid to solve problems, which often require learning new things.&lt;/p&gt; &lt;p&gt;Rather than focusing on a list of things other developers have learned, and targeting that list, I humbly propose that a leading indicator of acquiring this kind of knowledge is “hours per week spent in a state of intentional deep work”.&lt;/p&gt; &lt;p&gt;The above list of topics are lagging indicators of a high degree of technical knowledge. Someone acquires the knowledge, then, and only then, can demonstrate that they have it.&lt;/p&gt; &lt;p&gt;Leading indicators are “predictive”, in that if you can identify correctly those indicators, you can predict the outcome of the issue at hand.&lt;/p&gt; &lt;p&gt;In this case, the issue at hand is “become significantly more experienced in the domain of software development”.&lt;/p&gt; &lt;p&gt;I propose that a &lt;em&gt;leading indicator&lt;/em&gt; of someone gaining these skills is the amount of time they spend in a state of deep work.&lt;/p&gt; &lt;p&gt;I’d encourage you to read &lt;a href="https://www.goodreads.com/book/show/25744928-deep-work"&gt;Deep Work: Rules for Focused Success in a Distracted World&lt;/a&gt;. The author makes a case for deep work being a key role in the success of “knowledge workers” (which includes many types of work, including, of course, software development.)&lt;/p&gt; &lt;p&gt;If you’d rather not read the book, here’s the gist, from &lt;a href="https://www.samuelthomasdavies.com/book-summaries/business/deep-work/"&gt;this summary of the book&lt;/a&gt;:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;In order to produce the absolute best stuff you’re capable of, you need to commit to deep work.&lt;/li&gt; &lt;li&gt;The ability to quickly master hard things and the ability to produce at an elite level, in terms of both quality and speed, are two core abilities for thriving in today’s economy.&lt;/li&gt; &lt;li&gt;“To learn hard things quickly, you must focus intensely without distraction.”&lt;/li&gt; &lt;li&gt;“Your work is craft, and if you hone your ability and apply it with respect and care, then like the skilled wheelwright you can generate meaning in the daily efforts of your professional life.”&lt;/li&gt; &lt;li&gt;“The key to developing a deep work habit is to move beyond good intentions and add routines and rituals to your working life designed to minimize the amount of your limited willpower necessary to transition into and maintain a state of unbroken concentration.”&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Imagine two equally knowledgeable early-career software developers. They have the exact same skills on January 1, 2020. If the first software developer spends four hours a week doing deep work, while the second software developer spends fifteen hours a week doing deep work, their trajectories will be quite different, and that second developer will quickly gain technical knowledge and proficiencies.&lt;/p&gt; &lt;p&gt;So, if you’re an early-career software developer, track the time you spend doing deep work. That has you focusing on a leading indicator of growing in your skills.&lt;/p&gt; &lt;p&gt;At that point, you’ll benefit from Peter Drucker’s assessment:&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;What is measured, improves.&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;You’ll track how many hours you spend doing deep work, and by tracking it, you’ll do more and more of it.&lt;/p&gt; &lt;h2&gt;In conclusion&lt;/h2&gt; &lt;p&gt;Do more deep work, and over a year or two years, your skills will grow much faster than those doing less deep work. Eventually, you might find that you’re doing the work of a senior developer!&lt;/p&gt; &lt;p&gt;Good luck!&lt;/p&gt; &lt;p&gt;-Josh&lt;/p&gt; &lt;p&gt;&lt;em&gt;&lt;a href="https://josh.works/"&gt;Josh&lt;/a&gt; looks forward to being a senior developer some day. He’s only a few years into his career in the software development industry, but enjoys getting to bring knowledge and skills from his prior careers into his current role. He lives in (and works remotely from) Golden, CO, with his wife and loves to rock climb and read books, and can often be spotted in Denver-area climbing gyms or local crags.&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://letterstoanewdeveloper.com/2019/12/19/cultivate-the-skill-of-undivided-attention-or-deep-work/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 22:13:53 UT
      </pubDate>
      <guid>
        https://letterstoanewdeveloper.com/2019/12/19/cultivate-the-skill-of-undivided-attention-or-deep-work/
      </guid>
    </item>
    <item>
      <title>
        The Little Handbook of Statistical Practice
      </title>
      <link>
        http://www.jerrydallal.com/LHSP/LHSP.htm
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;p&gt;Chief, Biostatistics Unit&lt;br&gt; Jean Mayer USDA Human Nutrition Research Center on Aging&lt;br&gt; at Tufts University&lt;br&gt; 711 Washington Street&lt;br&gt; Boston, MA 02111&lt;br&gt; &lt;a href="mailto:Gerard.Dallal@tufts.edu"&gt;Gerard.Dallal@tufts.edu&lt;/a&gt; &lt;/p&gt;&lt;p&gt;A good case can be made that the best set of articles about statistical practice written for the practitioner is the series of &lt;a href="http://www.jerrydallal.com/LHSP/bmj.htm"&gt;Statistics Notes&lt;/a&gt; appearing in the British Medical Journal.&lt;/p&gt;&lt;div&gt;&lt;p&gt; There have been many attempts at online statistics instruction. &lt;a href="http://davidmlane.com/hyperstat/index.html"&gt;HyperStat&lt;/a&gt; is one of the better ones, not only for the content but also for the additional links.&lt;/p&gt;&lt;p&gt;&lt;span size="0"&gt;Counter reset&lt;br&gt;August 8, 2007&lt;/span&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;a href="http://www.jerrydallal.com/LHSP/LHSP.htm"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 22:14:06 UT
      </pubDate>
      <guid>
        http://www.jerrydallal.com/LHSP/LHSP.htm
      </guid>
    </item>
    <item>
      <title>
        How To Become A Hacker
      </title>
      <link>
        http://www.catb.org/esr/faqs/hacker-howto.html
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;p&gt;&lt;h2&gt;&lt;a id="idm1"&gt;&lt;/a&gt;How To Become A Hacker&lt;/h2&gt;&lt;/p&gt;&lt;p&gt;Copyright © 2001 Eric S. Raymond&lt;/p&gt;&lt;div&gt;&lt;table summary="Revision History"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;th colspan="3"&gt;&lt;strong&gt;Revision History&lt;/strong&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Revision 1.52&lt;/td&gt;&lt;td&gt;03 Jasnuary 2020&lt;/td&gt;&lt;td&gt;esr&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td colspan="3"&gt; Go makes a place as a plausible learning language, displacing Java. &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Revision 1.51&lt;/td&gt;&lt;td&gt;06 October 2017&lt;/td&gt;&lt;td&gt;esr&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td colspan="3"&gt; Link to "Things Every Hacker Once Knew." Mention USB-stick distros. Many updated translation links. &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Revision 1.50&lt;/td&gt;&lt;td&gt;19 July 2015&lt;/td&gt;&lt;td&gt;esr&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td colspan="3"&gt; Added link to "Let's Go Larval". &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Revision 1.49&lt;/td&gt;&lt;td&gt;21 November 2014&lt;/td&gt;&lt;td&gt;esr&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td colspan="3"&gt; Added link to "How To Learn Hacking". &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Revision 1.48&lt;/td&gt;&lt;td&gt;19 June 2014&lt;/td&gt;&lt;td&gt;esr&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td colspan="3"&gt; freshmeat/freecode is dead, alas. &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Revision 1.47&lt;/td&gt;&lt;td&gt;20 May 2014&lt;/td&gt;&lt;td&gt;esr&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td colspan="3"&gt; Fix up various stale links. Join a hackerspace! &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Revision 1.46&lt;/td&gt;&lt;td&gt;25 Sep 2013&lt;/td&gt;&lt;td&gt;esr&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td colspan="3"&gt; Add micropatronage explanation and gittip link. Why you should not ask me for advice on how to get started. &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Revision 1.45&lt;/td&gt;&lt;td&gt;12 May 2013&lt;/td&gt;&lt;td&gt;esr&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td colspan="3"&gt; Open Solaris isn't, and Unity screwed the pooch. &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Revision 1.44&lt;/td&gt;&lt;td&gt;20 May 2012&lt;/td&gt;&lt;td&gt;esr&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td colspan="3"&gt; Updated the critique of Java. &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Revision 1.43&lt;/td&gt;&lt;td&gt;07 Feb 2011&lt;/td&gt;&lt;td&gt;esr&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td colspan="3"&gt; Python passed Perl in popularity in 2010. &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Revision 1.42&lt;/td&gt;&lt;td&gt;22 Oct 2010&lt;/td&gt;&lt;td&gt;esr&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td colspan="3"&gt; Added "Historical note". &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Revision 1.40&lt;/td&gt;&lt;td&gt;3 Nov 2008&lt;/td&gt;&lt;td&gt;esr&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td colspan="3"&gt; Link fixes. &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Revision 1.39&lt;/td&gt;&lt;td&gt;14 Aug 2008&lt;/td&gt;&lt;td&gt;esr&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td colspan="3"&gt; Link fixes. &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Revision 1.38&lt;/td&gt;&lt;td&gt;8 Jan 2008&lt;/td&gt;&lt;td&gt;esr&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td colspan="3"&gt; Deprecate Java as a language to learn early. &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Revision 1.37&lt;/td&gt;&lt;td&gt;4 Oct 2007&lt;/td&gt;&lt;td&gt;esr&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td colspan="3"&gt; Recommend Ubuntu as a Unix distro for newbies. &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;&lt;/div&gt;&lt;hr&gt;&lt;/div&gt;&lt;p&gt;&lt;img src="http://www.catb.org/esr/faqs/glider.png"&gt;&lt;/p&gt;&lt;div&gt;&lt;div&gt;&lt;p&gt;&lt;h2&gt;&lt;a id="why_this"&gt;&lt;/a&gt;Why This Document?&lt;/h2&gt;&lt;/p&gt;&lt;/div&gt;&lt;p&gt;As editor of the &lt;a href="http://www.catb.org/jargon"&gt;Jargon File&lt;/a&gt; and author of a few other well-known documents of similar nature, I often get email requests from enthusiastic network newbies asking (in effect) "how can I learn to be a wizardly hacker?". Back in 1996 I noticed that there didn't seem to be any other FAQs or web documents that addressed this vital question, so I started this one. A lot of hackers now consider it definitive, and I suppose that means it is. Still, I don't claim to be the exclusive authority on this topic; if you don't like what you read here, write your own.&lt;/p&gt;&lt;p&gt;If you are reading a snapshot of this document offline, the current version lives at &lt;a href="http://catb.org/~esr/faqs/hacker-howto.html"&gt; http://catb.org/~esr/faqs/hacker-howto.html&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Note: there is a list of &lt;a title="Frequently Asked Questions" href="#FAQ"&gt;Frequently Asked Questions&lt;/a&gt; at the end of this document. Please read these—twice—before mailing me any questions about this document.&lt;/p&gt;&lt;p&gt;Numerous translations of this document are available: &lt;a href="http://www.abdulibrahim.com/%D9%83%D9%8A%D9%81-%D8%AA%D8%B5%D8%A8%D8%AD-%D9%87%D8%A7%D9%83%D8%B1/"&gt;Arabic&lt;/a&gt; &lt;a href="http://moneyaisle.com/worldwide/how-to-become-a-hacker-be"&gt;Belorussian&lt;/a&gt; &lt;a href="http://weknowyourdreams.com/questions.html"&gt;Bulgarian&lt;/a&gt; &lt;a href="http://zer4tul.github.io/docs/hacker-howto.html#hacker-howto"&gt;Chinese&lt;/a&gt;, &lt;a href="http://scientificachievements.com/jak-se-stat-hackerem/"&gt;Czech&lt;/a&gt;. &lt;a href="http://www.olemichaelsen.dk/hacker-howto.html"&gt;Danish&lt;/a&gt; &lt;a href="https://nobullshitseeds.com/translate/hacken-leren/"&gt;Dutch&lt;/a&gt; &lt;a href="http://www.kakupesa.net/hacker/"&gt;Estonian&lt;/a&gt; &lt;a href="http://thomasgil.com/hacker.html"&gt;French&lt;/a&gt; &lt;a href="http://www.linuxtaskforce.de/hacker-howto-ger.html"&gt;German&lt;/a&gt;, &lt;a href="https://sophron.latthi.com/hacker-howto-gr.html"&gt;Greek&lt;/a&gt; &lt;a href="http://www.forallworld.com/hogyan-valhat-egy-hacker/"&gt;Hungarian&lt;/a&gt;, &lt;a href="http://www.victorfleur.com/documents/hacker.html"&gt;Italian&lt;/a&gt; &lt;a href="http://he.wikisource.org/wiki/%D7%90%D7%99%D7%9A_%D7%9C%D7%94%D7%99%D7%95%D7%AA_%D7%94%D7%90%D7%A7%D7%A8"&gt;Hebrew&lt;/a&gt;, &lt;a href="http://cruel.org/freeware/hacker.html"&gt;Japanese&lt;/a&gt; &lt;a href="http://rtfb.lt/hacker-howto-lt.html"&gt;Lithuanian&lt;/a&gt; &lt;a href="http://stian.atlantiscrew.net/doc/hacker-howto.html"&gt;Norwegian&lt;/a&gt;, &lt;a href="http://ashiyane.org/forums/showthread.php?t=20570"&gt;Persian&lt;/a&gt; &lt;a href="http://michalp.net/blog/posts/hacker-howto"&gt;Polish&lt;/a&gt; &lt;a href="http://jvdm.sdf.org/pt/raquer-howto"&gt;Portuguese (Brazilian)&lt;/a&gt;, &lt;a href="http://garaj.xhost.ro/hacker-howto/hacker-howto.ro.htm"&gt;Romanian&lt;/a&gt; &lt;a href="http://www.sindominio.net/biblioweb/telematica/hacker-como.html"&gt;Spanish&lt;/a&gt;, &lt;a href="http://www.belgeler.org/howto/hacker-howto/hacker-howto.html"&gt;Turkish&lt;/a&gt;, and &lt;a href="http://www1.tripnet.se/~mly/open/faqs/hacker-howto.se.html"&gt;Swedish&lt;/a&gt;. Note that since this document changes occasionally, they may be out of date to varying degrees. &lt;/p&gt;&lt;p&gt;The five-dots-in-nine-squares diagram that decorates this document is called a &lt;span&gt;&lt;em&gt;glider&lt;/em&gt;&lt;/span&gt;. It is a simple pattern with some surprising properties in a mathematical simulation called &lt;a href="http://dmoz.org/Computers/Artificial_Life/Cellular_Automata/"&gt;Life&lt;/a&gt; that has fascinated hackers for many years. I think it makes a good visual emblem for what hackers are like — abstract, at first a bit mysterious-seeming, but a gateway to a whole world with an intricate logic of its own. Read more about the glider emblem &lt;a href="http://www.catb.org/~esr/hacker-emblem/"&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;If you find this document valuable, please support me on &lt;a href="http://patreon.com/esr"&gt;Patreon&lt;/a&gt; or &lt;a href="https://www.subscribestar.com/esr"&gt;SubscribeStar&lt;/a&gt;. And consider also supporting other hackers who have produced code that you use and value via &lt;a href="http://www.catb.org/esr/loadsharers/"&gt;Loadsharers&lt;/a&gt;. Lots of small but continuing donations add up quickly, and can free the people who have given you gifts of their labor to create more value.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;p&gt;&lt;h2&gt;&lt;a id="what_is"&gt;&lt;/a&gt;What Is a Hacker?&lt;/h2&gt;&lt;/p&gt;&lt;/div&gt;&lt;p&gt;The &lt;a href="http://www.catb.org/jargon"&gt;Jargon File&lt;/a&gt; contains a bunch of definitions of the term ‘hacker’, most having to do with technical adeptness and a delight in solving problems and overcoming limits. If you want to know how to &lt;span&gt;&lt;em&gt;become&lt;/em&gt;&lt;/span&gt; a hacker, though, only two are really relevant.&lt;/p&gt;&lt;p&gt;There is a community, a shared culture, of expert programmers and networking wizards that traces its history back through decades to the first time-sharing minicomputers and the earliest ARPAnet experiments. The members of this culture originated the term ‘hacker’. Hackers built the Internet. Hackers made the Unix operating system what it is today. Hackers make the World Wide Web work. If you are part of this culture, if you have contributed to it and other people in it know who you are and call you a hacker, you're a hacker.&lt;/p&gt;&lt;p&gt;The hacker mind-set is not confined to this software-hacker culture. There are people who apply the hacker attitude to other things, like electronics or music — actually, you can find it at the highest levels of any science or art. Software hackers recognize these kindred spirits elsewhere and may call them ‘hackers’ too — and some claim that the hacker nature is really independent of the particular medium the hacker works in. But in the rest of this document we will focus on the skills and attitudes of software hackers, and the traditions of the shared culture that originated the term ‘hacker’.&lt;/p&gt;&lt;p&gt;There is another group of people who loudly call themselves hackers, but aren't. These are people (mainly adolescent males) who get a kick out of breaking into computers and phreaking the phone system. Real hackers call these people ‘crackers’ and want nothing to do with them. Real hackers mostly think crackers are lazy, irresponsible, and not very bright, and object that being able to break security doesn't make you a hacker any more than being able to hotwire cars makes you an automotive engineer. Unfortunately, many journalists and writers have been fooled into using the word ‘hacker’ to describe crackers; this irritates real hackers no end.&lt;/p&gt;&lt;p&gt;The basic difference is this: hackers build things, crackers break them.&lt;/p&gt;&lt;p&gt;If you want to be a hacker, keep reading. If you want to be a cracker, go read the &lt;a&gt;alt.2600&lt;/a&gt; newsgroup and get ready to do five to ten in the slammer after finding out you aren't as smart as you think you are. And that's all I'm going to say about crackers.&lt;/p&gt;&lt;p&gt;&lt;img src="http://www.catb.org/esr/faqs/glider.png"&gt;&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;p&gt;&lt;h2&gt;&lt;a id="attitude"&gt;&lt;/a&gt;The Hacker Attitude&lt;/h2&gt;&lt;/p&gt;&lt;/div&gt;&lt;p&gt;Hackers solve problems and build things, and they believe in freedom and voluntary mutual help. To be accepted as a hacker, you have to behave as though you have this kind of attitude yourself. And to behave as though you have the attitude, you have to really believe the attitude.&lt;/p&gt;&lt;p&gt;But if you think of cultivating hacker attitudes as just a way to gain acceptance in the culture, you'll miss the point. Becoming the kind of person who believes these things is important for &lt;span&gt;&lt;em&gt;you&lt;/em&gt;&lt;/span&gt; — for helping you learn and keeping you motivated. As with all creative arts, the most effective way to become a master is to imitate the mind-set of masters — not just intellectually but emotionally as well.&lt;/p&gt;&lt;p&gt;Or, as the following modern Zen poem has it:&lt;/p&gt;&lt;p&gt;&lt;br&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;To&amp;nbsp;follow&amp;nbsp;the&amp;nbsp;path:&lt;br&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;look&amp;nbsp;to&amp;nbsp;the&amp;nbsp;master,&lt;br&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;follow&amp;nbsp;the&amp;nbsp;master,&lt;br&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;walk&amp;nbsp;with&amp;nbsp;the&amp;nbsp;master,&lt;br&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;see&amp;nbsp;through&amp;nbsp;the&amp;nbsp;master,&lt;br&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;become&amp;nbsp;the&amp;nbsp;master.&lt;br&gt; &lt;/p&gt;&lt;p&gt;So, if you want to be a hacker, repeat the following things until you believe them:&lt;/p&gt;&lt;div&gt;&lt;div&gt;&lt;p&gt;&lt;h3&gt;&lt;a id="believe1"&gt;&lt;/a&gt;1. The world is full of fascinating problems waiting to be solved.&lt;/h3&gt;&lt;/p&gt;&lt;/div&gt;&lt;p&gt;Being a hacker is lots of fun, but it's a kind of fun that takes lots of effort. The effort takes motivation. Successful athletes get their motivation from a kind of physical delight in making their bodies perform, in pushing themselves past their own physical limits. Similarly, to be a hacker you have to get a basic thrill from solving problems, sharpening your skills, and exercising your intelligence.&lt;/p&gt;&lt;p&gt;If you aren't the kind of person that feels this way naturally, you'll need to become one in order to make it as a hacker. Otherwise you'll find your hacking energy is sapped by distractions like sex, money, and social approval.&lt;/p&gt;&lt;p&gt;(You also have to develop a kind of faith in your own learning capacity — a belief that even though you may not know all of what you need to solve a problem, if you tackle just a piece of it and learn from that, you'll learn enough to solve the next piece — and so on, until you're done.)&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;p&gt;&lt;h3&gt;&lt;a id="believe2"&gt;&lt;/a&gt;2. No problem should ever have to be solved twice.&lt;/h3&gt;&lt;/p&gt;&lt;/div&gt;&lt;p&gt;Creative brains are a valuable, limited resource. They shouldn't be wasted on re-inventing the wheel when there are so many fascinating new problems waiting out there.&lt;/p&gt;&lt;p&gt;To behave like a hacker, you have to believe that the thinking time of other hackers is precious — so much so that it's almost a moral duty for you to share information, solve problems and then give the solutions away just so other hackers can solve &lt;span&gt;&lt;em&gt;new&lt;/em&gt;&lt;/span&gt; problems instead of having to perpetually re-address old ones.&lt;/p&gt;&lt;p&gt;Note, however, that "No problem should ever have to be solved twice." does not imply that you have to consider all existing solutions sacred, or that there is only one right solution to any given problem. Often, we learn a lot about the problem that we didn't know before by studying the first cut at a solution. It's OK, and often necessary, to decide that we can do better. What's not OK is artificial technical, legal, or institutional barriers (like closed-source code) that prevent a good solution from being re-used and &lt;span&gt;&lt;em&gt;force&lt;/em&gt;&lt;/span&gt; people to re-invent wheels.&lt;/p&gt;&lt;p&gt;(You don't have to believe that you're obligated to give &lt;span&gt;&lt;em&gt;all&lt;/em&gt;&lt;/span&gt; your creative product away, though the hackers that do are the ones that get most respect from other hackers. It's consistent with hacker values to sell enough of it to keep you in food and rent and computers. It's fine to use your hacking skills to support a family or even get rich, as long as you don't forget your loyalty to your art and your fellow hackers while doing it.)&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;p&gt;&lt;h3&gt;&lt;a id="believe3"&gt;&lt;/a&gt;3. Boredom and drudgery are evil.&lt;/h3&gt;&lt;/p&gt;&lt;/div&gt;&lt;p&gt;Hackers (and creative people in general) should never be bored or have to drudge at stupid repetitive work, because when this happens it means they aren't doing what only they can do — solve new problems. This wastefulness hurts everybody. Therefore boredom and drudgery are not just unpleasant but actually evil.&lt;/p&gt;&lt;p&gt;To behave like a hacker, you have to believe this enough to want to automate away the boring bits as much as possible, not just for yourself but for everybody else (especially other hackers).&lt;/p&gt;&lt;p&gt;(There is one apparent exception to this. Hackers will sometimes do things that may seem repetitive or boring to an observer as a mind-clearing exercise, or in order to acquire a skill or have some particular kind of experience you can't have otherwise. But this is by choice — nobody who can think should ever be forced into a situation that bores them.)&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;p&gt;&lt;h3&gt;&lt;a id="believe4"&gt;&lt;/a&gt;4. Freedom is good.&lt;/h3&gt;&lt;/p&gt;&lt;/div&gt;&lt;p&gt;Hackers are naturally anti-authoritarian. Anyone who can give you orders can stop you from solving whatever problem you're being fascinated by — and, given the way authoritarian minds work, will generally find some appallingly stupid reason to do so. So the authoritarian attitude has to be fought wherever you find it, lest it smother you and other hackers.&lt;/p&gt;&lt;p&gt;(This isn't the same as fighting all authority. Children need to be guided and criminals restrained. A hacker may agree to accept some kinds of authority in order to get something he wants more than the time he spends following orders. But that's a limited, conscious bargain; the kind of personal surrender authoritarians want is not on offer.)&lt;/p&gt;&lt;p&gt;Authoritarians thrive on censorship and secrecy. And they distrust voluntary cooperation and information-sharing — they only like ‘cooperation’ that they control. So to behave like a hacker, you have to develop an instinctive hostility to censorship, secrecy, and the use of force or deception to compel responsible adults. And you have to be willing to act on that belief.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;p&gt;&lt;h3&gt;&lt;a id="believe5"&gt;&lt;/a&gt;5. Attitude is no substitute for competence.&lt;/h3&gt;&lt;/p&gt;&lt;/div&gt;&lt;p&gt;To be a hacker, you have to develop some of these attitudes. But copping an attitude alone won't make you a hacker, any more than it will make you a champion athlete or a rock star. Becoming a hacker will take intelligence, practice, dedication, and hard work.&lt;/p&gt;&lt;p&gt;Therefore, you have to learn to distrust attitude and respect competence of every kind. Hackers won't let posers waste their time, but they worship competence — especially competence at hacking, but competence at anything is valued. Competence at demanding skills that few can master is especially good, and competence at demanding skills that involve mental acuteness, craft, and concentration is best.&lt;/p&gt;&lt;p&gt;If you revere competence, you'll enjoy developing it in yourself — the hard work and dedication will become a kind of intense play rather than drudgery. That attitude is vital to becoming a hacker.&lt;/p&gt;&lt;p&gt;&lt;img src="http://www.catb.org/esr/faqs/glider.png"&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;p&gt;&lt;h2&gt;&lt;a id="basic_skills"&gt;&lt;/a&gt;Basic Hacking Skills&lt;/h2&gt;&lt;/p&gt;&lt;/div&gt;&lt;p&gt;The hacker attitude is vital, but skills are even more vital. Attitude is no substitute for competence, and there's a certain basic toolkit of skills which you have to have before any hacker will dream of calling you one.&lt;/p&gt;&lt;p&gt;This toolkit changes slowly over time as technology creates new skills and makes old ones obsolete. For example, it used to include programming in machine language, and didn't until recently involve HTML. But right now it pretty clearly includes the following:&lt;/p&gt;&lt;div&gt;&lt;div&gt;&lt;p&gt;&lt;h3&gt;&lt;a id="skills1"&gt;&lt;/a&gt;1. Learn how to program.&lt;/h3&gt;&lt;/p&gt;&lt;/div&gt;&lt;p&gt;This, of course, is the fundamental hacking skill. If you don't know any computer languages, I recommend starting with Python. It is cleanly designed, well documented, and relatively kind to beginners. Despite being a good first language, it is not just a toy; it is very powerful and flexible and well suited for large projects. I have written a more detailed &lt;a href="http://www.linuxjournal.com/article.php?sid=3882"&gt;evaluation of Python&lt;/a&gt;. Good &lt;a href="https://www.python.org/about/gettingstarted/"&gt; tutorials&lt;/a&gt; are available at the &lt;a href="https://docs.python.org/3/tutorial/"&gt;Python web site&lt;/a&gt;; there's an excellent third-party one at &lt;a href="http://cscircles.cemc.uwaterloo.ca/"&gt;Computer Science Circles&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;I used to recommend Java as a good language to learn early, but &lt;a href="http://www.crosstalkonline.org/storage/issue-archives/2008/200801/200801-Dewar.pdf"&gt;this critique&lt;/a&gt; has changed my mind (search for &lt;span&gt;“&lt;span&gt;The Pitfalls of Java as a First Programming Language&lt;/span&gt;”&lt;/span&gt; within it). A hacker cannot, as they devastatingly put it &lt;span&gt;“&lt;span&gt;approach problem-solving like a plumber in a hardware store&lt;/span&gt;”&lt;/span&gt;; you have to know what the components actually &lt;span&gt;&lt;em&gt;do&lt;/em&gt;&lt;/span&gt;. Now I think it is probably best to learn C and Lisp first, then Java.&lt;/p&gt;&lt;p&gt;There is perhaps a more general point here. If a language does too much for you, it may be simultaneously a good tool for production and a bad one for learning. It's not only languages that have this problem; web application frameworks like RubyOnRails, CakePHP, Django may make it too easy to reach a superficial sort of understanding that will leave you without resources when you have to tackle a hard problem, or even just debug the solution to an easy one.&lt;/p&gt;&lt;p&gt;A better alternative to Java is to learn &lt;a href="https://golang.org/"&gt;Go&lt;/a&gt;. This relatively new language is pretty easy to move to from Python, and learning it give you a serious leg up on the possible next step, which is learning C. Additionally, one of the unknowns about the next few years is to what extent Go might actually displace C as a systems-programming language. There is a possible future in which that happens over much of C's traditional range.&lt;/p&gt;&lt;p&gt;If you get into serious programming, you will eventually have to learn C, the core language of Unix. C++ is very closely related to C; if you know one, learning the other will not be difficult. Neither language is a good one to try learning as your first, however. And, actually, the more you can avoid programming in C the more productive you will be.&lt;/p&gt;&lt;p&gt;C is very efficient, and very sparing of your machine's resources. Unfortunately, C gets that efficiency by requiring you to do a lot of low-level management of resources (like memory) by hand. All that low-level code is complex and bug-prone, and will soak up huge amounts of your time on debugging. With today's machines as powerful as they are, this is usually a bad tradeoff — it's smarter to use a language that uses the machine's time less efficiently, but your time much &lt;span&gt;&lt;em&gt;more&lt;/em&gt;&lt;/span&gt; efficiently. Thus, Python.&lt;/p&gt;&lt;p&gt;Other languages of particular importance to hackers include &lt;a href="http://www.perl.com/"&gt;Perl&lt;/a&gt; and &lt;a href="http://www.lisp.org/"&gt;LISP&lt;/a&gt;. Perl is worth learning for practical reasons; it's very widely used for active web pages and system administration, so that even if you never write Perl you should learn to read it. Many people use Perl in the way I suggest you should use Python, to avoid C programming on jobs that don't require C's machine efficiency. You will need to be able to understand their code.&lt;/p&gt;&lt;p&gt;LISP is worth learning for a different reason — the profound enlightenment experience you will have when you finally get it. That experience will make you a better programmer for the rest of your days, even if you never actually use LISP itself a lot. (You can get some beginning experience with LISP fairly easily by writing and modifying editing modes for the Emacs text editor, or Script-Fu plugins for the GIMP.)&lt;/p&gt;&lt;p&gt;It's best, actually, to learn all five of Python, C/C++, Perl, and LISP. Besides being the most important hacking languages, they represent very different approaches to programming, and each will educate you in valuable ways. Go is not quite to the point where it can be included among the most important hacking languages, but it seems headed for that status.&lt;/p&gt;&lt;p&gt;But be aware that you won't reach the skill level of a hacker or even merely a programmer simply by accumulating languages — you need to learn how to think about programming problems in a general way, independent of any one language. To be a real hacker, you need to get to the point where you can learn a new language in days by relating what's in the manual to what you already know. This means you should learn several very different languages.&lt;/p&gt;&lt;p&gt;I can't give complete instructions on how to learn to program here — it's a complex skill. But I can tell you that books and courses won't do it — many, maybe &lt;span&gt;&lt;em&gt;most&lt;/em&gt;&lt;/span&gt; of the best hackers are self-taught. You can learn language features — bits of knowledge — from books, but the mind-set that makes that knowledge into living skill can be learned only by practice and apprenticeship. What will do it is (a) &lt;span&gt;&lt;em&gt;reading code&lt;/em&gt;&lt;/span&gt; and (b) &lt;span&gt;&lt;em&gt;writing code&lt;/em&gt;&lt;/span&gt;.&lt;/p&gt;&lt;p&gt;Peter Norvig, who is one of Google's top hackers and the co-author of the most widely used textbook on AI, has written an excellent essay called &lt;a href="http://norvig.com/21-days.html"&gt;Teach Yourself Programming in Ten Years&lt;/a&gt;. His "recipe for programming success" is worth careful attention.&lt;/p&gt;&lt;p&gt;Learning to program is like learning to write good natural language. The best way to do it is to read some stuff written by masters of the form, write some things yourself, read a lot more, write a little more, read a lot more, write some more ... and repeat until your writing begins to develop the kind of strength and economy you see in your models.&lt;/p&gt;&lt;p&gt;I have had more to say about this learning process in &lt;a href="http://www.catb.org/esr/faqs/hacking-howto.html"&gt;How To Learn Hacking&lt;/a&gt;. It's a simple set of instructions, but not an easy one.&lt;/p&gt;&lt;p&gt;Finding good code to read used to be hard, because there were few large programs available in source for fledgeling hackers to read and tinker with. This has changed dramatically; open-source software, programming tools, and operating systems (all built by hackers) are now widely available. Which brings me neatly to our next topic...&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;p&gt;&lt;h3&gt;&lt;a id="skills2"&gt;&lt;/a&gt;2. Get one of the open-source Unixes and learn to use and run it.&lt;/h3&gt;&lt;/p&gt;&lt;/div&gt;&lt;p&gt;I'll assume you have a personal computer or can get access to one. (Take a moment to appreciate how much that means. The hacker culture originally evolved back when computers were so expensive that individuals could not own them.) The single most important step any newbie can take toward acquiring hacker skills is to get a copy of Linux or one of the BSD-Unixes, install it on a personal machine, and run it.&lt;/p&gt;&lt;p&gt;Yes, there are other operating systems in the world besides Unix. But they're distributed in binary — you can't read the code, and you can't modify it. Trying to learn to hack on a Microsoft Windows machine or under any other closed-source system is like trying to learn to dance while wearing a body cast.&lt;/p&gt;&lt;p&gt;Under Mac OS X it's possible, but only part of the system is open source — you're likely to hit a lot of walls, and you have to be careful not to develop the bad habit of depending on Apple's proprietary code. If you concentrate on the Unix under the hood you can learn some useful things.&lt;/p&gt;&lt;p&gt;Unix is the operating system of the Internet. While you can learn to use the Internet without knowing Unix, you can't be an Internet hacker without understanding Unix. For this reason, the hacker culture today is pretty strongly Unix-centered. (This wasn't always true, and some old-time hackers still aren't happy about it, but the symbiosis between Unix and the Internet has become strong enough that even Microsoft's muscle doesn't seem able to seriously dent it.)&lt;/p&gt;&lt;p&gt;So, bring up a Unix — I like Linux myself but there are other ways (and yes, you &lt;span&gt;&lt;em&gt;can&lt;/em&gt;&lt;/span&gt; run both Linux and Microsoft Windows on the same machine). Learn it. Run it. Tinker with it. Talk to the Internet with it. Read the code. Modify the code. You'll get better programming tools (including C, LISP, Python, and Perl) than any Microsoft operating system can dream of hosting, you'll have fun, and you'll soak up more knowledge than you realize you're learning until you look back on it as a master hacker.&lt;/p&gt;&lt;p&gt;For more about learning Unix, see &lt;a href="http://catb.org/~esr/faqs/loginataka.html"&gt;The Loginataka&lt;/a&gt;. You might also want to have a look at &lt;a href="http://catb.org/~esr/writings/taoup/"&gt;The Art Of Unix Programming&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;The blog &lt;a href="https://letsgolarval.wordpress.com/"&gt;Let's Go Larval!&lt;/a&gt; is a window on the learning process of a new Linux user that I think is unusually lucid and helpful. The post &lt;a href="https://letsgolarval.wordpress.com/2015/06/23/how-i-learned-linux/"&gt;How I Learned Linux&lt;/a&gt; makes a good starting point.&lt;/p&gt;&lt;p&gt;To get your hands on a Linux, see the &lt;a href="http://www.linux.org/"&gt;Linux Online!&lt;/a&gt; site; you can download from there or (better idea) find a local Linux user group to help you with installation.&lt;/p&gt;&lt;p&gt;During the first ten years of this HOWTO's life, I reported that from a new user's point of view, all Linux distributions are almost equivalent. But in 2006-2007, an actual best choice emerged: &lt;a href="http://www.ubuntu.com/"&gt;Ubuntu&lt;/a&gt;. While other distros have their own areas of strength, Ubuntu is far and away the most accessible to Linux newbies. Beware, though, of the hideous and nigh-unusable "Unity" desktop interface that Ubuntu introduced as a default a few years later; the Xubuntu or Kubuntu variants are better.&lt;/p&gt;&lt;p&gt;You can find BSD Unix help and resources at &lt;a href="http://www.bsd.org/"&gt;www.bsd.org&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;A good way to dip your toes in the water is to boot up what Linux fans call a &lt;a href="http://www.livecdnews.com/"&gt;live CD&lt;/a&gt;, a distribution that runs entirely off a CD or USB stick without having to modify your hard disk. This may be slow, because CDs are slow, but it's a way to get a look at the possibilities without having to do anything drastic.&lt;/p&gt;&lt;p&gt;I have written a primer on the &lt;a href="http://en.tldp.org/HOWTO/Unix-and-Internet-Fundamentals-HOWTO/index.html"&gt;basics of Unix and the Internet&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;I used to recommend against installing either Linux or BSD as a solo project if you're a newbie. Nowadays the installers have gotten good enough that doing it entirely on your own is possible, even for a newbie. Nevertheless, I still recommend making contact with your local Linux user's group and asking for help. It can't hurt, and may smooth the process.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;p&gt;&lt;h3&gt;&lt;a id="skills3"&gt;&lt;/a&gt;3. Learn how to use the World Wide Web and write HTML.&lt;/h3&gt;&lt;/p&gt;&lt;/div&gt;&lt;p&gt;Most of the things the hacker culture has built do their work out of sight, helping run factories and offices and universities without any obvious impact on how non-hackers live. The Web is the one big exception, the huge shiny hacker toy that even &lt;span&gt;&lt;em&gt;politicians&lt;/em&gt;&lt;/span&gt; admit has changed the world. For this reason alone (and a lot of other good ones as well) you need to learn how to work the Web.&lt;/p&gt;&lt;p&gt;This doesn't just mean learning how to drive a browser (anyone can do that), but learning how to write HTML, the Web's markup language. If you don't know how to program, writing HTML will teach you some mental habits that will help you learn. So build a home page.&lt;/p&gt;&lt;p&gt;But just having a home page isn't anywhere near good enough to make you a hacker. The Web is full of home pages. Most of them are pointless, zero-content sludge — very snazzy-looking sludge, mind you, but sludge all the same (for more on this see &lt;a href="http://catb.org/~esr/html-hell.html"&gt;The HTML Hell Page&lt;/a&gt;).&lt;/p&gt;&lt;p&gt;To be worthwhile, your page must have &lt;span&gt;&lt;em&gt;content&lt;/em&gt;&lt;/span&gt; — it must be interesting and/or useful to other hackers. And that brings us to the next topic...&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;p&gt;&lt;h3&gt;&lt;a id="skills4"&gt;&lt;/a&gt;4. If you don't have functional English, learn it.&lt;/h3&gt;&lt;/p&gt;&lt;/div&gt;&lt;p&gt;As an American and native English-speaker myself, I have previously been reluctant to suggest this, lest it be taken as a sort of cultural imperialism. But several native speakers of other languages have urged me to point out that English is the working language of the hacker culture and the Internet, and that you will need to know it to function in the hacker community.&lt;/p&gt;&lt;p&gt;Back around 1991 I learned that many hackers who have English as a second language use it in technical discussions even when they share a birth tongue; it was reported to me at the time that English has a richer technical vocabulary than any other language and is therefore simply a better tool for the job. For similar reasons, translations of technical books written in English are often unsatisfactory (when they get done at all).&lt;/p&gt;&lt;p&gt;Linus Torvalds, a Finn, comments his code in English (it apparently never occurred to him to do otherwise). His fluency in English has been an important factor in his ability to recruit a worldwide community of developers for Linux. It's an example worth following.&lt;/p&gt;&lt;p&gt;Being a native English-speaker does not guarantee that you have language skills good enough to function as a hacker. If your writing is semi-literate, ungrammatical, and riddled with misspellings, many hackers (including myself) will tend to ignore you. While sloppy writing does not invariably mean sloppy thinking, we've generally found the correlation to be strong — and we have no use for sloppy thinkers. If you can't yet write competently, learn to.&lt;/p&gt;&lt;p&gt;&lt;img src="http://www.catb.org/esr/faqs/glider.png"&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;p&gt;&lt;h2&gt;&lt;a id="status"&gt;&lt;/a&gt;Status in the Hacker Culture&lt;/h2&gt;&lt;/p&gt;&lt;/div&gt;&lt;p&gt;Like most cultures without a money economy, hackerdom runs on reputation. You're trying to solve interesting problems, but how interesting they are, and whether your solutions are really good, is something that only your technical peers or superiors are normally equipped to judge.&lt;/p&gt;&lt;p&gt;Accordingly, when you play the hacker game, you learn to keep score primarily by what other hackers think of your skill (this is why you aren't really a hacker until other hackers consistently call you one). This fact is obscured by the image of hacking as solitary work; also by a hacker-cultural taboo (gradually decaying since the late 1990s but still potent) against admitting that ego or external validation are involved in one's motivation at all.&lt;/p&gt;&lt;p&gt;Specifically, hackerdom is what anthropologists call a &lt;span&gt;&lt;em&gt;gift culture&lt;/em&gt;&lt;/span&gt;. You gain status and reputation in it not by dominating other people, nor by being beautiful, nor by having things other people want, but rather by giving things away. Specifically, by giving away your time, your creativity, and the results of your skill.&lt;/p&gt;&lt;p&gt;There are basically five kinds of things you can do to be respected by hackers:&lt;/p&gt;&lt;div&gt;&lt;div&gt;&lt;p&gt;&lt;h3&gt;&lt;a id="respect1"&gt;&lt;/a&gt;1. Write open-source software&lt;/h3&gt;&lt;/p&gt;&lt;/div&gt;&lt;p&gt;The first (the most central and most traditional) is to write programs that other hackers think are fun or useful, and give the program sources away to the whole hacker culture to use.&lt;/p&gt;&lt;p&gt;(We used to call these works “free software”, but this confused too many people who weren't sure exactly what “free” was supposed to mean. Most of us now prefer the term “&lt;a href="http://www.opensource.org/"&gt;open-source&lt;/a&gt;” software).&lt;/p&gt;&lt;p&gt;Hackerdom's most revered demigods are people who have written large, capable programs that met a widespread need and given them away, so that now everyone uses them.&lt;/p&gt;&lt;p&gt;But there's a bit of a fine historical point here. While hackers have always looked up to the open-source developers among them as our community's hardest core, before the mid-1990s most hackers most of the time worked on closed source. This was still true when I wrote the first version of this HOWTO in 1996; it took the mainstreaming of open-source software after 1997 to change things. Today, "the hacker community" and "open-source developers" are two descriptions for what is essentially the same culture and population — but it is worth remembering that this was not always so. (For more on this, see &lt;a title="Historical Note: Hacking, Open Source, and Free Software" href="#history"&gt;the section called “Historical Note: Hacking, Open Source, and Free Software”&lt;/a&gt;.)&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;p&gt;&lt;h3&gt;&lt;a id="respect2"&gt;&lt;/a&gt;2. Help test and debug open-source software&lt;/h3&gt;&lt;/p&gt;&lt;/div&gt;&lt;p&gt;They also serve who stand and debug open-source software. In this imperfect world, we will inevitably spend most of our software development time in the debugging phase. That's why any open-source author who's thinking will tell you that good beta-testers (who know how to describe symptoms clearly, localize problems well, can tolerate bugs in a quickie release, and are willing to apply a few simple diagnostic routines) are worth their weight in rubies. Even one of these can make the difference between a debugging phase that's a protracted, exhausting nightmare and one that's merely a salutary nuisance.&lt;/p&gt;&lt;p&gt;If you're a newbie, try to find a program under development that you're interested in and be a good beta-tester. There's a natural progression from helping test programs to helping debug them to helping modify them. You'll learn a lot this way, and generate good karma with people who will help you later on.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;p&gt;&lt;h3&gt;&lt;a id="respect3"&gt;&lt;/a&gt;3. Publish useful information&lt;/h3&gt;&lt;/p&gt;&lt;/div&gt;&lt;p&gt;Another good thing is to collect and filter useful and interesting information into web pages or documents like Frequently Asked Questions (FAQ) lists, and make those generally available.&lt;/p&gt;&lt;p&gt;Maintainers of major technical FAQs get almost as much respect as open-source authors.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;p&gt;&lt;h3&gt;&lt;a id="respect4"&gt;&lt;/a&gt;4. Help keep the infrastructure working&lt;/h3&gt;&lt;/p&gt;&lt;/div&gt;&lt;p&gt;The hacker culture (and the engineering development of the Internet, for that matter) is run by volunteers. There's a lot of necessary but unglamorous work that needs done to keep it going — administering mailing lists, moderating newsgroups, maintaining large software archive sites, developing RFCs and other technical standards.&lt;/p&gt;&lt;p&gt;People who do this sort of thing well get a lot of respect, because everybody knows these jobs are huge time sinks and not as much fun as playing with code. Doing them shows dedication.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;p&gt;&lt;h3&gt;&lt;a id="respect5"&gt;&lt;/a&gt;5. Serve the hacker culture itself&lt;/h3&gt;&lt;/p&gt;&lt;/div&gt;&lt;p&gt;Finally, you can serve and propagate the culture itself (by, for example, writing an accurate primer on how to become a hacker :-)). This is not something you'll be positioned to do until you've been around for while and become well-known for one of the first four things.&lt;/p&gt;&lt;p&gt;The hacker culture doesn't have leaders, exactly, but it does have culture heroes and tribal elders and historians and spokespeople. When you've been in the trenches long enough, you may grow into one of these. Beware: hackers distrust blatant ego in their tribal elders, so visibly reaching for this kind of fame is dangerous. Rather than striving for it, you have to sort of position yourself so it drops in your lap, and then be modest and gracious about your status.&lt;/p&gt;&lt;p&gt;&lt;img src="http://www.catb.org/esr/faqs/glider.png"&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;p&gt;&lt;h2&gt;&lt;a id="nerd_connection"&gt;&lt;/a&gt;The Hacker/Nerd Connection&lt;/h2&gt;&lt;/p&gt;&lt;/div&gt;&lt;p&gt;Contrary to popular myth, you don't have to be a nerd to be a hacker. It does help, however, and many hackers are in fact nerds. Being something of a social outcast helps you stay concentrated on the really important things, like thinking and hacking.&lt;/p&gt;&lt;p&gt;For this reason, many hackers have adopted the label ‘geek’ as a badge of pride — it's a way of declaring their independence from normal social expectations (as well as a fondness for other things like science fiction and strategy games that often go with being a hacker). The term 'nerd' used to be used this way back in the 1990s, back when 'nerd' was a mild pejorative and 'geek' a rather harsher one; sometime after 2000 they switched places, at least in U.S. popular culture, and there is now even a significant geek-pride culture among people who aren't techies.&lt;/p&gt;&lt;p&gt;If you can manage to concentrate enough on hacking to be good at it and still have a life, that's fine. This is a lot easier today than it was when I was a newbie in the 1970s; mainstream culture is much friendlier to techno-nerds now. There are even growing numbers of people who realize that hackers are often high-quality lover and spouse material.&lt;/p&gt;&lt;p&gt;If you're attracted to hacking because you don't have a life, that's OK too — at least you won't have trouble concentrating. Maybe you'll get a life later on.&lt;/p&gt;&lt;p&gt;&lt;img src="http://www.catb.org/esr/faqs/glider.png"&gt;&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;p&gt;&lt;h2&gt;&lt;a&gt;&lt;/a&gt;Points For Style&lt;/h2&gt;&lt;/p&gt;&lt;/div&gt;&lt;p&gt;Again, to be a hacker, you have to enter the hacker mindset. There are some things you can do when you're not at a computer that seem to help. They're not substitutes for hacking (nothing is) but many hackers do them, and feel that they connect in some basic way with the essence of hacking.&lt;/p&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Learn to write your native language well. Though it's a common stereotype that programmers can't write, a surprising number of hackers (including all the most accomplished ones I know of) are very able writers.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Read science fiction. Go to science fiction conventions (a good way to meet hackers and proto-hackers). &lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Join a hackerspace and make things (another good way to meet hackers and proto-hackers). &lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Train in a martial-arts form. The kind of mental discipline required for martial arts seems to be similar in important ways to what hackers do. The most popular forms among hackers are definitely Asian empty-hand arts such as Tae Kwon Do, various forms of Karate, Kung Fu, Aikido, or Ju Jitsu. Western fencing and Asian sword arts also have visible followings. In places where it's legal, pistol shooting has been rising in popularity since the late 1990s. The most hackerly martial arts are those which emphasize mental discipline, relaxed awareness, and precise control, rather than raw strength, athleticism, or physical toughness.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Study an actual meditation discipline. The perennial favorite among hackers is Zen (importantly, it is possible to benefit from Zen without acquiring a religion or discarding one you already have). Other styles may work as well, but be careful to choose one that doesn't require you to believe crazy things.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt; Develop an analytical ear for music. Learn to appreciate peculiar kinds of music. Learn to play some musical instrument well, or how to sing.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt; Develop your appreciation of puns and wordplay.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;p&gt;The more of these things you already do, the more likely it is that you are natural hacker material. Why these things in particular is not completely clear, but they're connected with a mix of left- and right-brain skills that seems to be important; hackers need to be able to both reason logically and step outside the apparent logic of a problem at a moment's notice.&lt;/p&gt;&lt;p&gt;Work as intensely as you play and play as intensely as you work. For true hackers, the boundaries between "play", "work", "science" and "art" all tend to disappear, or to merge into a high-level creative playfulness. Also, don't be content with a narrow range of skills. Though most hackers self-describe as programmers, they are very likely to be more than competent in several related skills — system administration, web design, and PC hardware troubleshooting are common ones. A hacker who's a system administrator, on the other hand, is likely to be quite skilled at script programming and web design. Hackers don't do things by halves; if they invest in a skill at all, they tend to get very good at it.&lt;/p&gt;&lt;p&gt;&lt;a id="not_to_do"&gt;&lt;/a&gt;Finally, a few things &lt;span&gt;&lt;em&gt;not&lt;/em&gt;&lt;/span&gt; to do.&lt;/p&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt; Don't use a silly, grandiose user ID or screen name. &lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt; Don't get in flame wars on Usenet (or anywhere else).&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt; Don't call yourself a ‘cyberpunk’, and don't waste your time on anybody who does.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt; Don't post or email writing that's full of spelling errors and bad grammar.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;p&gt;The only reputation you'll make doing any of these things is as a twit. Hackers have long memories — it could take you years to live your early blunders down enough to be accepted.&lt;/p&gt;&lt;p&gt;The problem with screen names or handles deserves some amplification. Concealing your identity behind a handle is a juvenile and silly behavior characteristic of crackers, warez d00dz, and other lower life forms. Hackers don't do this; they're proud of what they do and want it associated with their &lt;span&gt;&lt;em&gt;real&lt;/em&gt;&lt;/span&gt; names. So if you have a handle, drop it. In the hacker culture it will only mark you as a loser.&lt;/p&gt;&lt;p&gt;&lt;img src="http://www.catb.org/esr/faqs/glider.png"&gt;&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;p&gt;&lt;h2&gt;&lt;a id="history"&gt;&lt;/a&gt;Historical Note: Hacking, Open Source, and Free Software&lt;/h2&gt;&lt;/p&gt;&lt;/div&gt;&lt;p&gt;When I originally wrote this how-to in late 1996, some of the conditions around it were very different from the way they look today. A few words about these changes may help clarify matters for people who are confused about the relationship of open source, free software, and Linux to the hacker community. If you are not curious about this, you can skip straight to the FAQ and bibliography from here.&lt;/p&gt;&lt;p&gt;The hacker ethos and community as I have described it here long predates the emergence of Linux after 1990; I first became involved with it around 1976, and, its roots are readily traceable back to the early 1960s. But before Linux, most hacking was done on either proprietary operating systems or a handful of quasi-experimental homegrown systems like MIT's ITS that were never deployed outside of their original academic niches. While there had been some earlier (pre-Linux) attempts to change this situation, their impact was at best very marginal and confined to communities of dedicated true believers which were tiny minorities even within the hacker community, let alone with respect to the larger world of software in general.&lt;/p&gt;&lt;p&gt;What is now called "open source" goes back as far as the hacker community does, but until 1985 it was an unnamed folk practice rather than a conscious movement with theories and manifestos attached to it. This prehistory ended when, in 1985, arch-hacker Richard Stallman ("RMS") tried to give it a name — "free software". But his act of naming was also an act of claiming; he attached ideological baggage to the "free software" label which much of the existing hacker community never accepted. As a result, the "free software" label was loudly rejected by a substantial minority of the hacker community (especially among those associated with BSD Unix), and used with serious but silent reservations by a majority of the remainder (including myself).&lt;/p&gt;&lt;p&gt;Despite these reservations, RMS's claim to define and lead the hacker community under the "free software" banner broadly held until the mid-1990s. It was seriously challenged only by the rise of Linux. Linux gave open-source development a natural home. Many projects issued under terms we would now call open-source migrated from proprietary Unixes to Linux. The community around Linux grew explosively, becoming far larger and more heterogenous than the pre-Linux hacker culture. RMS determinedly attempted to co-opt all this activity into his "free software" movement, but was thwarted by both the exploding diversity of the Linux community and the public skepticism of its founder, Linus Torvalds. Torvalds continued to use the term "free software" for lack of any alternative, but publicly rejected RMS's ideological baggage. Many younger hackers followed suit.&lt;/p&gt;&lt;p&gt;In 1996, when I first published this Hacker HOWTO, the hacker community was rapidly reorganizing around Linux and a handful of other open-source operating systems (notably those descended from BSD Unix). Community memory of the fact that most of us had spent decades developing closed-source software on closed-source operating systems had not yet begun to fade, but that fact was already beginning to seem like part of a dead past; hackers were, increasingly, defining themselves as hackers by their attachments to open-source projects such as Linux or Apache.&lt;/p&gt;&lt;p&gt;The term "open source", however, had not yet emerged; it would not do so until early 1998. When it did, most of the hacker community adopted it within the following six months; the exceptions were a minority ideologically attached to the term "free software". Since 1998, and especially after about 2003, the identification of 'hacking' with 'open-source (and free software) development' has become extremely close. Today there is little point in attempting to distinguish between these categories, and it seems unlikely that will change in the future.&lt;/p&gt;&lt;p&gt;It is worth remembering, however, that this was not always so.&lt;/p&gt;&lt;p&gt;&lt;img src="http://www.catb.org/esr/faqs/glider.png"&gt;&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;p&gt;&lt;h2&gt;&lt;a id="FAQ"&gt;&lt;/a&gt;Frequently Asked Questions&lt;/h2&gt;&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;dl&gt;&lt;dt&gt;Q: &lt;a href="#hacker_already"&gt;How do I tell if I am already a hacker?&lt;/a&gt;&lt;/dt&gt;&lt;dt&gt;Q: &lt;a href="#teach_hack"&gt;Will you teach me how to hack?&lt;/a&gt;&lt;/dt&gt;&lt;dt&gt;Q: &lt;a href="#getting_started"&gt;How can I get started, then?&lt;/a&gt;&lt;/dt&gt;&lt;dt&gt;Q: &lt;a href="#when_start"&gt;When do you have to start? Is it too late for me to learn?&lt;/a&gt;&lt;/dt&gt;&lt;dt&gt;Q: &lt;a href="#how_long"&gt;How long will it take me to learn to hack?&lt;/a&gt;&lt;/dt&gt;&lt;dt&gt;Q: &lt;a href="#closed_lang"&gt;Is Visual Basic a good language to start with?&lt;/a&gt;&lt;/dt&gt;&lt;dt&gt;Q: &lt;a href="#I_want_to_crack_and_Im_an_idiot"&gt;Would you help me to crack a system, or teach me how to crack?&lt;/a&gt;&lt;/dt&gt;&lt;dt&gt;Q: &lt;a href="#passwords"&gt;How can I get the password for someone else's account?&lt;/a&gt;&lt;/dt&gt;&lt;dt&gt;Q: &lt;a href="#crackmail"&gt;How can I break into/read/monitor someone else's email?&lt;/a&gt;&lt;/dt&gt;&lt;dt&gt;Q: &lt;a href="#crackop"&gt;How can I steal channel op privileges on IRC?&lt;/a&gt;&lt;/dt&gt;&lt;dt&gt;Q: &lt;a href="#anti_crack"&gt;I've been cracked. Will you help me fend off further attacks?&lt;/a&gt;&lt;/dt&gt;&lt;dt&gt;Q: &lt;a href="#windows_grief"&gt;I'm having problems with my Windows software. Will you help me?&lt;/a&gt;&lt;/dt&gt;&lt;dt&gt;Q: &lt;a href="#real_hackers"&gt;Where can I find some real hackers to talk with?&lt;/a&gt;&lt;/dt&gt;&lt;dt&gt;Q: &lt;a href="#books"&gt;Can you recommend useful books about hacking-related subjects?&lt;/a&gt;&lt;/dt&gt;&lt;dt&gt;Q: &lt;a href="#mathematics"&gt;Do I need to be good at math to become a hacker?&lt;/a&gt;&lt;/dt&gt;&lt;dt&gt;Q: &lt;a href="#language_first"&gt;What language should I learn first?&lt;/a&gt;&lt;/dt&gt;&lt;dt&gt;Q: &lt;a href="#hardware"&gt;What kind of hardware do I need?&lt;/a&gt;&lt;/dt&gt;&lt;dt&gt;Q: &lt;a href="#started2"&gt;I want to contribute. Can you help me pick a problem to work on?&lt;/a&gt;&lt;/dt&gt;&lt;dt&gt;Q: &lt;a href="#MS_hater"&gt;Do I need to hate and bash Microsoft?&lt;/a&gt;&lt;/dt&gt;&lt;dt&gt;Q: &lt;a href="#no_living"&gt;But won't open-source software leave programmers unable to make a living?&lt;/a&gt;&lt;/dt&gt;&lt;dt&gt;Q: &lt;a href="#problems"&gt;Where can I get a free Unix?&lt;/a&gt;&lt;/dt&gt;&lt;/dl&gt;&lt;table&gt;&lt;colgroup&gt;&lt;col width="1%"&gt;&lt;col&gt;&lt;/colgroup&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;a id="hacker_already"&gt;&lt;/a&gt;&lt;a id="idm396"&gt;&lt;/a&gt;&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;How do I tell if I am already a hacker?&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;Ask yourself the following three questions:&lt;/p&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Do you speak code, fluently?&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Do you identify with the goals and values of the hacker community?&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Has a well-established member of the hacker community ever called you a hacker?&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;p&gt;If you can answer yes to &lt;span&gt;&lt;em&gt;all three&lt;/em&gt;&lt;/span&gt; of these questions, you are already a hacker. No two alone are sufficient.&lt;/p&gt;&lt;p&gt;The first test is about skills. You probably pass it if you have the minimum technical skills described earlier in this document. You blow right through it if you have had a substantial amount of code accepted by an open-source development project.&lt;/p&gt;&lt;p&gt;The second test is about attitude. If the &lt;a title="The Hacker Attitude" href="#attitude"&gt;five principles of the hacker mindset&lt;/a&gt; seemed obvious to you, more like a description of the way you already live than anything novel, you are already halfway to passing it. That's the inward half; the other, outward half is the degree to which you identify with the hacker community's long-term projects.&lt;/p&gt;&lt;p&gt;Here is an incomplete but indicative list of some of those projects: Does it matter to you that Linux improve and spread? Are you passionate about software freedom? Hostile to monopolies? Do you act on the belief that computers can be instruments of empowerment that make the world a richer and more humane place?&lt;/p&gt;&lt;p&gt;But a note of caution is in order here. The hacker community has some specific, primarily defensive political interests — two of them are defending free-speech rights and fending off "intellectual-property" power grabs that would make open source illegal. Some of those long-term projects are civil-liberties organizations like the Electronic Frontier Foundation, and the outward attitude properly includes support of them. But beyond that, most hackers view attempts to systematize the hacker attitude into an explicit political program with suspicion; we've learned, the hard way, that these attempts are divisive and distracting. If someone tries to recruit you to march on your capitol in the name of the hacker attitude, they've missed the point. The right response is probably &lt;span&gt;“&lt;span&gt;Shut up and show them the code.&lt;/span&gt;”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;The third test has a tricky element of recursiveness about it. I observed in &lt;a title="What Is a Hacker?" href="#what_is"&gt;the section called “What Is a Hacker?”&lt;/a&gt; that being a hacker is partly a matter of belonging to a particular subculture or social network with a shared history, an inside and an outside. In the far past, hackers were a much less cohesive and self-aware group than they are today. But the importance of the social-network aspect has increased over the last thirty years as the Internet has made connections with the core of the hacker subculture easier to develop and maintain. One easy behavioral index of the change is that, in this century, we have our own T-shirts.&lt;/p&gt;&lt;p&gt;Sociologists, who study networks like those of the hacker culture under the general rubric of "invisible colleges", have noted that one characteristic of such networks is that they have gatekeepers — core members with the social authority to endorse new members into the network. Because the "invisible college" that is hacker culture is a loose and informal one, the role of gatekeeper is informal too. But one thing that all hackers understand in their bones is that not every hacker is a gatekeeper. Gatekeepers have to have a certain degree of seniority and accomplishment before they can bestow the title. How much is hard to quantify, but every hacker knows it when they see it.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;a id="teach_hack"&gt;&lt;/a&gt;&lt;a id="idm419"&gt;&lt;/a&gt;&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;Will you teach me how to hack?&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;Since first publishing this page, I've gotten several requests a week (often several a day) from people to "teach me all about hacking". Unfortunately, I don't have the time or energy to do this; my own hacking projects, and working as an open-source advocate, take up 110% of my time.&lt;/p&gt;&lt;p&gt;Even if I did, hacking is an attitude and skill you basically have to teach yourself. You'll find that while real hackers want to help you, they won't respect you if you beg to be spoon-fed everything they know.&lt;/p&gt;&lt;p&gt;Learn a few things first. Show that you're trying, that you're capable of learning on your own. Then go to the hackers you meet with specific questions.&lt;/p&gt;&lt;p&gt;If you do email a hacker asking for advice, here are two things to know up front. First, we've found that people who are lazy or careless in their writing are usually too lazy and careless in their thinking to make good hackers — so take care to spell correctly, and use good grammar and punctuation, otherwise you'll probably be ignored. Secondly, don't &lt;span&gt;&lt;em&gt;dare&lt;/em&gt;&lt;/span&gt; ask for a reply to an ISP account that's different from the account you're sending from; we find people who do that are usually thieves using stolen accounts, and we have no interest in rewarding or assisting thievery.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;a id="getting_started"&gt;&lt;/a&gt;&lt;a id="idm428"&gt;&lt;/a&gt;&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;How can I get started, then?&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;The best way for you to get started would probably be to go to a LUG (Linux user group) meeting. You can find such groups on the &lt;a href="http://www.tldp.org/links/index.html"&gt;LDP General Linux Information Page&lt;/a&gt;; there is probably one near you, possibly associated with a college or university. LUG members will probably give you a Linux if you ask, and will certainly help you install one and get started.&lt;/p&gt;&lt;p&gt;Your next step (and your first step if you can't find a LUG nearby) should be to find an open-source project that interests you. Start reading code and reviewing bugs. Learn to contribute, and work your way in.&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;The only way in is by working to improve your skills.&lt;/em&gt;&lt;/span&gt; If you ask me personally for advice on how to get started, I will tell you these exact same things, because I don't have any magic shortcuts for you. I will also mentally write you off as a probable loser - because if you lacked the stamina to read this FAQ and the intelligence to understand from it that &lt;span&gt;&lt;em&gt;the only way in is by working to improve your skills&lt;/em&gt;&lt;/span&gt;, you're hopeless.&lt;/p&gt;&lt;p&gt;Another interesting possibility is to go visit a hackerspace. There is a burgeoning movement of people creating physical locations - maker's clubs - where they can hang out to work on hardware and software projects together, or work solo in a cogenial atmosphere. Hackerspaces often collect tools and specialized equipment that would be too expensive or logistically inconvenient for individuals to own. Hackerspaces are easy to find on the Internet; one may be located near you.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;a id="when_start"&gt;&lt;/a&gt;&lt;a id="idm439"&gt;&lt;/a&gt;&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;When do you have to start? Is it too late for me to learn?&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;Any age at which you are motivated to start is a good age. Most people seem to get interested between ages 15 and 20, but I know of exceptions in both directions.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;a id="how_long"&gt;&lt;/a&gt;&lt;a id="idm444"&gt;&lt;/a&gt;&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;How long will it take me to learn to hack?&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;That depends on how talented you are and how hard you work at it. Most people who try can acquire a respectable skill set in eighteen months to two years, if they concentrate. Don't think it ends there, though; in hacking (as in many other fields) it takes about ten years to achieve mastery. And if you are a real hacker, you will spend the rest of your life learning and perfecting your craft.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;a id="closed_lang"&gt;&lt;/a&gt;&lt;a id="idm449"&gt;&lt;/a&gt;&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;Is Visual Basic a good language to start with?&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;If you're asking this question, it almost certainly means you're thinking about trying to hack under Microsoft Windows. This is a bad idea in itself. When I compared trying to learn to hack under Windows to trying to learn to dance while wearing a body cast, I wasn't kidding. Don't go there. It's ugly, and it never stops being ugly.&lt;/p&gt;&lt;p&gt;There is a specific problem with Visual Basic; mainly that it's not portable. Though there is a prototype open-source implementations of Visual Basic, the applicable ECMA standards don't cover more than a small set of its programming interfaces. On Windows most of its library support is proprietary to a single vendor (Microsoft); if you aren't &lt;span&gt;&lt;em&gt;extremely&lt;/em&gt;&lt;/span&gt; careful about which features you use — more careful than any newbie is really capable of being — you'll end up locked into only those platforms Microsoft chooses to support. If you're starting on a Unix, much better languages with better libraries are available. Python, for example.&lt;/p&gt;&lt;p&gt;Also, like other Basics, Visual Basic is a poorly-designed language that will teach you bad programming habits. No, &lt;span&gt;&lt;em&gt;don't&lt;/em&gt;&lt;/span&gt; ask me to describe them in detail; that explanation would fill a book. Learn a well-designed language instead.&lt;/p&gt;&lt;p&gt;One of those bad habits is becoming dependent on a single vendor's libraries, widgets, and development tools. In general, any language that isn't fully supported under at least Linux or one of the BSDs, and/or at least three different vendors' operating systems, is a poor one to learn to hack in.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;a id="I_want_to_crack_and_Im_an_idiot"&gt;&lt;/a&gt;&lt;a id="idm459"&gt;&lt;/a&gt;&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;Would you help me to crack a system, or teach me how to crack?&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;No. Anyone who can still ask such a question after reading this FAQ is too stupid to be educable even if I had the time for tutoring. Any emailed requests of this kind that I get will be ignored or answered with extreme rudeness.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;a id="passwords"&gt;&lt;/a&gt;&lt;a id="idm464"&gt;&lt;/a&gt;&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;How can I get the password for someone else's account?&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;This is cracking. Go away, idiot.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;a id="crackmail"&gt;&lt;/a&gt;&lt;a id="idm469"&gt;&lt;/a&gt;&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;How can I break into/read/monitor someone else's email?&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;This is cracking. Get lost, moron.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;a id="crackop"&gt;&lt;/a&gt;&lt;a id="idm474"&gt;&lt;/a&gt;&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;How can I steal channel op privileges on IRC?&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;This is cracking. Begone, cretin.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;a id="anti_crack"&gt;&lt;/a&gt;&lt;a id="idm479"&gt;&lt;/a&gt;&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;I've been cracked. Will you help me fend off further attacks?&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;No. Every time I've been asked this question so far, it's been from some poor sap running Microsoft Windows. It is not possible to effectively secure Windows systems against crack attacks; the code and architecture simply have too many flaws, which makes securing Windows like trying to bail out a boat with a sieve. The only reliable prevention starts with switching to Linux or some other operating system that is designed to at least be capable of security.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;a id="windows_grief"&gt;&lt;/a&gt;&lt;a id="idm484"&gt;&lt;/a&gt;&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;I'm having problems with my Windows software. Will you help me?&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;Yes. Go to a DOS prompt and type "format c:". Any problems you are experiencing will cease within a few minutes.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;a id="real_hackers"&gt;&lt;/a&gt;&lt;a id="idm489"&gt;&lt;/a&gt;&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;Where can I find some real hackers to talk with?&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;The best way is to find a Unix or Linux user's group local to you and go to their meetings (you can find links to several lists of user groups on the &lt;a href="http://www.tldp.org/"&gt;LDP&lt;/a&gt; site at ibiblio).&lt;/p&gt;&lt;p&gt;(I used to say here that you wouldn't find any real hackers on IRC, but I'm given to understand this is changing. Apparently some real hacker communities, attached to things like GIMP and Perl, have IRC channels now.)&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;a id="books"&gt;&lt;/a&gt;&lt;a id="idm496"&gt;&lt;/a&gt;&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;Can you recommend useful books about hacking-related subjects?&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;I maintain a &lt;a href="http://en.tldp.org/HOWTO/Reading-List-HOWTO/index.html"&gt; Linux Reading List HOWTO&lt;/a&gt; that you may find helpful. The &lt;a href="http://www.catb.org/esr/faqs/loginataka.html"&gt;Loginataka&lt;/a&gt; may also be interesting.&lt;/p&gt;&lt;p&gt;For an introduction to Python, see the &lt;a href="http://docs.python.org/tutorial/index.html"&gt;tutorial &lt;/a&gt; on the Python site.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;a id="mathematics"&gt;&lt;/a&gt;&lt;a id="idm505"&gt;&lt;/a&gt;&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;Do I need to be good at math to become a hacker?&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;No. Hacking uses very little formal mathematics or arithmetic. In particular, you won't usually need trigonometry, calculus or analysis (there are exceptions to this in a handful of specific application areas like 3-D computer graphics). Knowing some formal logic and Boolean algebra is good. Some grounding in finite mathematics (including finite-set theory, combinatorics, and graph theory) can be helpful.&lt;/p&gt;&lt;p&gt;Much more importantly: you need to be able to think logically and follow chains of exact reasoning, the way mathematicians do. While the content of most mathematics won't help you, you will need the discipline and intelligence to handle mathematics. If you lack the intelligence, there is little hope for you as a hacker; if you lack the discipline, you'd better grow it.&lt;/p&gt;&lt;p&gt;I think a good way to find out if you have what it takes is to pick up a copy of Raymond Smullyan's book &lt;em&gt;What Is The Name Of This Book?&lt;/em&gt;. Smullyan's playful logical conundrums are very much in the hacker spirit. Being able to solve them is a good sign; &lt;span&gt;&lt;em&gt;enjoying&lt;/em&gt;&lt;/span&gt; solving them is an even better one.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;a id="language_first"&gt;&lt;/a&gt;&lt;a id="idm514"&gt;&lt;/a&gt;&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;What language should I learn first?&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;HTML if you don't already know it. There are a lot of glossy, hype-intensive &lt;span&gt;&lt;em&gt;bad&lt;/em&gt;&lt;/span&gt; HTML books out there, and distressingly few good ones. The one I like best is &lt;a href="http://www.oreilly.com/catalog/html5/"&gt;&lt;em&gt;HTML: The Definitive Guide&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;But HTML is not a full programming language. When you're ready to start programming, I would recommend starting with &lt;a href="http://www.python.org/"&gt;Python&lt;/a&gt;. You will hear a lot of people recommending Perl, but it's harder to learn and (in my opinion) less well designed.&lt;/p&gt;&lt;p&gt;C is really important, but it's also much more difficult than either Python or Perl. Don't try to learn it first.&lt;/p&gt;&lt;p&gt;Windows users, do &lt;span&gt;&lt;em&gt;not&lt;/em&gt;&lt;/span&gt; settle for Visual Basic. It will teach you bad habits, and it's not portable off Windows. Avoid.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;a id="hardware"&gt;&lt;/a&gt;&lt;a id="idm527"&gt;&lt;/a&gt;&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;What kind of hardware do I need?&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;It used to be that personal computers were rather underpowered and memory-poor, enough so that they placed artificial limits on a hacker's learning process. This stopped being true in the mid-1990s; any machine from an Intel 486DX50 up is more than powerful enough for development work, X, and Internet communications, and the smallest disks you can buy today are plenty big enough.&lt;/p&gt;&lt;p&gt;The important thing in choosing a machine on which to learn is whether its hardware is Linux-compatible (or BSD-compatible, should you choose to go that route). Again, this will be true for almost all modern machines. The only really sticky areas are modems and wireless cards; some machines have Windows-specific hardware that won't work with Linux.&lt;/p&gt;&lt;p&gt;There's a FAQ on hardware compatibility; the latest version is &lt;a href="http://en.tldp.org/HOWTO/Hardware-HOWTO/index.html"&gt; here&lt;/a&gt;.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;a id="started2"&gt;&lt;/a&gt;&lt;a id="idm535"&gt;&lt;/a&gt;&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;I want to contribute. Can you help me pick a problem to work on?&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;No, because I don't know your talents or interests. You have to be self-motivated or you won't stick, which is why having other people choose your direction almost never works.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;a id="MS_hater"&gt;&lt;/a&gt;&lt;a id="idm540"&gt;&lt;/a&gt;&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;Do I need to hate and bash Microsoft?&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;No, you don't. Not that Microsoft isn't loathsome, but there was a hacker culture long before Microsoft and there will still be one long after Microsoft is history. Any energy you spend hating Microsoft would be better spent on loving your craft. Write good code — that will bash Microsoft quite sufficiently without polluting your karma.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;a id="no_living"&gt;&lt;/a&gt;&lt;a id="idm545"&gt;&lt;/a&gt;&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;But won't open-source software leave programmers unable to make a living?&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;This seems unlikely — so far, the open-source software industry seems to be creating jobs rather than taking them away. If having a program written is a net economic gain over not having it written, a programmer will get paid whether or not the program is going to be open-source after it's done. And, no matter how much "free" software gets written, there always seems to be more demand for new and customized applications. I've written more about this at the &lt;a href="http://www.opensource.org/"&gt;Open Source&lt;/a&gt; pages.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;a id="problems"&gt;&lt;/a&gt;&lt;a id="idm551"&gt;&lt;/a&gt;&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;Where can I get a free Unix?&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;If you don't have a Unix installed on your machine yet, elsewhere on this page I include pointers to where to get the most commonly used free Unix. To be a hacker you need motivation and initiative and the ability to educate yourself. Start now...&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;&lt;p&gt;&lt;img src="http://www.catb.org/esr/faqs/glider.png"&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;a href="http://www.catb.org/esr/faqs/hacker-howto.html"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 22:14:16 UT
      </pubDate>
      <guid>
        http://www.catb.org/esr/faqs/hacker-howto.html
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://overreacted.io/my-decade-in-review/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;&lt;p&gt;I started this decade as a first-year college student fresh out of high school. I was 17, didn’t have a job, didn’t have any industry connections, and really didn’t know shit. And now you’re reading my blog! I would have been proud.&lt;/p&gt; &lt;p&gt;I’ve told bits and pieces of my story on different podcasts. Now feels like an appropriate time to write down the parts that were most memorable to me.&lt;/p&gt; &lt;p&gt;Every person’s story is unique and not directly reproducible. I’ve benefited immensely from the privilege of being born in an upper middle class family and looking like a typical coder stereotype. People took chances on me. Still, I hope that sharing my story can be helpful to compare our experiences. Even if our circumstances are too different, at least you might find some of it entertaining.&lt;/p&gt; &lt;h2 id="2010"&gt;&lt;a aria-hidden="" href="#2010"&gt;&lt;/a&gt;2010&lt;/h2&gt; &lt;p&gt;I was born in Russia and I finished the high school there in 2009. In Russia, higher education is free if you do well enough at tests. I tried my chances with a few colleges. I was particularly hoping to get into one college whose students often won programming competitions (which I thought was cool at the time).&lt;/p&gt; &lt;p&gt;However, it turned out my math exam scores weren’t good enough. So there were not many options I could choose from that had to do with programming. From the remaining options, I picked a college that gave Macbooks to students. (Remember the white plastic ones with GarageBand? They were the best.)&lt;/p&gt; &lt;p&gt;By the summer of 2010, I had just finished my first year there. It turned out that there wasn’t going to be much programming in the curriculum for two more years. But there was a lot of linear algebra, physics, and other subjects I didn’t find particularly interesting. Everything was well in the beginning, but I started slacking off and skipping lectures that I had to wake up early for. My gaps in knowledge gradually snowballed, and most of what I remember from my first year in the university is the anxiety associated with feeling like a total failure.&lt;/p&gt; &lt;p&gt;Even for subjects I knew well, things didn’t quite go as I planned. Our English classes were very rudimentary, and I got a verbal approval from the teacher to skip most of them. But when I came for the final test, I wasn’t &lt;em&gt;allowed&lt;/em&gt; to turn it in unless I pay money for hours of “catch up training” with the same teacher. This experience left me resentful and suspicious of higher education.&lt;/p&gt; &lt;p&gt;Aside from being a lousy student, I was also in my first serious relationship — and it wasn’t going very well either. I was unhappy, but I thought that you can solve this by continuing to be unhappy and “fixing” it. Unfortunately, I didn’t have the wisdom to get out of a non-working relationship for a few more years.&lt;/p&gt; &lt;p&gt;Now onto the bright side. Professionally, 2010 was an exciting year for me. I got my first job as a software developer! Here’s how that happened.&lt;/p&gt; &lt;p&gt;There was a small venue close to my college that hosted different events. This venue was a “business incubator” — mind you, not a Silicon Valley kind of business incubator — but a tiny Russian one. I have no idea what businesses they “incubated”. However, they hosted a talk about software development, and I decided to check it out because I was starving for that kind of content. I didn’t know any programmers in real life, and I didn’t know meetups existed!&lt;/p&gt; &lt;p&gt;I don’t remember what the talk was about now. But I knew the person who gave it was an executive in a Russian-American outsourcing company. I’ve been programming since 12, so I approached him and asked if they’re hiring. He gave me an email, I went through their test exercises, and in a few weeks got the job.&lt;/p&gt; &lt;p&gt;I started at my first job during the summer of 2010. My salary was $18k/year (yes that’s 18 and not 180). This is peanuts in the developed world, but again, this was Russia — so the rent was cheap too. I immediately moved out of my mom’s apartment and started renting a room for $150 a month. I was excited. With my first salary, I bought an iPhone and marvelled at how good the UI was.&lt;/p&gt; &lt;p&gt;Summer came and went, and then the second college year started. But it started without me. Now that I was doing actual work and people payed me for it, I lost my last bits of motivation for sitting at lectures and doing exercises. I stopped going there and didn’t show up for the midterm exams. I returned my Macbook. The only time I went there again was five years later, to pick up my papers.&lt;/p&gt; &lt;p&gt;A short digression. I’m not saying colleges are worthless, or that you should drop out. It was the right decision for me, but I knew I could fall back on my family (more on that later) when things are tough. I also already had a job.&lt;/p&gt; &lt;p&gt;I had the privilege to be seen as knowledgeable &lt;em&gt;by default&lt;/em&gt; due to my background (a guy who started coding early). People who don’t fit this stereotype often get a degree just to gain access to that assumed competence. So there’s that.&lt;/p&gt; &lt;h2 id="2011"&gt;&lt;a aria-hidden="" href="#2011"&gt;&lt;/a&gt;2011&lt;/h2&gt; &lt;p&gt;Most of my job was fixing up poor code after cheaper outsourcing companies. Having no industry experience myself, I overengineered every project to try every cool technology I could get my hands on. I even put &lt;a rel="nofollow noopener noreferrer" href="https://www.microsoft.com/en-us/research/project/moles-isolation-framework-for-net/"&gt;random Microsoft Research projects&lt;/a&gt; in production. Sorry about that. I did some good work too.&lt;/p&gt; &lt;p&gt;My first interesting work project involved a trip. Our client was an investment group in New York. I still don’t know anything about investments, but basically they had an email system that received orders, and those orders needed to go through different levels of approval. They had a service that manages that, but the service was extremely flaky, and nobody could figure out how it works. My job was to go onsite, work from New York for a month, and fix the service.&lt;/p&gt; &lt;p&gt;The service was written by a contractor from a cheaper outsourcing company. Nine years later, I still remember his name. The most memorable part of that code was a single thirty thousand line function. To figure out what it does, I had to print it on paper, lay out the sheets on my desk, and annotate them with a pencil. It turned out that it was the same block of code, repeated fifty times with different conditions. I guess someone was paid by the number of lines of code.&lt;/p&gt; &lt;p&gt;I spent that month adding a shitton of logging to figure out what the service does in production, and then rebuilding it from scratch to be less flaky. Working with a non-tech company was a perplexing experience. For example, I couldn’t push a bugfix without writing a Word document describing my changes and getting the IT department head to sign off on it. Now &lt;em&gt;that’s&lt;/em&gt; some code review.&lt;/p&gt; &lt;p&gt;Close to the end of my trip, I went to see a concert at a bar late at night. The next morning I was supposed to present my month of work to the client. My meeting was scheduled for 9am. Unfortunately, I overslept and only woke up at 1pm that day. My manager apologized for me, and I went home bitterly embarrassed.&lt;/p&gt; &lt;p&gt;There were no repercussions at work. The project was a success overall, and the client knew I’m some weird Russian dude who doesn’t know how to groom his hair. But I knew I made a fool of myself. I also wasn’t particularly looking forward to more “enterprise projects”. Work became a chore.&lt;/p&gt; &lt;p&gt;I was back in Saint Petersburg in Russia. In the summer, the sky there doesn’t go dark. During one night of soul-searching, I hopped from a bar to another with a vague sense of unease. Around 7am, a lightbulb went off in my head. I ate a shawarma, took a subway to the office, waited for HR, and quit my job.&lt;/p&gt; &lt;p&gt;My friend was planning a trip to Crimea (before it got annexed) and asked if I would like to join. I packed up a tent and an old Nokia phone that held battery for a week. We camped for two weeks, mostly naked, in a fog of alternative mind states. I barely remember anything from that trip except two episodes.&lt;/p&gt; &lt;p&gt;Once, somebody threatened me with a knife. That person said he would kill me, but he was gone the next day, and everything went on as normal. Another time, I foolishly tried to swim around the cliff alone and almost drowned. I was saved by a rock in the sea that I climbed and passed out on for what felt like an hour.&lt;/p&gt; &lt;p&gt;This trip acted like a hardware reset. My burnout was cured, and I was ready to write code again. (But don’t say I told you to almost die to cure a burnout.)&lt;/p&gt; &lt;p&gt;The only problem was… my skills were irrelevant! Yikes.&lt;/p&gt; &lt;p&gt;You see, I was mostly writing desktop software. Has anyone even heard of desktop software? That’s not a thing anymore. Either you do backend, or you do mobile, or you do front-end. I didn’t know anything about either of them. And I didn’t have a job. So I had to move back to live with my Mom. (Thanks, Mom!)&lt;/p&gt; &lt;p&gt;Soon, I saw a post on a social network. It was written by a Russian guy who came back from the Silicon Valley to Russia. He was looking for people who would volunteer to work on his projects for free, in return for him teaching us web development for free. At the time, that sounded like a good deal to me.&lt;/p&gt; &lt;p&gt;I joined this program. I found out quickly enough that there was no real teaching involved: we were given a few tutorials from the web, and we mostly learned from helping each other. Luckily, I could afford to do that for some time while I lived at my Mom’s place. I learned Git, basics of Python, Django, a bit of CSS and JavaScript, and some Bash to deploy my changes. Hello Web, here I go.&lt;/p&gt; &lt;p&gt;Nine years later, I’m still unsure how I feel about this program. On the one hand, we were working on his projects for free. On the other hand, we were given full root access, and it was really exciting to be able to push our changes in production and learn from our mistakes. It gave us a structure for learning. It didn’t cost us anything, and you could drop out any time. The projects had some social utility due to being around education. This reminded me of open source.&lt;/p&gt; &lt;p&gt;I still feel grateful to this person for setting up this ad hoc “bootcamp” and being my mentor. But I don’t want to imply that working for free is a good way to practice in general. I’m not offering advice here — I am only telling my story.&lt;/p&gt; &lt;p&gt;I built a dashboard where we could track our own learning achievements. My mentor suggested that I pitch it as a product to companies that run courses. My brief foray into playing “startups” was awkward. I didn’t know what product I was building, and I pitched different things to different people. Essentially, I ended up making several completely different websites for different clients with a single engine, and earned about $200 in the process. I wasted months of my time on it, as well as the time of friends who offered to help. I was ashamed of it, and shut it down. The silver lining was that I became a web developer.&lt;/p&gt; &lt;p&gt;But I still didn’t have a job.&lt;/p&gt; &lt;h2 id="2012"&gt;&lt;a aria-hidden="" href="#2012"&gt;&lt;/a&gt;2012&lt;/h2&gt; &lt;p&gt;As a 20 year old web developer, there was only one place I wanted to work at. It was a Russian social media company. Everybody in Russia used their product. That product was very polished. And the team was considered &lt;em&gt;cool&lt;/em&gt;. Almost elite.&lt;/p&gt; &lt;p&gt;Their executives often posted about how well-paid their engineers are. The small team of engineers seemed happy with the technical challenges and how the company treated them. In the Russian tech circles, many knew their names.&lt;/p&gt; &lt;p&gt;My mentor introduced me to their CTO, and I got a takehome exercise in JavaScript. It involved building a clone of their typeahead where you could select friends to message. I spent two weeks building it. It was pixel perfect in all browsers. I took care to replicate a similar caching and debouncing behavior.&lt;/p&gt; &lt;p&gt;The onsite interview was a disaster. Clearly, I didn’t have the experience at their scale. However, they said they’re willing to give me a try if I “understand their product”. They gave me a take-home exercise of designing a logged out state for that social media website. They wanted it to show a picture of a feature phone — many people didn’t know the mobile website works on cheap phones.&lt;/p&gt; &lt;p&gt;I spent a week designing that page. I did a lot of tiny details and even hid some Easter eggs in it. I was proud of myself. However, I couldn’t find any decent designs of a feature phone that wouldn’t look ugly. Instead, I put a beautiful iPhone design there. So aesthetically pleasing, I thought.&lt;/p&gt; &lt;p&gt;Of course, I got rejected. I ignored literally the only hard requirement — why was I so dense? I cried for a few hours because I didn’t really want to work anywhere else. I was still living with my Mom and was making no money.&lt;/p&gt; &lt;p&gt;At the time, I was seriously doubting my skills. Many things seemed “magic” to me. I started having doubts about whether dropping out was a good idea, after all. I signed up for an iOS development course on iTunes U. I also signed up for two courses on Coursera: Compilers and Machine Learning. Maybe they would make me a “real programmer”.&lt;/p&gt; &lt;p&gt;It was lonely to go through these courses on my own. I organized a tiny meetup with a few people from our web development “bootcamp”. We would gather and watch different online courses together at my mentor’s coworking space.&lt;/p&gt; &lt;p&gt;A month into it, I got an email. Someone was looking to hire a developer, and he heard about me from a person who went to my meetup. I was sick with mono and ignored the email, but this guy kept emailing me. He wanted to skype.&lt;/p&gt; &lt;p&gt;Roman Mazurenko was not a typical startup founder. Roman was interested in DIY publishing. Together with a couple of friends, for a few years, he somehow &lt;a rel="nofollow noopener noreferrer" href="https://youtu.be/Wj2FmNGw47c?t=9"&gt;made Moscow cool&lt;/a&gt;. He organized parties and posed for fashion magazines. I didn’t know what to expect. But Roman was very down-to-earth and fun to talk to. His dream was to build a DIY publishing platform like in this &lt;a rel="nofollow noopener noreferrer" href="https://vimeo.com/55247463"&gt;concept video&lt;/a&gt;. I would have to move to Moscow and learn iOS development on the go. (By the way, the video guy is not Roman but a friend, and the app in the video is a fake animation made with Flash. Roman was great at crafting smoke and mirrors.)&lt;/p&gt; &lt;p&gt;I said yes.&lt;/p&gt; &lt;p&gt;I didn’t finish my Compilers and Machine Learning courses. I learned enough to know these topics aren’t magic. After that, I lost most of my interest in them.&lt;/p&gt; &lt;h2 id="2013"&gt;&lt;a aria-hidden="" href="#2013"&gt;&lt;/a&gt;2013&lt;/h2&gt; &lt;p&gt;By 2013, my salary was $30k/year — almost twice what I made at my previous job. While low by US standards, it was pretty decent in Russia. I also negotiated some stock at Stampsy (spoiler alert: it ended up completely worthless).&lt;/p&gt; &lt;p&gt;Our team had five developers and two designers. We started by developing an iPad app, but neither of us had any real knowledge of iOS. I remember my relief when a teammate figured out how to implement the animation we needed for the first time. Until then, I thought we were doomed.&lt;/p&gt; &lt;p&gt;For a few months, I literally lived in our office. Looking back at this period, I’m not proud of my life-work balance, and it was not healthy. However, I learned more during these months than in two years before, and I don’t regret them.&lt;/p&gt; &lt;p&gt;Eventually, I moved out of the office. I’ve started to live in the same flat as Roman. My room cost me $1k/month. It was a spacious flat in the only area of Moscow that I enjoyed, and it was only five minutes of walk from the office.&lt;/p&gt; &lt;p&gt;We thought that some of the code we wrote might be useful to others. So we started publishing those pieces on GitHub. We didn’t expect anything grand, and even getting a couple of contributions was really nice. The most popular project I worked on during that period has 30 stars. To us, that was a &lt;em&gt;lot&lt;/em&gt;.&lt;/p&gt; &lt;p&gt;A designer on our team introduced me to Bret Victor’s talks — particularly, to &lt;a rel="nofollow noopener noreferrer" href="https://vimeo.com/36579366"&gt;Inventing on Principle&lt;/a&gt;. I thought it was a very good talk. A &lt;em&gt;very&lt;/em&gt; good one.&lt;/p&gt; &lt;p&gt;In April, we released the &lt;a rel="nofollow noopener noreferrer" href="https://www.youtube.com/watch?v=PjaL0xFbEY8"&gt;iPad app&lt;/a&gt; we’ve been working on. Apple reached out to our team and asked for assets to feature it in the App Store. We were over the moon. It stayed featured for weeks, and people started using it.&lt;/p&gt; &lt;p&gt;Our excitement quickly wore down as we realized there was no product market fit. The app was designed to create beautiful magazine-like layouts, but nobody had any beautiful content on an iPad. Also, the iPad camera had a horrible quality. The product didn’t make any sense. How could we not realize this?&lt;/p&gt; &lt;p&gt;My personal relationship was falling apart too. We weren’t a good fit, and mostly clung to each other out of fear of being alone. We finally broke up.&lt;/p&gt; &lt;p&gt;For a few months, I didn’t talk to people from our shared mutual circle and focused on work. But I realized that I missed one particular friend. I wrote to her, and she said she missed me too. I arranged a plan for a trip together.&lt;/p&gt; &lt;p&gt;I caught a cold. As the day of our would-be trip got closer, I felt worse, but I was hoping that maybe I’d be okay. When my train from Moscow to St. Petersburg had arrived, I clearly had a temperature. She said to come to her place anyway. She made me some hot tea, gave me warm socks, and we kissed. I moved in.&lt;/p&gt; &lt;h2 id="2014"&gt;&lt;a aria-hidden="" href="#2014"&gt;&lt;/a&gt;2014&lt;/h2&gt; &lt;p&gt;For me, 2014 was the year of React.&lt;/p&gt; &lt;p&gt;After a brief existential crisis, we abandoned the iPad app and decided to pivot to a webapp. That meant I had to learn JavaScript, this time for reals. We built a decent prototype with Backbone, but interactive parts were a pain to code.&lt;/p&gt; &lt;p&gt;My colleague saw React but initially dismissed it. But a few months later, he told me React wasn’t actually that bad. I decided to give React a try. Ironically, the first component I converted from Backbone to React was a Like button.&lt;/p&gt; &lt;p&gt;And it worked well. &lt;em&gt;Really&lt;/em&gt; well. It felt unlike anything I’ve seen.&lt;/p&gt; &lt;p&gt;React wasn’t a hard sell for the team. Over the next year we gradually converted all of our UI to React while shipping new features. React and the principle of unidirectional data flow allowed us to develop faster and with fewer bugs.&lt;/p&gt; &lt;p&gt;We started a private beta, and some photographers enjoyed creating visual stories with it. It was something between Medium, Pinterest, and Tumblr. There wasn’t a lot of traction, but it wasn’t a complete failure like the iPad app.&lt;/p&gt; &lt;p&gt;The only problem with using React was that there was virtually no ecosystem. When we just started, there was only one router (which was &lt;em&gt;not&lt;/em&gt; React Router), and we couldn’t figure out how to use it. So we made our own. After React Router came out, we adopted it and &lt;a rel="nofollow noopener noreferrer" href="https://github.com/ReactTraining/react-router/pull/388"&gt;added&lt;/a&gt; a feature we needed for our product.&lt;/p&gt; &lt;p&gt;There was no drag and drop solution for our use cases, so I &lt;a rel="nofollow noopener noreferrer" href="https://github.com/react-dnd/react-dnd/releases/tag/v0.1.0"&gt;ported&lt;/a&gt; my colleague’s library to React. I made &lt;a rel="nofollow noopener noreferrer" href="https://github.com/gaearon/react-document-title/releases/tag/v0.1.0"&gt;a helper&lt;/a&gt; to manage document titles. Wrote &lt;a rel="nofollow noopener noreferrer" href="https://github.com/paularmstrong/normalizr/releases/tag/v0.1.1"&gt;another library&lt;/a&gt; to normalize API responses. Jing Chen from the React IRC channel suggested the core idea, and it worked! Little did I know that in a few years, Twitter would build their new website with this library and maintain it.&lt;/p&gt; &lt;p&gt;I wanted to contribute to React itself, too. I reached out to Paul O’Shannessy and asked if there were any pull requests I could work on. I finished &lt;a rel="nofollow noopener noreferrer" href="https://github.com/facebook/react/pull/1601"&gt;my first task&lt;/a&gt; in a few days, but it didn’t get merged until a few months later. Big project release cycles, and all that. I was frustrated by the slowness in response so I put effort into the ecosystem instead. In retrospect, that was a lot more impactful.&lt;/p&gt; &lt;p&gt;In 2014, I did some of my first public speaking. I gave sort of a lecture about React at our office. It ended up going for two hours, and I’m still surprised that most of the people who showed up were polite enough to stay to the end.&lt;/p&gt; &lt;p&gt;Later, I signed up to give a talk at the BerlinJS meetup. My topic was “React and Flux”. I didn’t practice my talk, and I only went through the first half when my time ran out. People rolled their eyes, and I finally learned my lesson. From that point on, I would rehearse every talk from three up to fifteen times.&lt;/p&gt; &lt;p&gt;In 2014, I got my first email from a Facebook recruiter. I missed it in my inbox and only found it many months later. We still chatted eventually, but it turned out that hiring me in USA wouldn’t be easy because I didn’t have enough years of experience &lt;em&gt;and&lt;/em&gt; I dropped out of college. Oops.&lt;/p&gt; &lt;p&gt;There was one project I started in 2014 that was particularly dear to me. Like most important things in my life, it happened randomly. I was converting our app from require.js to webpack to enable code splitting. I read about a bizarre webpack feature called “hot module replacement” that allowed you to edit CSS without reloading the page. But in webpack, it could work for JavaScript too.&lt;/p&gt; &lt;p&gt;I was really confused by this feature so I &lt;a rel="nofollow noopener noreferrer" href="https://stackoverflow.com/questions/24581873/what-exactly-is-hot-module-replacement-in-webpack"&gt;asked&lt;/a&gt; about it on StackOverflow. Webpack was still very new, and its creator noticed my question and left a response. It gave me enough information to see I could tie this feature with React, in the spirit of the first demo from Bret Victor’s talk I mentioned earlier.&lt;/p&gt; &lt;p&gt;I wrote an extremely hacky proof of concept by editing React source code and adding a bunch of global variables. I decided I won’t go to sleep until it works, and by 7am I had a demo I could &lt;a rel="nofollow noopener noreferrer" href="https://twitter.com/dan_abramov/status/485611717183819776"&gt;tweet&lt;/a&gt;. Nobody cared about my Twitter before that, but this received some likes and retweets, and those 20 retweets were hugely validating. I knew then I’m not the only one who thinks this is exciting. This proof of concept was a throwaway effort and I didn’t have time to keep working on it at my job. I took a vacation, and finished off the &lt;a rel="nofollow noopener noreferrer" href="https://github.com/gaearon/react-hot-loader/tree/v0.1.0"&gt;prototype&lt;/a&gt; there.&lt;/p&gt; &lt;p&gt;Quick disclaimer: again, I’m not saying you “need to” work nights or vacations. I’m not glorifying hustle, and there are plenty of people with great careers who did none of that. In fact, if I were better at time management, I could probably find a way to squeeze those non-interrupted hours in my regular day, or to learn to make progress with interruptions. I am sharing this because I’m telling my story, and it would be a lie to pretend I did everything in a 40 hour week.&lt;/p&gt; &lt;h2 id="2015"&gt;&lt;a aria-hidden="" href="#2015"&gt;&lt;/a&gt;2015&lt;/h2&gt; &lt;p&gt;Our product went out of a private beta. It was growing, but slowly and linearly. The company was running out of funding and struggled to raise more money. And I wanted to spend more and more time on my open source projects.&lt;/p&gt; &lt;p&gt;I also wanted to give my first conference talk. Naturally, I wanted to talk about hot reloading, but I knew somebody already mentioned it at ReactConf, and I thought people wouldn’t be excited about it. I decided to add some spice to my &lt;a rel="nofollow noopener noreferrer" href="https://github.com/react-europe/cfp-2015/pull/7"&gt;talk proposal&lt;/a&gt; by adding “with time travel” — again, inspired by Bret’s demo. The proposal got accepted, and for a few months I didn’t think much about it.&lt;/p&gt; &lt;p&gt;In April, my salary got delayed by several weeks. It went through eventually, but I realized it’s time to look for a new job. I found some company using one of my projects, and they agreed to sponsor my work on it for a few months.&lt;/p&gt; &lt;p&gt;My girlfriend asked if I wanted to get married. I said I thought I’d get married late in my 30s. She asked: “Why?” I couldn’t really find any justification for waiting so we soon bought rings and got married. Our wedding has cost us $100.&lt;/p&gt; &lt;p&gt;The deadline for my talk was approaching. But I had no idea how to implement “time travel”. I knew that Elm had something similar, but I was scared to look at it because I worried I’d find out time travel can’t be implemented well in JS.&lt;/p&gt; &lt;p&gt;At the time, there were many Flux libraries. I’ve tried a few of those, notably Flummox by Andrew Clark, and I had a vague sense that making hot reloading work with Flux would &lt;em&gt;also&lt;/em&gt; let me implement time travel. Sunil’s &lt;a rel="nofollow noopener noreferrer" href="https://gist.github.com/threepointone/43f16389fd96561a8b0b"&gt;gist&lt;/a&gt; led me to an &lt;a rel="nofollow noopener noreferrer" href="https://gist.github.com/gaearon/c02f3eb38724b64ab812"&gt;idea&lt;/a&gt;: a variant of Flux pattern with a reducer function instead of a store. I had a &lt;a rel="nofollow noopener noreferrer" href="https://twitter.com/dan_abramov/status/597391033513697281"&gt;neat name&lt;/a&gt; in mind for it already. And I really needed it for my talk!&lt;/p&gt; &lt;p&gt;I implemented Redux just in time for my demo of time travel. My first talk rehearsal was on Skype. I was sweating, mumbling, and running over it too fast. At the end of my rehearsal, I asked the organizer if my talk was any good. He said “well… people &lt;em&gt;like&lt;/em&gt; you” which I took as an euphemism for horrible.&lt;/p&gt; &lt;p&gt;I asked a designer friend from the startup I just quit to help make my slides pretty. I added animations and transitions. The more polished my talk looked, the calmer and more confident I felt. I practiced it a dozen times.&lt;/p&gt; &lt;p&gt;I flew to Paris for my first technical conference. This was probably the happiest day of my life. For the first time, I put faces next to avatars. There were UI nerds and my personal heroes around me. It felt like going to Hogwarts.&lt;/p&gt; &lt;p&gt;My talk almost didn’t happen. In the morning, I found that my laptop refused to connect to the projector. I only had a few hours left. Christopher Chedeau was kind enough to lend me his laptop, and I transferred my live demo setup to his computer (except for the Sublime license, as you may know if you watched it).&lt;/p&gt; &lt;p&gt;At first, my demo didn’t run on Christopher’s laptop because we had different Node versions. The conference WiFi was so bad that downloading another Node version was a non-starter. Luckily, I found an npm command that rebuilds the binaries. It saved my demo. I gave my talk with his computer, and it &lt;a rel="nofollow noopener noreferrer" href="https://www.youtube.com/watch?v=xsSnOQynTHs"&gt;went well&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;I met many people in the audience who I already knew from Twitter. One of them was Jing Chen. I remembered her from our IRC chat on the React channel, and came to say hi. She asked whether FB recruiters contacted me before, and I said I couldn’t get a US visa. Jing asked whether I’m interested in working at the London office, and I had no idea there even &lt;em&gt;was&lt;/em&gt; a London office! I called my wife and asked if she’s up for moving to London. I thought she’d hate the idea, but she immediately said yes. So I said yes to an interview.&lt;/p&gt; &lt;p&gt;There were four people from FB at the conference, so Jing arranged a full interview right at the conference hotel. It was a regular interview process, except it was in Paris and everyone was sweaty because it was so hot outside. &lt;/p&gt; &lt;p&gt;Everything happened so spontaneously that I neither had time to prepare, nor to get nervous. At one point I freaked out and panicked because I couldn’t write three lines of code that swap two items in an array. I asked Jing to look away for a few seconds. She said “I know you can swap two items”, and that gave me the confidence to finish the answer and make it through the interview. I probably didn’t pass with flying colors, but I got the offer.&lt;/p&gt; &lt;p&gt;My talk got really popular. Andrew Clark has already deprecated Flummox — the most popular Flux library — in favor of Redux, which he co-wrote with me. People started putting Redux in production. New learners were confused by the README, which was written for early adopters who had all the existing context. I didn’t have a job, and it would take me several more months to get a UK visa.&lt;/p&gt; &lt;p&gt;I started a Patreon to sustain my projects for a few months — and specifically to write Redux documentation, create small example apps, and record some free videos about it. I raised about $5k/month on Patreon which was more than any salary I made by that point in my life. Folks from Egghead sent me some mic gear, and I recorded my “Getting Started with Redux” course. I can’t watch it without cringing today, but it has been very popular and made me good money (around $3k/month in royalties) for quite a while — even though it was free.&lt;/p&gt; &lt;p&gt;FB took care of handling most of the immigration process. My wife and I only had to fill some papers, and I had to take an English exam and do some health checks. FB did most of the work to relocate us, including moving our cat from Russia to UK (which cost around $5k). I was hired at engineering level 4, with initial base salary of $100k/year and an initial restricted stock unit grant of $125k vesting over four years. I also had a signing bonus of $18k which helped a lot as we were settling in. (By the way, tech salaries are lower in UK than in US.)&lt;/p&gt; &lt;p&gt;We arrived to London at the end of November 2015. We’ve never been to London before. We took a black cab from the airport. We couldn’t figure out how to turn off the heating in the cab for ten minutes so we got very sweaty and couldn’t see anything through the window. When we turned off the fan and the window cleared up, our eyes were wide like saucers. London was beautiful.&lt;/p&gt; &lt;p&gt;The next day, Roman Mazurenko got hit to death by a careless driver. He just got his US visa approved, and he came to Moscow to pick up his documents. He once told me that there’s something devilish about Moscow. It doesn’t just let you go. I would not see my friend again. Not in 2015, not ever.&lt;/p&gt; &lt;p&gt;Roman has had a sort of a &lt;a rel="nofollow noopener noreferrer" href="https://romanmazurenko.com/"&gt;digital&lt;/a&gt; &lt;a rel="nofollow noopener noreferrer" href="https://www.theverge.com/a/luka-artificial-intelligence-memorial-roman-mazurenko-bot"&gt;afterlife&lt;/a&gt;, courtesy of his friends. I know for a fact he would’ve loved the irony of having a two point five star &lt;a rel="nofollow noopener noreferrer" href="https://apps.apple.com/us/app/roman-mazurenko/id958946383"&gt;App Store rating&lt;/a&gt;.&lt;/p&gt; &lt;h2 id="2016"&gt;&lt;a aria-hidden="" href="#2016"&gt;&lt;/a&gt;2016&lt;/h2&gt; &lt;p&gt;New job. New city. New country. Different language. Unfamiliar accent. Big company. Orientation. Meeting rooms. Projects. Teams. Documents. Forms. Shit. Fuck. Fuck. Fuckety Fuck, Shit, Oh Dear, Blimey!&lt;/p&gt; &lt;p&gt;I barely remember the first few months. I was in a constant state of stress from trying to understand what people are saying without subtitles. What the hell is my manager telling me? Is it rude to ask to repeat again? Spell it for me?&lt;/p&gt; &lt;p&gt;What, I need to call a lady in Scotland to get a national insurance number &lt;em&gt;by phone&lt;/em&gt;? I don’t get a word she’s saying. What even &lt;em&gt;is&lt;/em&gt; the national insurance? Why do I have a “zero” tax code and why is my salary less than I expected? Wait, people &lt;em&gt;actually pay taxes&lt;/em&gt; here? What do I do when I’m sick? What’s NHS?&lt;/p&gt; &lt;p&gt;During my first trip to US in 2016 (part of onboarding), I forgot to eat the whole day, drank a lot of coffee, and had a full-fledged panic attack trying to explain how hot reloading works to a colleague. We called an ambulance, and I got a $800 bill (thankfully, paid by FB — or at least I don’t recall paying it myself).&lt;/p&gt; &lt;p&gt;Relocation was nerve-wracking even though the company handled most of the difficulties. I thought I did everything in the onboarding instructions, but I forgot to register with the police. (I confused this with registering at the post office, which we also had to do.) I only found out that we screwed up months later, and we were told it might affect our visas. Luckily, it didn’t so far.&lt;/p&gt; &lt;p&gt;Originally, I was supposed to join the React Native team in London. Usually, we hire people to go through Bootcamp and pick a team, but I didn’t have that freedom. I was preallocated. However, I wasn’t very excited about React Native in particular. I talked to Tom Occhino (he managed the React team at that time), and he suggested that I can join the &lt;a rel="nofollow noopener noreferrer" href="https://reactjs.org/community/team.html"&gt;React Core&lt;/a&gt; team (based in US) as the only UK member. I was already used to remote work from open source, so I agreed.&lt;/p&gt; &lt;p&gt;In 2016, there was a React boom, but everybody made their own “boilerplate” with a bundler, watcher, compiler, and so on. React became synonymous with modular JavaScript, ES6, and all the tooling complexity. Christopher Chedeau suggested to prototype a command-line interface for getting started with React. We made the first version in a few weeks and released &lt;a rel="nofollow noopener noreferrer" href="https://reactjs.org/blog/2016/07/22/create-apps-with-no-configuration.html"&gt;Create React App&lt;/a&gt;.&lt;/p&gt; &lt;h2 id="2017"&gt;&lt;a aria-hidden="" href="#2017"&gt;&lt;/a&gt;2017&lt;/h2&gt; &lt;p&gt;Egghead courses continued to bring steady side income with royalties. I didn’t think twice before spending them on food delivery or nice clothes.&lt;/p&gt; &lt;p&gt;It’s only in 2017 that I came to realize that these royalties are taxable as foreign income, and that I owe Her Majesty something like $30k. Oops. Like an adult, I got an accountant. Fixing this mess depleted all my savings again.&lt;/p&gt; &lt;p&gt;At work, we spent most of 2017 rewriting React from scratch. You know the result of it as &lt;a rel="nofollow noopener noreferrer" href="https://reactjs.org/blog/2017/09/26/react-v16.0.html"&gt;React 16&lt;/a&gt;. Sophie tells the story of how we did it &lt;a rel="nofollow noopener noreferrer" href="https://engineering.fb.com/web/react-16-a-look-inside-an-api-compatible-rewrite-of-our-frontend-ui-library/"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Aside from taxes, there wasn’t a lot happening in my personal life. I was still settling in. I got less shy dealing with bureaucracies. I could make and take phone calls without freaking out. I watched movies without subtitles. I learned how to deal with NHS and with private insurance. I stopped doing side projects.&lt;/p&gt; &lt;h2 id="20182019"&gt;&lt;a aria-hidden="" href="#20182019"&gt;&lt;/a&gt;2018–2019&lt;/h2&gt; &lt;p&gt;The last two years have been a blur. I’m still too close to them to have a clear perspective on what was important.&lt;/p&gt; &lt;p&gt;Professionally, our projects are as demanding as ever. If you follow React, you know about &lt;a rel="nofollow noopener noreferrer" href="https://reactjs.org/blog/2018/03/01/sneak-peek-beyond-react-16.html"&gt;some things&lt;/a&gt; &lt;a rel="nofollow noopener noreferrer" href="https://reactjs.org/blog/2018/11/13/react-conf-recap.html"&gt;we have been working on&lt;/a&gt;. I’ve grown as an engineer, and still have much to learn. Our London team has grown — I’m not alone now.&lt;/p&gt; &lt;p&gt;People occasionally recognize me. This is humbling. Someone once recognized me in a sauna and started complaining about React. Please don’t be that person.&lt;/p&gt; &lt;p&gt;I got promoted. I started this blog as a side project. I have &lt;a rel="nofollow noopener noreferrer" href="https://justjavascript.com/"&gt;another side project&lt;/a&gt; coming, which I’ve been musing about for the better part of these two years. I met more people from the internet and put more faces to avatars. This is fun.&lt;/p&gt; &lt;p&gt;I always knew that I liked building UIs. I got hooked on Visual Basic. I spent this decade building UIs, and then building a way to build UIs. And then talking about it and explaining it. But I realize now that my drive to &lt;em&gt;explain&lt;/em&gt; things is just as important to me as my drive to build. Perhaps, even more important.&lt;/p&gt; &lt;p&gt;I look forward to doing more of that in the next decade.&lt;/p&gt; &lt;p&gt;Or, should I say, &lt;em&gt;this&lt;/em&gt; decade?&lt;/p&gt; &lt;p&gt;Welcome to the twenties.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;a href="https://overreacted.io/my-decade-in-review/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 24 Mar 2020 22:14:45 UT
      </pubDate>
      <guid>
        https://overreacted.io/my-decade-in-review/
      </guid>
    </item>
    <item>
      <title>
        Myths about /dev/urandom
      </title>
      <link>
        https://www.2uo.de/myths-about-urandom/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;article&gt; &lt;header&gt; &lt;h2&gt;Myths about /dev/urandom&lt;/h2&gt; &lt;/header&gt; &lt;p&gt; There are a few things about /dev/urandom and /dev/random that are repeated again and again. Still they are false. &lt;/p&gt; &lt;dl&gt; &lt;dt&gt; &lt;p&gt; &lt;strong&gt; /dev/urandom is insecure. Always use /dev/random for cryptographic purposes. &lt;/strong&gt; &lt;/p&gt; &lt;/dt&gt; &lt;dd&gt; &lt;p&gt; Fact: /dev/urandom is the preferred source of cryptographic randomness on UNIX-like systems. &lt;/p&gt; &lt;/dd&gt; &lt;dt&gt; &lt;p&gt; &lt;strong&gt; /dev/urandom is a pseudo random number generator, a &lt;abbr title="Pseudorandom number generator"&gt;PRNG&lt;/abbr&gt;, while /dev/random is a “true” random number generator. &lt;/strong&gt; &lt;/p&gt; &lt;/dt&gt; &lt;dd&gt; &lt;p&gt; &lt;a href="#structure"&gt;Fact:&lt;/a&gt; Both /dev/urandom and /dev/random are using &lt;em&gt;the exact same&lt;/em&gt; &lt;abbr title="Cryptographically secure pseudorandom number generator"&gt;CSPRNG&lt;/abbr&gt; (a cryptographically secure pseudorandom number generator). They only differ in very few ways that have nothing to do with “true” randomness. &lt;/p&gt; &lt;/dd&gt; &lt;dt&gt; &lt;p&gt; &lt;strong&gt; /dev/random is unambiguously the better choice for cryptography. Even if /dev/urandom were comparably secure, there's no reason to choose the latter. &lt;/strong&gt; &lt;/p&gt; &lt;/dt&gt; &lt;dd&gt; &lt;p&gt; &lt;a href="#blocking"&gt;Fact:&lt;/a&gt; /dev/random has a very nasty problem: it blocks. &lt;/p&gt; &lt;/dd&gt; &lt;dt&gt; &lt;p&gt; &lt;strong&gt; But that's good! /dev/random gives out exactly as much randomness as it has entropy in its pool. /dev/urandom will give you insecure random numbers, even though it has long run out of entropy. &lt;/strong&gt; &lt;/p&gt; &lt;/dt&gt; &lt;dd&gt; &lt;p&gt; &lt;a href="#low-entropy"&gt;Fact:&lt;/a&gt; No. Even disregarding issues like availability and subsequent manipulation by users, the issue of entropy “running low” is a straw man. About 256 bits of entropy are enough to get computationally secure numbers for a long, long time. &lt;/p&gt; &lt;p&gt; And the fun only starts here: how does /dev/random know &lt;a href="#estimate"&gt;how much entropy&lt;/a&gt; there is available to give out? Stay tuned! &lt;/p&gt; &lt;/dd&gt; &lt;dt&gt; &lt;p&gt; &lt;strong&gt; But cryptographers always talk about constant re-seeding. Doesn't that contradict your last point? &lt;/strong&gt; &lt;/p&gt; &lt;/dt&gt; &lt;dd&gt; &lt;p&gt; &lt;a href="#re-seed"&gt;Fact:&lt;/a&gt; You got me! Kind of. It is true, the random number generator is constantly re-seeded using whatever entropy the system can lay its hands on. But that has (partly) other reasons. &lt;/p&gt; &lt;p&gt; Look, I don't claim that injecting entropy is bad. It's good. I just claim that it's bad to block when the entropy estimate is low. &lt;/p&gt; &lt;/dd&gt; &lt;dt&gt; &lt;p&gt; &lt;strong&gt; That's all good and nice, but even the man page for /dev/(u)random contradicts you! Does &lt;em&gt;anyone&lt;/em&gt; who knows about this stuff actually agree with you? &lt;/strong&gt; &lt;/p&gt; &lt;/dt&gt; &lt;dd&gt; &lt;p&gt; &lt;a href="#man-page"&gt;Fact:&lt;/a&gt; No, it really doesn't. It &lt;em&gt;seems&lt;/em&gt; to imply that /dev/urandom is insecure for cryptographic use, unless you really understand all that cryptographic jargon. &lt;/p&gt; &lt;p&gt; The man page does recommend the use of /dev/random in &lt;em&gt;some&lt;/em&gt; cases (it doesn't hurt, in my opinion, but is not strictly necessary), but it also recommends /dev/urandom as the device to use for “normal” cryptographic use. &lt;/p&gt; &lt;p&gt; And while appeal to authority is usually nothing to be proud of, in cryptographic issues you're generally right to be careful and try to get the opinion of a domain expert. &lt;/p&gt; &lt;p&gt; And yes, quite a few &lt;a href="#experts"&gt;experts&lt;/a&gt; share my view that /dev/urandom is the go-to solution for your random number needs in a cryptography context on UNIX-like systems. Obviously, their opinions influenced mine, not the other way around. &lt;/p&gt; &lt;/dd&gt; &lt;/dl&gt; &lt;p&gt; Hard to believe, right? I must certainly be wrong! Well, read on and let me try to convince you. &lt;/p&gt; &lt;p&gt; I tried to keep it out, but I fear there are two preliminaries to be taken care of, before we can really tackle all those points. &lt;/p&gt; &lt;p&gt; Namely, &lt;a href="#true-randomness"&gt;what is randomness&lt;/a&gt;, or better: what kind of randomness am I talking about here? &lt;/p&gt; &lt;p&gt; And, even more important, I'm really &lt;a href="#stupid"&gt;not being condescending&lt;/a&gt;. I have written this document to have a thing to point to, when this discussion comes up again. More than 140 characters. Without repeating myself again and again. Being able to hone the writing and the arguments itself, benefitting many discussions in many venues. &lt;/p&gt; &lt;p&gt; And I'm certainly willing to hear differing opinions. I'm just saying that it won't be enough to state that /dev/urandom is bad. You need to identify the points you're disagreeing with and engage them. &lt;/p&gt; &lt;h2 id="stupid"&gt;You're saying I'm stupid!&lt;/h2&gt; &lt;p&gt; Emphatically &lt;em&gt;no!&lt;/em&gt; &lt;/p&gt; &lt;p&gt; Actually, I used to believe that /dev/urandom was insecure myself, a few years ago. And it's something you and I almost had to believe, because all those highly respected people on Usenet, in web forums and today on Twitter told us. Even the &lt;a href="#man-page"&gt;man page&lt;/a&gt; seems to say so. Who were we to dismiss their convincing argument about “entropy running low”? &lt;/p&gt; &lt;p&gt; This misconception isn't so rampant because people are stupid, it is because with a little knowledge about cryptography (namely some vague idea what entropy is) it's very easy to be convinced of it. Intuition almost forces us there. Unfortunately, intuition is often wrong in cryptography. So it is here. &lt;/p&gt; &lt;h2 id="true-randomness"&gt;True randomness&lt;/h2&gt; &lt;p&gt; What does it mean for random numbers to be “truly random”? &lt;/p&gt; &lt;p&gt; I don't want to dive into that issue too deep, because it quickly gets philosophical. Discussions have been known to unravel quickly, because everyone can wax about their favorite model of randomness, without paying attention to anyone else. Or even making himself understood. &lt;/p&gt; &lt;p&gt; I believe that the “gold standard” for “true randomness” are quantum effects. Observe a photon pass through a semi-transparent mirror. Or not. Observe some radioactive material emit alpha particles. It's the best idea we have when it comes to randomness in the world. Other people might reasonably believe that those effects aren't truly random. Or even that there is no randomness in the world at all. Let a million flowers bloom. &lt;/p&gt; &lt;p&gt; Cryptographers often circumvent this philosophical debate by disregarding what it means for randomness to be “true”. They care about &lt;em&gt;unpredictability&lt;/em&gt;. As long as &lt;em&gt;nobody&lt;/em&gt; can get &lt;em&gt;any&lt;/em&gt; information about the next random number, we're fine. And when you're talking about random numbers as a prerequisite in using cryptography, that's what you should aim for, in my opinion. &lt;/p&gt; &lt;p&gt; Anyway, I don't care much about those “philosophically secure” random numbers, as I like to think of your “true” random numbers. &lt;/p&gt; &lt;h2 id="computationally-secure"&gt;Two kinds of security, one that matters&lt;/h2&gt; &lt;p&gt; But let's assume you've obtained those “true” random numbers. What are you going to do with them? &lt;/p&gt; &lt;p&gt; You print them out, frame them and hang them on your living-room wall, to revel in the beauty of a quantum universe? That's great, and I certainly understand. &lt;/p&gt; &lt;p&gt; Wait, what? You're &lt;em&gt;using&lt;/em&gt; them? For cryptographic purposes? Well, that spoils everything, because now things get a bit ugly. &lt;/p&gt; &lt;p&gt; You see, your truly-random, quantum effect blessed random numbers are put into some less respectable, real-world tarnished algorithms. &lt;/p&gt; &lt;p&gt; Because almost all of the cryptographic algorithms we use do not hold up to &lt;strong&gt;information-theoretic security&lt;/strong&gt;. They can “only” offer &lt;strong&gt;computational security&lt;/strong&gt;. The two exceptions that come to my mind are Shamir's Secret Sharing and the One-time pad. And while the first one may be a valid counterpoint (if you actually intend to use it), the latter is utterly impractical. &lt;/p&gt; &lt;p&gt; But all those algorithms you know about, &lt;abbr&gt;AES&lt;/abbr&gt;, &lt;abbr&gt;RSA&lt;/abbr&gt;, Diffie-Hellman, Elliptic curves, and all those crypto packages you're using, OpenSSL, GnuTLS, Keyczar, your operating system's crypto API, these are only computationally secure. &lt;/p&gt; &lt;p&gt; What's the difference? While information-theoretically secure algorithms are secure, &lt;em&gt;period&lt;/em&gt;, those other algorithms cannot guarantee security against an adversary with unlimited computational power who's trying all possibilities for keys. We still use them because it would take all the computers in the world taken together longer than the universe has existed, so far. That's the level of “insecurity” we're talking about here. &lt;/p&gt; &lt;p&gt; Unless some clever guy breaks the algorithm itself, using much less computational power. Even computational power achievable today. That's the big prize every cryptanalyst dreams about: breaking &lt;abbr&gt;AES&lt;/abbr&gt; itself, breaking &lt;abbr&gt;RSA&lt;/abbr&gt; itself and so on. &lt;/p&gt; &lt;p&gt; So now we're at the point where you don't trust the inner building blocks of the random number generator, insisting on “true randomness” instead of “pseudo randomness”. But then you're using those “true” random numbers in algorithms that you so despise that you didn't want them near your random number generator in the first place! &lt;/p&gt; &lt;p&gt; Truth is, when state-of-the-art hash algorithms are broken, or when state-of-the-art block ciphers are broken, it doesn't matter that you get “philosophically insecure” random numbers because of them. You've got nothing left to securely use them for anyway. &lt;/p&gt; &lt;p&gt; So just use those computationally-secure random numbers for your computationally-secure algorithms. In other words: use /dev/urandom. &lt;/p&gt; &lt;h2 id="structure"&gt;Structure of Linux's random number generator&lt;/h2&gt; &lt;h3 id="incorrect-structure"&gt;An incorrect view&lt;/h3&gt; &lt;p&gt; Chances are, your idea of the kernel's random number generator is something similar to this: &lt;/p&gt; &lt;figure&gt; &lt;img alt="image: mythical structure of the kernel's random number generator" src="https://www.2uo.de/myths-about-urandom/structure-no-73d42e4b.png"&gt; &lt;figcaption&gt; Mythical structure of the kernel's random number generator &lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt; “True randomness”, albeit possibly skewed and biased, enters the system and its entropy is precisely counted and immediately added to an internal entropy counter. After de-biasing and whitening it's entering the kernel's entropy pool, where both /dev/random and /dev/urandom get their random numbers from. &lt;/p&gt; &lt;p&gt; The “true” random number generator, /dev/random, takes those random numbers straight out of the pool, if the entropy count is sufficient for the number of requested numbers, decreasing the entropy counter, of course. If not, it blocks until new entropy has entered the system. &lt;/p&gt; &lt;p&gt; The important thing in this narrative is that /dev/random basically yields the numbers that have been input by those randomness sources outside, after only the necessary whitening. Nothing more, just pure randomness. &lt;/p&gt; &lt;p&gt; /dev/urandom, so the story goes, is doing the same thing. Except when there isn't sufficient entropy in the system. In contrast to /dev/random, it does not block, but gets “low quality random” numbers from a pseudorandom number generator (conceded, a cryptographically secure one) that is running alongside the rest of the random number machinery. This &lt;abbr&gt;CSPRNG&lt;/abbr&gt; is just seeded once (or maybe every now and then, it doesn't matter) with “true randomness” from the randomness pool, but you can't really trust it. &lt;/p&gt; &lt;p&gt; In this view, that seems to be in a lot of people's minds when they're talking about random numbers on Linux, avoiding /dev/urandom is plausible. &lt;/p&gt; &lt;p&gt; Because either there is enough entropy left, then you get the same you'd have gotten from /dev/random. Or there isn't, then you get those low-quality random numbers from a &lt;abbr&gt;CSPRNG&lt;/abbr&gt; that almost never saw high-entropy input. &lt;/p&gt; &lt;p&gt; Devilish, right? Unfortunately, also utterly wrong. In reality, the internal structure of the random number generator looks like this. &lt;/p&gt; &lt;h3 id="correct-structure"&gt;A better simplification&lt;/h3&gt; &lt;h4 id="before-linux-4.8"&gt;Before Linux 4.8&lt;/h4&gt; &lt;figure&gt; &lt;img alt="image: actual structure of the kernel's random number generator before Linux 4.8" src="https://www.2uo.de/myths-about-urandom/structure-yes-c3cb7536.png"&gt; &lt;figcaption&gt; Actual structure of the kernel's random number generator before Linux 4.8 &lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt; See the big difference? The &lt;abbr&gt;CSPRNG&lt;/abbr&gt; is not running alongside the random number generator, filling in for those times when /dev/urandom wants to output something, but has nothing good to output. The &lt;abbr&gt;CSPRNG&lt;/abbr&gt; is an integral part of the random number generation process. There is no /dev/random handing out “good and pure” random numbers straight from the whitener. Every randomness source's input is thoroughly mixed and hashed inside the &lt;abbr&gt;CSPRNG&lt;/abbr&gt;, before it emerges as random numbers, either via /dev/urandom or /dev/random. &lt;/p&gt; &lt;p id="estimate"&gt; Another important difference is that there is no entropy &lt;em&gt;counting&lt;/em&gt; going on here, but &lt;em&gt;estimation&lt;/em&gt;. The amount of entropy some source is giving you isn't something obvious that you just get, along with the data. It has to be estimated. Please note that when your estimate is too optimistic, the dearly held property of /dev/random, that it's only giving out as many random numbers as available entropy allows, is gone. Unfortunately, it's hard to estimate the amount of entropy. &lt;/p&gt; &lt;p&gt; The Linux kernel uses only the arrival times of events to estimate their entropy. It does that by interpolating polynomials of those arrival times, to calculate “how surprising” the actual arrival time was, according to the model. Whether this polynomial interpolation model is the best way to estimate entropy is an interesting question. There is also the problem that internal hardware restrictions might influence those arrival times. The sampling rates of all kinds of hardware components may also play a role, because they directly influence the values and the granularity of those event arrival times. &lt;/p&gt; &lt;p&gt; In the end, to the best of our knowledge, the kernel's entropy estimate is pretty good. Which means it's conservative. People argue about how good it really is, but that issue is far above my head. Still, if you insist on never handing out random numbers that are not “backed” by sufficient entropy, you might be nervous here. I'm sleeping sound because I don't care about the entropy estimate. &lt;/p&gt; &lt;p&gt; So to make one thing crystal clear: both /dev/random and /dev/urandom are fed by &lt;em&gt;the same&lt;/em&gt; &lt;abbr&gt;CSPRNG&lt;/abbr&gt;. Only the behavior when their respective pool runs out of entropy, according to some estimate, differs: /dev/random blocks, while /dev/urandom does not. &lt;/p&gt; &lt;h4 id="from-linux-4.8"&gt;From Linux 4.8 onward&lt;/h4&gt; &lt;p&gt; In Linux 4.8 the equivalency between /dev/urandom and /dev/random was given up. Now /dev/urandom output does not come from an entropy pool, but directly from a &lt;abbr&gt;CSPRNG&lt;/abbr&gt;. &lt;/p&gt; &lt;figure&gt; &lt;img alt="image: actual structure of the kernel's random number generator from Linux 4.8 onward" src="https://www.2uo.de/myths-about-urandom/structure-new-728f5983.png"&gt; &lt;figcaption&gt; Actual structure of the kernel's random number generator from Linux 4.8 onward &lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt; &lt;a href="#csprng"&gt;We will see shortly&lt;/a&gt; why that is not a security problem. &lt;/p&gt; &lt;h2&gt;What's wrong with blocking?&lt;/h2&gt; &lt;p&gt; Have you ever waited for /dev/random to give you more random numbers? Generating a PGP key inside a virtual machine maybe? Connecting to a web server that's waiting for more random numbers to create an ephemeral session key? &lt;/p&gt; &lt;p&gt; That's the problem. It inherently runs counter to availability. So your system is not working. It's not doing what you built it to do. Obviously, that's bad. You wouldn't have built it if you didn't need it. &lt;/p&gt; &lt;p&gt; But the problem runs even deeper: people don't like to be stopped in their ways. They will devise workarounds, concoct bizarre machinations to just get it running. People who don't know anything about cryptography. Normal people. &lt;/p&gt; &lt;p&gt; Why not patching out the call to &lt;code&gt;random()&lt;/code&gt;? Why not having some guy in a web forum tell you how to use some strange ioctl to increase the entropy counter? Why not switch off &lt;abbr title="Secure sockets layer"&gt;SSL&lt;/abbr&gt; altogether? &lt;/p&gt; &lt;p&gt; In the end you just educate your users to do foolish things that compromise your system's security without you ever knowing about it. &lt;/p&gt; &lt;p&gt; It's easy to disregard availability, usability or other nice properties. Security trumps everything, right? So better be inconvenient, unavailable or unusable than feign security. &lt;/p&gt; &lt;p&gt; But that's a false dichotomy. Blocking is not necessary for security. As we &lt;a href="#correct-structure"&gt;saw&lt;/a&gt;, /dev/urandom gives you the same kind of random numbers as /dev/random, straight out of a &lt;abbr&gt;CSPRNG&lt;/abbr&gt;. Use it! &lt;/p&gt; &lt;h2 id="csprng"&gt;The &lt;abbr&gt;CSPRNG&lt;/abbr&gt;s are alright&lt;/h2&gt; &lt;p&gt; But now everything sounds really bleak. If even the high-quality random numbers from /dev/random are coming out of a &lt;abbr&gt;CSPRNG&lt;/abbr&gt;, how can we use them for high-security purposes? &lt;/p&gt; &lt;p&gt; It turns out, that “looking random” is &lt;em&gt;the&lt;/em&gt; basic requirement for a lot of our cryptographic building blocks. If you take the output of a cryptographic hash, it has to be indistinguishable from a random string so that cryptographers will accept it. If you take a block cipher, its output (without knowing the key) must also be indistinguishable from random data. &lt;/p&gt; &lt;p&gt; If anyone could gain an advantage over brute force breaking of cryptographic building blocks, using some perceived weakness of those &lt;abbr&gt;CSPRNG&lt;/abbr&gt;s over “true” randomness, then it's the same old story: you don't have anything left. Block ciphers, hashes, everything is based on the same mathematical fundament as &lt;abbr&gt;CSPRNG&lt;/abbr&gt;s. So don't be afraid. &lt;/p&gt; &lt;h2 id="low-entropy"&gt;What about entropy running low?&lt;/h2&gt; &lt;p&gt; It doesn't matter. &lt;/p&gt; &lt;p&gt; The underlying cryptographic building blocks are designed such that an attacker cannot predict the outcome, as long as there was enough randomness (a.k.a. entropy) &lt;em&gt;in the beginning&lt;/em&gt;. A usual lower limit for “enough” may be 256 bits. No more. &lt;/p&gt; &lt;p&gt; Considering that we were pretty hand-wavey about the term “entropy” in the first place, it feels right. As we saw, the kernel's random number generator cannot even precisely know the amount of entropy entering the system. Only an estimate. And whether the model that's the basis for the estimate is good enough is pretty unclear, too. &lt;/p&gt; &lt;h2 id="re-seed"&gt;Re-seeding&lt;/h2&gt; &lt;p&gt; But if entropy is so unimportant, why is fresh entropy constantly being injected into the random number generator? &lt;/p&gt; &lt;p&gt; First, it cannot hurt. If you've got more randomness just lying around, by all means use it! &lt;/p&gt; &lt;p&gt; There is another reason why re-seeding the random number generator every now and then is important: &lt;/p&gt; &lt;p&gt; Imagine an attacker knows everything about your random number generator's internal state. That's the most severe security compromise you can imagine, the attacker has full access to the system. &lt;/p&gt; &lt;p&gt; You've totally lost now, because the attacker can compute all future outputs from this point on. &lt;/p&gt; &lt;p&gt; But over time, with more and more fresh entropy being mixed into it, the internal state gets more and more random again. So that such a random number generator's design is kind of self-healing. &lt;/p&gt; &lt;p&gt; But this is injecting entropy into the generator's internal state, it has nothing to do with blocking its output. &lt;/p&gt; &lt;h2 id="man-page"&gt;The random and urandom man page&lt;/h2&gt; &lt;p&gt; The man page for /dev/random and /dev/urandom is pretty effective when it comes to instilling fear into the gullible programmer's mind: &lt;/p&gt; &lt;blockquote&gt; A read from the /dev/urandom device will not block waiting for more entropy. As a result, if there is not sufficient entropy in the entropy pool, the returned values are theoretically vulnerable to a cryptographic attack on the algorithms used by the driver. Knowledge of how to do this is not available in the current unclassified literature, but it is theoretically possible that such an attack may exist. If this is a concern in your application, use /dev/random instead. &lt;/blockquote&gt; &lt;p&gt; Such an attack is not known in “unclassified literature”, but the NSA certainly has one in store, right? And if you're really concerned about this (you should!), please use /dev/random, and all your problems are solved. &lt;/p&gt; &lt;p&gt; The truth is, while there may be such an attack available to secret services, evil hackers or the Bogeyman, it's just not rational to just take it as a given. &lt;/p&gt; &lt;p&gt; And even if you need that peace of mind, let me tell you a secret: no practical attacks on &lt;abbr&gt;AES&lt;/abbr&gt;, &lt;abbr&gt;SHA-3&lt;/abbr&gt; or other solid ciphers and hashes are known in the “unclassified” literature, either. Are you going to stop using those, as well? Of course not! &lt;/p&gt; &lt;p&gt; Now the fun part: “use /dev/random instead”. While /dev/urandom does not block, its random number output comes from the very same &lt;abbr&gt;CSPRNG&lt;/abbr&gt; as /dev/random's. &lt;/p&gt; &lt;p&gt; &lt;em&gt;If&lt;/em&gt; you really need information-theoretically secure random numbers (you don't!), and that's about the only reason why the entropy of the &lt;abbr&gt;CSPRNG&lt;/abbr&gt;'s input matters, you can't use /dev/random, either! &lt;/p&gt; &lt;p&gt; The man page is silly, that's all. At least it tries to redeem itself with this: &lt;/p&gt; &lt;blockquote&gt; If you are unsure about whether you should use /dev/random or /dev/urandom, then probably you want to use the latter. As a general rule, /dev/urandom should be used for everything except long-lived &lt;abbr&gt;GPG&lt;/abbr&gt;/&lt;abbr&gt;SSL&lt;/abbr&gt;/&lt;abbr&gt;SSH&lt;/abbr&gt; keys. &lt;/blockquote&gt; &lt;p&gt; Fine. I think it's unnecessary, but if you want to use /dev/random for your “long-lived keys”, by all means, do so! You'll be waiting a few seconds typing stuff on your keyboard, that's no problem. &lt;/p&gt; &lt;p&gt; But please don't make connections to a mail server hang forever, just because you “wanted to be safe”. &lt;/p&gt; &lt;h2 id="experts"&gt;Orthodoxy&lt;/h2&gt; &lt;p&gt; The view espoused here is certainly a tiny minority's opinions on the Internet. But ask a real cryptographer, you'll be hard pressed to find someone who sympathizes much with that blocking /dev/random. &lt;/p&gt; &lt;p&gt; Let's take &lt;a href="http://www.mail-archive.com/cryptography@randombit.net/msg04763.html"&gt;Daniel Bernstein&lt;/a&gt;, better known as djb: &lt;/p&gt; &lt;blockquote&gt; &lt;p&gt; Cryptographers are certainly not responsible for this superstitious nonsense. Think about this for a moment: whoever wrote the /dev/random manual page seems to simultaneously believe that &lt;/p&gt; &lt;p&gt; (1) we can't figure out how to deterministically expand one 256-bit /dev/random output into an endless stream of unpredictable keys (this is what we need from urandom), but &lt;/p&gt; &lt;p&gt; (2) we _can_ figure out how to use a single key to safely encrypt many messages (this is what we need from &lt;abbr&gt;SSL&lt;/abbr&gt;, &lt;abbr&gt;PGP&lt;/abbr&gt;, etc.). &lt;/p&gt; &lt;p&gt; For a cryptographer this doesn't even pass the laugh test. &lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt; Or &lt;a href="http://security.stackexchange.com/questions/3936/is-a-rand-from-dev-urandom-secure-for-a-login-key/3939#3939"&gt;Thomas Pornin&lt;/a&gt;, who is probably one of the most helpful persons I've ever encountered on the Stackexchange sites: &lt;/p&gt; &lt;blockquote&gt; &lt;p&gt; The short answer is yes. The long answer is also yes. /dev/urandom yields data which is indistinguishable from true randomness, given existing technology. Getting “better” randomness than what /dev/urandom provides is meaningless, unless you are using one of the few "information theoretic" cryptographic algorithm, which is not your case (you would know it). &lt;/p&gt; &lt;p&gt; The man page for urandom is somewhat misleading, arguably downright wrong, when it suggests that /dev/urandom may "run out of entropy" and /dev/random should be preferred; &lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt; Or maybe &lt;a href="http://sockpuppet.org/blog/2014/02/25/safely-generate-random-numbers/"&gt;Thomas Ptacek&lt;/a&gt;, who is not a real cryptographer in the sense of designing cryptographic algorithms or building cryptographic systems, but still the founder of a well-reputed security consultancy that's doing a lot of penetration testing and breaking bad cryptography: &lt;/p&gt; &lt;blockquote&gt; &lt;p&gt; Use urandom. Use urandom. Use urandom. Use urandom. Use urandom. Use urandom. &lt;/p&gt; &lt;/blockquote&gt; &lt;h2 id="problems"&gt;Not everything is perfect&lt;/h2&gt; &lt;p&gt; /dev/urandom isn't perfect. The problems are twofold: &lt;/p&gt; &lt;p&gt; On Linux, unlike FreeBSD, /dev/urandom never blocks. Remember that the whole security rested on some starting randomness, a seed? &lt;/p&gt; &lt;p&gt; Linux's /dev/urandom happily gives you not-so-random numbers before the kernel even had the chance to gather entropy. When is that? At system start, booting the computer. &lt;/p&gt; &lt;p&gt; FreeBSD does the right thing: they don't have the distinction between /dev/random and /dev/urandom, both are the same device. At startup /dev/random blocks once until enough starting entropy has been gathered. Then it won't block ever again. &lt;/p&gt; &lt;p&gt; On Linux it isn't too bad, because Linux distributions save some random numbers when booting up the system (but after they have gathered some entropy, since the startup script doesn't run immediately after switching on the machine) into a seed file that is read next time the machine is booting. So you carry over the randomness from the last running of the machine. &lt;/p&gt; &lt;p&gt; Obviously that isn't as good as if you let the shutdown scripts write out the seed, because in that case there would have been much more time to gather entropy. The advantage is obviously that this does not depend on a proper shutdown with execution of the shutdown scripts (in case the computer crashes, for example). &lt;/p&gt; &lt;p&gt; And it doesn't help you the very first time a machine is running, but the Linux distributions usually do the same saving into a seed file when running the installer. So that's mostly okay. &lt;/p&gt; &lt;p&gt; Virtual machines are the other problem. Because people like to clone them, or rewind them to a previously saved check point, this seed file doesn't help you. &lt;/p&gt; &lt;p&gt; But the solution still isn't using /dev/random everywhere, but properly seeding each and every virtual machine after cloning, restoring a checkpoint, whatever. &lt;/p&gt; &lt;h2&gt;tldr;&lt;/h2&gt; &lt;p&gt; &lt;strong&gt;Just use /dev/urandom!&lt;/strong&gt; &lt;/p&gt; &lt;/article&gt;&lt;/div&gt;&lt;a href="https://www.2uo.de/myths-about-urandom/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Wed, 25 Mar 2020 13:42:45 UT
      </pubDate>
      <guid>
        https://www.2uo.de/myths-about-urandom/
      </guid>
    </item>
    <item>
      <title>
        10 Most(ly dead) Influential Programming Languages • Hillel Wayne
      </title>
      <link>
        https://hillelwayne.com/post/influential-dead-languages/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;article lang="en"&gt; &lt;div&gt; &lt;p&gt;The other day I read &lt;a href="https://anarc.at/blog/2020-02-02-most-significant-programming-languages-history/"&gt;20 most significant programming languages in history&lt;/a&gt;, a “preposterous table I just made up.” He certainly got preposterous right: he lists Go as “most significant” but not ALGOL, Smalltalk, or ML. He also leaves off Pascal because it’s “mostly dead”. Preposterous! That defeats the whole point of what “significant in history” means.&lt;/p&gt; &lt;p&gt;So let’s talk about some “mostly dead” languages and why they matter so much.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Disclaimer:&lt;/strong&gt; Yeah not all of these are dead and not all of these are forgotten. Like most people have heard of Smalltalk, right? Also there’s probably like a billion mistakes in this, because when you’re doing a survey of 60 years of computing history you’re gonna get some things wrong. Feel free to yell at me if you see anything!&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Disclaimer 2:&lt;/strong&gt; Yeah I know some of these are “first to invent” and others are “first to popularize”. History is complicated!&lt;/p&gt; &lt;h3 id="detecting-influence"&gt;Detecting Influence&lt;/h3&gt; &lt;p&gt;Before we start, a quick primer on finding influence. Just knowing that X was the first language with feature Z doesn’t mean that X actually &lt;em&gt;influenced&lt;/em&gt; Z. While &lt;a href="https://core.ac.uk/download/pdf/82537271.pdf"&gt;Absys&lt;/a&gt; was arguably the first logic programming language, almost all of logic programming actually stems from Prolog, which was developed independently. Ultimately there’s only one way to know for certain that X influenced Y: citation. This means one of&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Y cites X in its reference manual&lt;/li&gt; &lt;li&gt;Y cites a paper that cites X&lt;/li&gt; &lt;li&gt;The author of Y says “we were influenced by X.”&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Citations are transitive. Sometimes the language manual for Q lists motivating document R, which cites paper S as an inspiration, which mentions it got the ideas from language T. Then we know that T influenced Q, even if the chain is several steps long. This means digging through many sources to find a signal. To speed this up we use heuristics to decide where to look.&lt;/p&gt; &lt;p&gt;One effective heuristic is programming language &lt;strong&gt;cognates&lt;/strong&gt;. It’s very rare for languages to independently come up with the same syntax. So if two languages share some syntax, one likely influenced the other. For example: even without reading design decisions by Matz, we know that Ruby was influenced by Smalltalk, as they both filter a list with a &lt;code&gt;select&lt;/code&gt; method. This isn’t conclusive evidence. Maybe Matz came up with it independently, or maybe Ruby and Smalltalk were both influenced by a common ancestor. But it gives us a place to start looking.&lt;/p&gt; &lt;h3 id="cobol"&gt;COBOL&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Background:&lt;/strong&gt; CODASYL, 1960. COBOL is shaped by the business/science split in computing. At that time high-level industry languages were either used for engineering computations or managing data. The engineers had all gotten behind FORTRAN while the business world was a mess of COMTRAN, FLOW-MATIC, and others, so the Department of Defense got a committee together to make a single universal business language. That’s COBOL.&lt;/p&gt; &lt;p&gt;COBOL was one of the four “mother” languages, along with ALGOL, FORTRAN, and LISP. While we consider it a punchline today, it was once the most popular language in the world. It still runs a lot of our legacy business systems.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Significance&lt;/strong&gt;: In terms of syntax and semantics we don’t see much of COBOL in modern computing. COBOL’s most important addition is the concept of record data. In FORTRAN and ALGOL, your only data structure was the static array. In COBOL, though, you could read in structured files with hierarchical data, and it would automatically destructure them into the representative variables. This was a precursor to modern day structs.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Cause of Death&lt;/strong&gt;: Two factors here. One: COBOL had no overlap with other PLT efforts. Very few people built on COBOL. This meant that second or third generation languages, which built on the lessons of their ancestors, had almost no COBOL DNA. This was less intrinsic problem of COBOL and more because of the academia’s disdain for its creation process. CODASYL was a business group and obviously wasn’t worth paying attention to.&lt;sup id="fnref:disdain"&gt;&lt;a href="#fn:disdain"&gt;1&lt;/a&gt;&lt;/sup&gt; COBOL was also enormously complex, even for today’s languages. This means that COBOL compilers lagged contemporaries on microcomputers and minicomputers, giving spaces for other languages to flourish and eventually outcompete it.&lt;/p&gt; &lt;h3 id="algol"&gt;ALGOL&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Background&lt;/strong&gt;: The ALGOL committee, 1960. ALGOL-58 came out two years before but was quickly superseded, so I’m wrapping them into each other. The committee wanted to make a good language for researching algorithms. In other words, ALGOL was a formalized “pseudocode”.&lt;/p&gt; &lt;p&gt;Of the four mother languages, ALGOL is the most “dead”; Everybody still knows about LISP,&lt;sup id="fnref:lisp"&gt;&lt;a href="#fn:lisp"&gt;2&lt;/a&gt;&lt;/sup&gt; COBOL still powers tons of legacy systems, and most scientific packages still have some FORTRAN. But I’ve met plenty of programmers who haven’t even heard of ALGOL. You’d think it’d be the least important of the mother languages, but it’s the opposite. Of the four, only LISP comes anywhere &lt;em&gt;close&lt;/em&gt; to the pervasive importance of ALGOL.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Significance&lt;/strong&gt;: Let’s see: lexical scoping, structured programming, nested functions, formal language specifications, call-by-name semantics, BNF grammars, block comments… every modern language today is deeply influenced by ALGOL.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Cause of Death&lt;/strong&gt;: ALGOL was a research language, not a commercial language. It was designed for studying algorithms. The spec didn’t define any I/O, which kinda made it impossible to use in practice. Sure, you could write a compiler extension, but then you might as well add other stuff too.&lt;/p&gt; &lt;p&gt;And that’s exactly what people did. In 1960 and 70 people made a huge number of ALGOL-likes by extending ALGOL with I/O and extra data structures. This includes JOVIAL, SIMULA, CLU, and CPL. Later languages were then based off these extensions, not ALGOL directly. We call C an “ALGOL-like”, but it’s actually a BCPL-like, which was a CPL-like, which was an ALGOL-like. ALGOL’s children buried it.&lt;/p&gt; &lt;p&gt;Eventually the ALGOL people tried to extend it into ALGOL-68, which radically departed from ALGOL-60 and hasn’t had close to the same influence. The ALGOL-60 lineage continues with Niklaus Wirth’s Pascal.&lt;/p&gt; &lt;h3 id="apl"&gt;APL&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Background&lt;/strong&gt;: Ken Iverson, 1962. Originally a hand-written notation for array math, IBM picked it up and used as an programming language. As a language, APL focused on array processing: being able to concisely manipulate large blocks of numbers.&lt;/p&gt; &lt;p&gt;If you’ve heard of APL before, you probably know it as “that weird symbol language”. One of the most notorious code snippets is this implementation of the Game of Life:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="apl"&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;life&lt;/span&gt;&lt;span&gt;←{&lt;/span&gt;&lt;span&gt;↑&lt;/span&gt;&lt;span&gt;1&lt;/span&gt; &lt;span&gt;⍵&lt;/span&gt;&lt;span&gt;∨&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;∧&lt;/span&gt;&lt;span&gt;3&lt;/span&gt; &lt;span&gt;4&lt;/span&gt;&lt;span&gt;=+&lt;/span&gt;&lt;span&gt;/&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;¯1&lt;/span&gt; &lt;span&gt;0&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;∘.&lt;/span&gt;&lt;span&gt;⊖&lt;/span&gt;&lt;span&gt;¯1&lt;/span&gt; &lt;span&gt;0&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;∘.&lt;/span&gt;&lt;span&gt;⌽⊂&lt;/span&gt;&lt;span&gt;⍵&lt;/span&gt;&lt;span&gt;}&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;You had to write it with a specialized keyboard, like this:&lt;/p&gt; &lt;figure&gt; &lt;img title="IBM APL Keyboard" src="https://hillelwayne.com/post/influential-dead-languages/IDSkeyboard.jpg"&gt; &lt;figcaption&gt;An APL keyboard &lt;a href="https://www.dyalog.com/50-years-of-apl/photo-gallery.htm"&gt;(source)&lt;/a&gt;&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;Nonetheless, APL got popular on mainframes for running with very low memory requirements.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Significance&lt;/strong&gt;: Array processing. At a time when adding two lists of numbers meant a map or a loop, APL introduced the idea of operating on the entire array &lt;em&gt;at once&lt;/em&gt;. For example:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="apl"&gt;&lt;span&gt;&lt;/span&gt; &lt;span&gt;1&lt;/span&gt; &lt;span&gt;+&lt;/span&gt; &lt;span&gt;1&lt;/span&gt; &lt;span&gt;2&lt;/span&gt; &lt;span&gt;3&lt;/span&gt; &lt;span&gt;4&lt;/span&gt; &lt;span&gt;2&lt;/span&gt; &lt;span&gt;3&lt;/span&gt; &lt;span&gt;4&lt;/span&gt; &lt;span&gt;5&lt;/span&gt; &lt;span&gt;1&lt;/span&gt; &lt;span&gt;2&lt;/span&gt; &lt;span&gt;3&lt;/span&gt; &lt;span&gt;4&lt;/span&gt; &lt;span&gt;+&lt;/span&gt; &lt;span&gt;1&lt;/span&gt; &lt;span&gt;2&lt;/span&gt; &lt;span&gt;3&lt;/span&gt; &lt;span&gt;4&lt;/span&gt; &lt;span&gt;2&lt;/span&gt; &lt;span&gt;4&lt;/span&gt; &lt;span&gt;6&lt;/span&gt; &lt;span&gt;8&lt;/span&gt; &lt;span&gt;2&lt;/span&gt; &lt;span&gt;4&lt;/span&gt; &lt;span&gt;⍴&lt;/span&gt; &lt;span&gt;⍳&lt;/span&gt;&lt;span&gt;8&lt;/span&gt; &lt;span&gt;1&lt;/span&gt; &lt;span&gt;2&lt;/span&gt; &lt;span&gt;3&lt;/span&gt; &lt;span&gt;4&lt;/span&gt; &lt;span&gt;5&lt;/span&gt; &lt;span&gt;6&lt;/span&gt; &lt;span&gt;7&lt;/span&gt; &lt;span&gt;8&lt;/span&gt; &lt;span&gt;1&lt;/span&gt; &lt;span&gt;2&lt;/span&gt; &lt;span&gt;3&lt;/span&gt; &lt;span&gt;4&lt;/span&gt; &lt;span&gt;+&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;&lt;span&gt;]&lt;/span&gt; &lt;span&gt;2&lt;/span&gt; &lt;span&gt;4&lt;/span&gt; &lt;span&gt;⍴&lt;/span&gt; &lt;span&gt;⍳&lt;/span&gt;&lt;span&gt;8&lt;/span&gt; &lt;span&gt;2&lt;/span&gt; &lt;span&gt;4&lt;/span&gt; &lt;span&gt;6&lt;/span&gt; &lt;span&gt;8&lt;/span&gt; &lt;span&gt;6&lt;/span&gt; &lt;span&gt;8&lt;/span&gt; &lt;span&gt;10&lt;/span&gt; &lt;span&gt;12&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;This was a &lt;em&gt;really big deal&lt;/em&gt; in scientific circles. So much applied math boils down to large-scale operations on large matrices. When you can just take the outer product with &lt;code&gt;∘.f&lt;/code&gt;, it’s really damn easy to take outer products!&lt;/p&gt; &lt;p&gt;Through this innovation APL lead to R, numpy, pandas, Matlab, etc. There’s also the direct descendants of APL: J, Dyalog, K, Q. They’ve been less successful but still see lots of use in the finance sector.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Cause of Death&lt;/strong&gt;: Well, the obvious problem is the keyboards. If you can’t write it in ASCII, you’re not going to write very much of it. Iverson fixed this with J, which uses digraphs instead of different symbols. Instead of &lt;code&gt;≠&lt;/code&gt;, you write &lt;code&gt;~:&lt;/code&gt;. This was in 1990, though, which is a bit late to popularize a radically different programming style.&lt;/p&gt; &lt;p&gt;The subtler problem is that APL and J only worked on homogeneous data. You can’t store both strings and numbers in the same data structure (unless you use boxes, which is a whole other can of worms) and working with strings is generally a nightmare. So no dataframes, which excludes a lot of modern data science.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Further Reading:&lt;/strong&gt; &lt;a href="http://www.eecg.toronto.edu/~jzhu/csc326/readings/iverson.pdf"&gt;Notation as a Tool of Thought&lt;/a&gt;&lt;/p&gt; &lt;h3 id="basic"&gt;BASIC&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Background&lt;/strong&gt;: John Kemeny, 1964. Originally a simplified FORTRAN-like, intended to help people outside engineering use computers.&lt;/p&gt; &lt;p&gt;BASIC really took off in the microcomputer era. The first microcomputers didn’t have enough memory to compile “real” programming languages, whereas you could cram a pared-down BASIC compiler into like 2 kilobytes. BASIC became a &lt;em&gt;lingua franca&lt;/em&gt; for early-stage programmers. If you were programming at home in the 1970’s, you were probably writing BASIC on a microcomputer.&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="basic"&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;10 &lt;/span&gt;&lt;span&gt;PRINT&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;"Hello, World!"&lt;/span&gt; &lt;span&gt;20 &lt;/span&gt;&lt;span&gt;END&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;&lt;strong&gt;Significance&lt;/strong&gt;: The biggest &lt;em&gt;technical&lt;/em&gt; impact is runtime interpretation. BASIC was the first language with a real-time interpreter (the &lt;a href="https://en.wikipedia.org/wiki/Dartmouth_Time_Sharing_System"&gt;Dartmouth Time Sharing System&lt;/a&gt;), beating APL by a year. And that APL system was only available to IBM customers, so really it was BASIC or nothing for a long time.&lt;sup id="fnref:joss"&gt;&lt;a href="#fn:joss"&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt; &lt;p&gt;BASIC had a bigger &lt;em&gt;social&lt;/em&gt; impact. It brought programming to households, kids especially. Many of the influential programmers in the 80’s and 90’s first learned how to program on BASIC. Many enterprise programs were also written in BASIC, which probably helped accelerate the decline of Cobol.&lt;/p&gt; &lt;p&gt;BASIC has one more neat trick up its sleeve: Office tooling! Microsoft eventually turned BASIC into Visual Basic, which they used as the Office macro language. This then spread to OpenOffice and LibreOffice, entrenching BASIC in that particular niche. More recently it’s lost ground to JavaScript and is now a legacy macro language.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Cause of Death&lt;/strong&gt;: People saw BASIC as a “lesser” language. You might use it if you were a kid or a small business owner, but &lt;em&gt;real&lt;/em&gt; programmers used a &lt;em&gt;real&lt;/em&gt; language. Once manufacturers could cheaply make microcomputers with more than 16k of RAM they started depreciating BASIC for languages like Pascal and C.&lt;/p&gt; &lt;p&gt;BASIC lived on for a while as a legacy kids teaching language, but seems to have died out of that niche, too.&lt;/p&gt; &lt;h3 id="pl-i"&gt;PL/I&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Background:&lt;/strong&gt; IBM, 1966. IBM’s business was split into two languages: FORTRAN for scientists and COMTRAN for business folk. Facing competition from COBOL and wanting to streamline their systems, they tried to make a language that was useful for both engineering and business purposes. This ended up looking like a sort of superset of the two languages, with a bunch of additional features stapled on top.&lt;sup id="fnref:pli"&gt;&lt;a href="#fn:pli"&gt;4&lt;/a&gt;&lt;/sup&gt; Now everybody could use the same language and IBM can make a lot more money! Yaaaaaaaay&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Significance:&lt;/strong&gt; The authors of ALGOL-68 mockingly called PL/I an obsolete language. But everything ALGOL-68 did, PL/I did earlier and better. While COBOL got structured data first, PL/I was the first language to implement them as a type. In COBOL, reading in a user with a name would give you two global variables, &lt;code&gt;user&lt;/code&gt; and &lt;code&gt;name&lt;/code&gt;. In PL/I, you’d get one variable with a field, &lt;code&gt;user.name&lt;/code&gt;. PL/I was also the first high-level language with pointers for direct memory manipulation, constants, and function overloading.&lt;sup id="fnref:overloading"&gt;&lt;a href="#fn:overloading"&gt;5&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt; &lt;p&gt;Many of these ideas entered mainstream programming via C, which was a mix of both BCPL and PL/I. C even uses PL/I’s comment syntax.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Cause of Death:&lt;/strong&gt; All the FORTRAN programmers thought it was too much like COBOL and all the COBOL programmers thought it was too much like FORTRAN. IBM had tried to take on two established languages with a much more complicated one. It didn’t help that they were the only group with the compiler, meaning everybody else was mistrustful of vendor lock-in. By the time IBM was able to make headway in both of these issues the wider computing world had already moved on to the microcomputer era, where PL/I was out competed by BASIC.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Further Reading:&lt;/strong&gt; &lt;a href="https://multicians.org/pl1.html"&gt;The Choice of PL/I&lt;/a&gt;&lt;/p&gt; &lt;h3 id="simula-67"&gt;SIMULA 67&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Background&lt;/strong&gt;: Ole Dahl and Kristen Nygaard, 1967. They extended ALGOL for doing simulations. First they made SIMULA I, which had dedicated simulation and “activity” syntax. SIMULA I saw some early use, but the two were dissatisfied with how “specialized” the language felt and how much duplicate code they had in their simulations. They wanted to make a more general framework for representing things in general, not simulations only.&lt;/p&gt; &lt;p&gt;Their idea was to allow users to define new types called “classes” with polymorphic function resolution. Then users could build the simulation features as a special case of the object system, making it easy to customize how it all worked to their particular needs.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Significance&lt;/strong&gt;: While SIMULA wasn’t the first “true” OOP language, it was the first language with proper objects and laid much of the groundwork that others would build on. This includes the class/object split, subclassing, virtual methods, and protected attributes. It inspired almost all of the academic research into objects after 1967. Both CLU and ML cited SIMULA as a major source of inspiration. Bjarne Stroustroup did his PhD on SIMULA, eventually incorporating a lot of its ideas into C++.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Cause of Death&lt;/strong&gt;: In that same PhD Stroustroup claimed that SIMULA was waaaaaay too slow to use at scale. “Good luck getting anything done if you aren’t on a mainframe” slow. It’s worth noting that Smalltalk-80, which took the same ideas even further, had an extra 13 years of Moore’s law behind it. And even Smalltalk was often mocked as too slow. Everybody went and implemented the ideas in SIMULA that they could integrate into faster, simpler languages.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Further Reading&lt;/strong&gt;: &lt;a href="https://www.idi.ntnu.no/grupper/su/publ/simula/holmevik-simula-ieeeannals94.pdf"&gt;Compiling SIMULA: a historical study of technological genesis&lt;/a&gt;, &lt;a href="http://campus.hesge.ch/daehne/2004-2005/langages/simula.htm"&gt;The History of Simula&lt;/a&gt;&lt;/p&gt; &lt;h3 id="pascal"&gt;Pascal&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Background&lt;/strong&gt;: Niklaus Wirth, 1970. Made to capture the essence of ALGOL-60 after ALGOL-68 got waaaaaay too complicated for Wirth’s liking. It first got big as the “introduction to CS” language, and by the early 80’s was the second-most popular language on the Usenet job boards. Wirth considers the whole family- Pascal, Modula, and Oberon- as a single unified language concept.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Significance&lt;/strong&gt;: Pascal didn’t introduce any completely new ideas. It was an intentionally conservative language that tried to pick the best parts of the past decade and provide them in a unified package. Pascal brought ALGOL syntax outside academia, so much so that ALGOL’s assignment syntax, &lt;code&gt;:=&lt;/code&gt;, got called “Pascal style” instead. From this point on most language features that look like ALGOL were more likely inspired by Pascal than directly by ALGOL itself.&lt;/p&gt; &lt;p&gt;While Pascal wasn’t very innovative, variants of it were. Wirth also pioneered the idea of “stepwise refinement” as a means of writing rigorous software. This eventually lead to the Modulas, which popularized first class software modules, and Euclid, the first formal verification language to see production use.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Cause of Death&lt;/strong&gt;: I’m calling a mulligan on this one. Unlike most of the other ones on this list, Pascal didn’t have major structural barriers or a sharp competitor. Sure, it competed with C, but it was still doing fine for a very long time. People usually attribute the &lt;a href="https://www.lysator.liu.se/c/bwk-on-pascal.html"&gt;Why Pascal is not my favorite language&lt;/a&gt; essay, but that’s too neat of an answer and history is a lot messier. Also, Delphi is still pretty high-ranked in the TIOBE and PYPA measurements, so it’s not exactly &lt;em&gt;dead&lt;/em&gt; in the same way SIMULA is. An accurate analysis of the fall of Pascal would be longer than the rest of this essay.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Further Reading:&lt;/strong&gt; &lt;a href="http://web.eah-jena.de/~kleine/history/languages/Wirth-PascalRevisedReport.pdf"&gt;The Programming Language Pascal&lt;/a&gt;, &lt;a href="https://www.swissdelphicenter.ch/en/niklauswirth.php"&gt;Pascal and its Successors&lt;/a&gt;&lt;/p&gt; &lt;h3 id="clu"&gt;CLU&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Background&lt;/strong&gt;: Barbara Liskov, 1975. Liskov wanted to mess around with abstract data types. That’s it. That’s the whole reason for CLU.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Significance&lt;/strong&gt;: CLU might be the most influential language that nobody’s ever heard of. Iterators? CLU. Abstract data types? CLU. Generics? CLU. Checked exceptions? CLU.&lt;/p&gt; &lt;p&gt;We didn’t adopt the same terminology, so it’s not 100% obvious it all comes from CLU, but still. Every language spec for the next decade would namedrop CLU. CLU did a lot.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Cause of Death:&lt;/strong&gt; CLU was a showcase language; Liskov wanted to get people to adopt her &lt;em&gt;ideas&lt;/em&gt;, not her specific &lt;em&gt;language&lt;/em&gt;. And they did: almost every language today owes &lt;em&gt;something&lt;/em&gt; to CLU. As soon as she completed CLU she moved on to &lt;strong&gt;Argus&lt;/strong&gt;, which was supposed to showcase her ideas on concurrency. That hasn’t seen nearly the same adoption, and there’s still a lot of stuff in it left to mine.&lt;/p&gt; &lt;p&gt;Further reading: &lt;a href="https://web.archive.org/web/20030917041834/http://www.lcs.mit.edu/publications/pubs/pdf/MIT-LCS-TR-561.pdf"&gt;A History of CLU&lt;/a&gt;&lt;/p&gt; &lt;h3 id="ml"&gt;ML&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Background&lt;/strong&gt;: Robin Milner, 1976.&lt;sup id="fnref:ml"&gt;&lt;a href="#fn:ml"&gt;6&lt;/a&gt;&lt;/sup&gt; Milner was building the LCF Prover, one of the first &lt;strong&gt;proof assistants.&lt;/strong&gt; If you wrote a proof in the right format, LCF could check to see if it was correct or not. To assist in writing the proofs, Milner created a &lt;em&gt;metalanguage&lt;/em&gt; based on sound mathematical formalisms, which at the time meant strict static types and higher-order functions. Eventually ML was standardized as Standard ML.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Significance&lt;/strong&gt;: ML is arguably the oldest “algebraic programming language”. There’s a lot of stuff we attribute to ML: algebraic data types, modules, typed functional programming. Surprisingly, it was &lt;em&gt;not&lt;/em&gt; the first for a lot of these! The first ML was just designed to work with LCF and wasn’t a general purpose language, so lacked a lot of these features. As people started making it more general they pulled ideas from other research languages and incorporated them into ML. One &lt;em&gt;very&lt;/em&gt; important idea did start in ML, though: type inference. ML was the first statically-typed language where you didn’t &lt;em&gt;have&lt;/em&gt; to write the types out, as the compiler would figure out the types for you. This paved the way for typed FP to escape academia and enter production use.&lt;/p&gt; &lt;p&gt;ML also greatly influenced modern theorem provers. The “program” languages for Isabelle, CVC3, and Coq are ML-based. And a &lt;em&gt;lot&lt;/em&gt; of type theory was based on ML, though in more recent years the Haskell branch of FP has become more popular.&lt;sup id="fnref:haskell"&gt;&lt;a href="#fn:haskell"&gt;7&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Cause of Death&lt;/strong&gt;: ML had a lot of interesting features, but people paid attention to it for the type inference. At the time ML was still a special purpose language for the theorem provers. SML came out the same year as Haskell, which was a much “purer” example of a typed FP language.&lt;sup id="fnref:ml"&gt;&lt;a href="#fn:ml"&gt;6&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt; &lt;h3 id="smalltalk"&gt;Smalltalk&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Background&lt;/strong&gt;: Alan Kay, 1972, 1976, and 1980. It’s sort of a moving target. Smalltalk-72 was the first, Smalltalk-76 introduced the idea of “object-oriented programming” to the wider world, and Smalltalk-80 was the one that saw widespread adoption.&lt;/p&gt; &lt;p&gt;Smalltalk wasn’t the first language with objects but it was the first “object-oriented” one. The difference was that Simula &lt;em&gt;had&lt;/em&gt; objects in addition to primitives like numbers and booleans, while in Smalltalk, booleans &lt;em&gt;were also&lt;/em&gt; objects. I wrote a bit about this &lt;a href="https://www.hillelwayne.com/post/alan-kay/"&gt;here&lt;/a&gt; if you want to learn more.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Significance&lt;/strong&gt;: We sometimes think that Smalltalk is “true” OOP and things like Java and Python aren’t “real” OOP, but that’s not true. OOP is a giant mess of many different influences, just like every other paradigm. But it was certainly the thing that &lt;em&gt;popularized&lt;/em&gt; the idea. If you crack open any general theory OOP book from the mid-80’s or early 90’s, they’ll be in Smalltalk. Many will also translate their examples to C++, and a few will use another language, but everybody will use Smalltalk.&lt;/p&gt; &lt;p&gt;Smalltalk also spread the idea of objects as shareable data, leading the way to CORBA, and it inspired the computational Actor model.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Cause of Death&lt;/strong&gt;: The common belief is that Smalltalk lost because people used C++ instead. But that’s untrue. Smalltalk did have some issues, specifically its difficulty interoping with other tools and poor runtime performance. But even into the 1990’s Smalltalk was doing respectable business and many people assumed it would be a dominant business language.&lt;/p&gt; &lt;p&gt;Then Java happened.&lt;/p&gt; &lt;figure&gt; &lt;img title="Popularity of languages" src="https://hillelwayne.com/post/influential-dead-languages/java.jpg"&gt; &lt;figcaption&gt;&lt;a href="https://books.google.com/ngrams/graph?content=Java+language%2Csmalltalk+language%2Ceiffel+language%2Csimula+language%2Cada+language&amp;amp;case_insensitive=on&amp;amp;year_start=1980&amp;amp;year_end=2000&amp;amp;corpus=15&amp;amp;smoothing=2&amp;amp;share=&amp;amp;direct_url=t4%3B%2CJava%20language%3B%2Cc0%3B%2Cs0%3B%3BJava%20language%3B%2Cc0%3B%3BJava%20Language%3B%2Cc0%3B%3BJAVA%20LANGUAGE%3B%2Cc0%3B.t4%3B%2Csmalltalk%20language%3B%2Cc0%3B%2Cs0%3B%3BSmalltalk%20language%3B%2Cc0%3B%3BSmalltalk%20Language%3B%2Cc0%3B%3BSmallTalk%20language%3B%2Cc0%3B.t1%3B%2CEiffel%20language%3B%2Cc0%3B.t4%3B%2Csimula%20language%3B%2Cc0%3B%2Cs0%3B%3BSimula%20language%3B%2Cc0%3B%3BSIMULA%20language%3B%2Cc0%3B%3BSIMULA%20Language%3B%2Cc0%3B.t4%3B%2Cada%20language%3B%2Cc0%3B%2Cs0%3B%3BAda%20language%3B%2Cc0%3B%3BAda%20Language%3B%2Cc0%3B%3BADA%20language%3B%2Cc0%3B%3BADA%20LANGUAGE%3B%2Cc0%3B%3BADA%20Language%3B%2Cc0#t4%3B%2CJava%20language%3B%2Cc0%3B%2Cs0%3B%3BJava%20language%3B%2Cc0%3B%3BJava%20Language%3B%2Cc0%3B%3BJAVA%20LANGUAGE%3B%2Cc0%3B.t4%3B%2Csmalltalk%20language%3B%2Cc0%3B%2Cs0%3B%3BSmalltalk%20language%3B%2Cc0%3B%3BSmalltalk%20Language%3B%2Cc0%3B%3BSmallTalk%20language%3B%2Cc0%3B.t1%3B%2CEiffel%20language%3B%2Cc0%3B.t4%3B%2Csimula%20language%3B%2Cc0%3B%2Cs0%3B%3BSimula%20language%3B%2Cc0%3B%3BSIMULA%20language%3B%2Cc0%3B%3BSIMULA%20Language%3B%2Cc0%3B.t4%3B%2Cada%20language%3B%2Cc0%3B%2Cs0%3B%3BAda%20language%3B%2Cc0%3B%3BAda%20Language%3B%2Cc0%3B%3BADA%20language%3B%2Cc0%3B%3BADA%20LANGUAGE%3B%2Cc0%3B%3BADA%20Language%3B%2Cc0"&gt;(source)&lt;/a&gt;&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;Smalltalk wasn’t the only casualty of the “Javapocalypse”: Java also marginalized Eiffel, Ada95, and pretty much everything else in the OOP world. The interesting question isn’t “Why did Smalltalk die”, it’s “Why did C++ survive”. I think it’s because C++ had better C interop so was easier to extend into legacy systems.&lt;/p&gt; &lt;hr&gt; &lt;p&gt;This is just a small sample of the important dead languages. I didn’t cover ALPHARD, ALTRAN, Argus, Automath, BCPL, COMTRAN, CPL, Eiffel, FLOW-MATIC, HOPE, Hypercard, ISWIM, JOVIAL, MacSyma, Mesa, Miranda, Multics Shell, PLANNER, SMP, Sketchpad, or SNOBOL. All of them contributed in their own way to the modern programming world. History is complicated.&lt;/p&gt; &lt;p&gt;Most influential languages never went mainstream. Few people used any one of them. But each one inspired people, who inspired other people, so the DNA of these forgotten languages appear decades after they’re forgotten. But there are also untold languages that didn’t get their ideas out. The &lt;a href="http://hopl.info/"&gt;Encyclopaedia of Programming Languages&lt;/a&gt; lists over 8,000 programming languages. Many of them had ideas that never left their bubble. Consider how much we’d have lost if nobody had heard of SIMULA, or Liskov never shared CLU.&lt;/p&gt; &lt;p&gt;That’s one reason I love studying history. To learn what we’ve lost and find it again.&lt;/p&gt; &lt;hr&gt; &lt;p&gt;The first draft of this was originally shared on my &lt;a href="https://buttondown.email/hillelwayne/"&gt;newsletter&lt;/a&gt;. If you found this interesting, why not subscribe?&lt;/p&gt; &lt;p&gt;&lt;em&gt;Thanks to &lt;a href="https://miikka.me/"&gt;Miikka Koskinen&lt;/a&gt; , &lt;a href="https://medium.com/@kevlinhenney"&gt;Kevlin Henney&lt;/a&gt; , Eric Fischer, and Levi Pearson for corrections and feedback.&lt;/em&gt;&lt;/p&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt;&lt;a href="https://hillelwayne.com/post/influential-dead-languages/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Thu, 26 Mar 2020 11:12:08 UT
      </pubDate>
      <guid>
        https://hillelwayne.com/post/influential-dead-languages/
      </guid>
    </item>
    <item>
      <title>
        Meta book recommendations from Ask Hacker News threads - MapFilterFold
      </title>
      <link>
        https://mapfilterfold.com/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;section id="home" role="main"&gt; &lt;div&gt; &lt;div&gt; &lt;p&gt;&lt;a href="https://mapfilterfold.com/articles/early_founders"&gt; For early stage founders &lt;/a&gt; &lt;/p&gt;&lt;/div&gt; &lt;div&gt; &lt;p&gt;&lt;a href="https://mapfilterfold.com/articles/soft_skills"&gt; Communication soft skills &lt;/a&gt; &lt;/p&gt;&lt;/div&gt; &lt;div&gt; &lt;p&gt;&lt;a href="https://mapfilterfold.com/articles/oddities"&gt; Oditties and fun &lt;/a&gt; &lt;/p&gt;&lt;/div&gt; &lt;div&gt; &lt;div id="mc_embed_signup"&gt; &lt;form novalidate="" name="mc-embedded-subscribe-form" id="mc-embedded-subscribe-form" method="post" action="https://matthewodette.us2.list-manage.com/subscribe/post?u=ba934813855e9555ef8f453b5&amp;amp;id=e82be99faa"&gt; &lt;/form&gt; &lt;/div&gt; &lt;p&gt;&lt;small&gt;Up next: systems thinking&lt;span&gt; hits&lt;/span&gt;&lt;/small&gt; &lt;/p&gt;&lt;/div&gt; &lt;/div&gt; &lt;div&gt; &lt;div&gt;&lt;p&gt;&lt;a href="https://mapfilterfold.com/?nonfiction=true"&gt;Nonfiction&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://mapfilterfold.com/?nonfiction=false"&gt;Fiction&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://mapfilterfold.com/"&gt;Both&lt;/a&gt;&lt;/p&gt;&lt;/div&gt; &lt;div&gt; &lt;form method="get" action="/"&gt; &lt;/form&gt; &lt;/div&gt; &lt;/div&gt; &lt;div&gt; &lt;div&gt; &lt;div&gt; &lt;p&gt;&lt;a href="https://mapfilterfold.com/books/106"&gt; &lt;span&gt; 84 &lt;/span&gt; &lt;span&gt;hits&lt;/span&gt; &lt;/a&gt; &lt;/p&gt;&lt;/div&gt; &lt;p&gt;&lt;a href="https://mapfilterfold.com/books/106"&gt; &lt;img src="https://images-na.ssl-images-amazon.com/images/I/41RtytNpsfL._SL160_.jpg"&gt; &lt;/a&gt; &lt;/p&gt; &lt;/div&gt; &lt;div&gt; &lt;p&gt; &lt;h2&gt; &lt;a href="https://mapfilterfold.com/books/106" aria-label="Goto book titled Thinking, Fast and Slow"&gt;Thinking, Fast and Slow&lt;/a&gt; &lt;/h2&gt; &lt;/p&gt; &lt;p&gt; &lt;h3&gt;by &lt;a href="https://mapfilterfold.com/books/?author=Daniel%20Kahneman" aria-label="Goto author: #(@book.author}"&gt;Daniel Kahneman&lt;/a&gt; &lt;/h3&gt; &lt;/p&gt; &lt;p&gt; IanCal: A stunningly good book about cognitive biases, with fairly understated claims and backed up with studies. Excellent advice for life and it's changed how I view decisions and interactions. &lt;a href="https://mapfilterfold.com/books/106" aria-label="Read more comments about this book"&gt;read comments&lt;/a&gt; &lt;/p&gt; &lt;div&gt; &lt;p&gt; in: &lt;a href="https://mapfilterfold.com/?nonfiction=true" aria-label="Goto nonfiction books"&gt;nonfiction&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=psychology" aria-label="Goto genre psychology"&gt;psychology&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=business" aria-label="Goto genre business"&gt;business&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=economics" aria-label="Goto genre economics"&gt;economics&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=mental%20models" aria-label="Goto genre mental models"&gt;mental models&lt;/a&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;div&gt; &lt;div&gt; &lt;div&gt; &lt;p&gt;&lt;a href="https://mapfilterfold.com/books/116"&gt; &lt;span&gt; 78 &lt;/span&gt; &lt;span&gt;hits&lt;/span&gt; &lt;/a&gt; &lt;/p&gt;&lt;/div&gt; &lt;p&gt;&lt;a href="https://mapfilterfold.com/books/116"&gt; &lt;img src="https://images-na.ssl-images-amazon.com/images/I/51NVtjOrnqL._SL160_.jpg"&gt; &lt;/a&gt; &lt;/p&gt; &lt;/div&gt; &lt;div&gt; &lt;p&gt; &lt;h2&gt; &lt;a href="https://mapfilterfold.com/books/116" aria-label="Goto book titled How to Win Friends and Influence People"&gt;How to Win Friends and Influence People&lt;/a&gt; &lt;/h2&gt; &lt;/p&gt; &lt;p&gt; &lt;h3&gt;by &lt;a href="https://mapfilterfold.com/books/?author=Dale%20Carnegie" aria-label="Goto author: #(@book.author}"&gt;Dale Carnegie&lt;/a&gt; &lt;/h3&gt; &lt;/p&gt; &lt;p&gt; beat: Not creepy at all, despite how the title sounds in today's language. This book is the bible of how to get along with others. It's been in continuous print since before WWII, for good reason. &lt;a href="https://mapfilterfold.com/books/116" aria-label="Read more comments about this book"&gt;read comments&lt;/a&gt; &lt;/p&gt; &lt;div&gt; &lt;p&gt; in: &lt;a href="https://mapfilterfold.com/?nonfiction=true" aria-label="Goto nonfiction books"&gt;nonfiction&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=business" aria-label="Goto genre business"&gt;business&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=psychology" aria-label="Goto genre psychology"&gt;psychology&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=leadership" aria-label="Goto genre leadership"&gt;leadership&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=communication" aria-label="Goto genre communication"&gt;communication&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=management" aria-label="Goto genre management"&gt;management&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=self%20improvement" aria-label="Goto genre self improvement"&gt;self improvement&lt;/a&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;div&gt; &lt;div&gt; &lt;div&gt; &lt;p&gt;&lt;a href="https://mapfilterfold.com/books/67"&gt; &lt;span&gt; 74 &lt;/span&gt; &lt;span&gt;hits&lt;/span&gt; &lt;/a&gt; &lt;/p&gt;&lt;/div&gt; &lt;p&gt;&lt;a href="https://mapfilterfold.com/books/67"&gt; &lt;img src="https://images-na.ssl-images-amazon.com/images/I/41lZKXt1%2BML._SL160_.jpg"&gt; &lt;/a&gt; &lt;/p&gt; &lt;/div&gt; &lt;div&gt; &lt;p&gt; &lt;h2&gt; &lt;a href="https://mapfilterfold.com/books/67" aria-label="Goto book titled Sapiens: A Brief History of Humankind"&gt;Sapiens: A Brief History of Humankind&lt;/a&gt; &lt;/h2&gt; &lt;/p&gt; &lt;p&gt; &lt;h3&gt;by &lt;a href="https://mapfilterfold.com/books/?author=Yuval%20Noah%20Harari" aria-label="Goto author: #(@book.author}"&gt;Yuval Noah Harari&lt;/a&gt; &lt;/h3&gt; &lt;/p&gt; &lt;p&gt; air7: Hands down the book that most influenced me. The book had (for me) not one but several simple-yet-profound ideas that were forever inserted into the foreground of how I make sense of the world. &lt;a href="https://mapfilterfold.com/books/67" aria-label="Read more comments about this book"&gt;read comments&lt;/a&gt; &lt;/p&gt; &lt;div&gt; &lt;p&gt; in: &lt;a href="https://mapfilterfold.com/?nonfiction=true" aria-label="Goto nonfiction books"&gt;nonfiction&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=history" aria-label="Goto genre history"&gt;history&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=philosophy" aria-label="Goto genre philosophy"&gt;philosophy&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=anthropology" aria-label="Goto genre anthropology"&gt;anthropology&lt;/a&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;div&gt; &lt;div&gt; &lt;div&gt; &lt;p&gt;&lt;a href="https://mapfilterfold.com/books/254"&gt; &lt;span&gt; 68 &lt;/span&gt; &lt;span&gt;hits&lt;/span&gt; &lt;/a&gt; &lt;/p&gt;&lt;/div&gt; &lt;p&gt;&lt;a href="https://mapfilterfold.com/books/254"&gt; &lt;img src="https://images-na.ssl-images-amazon.com/images/I/512BblrQFqL._SL160_.jpg"&gt; &lt;/a&gt; &lt;/p&gt; &lt;/div&gt; &lt;div&gt; &lt;p&gt; &lt;h2&gt; &lt;a href="https://mapfilterfold.com/books/254" aria-label="Goto book titled Gödel, Escher, Bach"&gt;Gödel, Escher, Bach&lt;/a&gt; &lt;/h2&gt; &lt;/p&gt; &lt;p&gt; &lt;h3&gt;by &lt;a href="https://mapfilterfold.com/books/?author=Douglas%20R.%20Hofstadter" aria-label="Goto author: #(@book.author}"&gt;Douglas R. Hofstadter&lt;/a&gt; &lt;/h3&gt; &lt;/p&gt; &lt;p&gt; mck-: What a unique masterpiece. Covers a wide range fascinating concepts through the three geniuses in Math, Art, and Music... &lt;a href="https://mapfilterfold.com/books/254" aria-label="Read more comments about this book"&gt;read comments&lt;/a&gt; &lt;/p&gt; &lt;div&gt; &lt;p&gt; in: &lt;a href="https://mapfilterfold.com/?nonfiction=true" aria-label="Goto nonfiction books"&gt;nonfiction&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=philosophy" aria-label="Goto genre philosophy"&gt;philosophy&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=math" aria-label="Goto genre math"&gt;math&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=mental%20models" aria-label="Goto genre mental models"&gt;mental models&lt;/a&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;div&gt; &lt;div&gt; &lt;div&gt; &lt;p&gt;&lt;a href="https://mapfilterfold.com/books/214"&gt; &lt;span&gt; 62 &lt;/span&gt; &lt;span&gt;hits&lt;/span&gt; &lt;/a&gt; &lt;/p&gt;&lt;/div&gt; &lt;p&gt;&lt;a href="https://mapfilterfold.com/books/214"&gt; &lt;img src="https://images-na.ssl-images-amazon.com/images/I/51i9cZv%2B6KL._SL160_.jpg"&gt; &lt;/a&gt; &lt;/p&gt; &lt;/div&gt; &lt;div&gt; &lt;p&gt; &lt;h2&gt; &lt;a href="https://mapfilterfold.com/books/214" aria-label="Goto book titled Meditations"&gt;Meditations&lt;/a&gt; &lt;/h2&gt; &lt;/p&gt; &lt;p&gt; &lt;h3&gt;by &lt;a href="https://mapfilterfold.com/books/?author=Marcus%20Aurelius" aria-label="Goto author: #(@book.author}"&gt;Marcus Aurelius&lt;/a&gt; &lt;/h3&gt; &lt;/p&gt; &lt;p&gt; jonathansorum: Meditations easily has my highest rate of highlighted words in relation to total book length. Seems like every page (almost) has some eternal and profound in it. &lt;a href="https://mapfilterfold.com/books/214" aria-label="Read more comments about this book"&gt;read comments&lt;/a&gt; &lt;/p&gt; &lt;div&gt; &lt;p&gt; in: &lt;a href="https://mapfilterfold.com/?nonfiction=true" aria-label="Goto nonfiction books"&gt;nonfiction&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=philosophy" aria-label="Goto genre philosophy"&gt;philosophy&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=history" aria-label="Goto genre history"&gt;history&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=spirituality" aria-label="Goto genre spirituality"&gt;spirituality&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=psychology" aria-label="Goto genre psychology"&gt;psychology&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=leadership" aria-label="Goto genre leadership"&gt;leadership&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=self%20improvement" aria-label="Goto genre self improvement"&gt;self improvement&lt;/a&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;div&gt; &lt;div&gt; &lt;div&gt; &lt;p&gt;&lt;a href="https://mapfilterfold.com/books/86"&gt; &lt;span&gt; 60 &lt;/span&gt; &lt;span&gt;hits&lt;/span&gt; &lt;/a&gt; &lt;/p&gt;&lt;/div&gt; &lt;p&gt;&lt;a href="https://mapfilterfold.com/books/86"&gt; &lt;img src="https://images-na.ssl-images-amazon.com/images/I/41BSMHjI39L._SL160_.jpg"&gt; &lt;/a&gt; &lt;/p&gt; &lt;/div&gt; &lt;div&gt; &lt;p&gt; &lt;h2&gt; &lt;a href="https://mapfilterfold.com/books/86" aria-label="Goto book titled The Selfish Gene"&gt;The Selfish Gene&lt;/a&gt; &lt;/h2&gt; &lt;/p&gt; &lt;p&gt; &lt;h3&gt;by &lt;a href="https://mapfilterfold.com/books/?author=Richard%20Dawkins" aria-label="Goto author: #(@book.author}"&gt;Richard Dawkins&lt;/a&gt; &lt;/h3&gt; &lt;/p&gt; &lt;p&gt; sorenn111: The Selfish Gene has been the most influential book on my life. Especially when Dawkins makes the point about pre-darwininan philosophy needing rethinking. His point being... &lt;a href="https://mapfilterfold.com/books/86" aria-label="Read more comments about this book"&gt;read comments&lt;/a&gt; &lt;/p&gt; &lt;div&gt; &lt;p&gt; in: &lt;a href="https://mapfilterfold.com/?nonfiction=true" aria-label="Goto nonfiction books"&gt;nonfiction&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=biology" aria-label="Goto genre biology"&gt;biology&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=evolution" aria-label="Goto genre evolution"&gt;evolution&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=philosophy" aria-label="Goto genre philosophy"&gt;philosophy&lt;/a&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;div&gt; &lt;div&gt; &lt;div&gt; &lt;p&gt;&lt;a href="https://mapfilterfold.com/books/550"&gt; &lt;span&gt; 51 &lt;/span&gt; &lt;span&gt;hits&lt;/span&gt; &lt;/a&gt; &lt;/p&gt;&lt;/div&gt; &lt;p&gt;&lt;a href="https://mapfilterfold.com/books/550"&gt; &lt;img src="https://images-na.ssl-images-amazon.com/images/I/51cUVaBWZzL._SL160_.jpg"&gt; &lt;/a&gt; &lt;/p&gt; &lt;/div&gt; &lt;div&gt; &lt;p&gt; &lt;h2&gt; &lt;a href="https://mapfilterfold.com/books/550" aria-label="Goto book titled The Pragmatic Programmer"&gt;The Pragmatic Programmer&lt;/a&gt; &lt;/h2&gt; &lt;/p&gt; &lt;p&gt; &lt;h3&gt;by &lt;a href="https://mapfilterfold.com/books/?author=Andy%20Hunt" aria-label="Goto author: #(@book.author}"&gt;Andy Hunt&lt;/a&gt; &lt;/h3&gt; &lt;/p&gt; &lt;p&gt; BFatts: A fantastic language-agnostic manual that still applies heavily today. &lt;a href="https://mapfilterfold.com/books/550" aria-label="Read more comments about this book"&gt;read comments&lt;/a&gt; &lt;/p&gt; &lt;div&gt; &lt;p&gt; in: &lt;a href="https://mapfilterfold.com/?nonfiction=true" aria-label="Goto nonfiction books"&gt;nonfiction&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=programming" aria-label="Goto genre programming"&gt;programming&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=computer%20science" aria-label="Goto genre computer science"&gt;computer science&lt;/a&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;div&gt; &lt;div&gt; &lt;div&gt; &lt;p&gt;&lt;a href="https://mapfilterfold.com/books/372"&gt; &lt;span&gt; 47 &lt;/span&gt; &lt;span&gt;hits&lt;/span&gt; &lt;/a&gt; &lt;/p&gt;&lt;/div&gt; &lt;p&gt;&lt;a href="https://mapfilterfold.com/books/372"&gt; &lt;img src="https://images-na.ssl-images-amazon.com/images/I/41F75p2GedL._SL160_.jpg"&gt; &lt;/a&gt; &lt;/p&gt; &lt;/div&gt; &lt;div&gt; &lt;p&gt; &lt;h2&gt; &lt;a href="https://mapfilterfold.com/books/372" aria-label="Goto book titled Zen and the Art of Motorcycle Maintenance"&gt;Zen and the Art of Motorcycle Maintenance&lt;/a&gt; &lt;/h2&gt; &lt;/p&gt; &lt;p&gt; &lt;h3&gt;by &lt;a href="https://mapfilterfold.com/books/?author=Robert%20M.%20Pirsig" aria-label="Goto author: #(@book.author}"&gt;Robert M. Pirsig&lt;/a&gt; &lt;/h3&gt; &lt;/p&gt; &lt;p&gt; Roelven: It has shaped my thinking on 'what is good' or 'what does quality' mean. As an engineer it is easy to appreciate the author slowly going insane about the details he keeps coming back to... &lt;a href="https://mapfilterfold.com/books/372" aria-label="Read more comments about this book"&gt;read comments&lt;/a&gt; &lt;/p&gt; &lt;div&gt; &lt;p&gt; in: &lt;a href="https://mapfilterfold.com/books/?nonfiction=false" aria-label="Goto fiction books"&gt;fiction&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=philosophy" aria-label="Goto genre philosophy"&gt;philosophy&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=spirituality" aria-label="Goto genre spirituality"&gt;spirituality&lt;/a&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;div&gt; &lt;div&gt; &lt;div&gt; &lt;p&gt;&lt;a href="https://mapfilterfold.com/books/65"&gt; &lt;span&gt; 46 &lt;/span&gt; &lt;span&gt;hits&lt;/span&gt; &lt;/a&gt; &lt;/p&gt;&lt;/div&gt; &lt;p&gt;&lt;a href="https://mapfilterfold.com/books/65"&gt; &lt;img src="https://images-na.ssl-images-amazon.com/images/I/410RTQezHYL._SL160_.jpg"&gt; &lt;/a&gt; &lt;/p&gt; &lt;/div&gt; &lt;div&gt; &lt;p&gt; &lt;h2&gt; &lt;a href="https://mapfilterfold.com/books/65" aria-label="Goto book titled The Design of Everyday Things"&gt;The Design of Everyday Things&lt;/a&gt; &lt;/h2&gt; &lt;/p&gt; &lt;p&gt; &lt;h3&gt;by &lt;a href="https://mapfilterfold.com/books/?author=Donald%20A.%20Norman" aria-label="Goto author: #(@book.author}"&gt;Donald A. Norman&lt;/a&gt; &lt;/h3&gt; &lt;/p&gt; &lt;p&gt; davidgh: A masterpiece. The age of the book proves it. It is as relevant today as it was when written 30 years ago. The only downside to the book is it will ruin every elevator, door handle and... &lt;a href="https://mapfilterfold.com/books/65" aria-label="Read more comments about this book"&gt;read comments&lt;/a&gt; &lt;/p&gt; &lt;div&gt; &lt;p&gt; in: &lt;a href="https://mapfilterfold.com/?nonfiction=true" aria-label="Goto nonfiction books"&gt;nonfiction&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=design" aria-label="Goto genre design"&gt;design&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=business" aria-label="Goto genre business"&gt;business&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=psychology" aria-label="Goto genre psychology"&gt;psychology&lt;/a&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;div&gt; &lt;div&gt; &lt;div&gt; &lt;p&gt;&lt;a href="https://mapfilterfold.com/books/108"&gt; &lt;span&gt; 45 &lt;/span&gt; &lt;span&gt;hits&lt;/span&gt; &lt;/a&gt; &lt;/p&gt;&lt;/div&gt; &lt;p&gt;&lt;a href="https://mapfilterfold.com/books/108"&gt; &lt;img src="https://images-na.ssl-images-amazon.com/images/I/4137OkbPQ4L._SL160_.jpg"&gt; &lt;/a&gt; &lt;/p&gt; &lt;/div&gt; &lt;div&gt; &lt;p&gt; &lt;h2&gt; &lt;a href="https://mapfilterfold.com/books/108" aria-label="Goto book titled Zero to One: Notes on Startups, or How to Build the Future"&gt;Zero to One: Notes on Startups, or How to Build the Future&lt;/a&gt; &lt;/h2&gt; &lt;/p&gt; &lt;p&gt; &lt;h3&gt;by &lt;a href="https://mapfilterfold.com/books/?author=Peter%20Thiel" aria-label="Goto author: #(@book.author}"&gt;Peter Thiel&lt;/a&gt; &lt;/h3&gt; &lt;/p&gt; &lt;p&gt; shawn: I think it's a good one because it's a mix of analysis and history. Thiel had a unique vantage point, and he shares it well. It also challenges you to be ambitious, which is becoming a rare sentiment. &lt;a href="https://mapfilterfold.com/books/108" aria-label="Read more comments about this book"&gt;read comments&lt;/a&gt; &lt;/p&gt; &lt;div&gt; &lt;p&gt; in: &lt;a href="https://mapfilterfold.com/?nonfiction=true" aria-label="Goto nonfiction books"&gt;nonfiction&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=business" aria-label="Goto genre business"&gt;business&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=entrepreneurship" aria-label="Goto genre entrepreneurship"&gt;entrepreneurship&lt;/a&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;div&gt; &lt;div&gt; &lt;div&gt; &lt;p&gt;&lt;a href="https://mapfilterfold.com/books/154"&gt; &lt;span&gt; 42 &lt;/span&gt; &lt;span&gt;hits&lt;/span&gt; &lt;/a&gt; &lt;/p&gt;&lt;/div&gt; &lt;p&gt;&lt;a href="https://mapfilterfold.com/books/154"&gt; &lt;img src="https://images-na.ssl-images-amazon.com/images/I/419QSJTZ%2BbL._SL160_.jpg"&gt; &lt;/a&gt; &lt;/p&gt; &lt;/div&gt; &lt;div&gt; &lt;p&gt; &lt;h2&gt; &lt;a href="https://mapfilterfold.com/books/154" aria-label="Goto book titled Antifragile: Things That Gain from Disorder"&gt;Antifragile: Things That Gain from Disorder&lt;/a&gt; &lt;/h2&gt; &lt;/p&gt; &lt;p&gt; &lt;h3&gt;by &lt;a href="https://mapfilterfold.com/books/?author=Nassim%20Nicholas%20Taleb" aria-label="Goto author: #(@book.author}"&gt;Nassim Nicholas Taleb&lt;/a&gt; &lt;/h3&gt; &lt;/p&gt; &lt;p&gt; jurgenwerk: Man, reading this book really put a fire under my ass. I realized how much more I could be getting out of life by pursuing optionality and using the barbell strategy. &lt;a href="https://mapfilterfold.com/books/154" aria-label="Read more comments about this book"&gt;read comments&lt;/a&gt; &lt;/p&gt; &lt;div&gt; &lt;p&gt; in: &lt;a href="https://mapfilterfold.com/?nonfiction=true" aria-label="Goto nonfiction books"&gt;nonfiction&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=philosophy" aria-label="Goto genre philosophy"&gt;philosophy&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=business" aria-label="Goto genre business"&gt;business&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=economics" aria-label="Goto genre economics"&gt;economics&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=psychology" aria-label="Goto genre psychology"&gt;psychology&lt;/a&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;div&gt; &lt;div&gt; &lt;div&gt; &lt;p&gt;&lt;a href="https://mapfilterfold.com/books/110"&gt; &lt;span&gt; 42 &lt;/span&gt; &lt;span&gt;hits&lt;/span&gt; &lt;/a&gt; &lt;/p&gt;&lt;/div&gt; &lt;p&gt;&lt;a href="https://mapfilterfold.com/books/110"&gt; &lt;img src="https://images-na.ssl-images-amazon.com/images/I/41nLuZrSbNL._SL160_.jpg"&gt; &lt;/a&gt; &lt;/p&gt; &lt;/div&gt; &lt;div&gt; &lt;p&gt; &lt;h2&gt; &lt;a href="https://mapfilterfold.com/books/110" aria-label="Goto book titled Man's Search for Meaning"&gt;Man's Search for Meaning&lt;/a&gt; &lt;/h2&gt; &lt;/p&gt; &lt;p&gt; &lt;h3&gt;by &lt;a href="https://mapfilterfold.com/books/?author=Viktor%20E.%20Frankl" aria-label="Goto author: #(@book.author}"&gt;Viktor E. Frankl&lt;/a&gt; &lt;/h3&gt; &lt;/p&gt; &lt;p&gt; bradbatt: Amazingly powerful read. It is simultaneously completely saddening to read what some humans are capable of doing to others, but also inspiring to see those who were victims of the holocaust... &lt;a href="https://mapfilterfold.com/books/110" aria-label="Read more comments about this book"&gt;read comments&lt;/a&gt; &lt;/p&gt; &lt;div&gt; &lt;p&gt; in: &lt;a href="https://mapfilterfold.com/?nonfiction=true" aria-label="Goto nonfiction books"&gt;nonfiction&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=psychology" aria-label="Goto genre psychology"&gt;psychology&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=philosophy" aria-label="Goto genre philosophy"&gt;philosophy&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=history" aria-label="Goto genre history"&gt;history&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=memoir" aria-label="Goto genre memoir"&gt;memoir&lt;/a&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;div&gt; &lt;div&gt; &lt;div&gt; &lt;p&gt;&lt;a href="https://mapfilterfold.com/books/103"&gt; &lt;span&gt; 40 &lt;/span&gt; &lt;span&gt;hits&lt;/span&gt; &lt;/a&gt; &lt;/p&gt;&lt;/div&gt; &lt;p&gt;&lt;a href="https://mapfilterfold.com/books/103"&gt; &lt;img src="https://images-na.ssl-images-amazon.com/images/I/51WGi3Fh9iL._SL160_.jpg"&gt; &lt;/a&gt; &lt;/p&gt; &lt;/div&gt; &lt;div&gt; &lt;p&gt; &lt;h2&gt; &lt;a href="https://mapfilterfold.com/books/103" aria-label="Goto book titled Deep Work: Rules for Focused Success in a Distracted World"&gt;Deep Work: Rules for Focused Success in a Distracted World&lt;/a&gt; &lt;/h2&gt; &lt;/p&gt; &lt;p&gt; &lt;h3&gt;by &lt;a href="https://mapfilterfold.com/books/?author=Cal%20Newport" aria-label="Goto author: #(@book.author}"&gt;Cal Newport&lt;/a&gt; &lt;/h3&gt; &lt;/p&gt; &lt;p&gt; jacobkg: Starts with the thesis that a generation of workers have forgotten how to concentrate on mentally challenging tasks. Full of ideas and inspiration for rebuilding your stamina for intense focused thought. &lt;a href="https://mapfilterfold.com/books/103" aria-label="Read more comments about this book"&gt;read comments&lt;/a&gt; &lt;/p&gt; &lt;div&gt; &lt;p&gt; in: &lt;a href="https://mapfilterfold.com/?nonfiction=true" aria-label="Goto nonfiction books"&gt;nonfiction&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=business" aria-label="Goto genre business"&gt;business&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=productivity" aria-label="Goto genre productivity"&gt;productivity&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=psychology" aria-label="Goto genre psychology"&gt;psychology&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=self%20improvement" aria-label="Goto genre self improvement"&gt;self improvement&lt;/a&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;div&gt; &lt;div&gt; &lt;div&gt; &lt;p&gt;&lt;a href="https://mapfilterfold.com/books/113"&gt; &lt;span&gt; 39 &lt;/span&gt; &lt;span&gt;hits&lt;/span&gt; &lt;/a&gt; &lt;/p&gt;&lt;/div&gt; &lt;p&gt;&lt;a href="https://mapfilterfold.com/books/113"&gt; &lt;img src="https://images-na.ssl-images-amazon.com/images/I/51H17R%2BbW8L._SL160_.jpg"&gt; &lt;/a&gt; &lt;/p&gt; &lt;/div&gt; &lt;div&gt; &lt;p&gt; &lt;h2&gt; &lt;a href="https://mapfilterfold.com/books/113" aria-label="Goto book titled Structure and Interpretation of Computer Programs"&gt;Structure and Interpretation of Computer Programs&lt;/a&gt; &lt;/h2&gt; &lt;/p&gt; &lt;p&gt; &lt;h3&gt;by &lt;a href="https://mapfilterfold.com/books/?author=Harold%20Abelson" aria-label="Goto author: #(@book.author}"&gt;Harold Abelson&lt;/a&gt; &lt;/h3&gt; &lt;/p&gt; &lt;p&gt; throwaway124567: Very good. It was MITs old CS textbook, it’s still highly relevant. It takes a while to get through and you probably would get the most value out of it if you already have a lot of programming experience. &lt;a href="https://mapfilterfold.com/books/113" aria-label="Read more comments about this book"&gt;read comments&lt;/a&gt; &lt;/p&gt; &lt;div&gt; &lt;p&gt; in: &lt;a href="https://mapfilterfold.com/?nonfiction=true" aria-label="Goto nonfiction books"&gt;nonfiction&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=programming" aria-label="Goto genre programming"&gt;programming&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=computer%20science" aria-label="Goto genre computer science"&gt;computer science&lt;/a&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;div&gt; &lt;div&gt; &lt;div&gt; &lt;p&gt;&lt;a href="https://mapfilterfold.com/books/183"&gt; &lt;span&gt; 37 &lt;/span&gt; &lt;span&gt;hits&lt;/span&gt; &lt;/a&gt; &lt;/p&gt;&lt;/div&gt; &lt;p&gt;&lt;a href="https://mapfilterfold.com/books/183"&gt; &lt;img src="https://images-na.ssl-images-amazon.com/images/I/51J1VwsSv1L._SL160_.jpg"&gt; &lt;/a&gt; &lt;/p&gt; &lt;/div&gt; &lt;div&gt; &lt;p&gt; &lt;h2&gt; &lt;a href="https://mapfilterfold.com/books/183" aria-label="Goto book titled The Mythical Man-Month: Essays on Software Engineering"&gt;The Mythical Man-Month: Essays on Software Engineering&lt;/a&gt; &lt;/h2&gt; &lt;/p&gt; &lt;p&gt; &lt;h3&gt;by &lt;a href="https://mapfilterfold.com/books/?author=Frederick%20P.%20Brooks%20Jr." aria-label="Goto author: #(@book.author}"&gt;Frederick P. Brooks Jr.&lt;/a&gt; &lt;/h3&gt; &lt;/p&gt; &lt;p&gt; ereyes01: One of the most important books ever written on software engineering practice. Author Frederick Brooks won the Turing Award for this book and for his work on IBM's System/360... &lt;a href="https://mapfilterfold.com/books/183" aria-label="Read more comments about this book"&gt;read comments&lt;/a&gt; &lt;/p&gt; &lt;div&gt; &lt;p&gt; in: &lt;a href="https://mapfilterfold.com/?nonfiction=true" aria-label="Goto nonfiction books"&gt;nonfiction&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=programming" aria-label="Goto genre programming"&gt;programming&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=business" aria-label="Goto genre business"&gt;business&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=management" aria-label="Goto genre management"&gt;management&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=computer%20science" aria-label="Goto genre computer science"&gt;computer science&lt;/a&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;div&gt; &lt;div&gt; &lt;div&gt; &lt;p&gt;&lt;a href="https://mapfilterfold.com/books/114"&gt; &lt;span&gt; 36 &lt;/span&gt; &lt;span&gt;hits&lt;/span&gt; &lt;/a&gt; &lt;/p&gt;&lt;/div&gt; &lt;p&gt;&lt;a href="https://mapfilterfold.com/books/114"&gt; &lt;img src="https://images-na.ssl-images-amazon.com/images/I/51l1eHtGLoL._SL160_.jpg"&gt; &lt;/a&gt; &lt;/p&gt; &lt;/div&gt; &lt;div&gt; &lt;p&gt; &lt;h2&gt; &lt;a href="https://mapfilterfold.com/books/114" aria-label="Goto book titled Siddhartha"&gt;Siddhartha&lt;/a&gt; &lt;/h2&gt; &lt;/p&gt; &lt;p&gt; &lt;h3&gt;by &lt;a href="https://mapfilterfold.com/books/?author=Hermann%20Hesse" aria-label="Goto author: #(@book.author}"&gt;Hermann Hesse&lt;/a&gt; &lt;/h3&gt; &lt;/p&gt; &lt;p&gt; acrodrig: I think it's the closest I have come to understanding "enlightenment" (whatever it may mean for each person). Give it a try. &lt;a href="https://mapfilterfold.com/books/114" aria-label="Read more comments about this book"&gt;read comments&lt;/a&gt; &lt;/p&gt; &lt;div&gt; &lt;p&gt; in: &lt;a href="https://mapfilterfold.com/books/?nonfiction=false" aria-label="Goto fiction books"&gt;fiction&lt;/a&gt; | &lt;a href="https://mapfilterfold.com/books/?genre=philosophy" aria-label="Goto genre philosophy"&gt;philosophy&lt;/a&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div&gt; &lt;nav role="navigation" aria-label="pagination"&gt;&lt;a disabled="" rel="prev" href="https://mapfilterfold.com/?page=0"&gt;Previous&lt;/a&gt;&lt;a rel="next" href="https://mapfilterfold.com/?page=2"&gt;Next Page&lt;/a&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://mapfilterfold.com/?page=1" aria-label="Goto page 1"&gt;1&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://mapfilterfold.com/?page=2" aria-label="Goto page 2"&gt;2&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://mapfilterfold.com/?page=3" aria-label="Goto page 3"&gt;3&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;…&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://mapfilterfold.com/?page=189" aria-label="Goto page 189"&gt;189&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/nav&gt; &lt;/div&gt; &lt;/section&gt;&lt;/div&gt;&lt;a href="https://mapfilterfold.com/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Fri, 27 Mar 2020 14:57:39 UT
      </pubDate>
      <guid>
        https://mapfilterfold.com/
      </guid>
    </item>
    <item>
      <title>
        Why You Need To Start Using A Decision Journal
      </title>
      <link>
        https://blog.trello.com/decision-journal
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt; &lt;p&gt;&lt;span data-hs-cos-type="rich_text" data-hs-cos-general-type="meta_field" id="hs_cos_wrapper_post_body"&gt;&lt;p&gt;&lt;img sizes="(max-width: 2400px) 100vw, 2400px" srcset="https://blog.trello.com/hs-fs/hubfs/decision%20journal%20.png?width=1200&amp;amp;name=decision%20journal%20.png 1200w, https://blog.trello.com/hs-fs/hubfs/decision%20journal%20.png?width=2400&amp;amp;name=decision%20journal%20.png 2400w, https://blog.trello.com/hs-fs/hubfs/decision%20journal%20.png?width=3600&amp;amp;name=decision%20journal%20.png 3600w, https://blog.trello.com/hs-fs/hubfs/decision%20journal%20.png?width=4800&amp;amp;name=decision%20journal%20.png 4800w, https://blog.trello.com/hs-fs/hubfs/decision%20journal%20.png?width=6000&amp;amp;name=decision%20journal%20.png 6000w, https://blog.trello.com/hs-fs/hubfs/decision%20journal%20.png?width=7200&amp;amp;name=decision%20journal%20.png 7200w" width="2400" alt="decision journal" src="https://blog.trello.com/hs-fs/hubfs/decision%20journal%20.png?width=2400&amp;amp;name=decision%20journal%20.png"&gt;&lt;/p&gt; &lt;p&gt;Do you remember those “choose your own adventure” books from your childhood? Where the pages were filled with different options and the choices you made advanced the plot?&amp;nbsp;&lt;/p&gt; &lt;p&gt;Yeah, real life feels a lot like that—except, it’s never-ending and not always as thrilling. That’s because we’re faced with a lot of decisions each and every day. And I mean &lt;i&gt;a lot&lt;/i&gt; of them.&amp;nbsp;&lt;/p&gt; &lt;p&gt;So instead of throwing your hands up in the air, what should you do instead in the face of an endless list of decisions?&amp;nbsp;&lt;/p&gt; &lt;h2&gt;&lt;strong&gt;Decisions, Decisions: Are We All Burnt Out On Making Choices?&lt;/strong&gt;&lt;/h2&gt; &lt;p&gt;Some estimates go as far as to say that you need to make upwards of &lt;a rel="nofollow noopener" href="http://science.unctv.org/content/reportersblog/choices"&gt;35,000 remotely conscious choices&lt;/a&gt; on a daily basis. Even funnier? A &lt;a rel="nofollow noopener" href="https://news.cornell.edu/stories/2006/12/mindless-autopilot-drives-people-underestimate-food-decisions"&gt;study out of Cornell&lt;/a&gt; found that you make over 200 decisions a day just related to what you’ll eat or drink.&lt;/p&gt; &lt;p&gt;It’s no wonder that so many of us feel like our decision-making muscles are worn out. In fact, the feeling of exhaustion over needing to choose between option A and option B is so relatable that it’s even been given a name: &lt;a rel="noopener" href="https://blog.trello.com/beat-decision-fatigue-with-better-brain-habits"&gt;decision fatigue&lt;/a&gt;.&amp;nbsp;&lt;/p&gt; &lt;p&gt;Plenty of research demonstrates that the quality of your decisions decreases as you make more choices, simply because you get plain ol’ tired of making them. And, it seems like nobody is immune. &lt;a rel="nofollow noopener" href="https://www.pnas.org/content/108/17/6889"&gt;One study&lt;/a&gt; of judges (who we’d all like to think of as sound decision-makers) found that they were way more likely to grant parole in the morning, compared with later in the day.&amp;nbsp;&lt;/p&gt; &lt;p&gt;Decisions can be exhausting, but they’re also an essential part of your daily life. From the small ones (what should you eat for lunch?) to the giant ones (should you change careers?), you’re in the driver’s seat.&lt;/p&gt; &lt;p&gt;&lt;img alt="bad at making decisions" src="https://blog.trello.com/hubfs/bad%20at%20making%20decisions.gif"&gt;&lt;/p&gt; &lt;p&gt;So, how can you get better at making choices—particularly the big ones that have potentially major consequences? Should you engage in a rousing game of eenie, meenie, miney, moe? Throw a dart at a board?&lt;/p&gt; &lt;p&gt;As it turns out, a decision journal might just be the tool you need.&amp;nbsp;&lt;/p&gt; &lt;h2&gt;&lt;strong&gt;So...What Is A Decision Journal?&amp;nbsp;&lt;/strong&gt;&lt;/h2&gt; &lt;p&gt;I can’t blame you if the term “decision journal” inspires visions of writing a bunch of heartfelt “dear diary” entries in a locked notebook.&amp;nbsp;&lt;/p&gt; &lt;p&gt;But, this concept is actually a pretty straightforward journaling exercise. In your decision journal (it can be anything from a &lt;a rel="noopener" href="https://trello.com/power-ups/55a5d916446f517774210006/google-drive"&gt;Google Document&lt;/a&gt; to a cheap notebook to even a Trello board), you simply chronicle your bigger decisions and record how you felt when you made them.&amp;nbsp;&lt;/p&gt; &lt;p&gt;As an &lt;a rel="nofollow noopener" href="https://fs.blog/2014/02/decision-journal/"&gt;article for Farnam Street&lt;/a&gt; recommends, when you’re faced with a large decision, use your journal to document the following:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The choice you’ve made&lt;/li&gt; &lt;li&gt;What you expect to happen as a result of that choice&lt;/li&gt; &lt;li&gt;Why you expect things to pan out that way&lt;/li&gt; &lt;li&gt;How you feel about your decision&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;For example, imagine that you were wrestling with the choice of whether or not to apply for an internal transfer to a different department within your company. Once you’ve actually made your choice (you’re going to go for it and toss your hat into the ring!), you’d use your decision journal to jot down the nuts and bolts of that decision, your assumptions, and your emotional state when you settled on your outcome.&amp;nbsp;&lt;/p&gt; &lt;h2&gt;&lt;strong&gt;How A Decision Journal Can Help Declutter Your Brain&lt;/strong&gt;&lt;/h2&gt; &lt;p&gt;A decision journal isn’t necessarily an in-the-moment tool like a &lt;a rel="nofollow noopener" href="https://toggl.com/blog/decision-matrix"&gt;decision matrix&lt;/a&gt; or a trusty pros and cons list.&amp;nbsp;&lt;/p&gt; &lt;p&gt;Instead, it’s something you’ll use for reflection. By documenting and periodically reviewing the decisions you make over time, you’ll get a better grasp on your state of mind and identify things like trends or common traps you find yourself falling into.&amp;nbsp;&lt;/p&gt; &lt;p&gt;To put it simply, a decision journal helps to refine your decision-making process as you move forward, rather than being something that helps you actually make a choice in the moment.&lt;/p&gt; &lt;p&gt;If that seems like an unnecessary formality, I promise it’s not—because it’ll help you overcome something called the hindsight bias.&amp;nbsp;&lt;/p&gt; &lt;p&gt;“Research shows that we selectively recall information that confirms what we know to be true and we try to create a narrative that makes sense out of the information we have,” explains an &lt;a rel="nofollow noopener" href="https://www.psychologicalscience.org/news/releases/i-knew-it-all-along-didnt-i-understanding-hindsight-bias.html"&gt;article for the Association for Psychological Science&lt;/a&gt;. “When this narrative is easy to generate, we interpret that to mean that the outcome must have been foreseeable.”&lt;/p&gt; &lt;p&gt;Basically, when you stroke your ego by telling yourself that you’re a fortune teller, you create major blindspots and lose out on opportunities to improve. You need to be able to clearly see where you make mistakes and why they happen. Ultimately, that information helps you make better choices moving forward.&amp;nbsp;&lt;/p&gt; &lt;p&gt;Maybe your decision journal will illuminate the fact that you have the tendency to make irrational choices when you’re stressed and under the gun. Knowing this, you can move through future decisions by giving yourself some space to breathe and mull things over a little more.&amp;nbsp;&lt;/p&gt; &lt;p&gt;Or, perhaps every time you marked down that you felt wary of a decision, it turned out poorly. That’s a sign that maybe you need to start trusting your gut.&amp;nbsp;&lt;/p&gt; &lt;h2&gt;&lt;strong&gt;How To Make The Most Of Your Decision Journal&lt;/strong&gt;&lt;/h2&gt; &lt;p&gt;The process of decision journaling itself is pretty cut and dried: you write down your decision, your assumptions, and your emotions.&lt;/p&gt; &lt;p&gt;But, there are a few other tips you’ll want to keep in mind to really make the most of this practice.&amp;nbsp;&lt;/p&gt; &lt;h3&gt;&lt;strong&gt;1. Don’t Use It For Everything&lt;/strong&gt;&lt;/h3&gt; &lt;p&gt;I know what you’re thinking: Journaling about your decisions is just another thing to add to your to-do list—which most of us don’t need, especially since &lt;a rel="nofollow noopener" href="https://www.cnbc.com/2017/03/29/most-american-workers-are-stressed-most-of-the-time.html"&gt;60% of workers&lt;/a&gt; reportedly feel stressed more than three work days per week.&amp;nbsp;&lt;/p&gt; &lt;p&gt;Your decision journal shouldn’t be a burdensome activity that slows down the process of making every single decision.&amp;nbsp;&lt;/p&gt; &lt;p&gt;Reserve it exclusively for the larger decisions that have potentially major consequences and require some serious thought and deliberation. After all, there’s no need to journal about whether you should order a turkey club or a chicken burrito for lunch that day.&amp;nbsp;&amp;nbsp;&lt;/p&gt; &lt;p&gt;&lt;img sizes="(max-width: 500px) 100vw, 500px" srcset="https://blog.trello.com/hs-fs/hubfs/how%20to%20use%20a%20decision%20journal.gif?width=250&amp;amp;name=how%20to%20use%20a%20decision%20journal.gif 250w, https://blog.trello.com/hs-fs/hubfs/how%20to%20use%20a%20decision%20journal.gif?width=500&amp;amp;name=how%20to%20use%20a%20decision%20journal.gif 500w, https://blog.trello.com/hs-fs/hubfs/how%20to%20use%20a%20decision%20journal.gif?width=750&amp;amp;name=how%20to%20use%20a%20decision%20journal.gif 750w, https://blog.trello.com/hs-fs/hubfs/how%20to%20use%20a%20decision%20journal.gif?width=1000&amp;amp;name=how%20to%20use%20a%20decision%20journal.gif 1000w, https://blog.trello.com/hs-fs/hubfs/how%20to%20use%20a%20decision%20journal.gif?width=1250&amp;amp;name=how%20to%20use%20a%20decision%20journal.gif 1250w, https://blog.trello.com/hs-fs/hubfs/how%20to%20use%20a%20decision%20journal.gif?width=1500&amp;amp;name=how%20to%20use%20a%20decision%20journal.gif 1500w" width="500" alt="how to use a decision journal" src="https://blog.trello.com/hs-fs/hubfs/how%20to%20use%20a%20decision%20journal.gif?width=500&amp;amp;name=how%20to%20use%20a%20decision%20journal.gif"&gt;&lt;/p&gt; &lt;h3&gt;&lt;strong&gt;2. Keep It Simple&lt;/strong&gt;&lt;/h3&gt; &lt;p&gt;Your decision journal should be used to evaluate your more complex decisions, but that doesn’t mean that the journal itself should be complicated.&lt;/p&gt; &lt;p&gt;Remember, you want this to be something that’s easy to refer back to and reflect on. Having pages and pages about every option you considered and every detail about your emotional state will only make this a cumbersome resource for you (meaning it’ll probably just collect dust in your desk drawer).&lt;/p&gt; &lt;p&gt;Use simple language, short sentences, and be as straightforward as possible when documenting your decisions and emotions. That will allow you to look back and get the information you really need—without wading through paragraphs of flowery language and unnecessary details.&amp;nbsp;&lt;/p&gt; &lt;h3&gt;&lt;strong&gt;3. Create A Simple Template For Yourself&lt;/strong&gt;&lt;/h3&gt; &lt;p&gt;One of the best ways to keep things simple is to create a template that you can use time and time again. It’ll prompt you to stay focused on the need-to-know information and remove a lot of the guesswork and ambiguity from the decision journaling process.&lt;/p&gt; &lt;p&gt;Whether you want to create a templated Trello card or start a simple document that you can keep copying, make sure that your decision journal template touches on the basics. Here’s what this could look like:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Date I made this decision: ___________________________&lt;/strong&gt;&lt;/li&gt; &lt;/ul&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;The decision I made was: ____________________________&lt;/strong&gt;&lt;/li&gt; &lt;/ul&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;I believe this decision will lead to: __________________&lt;/strong&gt;&lt;/li&gt; &lt;/ul&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Why I believe this decision will pan out this way: _____________________________________________________&lt;/strong&gt;&lt;/li&gt; &lt;/ul&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;How I feel about the decision I’ve made: ______________________________________________________&lt;/strong&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;See? Not so difficult after all. Of course, you’re welcome to add more to your own template if it helps you, but the point is to at least get a basic process in place. That’ll make the process of journaling less daunting—and make you way more likely to stick to it.&amp;nbsp;&lt;/p&gt; &lt;h3&gt;&lt;strong&gt;4. Review Your Journal Frequently&lt;/strong&gt;&lt;/h3&gt; &lt;p&gt;A decision journal isn’t about helping you make choices in the heat of the moment. It’s a record that you can refer back to in order to understand your blind spots and make better decisions moving forward.&lt;/p&gt; &lt;p&gt;So, that means you need to actually look back at it—and you should plan to do so frequently (aim for every quarter, at the very least).&lt;/p&gt; &lt;p&gt;Research shows that we all tend to have an inflated view of our own performance. In &lt;a rel="nofollow noopener" href="https://www.npr.org/templates/story/story.php?storyId=15073430"&gt;one study&lt;/a&gt;, engineers were asked if they believed they were in the top 5% of the engineers at their company, and a whopping 40% of them said “yes.”&lt;/p&gt; &lt;p&gt;And, even further, our own self-ratings aren’t correlated with positive performance. A &lt;a rel="nofollow noopener" href="https://www.npr.org/templates/story/story.php?storyId=15073430"&gt;separate study&lt;/a&gt; of physicians found that things like supervisor and peer ratings of surgical residents were fairly accurate in predicting whether or not residents would perform well on their board exams, but there was zero relationship between self-ratings and their exam success.&lt;/p&gt; &lt;p&gt;“We apply a lot of positive spin to evidence we get about ourselves,” explains David Dunning, a Professor of Psychology at Cornell University, in an &lt;a rel="nofollow noopener" href="https://www.npr.org/templates/story/story.php?storyId=15073430"&gt;interview with NPR&lt;/a&gt; about both studies. “People obviously want to think pleasant things about themselves. They want to avoid thinking threatening things about themselves.”&lt;/p&gt; &lt;p&gt;In short, we aren’t great at honestly evaluating ourselves, which means we probably won’t be able to spot our decision-making weaknesses and pitfalls on our own.&amp;nbsp;&lt;/p&gt; &lt;p&gt;&lt;img alt="following your own advice" src="https://blog.trello.com/hubfs/following%20your%20own%20advice.gif"&gt;&lt;/p&gt; &lt;p&gt;If you answer honestly and follow your prompts, your decision journal will serve as an unbiased third party that will equip you with valuable feedback—provided you make the time to lean on it frequently, of course.&amp;nbsp;&lt;/p&gt; &lt;p&gt;When it’s time for you to review your entries, give yourself some quiet, focused time to reflect:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Are there mistakes you see yourself making again and again?&lt;/li&gt; &lt;li&gt;Are there certain types of decisions that make you feel more anxious than others?&lt;/li&gt; &lt;li&gt;What about the types of decisions that inspire a lot of confidence?&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;This time for self-reflection is more than just a feel-good exercise, as you’ll quickly identify areas of improvement. And, the more you do that, the better you’ll get at making choices—which will help you kick that pesky decision fatigue we mentioned earlier to the curb.&amp;nbsp;&lt;/p&gt; &lt;h2&gt;&lt;strong&gt;Flex Those Decision-Making Muscles And Put Pen To Paper&amp;nbsp;&lt;/strong&gt;&lt;/h2&gt; &lt;p&gt;The “choose your own adventure” books of your childhood were fun. But, in real life, needing to make decision after decision can be draining and ultimately lead to some lackluster choices.&lt;/p&gt; &lt;p&gt;That’s why a decision journal should be your not-so-secret weapon. It’ll give you some helpful insight into your own decision-making process, so you can improve your selections moving forward.&amp;nbsp;&lt;/p&gt; &lt;p&gt;While it’s not designed to help you pick between that turkey sandwich or burrito, it will help you approach your larger, real-life decisions with as much certainty as you had when you were a kid choosing which page to flip to.&amp;nbsp;&lt;/p&gt; &lt;hr&gt; &lt;p&gt;&lt;em&gt;Good or bad, we'd love to hear your thoughts. Find us on Twitter (&lt;a data-ol-has-click-handler="" rel="nofollow noopener" href="https://twitter.com/trello"&gt;@trello&lt;/a&gt;) or write in to&amp;nbsp;&lt;a data-ol-has-click-handler="" rel="nofollow noopener" href="mailto:support@trello.com"&gt;support@trello.com&lt;/a&gt;&amp;nbsp;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Next:&lt;/strong&gt; &lt;em&gt;&lt;a rel="noopener" href="https://blog.trello.com/do-not-have-a-plan"&gt;Feeling Uncertain? How To Move Forward Without A Plan&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&lt;/span&gt; &lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://blog.trello.com/decision-journal"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Fri, 27 Mar 2020 17:16:05 UT
      </pubDate>
      <guid>
        https://blog.trello.com/decision-journal
      </guid>
    </item>
    <item>
      <title>
        How Scientists Can Thrive in the Startup World: Academia to Startup, Becoming a Founder, Science + Biotech | Y Combinator
      </title>
      <link>
        https://blog.ycombinator.com/science-startups/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;&lt;p&gt;&lt;strong&gt;When Dave Messina entered a graduate program for genomics in 1998, he was elated. He was taking the first steps of what could be a career at a top-tier university, working on scientific research that could impact millions of lives.&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;But while his chosen field had so much promise, he realized that for him, the academic environment might not.&lt;/p&gt; &lt;p&gt;“I looked around, and saw that some of the smartest scientists I'd ever met were having trouble getting funded, and moving forward in their research,” Messina says. “The life of an academic scientist is really hard. You’ve got to really, really want it. And even then, for many people it just doesn’t work out.”&lt;/p&gt; &lt;p&gt;&lt;img height="1466" width="2500" src="https://ycombinator.wpengine.com/wp-content/uploads/2016/10/transcriptic-workcell.jpg"&gt; Transcriptic&lt;/p&gt; &lt;p&gt;Messina quickly realized that the best way for him to succeed in the field of genomics might be to work outside of academia altogether. At that time, though, there wasn’t a clear path to follow.&lt;/p&gt; &lt;p&gt;“I thought, ‘Maybe I can get into a company, and move my way up so that I can dig into important research there.’ So I talked to a lot of people,” he says. “They all knew of someone who had tried it at a larger biotech corporation, but it definitely was the exception.”&lt;/p&gt; &lt;p&gt;So Messina created the path for himself. He eventually pulled back from the PhD track in genetics at Washington University in St. Louis, and instead obtained a Masters Degree. He went on to earn his PhD in computational biology, opting to concentrate on the software that does the heavy lifting in genome analysis. And in 2012, he joined RNA sequencing software startup &lt;a href="https://cofactorgenomics.com/"&gt;Cofactor Genomics&lt;/a&gt;, where he now serves as COO.&lt;/p&gt; &lt;p&gt;Today, Messina says that startups are an increasingly viable place for the kinds of research careers that used to be found only in the ivory tower and big corporations.&lt;/p&gt; &lt;p&gt;He’s not alone in that belief. Y Combinator has funded an increasing number of startups with biotech and life sciences applications, many of which are led by founders who have crossed over from years in the academic realm. Since 2014 alone, more than 24 startups with a biotech or life sciences focus have launched out of the YC program. The wider field of Silicon Valley investors has also developed a heightened interest in the space, with firms such as Andreessen Horowitz launching &lt;a href="http://a16z.com/2015/11/18/bio-fund/"&gt;new funds&lt;/a&gt; dedicated entirely to investing in biotech and life sciences startups.&lt;/p&gt; &lt;p&gt;Below are some insights and lessons learned from several founders from this new breed of science-oriented startups on how to navigate the path between academia and Silicon Valley.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Analyzing risk&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;The first step for many people leaving the realm of traditional academic research and entering the startup space is assessing the risks of making such a change. The odds may not be as daunting as they may expect.&lt;/p&gt; &lt;p&gt;"Coming from academia, there's a myth that it's really risky to join a startup, and in my experience that's not true at all," Messina says. "It depends on the field, but look at the Genome Institute at Washington University in St. Louis, which is a premiere organization. Just a few weeks ago, they didn't get a big grant that they were expecting to get, and they had to lay off 20 percent of their workforce. The good news now is that there are companies and startups around who are hiring those people."&lt;/p&gt; &lt;p&gt;&lt;img height="733" width="1100" src="https://ycombinator.wpengine.com/wp-content/uploads/2016/10/cofactor-lab.jpg"&gt; Cofactor Genomics&lt;/p&gt; &lt;p&gt;That said, there are a number of options for scientists to weigh. "You don't have to jump in all the way and say you're going to start a company immediately. There's a whole continuum," Messina says. He recommends that current PhD and postdoctoral candidates take on part-time roles at startups through programs such as the St. Louis-based &lt;a href="http://thebalsagroup.org/"&gt;BALSA Group&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;For those who have decided to launch a science-oriented startup, it's also important to consider the inherent risks of your product and approach.&lt;/p&gt; &lt;p&gt;"If you're someone coming from a PhD or postdoc background with an idea for a startup, it's so important that you reduce your technical risk," says Max Hodak, the co-founder of robotic bio lab startup &lt;a href="https://www.transcriptic.com/"&gt;Transcriptic&lt;/a&gt;. "Otherwise, you might spend a lot of time and money trying to find some novel pathway, and then find it's not there."&lt;/p&gt; &lt;p&gt;Not being clear-eyed about your startup's technical risks could lead to a crunch in funding, Hodak says. "Venture capitalists say they want to invest in hard tech, but VCs hate technical risk. They're comfortable with market risk, but technical risk is really difficult for them to reconcile. In biotech, a lot of founders have more technical risk than they think they do."&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Adjust your time scales&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Thanks to advances in both computing and equipment, it's now affordable for startups to perform the kinds of lab research that would not have been possible outside of large institutions even five years ago, says Matt De Silva, the founder of personalized brain cancer treatment startup &lt;a href="https://www.notablelabs.com/"&gt;Notable Labs&lt;/a&gt;. But, he says, there are key differences in how a lab should operate at a startup versus a traditional research environment.&lt;/p&gt; &lt;p&gt;"There are certain aspects of academia that are very useful in a startup: the creativity, the looking at things from first principles, the open-mindedness," De Silva says. "But the big challenges are the time scales and the quality expectations. For a startup, work needs to be both faster and more rigorous than an academic lab. In academia, in order to publish a paper, often you just have to get it to work one time out of ten -- so you think, OK, I'll just keep doing the experiment until it works. We need it to work nine or ten times out of ten. If something from a paper doesn't bear out, the impact can be mitigated. If you have a product you're developing, it can be a disaster."&lt;/p&gt; &lt;p&gt;&lt;img height="400" width="652" src="https://ycombinator.wpengine.com/wp-content/uploads/2016/10/ubiome-lab.jpg"&gt; uBiome&lt;/p&gt; &lt;p&gt;Jessica Richman, the co-founder and CEO of human microbiome testing startup &lt;a&gt;uBiome&lt;/a&gt;, agrees. "In academia, it's not uncommon to get a different result than expected and say 'Okay, let's come back to it in a month, and let's discuss it then.’ At a startup, that really doesn't work. You can wait and come back to it that afternoon, at the latest,” she says. “Think about what a 'hacker' was to traditional computer scientists. Startups need the life sciences equivalent of that."&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Communicate your idea&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;"The cultural differences between academia and startups cannot be overstated," uBiome's Richman says. "I tell scientists to approach the startup world like an anthropologist would: Read all the books you can, learn about the culture, observe the people, figure out how they do things. A lot of the books you’ll read will probably have bad startup advice, but you'll get a picture of the thought processes and the language."&lt;/p&gt; &lt;p&gt;Coming from academia, where projects are funded by grants, it can be a big change to go into investor-funded startups. "It's important to learn how to tell the story of a business, as opposed to the story of a grant," Richman says. Often, people successfully secure a grant by describing things that have been proven in existing scientific literature, and highlighting how their project fills a gap in the research that's been done. Startup investors aren't typically impressed by that narrative, she says. "The story of a business is about vision and progress: What are you going to do, how far have you gone so far, and how are you going to make money."&lt;/p&gt; &lt;p&gt;She says that the mores around raising funding are different from grants, too. "The whole funding environment for startups can be hard to navigate. You're used to applying to grants -- there's no having lunch with someone, they turn you down, but then they talk to a friend, then you hear that their friend wants to invest," Richman says. "In academia, there's no wheeling and dealing around the grant process. It's important to get used to that. I'll talk to founders who are coming from academia about their fundraising, and they'll say, 'I talked to 3 people and they all said no.' That's not how it works. You need to talk to 300 people. It's a sales process. Getting startup funding isn't about applying for something and sitting back and waiting."&lt;/p&gt; &lt;p&gt;Nailing communication is also key for hiring. Transcriptic's Hodak says that if you can quickly and clearly communicate what your startup does to someone without a life sciences or biotech background, you may find that it's easier to hire engineers than you might expect. "Sam Altman told me once that it's paradoxically easier to do a 'hard' startup than an easy one, because people want to help you. I've found that to be really true," he says. "I can't imagine in this environment trying to recruit for a social mobile app. That would blow my mind. But it's easier to get really good people when you can tell them you're building robots that are furthering the field of science."&lt;/p&gt; &lt;p&gt;&lt;img height="492" width="736" src="https://ycombinator.wpengine.com/wp-content/uploads/2016/10/cofactor-employee.jpg"&gt; Cofactor Genomics&lt;/p&gt; &lt;p&gt;Notable Labs' De Silva says that his company’s first full stack developer hire actually reached out to them, after reading about Notable’s mission of helping find a cure for brain cancer in the press. "There's a growing group of software engineers who are tired of using their skills to optimize ads,” De Silva says. “If you can communicate that if your company is successful, it will be directly impacting people's lives, great people will want to help you achieve that."&lt;/p&gt; &lt;p&gt;&lt;strong&gt;What shouldn't change&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;For all the differences between the two sectors, there are some things that should not change as scientists enter the startup environment.&lt;/p&gt; &lt;p&gt;"As the tech world is blending into the biotech world, founders and investors need to be conscious that the burden of proof in science is very high, and that won't change," Notable Labs’ De Silva says. "If you're a startup in this space, you need to be transparent, you need to run trials, you need to show your science works in all the same ways that traditional institutions have. Talking a big game, being secretive, and raising a huge amount of money sometimes works in software and web tech. But it's an inverse playbook in biotech. The stakes are higher, and people will hold you to that, as they should."&lt;/p&gt; &lt;p&gt;According to Transcriptic's Hodak, maintaining a healthy respect for the complexity of science and instilling it into the non-scientific team members and investors is crucial. "For people not coming from a science background, it's easy to underestimate how difficult these things are,” Hodak says. "There are a lot of people from the tech sector seeing the opportunities here but underestimating the technical complexity. Yes, there's a lot of opportunity, and a lot of improvement to be had, but it's very complicated in non-obvious ways."&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://blog.ycombinator.com/science-startups/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Fri, 27 Mar 2020 18:25:41 UT
      </pubDate>
      <guid>
        https://blog.ycombinator.com/science-startups/
      </guid>
    </item>
    <item>
      <title>
        New grad vs senior dev | Fabulous adventures in coding
      </title>
      <link>
        https://ericlippert.com/2020/03/27/new-grad-vs-senior-dev/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt; &lt;p&gt;A student who I used to tutor in CS occasionally sent me a meme yesterday which showed “NEW GRAD vs SENIOR DEVELOPER”; the new grad is all caps yelling&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;NO! YOU CAN’T JUST USE BRUTE FORCE HERE! WE NEED TO USE SEGMENT TREES TO GET UPDATE TIME COMPLEXITY DOWN TO O(LOG N)! BREAK THE DATA INTO CHUNKS AT LEAST! OH THE INEFFICIENCY!!!&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;and the senior developer responds&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;Ha ha, nested for loops go brrrrrrrrrrrr…&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;OK, that’s silly and juvenile, but… oh no, I feel a flashback coming on.&lt;/p&gt; &lt;p&gt;…&lt;/p&gt; &lt;p&gt;…&lt;/p&gt; &lt;p&gt;…&lt;/p&gt; &lt;p&gt;It is 1994 and I am a second-year CS student at my first internship at Microsoft on the Visual Basic compiler team, reading the source code for InStr for the first time. InStr is the function in Visual Basic that takes two strings, call them &lt;strong&gt;source&lt;/strong&gt; and &lt;strong&gt;query&lt;/strong&gt;, and tells you the index at which &lt;strong&gt;query&lt;/strong&gt; first appears as a substring of &lt;strong&gt;source&lt;/strong&gt;, and the implementation is naive-brute-force.&lt;/p&gt; &lt;p&gt;I am shocked to learn this! Shocked, I tell you!&lt;/p&gt; &lt;p&gt;Let me digress slightly here and say what the naive brute force algorithm is for this problem.&lt;/p&gt; &lt;hr&gt; &lt;p&gt;Aside: To keep it simple we’ll ignore all the difficulties inherent in this problem entailed by the fact that VB was the first Microsoft product where one version worked everywhere in the world on every version of Windows no matter how Windows was localized; systems that used Chinese DBCS character encodings ran the same VB binary as systems that used European code pages, and we had to support all these encodings plus Unicode UTF-16. As you might imagine, the string code was a bit of a mess. (And cleaning it up in VBScript was one of my first jobs as an FTE in 1996!)&lt;/p&gt; &lt;p&gt;Today for simplicity we’ll just assume we have a flat, zero-terminated array of chars, one character per char as was originally intended.&lt;/p&gt; &lt;hr&gt; &lt;p&gt;The &lt;em&gt;extremely&lt;/em&gt; naive algorithm for finding a string in another goes something like this pseudo-C algorithm:&lt;/p&gt; &lt;pre&gt;bool starts(char *source, char *query) { int i = 0; while (query[i] != '\0') { if (source[i] != query[i]) return false; i = i + 1; } return true; } int find(char *source, char *query) { int i = 0; while (source[i] != '\0') { if (starts(source + i, query)) return i; i = i + 1; } return -1; }&lt;/pre&gt; &lt;p&gt;The attentive reader will note that this is the aforementioned &lt;strong&gt;nested for loop&lt;/strong&gt;; I’ve just extracted the nested loop into its own helper method. The extremely attentive reader will have already noticed that I wrote a few bugs into the algorithm above; what are they?&lt;/p&gt; &lt;p&gt;Of course there are many nano-optimizations one can perform on this algorithm if you know a few C tips and tricks; again, we’ll ignore those. It’s the algorithmic complexity I’m interested in here.&lt;/p&gt; &lt;p&gt;The action of the algorithm is straightforward. If we want to know if query “banana” is inside source “apple banana orange” then we ask:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;does “apple banana orange” start with “banana”? No.&lt;/li&gt; &lt;li&gt;does “pple banana orange” start with “banana”? No.&lt;/li&gt; &lt;li&gt;does “ple banana orange” start with “banana”? No.&lt;/li&gt; &lt;li&gt;…&lt;/li&gt; &lt;li&gt;does “banana orange” start with “banana”? Yes! We’re done.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;It might not be clear why the naive algorithm is bad. The key is to think about what the worst case is. The worst case would have to be one where there is no match, because that means we have to check the most possible substrings. Of the no-match cases, what are the worst ones? The ones where &lt;strong&gt;starts&lt;/strong&gt;&amp;nbsp;does the most work to return false.&amp;nbsp; For example, suppose &lt;strong&gt;source&lt;/strong&gt; is “aaaaaaaaaaaaaaaaaaaa” — twenty characters — and &lt;strong&gt;query&lt;/strong&gt; is “aaaab”. What does the naive algorithm do?&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Does “aaaaaaaaaaaaaaaaaaaa” start with “aaaab”? No, but it takes five comparisons to determine that.&lt;/li&gt; &lt;li&gt;Does “aaaaaaaaaaaaaaaaaaa” start with “aaaab”? No, but it takes five comparisons to determine that.&lt;/li&gt; &lt;li&gt;… and so on.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;In the majority of attempts it takes us the maximum number of comparisons to determine that the &lt;strong&gt;source&lt;/strong&gt; substring does not start with the &lt;strong&gt;query&lt;/strong&gt;. The naive algorithm’s worst case is O(n*m) where n is the length of &lt;strong&gt;source&lt;/strong&gt; and m is the length of the &lt;strong&gt;query&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;There are a lot of obvious ways to make minor improvements to the extremely naive version above, and in fact the implementation in VB was slightly better. The implementation in VB was basically this:&lt;/p&gt; &lt;pre&gt;char* skipto(char *source, char c) { char *result = source; while (*result != '\0' &amp;amp;&amp;amp; *result != c) result = result + 1; return result; } int find(char *source, char *query) { char *current = skipto(source, query[0]); while (*current != '\0;) { if (starts(current, query)) return current - source; current = skipto(current + 1, query[0]); } return -1; }&lt;/pre&gt; &lt;p&gt;(WOW, EVEN MORE BUGS! Can you spot them? It’s maybe easier this time.)&lt;/p&gt; &lt;p&gt;This is more complicated but not actually better algorithmically; all we’ve done is moved the initial check in &lt;strong&gt;starts&lt;/strong&gt;&amp;nbsp;that checks for equality of the first letters into its own helper method. In fact, what the heck, this code looks &lt;em&gt;worse&lt;/em&gt;. It does &lt;em&gt;more work&lt;/em&gt; and is &lt;em&gt;more complicated&lt;/em&gt;. What’s going on here? We’ll come back to this.&lt;/p&gt; &lt;p&gt;As I said, I was a second year CS student and (no surprise) a bit of a keener; I had read ahead and knew that there were string finding algorithms that are considerably better than O(n*m). The basic strategy of these better algorithms is to do some preprocessing of the strings to look for interesting features that allow you to “skip over” regions of the source string that you know cannot possibly contain the query string.&lt;/p&gt; &lt;p&gt;This is a heavily-studied problem because, first off, obviously it is a “foundational” problem; finding substrings is useful in many other algorithms, and second, because we genuinely do have extremely difficult problems to solve in this space. “Find this DNA fragment inside this genome”, for example, involves strings that may be billions of characters long with lots of partial matches.&lt;/p&gt; &lt;p&gt;I’m not going to go into the various different algorithms that are available to solve this problem and their many pros and cons; you can &lt;a href="https://en.wikipedia.org/wiki/String-searching_algorithm#Single-pattern_algorithms"&gt;read about them on Wikipedia&lt;/a&gt; if you’re interested.&lt;/p&gt; &lt;p&gt;Anyways, where was I, oh yes, &lt;strong&gt;CS student summer intern vs Senior Developer&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;I read this code and was outraged that it was not the most asymptotically efficient possible code, so I got a meeting with Tim Paterson, who had written much of the string library and had the office next to me.&lt;/p&gt; &lt;p&gt;Let me repeat that for those youngsters in the audience here, &lt;strong&gt;TIM FREAKIN’ PATERSON.&lt;/strong&gt; Tim “QDOS” Paterson, who one fine day wrote an operating system, sold it to BillG, and that became MS-DOS,&lt;em&gt; the most popular operating system in the world.&lt;/em&gt; &lt;a href="https://ericlippert.com/2003/09/26/what-could-numeric-rounding-possibly-have-to-do-with-ms-dos/"&gt;As I’ve mentioned before, Tim was very intimidating to young me and did not always suffer foolish questions gladly&lt;/a&gt;, but it turned out that in this case he was very patient with all-caps THIS IS INEFFICIENT Eric. More patient than I likely deserved.&lt;/p&gt; &lt;p&gt;As Tim explained to me, first off, the reason why VB does this seemingly bizarre “find the first character match, then check if &lt;strong&gt;query&lt;/strong&gt; is a prefix of &lt;strong&gt;source&lt;/strong&gt;” logic is because the &lt;strong&gt;skipto&lt;/strong&gt;&amp;nbsp;method is not written in the naive fashion that I showed here. &lt;strong&gt;The skipto method is a single x86 machine instruction.&lt;/strong&gt; (&lt;strong&gt;REPNE SCASB,&lt;/strong&gt; maybe? My x86 machine code knowledge was never very good. It was something in the &lt;strong&gt;REP&lt;/strong&gt; family at least.) It is &lt;em&gt;blazingly&lt;/em&gt; fast. It harnesses the power of purpose-built hardware to solve the problem of “where’s that first character at?”&lt;/p&gt; &lt;p&gt;That explains that; it genuinely is a big perf win to let the hardware do the heavy lifting here. But what about the asymptotic problem? Well, as Tim patiently explained to me, guess what? Most VB developers are NOT asking if “aaaab” can be found in “aaaaaaa…”. The vast majority of VB developers are asking is “London” anywhere in this address, or similar problems where the strings are normal human-language strings without a lot of repetitions, and both the source and query strings are &lt;em&gt;short&lt;/em&gt;.&amp;nbsp; Like, very short. Less than 100 characters short. Fits into a cache line short.&lt;/p&gt; &lt;p&gt;Think about it this way; most &lt;strong&gt;source&lt;/strong&gt; strings that VB developers are searching have any given character in them maybe 2% of the time, and so for whatever the start character is of the &lt;strong&gt;query&lt;/strong&gt; string, the &lt;strong&gt;skipto&lt;/strong&gt;&amp;nbsp;step is going to find those 2% of possible matches &lt;em&gt;very quickly&lt;/em&gt;. And then the &lt;strong&gt;starts&lt;/strong&gt;&amp;nbsp;step is the vast majority of the time going to &lt;em&gt;very quickly&lt;/em&gt; identify false matches. &lt;strong&gt;In practice the naive brute force algorithm is almost always O(n + m).&amp;nbsp;&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Moreover, Tim explained to me, any solution that involves allocating a table, preprocessing strings, and so on, is going to take longer to do all that stuff than the blazingly-fast-99.9999%-of-the-time brute force algorithm takes to just give you the answer. The additional complexity is simply not worth it in scenarios that are relevant to VB developers. VB developers are developing line-of-business solutions, and their line of business is not typically genomics; if it is, they have special-purpose libraries for those problems; they’re not using &lt;strong&gt;InStr&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;…&lt;/p&gt; &lt;p&gt;…&lt;/p&gt; &lt;p&gt;…&lt;/p&gt; &lt;p&gt;And we’re back in 2020. I hope you enjoyed that trip down memory lane.&lt;/p&gt; &lt;p&gt;It turns out that yes, fresh grads and keener interns &lt;em&gt;do&lt;/em&gt; complain to senior developers about asymptotic efficiency, and senior developers &lt;em&gt;do&lt;/em&gt; say “but nested for loops go &lt;em&gt;brrrrrrr&lt;/em&gt;” — yes, they go &lt;em&gt;brrrrrr&lt;/em&gt; extremely quickly much of the time, and senior developers know that!&lt;/p&gt; &lt;p&gt;And now I am the senior developer, and I try to be patient with the fresh grads as my mentors were patient with me.&lt;/p&gt; &lt;hr&gt; &lt;p&gt;UPDATE: Welcome, Hacker News readers. I always know when I’m linked from Hacker News because of the huge but short-lived spike in traffic. &lt;a href="https://news.ycombinator.com/item?id=22712178"&gt;The original author of the meme that inspired this post has weighed in&lt;/a&gt;. Thanks for inspiring this trip back to a simpler time!&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://ericlippert.com/2020/03/27/new-grad-vs-senior-dev/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sat, 28 Mar 2020 15:11:56 UT
      </pubDate>
      <guid>
        https://ericlippert.com/2020/03/27/new-grad-vs-senior-dev/
      </guid>
    </item>
    <item>
      <title>
        Radical Solutions • Damn Interesting
      </title>
      <link>
        https://www.damninteresting.com/radical-solutions/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;p&gt;© All Rights Reserved. Please do not distribute without written permission from Damn Interesting.&lt;/p&gt;&lt;article&gt; &lt;p&gt;Paris, 29 May 1832. All through the night, a young Frenchman named Évariste Galois stayed awake, quill in hand, frantically scrawling notes and equations across dozens of sheets of paper. He had only been studying mathematics seriously for a few years, but he had proven to be a veritable prodigy. After quickly exhausting the knowledge of his teachers, he’d branched out into his own research, extraordinarily prescient.&lt;/p&gt; &lt;p&gt;By all rights, Galois ought to have been lauded and laurelled by the scientific community for his work. Above all, he should have been recognised and rewarded by France’s prestigious Academy of Sciences. But Galois⁠—at least, by his own reckoning⁠—had received little but dismissal from the mathematics community. Now he sat feverishly scribbling a letter to his best friend, trying to commit as many of his recent ideas to paper as possible. Finally, in the wee hours of the morning, Galois had sketched out most of what he felt able to capture. “You know … that these aren’t the only subjects I’ve explored,” he wrote. “But I don’t have time”. Twenty-year-old Galois fully expected that he was about to be shot to death. &lt;/p&gt; &lt;p&gt; Évariste Galois was born on 25 October 1811 in the town of Bourg-la-Reine, today part of the southern suburbs of Paris. Although his parents ran a well-regarded boarding school of their own, they sent young Évariste to study in Paris shortly before he turned twelve to improve his social opportunities.&lt;/p&gt; &lt;p&gt;Galois’s new school, the &lt;i&gt;Collège royal de Louis-le-Grand&lt;/i&gt; was and remains prestigious, but in the early 19th century, it boasted not only an unparalleled list of alumni⁠—among them such luminaries as Voltaire and Charles-Marie de La Condamine⁠—but also a fearsomely draconian atmosphere. Meals were meagre, facilities failing, cold constant, rats regular, and punishments painful, with the students under constant surveillance. The punitive environment⁠—plus homesickness and health issues⁠—took its toll on Galois. In his third year, his grades began to drop, and he earned a reputation as a loner and a troublemaker. One teacher labelled him a “chatterer” who “has, I believe, taken upon himself the task of wearing me out”. That said, Galois’s time at the school would soon lead to two major upheavals in the 14-year-old’s life⁠—one political, the other intellectual.&lt;/p&gt; &lt;figure data-embiggen="true"&gt;&lt;p&gt;&lt;img title="Evariste Galois, drawn from memory by his brother" alt="Evariste Galois, drawn from memory by his brother" data-lazy-load-src="https://damn-8791.kxcdn.com/wp-content/uploads/2020/03/Evariste-Galois.jpg" data-height-ratio="1.3636363636364" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAMAAAAoyzS7AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAAZQTFRFgYGBAAAAqeg2zgAAAAxJREFUeNpiYAAIMAAAAgABT21Z4QAAAABJRU5ErkJggg=="&gt;&lt;/p&gt;&lt;figcaption&gt;Evariste Galois, drawn from memory by his brother&lt;/figcaption&gt;&lt;/figure&gt; &lt;p&gt;Galois grew up at the tail-end of France’s revolutionary and Napoleonic years, which had infused the country’s intellectual bloodstream with liberal ideas. Despite the restored monarchy’s attempts to crack down on this unseemly radicalism, the school had developed a liberal reputation. A new school principal, Nicolas Berthot, thought this merited a course correction, and set about inaugurating new rules harkening back to the school’s harsh old Jesuit roots. In response, students undertook a campaign of nonviolent resistance⁠—when asked to sing hymns, speak in class, or toast the King at meals, they remained mute. Berthot, apparently not one for half measures, simply expelled the students⁠—over 100 of them. While Galois was not directly involved, he was appalled by Berthot’s peremptory reaction. It was in this atmosphere of injustice and oppression that young Galois began his shift from mere liberal-minded student to full-blown anti-authoritarian.&lt;/p&gt; &lt;p&gt;In contrast, Galois’s academic upheaval was due to a happy convergence between an academic restructuring and his own academic failure. With his grades plummeting, he was forced to repeat his entire third year. This cannot have been welcome news, but there was an unexpected upside. The third-year curriculum had just been changed, and would now introduce students to arithmetic and geometry alongside their continued study of the classics. Galois was about to meet mathematics. Few blind dates have gone so well.&lt;/p&gt; &lt;p&gt;Instantly sparked, the 15-year-old devoured entire textbooks on algebra, calculus, and geometry. Galois’s other classes, already somewhat neglected, fell off his radar almost entirely. Faculty soon abandoned all hope of getting any other subject into his brain.&lt;/p&gt; &lt;p&gt;Galois leapt straight into a heavily intuitive, original approach to tackling big unanswered questions. His concerned teachers suggested that he outline his problem-solving more methodically, or at least follow the basics of showing his work, but he was not interested in such elementary claptrap. Within mere months, he had outgrown his coursework and reached the extremities of contemporary mathematical knowledge. &lt;/p&gt; &lt;p&gt;Fully aware of his own preternatural talent, Galois set his sights on attending the &lt;i&gt;École polytechnique&lt;/i&gt;⁠—France’s foremost technical school⁠—as soon as possible. As he was nearing 16, the minimum age of admission, he registered for the entrance exam immediately. Nearly as immediately, he failed. Still, failing the entrance exam was nothing to be ashamed of. Many students went into their first attempts seeking only to get a sense of how the exam worked⁠—which made sense, as it was a fast-paced verbal interrogation at a blackboard. Just one in three examinees passed on their first try. Though Galois’s failure forced him to remain at Louis-le-Grand, he could at least console himself that this was only a temporary setback.&lt;/p&gt; &lt;p&gt;A further consolation appeared in the form of an enthusiastic new mathematics teacher who grasped the scope of Galois’s ideas and quickly became his mentor. Under this mentor’s guidance, in April 1829, 17-year-old Galois published a short paper on repeating fractions in a respected scholarly journal. Impressive though this was, for Galois this was only a side-project, dwarfed by breakthroughs he was making in the area of polynomial equations. This was a big deal. Mathematicians had collectively hit a wall with polynomials late in the 18th century, and Galois was about to suggest a way over.&lt;/p&gt; &lt;p&gt;For people who remember algebra classes, the most familiar type of polynomial is the &lt;i&gt;quadratic equation&lt;/i&gt;, which can be useful in calculating areas, solving some accounting tasks, and addressing some physics problems. It is generally written as: &lt;/p&gt; &lt;center&gt;&lt;i&gt;ax&lt;sup&gt;2&lt;/sup&gt; + bx + c = 0&lt;/i&gt;&lt;/center&gt; &lt;p&gt;“X” is the single unknown value to solve for. There are multiple ways of figuring out the possible value(s) for &lt;i&gt;x&lt;/i&gt;, but one reliable way is by taking &lt;i&gt;a&lt;/i&gt;, &lt;i&gt;b&lt;/i&gt;, and &lt;i&gt;c&lt;/i&gt; and plugging them into a formula that was discovered by Spanish mathematician Abraham bar Hiyya Ha-Nasi around the year 1100 AD. It is fittingly known as the &lt;i&gt;quadratic formula&lt;/i&gt;:&lt;/p&gt; &lt;center&gt;&lt;img height="94" width="340" src="https://www.damninteresting.com/wp-content/uploads/2020/03/quadratic-equation-340x94.png"&gt;&lt;/center&gt; &lt;p&gt;What makes a quadratic equation ‘quadratic’ is that &lt;i&gt;x&lt;/i&gt; is squared, or to the power of 2. So a quadratic equation is said to have a &lt;i&gt;degree&lt;/i&gt; of 2. An equation where &lt;i&gt;x&lt;/i&gt; is to the power of 3 (but nothing more) has a degree of 3, and these are called &lt;i&gt;cubic equations&lt;/i&gt;, which look like this:&lt;/p&gt; &lt;center&gt;&lt;i&gt;ax&lt;sup&gt;3&lt;/sup&gt; + bx&lt;sup&gt;2&lt;/sup&gt; + cx + d = 0&lt;/i&gt;&lt;/center&gt; &lt;p&gt;The quadratic formula doesn’t help with cubic equations, but a working &lt;i&gt;cubic formula&lt;/i&gt; was discovered sequentially by three Italian mathematicians in the 16th century. A student of one of theirs went one further, literally, managing to find an enormously complicated general formula for &lt;i&gt;quartic equations&lt;/i&gt;⁠—those of degree 4.&lt;/p&gt; &lt;p&gt;The outstanding question Galois wished to tackle was: Is there a formula to solve &lt;i&gt;quintic equations&lt;/i&gt;, i.e. those of degree 5? Prominent mathematicians of the day suspected that a general solution for quintic equations simply did not exist. However, a mere failure to find such a formula was not evidence. Italian mathematician Paolo Ruffini came close to proving that no such general solution existed for 5th-degree equations, which he published in a paper in 1799.&lt;/p&gt; &lt;p&gt;Picking up more or less where Ruffini left off, 17-year-old Galois set out to prove that no general formula existed for quintic equations. More broadly, Galois took an interest in an overarching question: what determined &lt;i&gt;whether or not&lt;/i&gt; a general formula exists for a given degree?&lt;/p&gt; &lt;p&gt;Galois’s approach to untangling the matter was stunningly original. He tied equations to several major new conceptual frames. He identified &lt;i&gt;groups&lt;/i&gt;: sets of entities linked by a specific set of certain properties. Then &lt;i&gt;permutations&lt;/i&gt;: all the different ways of ordering the members of a set. And &lt;i&gt;symmetries&lt;/i&gt;: ways in which entities look like other parts of themselves. There was so much uncharted territory here that Galois found himself inventing a brand-new approach to algebra. The system he devised for describing the subtle internal characteristics of groups⁠—&lt;i&gt;group theory&lt;/i&gt;⁠—was almost unprecedented, but so versatile that it could capture the behaviour of not only numbers, but all sorts of grouped items and ways in which their components showed self-similarity. When it came to polynomials, Galois’s major insight was that solvability of a given equation ultimately had far less to do with the equation’s degree, and far more to do with its internal properties related to symmetry. Astrophysicist and popular-mathematics author Mario Livio offers this analogy:&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;“Classifying equations by their degree is analogous to grouping the wooden building blocks in a toy box according to their sizes. Galois’s classification by symmetry properties is equivalent to the realization that the shape of the blocks⁠—round, square, or triangular⁠—was a more important characteristic.”&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;Using his own new group theory to break a complicated polynomial equation into smaller pieces and test &lt;i&gt;those&lt;/i&gt; for solvability, Galois showed definitively that quintic equations, considered as a set, would not resolve this way. His results gave mathematics a way of determining &lt;i&gt;whether&lt;/i&gt; a particular polynomial can be solved through a formula. All polynomials of degrees 2, 3, and 4 qualified. Starting at degree 5, however, some did and others did not⁠—and thus there was no way a general solution could apply to all of them.&lt;/p&gt; &lt;figure data-embiggen="true"&gt;&lt;p&gt;&lt;img title="A depiction of Paris, 1829, by Giuseppe Canella" alt="A depiction of Paris, 1829, by Giuseppe Canella" data-lazy-load-src="https://damn-8791.kxcdn.com/wp-content/uploads/2020/03/GiuseppeCanella-PlaceLouisXVI-1829.jpg" data-height-ratio="0.70588235294118" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAMAAAAoyzS7AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAAZQTFRFgYGBAAAAqeg2zgAAAAxJREFUeNpiYAAIMAAAAgABT21Z4QAAAABJRU5ErkJggg=="&gt;&lt;/p&gt;&lt;figcaption&gt;A depiction of Paris, 1829, by Giuseppe Canella&lt;/figcaption&gt;&lt;/figure&gt; &lt;p&gt;Galois’s mentor Louis Richard, for one, was well-aware that the boy’s ideas were visionary. Richard decided to help his brilliant protégé submit two papers to the Academy of Sciences in the spring of 1829. Getting the Academy’s attention was an essential step for any aspiring mathematician in France at the time. It was the most prestigious scientific organisation in the country, and having a paper accepted there would be a spectacular feather in Galois’s cap. It wouldn’t hurt when it came to his second attempt at being admitted to the Polytechnique, either.&lt;/p&gt; &lt;p&gt;Only members of the Academy could present new findings to the august body, so Galois needed to find a willing sponsor to present papers on his behalf. Richard reached out to the revered Augustin-Louis Cauchy, likely because 15 years earlier, Cauchy had published two papers on general theories of permutations. Cauchy, one of the most prolific mathematicians in history, rarely had time to read and endorse other people’s work⁠—but in this case, against the odds, he agreed. In May and June 1829, he presented a pair of complementary papers by Galois to the Academy of Sciences, and made plans to present a third in January 1830.&lt;/p&gt; &lt;p&gt;But the thrill was about to be brutally crushed. A new priest had been assigned to Galois’s hometown of Bourg-la-Reine, one who immediately clashed with its liberal and warmhearted mayor⁠—who happened to be Galois’s father, Nicolas-Gabriel Galois. Determined to save the souls of his parish from the insidious influences of broad-mindedness and insufficient monarchism, the priest devised a plan to undermine the elder Galois and force him out of office. The well-liked Nicolas-Gabriel had a fondness for playful writing at times – delighting the townsfolk with short coupled rhymes. Taking note of this idiosyncracy, the priest began to author his own rhyming couplets in the mayor’s characteristic style, making them mean-spirited rather than playful, and signing them with Nicolas-Gabriel’s name. The slanderous counterfeits spread. Ultimately, the plot proved even more successful than the priest had hoped. In July 1829, devastated by the impersonation and by the loss of his good name, Nicolas-Gabriel Galois took his own life. He had been the mayor of the town for 15 years.&lt;/p&gt; &lt;p&gt;The truth quickly emerged. Astoundingly, the priest attempted to take part in the funeral ceremony⁠—only to find himself fleeing a mob of furious townspeople and volleys of stones. Galois witnessed the entire scene, and his grief and rage can only be imagined. He had already had reason to resent and oppose his country’s religious right wing: the political had now become intensely personal.&lt;/p&gt; &lt;p&gt;And then, with spectacularly bad timing, the next round of entrance exams for the École polytechnique was upon him. Galois⁠—short-tempered at the best of times, labouring under the emotional toll of his father’s death, convinced of his own genius, already bitter at the perceived injustice of having been rejected the first time around⁠—was in no state to deal with a second high-stakes examination at a blackboard. He was never at his best explaining ideas verbally in the first place, and he had spent the year working on original research rather than preparing for the examination. On top of that, Galois’s examiner was a man known for asking extremely simple questions⁠—not to test candidates’ knowledge, but to gauge their reaction to being asked them. Faced with an examiner who struck him as blitheringly ignorant, Galois did not do well. Unverified legend has long claimed that the exam came to an end when the candidate flung the eraser at the examiner’s face.&lt;/p&gt; &lt;figure data-embiggen="true"&gt;&lt;p&gt;&lt;img title="The gates of the Polytechnique in Galois's time" alt="The gates of the Polytechnique in Galois's time" data-lazy-load-src="https://damn-8791.kxcdn.com/wp-content/uploads/2020/03/Ecole_Polytechnique-1400.jpg" data-height-ratio="0.75" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAMAAAAoyzS7AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAAZQTFRFgYGBAAAAqeg2zgAAAAxJREFUeNpiYAAIMAAAAgABT21Z4QAAAABJRU5ErkJggg=="&gt;&lt;/p&gt;&lt;figcaption&gt;The gates of the Polytechnique in Galois's time&lt;/figcaption&gt;&lt;/figure&gt; &lt;p&gt;Whether it was his mathematics or his temper that sunk him, Galois was again denied admission to the Polytechnique. He turned his attention to a backup option: the &lt;i&gt;École préparatoire&lt;/i&gt; (Preparatory School), whose main job was training teachers. It had its own set of entrance exams⁠—across a range of subjects, including several that were not mathematics. Although the application deadline for the school had passed, Galois wrote a letter to the administration asking them to let him apply anyway. His letter suggests that recent events had not compromised his cockiness. The examiners allowed him to proceed, but the science adjudicator in particular was less than impressed, commenting dryly that Galois “knows absolutely nothing”:&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;“I was told this student had an aptitude for Mathematics; this surprises me greatly, as based on his examination, I think he possesses very little intelligence, or, at least, it’s so well hidden that I was unable to discover it[.]”&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;Nevertheless, Galois’s scores for mathematics were high enough⁠—and his answers, for a change, expressed clearly enough⁠—that he was admitted to the École préparatoire in November 1829.&lt;/p&gt; &lt;p&gt;Galois had a way forward. However, his fledgling mathematics career ran into turbulence shortly after takeoff, due to the untimely death of a Norwegian mathematician named Niels Henrik Abel. Amiable but hapless, Abel had been unsuccessfully clamoring for attention from French mathematicians for years. He had even travelled to Paris to seek recognition, and sent one of his own papers to Augustin-Louis Cauchy. Alas, Cauchy had failed to get around to reading it. Even Abel’s defeated letter to Cauchy several years later, requesting the return of his manuscript, went unacknowledged. Then, only 26 years old, Abel succumbed to tuberculosis.&lt;/p&gt; &lt;p&gt;When news of Abel’s death reached the Academy in June 1829, Cauchy scrambled to defend himself⁠—awkwardly and unconvincingly⁠—for having neglected the young Norwegian. He rushed to read Abel’s three-year-old manuscript and present it to the Academy, just a few weeks after his second presentation on Galois’s work. It was immediately apparent that Abel had reached many of the same conclusions as Galois, and done so earlier⁠—publishing a proof that there could be no general formula for polynomials of any individual degree of 5 or above. That autumn, the &lt;i&gt;Bulletin de Férussac&lt;/i&gt; published both an obituary of Abel and a detailed analysis of one of his earlier papers. For those in the know, this underscored the fact that while Galois had made some phenomenal breakthroughs, Abel had reached some of the same insights first. Their methods were entirely distinct, but when it came to the conclusions, Galois⁠—nine years younger⁠—had been provably pre-empted. Unsurprisingly, Cauchy’s planned third presentation of Galois’s research did not go ahead as planned in 1830⁠—though, as science historian René Taton points out, the normally irascible Galois did not complain about this, which suggests that he voluntarily withdrew his work given the unintended overlap with Abel’s findings.&lt;/p&gt; &lt;figure data-embiggen="true"&gt;&lt;p&gt;&lt;img title="Niels Henrik Abel" alt="Niels Henrik Abel" data-lazy-load-src="https://damn-8791.kxcdn.com/wp-content/uploads/2020/03/Niels_Henrik_Abel-1400.jpg" data-height-ratio="1.25" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAMAAAAoyzS7AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAAZQTFRFgYGBAAAAqeg2zgAAAAxJREFUeNpiYAAIMAAAAgABT21Z4QAAAABJRU5ErkJggg=="&gt;&lt;/p&gt;&lt;figcaption&gt;Niels Henrik Abel&lt;/figcaption&gt;&lt;/figure&gt; &lt;p&gt;That said, Galois could still salvage the considerable original components of his own work. Abel had not scooped him on group theory. While keeping up with his regular schoolwork, Galois compiled his research into a manuscript and submitted it at the end of February 1830 to the Academy’s inaugural Grand Prize in mathematics. Despite a few setbacks, Galois was carving himself a respectable place in the mathematical world. If he were to win the Grand Prize, it would cement his status as a leading light of his generation.&lt;/p&gt; &lt;p&gt;On 28 June 1830, the results of the Grand Prize were announced, and Galois’s name was nowhere to be seen. The jury chose to award the prize to two mathematicians for their separate work on elliptic functions. One was the German Carl Gustav Jacob Jacobi; the other, posthumously, was Abel. A clause in the contest rules specified that the jury could award the prize to any paper published in the previous year, not just official entries; the Academy thus made amends to the memory of the young man it had ignored in life.&lt;/p&gt; &lt;p&gt;Another young man, however, was available to feel disregarded in Abel’s place. Galois could not possibly have objected to the winners on mathematical grounds; he strongly identified with Abel, and Jacobi appears to have been one of the few other mathematicians he respected. What was galling for Galois was that his manuscript was not even listed as an official contest entry. Indeed, when he asked to have his paper returned, it could not be found. This turned out to be simple bad luck. The Permanent Secretary of the Academy, Joseph Fourier, had served on the jury for the Grand Prize, and had taken Galois’s manuscript home with him to read. Unfortunately, he died in mid-May; Galois’s manuscript was lost somewhere in the shuffle of his papers, and it never resurfaced.&lt;/p&gt; &lt;p&gt;Galois already had a sizable chip on one shoulder, and was fast developing one on the other as well. He was increasingly convinced that the Academy was deliberately shunning him. Perhaps, he thought, they were too incompetent to understand his dramatically forward-thinking mathematical ideas &lt;i&gt;and&lt;/i&gt; too stodgy to approve of his dramatically forward-thinking political convictions. Galois’s resentment can only have been compounded when, in late July 1830, he took an exam on differential and integral calculus and placed only fourth out of eight students⁠—a shockingly low rank for someone who was having papers published in the same journal as Cauchy. On top of it all, he was still irritated at having twice been denied the chance to study at the Polytechnique, both for the quality of its mathematics instruction and for its opportunities in the way of anti-monarchist political activism. The second of these was about to be on full display as the tectonic plates of French politics shifted in the summer of 1830.&lt;/p&gt; &lt;figure data-embiggen="true"&gt;&lt;p&gt;&lt;img title="King Charles X of France" alt="King Charles X of France" data-lazy-load-src="https://damn-8791.kxcdn.com/wp-content/uploads/2020/03/Carlos_X_de_Francia_François_Gérard-scaled.jpg" data-height-ratio="1.4342629482072" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAMAAAAoyzS7AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAAZQTFRFgYGBAAAAqeg2zgAAAAxJREFUeNpiYAAIMAAAAgABT21Z4QAAAABJRU5ErkJggg=="&gt;&lt;/p&gt;&lt;figcaption&gt;King Charles X of France&lt;/figcaption&gt;&lt;/figure&gt; &lt;p&gt;King Charles X, to put it mildly, was extremely conservative. The ministers he chose were even more so. All of them remained traumatised by the French Revolution of 1789, which had resulted in the mass decapitation of their peers⁠—including more than a few members of Charles’s family. As a result, they were dedicated to doing away with those ridiculous ideas of liberty, equality, and fraternity that the revolution had propagated. &lt;/p&gt; &lt;p&gt;When the results of an election in the summer of 1830 favoured the liberal left, the government’s ossified leaders retaliated with a particularly boneheaded decision. A series of decrees dissolved the newly elected legislature before it had even met, reduced the assembly’s size by 170 seats, drastically curtailed voting rights in favour of the wealthy, censored opposition publications, and called for a do-over election in September. The government must have expected that the liberals would be unhappy, but as the prime minister reported that he received regular visitations from the Virgin Mary and she had told him everything would be fine, they went ahead anyway. What they didn’t take into account was that essentially abolishing the printing industry would also make the typographers unhappy. With their livelihoods gone, they spilled into the streets, quickly followed by their working-class peers, and then the furious middle class.&lt;/p&gt; &lt;p&gt;Riots became the lightning-speed July Revolution, which quickly became mythologised as the &lt;i&gt;Trois Glorieuses&lt;/i&gt;, the “Three Glorious Days”, where all classes had united to throw out a tyrannous regime. Members of the democratically organised National Guard⁠—which had been founded during the Revolution but that Charles had abolished⁠—pulled out their old uniforms from the cupboard and spontaneously reformed the militia. They came to be known as the heroes of the hour⁠—along with the students of the Polytechnique, who also jumped into the fray.&lt;/p&gt; &lt;p&gt;Their counterparts at the École préparatoire, on the other hand, were shut out. Or, more precisely, shut in. As the battle raged on the streets of Paris, the school’s administrators locked the doors to keep their students from taking part. The school’s new principal, Joseph-Daniel Guigniault, twice threatened to call in the military to keep order among his pupils. (This might not have accomplished anything. The royalist army was a bit preoccupied, trying to control the streets while upper-storey inhabitants of buildings showered them with furniture, including the occasional piano.) Guigniault made matters worse by uttering condescending comments about the revolutionaries. As it was, he could at least claim that he kept his students safe. The only one of them who seems to have been at any risk of injury during the Trois Glorieuses was Galois, who by most reports was so eager to get involved with the rioting that he tried to climb over the schoolyard wall.&lt;/p&gt; &lt;p&gt;His participation was unnecessary. Charles X faced the facts and went off into exile, while France proclaimed a new constitutional monarchy under a new king, Louis-Philippe. The National Guard became a key part of the imagery surrounding the change, their blue-white-red uniforms matching the newly restored tricolour flag flapping everywhere. &lt;/p&gt; &lt;figure data-embiggen="true"&gt;&lt;p&gt;&lt;img title="Prise de l'Hôtel de ville : le Pont d'Arcole by Amédée Bourgeois" alt="Prise de l'Hôtel de ville : le Pont d'Arcole by Amédée Bourgeois" data-lazy-load-src="https://damn-8791.kxcdn.com/wp-content/uploads/2020/03/Prise_de_lHôtel_de_ville_-_le_Pont_dArcole-scaled.jpg" data-height-ratio="0.73823529411765" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAMAAAAoyzS7AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAAZQTFRFgYGBAAAAqeg2zgAAAAxJREFUeNpiYAAIMAAAAgABT21Z4QAAAABJRU5ErkJggg=="&gt;&lt;/p&gt;&lt;figcaption&gt;&lt;i&gt;Prise de l'Hôtel de ville : le Pont d'Arcole&lt;/i&gt; by Amédée Bourgeois&lt;/figcaption&gt;&lt;/figure&gt; &lt;p&gt;The new regime, however, did not please everyone: it was a compromise that did not go far enough for the left and was anathema to the right. Paris, which set the tone for the whole country, remained a cramped medieval city with an underpaid, underfed working class. There were ongoing flare-ups of both rioting and disease. For Galois, the revolution also meant the loss of his best source of support at the Academy of Sciences: Cauchy, who was a right-wing Catholic and diehard supporter of the old monarchy, had left the country rather than take the required oath of loyalty to the new king. &lt;/p&gt; &lt;p&gt;Galois’s own path, naturally, was diametrically opposed. He joined the newly founded &lt;i&gt;Société des amis du peuple&lt;/i&gt;, a republican group so radical that it was banned altogether in October 1830, after which it became a (theoretically) secret society. While the Polytechnique was being laurelled for its active liberalism, Galois was stuck behind locked doors with its despised principal Guigniault⁠—his best chance at fighting the Establishment being stifled by the Establishment. To Galois, the principal’s behaviour was infuriatingly hypocritical. At first, Guigniault had mocked and dismissed the revolutionaries⁠—only to drape himself ostentatiously in the tricolour of those same revolutionaries at the battle’s end. Guigniault also made the empty gesture of changing the name of the school itself back to its Napoleon-era name of &lt;i&gt;École normale&lt;/i&gt;, while at the same time continuing to insist that “good students should not be interested in politics”.&lt;/p&gt; &lt;p&gt;Galois exchanged an increasingly testy series of letters with school administrators, criticising Guigniault’s response to the riots and revolution. When Galois published an “anonymous” letter in a prominent education-focused journal, spilling the matter into the press and thus the public, Guigniault simply expelled him. &lt;/p&gt; &lt;p&gt;With school off the table, nothing prevented Galois from getting in on the glory of the National Guard. The young mathematician enlisted in one of the Guard’s artillery batteries, one known to be a hotbed of republican sentiment. A good chance lay ahead for the republicans to demonstrate their continued displeasure with current affairs. Several of Charles X’s ministers were on trial, and the consensus on the left was that anything less than death sentences would be tantamount to acquittal⁠—and grounds for another uprising.&lt;/p&gt; &lt;p&gt;Wearing a newly purchased uniform, Galois would have been among the artillerymen stationed at the Louvre on 21 December 1830 when the sentences were announced. The ministers were sentenced to life in prison rather than death. The situation was precarious for days, and several members of the artillery were arrested for seditious behaviour. King Louis-Philippe, no fool, realised that leaving a bunch of radical republicans in charge of cannons might not be the wisest course. On 31 December, he dissolved the National Guard’s artillery units, outlawing the wearing of their uniforms. Galois’s military career had lasted, at most, three weeks.&lt;/p&gt; &lt;p&gt;Untethered from all institutions, Galois floundered, but the Academy of Sciences extended an olive branch. One of its most respected mathematicians, Siméon Denis Poisson⁠—who had shared journal space with both Galois and Cauchy just a few months earlier⁠—requested that Galois send them a new paper. Galois wrote a new manuscript⁠—probably a re-creation of his lost submission to the Grand Prize⁠—and submitted it on 17 January 1831. After two months passed with no word, Galois followed up with a snide letter to the President of the Academy, suggesting there was something fishy in Poisson’s delay. Pointedly rehashing his experience, Galois topped it off with a direct accusation of ulterior motives:&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;“…the examining committee decided &lt;i&gt;a priori&lt;/i&gt; that I could not have resolved this problem, firstly because my name was Galois, and moreover because I was a student. And the committee misplaced my paper. And I was told that my paper was misplaced. This lesson should have sufficed me […] to this day, my research has met more or less the same fate […] Will the analogy be pursued to the end? Please […] invite Messrs. Lacroix and Poisson to declare whether they have &lt;u&gt;misplaced&lt;/u&gt; my paper, or whether they intend to report on it to the Academy.”&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;Needless to say, this was not a good strategy for building a career. Other mathematicians were left shaking their heads at Galois’s behaviour. Rumours flew that he was losing his mind.&lt;/p&gt; &lt;p&gt;On 16 April 1831, nineteen of Galois’s fellow republicans were acquitted of sedition charges. Overjoyed, their allies carried them home in triumph, and quickly decided to hold a celebratory banquet in their honour. There was no right to free association in France at the time, but even the most dictatorial regimes knew better than to get between the French and a good meal. A banquet was therefore one of very few legal ways of gathering a large group of like-minded people to exchange ideas (or to collectively decide to defenestrate a bust of the king, or both). The venue was a restaurant, but not one known for its cuisine. Rather, it was the largest space in Paris that a group could book easily. A year earlier, it had hosted a liberal banquet that had laid the groundwork for the end of Charles X’s rule. Now Galois looked forward to a similar event⁠—and in preparation, he visited a local knife-maker and very eagerly ordered a ‘folding dagger’.&lt;/p&gt; &lt;figure data-embiggen="true"&gt;&lt;p&gt;&lt;img title="Alexandre Dumas ca. 1831" alt="Alexandre Dumas ca. 1831" data-lazy-load-src="https://damn-8791.kxcdn.com/wp-content/uploads/2020/03/dumas-cropped.jpg" data-height-ratio="1.3846153846154" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAMAAAAoyzS7AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAAZQTFRFgYGBAAAAqeg2zgAAAAxJREFUeNpiYAAIMAAAAgABT21Z4QAAAABJRU5ErkJggg=="&gt;&lt;/p&gt;&lt;figcaption&gt;Alexandre Dumas ca. 1831&lt;/figcaption&gt;&lt;/figure&gt; &lt;p&gt;One of the other revolutionaries in attendance at the banquet was Alexandre Dumas. The future creator of the Three Musketeers and the Count of Monte Cristo, Dumas was already a renowned playwright; only a week earlier, one of his plays had become the theatrical sensation of the year. He had also been an artilleryman in the same National Guard battery as Galois and many of the nineteen acquitted republicans. Recalling the event much later in his &lt;i&gt;Memoirs&lt;/i&gt;, Dumas wrote that “it would have been difficult to find two hundred people more hostile to the government in all of Paris”. Even so, Galois eventually managed to find a way to stand out. As the number of emptied champagne bottles grew and the banqueters began to forego their promise not to make any unapproved toasts, Dumas suddenly became aware that&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;“[a]n extremely animated scene was taking place fifteen or twenty places down from me. A young man, holding his raised glass and an open dagger in the same hand, was striving to make himself heard. It was Évariste Galois, […] one of the most ardent republicans.”&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;Ardent and, it must be said, drunk. Galois later admitted to a friend that if he’d been sober, he would never have behaved as he did. Dumas could not hear over the immediate roar of the crowd, but he did work out that the words “Louis-Philippe” had been uttered, that Galois’s open dagger was unambiguous, and that there were limits to his own radicalism. Catching each other’s eye, Dumas and his neighbour hopped out a window and skedaddled⁠—which, from a banquet on the ground floor, was admittedly easier than it might have been.&lt;/p&gt; &lt;p&gt;What Galois had done was to openly call for regicide⁠—a crime so unthinkable that the criminal code classified it as being as unnatural as parricide. Dumas knew well that plays could be banned simply for alluding to it. This action was too radical even for the radicals: republicans did not want their movement reminding the nation of the constant guillotining that had marked the 1789 Revolution. But Galois’s fiery outburst was soon all over the newspapers, causing considerable embarrassment. The morning after the banquet, Galois was arrested at his mother’s house.&lt;/p&gt; &lt;p&gt;Galois’s supporters latched onto the fact that the threat had technically been conditional⁠—“To Louis-Philippe, should he betray [his oath to uphold the constitution]”⁠—with the crowd’s noise burying the second half. Astonishingly, at his own trial on 15 June 1831, Galois did not take advantage of this escape rope. Instead, he doubled down in every possible way. Not only did he &lt;i&gt;not&lt;/i&gt; blame drunkenness, he insisted that he had &lt;i&gt;intended&lt;/i&gt; what he’d said, conditionals be damned. In open court, with a gobsmacked audience looking on, Galois confirmed that it &lt;i&gt;had&lt;/i&gt; been an assassination threat, that he had &lt;i&gt;not&lt;/i&gt; just been expressing his personal opinion, and that he &lt;i&gt;was&lt;/i&gt; attempting to goad others into making attempts on the king’s life. Indeed, Galois went on, in his opinion Louis-Philippe probably already &lt;i&gt;had&lt;/i&gt; betrayed his oath. Around this point, the judge cut the interrogation short⁠—either to keep a lid on Galois’s outrageous sentiments, or simply to stop him from digging himself even more deeply into a hole.&lt;/p&gt; &lt;figure data-embiggen="true"&gt;&lt;p&gt;&lt;img title="King Louis-Philippe I" alt="King Louis-Philippe I" data-lazy-load-src="https://damn-8791.kxcdn.com/wp-content/uploads/2020/03/Louis_Philippe_I.jpg" data-height-ratio="1.5450643776824" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAMAAAAoyzS7AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAAZQTFRFgYGBAAAAqeg2zgAAAAxJREFUeNpiYAAIMAAAAgABT21Z4QAAAABJRU5ErkJggg=="&gt;&lt;/p&gt;&lt;figcaption&gt;King Louis-Philippe I&lt;/figcaption&gt;&lt;/figure&gt; &lt;p&gt;Surprisingly, Galois was acquitted. Dumas’s explanation was that the jurors either agreed with Galois, or simply thought he was beyond sanity. Most other sources agree that the judge and jury took pity on him because he was so young⁠—still only 19. &lt;/p&gt; &lt;p&gt;Against the odds, Galois had slipped out of the political noose. Not only that, but the publicity dislodged the apparent impasse at the Academy of Sciences. On the day his trial started, the newspaper &lt;i&gt;Le Globe&lt;/i&gt; published a lengthy letter detailing Galois’s experiences with the Academy. Specifically, the publication argued that Poisson⁠—who had requested the new paper from Galois in the first place⁠—had really dropped the ball. Perhaps encouraged to hurry, Poisson and his co-referee submitted their report a few weeks after Galois’s acquittal, on 4 July 1831, then presented it publicly to the Academy a week later.&lt;/p&gt; &lt;p&gt;A months-long wait for a response to a manuscript was not actually anything unusual. The Academy was swamped with submissions. Mathematical historian Caroline Ehrhardt reports that two-thirds of the papers submitted to the Academy never received a report at all⁠—and of those that did, few got more than a few terse sentences. Galois’s complaint of neglect in March was baseless. Fortunately, the Academy did not dismiss him out-of-hand for his impudence⁠—which is just as well, for this manuscript contained what astrophysicist/author Mario Livio later called “one of the most imaginative breakthroughs in the history of algebra”⁠—the core of his invention of group theory.&lt;/p&gt; &lt;p&gt;To their credit, the reviewers produced a lengthy, thorough, and detailed report on Galois’s manuscript. It was clear that they saw and appreciated the links between Galois’s ideas and Abel’s. But their evaluation was not what Galois had hoped for: overall, Poisson and Lacroix confessed that they were baffled. The math itself was not the problem; rather, they were not always able to follow the argumentation.&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;“[…] we have made every effort to understand Mr. Galois’s demonstration. His reasoning is neither clear enough not developed enough for us to have been able to judge its exactness […] The author announces that this proposition […] is part of a general theory liable of many other applications. It is often the case that the different parts of a theory, by mutually illuminating one another, are easier to grasp when taken together rather than in isolation. We can therefore wait for the author to have published his work in its entirety before coming to a definitive opinion […]”&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;Several contextual factors worked against Galois. He still did not have training in the conventions of writing out mathematical discoveries⁠—a skill he could have picked up at the Polytechnique. Added to this, his work was pure mathematics; this would have resonated with the absent Cauchy, but for the other members of the Academy at the time, what was important was applied mathematics. Plus, algebra was still thought of as a tool rather than a subfield of mathematics in and of itself; Poisson and Lacroix would have been judging Galois’s manuscript through the lens of mathematical analysis⁠—what we now call differential calculus⁠—and looking for its practical potential. Galois’s ideas likely struck them as a pointless excursion into &lt;i&gt;terra incognita&lt;/i&gt;. With the benefit of hindsight, Mario Livio slams the reviewers for reacting so lukewarmly to Galois’s manuscript. However, in modern academic parlance, the referees’ report is much more “revise and resubmit” than it is an outright rejection. More than one modern mathematician has admitted they would likely have made the same decision in response to the manuscript as it was.&lt;/p&gt; &lt;p&gt;None of this counted for Galois. Furious, he became convinced once and for all that the Academy was out to get him. And as usual, mathematical disappointment dovetailed with political trouble. Only days later, on 14 July 1831, the police set out very early for Galois’s home. Knowing him to be a troublemaker, they were hoping to nab him in a pre-emptive roundup of republican rowdies known to have plans for commemorating the fall of the Bastille. No Évariste Galois was found⁠—because he had already left home that morning. The police eventually caught up with him and his friend Ernest Duchâtelet. The young men were going to an illegal march, with Galois illegally wearing his National Guard uniform⁠—not to mention carrying a rifle, a couple of pistols, and a dagger. Placed under arrest, the pair complied calmly enough that the officers didn’t think to confiscate their prisoners’ rifles until they were halfway to the police station.&lt;/p&gt; &lt;figure data-embiggen="true"&gt;&lt;p&gt;&lt;img title="Sainte-Pélagie prison" alt="Sainte-Pélagie prison" data-lazy-load-src="https://damn-8791.kxcdn.com/wp-content/uploads/2020/03/Prison_de_Sainte-Pélagie_-_Vue_Extérieure-scaled.jpg" data-height-ratio="0.80294117647059" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAMAAAAoyzS7AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAAZQTFRFgYGBAAAAqeg2zgAAAAxJREFUeNpiYAAIMAAAAgABT21Z4QAAAABJRU5ErkJggg=="&gt;&lt;/p&gt;&lt;figcaption&gt;Sainte-Pélagie prison&lt;/figcaption&gt;&lt;/figure&gt; &lt;p&gt;Galois was thrown in jail to await trial, but his stay in Sainte-Pélagie prison got off to an eventful start. As the anniversary of the July Revolution approached, the republican prisoners got more and more excited. On 28 July 1831, they happily spent the day yelling anti-royalist slogans, insulting passers-by, and throwing things out of windows. Towards evening, a loaf of bread hit a woman on the head so hard that she was left bruised and bleeding (a testament to the sort of food the inmates were given). Half an hour later, one of Galois’s cellmates began to caterwaul &lt;i&gt;La Marseillaise&lt;/i&gt; as he undressed for bed in front of the window. Outside, an exasperated local citizen sick of the ruckus let off a round of buckshot that hit the man clear in the face. Inside, panic erupted. The guards on the scene managed to regain control only by throwing three of the inmates⁠—including both Galois and Monsieur &lt;i&gt;La Marseillaise&lt;/i&gt;⁠—into the dungeon. This action itself nearly caused a riot, and rumours flew that the shot had been fired by a prison employee at the governor’s order.&lt;/p&gt; &lt;p&gt;Galois was only in the dungeon for three days, but it was three months before he came to trial. This time around, Galois backed down and feebly claimed that he hadn’t realised that wearing his uniform was illegal. The judge was unconvinced. Probably feeling that Galois’s previous acquittal had failed to teach him a much-needed lesson, he sentenced the young man to a further six months in jail. This sentence was disproportionately long, especially considering that Duchâtelet⁠—who had sketched a guillotine on his cell wall and added verses that threatened Louis-Philippe⁠—would have to do only three.&lt;/p&gt; &lt;p&gt;Imprisonment did not suit Galois. Still, the dampness and discipline of Sainte-Pélagie was probably more comfortable than boarding school had been. Prisoners could receive visitors every Thursday and Sunday, chat among themselves, walk about. Nevertheless, Galois soon fell into despair. Some of his co-inmates began referring to him as “an old man of twenty”. His sister Nathalie, who visited constantly, thought the same, finding him as hollow-eyed as someone 30 years older. Galois had already proven at the banquet in May that he could drink beyond his limits⁠—an ability that he now had cause to demonstrate repeatedly. Fellow inmate François-Vincent Raspail, the president of the banned &lt;i&gt;Société des amis du peuple&lt;/i&gt;, describes how prisoners taunted Galois by calling him a water-drinker. In response, Galois began downing entire bottles of brandy in one go, with predictable consequences. His mental state deteriorated, reopening his grief over the death of his father. He may even have attempted suicide, prevented only by Raspail’s intervention.&lt;/p&gt; &lt;p&gt;But Galois also spent a great deal of time in prison pacing and doing mathematics in his head. He even worked out a plan to bypass the Academy and publish two manuscripts privately with the help of his friend Auguste Chevalier. One of these papers⁠—”On the Conditions for Solubility of Equations by Radicals”⁠—was a revision of the paper that the Academy had balked at; the other was a new work on “Primitive Equations Solvable by Radicals”, which Galois (now particularly adept at anything having to do with radicals) seems to have undertaken starting in the summer of 1830. Before he got out of prison, he had put considerable energy into drafting a preface to the two works. This was a five-page manifesto dripping with vitriol and heavy-handed sarcasm, along with self-congratulatory sentiments about his own independence from the Academy and “how lowly I esteem my adversaries”. Among other things, he was still stewing over his lost paper.&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;“I must mention how manuscripts most often end up lost in the folders of Messrs. the members of the Institute, though truly I can’t conceive of such carelessness on the part of men who have the death of Abel on their conscience.”&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;He snarkily outlines how he could have clogged his manuscript with useless details to make it easier to understand and appease his reviewers’ request for additional information. He witheringly suggests that the examiners in charge of testing candidates for the Polytechnique deserve to be members of the Academy, given that “they certainly have no place in posterity”. He presents himself as a martyr figure, “knowingly exposing myself to the mockery of dunces”, and even obliquely lambastes the Academy for favouring applied over pure mathematics. Clearly, prison had done nothing to temper either Galois’s simmering rage or his self-esteem⁠—nor, for that matter, his politics.&lt;/p&gt; &lt;p&gt;In spite of this, Galois was released from prison in March, before he had completed either his manuscripts or his sentence. The authorities sent him to a small halfway house run by a man named Denis Faultrier to recover his broken health. The transfer dramatically changed things. Back in prison, Galois had told Raspail that the one thing he truly lacked was someone he could love “with his heart alone”. Now that lack was about to be rectified⁠—but it would not end well.&lt;/p&gt; &lt;figure data-embiggen="true"&gt;&lt;p&gt;&lt;img title="'Évariste' superimposed on 'Stéphanie' at top left, and E and S monograms bottom left" alt="'Évariste' superimposed on 'Stéphanie' at top left, and E and S monograms bottom left" data-lazy-load-src="https://damn-8791.kxcdn.com/wp-content/uploads/2020/03/evariste-stephanie.jpg" data-height-ratio="0.48823529411765" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAMAAAAoyzS7AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAAZQTFRFgYGBAAAAqeg2zgAAAAxJREFUeNpiYAAIMAAAAgABT21Z4QAAAABJRU5ErkJggg=="&gt;&lt;/p&gt;&lt;figcaption&gt;'Évariste' superimposed on 'Stéphanie' at top left, and E and S monograms bottom left&lt;/figcaption&gt;&lt;/figure&gt; &lt;p&gt;After his transfer, Galois became acquainted with a woman named Stéphanie, and reacted to her rather as he had to his first encounter with mathematics. It turned out that Galois fell in love as wildly as he did everything else. Even as he went over old papers, presumably still working on his pair of manuscripts, he doodled Stéphanie’s name in the margins. On one page, he superimposed the names “Évariste” and “Stéphanie”; on another, he sketched out some rather elegant monograms combining the initials “E” and “S”. Clearly, Galois had it bad.&lt;/p&gt; &lt;p&gt;The object of his fixation was almost certainly Stéphanie Félicité Poterin du Motel, a cousin of Denis Faultrier’s. Nearly 20 years old, she did not seem to reciprocate Galois’s affections. On 14 May 1832, she wrote to him:&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;“Let us please make an end of this matter. I do not have sufficient wit to follow a correspondence of this type, but I will try to have enough to converse with you as I did before anything happened… no longer think about things that could not exist and that never will exist.”&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;Another excerpt was even more crushing:&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;“…be persuaded, Sir, it would doubtless never have been more; you are assuming wrongly and your regrets are ill-founded.”&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;She ruled out even the possibility of a friendship, telling Galois that he was wrong to believe that men and women could ever be true friends.&lt;/p&gt; &lt;p&gt;A heartbroken Galois swirled downwards into an emotional whirlpool. His friend Auguste Chevalier grew alarmed, thinking that Galois was revelling in his own misery; Chevalier accused him of “being drunk on the putrefied muck of a rotten world infecting [his] heart, [his] mind, and [his] hands.” In a consoling letter, Chevalier apparently urged him, not for the first time, to seek refuge in religion. On 25 May 1832, Galois wrote back.&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;“[H]ow can one destroy the traces of emotions as violent as those I have passed through? How can one console oneself for having exhausted in one month the greatest source of bliss available to man, to have exhausted it without bliss, without hope, certain one has drained it dry for life? […] for your part, you feel obliged to do your best to convert me. But it is my duty to warn you, as I’ve done a hundred times, that your efforts are in vain. […] I’m disenchanted with everything, even the love of glory.”&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;Still, this all-encompassing existential loathing did not stop Galois from looking forward to reuniting with Chevalier in a few days. But the trip never happened. What actually happened in the next four days is unknown, but the night of the 29th found Galois desperately dashing off additional letters instead of sleeping. One was addressed to a pair of his republican friends:&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;“I have been challenged [to a duel] by two patriots…it was impossible for me to refuse.”&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;Officially, duelling was illegal at the time, but Galois was right. Like most of the rest of Europe, plus the New World (hello Mr. Hamilton, Mr. Burr), France was in the grip of a duelling frenzy. If anything, the historical reality makes the way the Three Musketeers duel at the drop of a hankie seem downright restrained. More than 200 people died in duels in France between 1826 and 1834 alone. Alexandre Dumas knew this firsthand: he had won his first duel when he was 22 (though his trousers had fallen down in the process). Politicians blew out the brains of other politicians, journalists from opposing sides of the political divide killed each other with pistol or sword, authors and literary critics could be found on the fighting fields, young men took aim at each other over women, professional killers went around challenging people for jostling them in the street. In Bordeaux, a duelling club was founded whose members swore to only ever fight to the death: the association lasted three years, until a newcomer systematically killed all twelve surviving members. In 1837, two law professors took up swords over whether a certain passage in the 6th-century &lt;i&gt;Digest&lt;/i&gt; of Justinian should end with a colon or a semicolon. (Professor Semicolon won by sticking three inches of steel into Professor Colon’s arm.) The poet Lamartine, who ended up in a duel in 1825 after one of his poems included a mildly uncomplimentary line about Italy, summed up the ethos by remarking that “It takes more courage to refuse one duel than to fight ten”.&lt;/p&gt; &lt;p&gt;In this atmosphere, there was never any question as to whether Galois would accept the challenge: any young man refusing would forever be branded a coward, and a fellow of above-average hotheadedness was unlikely to consider the possibility anyway. But Galois did not think he was fighting a duel for a particularly glorious cause. In a letter he addressed to “all republicans”, he wrote:&lt;/p&gt; &lt;figure data-embiggen="true"&gt;&lt;p&gt;&lt;img title="A page from Galois's memoir/article, with &amp;quot;I don't have time&amp;quot; scrawled in the margin" alt="A page from Galois's memoir/article, with &amp;quot;I don't have time&amp;quot; scrawled in the margin" data-lazy-load-src="https://damn-8791.kxcdn.com/wp-content/uploads/2020/03/galois-letter.jpg" data-height-ratio="1.44" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAMAAAAoyzS7AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAAZQTFRFgYGBAAAAqeg2zgAAAAxJREFUeNpiYAAIMAAAAgABT21Z4QAAAABJRU5ErkJggg=="&gt;&lt;/p&gt;&lt;figcaption&gt;A page from Galois's memoir/article, with "I don't have time" scrawled in the margin&lt;/figcaption&gt;&lt;/figure&gt; &lt;blockquote&gt;&lt;p&gt;“I die the victim of a shameless flirt and her two dupes. My life is being extinguished in a miserable bit of gossip. Oh! Why die for something so small⁠—die for something so contemptible!”&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;He closed by describing himself in Latin: “&lt;i&gt;Nitens lux, horrenda procella, tenebris æternis involuta&lt;/i&gt;”, which translates to “a brilliant light, swallowed by an awful tempest, wrapped in eternal darkness.” Id est, the turducken of melodrama.&lt;/p&gt; &lt;p&gt;As Samuel Johnson said, the certainty of being hanged in the morning concentrates the mind wonderfully. The possibility of being shot did precisely the same to Galois. A few days earlier, he had been doubting his ability to ever do math again; now he began a letter to Auguste Chevalier. “My dear Friend,” he wrote, “I’ve done several new things in analysis.” Then, in small, neat handwriting, over seven pages, he frantically set about getting down as many of his original ideas as he could. These provided enough material, Galois claimed, for three manuscripts. The first was the one the Academy had shrugged at; Galois insisted he stood by it, with only a small number of corrections. He then sketched out the most important parts of the other two manuscripts that he envisioned. Only at the end of the letter did some sense of finality come into play:&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;“You know, my dear Auguste, that these are not the only topics that I have explored […] But I don’t have time and my ideas are not yet very well developed in this immense area.”&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;He concluded by asking Chevalier to publish the entire text of the letter itself in the &lt;i&gt;Revue encyclopédique&lt;/i&gt;, and to publicly ask mathematicians Carl Gustav Jacob Jacobi or Carl Friedrich Gauss, or both, “to give their opinion, not on the truth, but on the importance of these theorems”. He also defended himself against the risk of again being accused of cursory mathematical argumentation:&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;“In my life, I’ve often taken the risk of advancing propositions about which I wasn’t certain. But everything I’ve written here has been in my mind for almost a year, and it is too much in my interest not to make mistakes for anyone to suspect that I’ve here formulated theorems for which I don’t have complete demonstrations.”&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;And yet, on the night of the 29th, Galois also revisited the copy of the manuscript that the Academy had returned to him. At one point, he scrawled in a margin, “There is something to be completed in this proof. I don’t have time”⁠—a poignant admission that reviewers’ calls for greater clarity had not been entirely undue.&lt;/p&gt; &lt;p&gt;At the scheduled time, on the outskirts of Paris, with a handful of witnesses, Galois and his challenger chose their pistols. It is possible that only one of them was loaded⁠—an uncommon but not unknown option that added an element of Russian roulette to the mix. The two men walked to twenty-five paces, turned to face one another, and shot. Hit in the abdomen, Galois dropped to the ground. Someone⁠—possibly an onlooker, possibly a passerby⁠—transported him to the nearby Cochin Hospital.&lt;/p&gt; &lt;p&gt;Conscious, but badly wounded, Galois lay in a room with four or five other patients. The only family member to have heard about the duel was his younger brother Alfred, who raced to the hospital and soon became despondent. Galois’s wound was not only severe, but also oddly positioned. It was as if he had not tried to minimise his chances of being shot; he might not even have turned to the side as he faced his foe as was customary. The injury was extensive, and already infected. The hospital surgeon and both brothers all knew that there was little to be done. Alfred was in tears, but Galois stoically instructed his brother, “Don’t cry. I need all of my courage to die at the age of twenty.” He characteristically rejected an attempt to have a priest attend to him, then, at 10:00 a.m. on 31 May 1832, Évariste Galois died in his brother’s arms.&lt;/p&gt; &lt;figure data-embiggen="true"&gt;&lt;p&gt;&lt;img title="Pistol duel in the XIX century by Bauce and Rouget" alt="Pistol duel in the XIX century by Bauce and Rouget" data-lazy-load-src="https://damn-8791.kxcdn.com/wp-content/uploads/2020/03/Duel_pistolet.jpg" data-height-ratio="0.76470588235294" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAMAAAAoyzS7AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAAZQTFRFgYGBAAAAqeg2zgAAAAxJREFUeNpiYAAIMAAAAgABT21Z4QAAAABJRU5ErkJggg=="&gt;&lt;/p&gt;&lt;figcaption&gt;&lt;i&gt;Pistol duel in the XIX century&lt;/i&gt; by Bauce and Rouget&lt;/figcaption&gt;&lt;/figure&gt; &lt;p&gt;Legend has long held that a large crowd attended Galois’s funeral that Saturday. The Prefect of Police claimed much later in his memoirs that some two to three thousand people were there. However, on the day itself, the same man’s report to the Minister of the Interior stated that the actual number was around 150, mostly other republicans. They set off at 11:30 a.m. on 2 June to accompany Évariste Galois from Cochin Hospital to the Montparnasse graveyard. After some good old fiery political speeches, Galois’s body became the 18th of 21 to be placed in a common grave⁠—after which the attendees passed the hat around to pay for the funeral costs.&lt;/p&gt; &lt;p&gt;Perhaps more than 150 had &lt;i&gt;intended&lt;/i&gt; to be there. Paris was (again) on the verge of insurrection, and the republicans were looking for an excuse to gather and start a riot. Galois’s funeral might have fit the bill perfectly⁠—except that the day before saw the death of General Jean Maximilien Lamarque. Lamarque was a prominent advocate for the wretched, miserable poor⁠—who, despite what certain modern stage productions suggest, were not inclined to be tuneful about their state. The republicans quickly realised that Lamarque’s funeral would be the higher-profile event, and rescheduled the rebellion. Thus, Évariste Galois was once again shoved aside and left out, even in death. His duel deprived him by just a few days of the opportunity to die a glorious republican martyr in the ill-fated 1832 June Rebellion. His friends of the Société des amis du peuple would appear thinly disguised in one of the best-selling novels of all time, but there are no mathematicians among the students in Victor Hugo’s &lt;i&gt;Les Misérables&lt;/i&gt;. Adding insult to fatal injury, among those who fought heroically on the June barricades, and survived, was a certain Étienne-François Pecheux d’Herbenville⁠—who most likely fired the bullet that prevented Galois from ever getting to join a revolution.&lt;/p&gt; &lt;p&gt;The identity of Galois’s opponent has long been one of the many mysteries surrounding the duel. Alexandre Dumas specifically named him as d’Herbenville, but Dumas is not infallible, and other evidence seemed to suggest otherwise. Two days after the duel, a newspaper from the town of Lyon, &lt;i&gt;Le Précurseur&lt;/i&gt;, reported on the duel, describing the victor as “one of [Galois’s] old friends, like him a very young man, like him a member of the Société des amis du peuple, and who had … also been a figure in a political trial”. The article attributed the duel to a romantic argument, and identified Galois’s foe by the initials “L.D.” &lt;/p&gt; &lt;p&gt;The &lt;i&gt;Précurseur&lt;/i&gt; article is full of small inaccuracies, but even taking these into account, it is tricky to make their depiction match Dumas’s identification. On the one hand, d’Herbenville⁠—a charming young man who liked to wrap his cartridges in pink silk paper⁠—was indeed a republican. In fact, he was one of the nineteen republicans whose acquittal was celebrated with the notorious banquet that ended with Galois’s drunken oath and Dumas’s autodefenestration. But beyond this there was no evidence of any connection between the two, let alone of old friendship. Given that Galois did not have many friends, other candidates have been sought. Mario Livio, among others, has argued for Galois’s friend and fellow prisoner Ernest Duchâtelet, who has the advantage of both being a friend and having at least one of the right initials. &lt;/p&gt; &lt;p&gt;Recent discoveries, however, make it almost certain that Dumas was right after all. One key piece of evidence is a copy of France’s 1791 revolutionary constitution. Among its owners was a Swiss medical student named Larguier, who wrote on it, “This manuscript was given to me by Gallois killed in a duel by Pécheux d’Herbinville”. Meanwhile, Olivier Courcelle’s research has discovered that d’Herbenville’s names were rarely spelt the same way twice in the press. Among the variations were forms such as “Lepescheux” and “Dherbinville”⁠—these would give us the “L. D.” reported by &lt;i&gt;Le Précurseur&lt;/i&gt;. Most tellingly of all, recent close analysis of Galois’s manuscripts has shown that, though crossed out, d’Herbenville’s name appears in Galois’s papers, proving that the two were indeed connected somehow. How, and as of when, is unknown, but Courcelle has discovered that d’Herbenville took classes at Louis-le-Grand at the same time that Galois resided at the school. Moreover, d’Herbenville studied mathematics at school before turning his attention elsewhere, and eventually became an engineer. In d’Herbenville, Galois would have found a radical republican he could talk shop with.&lt;/p&gt; &lt;p&gt;But knowing the identity of Galois’s killer does not solve the greater mystery of why the duel was fought at all, nor explain its oddities. The confusion over who took Galois to the hospital suggests that he went into the duel without any witnesses of his own⁠—a baffling choice given that one of the witnesses’ duties was to ensure prompt medical care for the wounded. Between this and Galois’s uncommon injury, several commentators have suggested that Galois went into the duel intending to die. One theory even holds that he was sacrificing himself for his political cause. But this is difficult to reconcile with his open letter to “all republicans”, in which he begs “my friends the patriots not to reproach me for dying for something other than the country”. Instead, he attributes the death he foresees for himself to “a miserable bit of gossip”. Moreover, one of Galois’s last-minute letters suggests that the challenger(s) “charged me &lt;i&gt;on my honour&lt;/i&gt; not to inform any patriot” (italics in original). Galois’s devastated brother Alfred, meanwhile, thought Galois had been shot by secret police agents acting on behalf of the king. This is profoundly unlikely. Even if Louis-Philippe’s regime had been prone to assassinating people⁠—which it does not appear to have been⁠—Galois was simply not important enough to warrant eliminating, particularly in such a convoluted manner.&lt;/p&gt; &lt;figure data-embiggen="true"&gt;&lt;p&gt;&lt;img title="A French postage stamp commemorating Évariste Galois" alt="A French postage stamp commemorating Évariste Galois" data-lazy-load-src="https://damn-8791.kxcdn.com/wp-content/uploads/2020/03/galois-stamp.jpg" data-height-ratio="0.7" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAMAAAAoyzS7AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAAZQTFRFgYGBAAAAqeg2zgAAAAxJREFUeNpiYAAIMAAAAgABT21Z4QAAAABJRU5ErkJggg=="&gt;&lt;/p&gt;&lt;figcaption&gt;A French postage stamp commemorating Évariste Galois&lt;/figcaption&gt;&lt;/figure&gt; &lt;p&gt;More likely, it was simply a ‘matter of honour’⁠—and the generally accepted explanation is that the honour in question was Stéphanie du Motel’s. Most commentators identify the ‘shameless flirt’ of Galois’s letter as Stéphanie, though whether she deserved that appellation is entirely unknowable⁠—as is whether the challengers were in any way ‘dupes’. Quite possibly, Galois had simply importuned her so much that she had no option but to ask for assistance. Certainly, Galois indicates that he insulted his challengers, and did so to their faces: he wrote in his open letter that he “repent[s] having spoken a fateful truth to men who were so poorly prepared to hear it coolly”. With Galois’s temper, it seems unlikely that any of it was done coolly. As research continues into Galois’s papers and what he crossed out where, answers may yet come to light. Recent findings have confirmed that there was a police report about the duel; perhaps it will be found in an archive somewhere.&lt;/p&gt; &lt;p&gt;Alfred Galois and Auguste Chevalier were left with the weighty task of doing justice to Évariste Galois’s mathematical legacy, and it took time. It was not until 1843 that Galois’s luck changed, when his work reached French mathematician (and member of the Academy) Joseph Liouville. As he worked through Galois’s papers, Liouville noted their brevity and relative opacity, but realised that what Galois had proposed years before was both mathematically rigorous and far ahead of its time. In 1846, Liouville published Galois’s “ingenious and profound” work in his own internationally renowned journal, and thus it reached the wider mathematical community at last. Within 15 years, what came to be known as &lt;i&gt;Galois theory&lt;/i&gt; was being taught in algebra classes. Historian Amir Alexander says that Galois “had become an iconic figure of the field, a revered martyr to mathematics”.&lt;/p&gt; &lt;p&gt;It is a curious fact that what seems at first glance to be nothing but “pure” mathematics often later turns out to have important applied uses. While the Academy of Sciences could not see the practical side at the time, Galois’s new ways of approaching symmetries, permutations, and groups turned out to apply to, well, basically everything. Subtle symmetry appears to play a profound, central role in the laws of physics as we understand them. It applies just as well to the miniscule (particle physics) as to the humongous (cosmology), and is scattered throughout just about everything in nature that shows organised behaviour. One can only imagine what Galois might have been able to contribute with more than just a few years of research.&lt;/p&gt; &lt;p&gt;The story of Évariste Galois⁠—a revolutionary in every sense⁠—has become something of a legend in the last 150 years, not least because of the dual figure he presents as mathematical visionary and political lightning-rod. Early obituaries all focused on him as a republican. As early as 1846, however, Liouville could dismiss Galois’s political activities as nothing more than “a pity”, and for several decades this was the common verdict. Neither of these is the full story. Galois’s mathematical thought and his political thinking are deeply intertwined. In one of his draft papers, an equation that cannot be broken down further leads him to write the word “Indivisible”, and beneath that, “Indivisibility of the republic”, followed on a new line by “Liberty, equality, fraternity, or death”. Among the scrawls on the same page are the words “Une femme” (“a woman”)⁠—and, deeply scrawled out and now visible only with specialised equipment, the name of Pecheux d’Herbenville.&lt;/p&gt; &lt;p&gt;Galois closed his final mathematical statement with the bitter hope that after Jacobi and Gauss had given their opinion on the importance of his theorems, “there will be, I hope, some people who will find it to their advantage to decipher all this mess.”&lt;/p&gt; &lt;p&gt;There were, and they did.&lt;/p&gt; &lt;/article&gt;&lt;/div&gt;&lt;a href="https://www.damninteresting.com/radical-solutions/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sun, 29 Mar 2020 16:28:51 UT
      </pubDate>
      <guid>
        https://www.damninteresting.com/radical-solutions/
      </guid>
    </item>
    <item>
      <title>
        Yes to everything | Riccardo Mori
      </title>
      <link>
        http://morrick.me/archives/8840
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt; &lt;p&gt;Every time I gather observations and thoughts for a piece on the iPad, I feel I keep returning to the same old insights I’ve had for years. I knew Apple would complicate the iPad’s user interface this way. That many people are happy with it doesn’t mean it’s inherently a good&amp;nbsp;idea.&amp;nbsp;&lt;/p&gt; &lt;p&gt;Anyway. The other day, Apple introduced new iPad Pros, and an updated MacBook Air line-up. Most notably on the iPad hardware front, along with improving whatever feature was improvable, Apple has presented a new accessory — the Magic Keyboard. It has a trackpad. And on the software front, the upcoming iPadOS 13.4 will offer full mouse and trackpad support.&amp;nbsp;&lt;/p&gt; &lt;p&gt;Trackpad support was of course well received by iPad fans and all the people using the iPad as a main (or sole) computing device for work and leisure. Some praised the innovation of the new cursor, which Apple in their marketing describe as being &lt;em&gt; The biggest thing to happen to the cursor since point and click&lt;/em&gt;. (Let me pause and &lt;em&gt;eyeroll&lt;/em&gt; for a moment here). It’s an interesting take and a good execution. It’s also the least Apple could do on such a device — devising a cursor that is more context-aware and responsive than the one you find in a traditional computer is frankly more consequential than innovative.&lt;/p&gt; &lt;p&gt;As is consequential the fact that now the iPad supports mouse/trackpad input. Some of the comments I saw floating around mentioned how Apple has finally given in to the pressing requests from the iPad community, from people who wanted a more ‘Surface-like’ approach for the iPad, so as to make it a more suitable device for productivity.&lt;/p&gt; &lt;p&gt;While that may also be true, what I think is that Apple has actually given in to adding mouse/trackpad support to the iPad because they were essentially out of options. And because for them it is a convenient problem solver. It’s Mr Wolf in &lt;em&gt;Pulp Fiction&lt;/em&gt;: the one you call when you need a professional to clean up your&amp;nbsp;mess.&lt;/p&gt; &lt;p&gt;And the iPad’s user interface &lt;em&gt;still&lt;/em&gt; looks a bit messy. You may be accustomed to it. You may be so proficient at moving inside of it that you even love it. I’m not here to criticise your preferences or the iPad as a device. You wanted a ‘faster horse’ — enjoy your faster horse&lt;sup&gt;&lt;strong&gt;[&lt;a href="#ft1" name="note1"&gt;1&lt;/a&gt;]&lt;/strong&gt;&lt;/sup&gt;. I’m simply speaking from a conceptual standpoint. And from that standpoint, what I see is that the iPad’s user interface is a patchwork. Features, gestures, combinations of gestures, user interface layers, all stitched together over the&amp;nbsp;years.&amp;nbsp;&lt;/p&gt; &lt;p&gt;Steve Jobs was quoted as saying: “People think focus means saying yes to the thing you’ve got to focus on. But that’s not what it means at all. It means saying no to the hundred other good ideas that there are. You have to pick carefully. I’m actually as proud of the things we haven’t done as the things I have done. Innovation is saying ‘no’ to 1,000 things.”&lt;/p&gt; &lt;p&gt;By contrast, it appears the iPad is increasingly saying yes to everything.&lt;/p&gt; &lt;p&gt;Those who have no problems with the poor discoverability of several gestures or features still see the iPad as a flexible device that adapts to the needs of its users. They say, “If you feel that the multitasking interface is opaque, it’s okay. You’re not accustomed to it, and you probably don’t need it. The iPad keeps being intuitive for those who only use it at a basic&amp;nbsp;level.”&lt;/p&gt; &lt;p&gt;From a visual standpoint, there might be very little difference between a feature that is not visible and a feature that is out of the way. Conceptually, this is a big deal instead. A feature that is not visible and your only way to find it is by reading about it somewhere, or seeing a video tutorial, is something undiscoverable and poorly executed. A feature that is out of the way, but you get hints of its existence by the system, is an indication of at least a modicum of design-oriented thinking behind it. If the iPad’s user interface were truly well thought-out, the more so-called ‘pro’ features would be more discoverable. I wouldn’t get feedback messages from regular folks telling me, &lt;em&gt;I didn’t know I could do this on my iPad&lt;/em&gt;, with some even adding that they discovered some gesture or feature while erroneously performing a known&amp;nbsp;one.&lt;/p&gt; &lt;p&gt;The more layers of interaction you give to the device, the trickier things get. If the solution to a previously undiscoverable feature is to make the feature (more) discoverable through the use of a different input source, you may have found a way out of the dead end you got stuck in, but it’s not good design, strictly speaking. (I remember an exchange between a woman and an electronics shop’s employee: after buying a Windows laptop she returned to the shop to complain about the poor trackpad performance, and the employee told her to “just use a mouse”. Why not make a better trackpad, instead?)&amp;nbsp;&lt;/p&gt; &lt;h3&gt;The comparison with Microsoft’s Surface&lt;/h3&gt; &lt;p&gt;The iPad getting proper mouse input support, and the new Magic Keyboard for the iPad featuring a regular trackpad, have naturally invited people and reviewers to draw comparisons between the iPad and the Surface. But I don’t see it as Apple ‘catching up’ with Microsoft. I see it more as Apple bringing their racing car to a different kind of championship.&lt;/p&gt; &lt;p&gt;Microsoft’s Surface may have its flaws. Its user interface may have its inconsistencies and limitations, but it doesn’t bear the signs of the iPad’s long-standing identity crisis. The Surface and the iPad have different origin stories, and those are reflected in the way you approach and use these devices.&lt;/p&gt; &lt;p&gt;The Surface wasn’t really born as a pure tablet with a tailored mobile operating system on it. The concept Microsoft wanted to contribute was of an ultracompact laptop first, with tablet functionalities added on as a convenient alternative to perform quick tasks as needed, without burdening the user with a device fixed in its laptop configuration and behaving like a laptop all the&amp;nbsp;time.&amp;nbsp;&lt;/p&gt; &lt;p&gt;Still, all the devices in the different Surface product lines &lt;em&gt;are&lt;/em&gt; essentially laptops (of different weights and capabilities) that can work as, or transform into, tablets when the need arises. Even the first generation of Surface devices back in 2012–2013 were hardly ever seen in the wild without their keyboard, despite it being ‘optional’. They’re very much touchscreen computers with a tablet mode, with productivity as their main purpose. Technically, their Apple counterpart would be something more akin to a &lt;a href="https://en.wikipedia.org/wiki/Modbook"&gt;ModBook&lt;/a&gt; than an&amp;nbsp;iPad.&lt;/p&gt; &lt;p&gt;Their operating system, in a way or another, has always been some version of Windows with additional touch- and tablet-friendly features enabled, to make the Surface a more versatile device.&amp;nbsp;&lt;/p&gt; &lt;p&gt;The Surface knows what it is. And Surface users know what to expect from it, in terms of functionality and interface. The user interface could be improved here and there, but it’s not ambiguous. The levels of interaction comfort aren’t either. There is a distinctive best/good/okay comfort range as you go from operating a Surface like a Windows laptop, to using it as a tablet with pen input, to using it with touch input with just your fingers. But that feels fine because that’s the experience the Surface is supposed to provide.&amp;nbsp;&lt;/p&gt; &lt;p&gt;What Microsoft has strived to do over the past eight or so years has been to improve the Surface experience within that model, within that paradigm, and I’d say they’ve been rather successful at that. The next step is represented by devices like the Neo and the Duo, that introduce the new dual screen idea in form and function. The aim is, again, to improve productivity by creating a literal dual space to multitask and facilitate interoperation between apps and tasks, if and when needed.&amp;nbsp;&lt;/p&gt; &lt;p&gt;The iPad, on the other hand, has had a more varied history, and has been more of a chameleon — with regard to both purpose and interface. It was born as a separate device with unique characteristics to fill the perceived void between a laptop and a smartphone. In 2010, when introducing the iPad, Steve Jobs said, &lt;em&gt; In order to really create a new category of devices, those devices are going to have to be far better at doing some key tasks. They’re gonna have to be far better at doing some really important things: better than the laptop, better than the smartphone.&lt;/em&gt;&lt;/p&gt; &lt;p&gt;And in its first iterations, the iPad was exactly that; its identity pretty clear — ‘a big iPhone’ that could be just as easy to use as an iPhone, but better at doing certain things due to its bigger display. And better than a laptop because certain basic tasks and operations were simply more intuitive to carry out thanks to the multi-touch interface. That really killed all the remaining netbooks still in use at the time, and many non-tech-savvy people were happy to use a small laptop-sized device that was much less intimidating to use than a traditional computer. All thanks to its user interface and its very operating system, that was &lt;em&gt;not&lt;/em&gt; Mac OS X slapped on a touch-based device, but something that felt much more integrated and suitable for such a device. The learning curve was also low because people already knew iOS thanks to the iPhone’s success.&lt;/p&gt; &lt;p&gt;Then, unfortunately, Steve Jobs passed away.&lt;/p&gt; &lt;p&gt;I can see your eyes rolling from here, but bear with me. Although I’ve never denied my utter preference for Jobs’s leadership over Cook’s, I’m not trying to argue that the iPad would necessarily have had a better development and trajectory under Jobs, but it’s undeniable that the iPad is perhaps the device that has suffered the most from Jobs’s absence. Under his tenure, Apple released the first-generation iPad and the iPad 2. The iPad 2 was a first real improvement over the iPad 1: it was thinner, more powerful, and it had cameras. The iPads that came out afterwards, between 2012 and 2015, were essentially the same thing as the iPad 2, with obvious improvements in the hardware, and some improvements in the software. Conceptually, very little moved forward. The iPad Air 2, produced between 2014 and 2016, for all intents and purposes was just like the first iPad, just faster, better, and with more capable apps.&lt;/p&gt; &lt;p&gt;As for its conceptual evolution, as for changing the computing experience altogether, however, the iPad felt like a device stuck in stagnant waters. And it still felt pretty much like a device that didn’t know what it wanted to become. It was created as a consumption device first, with the ability to serve as an artistic tool for creation and to do the occasional productivity task if you tried really hard, with the right apps, and jumping through the right hoops. Styluses and external keyboards have always been usable on it, but the iPad has always been a ‘touch-first’ device, meant to be used like a tablet, not like an ultraportable laptop. I can’t speak for Jobs here, but I’m pretty sure he would have said something like, &lt;em&gt;If you need to use the iPad as a laptop replacement, maybe it’s better if you just used a real laptop.&lt;/em&gt;&lt;/p&gt; &lt;p&gt;But then an increasing number of people, especially tech nerds, started to demand from Apple something more akin to Microsoft’s Surface in features and functionality. And Apple, from 2015–2016 onwards, started to oblige, little by little. And so they have been repurposing the iPad as it goes along without really jettisoning anything. The process has been utterly additive. Employing the famous Jobs’s analogy of trucks and cars, I’d say that from its origins as a sports car, the iPad has progressively become a sports car that can be retrofitted with a trailer, off-road tyres, a 4WD transmission, and so&amp;nbsp;forth.&amp;nbsp;&lt;/p&gt; &lt;p&gt;Some look at the latest iPad Pro, at the full support for mouse input in iPadOS 13.4, at the new Magic Keyboard with trackpad, as a winning combination of tools that make the iPad a truly versatile device. And maybe it is so from a practical standpoint. Again, conceptually, I look at ten years of the iPad and I see its trajectory as going from being a ‘jack of some trades, master of some’ to being a ‘jack of all trades, &lt;em&gt;still&lt;/em&gt; master of some, but not&amp;nbsp;all’.&amp;nbsp;&lt;/p&gt; &lt;p&gt;The story and evolution of Microsoft’s Surface are perhaps simpler and less ambitious, but over the years have proceeded with a much clearer process, iterations, and intentions. Apple now probably aims for the iPad to be a sort of blank-slate device, so technically capable that it can do anything you want it to do. But all this retrofitting to make it also behave like a compact laptop has been — still is — a painful process to behold. I keep feeling the iPad could have been so much more in so many different, countercurrent ways, and all it has done in ten years is to become something more conventional.&lt;/p&gt; &lt;p&gt;Where the iPad is truly at the forefront today is hardware (industrial design + manufacturing + tech specs). But idea, concept, purpose? Not anymore. Others are trying to match the iPad in hardware, Apple is borrowing ideas and purposes from others. If there’s combined progress in all this, it’s inertial.&lt;/p&gt; &lt;p&gt;Again, I can’t be sure, I don’t have the ability to see alternate timelines, but I truly wonder what was Jobs’s ultimate idea for the iPad. What direction he wanted to point it. I’m not saying that things would have been better if Steve Jobs were still among us. But I’m sure we would have felt a stronger sense of direction for the iPad. A clearer vision, even if more polarising, perhaps.&amp;nbsp;&lt;/p&gt; &lt;p&gt;What &lt;em&gt;I felt&lt;/em&gt; back in 2010–2011 was that Jobs’s plan could have been to gradually evolve the iPad into a unique computing device, using the tablet format and the multi-touch interface to effectively &lt;em&gt;revolutionise&lt;/em&gt; what it meant to be productive using something that is not a traditional computer; to end up with a device that could go beyond the old and established paradigms and metaphors of traditional desktop computing. If he had wanted the iPad to progressively become a Surface-like device, he would have probably sherlocked the aforementioned ModBook and create a touch MacBook with Mac OS&amp;nbsp;X.&lt;/p&gt; &lt;p&gt;Maybe this is the root of my general feeling of disappointment in the iPad — that Apple didn’t make enough efforts to come up with a transformative UI that could revolutionise how people can be productive on a tablet, without having to resort to traditional paradigms and input devices. Without reinventing the computing wheel for so many tasks just so they can be easily carried out on an iPad, even when it would make much more sense to just use a laptop.&lt;/p&gt; &lt;p&gt;Yes, maybe my expectations have always been high on this front. But not unreasoningly so. Is it really too much to ask of a tablet today, after seeing how innovative certain parts of the Apple Newton’s user interface could be more than 20 years&amp;nbsp;ago?&lt;/p&gt; &lt;p&gt;For some, having an iPad acquire more Surface-like capabilities may be a success, a much awaited move that will solve so many things. For me this move, that brings the iPad even closer to a Mac laptop in functionality, in turn makes the iPad &lt;em&gt;even less&lt;/em&gt; compelling.&amp;nbsp;&lt;/p&gt; &lt;h3&gt;The big picture&lt;/h3&gt; &lt;p&gt;Judging by previous feedback I received after publishing other articles on the iPad and ranting about my disappointment, a lot of people think I’m still clinging to the past, to the Mac and traditional computers, that I’m averse to change, that I’m ‘old’ and not flexible enough to adapt to this bright future of computing spearheaded by this incredibly awesome and innovative device that is the&amp;nbsp;iPad.&amp;nbsp;&lt;/p&gt; &lt;p&gt;Others mistake my criticism for the iPad at the conceptual level for criticism aimed at the device itself. Nothing could be further from the truth. I do think the iPad is an impressive device. I don’t deny it’s an engineering feat. I absolutely think you can do all kinds of serious work on it. And I’m happy for all those who are able to make the most of it. (Yes, whenever the iPad vs Mac debate rages on Twitter, I have indeed indulged in some sarcasm. But come on, who doesn’t on Twitter?)&lt;/p&gt; &lt;p&gt;However, as someone who for several years has cultivated a deep interest for the history of computing and the user interface, I simply can’t look at the iPad (or the Surface, for that matter) and see real progress. Again, I’m not talking about computing power and features. The iPad Pro today is so much more powerful than a supercomputer from the 1970s. I’m talking conceptually. The ideas that drove the computer scientists at RAND corporation to create the RAND tablet in the mid-1960s were more advanced in scope than the ideas behind any tablet available today. And in certain respects more daring, as that tablet was meant to be operated without any keyboard whatsoever. It had an amazing handwriting recognition for the time, and all input came via its stylus. And some of the capabilities of &lt;a href="https://en.wikipedia.org/wiki/Sketchpad"&gt;Sketchpad&lt;/a&gt;, the groundbreaking program written by Ivan Sutherland in 1963, are still hard to beat in intuitiveness and execution, almost sixty years&amp;nbsp;later.&lt;/p&gt; &lt;p&gt;So when I see a tablet device in 2020 become more usable thanks to it finally supporting &lt;em&gt;mouse input&lt;/em&gt; of all things, and not because of some other advancement in touch technology, input method, user interaction or user interface design, forgive me if I feel underwhelmed and a bit disheartened. What we do with our devices today is something people like Alan Kay envisaged in the 1960s and 1970s. So no, I’m not clinging to the past or averse to change. I see where we are today and I’m baffled we haven’t advanced further. Or rather, the hardware has. But concepts, paradigms and metaphors are still the ones that have been circulating for more than sixty years. Today I see future-looking hardware marred by backward-looking software, interfaces, and interactions. In a sense, everyone’s clinging to the past, in a way or another.&lt;/p&gt; &lt;p&gt;Then why do I still choose the Mac over the iPad? Until I see real progress on those fronts I mentioned above, why should I waste time, money, and energies to be able to do on an iPad the same things I can already do with ease, experience and efficiency on a Mac? I would gladly undergo the re-learning process if that meant mastering a new device or interface concept that would bring significant benefits over ‘the old ways’ in terms of interaction, productivity, fulfilment, and so forth — or even something new in a meaningful way, something that was not possible before. But for now I keep seeing ‘the old ways’ re-emerge here and there behind the external layer of coolness of the iPad. I can’t be averse to change when I don’t even really perceive change in the first&amp;nbsp;place.&lt;/p&gt; &lt;hr&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="http://morrick.me/archives/8840"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Mon, 30 Mar 2020 11:38:05 UT
      </pubDate>
      <guid>
        http://morrick.me/archives/8840
      </guid>
    </item>
    <item>
      <title>
        How Apple Is Working From Home — The Information
      </title>
      <link>
        https://www.theinformation.com/articles/how-apple-is-working-from-home?utm_source=hackernews&amp;utm_medium=unlock
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;section id="ti-content"&gt; &lt;article id="4363"&gt; &lt;figcaption id="hero-image-caption"&gt; Apple's headquarters in Cupertino, California. Photo by Bloomberg &lt;/figcaption&gt; &lt;div id="article-container"&gt; &lt;div&gt; &lt;p&gt; March 30, 2020 10:02 AM PDT &lt;/p&gt; &lt;/div&gt; &lt;div&gt; &lt;p&gt;Normally, Apple’s hardware teams meet in person at the company’s Cupertino, California, headquarters to review upcoming products, often bringing key components of their devices to show colleagues.&amp;nbsp;&lt;/p&gt;&lt;p&gt;But now that they are sidelined at home due to Covid-19, members of those teams are improvising new tactics for getting their work done. During video calls, they have resorted to tracing shapes in the air to describe components they’ve had to leave back in the office, said two employees. Because of travel restrictions, they’ve had to make decisions based on grainy photos of parts sent from Chinese factories, rather than doing so in person.&amp;nbsp;&lt;/p&gt;&lt;p&gt;As the tech industry braces for an economic downturn caused by the global pandemic, its biggest companies, which sit on billions of dollars of cash reserves, are perhaps best positioned. But Apple, one of the world’s most valuable companies, faces a unique set of challenges because of its secretive culture, focus on hardware and dependence on Chinese manufacturing, according to interviews The Information conducted in recent days with a dozen current and former employees, as well as others who work closely with the company. &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id="read-this-article"&gt; &lt;p&gt; &lt;h2&gt; Join now to read the full story &lt;/h2&gt; &lt;/p&gt; &lt;/div&gt; &lt;div&gt; &lt;div&gt; &lt;p&gt;&lt;span&gt; The Takeaway &lt;/span&gt; &lt;span&gt; &lt;span&gt; Media/Telecom &lt;/span&gt; &lt;/span&gt; &lt;/p&gt; &lt;div&gt; &lt;div&gt; &lt;p&gt; What Critics of the News Industry Get Right—and Wrong &lt;/p&gt; &lt;p&gt; By Jessica E. Lessin · Feb. 6, 2021 7:46 AM PST &lt;/p&gt; &lt;/div&gt; &lt;div&gt; &lt;picture&gt; &lt;source srcset="https://tii.imgix.net/production/articles/5299/311bc6f4-90de-4a9c-9532-c04168b04634.png?w=400&amp;amp;fm=webp&amp;amp;auto=compress" media="(min-width: 1px) and (max-width: 9999px)" type="image/webp"&gt; &lt;source srcset="https://tii.imgix.net/production/articles/5299/311bc6f4-90de-4a9c-9532-c04168b04634.png?w=400&amp;amp;fm=jpeg&amp;amp;auto=compress" type="image/jpeg"&gt; &lt;img src="https://tii.imgix.net/production/articles/5299/311bc6f4-90de-4a9c-9532-c04168b04634.png?w=400&amp;amp;fm=jpeg&amp;amp;auto=compress" alt=""&gt; &lt;/picture&gt; &lt;/div&gt; &lt;/div&gt; &lt;p&gt; Thank you for your feedback on my column last week about the nightmare I believe is waiting for the news industry. It is clear that technology hasn’t just anointed Google, Facebook and Twitter the new gatekeepers. It has gone further and killed the very notion of a gatekeeper itself. The result is an increasingly loud mess of services where leaders can say what they want, whenever they... &lt;/p&gt; &lt;/div&gt; &lt;div&gt; &lt;div&gt; &lt;p&gt; Oscar Health Files to Go Public, Hippo in SPAC Talks &lt;/p&gt; &lt;p&gt; By Ross Matican · Feb. 5, 2021 &lt;/p&gt; &lt;/div&gt; &lt;div&gt; &lt;p&gt; Microsoft Suspends Donations to Politicians Who Voted to Overturn Election &lt;/p&gt; &lt;p&gt; By Kevin McLaughlin · Feb. 5, 2021 &lt;/p&gt; &lt;/div&gt; &lt;div&gt; &lt;p&gt; Alibaba’s $5 Billion Bond Draws Demand Despite Regulatory Crackdown &lt;/p&gt; &lt;p&gt; By Wayne Ma · Feb. 5, 2021 &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div&gt; &lt;p&gt;&lt;img src="https://www.theinformation.com/assets/app-articles-tab-screenshot-df5e9fa155933249c0cec82b657666156d6c21acdb60d1ea971bb7bd0ac37746.png" loading="lazy" id="app-screenshot" srcset="https://www.theinformation.com/assets/app-articles-tab-screenshot@2x-3c2289fa3376fba910bde19989adba825d62fb1385dbc047be504492de139916.png 2x, https://www.theinformation.com/assets/app-articles-tab-screenshot@3x-44c65f79a467abd2d085a16eee43e179fe5282888dc9f1179bf7f237812d10f3.png 3x"&gt; &lt;/p&gt; &lt;/div&gt; &lt;div&gt; &lt;p&gt;&lt;img src="https://www.theinformation.com/assets/locked-homepage-video-insert.jpg"&gt; &lt;/p&gt; &lt;/div&gt; &lt;div&gt; &lt;p&gt;&lt;img src="https://www.theinformation.com/images/locked-homepage-article-insert.png"&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/section&gt;&lt;/div&gt;&lt;a href="https://www.theinformation.com/articles/how-apple-is-working-from-home?utm_source=hackernews&amp;utm_medium=unlock"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Mon, 30 Mar 2020 17:53:21 UT
      </pubDate>
      <guid>
        https://www.theinformation.com/articles/how-apple-is-working-from-home?utm_source=hackernews&amp;utm_medium=unlock
      </guid>
    </item>
    <item>
      <title>
        404:This page could not be found
      </title>
      <link>
        https://www.aaronkharris.com/asking-questions
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div id="__next"&gt;&lt;h2&gt;404&lt;/h2&gt;&lt;p&gt;&lt;h2&gt;This page could not be found&lt;/h2&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;a href="https://www.aaronkharris.com/asking-questions"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Mon, 30 Mar 2020 17:57:49 UT
      </pubDate>
      <guid>
        https://www.aaronkharris.com/asking-questions
      </guid>
    </item>
    <item>
      <title>
        Google Is Ruining the Internet
      </title>
      <link>
        https://www.superhighway98.com/google
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div id="siteWrapper"&gt; &lt;main role="main" id="page"&gt; &lt;div data-edit-main-image="" data-collection-id="5973cf07893fc04502e1f016" data-content-field="main-content" id="content"&gt; &lt;article data-item-id="5ff328f5fc8ee327dd5f50b1" id="article-5ff328f5fc8ee327dd5f50b1"&gt; &lt;div id="item-5ff328f5fc8ee327dd5f50b1" data-block-type="2" data-updated-on="1609771272867" data-type="item" data-layout-label="Post Body"&gt;&lt;p&gt;In August 2018, I searched for "Henry Beard" in Google Images and got back a page full of pictures of Henry Cavill &lt;em&gt;with a beard&lt;/em&gt;. This didn't happen because Google is stupid. On the contrary, Google was smart enough to know that Henry Cavill's beard &lt;a href="https://trends.google.com/trends/explore?date=all&amp;amp;geo=US&amp;amp;q=henry%20cavill%20beard"&gt;was a hot topic&lt;/a&gt;: A QDF (query deserves freshness) algorithm altered the search results to &lt;em&gt;emphasize popularity over accuracy&lt;/em&gt;.&lt;/p&gt;&lt;p&gt;Search for "GM" and the Gmail homepage ranks prominently. Is Google pushing its own products on people? Well, &lt;a href="http://www.seobook.com/brands-vs-ads"&gt;yes&lt;/a&gt;, but not here. This is an example of a query refinement algorithm at work. Google is altering its results in recognition of the fact that many people who search "gm" subsequently search for "gmail." &lt;/p&gt;&lt;p&gt;(I.e. Based on what a searcher types next, Google knows when someone has made a fat finger error and then assumes that other fingers are fat, too.)&lt;/p&gt;&lt;p&gt;These examples are trivial, but they speak to a bigger problem.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;Rewarding laziness leads to more laziness&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Remember that story about the Polish dentist who pulled out all of her ex-boyfriend's teeth in an act of revenge? It was complete BS. 100% fabricated. &lt;a href="https://www.snopes.com/fact-check/boyfriend-pull-teeth/"&gt;No one knows who wrote it&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Nevertheless, it was picked up by &lt;em&gt;Fox News&lt;/em&gt;, the &lt;em&gt;Los Angeles Times&lt;/em&gt; and many other publishers. That was eight years ago, yet when I search now for "dentist pulled ex boyfriends teeth," I get a featured snippet that quotes &lt;em&gt;ABC News&lt;/em&gt;' original, uncorrected story.&lt;/p&gt;&lt;p&gt;Who invented the fidget spinner? Ask Google Assistant and it will tell you that Catherine Hettinger did: a conclusion based on poorly-reported stories from &lt;em&gt;The Guardian&lt;/em&gt;, &lt;em&gt;The New York Times&lt;/em&gt; and other major news outlets. &lt;a href="https://www.bloomberg.com/news/articles/2017-05-11/how-the-fidget-spinner-origin-story-spun-out-of-control"&gt;&lt;em&gt;Bloomberg&lt;/em&gt;'s Joshua Brustein&lt;/a&gt; clearly demonstrated that Ms. Hettinger did not invent the low friction toy. Nevertheless, ask Google Assistant "who &lt;em&gt;really&lt;/em&gt; invented the fidget spinner?" and you'll get the same answer: Catherine Hettinger.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;A Descent Into Mob Rule&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;a href="https://www.johnwdefeo.com/my-work/superhighway-98"&gt;In 1998&lt;/a&gt;, the velocity of information was slow and the cost of publishing it was high (even on the web). Google leveraged those realities to make the best information retrieval system in the world. &lt;/p&gt;&lt;p&gt;Today, information is free, plentiful and fast moving; somewhat by design, Google has become a card catalog that is constantly being reordered by an angry, misinformed mob.&lt;/p&gt;&lt;p&gt;The web was supposed to forcefully challenge our opinions and push back, like a personal trainer who doesn't care how tired his or her client is. Instead, Google has become like the pampering robots in &lt;em&gt;WALL-E&lt;/em&gt;, giving us what we want at the expense of what we need. But, it's not our bodies that are turning into mush: It’s our minds.&lt;/p&gt;&lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;/main&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://www.superhighway98.com/google"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 31 Mar 2020 21:22:13 UT
      </pubDate>
      <guid>
        https://www.superhighway98.com/google
      </guid>
    </item>
    <item>
      <title>
        Building a Literal Library of Building Blocks - sulami's blog
      </title>
      <link>
        https://sulami.github.io/posts/building-a-literal-library-of-building-blocks/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div id="container"&gt; &lt;article&gt; &lt;p&gt; Posted on February 2, 2019 &lt;/p&gt; &lt;section&gt; &lt;p&gt;This post&lt;span&gt;&lt;label for="sn-1"&gt;&lt;/label&gt;&lt;span&gt;I know, insert the obligatory “I haven’t posted in a while” bit here.&lt;/span&gt;&lt;/span&gt; is heavily inspired by &lt;a href="https://soundcloud.com/defn-771544745/30-zach-tellman-aka-ztellman"&gt;a remark Zach Tellman made on the defn podcast&lt;/a&gt;, where he says:&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;Having been a professional programmer for a decade, I have a decade’s worth of experience at writing stuff from scratch, not a decade’s worth of tools in my toolbox. And that seems like a not optimal set of circumstances. &lt;em&gt;[Quote at 57:45]&lt;/em&gt;&lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt;I have listened to this some time around Christmas, and this quote has kept me thinking over the past couple of months. What Zach is talking about is a project he is working on which would allow you to capture explorative programming in the branching fashion in which it happens. His example revolves around using a shell to perform some work, like extracting some specific values from a file.&lt;span&gt;&lt;label for="sn-2"&gt;&lt;/label&gt;&lt;span&gt;You should really go and listen to the episode, he has a lot of very great insights.&lt;/span&gt;&lt;/span&gt; He explains how we work out these sequences of commands that to accomplish our goal, but never generalise them, but instead throw them away, just to write them from scratch the next time we encounter a similar problem. This rings true for all kinds of programming, not just shell scripting, though shell scripts are especially susceptible to this.&lt;/p&gt; &lt;p&gt;Like Zach, I believe this to be a suboptimal situation. Especially being a functional programmer, I believe in small, abstract building blocks, composition, and code reuse, rather than overly specific, bespoke solutions that have to be written from scratch every time. I am someone who tinkers a lot, and there is a lot of code I never commit anywhere. As a matter of fact, I have a habit of creating throw-away files or whole projects in &lt;code&gt;/tmp&lt;/code&gt; just to play with something for anywhere between five minutes and a weekend. At the same time I also have a repository on my Github literally called playground, which contains all kinds of small things that I did not want to go through the hassle of creating a Github repository for.&lt;span&gt;&lt;label for="sn-3"&gt;&lt;/label&gt;&lt;span&gt;Interesting aside: while creating a local repository has so little friction that I do it all the time, only a fraction of them ever touch Github’s servers, as creating a repository through the web interface incurs so much friction.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;This repository has allowed me to cannibalise some snippets of codes I used in the past, but it is not what I would call a comprehensive library of generalised solutions to problems I repeatedly face. And that has been hugely helpful already, for example I have written about path-finding using the A* algorithm before, so I had a working implementation ready when I needed it for another project.&lt;/p&gt; &lt;p&gt;Having a library, in the worldly sense of the word, of useful, generalised snippets of code would institutionalise the knowledge of them. You would not have to remember how to invert a binary tree, because if you have ever played with binary trees you would already have an implementation handy, and it would be tried and tested, and performance-optimised.&lt;/p&gt; &lt;h2 id="practical-implementations"&gt;Practical Implementations&lt;/h2&gt; &lt;p&gt;Having arrived at the decision of generalising and collecting useful snippets of code somewhere, we are now facing the question of where somewhere actually is, and how we distribute the snippets in a way that allows us to easily use them.&lt;/p&gt; &lt;p&gt;The simplest solution would be to maintain one or several collections of useful snippets, and just copy-pasting them into the code you are writing. While this is fast and simple, it does not facilitate innovation flowing in either direction. Updates to the generalised versions are not included in downstream products using them, and vice versa. The result would likely be a duplication of similar, but subtly different solutions to all kinds of problems, scattered over various projects. Bugs that have long been fixed in one of them might still be present in others.&lt;/p&gt; &lt;p&gt;The alternative solution is packaging your snippets, and using them as a library. Most of the practical implementation will depend on the programming language you are using, and what kind of projects you are usually working on. Zach Tellman himself has a Clojure library called &lt;a href="https://github.com/ztellman/potemkin"&gt;Potemkin&lt;/a&gt;, which is a collection of “some ideas which are almost good”, and which he uses as a dependency for most of his other libraries.&lt;/p&gt; &lt;p&gt;While this incurs some overhead, namely the packaging of the library, it does come with a lot of advantages. Other people can benefit from your library. Depending on the scale of the overhead involved with building a library, splitting snippets by topic into “actual” libraries might make sense. It does require more abstraction, and more documentation, but that is not a bad thing. For a simple library with a handful of data structures or functions, writing a quick readme and some docstrings takes less than an hour.&lt;/p&gt; &lt;p&gt;There is still room for a default, catch-all library that is just for personal use and contains miscellaneous snippets without any particular topic, and it can be where new snippets end up first. If a section of it grows large enough, it can be extracted into its own library. The bottom line here is, if you write something that solves a problem, keep it somewhere, ideally where you can find it again. Even if it is not generalised or documented, it might come in handy in the future.&lt;/p&gt; &lt;/section&gt; &lt;/article&gt;&lt;/div&gt;&lt;/div&gt;&lt;a href="https://sulami.github.io/posts/building-a-literal-library-of-building-blocks/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Wed, 1 Apr 2020 12:03:04 UT
      </pubDate>
      <guid>
        https://sulami.github.io/posts/building-a-literal-library-of-building-blocks/
      </guid>
    </item>
    <item>
      <title>
        How to SSH Properly | SSH Security Best Practices | Teleport
      </title>
      <link>
        https://gravitational.com/blog/how-to-ssh-properly/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;article&gt; &lt;a href="https://gravitational.com/blog/index.xml"&gt;&lt;i&gt;&lt;/i&gt;&lt;/a&gt; &lt;h2&gt;How to SSH Properly&lt;/h2&gt; &lt;p&gt;&lt;img alt="SSH best practices" width="100%" src="https://gravitational.com/blog/images/2020/how-to-ssh-properly-header.png"&gt;&lt;/p&gt; &lt;p&gt;&lt;em&gt;This blog post has been updated as of 01/25/2021.&lt;/em&gt;&lt;/p&gt; &lt;h2 id="ssh-best-practices"&gt;SSH Best Practices&lt;/h2&gt; &lt;p&gt;There’s no denying that &lt;a href="https://www.openssh.com/"&gt;SSH&lt;/a&gt; is the &lt;em&gt;de facto&lt;/em&gt; tool for *nix server administration. It’s far from perfect, but it was designed with security in mind and there’s been a huge amount of tooling written over the years to make it easier to use. In addition, many popular products and just about every server deployment system integrates with SSH somehow. It is universally supported across pretty much all architectures and distributions, from Raspberry Pis all the way up to massive supercomputer clusters.&lt;/p&gt; &lt;p&gt;SSH is a powerful tool which often grants a lot of access to anyone using it to log into a server. In this post, I’m going to talk about a few different ways that you can easily improve the security of your SSH model without needing to deploy a new application or make any huge changes to user experience.&lt;/p&gt; &lt;p&gt;In essence, this blog post is a collection of &lt;strong&gt;industry best practices to SSH security&lt;/strong&gt;, and it’s written with OpenSSH users in mind.&lt;/p&gt; &lt;h2 id="ssh-certificates"&gt;SSH certificates&lt;/h2&gt; &lt;p&gt;Most people can agree that using public key authentication for SSH is generally better than using passwords. Nobody ever types in a private key, so it can’t be keylogged or observed over your shoulder. SSH keys have their own issues, however, some of which we’ve covered in a &lt;a href="https://gravitational.com/blog/ssh-key-management/"&gt;previous post about SSH key management&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;The next level up from SSH keys is SSH certificates. OpenSSH has supported the use of certificates since &lt;a href="https://www.openssh.com/txt/release-5.4"&gt;OpenSSH 5.4&lt;/a&gt; which was released back in 2010.&lt;/p&gt; &lt;p&gt;With &lt;a href="https://gravitational.com/blog/ssh-certificates-explained/"&gt;SSH certificates&lt;/a&gt;, you generate a certificate authority (CA) and then use this to issue and cryptographically sign certificates which can authenticate users to hosts, or hosts to users. You can generate a keypair using the &lt;code&gt;ssh-keygen&lt;/code&gt; command, like this:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="text"&gt;$ ssh-keygen -t rsa -b 4096 -f host_ca -C host_ca Generating public/private rsa key pair. Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in host_ca. Your public key has been saved in host_ca.pub. The key fingerprint is: SHA256:tltbnMalWg+skhm+VlGLd2xHiVPozyuOPl34WypdEO0 host_ca The key's randomart image is: +---[RSA 4096]----+ | +o.| | .+..o| | o.o.+ | | o o.= E| | S o o=o | | ....+ = +.| | ..=. %.o.o| | *o Oo=.+.| | .oo=ooo+..| +----[SHA256]-----+ $ ls -l total 8 -rw-------. 1 gus gus 3381 Mar 19 14:30 host_ca -rw-r--r--. 1 gus gus 737 Mar 19 14:30 host_ca.pub&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;The &lt;code&gt;host_ca&lt;/code&gt; file is the host CA’s private key and should be protected. Don’t give it out to anyone, don’t copy it anywhere, and make sure that as few people have access to it as possible. Ideally, it should live on a machine which doesn’t allow direct access and all certificates should be issued by an automated process.&lt;/p&gt; &lt;p&gt;In addition, it’s best practice to generate and use two separate CAs - one for signing host certificates, one for signing user certificates. This is because you don’t want the same processes that add hosts to your fleet to also be able to add users (and vice versa). Using separate CAs also means that in the event of a private key being compromised, you only need to reissue the certificates for either your hosts or your users, not both at once.&lt;/p&gt; &lt;p&gt;As such, we’ll also generate a &lt;code&gt;user_ca&lt;/code&gt; with this command:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="text"&gt;$ ssh-keygen -t rsa -b 4096 -f user_ca -C user_ca&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;The &lt;code&gt;user_ca&lt;/code&gt; file is the user CA’s private key and should also be protected in the same way as the host CA’s private key.&lt;/p&gt; &lt;h3 id="issuing-host-certificates-to-authenticate-hosts-to-users"&gt;Issuing host certificates (to authenticate hosts to users)&lt;/h3&gt; &lt;p&gt;In this example, we’ll generate a new host key (with no passphrase), then sign it with our CA. You can also sign the existing SSH host public key if you’d prefer not to regenerate a new key by copying the file (&lt;code&gt;/etc/ssh/ssh_host_rsa_key.pub&lt;/code&gt;) from the server, signing it on your CA machine, and then copying it back.&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="text"&gt;$ ssh-keygen -f ssh_host_rsa_key -N '' -b 4096 -t rsa $ ls -l -rw------- 1 ec2-user ec2-user 3247 Mar 17 14:49 ssh_host_rsa_key -rw-r--r-- 1 ec2-user ec2-user 764 Mar 17 14:49 ssh_host_rsa_key.pub $ ssh-keygen -s host_ca -I host.example.com -h -n host.example.com -V +52w ssh_host_rsa_key.pub Enter passphrase: # the passphrase used for the host CA Signed host key ssh_host_rsa_key-cert.pub: id "host.example.com" serial 0 for host.example.com valid from 2020-03-16T15:00:00 to 2021-03-15T15:01:37 $ ls -l -rw------- 1 ec2-user ec2-user 3247 Mar 17 14:49 ssh_host_rsa_key -rw-r--r-- 1 ec2-user ec2-user 2369 Mar 17 14:50 ssh_host_rsa_key-cert.pub -rw-r--r-- 1 ec2-user ec2-user 764 Mar 17 14:49 ssh_host_rsa_key.pub&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;&lt;code&gt;ssh_host_rsa_key-cert.pub&lt;/code&gt; contains the signed host certificate.&lt;/p&gt; &lt;p&gt;Here’s an explanation of the flags used:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;-s host_ca&lt;/code&gt;: specifies the filename of the CA private key that should be used for signing.&lt;/li&gt; &lt;li&gt;&lt;code&gt;-I host.example.com&lt;/code&gt;: the certificate’s identity - an alphanumeric string that will identify the server. I recommend using the server’s hostname. This value can also be used to revoke a certificate in future if needed.&lt;/li&gt; &lt;li&gt;&lt;code&gt;-h&lt;/code&gt;: specifies that this certificate will be a host certificate rather than a user certificate.&lt;/li&gt; &lt;li&gt;&lt;code&gt;-n host.example.com&lt;/code&gt;: specifies a comma-separated list of principals that the certificate will be valid for authenticating - for host certificates, this is the hostname used to connect to the server. If you have DNS set up, you should use the server’s FQDN (for example &lt;code&gt;host.example.com&lt;/code&gt;) here. If not, use the hostname that you will be using in an &lt;code&gt;~/.ssh/config&lt;/code&gt; file to connect to the server.&lt;/li&gt; &lt;li&gt;&lt;code&gt;-V +52w&lt;/code&gt;: specifies the validity period of the certificate, in this case 52 weeks (one year). Certificates are valid forever by default - expiry periods for host certificates are highly recommended to encourage the adoption of a process for rotating and replacing certificates when needed.&lt;/li&gt; &lt;/ul&gt; &lt;h3 id="configuring-ssh-to-use-host-certificates"&gt;Configuring SSH to use host certificates&lt;/h3&gt; &lt;p&gt;You also need to tell the server to use this new host certificate. Copy the three files you just generated to the server, store them under the &lt;code&gt;/etc/ssh&lt;/code&gt; directory, set the permissions to match the other files there, then add this line to your&lt;code&gt;/etc/ssh/sshd_config&lt;/code&gt; file:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="text"&gt;HostCertificate /etc/ssh/ssh_host_rsa_key-cert.pub&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;Once this is done, restart &lt;code&gt;sshd&lt;/code&gt; with &lt;code&gt;systemctl restart sshd&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Your server is now configured to present a certificate to anyone who connects. For your local &lt;code&gt;ssh&lt;/code&gt; client to make use of this (and automatically trust the host based on the certificate’s identity), you will also need to add the CA’s public key to your &lt;code&gt;known_hosts&lt;/code&gt; file.&lt;/p&gt; &lt;p&gt;You can do this by taking the contents of the &lt;code&gt;host_ca.pub&lt;/code&gt; file, adding &lt;code&gt;@cert-authority *.example.com&lt;/code&gt; to the beginning, then appending the contents to &lt;code&gt;~/.ssh/known_hosts&lt;/code&gt;:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="text"&gt;@cert-authority *.example.com ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQDwiOso0Q4W+KKQ4OrZZ1o1X7g3yWcmAJtySILZSwo1GXBKgurV4jmmBN5RsHetl98QiJq64e8oKX1vGR251afalWu0w/iW9jL0isZrPrmDg/p6Cb6yKnreFEaDFocDhoiIcbUiImIWcp9PJXFOK1Lu8afdeKWJA2f6cC4lnAEq4sA/Phg4xfKMQZUFG5sQ/Gj1StjIXi2RYCQBHFDzzNm0Q5uB4hUsAYNqbnaiTI/pRtuknsgl97xK9P+rQiNfBfPQhsGeyJzT6Tup/KKlxarjkMOlFX2MUMaAj/cDrBSzvSrfOwzkqyzYGHzQhST/lWQZr4OddRszGPO4W5bRQzddUG8iC7M6U4llUxrb/H5QOkVyvnx4Dw76MA97tiZItSGzRPblU4S6HMmCVpZTwva4LLmMEEIk1lW5HcbB6AWAc0dFE0KBuusgJp9MlFkt7mZkSqnim8wdQApal+E3p13d0QZSH3b6eB3cbBcbpNmYqnmBFrNSKkEpQ8OwBnFvjjdYB7AXqQqrcqHUqfwkX8B27chDn2dwyWb3AdPMg1+j3wtVrwVqO9caeeQ1310CNHIFhIRTqnp2ECFGCCy+EDSFNZM+JStQoNO5rMOvZmecbp35XH/UJ5IHOkh9wE5TBYIeFRUYoc2jHNAuP2FM4LbEagGtP8L5gSCTXNRM1EX2gQ== host_ca&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;The value &lt;code&gt;*.example.com&lt;/code&gt; is a pattern match, indicating that this certificate should be trusted for identifying any host which you connect to that has a domain of &lt;code&gt;*.example.com&lt;/code&gt; - such as &lt;code&gt;host.example.com&lt;/code&gt; above. This is a comma-separated list of applicable hostnames for the certificate, so if you’re using IP addresses or SSH config entries here, you can change this to something like &lt;code&gt;host1,host2,host3&lt;/code&gt; or &lt;code&gt;1.2.3.4,1.2.3.5&lt;/code&gt; as appropriate.&lt;/p&gt; &lt;p&gt;Once this is configured, remove any old host key entries for &lt;code&gt;host.example.com&lt;/code&gt; in your &lt;code&gt;~/.ssh/known_hosts&lt;/code&gt; file, and start an &lt;code&gt;ssh&lt;/code&gt; connection. You should be connected straight to the host without needing to trust the host key. You can check that the certificate is being presented correctly with a command like this:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="text"&gt;$ ssh -vv host.example.com 2&amp;gt;&amp;amp;1 | grep "Server host certificate" debug1: Server host certificate: &lt;a data-cfemail="bdceced590cfcedc90ded8cfc990cb8d8cfdd2cdd8d3ceced593ded2d0" href="https://gravitational.com/cdn-cgi/l/email-protection"&gt;[email&amp;nbsp;protected]&lt;/a&gt; SHA256:dWi6L8k3Jvf7NAtyzd9LmFuEkygWR69tZC1NaZJ3iF4, serial 0 ID "host.example.com" CA ssh-rsa SHA256:8gVhYAAW9r2BWBwh7uXsx2yHSCjY5OPo/X3erqQi6jg valid from 2020-03-17T11:49:00 to 2021-03-16T11:50:21 debug2: Server host certificate hostname: host.example.com&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;At this point, you could continue by issuing host certificates for all hosts in your estate using your host CA. The benefit of doing this is twofold: you no longer need to rely on the insecure &lt;a href="https://en.wikipedia.org/wiki/Trust_on_first_use"&gt;trust on first use (TOFU)&lt;/a&gt; model for new hosts, and if you ever redeploy a server and therefore change the host key for a certain hostname, your new host could automatically present a signed host certificate and avoid the dreaded &lt;code&gt;WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!&lt;/code&gt; message.&lt;/p&gt; &lt;h3 id="issuing-user-certificates-to-authenticate-users-to-hosts"&gt;Issuing user certificates (to authenticate users to hosts)&lt;/h3&gt; &lt;p&gt;In this example, we’ll generate a new user key and sign it with our user CA. It’s up to you whether you use a passphrase or not.&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="text"&gt;$ ssh-keygen -f user-key -b 4096 -t rsa $ ls -l -rw-r--r--. 1 gus gus 737 Mar 19 16:33 user-key.pub -rw-------. 1 gus gus 3369 Mar 19 16:33 user-key $ ssh-keygen -s user_ca -I &lt;a data-cfemail="4e293b3d0e29213a2b222b3e213c3a602d2123" href="https://gravitational.com/cdn-cgi/l/email-protection"&gt;[email&amp;nbsp;protected]&lt;/a&gt; -n ec2-user,gus -V +1d user-key.pub Enter passphrase: # the passphrase used for the user CA Signed user key user-key-cert.pub: id "&lt;a data-cfemail="197e6c6a597e766d7c757c69766b6d377a7674" href="https://gravitational.com/cdn-cgi/l/email-protection"&gt;[email&amp;nbsp;protected]&lt;/a&gt;" serial 0 for ec2-user,gus valid from 2020-03-19T16:33:00 to 2020-03-20T16:34:54 $ ls -l -rw-------. 1 gus gus 3369 Mar 19 16:33 user-key -rw-r--r--. 1 gus gus 2534 Mar 19 16:34 user-key-cert.pub -rw-r--r--. 1 gus gus 737 Mar 19 16:33 user-key.pub&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;&lt;code&gt;user-key-cert.pub&lt;/code&gt; contains the signed user certificate. You’ll need both this and the private key (&lt;code&gt;user-key&lt;/code&gt;) for logging in.&lt;/p&gt; &lt;p&gt;Here’s an explanation of the flags used:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;-s user_ca&lt;/code&gt;: specifies the CA private key that should be used for signing&lt;/li&gt; &lt;li&gt;&lt;code&gt;-I &lt;a data-cfemail="6205171122050d16070e07120d10164c010d0f" href="https://gravitational.com/cdn-cgi/l/email-protection"&gt;[email&amp;nbsp;protected]&lt;/a&gt;&lt;/code&gt;: the certificate’s identity, an alphanumeric string that will be visible in SSH logs when the user certificate is presented. I recommend using the email address or internal username of the user that the certificate is for - something which will allow you to uniquely identify a user. This value can also be used to revoke a certificate in future if needed.&lt;/li&gt; &lt;li&gt;&lt;code&gt;-n ec2-user,gus&lt;/code&gt;: specifies a comma-separated list of principals that the certificate will be valid for authenticating, i.e. the *nix users which this certificate should be allowed to log in as. In our example, we’re giving this certificate access to both &lt;code&gt;ec2-user&lt;/code&gt; and &lt;code&gt;gus&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;code&gt;-V +1d&lt;/code&gt;: specifies the validity period of the certificate, in this case &lt;code&gt;+1d&lt;/code&gt; means 1 day. Certificates are valid forever by default, so using an expiry period is a good way to limit access appropriately and ensure that certificates can’t be used for access perpetually.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;If you need to see the options that a given certificate was signed with, you can use &lt;code&gt;ssh-keygen -L&lt;/code&gt;:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="text"&gt;$ ssh-keygen -L -f user-key-cert.pub user-key-cert.pub: Type: &lt;a data-cfemail="abd8d8c386d9d8ca86c8ced9df86dd9b9aebc4dbcec5d8d8c385c8c4c6" href="https://gravitational.com/cdn-cgi/l/email-protection"&gt;[email&amp;nbsp;protected]&lt;/a&gt; user certificate Public key: RSA-CERT SHA256:egWNu5cUZaqwm76zoyTtktac2jxKktj30Oi/ydrOqZ8 Signing CA: RSA SHA256:tltbnMalWg+skhm+VlGLd2xHiVPozyuOPl34WypdEO0 (using ssh-rsa) Key ID: "&lt;a data-cfemail="a9cedcdae9cec6ddccc5ccd9c6dbdd87cac6c4" href="https://gravitational.com/cdn-cgi/l/email-protection"&gt;[email&amp;nbsp;protected]&lt;/a&gt;" Serial: 0 Valid: from 2020-03-19T16:33:00 to 2020-03-20T16:34:54 Principals: ec2-user gus Critical Options: (none) Extensions: permit-X11-forwarding permit-agent-forwarding permit-port-forwarding permit-pty permit-user-rc&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;h3 id="configuring-ssh-for-user-certificate-authentication"&gt;Configuring SSH for user certificate authentication&lt;/h3&gt; &lt;p&gt;Once you’ve signed a certificate, you also need to tell the server that it should trust certificates signed by the user CA. To do this, copy the &lt;code&gt;user_ca.pub&lt;/code&gt; file to the server and store it under &lt;code&gt;/etc/ssh&lt;/code&gt;, fix the permissions to match the other public key files in the directory, then add this line to &lt;code&gt;/etc/ssh/sshd_config&lt;/code&gt;:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="text"&gt;TrustedUserCAKeys /etc/ssh/user_ca.pub&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;Once this is done, restart &lt;code&gt;sshd&lt;/code&gt; with &lt;code&gt;systemctl restart sshd&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Your server is now configured to trust anyone who presents a certificate issued by your user CA when they connect. If you have a certificate in the same directory as your private key (specified with the &lt;code&gt;-i&lt;/code&gt; flag, for example &lt;code&gt;ssh -i /home/gus/user-key &lt;a data-cfemail="abcec89986ded8ced9ebc3c4d8df85ced3cac6dbc7ce85c8c4c6" href="https://gravitational.com/cdn-cgi/l/email-protection"&gt;[email&amp;nbsp;protected]&lt;/a&gt;&lt;/code&gt;), it will automatically be used when connecting to servers.&lt;/p&gt; &lt;h3 id="checking-logs"&gt;Checking logs&lt;/h3&gt; &lt;p&gt;If you look in your server’s &lt;code&gt;sshd&lt;/code&gt; log (for example, by running &lt;code&gt;journalctl -u sshd&lt;/code&gt;), you will see the name of the certificate being used for authentication, along with the fingerprint of the signing CA:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="text"&gt;sshd[14543]: Accepted publickey for ec2-user from 1.2.3.4 port 53734 ssh2: RSA-CERT ID &lt;a data-cfemail="a5c2d0d6e5c2cad1c0c9c0d5cad7d18bc6cac8" href="https://gravitational.com/cdn-cgi/l/email-protection"&gt;[email&amp;nbsp;protected]&lt;/a&gt; (serial 0) CA RSA SHA256:tltbnMalWg+skhm+VlGLd2xHiVPozyuOPl34WypdEO0&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;If the user tries to log in as a principal (user) which they do not have permission to use (for example, their certificate grants &lt;code&gt;ec2-user&lt;/code&gt; but they try to use &lt;code&gt;root&lt;/code&gt;), you’ll see this error in the logs:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="text"&gt;sshd[14612]: error: key_cert_check_authority: invalid certificate sshd[14612]: error: Certificate invalid: name is not a listed principal&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;If the certificate being presented has expired, you’ll see this error in the logs:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="text"&gt;sshd[14240]: error: key_cert_check_authority: invalid certificate sshd[14240]: error: Certificate invalid: expired&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;One way that you could make further use of user certificates is to set up a script which will use your CA to issue a certificate to log into production servers, valid only for the next two hours. Every use of this script or process could add logs as to who requested a certificate and embed their email address into the certificate. After this is done, every time the user uses that certificate to access a server (regardless of which principal they log in as), their email address will be logged. This can provide a useful part of an audit trail.&lt;/p&gt; &lt;p&gt;There are many other useful things you can do with SSH certificates, such as forcing a specific command to be run when presenting a certain certificate, or denying the ability to forward ports, X11 traffic or SSH agents. Take a look at &lt;code&gt;man ssh-keygen&lt;/code&gt; for some ideas.&lt;/p&gt; &lt;h2 id="enforce-the-use-of-a-bastion-host"&gt;Enforce the use of a bastion host&lt;/h2&gt; &lt;p&gt;Another way to improve your SSH security is to enforce the use of a &lt;a href="https://en.wikipedia.org/wiki/Bastion_host"&gt;bastion host&lt;/a&gt; - a server which is specifically designed to be the only gateway for access to your infrastructure. Lessening the size of any potential attack surface through the use of firewalls enables you to keep a better eye on who is accessing what.&lt;/p&gt; &lt;p&gt;Switching to the use of a bastion host doesn’t have to be an arduous task, especially if you’re using SSH certificates. By setting up your local &lt;code&gt;~/.ssh/config&lt;/code&gt; file, you can automatically configure all connections to hosts within a certain domain to go through the bastion.&lt;/p&gt; &lt;p&gt;Here’s a very quick example of how to force SSH access to any host in the example.com domain to be routed through a bastion host, &lt;code&gt;bastion.example.com&lt;/code&gt;:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="text"&gt;Host *.example.com ProxyJump bastion.example.com IdentityFile ~/user-key Host bastion.example.com ProxyJump none IdentityFile ~/user-key&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;To make this even simpler, if you add &lt;code&gt;user-key&lt;/code&gt; to your local &lt;code&gt;ssh-agent&lt;/code&gt; with &lt;code&gt;ssh-add user-key&lt;/code&gt;, you can also remove the &lt;code&gt;IdentityFile&lt;/code&gt; entries from the SSH config file.&lt;/p&gt; &lt;p&gt;Once you’re using the bastion host for your connections, you can use &lt;code&gt;iptables&lt;/code&gt; (or another *nix firewall configuration tool of your choosing) on servers behind the bastion to block all other incoming SSH connections. Here’s a rough example using &lt;code&gt;iptables&lt;/code&gt;:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="text"&gt;$ iptables -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT $ iptables -A INPUT -p tcp --dport 22 -s &amp;lt;public IP of the bastion&amp;gt; -j ACCEPT $ iptables -A INPUT -p tcp --dport 22 -j DROP&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;It’s a good idea to leave a second SSH session connected to the bastion while running these commands so that if you inadvertently input the wrong IP address or command, you should still have working access to the bastion to fix it via the already-established connection.&lt;/p&gt; &lt;h2 id="add-2-factor-authentication-to-your-ssh-logins"&gt;Add 2-factor authentication to your SSH logins&lt;/h2&gt; &lt;p&gt;2-factor authentication makes it more difficult for bad actors to log into your systems by enforcing the need for two different “factors” or methods to be able to successfully authenticate.&lt;/p&gt; &lt;p&gt;This usually comes down to needing both “something you know” (like a password, or SSH certificate in our example) and “something you have” (like a token from an app installed on your phone, or an SMS with a unique code). One other possibility is requiring the use of “something you are” - for example a fingerprint, or your voice.&lt;/p&gt; &lt;p&gt;In this example, we’ll install the &lt;code&gt;google-authenticator&lt;/code&gt; &lt;a href="https://en.wikipedia.org/wiki/Pluggable_authentication_module"&gt;pluggable authentication module&lt;/a&gt;, which will require users to input a code from the Google Authenticator app on their phone in order to log in successfully. You can download the app for &lt;a href="https://apps.apple.com/us/app/google-authenticator/id388497605"&gt;iOS here&lt;/a&gt; and &lt;a href="https://play.google.com/store/apps/details?id=com.google.android.apps.authenticator2"&gt;Android here&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;As a general note, it’s always important to consider the user experience when enforcing security measures. If your measures are too draconian then users may attempt to find ways to defeat and work around them, which will eventually reduce the overall security of your systems and lead to the creation of back doors. To give our users a reasonable experience in this example, we are only going to require 2-factor authentication to be able to log into our bastion host. Once authenticated there, users should be able to log into other hosts simply by using their valid SSH certificate. This combination should give an acceptable level of security without interfering too much with user workflows. With this in mind, however, it is always prudent and appropriate to enforce extra security measures in specific environments which contain critical production data or sensitive information.&lt;/p&gt; &lt;h3 id="install-google-authenticator"&gt;Install google-authenticator&lt;/h3&gt; &lt;p&gt;On RHEL/CentOS based systems, you can install the &lt;code&gt;google-authenticator&lt;/code&gt; module from the EPEL repository:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="text"&gt;$ sudo yum install https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm # for RHEL/CentOS 7, change for other versions $ sudo yum install google-authenticator&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;For Debian/Ubuntu-based systems, this is available as the &lt;code&gt;libpam-google-authenticator&lt;/code&gt; package:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="text"&gt;$ sudo apt-get install libpam-google-authenticator&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;The &lt;code&gt;google-authenticator&lt;/code&gt; module has many options you can set &lt;a href="https://github.com/google/google-authenticator-libpam/blob/master/man/google-authenticator.1.md"&gt;which are documented here&lt;/a&gt;. In the interest of saving time, we are going to use some sane defaults in this example: disallow reuse of the same token twice, issue time-based rather than counter-based codes, and limit the user to a maximum of three logins every 30 seconds. To set up Google 2-factor authentication with these settings, a user should run this command:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="text"&gt;$ google-authenticator -d -f -t -r 3 -R 30 -W&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;You can also run &lt;code&gt;google-authenticator&lt;/code&gt; with no flags and answer some prompts to set up interactively if you prefer.&lt;/p&gt; &lt;p&gt;This will output a QR code that the user can scan with the app on their phone, plus some backup codes which they can use if they lose access to the app. These codes should be stored offline in a secure location.&lt;/p&gt; &lt;p&gt;Scan the generated QR code for your user now with the Google Authenticator app and make sure that you have a 6-digit code displayed. If you need to edit or change any settings in future, or remove the functionality completely, the configuration will be stored under &lt;code&gt;~/.google_authenticator&lt;/code&gt;.&lt;/p&gt; &lt;h3 id="configure-pam-for-2-factor-authentication"&gt;Configure PAM for 2-factor authentication&lt;/h3&gt; &lt;p&gt;To make the system enforce the use of these OTP (one-time password) codes, we’ll first need to edit the PAM configuration for the &lt;code&gt;sshd&lt;/code&gt; service (&lt;code&gt;/etc/pam.d/sshd&lt;/code&gt;) and add this line to the end of the file:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="text"&gt;auth required pam_google_authenticator.so nullok&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;The &lt;code&gt;nullok&lt;/code&gt; at the end of this line means that users who don’t have a second factor configured yet will still be allowed to log in so that they can set one up. Once you have 2-factor set up for all your users, you should remove &lt;code&gt;nullok&lt;/code&gt; from this line to properly enforce the use of a second factor.&lt;/p&gt; &lt;p&gt;We also need to change the default authentication methods so that SSH won’t prompt users for a password if they don’t present a 2-factor token. These changes are also made in the &lt;code&gt;/etc/pam.d/sshd&lt;/code&gt; file:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;On RHEL/CentOS-based systems, comment out &lt;code&gt;auth substack password-auth&lt;/code&gt; by adding a &lt;code&gt;#&lt;/code&gt; to the beginning of the line: &lt;code&gt;#auth substack password-auth&lt;/code&gt;&lt;/li&gt; &lt;li&gt;On Debian/Ubuntu-based systems, comment out &lt;code&gt;@include common-auth&lt;/code&gt; by adding a &lt;code&gt;#&lt;/code&gt; to the beginning of the line: &lt;code&gt;#@include common-auth&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Save the &lt;code&gt;/etc/pam.d/sshd&lt;/code&gt; file once you’re done.&lt;/p&gt; &lt;h3 id="configure-ssh-for-2-factor-authentication"&gt;Configure SSH for 2-factor authentication&lt;/h3&gt; &lt;p&gt;We also need to tell SSH to require the use of 2-factor authentication. To do this, we make a couple of changes to the &lt;code&gt;/etc/ssh/sshd_config&lt;/code&gt; file.&lt;/p&gt; &lt;p&gt;Firstly, we need to change &lt;code&gt;ChallengeResponseAuthentication no&lt;/code&gt; to &lt;code&gt;ChallengeResponseAuthentication yes&lt;/code&gt; to allow the use of PAM for credentials.&lt;/p&gt; &lt;p&gt;We also need to set the list of acceptable methods for authentication by adding this line to the end of the file (or editing the line if it already exists):&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="text"&gt;AuthenticationMethods publickey,keyboard-interactive&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;This tells SSH that it should require both a public key (which we are going to be satisfying using an SSH certificate) and a keyboard-interactive authentication (which will be provided and satisfied by the &lt;code&gt;sshd&lt;/code&gt; PAM stack). Save the &lt;code&gt;/etc/ssh/sshd_config&lt;/code&gt; file once you’re done.&lt;/p&gt; &lt;p&gt;At this point, you should restart &lt;code&gt;sshd&lt;/code&gt; with &lt;code&gt;systemctl restart sshd&lt;/code&gt;. Make sure to leave an SSH connection open so that you can fix any errors if you need to. Restarting SSH will leave existing connections active, but new connections may not be allowed if there is a configuration problem.&lt;/p&gt; &lt;h3 id="test-it-out"&gt;Test it out&lt;/h3&gt; &lt;p&gt;Connect to your bastion host directly and you should see a prompt asking you for your 2-factor code:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="text"&gt;$ ssh bastion.example.com Verification code: &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;Type the code presented by your Google Authenticator app and your login should proceed normally.&lt;/p&gt; &lt;p&gt;If you check the &lt;code&gt;sshd&lt;/code&gt; log with &lt;code&gt;journalctl -u sshd&lt;/code&gt;, you should see a line indicating that your login succeeded:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code data-lang="text"&gt;Mar 23 16:51:13 ip-172-31-33-142.ec2.internal sshd[29340]: Accepted keyboard-interactive/pam for gus from 1.2.3.4 port 42622 ssh2&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt; &lt;p&gt;In conclusion, the recommended industry best practices for SSH security are:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Use SSH certificates&lt;/li&gt; &lt;li&gt;Enforce the use of bastion hosts&lt;/li&gt; &lt;li&gt;Add 2-factor authentication to your SSH logins&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The methods above give practical examples of several ways in which you can improve the security of your SSH infrastructure, all while giving users the flexibility to keep using the tools they’re familiar with.&lt;/p&gt; &lt;p&gt;This blog post was written by Gus, who works on &lt;a href="https://gravitational.com/teleport/how-it-works/"&gt;Teleport&lt;/a&gt;, the open-source SSH access tool which implements the industry-best practices for SSH access by default, and requires minimal configuration.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Related Posts&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://gravitational.com/blog/ssh-handshake-explained/"&gt;SSH Handshake Explained | What is SSH Handshake?&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://gravitational.com/blog/ssh-restricted-shells/"&gt;Restricted Shell | Restricted commands for SSH&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://gravitational.com/blog/ssh-certificate-authority-pinning/"&gt;How to Use Certificate Pinning to Improve UX&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;a href="https://gravitational.com/tags/ssh/"&gt;ssh&lt;/a&gt; &lt;a href="https://gravitational.com/tags/teleport/"&gt;teleport&lt;/a&gt; &lt;a href="https://gravitational.com/tags/security/"&gt;security&lt;/a&gt; &amp;nbsp; &lt;/article&gt;&lt;/div&gt;&lt;a href="https://gravitational.com/blog/how-to-ssh-properly/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Wed, 1 Apr 2020 17:29:19 UT
      </pubDate>
      <guid>
        https://gravitational.com/blog/how-to-ssh-properly/
      </guid>
    </item>
    <item>
      <title>
        A crash course in compilers – Increment: Programming Languages
      </title>
      <link>
        https://increment.com/programming-languages/crash-course-in-compilers/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;&lt;p&gt;Late one night on an uncrowded subway car in New York City, I had my laptop open, working on a game whose deadline was drawing near. A gentleman sat next to me and, seeing the walls of colored text on my screen, asked if I was writing C++. I told him I wasn’t, and he was curious to hear what language I was using. I was working on a web game in a programming language I had designed for myself, and I told him so&lt;span&gt;—&lt;/span&gt;it was something that I made up, I said. After looking at me for a moment, he asked,&lt;span&gt;&lt;/span&gt;&lt;span&gt; “&lt;/span&gt;Why would anyone do that?” I started to answer, but alas, we had arrived at his stop, and he disappeared onto the platform before I could explain myself. In many ways, I’ve been trying to answer that man’s question for years&amp;nbsp;now&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;The thing is, I absolutely love programming languages. I work as a graphics and video game developer, which is thrilling and challenging work, but secretly I would rather be hacking on compilers. I love languages because, of everything I’ve encountered in computing, languages are by far the weirdest. They combine the brain-bending rigor of abstract math, the crushing pressures of capitalistic industry, and the irrational anxiety of a high school prom. The decision to adopt or avoid a language is always a mix of their perceived formal power (“Does this language even have this particular feature?”), employability (“Will this language get me a job?”), and popularity (“Does anyone important use this language anymore?”). I can’t think of another engineering tool that demands similar quasi-religious devotion from its users. Programming languages ask us to reshape our minds, and that makes them deeply personal and&amp;nbsp;subjective&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;The field of study of programming languages is called programming language theory, or &lt;span&gt;PLT.&lt;/span&gt; Software engineers are confronted with programming languages just about every day, but few develop a deep relationship with &lt;span&gt;PLT.&lt;/span&gt; Languages are tools, primarily, a means to an end, and most professionals will do fine just learning to use the popular ones well enough to get their jobs&amp;nbsp;done&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Diving deeper into &lt;span&gt;PLT,&lt;/span&gt; though, is a great way to grow as a developer. Not only is language design a lot of fun, but a deeper understanding of the tools you use every day will give you a better handle on them, and can make learning new languages considerably easier, even if you don’t dream of becoming the next &lt;a href="https://www.python.org/"&gt;&lt;strong&gt;Guido van Rossum&lt;/strong&gt;&lt;/a&gt; or &lt;a href="https://clojure.org/"&gt;&lt;strong&gt;Rich Hickey&lt;/strong&gt;&lt;/a&gt;. And hey, you never know&lt;span&gt;—&lt;/span&gt;your personal project could become the next major piece of software engineering infrastructure. &lt;a href="https://secure.php.net/history.php"&gt;It’s happened&amp;nbsp;before&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;h2 id="what-is-a-programming-language"&gt;&lt;a href="#what-is-a-programming-language"&gt;What is a programming language?&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;So, what is a programming language? This might seem like an odd question to ask about tools this ubiquitous, but starting from a definition is often helpful to focus the conversation. A programming language is a formal language used to communicate instructions to a computer. It is formal in that it conforms to a rigid set of rules that determine what is and is not allowed. It is a means of communication in that the primary goal of the tool is to translate ideas in a programmer’s head into a form that a computer can act on. The fact that you are communicating with a computer is significant. Unlike other forms of language, or even instructional arts like musical composition or screenwriting, the final agent fulfilling the instructions is not human. The result is that qualities that other forms of communication tend to depend on&lt;span&gt;—&lt;/span&gt;like intuition, common sense, and context&lt;span&gt;—&lt;/span&gt;are not&amp;nbsp;available&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;The decisive factor in what makes something a programming language (or not) is known as Turing completeness. Alan Turing’s seminal work in the 1940s included the definition of the Turing machine, a mathematical description of an abstract computer that became foundational for our understanding of how algorithms work. A Turing machine can, provably, implement any computable algorithm, and any system that can simulate the Turing machine can do so as well. Such a system is deemed Turing complete, and most programming languages have this status as a basic goal (though there are some interesting languages that do not). A deep dive into computability theory is beyond the scope of this article, but suffice it to say that a language with some notion of state (often variables or argument passing) and conditionals is most likely Turing complete. This leaves out markup languages like &lt;span&gt;HTML &lt;/span&gt;and configuration languages like &lt;span&gt;YAML &lt;/span&gt;or &lt;span&gt;JSON,&lt;/span&gt; but includes a hilarious collection of systems that are &lt;a href="http://beza1e1.tuxen.de/articles/accidentally_turing_complete.html"&gt;accidentally Turing complete&lt;/a&gt; (including an abuse of &lt;span&gt;HTML &lt;/span&gt;and&amp;nbsp;&lt;span&gt;CSS)&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;In practice, you interact with programming languages via computer programs or software libraries into which you feed code in order to produce an effect. They come in two broad manifestations: as compilers and as interpreters. Each approach has its advantages and disadvantages, and the line between the two can be quite blurry, with frameworks like Mono going so far as to &lt;a href="http://www.mono-project.com/news/2017/11/13/mono-interpreter/"&gt;offer both simultaneously&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;An interpreter’s job is to take source code and immediately implement its effects. An interpreter turns source code into an internal representation that it can use to carry out the computation the source code describes. This representation will include the functions, variables, expressions, statements, and all other semantics of the source language. You can think of source code as an extreme, Turing-complete configuration file that controls the interpreter’s behavior. My first foray into language design was based on &lt;a href="http://norvig.com/lispy.html"&gt;Peter Norvig’s excellent Lispy interpreter in Python&lt;/a&gt;, and the more recent &lt;strong&gt;&lt;a href="https://github.com/kanaka/mal"&gt;&lt;span&gt;MAL &lt;/span&gt;project&lt;/a&gt;&lt;/strong&gt; has amassed implementations in 72 languages. The advantages of interpreters include their simplicity, the fact that they can often start executing faster than compilers, and their ability to run in environments where compiling new code is prohibited (like on &lt;a href="https://developer.apple.com/app-store/review/guidelines/#software-requirements"&gt;iOS&lt;/a&gt; or most video game&amp;nbsp;consoles)&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;This piece, however, will focus on compilers. The job of a compiler is to take source code and translate it into a target code with the same meaning. Often that target code is in a lower-level language like machine code, but that isn’t always the case. The generated target code can then be evaluated in order to carry out the computation of the original source code. Compilers can be thought of as a pipeline of transformations, starting with the programmer’s source code and proceeding through a series of internal representations that end in the desired target code, after which it is handed off to another system for&amp;nbsp;evaluation&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;The classic example is a compiler for the C programming language, where source code written in C is compiled into machine code that a computer’s hardware can execute directly. In this case, a higher-level language is compiled into a lower-level one. C# and Java are similar, but they compile into &lt;strong&gt;bytecodes&lt;/strong&gt; that are executed by the &lt;a href="https://en.wikipedia.org/wiki/Common_Language_Runtime"&gt;Common Language Runtime&lt;/a&gt; (&lt;span&gt;CLR)&lt;/span&gt; and the &lt;a href="https://en.wikipedia.org/wiki/Java_bytecode"&gt;Java virtual machine&lt;/a&gt; (&lt;span&gt;JVM)&lt;/span&gt;, respectively, as opposed to physical hardware. Virtual machines like the &lt;span&gt;CLR &lt;/span&gt;and the &lt;span&gt;JVM &lt;/span&gt;provide cross-platform environments that handle a lot of low-level details for you while providing additional functionality like garbage collection and a type system. There are even cases where it is desirable to compile a lower-level language into a higher-level one. To run in the browser, the &lt;a href="http://jsil.org/"&gt;&lt;span&gt;JSIL&lt;/span&gt;&lt;/a&gt; project compiles C# bytecode into JavaScript so it can run on the web, and &lt;a href="https://github.com/kripken/emscripten"&gt;Emscripten&lt;/a&gt; does the same for C and C++. There are also situations where the same language is both the source and target language. The so-called transpilers &lt;a href="https://babeljs.io/"&gt;Babel&lt;/a&gt; and &lt;a href="https://developers.google.com/closure/"&gt;Closure&lt;/a&gt; compile JavaScript into JavaScript in order to access new features of the language and implement optimizations,&amp;nbsp;respectively&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;h2 id="how-does-a-compiler-work"&gt;&lt;a href="#how-does-a-compiler-work"&gt;How does a compiler work?&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Compilers tend to proceed in a linear sequence of phases, each phase providing the next with its input. Even wildly different languages will broadly have the same structure. Comparing the compilation steps of different languages is a useful way to get a handle on the general process, and to begin to grok how a compiler&amp;nbsp;works&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;h3 id="parsing"&gt;Parsing&lt;/h3&gt;&lt;p&gt;The first question a compiler has to answer is,&lt;span&gt;&lt;/span&gt;&lt;span&gt; “&lt;/span&gt;What did the programmer say?” This step in the compiler pipeline is usually called parsing. The user prepares source code that is valid in the language they are programming in. Source code is often text, but it doesn’t have to be&lt;span&gt;—&lt;/span&gt;take the visual languages &lt;a href="https://scratch.mit.edu/"&gt;Scratch&lt;/a&gt;, &lt;a href="https://puredata.info/"&gt;Pure Data (Pd&lt;/a&gt;), and &lt;a href="https://cycling74.com/products/max/"&gt;Max/&lt;span&gt;MSP&lt;/span&gt;&lt;/a&gt;, for example. Once the programmer has prepared their source code, the compiler’s first task is to turn it into a data structure that is useful to later stages of the compiler. This is the stage where errors specific to the syntax are reported, like missing semicolons or unmatched braces. This is done differently from language to language, but in two broad categories: Lisp reading and scanning/parsing&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Languages in the Lisp family are notorious for their simple syntaxes. The simplicity is a result of deliberate design, but also a side-effect of a property that Lisp programmers take very seriously: Lisp source code is a literal representation of Lisp data. Put another way, Lisp source code is &lt;a href="https://en.wikipedia.org/wiki/Homoiconicity"&gt;homoiconic&lt;/a&gt; with Lisp data. To that end, the first step in a Lisp compiler is to turn source code text into data structures that the language understands. Historically this has included lists, numbers, and symbols, known collectively as&lt;span&gt;&lt;/span&gt;&lt;span&gt; “&lt;/span&gt;symbolic expressions” or&lt;span&gt;&lt;/span&gt;&lt;span&gt; “&lt;/span&gt;s-expressions,” but modern Lisps like Clojure include hashmaps, vectors, and sets in their syntax. Lisps traditionally call this step&lt;span&gt;&lt;/span&gt;&lt;span&gt; “&lt;/span&gt;reading” instead of parsing (which is where the R in &lt;a href="https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop"&gt;&lt;span&gt;REPL&lt;/span&gt;&lt;/a&gt; comes from, a Lisp idea). Lisp readers are simple enough that they tend to be written by hand. &lt;a href="https://github.com/clojure/clojure/blob/master/src/jvm/clojure/lang/LispReader.java"&gt;Clojure’s reader&lt;/a&gt; is handwritten in Java and contains a combination of regular expressions and &lt;a href="https://github.com/clojure/clojure/blob/master/src/jvm/clojure/lang/LispReader.java#L282"&gt;string operations&lt;/a&gt; to convert text into data structures, even matching against &lt;a href="https://github.com/clojure/clojure/blob/master/src/jvm/clojure/lang/LispReader.java#L383"&gt;string literals&lt;/a&gt; when it needs&amp;nbsp;to&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Languages with more complex syntax require more work. The majority of mainstream languages require a two-step process: scanning followed by parsing. A scanner (also known as a lexical analyzer) reads source text and produces a linear stream of tokens; the parser reads the stream of tokens and recognizes patterns to transform into nodes in an abstract syntax tree that the next step of the pipeline will deal with. The complexity of this step depends on the complexity of the syntax of the language. Some languages will use handwritten scanners and parsers, while others will depend on parser generators like Lex/Yacc or &lt;a href="https://github.com/westes/flex"&gt;Flex&lt;/a&gt;/&lt;a href="https://www.gnu.org/software/bison/"&gt;Bison&lt;/a&gt;, which take as input a specification of the desired grammar of the language, and produce as output a scanner and parser for that&amp;nbsp;language&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;TypeScript’s &lt;a href="https://github.com/Microsoft/TypeScript/blob/master/src/compiler/scanner.ts"&gt;scanner&lt;/a&gt; is handwritten and features recognizable constructs like &lt;a href="https://github.com/Microsoft/TypeScript/blob/master/src/compiler/scanner.ts#L64"&gt;mapping from keywords to token types&lt;/a&gt; and a &lt;a href="https://github.com/Microsoft/TypeScript/blob/master/src/compiler/scanner.ts#L1413"&gt;large statement switching on character codes&lt;/a&gt; to determine what to scan next. The tokens allow the &lt;a href="https://github.com/Microsoft/TypeScript/blob/master/src/compiler/parser.ts"&gt;parser&lt;/a&gt; to reason with higher-level constructs like &lt;code&gt;SyntaxKind.​AsteriskToken&lt;/code&gt; and &lt;code&gt;SyntaxKind.​OpenBraceToken&lt;/code&gt; as in the &lt;code&gt;&lt;a href="https://github.com/Microsoft/TypeScript/blob/master/src/compiler/parser.ts#L5906"&gt;parse​Import​Declaration​Or​Import​Equals​Declaration&lt;/a&gt;&lt;/code&gt; function. CoffeeScript relies on &lt;a href="https://github.com/zaach/jison"&gt;Jison&lt;/a&gt;, a JavaScript port of Bison, for &lt;a href="https://github.com/jashkenas/coffeescript/blob/master/src/grammar.coffee"&gt;its parsing&lt;/a&gt;. We can see the language described as &lt;a href="https://github.com/jashkenas/coffeescript/blob/master/src/grammar.coffee#L71"&gt;a grammar&lt;/a&gt; with declarative rules, like the rules for &lt;a href="https://github.com/jashkenas/coffeescript/blob/master/src/grammar.coffee#L779"&gt;if expressions&lt;/a&gt;. Ruby’s Yacc grammar is a favorite of mine: In order to implement Ruby’s famously appealing syntax, the grammar comes out to a colossal 11,400+ lines of Yacc&amp;nbsp;code!&lt;/p&gt;&lt;h3 id="analysis"&gt;Analysis&lt;/h3&gt;&lt;p&gt;Once parsing is complete, the compiler must analyze the parsed code into an abstract syntax tree, or &lt;span&gt;AST.&lt;/span&gt; Analysis answers the question,&lt;span&gt;&lt;/span&gt;&lt;span&gt; “&lt;/span&gt;What did the user mean?” Languages in the Lisp family will usually take an additional step to go from the s-expressions the reader produced to an initial &lt;span&gt;AST,&lt;/span&gt; while the parsers of languages outside the Lisp family will usually produce an &lt;span&gt;AST &lt;/span&gt;directly. This is where the semantic features of the language are implemented, like name resolution, control flow, and function invocation. Additionally, analysis is a phase where optimizations can begin to happen, by transforming the &lt;span&gt;AST &lt;/span&gt;into semantically equivalent &lt;span&gt;ASTs&lt;/span&gt; that perform better. This is likely the most varied phase between compilers, and each language will be radically different here. There aren’t really any libraries or &lt;span&gt;APIs&lt;/span&gt; to lean on here, and it’s up to the language implementer to derive this meaning&amp;nbsp;themselves&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;In languages with types, this is where type information is inferred, flowed, and validated. Even dynamically typed languages can flow type information in order to gain performance. For example, Clojure&lt;span&gt;CLR &lt;/span&gt;uses &lt;strong&gt;reflection&lt;/strong&gt; to determine the type of its &lt;a href="https://github.com/clojure/clojure-clr/blob/master/Clojure/Clojure/CljCompiler/Ast/StaticMethodExpr.cs#L83"&gt;static method invocations&lt;/a&gt; and &lt;a href="https://github.com/clojure/clojure-clr/blob/master/Clojure/Clojure/CljCompiler/Ast/StaticFieldExpr.cs#L106"&gt;static field lookups&lt;/a&gt;. This information is used to generate better bytecode and compiler errors. Languages like TypeScript provide a type system to a target that is dynamically typed by &lt;a href="https://github.com/Microsoft/TypeScript/blob/master/src/compiler/checker.ts"&gt;thoroughly checking types in the analysis phase&lt;/a&gt; and issuing a warning if types do not line up. Type-safe languages like Haskell will dedicate a &lt;a href="https://github.com/ghc/ghc/tree/master/compiler/typecheck"&gt;large portion of their analysis&lt;/a&gt; phase to type&amp;nbsp;checking&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;h3 id="emission"&gt;Emission&lt;/h3&gt;&lt;p&gt;Once an &lt;span&gt;AST &lt;/span&gt;is produced and settled on, the final step is to emit the target code. When targeting machine code, modern languages will most often use the &lt;a href="https://llvm.org/"&gt;&lt;span&gt;LLVM &lt;/span&gt;toolchain&lt;/a&gt;. &lt;span&gt;LLVM &lt;/span&gt;is an exciting project because it unifies various hardware platforms and optimizations under one target. It specifies its own &lt;a href="https://llvm.org/docs/LangRef.html"&gt;intermediate representation (&lt;span&gt;LLVM &lt;/span&gt;&lt;span&gt;IR)&lt;/span&gt;&lt;/a&gt; that a compiler would emit. &lt;span&gt;IR &lt;/span&gt;code then goes through the same parse-analyze-emit pipeline described in this article to turn into machine code. The benefit is that &lt;span&gt;LLVM &lt;/span&gt;presents a more straightforward assembly language that is still very low level without concerning the language developer with platform-specific quirks. Targeting &lt;span&gt;IR &lt;/span&gt;means your language can take advantage of optimizations written for C and C++ with no additional effort on your part. &lt;span&gt;LLVM &lt;/span&gt;exposes both a &lt;a href="https://llvm.org/docs/ProgrammersManual.html"&gt;C++&lt;/a&gt; and a &lt;a href="https://llvm.org/doxygen/group__LLVMC.html"&gt;C&lt;/a&gt; &lt;span&gt;API &lt;/span&gt;to generate &lt;span&gt;IR.&lt;/span&gt; The C &lt;span&gt;API &lt;/span&gt;means bindings to other languages are possible (I’ve successfully used them in &lt;a href="https://github.com/kevinmehall/node-llvm"&gt;Node&lt;/a&gt; and &lt;a href="https://github.com/Microsoft/LLVMSharp/"&gt;C#&lt;/a&gt;). &lt;span&gt;LLVM &lt;/span&gt;can even be found in compilers for dynamic languages like&amp;nbsp;&lt;a href="https://github.com/JuliaLang/julia/blob/master/src/codegen.cpp#L3345"&gt;Julia&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Virtual machine targets like the &lt;span&gt;CLR &lt;/span&gt;and the &lt;span&gt;JVM &lt;/span&gt;are similar, but each exposes a bytecode language that is at an even higher level than &lt;span&gt;LLVM &lt;/span&gt;&lt;span&gt;IR.&lt;/span&gt; C#’s standard library provides a very robust namespace &lt;a href="https://msdn.microsoft.com/en-us/library/system.reflection.emit%28v=vs.110%29.aspx"&gt;specifically for generating bytecode&lt;/a&gt; that exposes an object-oriented interface to emit &lt;a href="https://msdn.microsoft.com/en-us/library/system.reflection.emit.assemblybuilder%28v=vs.110%29.aspx"&gt;assemblies&lt;/a&gt;, &lt;a href="https://msdn.microsoft.com/en-us/library/system.reflection.emit.typebuilder%28v=vs.110%29.aspx"&gt;types&lt;/a&gt;, &lt;a href="https://msdn.microsoft.com/en-us/library/system.reflection.emit.methodbuilder%28v=vs.110%29.aspx"&gt;methods&lt;/a&gt;, and every other aspect of bytecode. Java does not have a comparable namespace in its own standard library, but third-party libraries like &lt;a href="http://asm.ow2.org/"&gt;&lt;span&gt;ASM&lt;/span&gt;&lt;/a&gt; or &lt;a href="https://commons.apache.org/proper/commons-bcel/"&gt;&lt;span&gt;BCEL&lt;/span&gt;&lt;/a&gt; can fill this gap. These &lt;span&gt;APIs&lt;/span&gt; can be seen in somewhat wrapped form in Clojure’s &lt;a href="https://github.com/clojure/clojure/blob/master/src/jvm/clojure/lang/Compiler.java#L3795"&gt;&lt;span&gt;JVM&lt;/span&gt;&lt;/a&gt; and &lt;a href="https://github.com/clojure/clojure-clr/blob/master/Clojure/Clojure/CljCompiler/Ast/InvokeExpr.cs#L382"&gt;&lt;span&gt;CLR&lt;/span&gt;&lt;/a&gt;&amp;nbsp;compilers&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;If the target is source code in a high-level language, emission might actually involve concatenating strings together. There often isn’t an existing &lt;span&gt;API &lt;/span&gt;to generate source code in a high-level programming language&lt;span&gt;—&lt;/span&gt;the expectation is that a human programmer will manually type it all out. This is an issue for languages that compile to JavaScript, as is evident in the &lt;a href="https://github.com/clojure/clojurescript/blob/master/src/main/clojure/cljs/compiler.cljc#L604"&gt;ClojureScript&lt;/a&gt; and &lt;a href="https://github.com/Microsoft/TypeScript/blob/master/src/compiler/emitter.ts#L1877"&gt;TypeScript&lt;/a&gt; compilers. Some languages, like Carp, treat C as their compile target, resulting in &lt;a href="https://github.com/carp-lang/Carp/blob/master/src/Emit.hs#L537"&gt;similar-looking emission&amp;nbsp;phases&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;h3 id="tooling-and-ecosystems"&gt;Tooling and ecosystems&lt;/h3&gt;&lt;p&gt;At this point, formally speaking, you’re done! The compiler has transformed code from the source language into the target language and achieved its basic goal. In practice, however, the job of a language designer is just beginning. Languages are more than their compilers, and the day-to-day experience of working with a language actually involves myriad developer tools acting in concert. Once a language’s compiler is working, the question then becomes one of editor integration, debugger support, documentation, a community, and a library ecosystem. Most of this takes considerable time to develop, and this is what gives existing languages inertia over new&amp;nbsp;ones&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Historically, languages had not directly addressed the task of managing third-party libraries, or packages. In the pre-web, pre-open source days, when languages like C++ arrived, the issue of integrating with a stranger’s code was nowhere near as complicated as it is now. Even languages that appeared in the 1990s tended to not include package managers, with Ruby’s &lt;a href="https://rubygems.org/"&gt;RubyGems&lt;/a&gt; not landing until eight years after Ruby itself. Post-web languages are more likely to include a package manager as part of their standard tooling, as &lt;a href="http://elm-lang.org/blog/announce/package-manager"&gt;Elm&lt;/a&gt; and &lt;a href="https://github.com/rust-lang/cargo"&gt;Rust&lt;/a&gt; do. Most package managers are specific to their languages, custom built, and require server infrastructure, though generic solutions like &lt;a href="https://github.com/whyrusleeping/gx"&gt;Gx&lt;/a&gt; and &lt;a href="https://nixos.org/nix/"&gt;Nix&lt;/a&gt; are available as well. Gx is interesting because it operates over &lt;a href="https://ipfs.io/"&gt;&lt;span&gt;IPFS&lt;/span&gt;&lt;/a&gt;, a peer-to-peer protocol that requires no central server coordination. Nix is the result of Eelco Dolstra’s PhD thesis,&lt;span&gt;&lt;/span&gt;&lt;span&gt; “&lt;/span&gt;&lt;a href="http://grosskurth.ca/bib/2006/dolstra-thesis.pdf"&gt;The Purely Functional Software Deployment Model&lt;/a&gt;,” and is primarily used in the Nix&lt;span&gt;OS &lt;/span&gt;operating system. It’s purely functional and, as a result, provides very reproducible&amp;nbsp;deployments&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Integrating with editors has also been a pain, traditionally. Programmers expect good syntax highlighting, completion, and other features all in their favorite editor. It was usually up to the community to provide these bindings, leading to an uneven developer experience across editors. Recently, Microsoft has put out what they call the &lt;a href="https://langserver.org/"&gt;Language Server Protocol&lt;/a&gt; to help address these issues and make it easier to integrate new programming languages with text editors. It’s essentially a network protocol for a text editor. Your language only needs to implement the protocol once, and then every editor that supports it (which is most major editors) can communicate with your language to get autocomplete and other&amp;nbsp;features&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;h2 id="why-anyone-would-do-this"&gt;&lt;a href="#why-anyone-would-do-this"&gt;Why anyone would do this&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;If you’re reading this, gentleman from the subway, I hope it has begun to answer your question about why anyone would make up a programming language. It’s a wonderful puzzle to solve, and more approachable than it may seem at first. Languages represent different ideas of how to capture human creativity on a machine, and I’ve never been disappointed by pulling the curtain back on an implementation to see how it ticks. Seeing common patterns across different languages and getting a sense of their trade-offs also gives you a new perspective when picking up new languages, something every working programmer will have to do at some point in their&amp;nbsp;career&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Whether you’re building the next chapter in the history of software engineering or just peeking under the hood of a machine that you use every day, the world of programming languages is yours to explore. It will expand your mind and make you a better programmer&lt;span&gt;—&lt;/span&gt;and you might not even be the strangest person on the&amp;nbsp;train&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;a href="https://increment.com/programming-languages/crash-course-in-compilers/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Thu, 2 Apr 2020 21:24:50 UT
      </pubDate>
      <guid>
        https://increment.com/programming-languages/crash-course-in-compilers/
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://www.cs.cmu.edu/~mleone/how-to.html
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt; A collection of advice about how to do research and how to communicate effectively (primarily for computer scientists). &lt;h2&gt;Writing and Publishing&lt;/h2&gt; &lt;ul&gt; &lt;li&gt; &lt;a href="http://www.sce.carleton.ca/faculty/chinneck/thesis.html"&gt; How to Organize your Thesis&lt;/a&gt;, by John W. Chinneck. &lt;/li&gt;&lt;li&gt; &lt;a href="ftp://parcftp.xerox.com/pub/popl96/pugh/advice.ps.Z"&gt; Advice to Authors of Extended Abstracts&lt;/a&gt;, by William Pugh. &lt;/li&gt;&lt;li&gt; &lt;a href="ftp://ftp.math.ohio-state.edu/pub/math.style/hint.ps"&gt;Hints on good mathematical writing&lt;/a&gt;, by David Goss &lt;/li&gt;&lt;li&gt; &lt;a href="ftp://ftp.math.ohio-state.edu/pub/math.style/mit.ps"&gt; A primer on mathematical writing&lt;/a&gt;, by Steven L. Kleiman &lt;/li&gt;&lt;li&gt; &lt;a href="ftp://parcftp.xerox.com/pub/popl96/vanLeunenLipton"&gt; How To Have Your Abstract Rejected&lt;/a&gt;, by van Leunen and Lipton. &lt;/li&gt;&lt;li&gt; &lt;a href="ftp://fast.cs.utah.edu/pub/writing-papers.ps"&gt; An Evaluation of the Ninth SOSP Submissions, or, How (and How Not) to Write a Good Systems Paper&lt;/a&gt; by Roy Levin and David D. Redell &lt;/li&gt;&lt;li&gt; &lt;a href="http://ursamajor.uvic.ca/how.to.publish.html"&gt; How to Get a Paper Accepted at OOPSLA&lt;/a&gt;, by Alan Snyder. &lt;ul&gt; &lt;li&gt; Includes &lt;a href="http://ursamajor.uvic.ca/how.to.panel.html"&gt; comments from an OOPSLA program committee.&lt;/a&gt; &lt;/li&gt;&lt;/ul&gt; &lt;/li&gt;&lt;li&gt; &lt;a href="ftp://parcftp.xerox.com/pub/popl96/suggestions"&gt; Advice for 1996 POPL submissions&lt;/a&gt; &lt;/li&gt;&lt;/ul&gt; &lt;h2&gt;Research Skills&lt;/h2&gt; &lt;ul&gt; &lt;li&gt; &lt;a href="http://www.cs.umd.edu/~oleary/gradstudy/gradstudy.html"&gt; Graduate Study in the Computer and Mathematical Sciences: A Survival Manual&lt;/a&gt;, by Dianne O'Leary &lt;/li&gt;&lt;li&gt; &lt;a href="http://www.cs.indiana.edu/how.2b/how.2b.html"&gt; How to be a Good Graduate Student/Advisor&lt;/a&gt;, by Marie desJardins &lt;/li&gt;&lt;li&gt; &lt;a href="ftp://cs.williams.edu/pub/bailey/research.ps"&gt; A Letter to Research Students&lt;/a&gt;, by Duane A. Bailey &lt;/li&gt;&lt;li&gt;&lt;a href="http://www.cs.indiana.edu/mit.research.how.to.html"&gt; How to do Research in the MIT AI Lab&lt;/a&gt;, ed. David Chapman &lt;/li&gt;&lt;li&gt; The IUCS &lt;a href="http://www.cs.indiana.edu/docproject/handbook/part1.9.html"&gt; Graduate Student Survival Guide&lt;/a&gt;. &lt;ul&gt; &lt;li&gt; Includes &lt;a href="http://www.cs.indiana.edu/docproject/handbook/section1.9.0.3.html"&gt; Survival Skills for Graduate Women&lt;/a&gt; &lt;/li&gt;&lt;li&gt; and &lt;a href="http://www.cs.indiana.edu/docproject/handbook/section1.9.0.6.html"&gt; The Assistant Professor's Guide to the Galaxy&lt;/a&gt;. &lt;/li&gt;&lt;/ul&gt; &lt;/li&gt;&lt;/ul&gt; &lt;h2&gt;Speaking&lt;/h2&gt; &lt;ul&gt; &lt;li&gt; &lt;a href="ftp://ftp.dcs.glasgow.ac.uk/pub/glasgow-fp/papers/giving-a-talk.ps.Z"&gt; How to Give a Good Research Talk&lt;/a&gt;, by Simon Peyton Jones et al. &lt;/li&gt;&lt;li&gt; &lt;a href="ftp://ftp.unt.edu/ian/guides/speaker/speaker.ps"&gt; How to Present a Paper in Theoretical Computer Science&lt;/a&gt;, by Ian Parberry. &lt;/li&gt;&lt;/ul&gt; &lt;h2&gt;Career Development&lt;/h2&gt; &lt;ul&gt; &lt;li&gt; &lt;a href="http://communication.ucsd.edu/pagre/network.html"&gt; Networking on the Network&lt;/a&gt; by Phil Agre &lt;/li&gt;&lt;li&gt;&lt;a href="http://www-ccsl.cs.umass.edu/~kaplan/jobs/"&gt;Computer Science Faculty and Research Positions&lt;/a&gt; &lt;/li&gt;&lt;li&gt; &lt;a href="http://snorri.chem.washington.edu/ysnarchive/"&gt; The Young Scientists' Network&lt;/a&gt; &lt;/li&gt;&lt;li&gt; &lt;a href="http://cra.org/womencom.html"&gt; CRA Committee on the Status of Women in Research&lt;/a&gt; &lt;ul&gt; &lt;li&gt; Includes a &lt;a href="http://cra.org/craw-docs/gradinfokit.html"&gt; Graduate School Information Kit for Women in Computer Science and Engineering&lt;/a&gt; &lt;/li&gt;&lt;li&gt; and the &lt;a href="http://cra.org/mentor.html"&gt; Distributed Mentor Project&lt;/a&gt; for female undergraduates. &lt;/li&gt;&lt;/ul&gt; &lt;/li&gt;&lt;li&gt; &lt;a href="http://bunny.cs.uiuc.edu/funding/academicCareers.html"&gt;ACM SIGMOD academic careers information&lt;/a&gt; &lt;ul&gt; &lt;li&gt; Includes &lt;a href="ftp://ics.uci.edu/pub/mentoring-workshop"&gt;transcripts from the Workshop on Academic Careers for Women&lt;/a&gt;. &lt;/li&gt;&lt;/ul&gt; &lt;/li&gt;&lt;/ul&gt; &lt;h2&gt;Related Topics and Resources&lt;/h2&gt; &lt;ul&gt; &lt;li&gt; &lt;a href="http://www.eecs.nwu.edu:8001/jmyers/gradstudent.html"&gt; Information resources for graduate students&lt;/a&gt; by Jennifer Myers. &lt;/li&gt;&lt;li&gt; &lt;a href="ftp://ftp.unt.edu/ian/guides/referee/manuscript.ps"&gt; A Guide for New Referees in Theoretical Computer Science&lt;/a&gt;, by Ian Parberry. &lt;/li&gt;&lt;li&gt; &lt;a href="http://www.nas.edu/nap/online/obas"&gt; On Being A Scientist: Responsible Conduct In Research&lt;/a&gt;, from the National Academy of Sciences &lt;/li&gt;&lt;li&gt; Papers on &lt;a href="http://www.ai.mit.edu/people/ellens/gender.html"&gt; women in computer science&lt;/a&gt;. &lt;ul&gt; &lt;li&gt; Includes &lt;a href="http://www.ai.mit.edu/people/ellens/Gender/pap/pap.html"&gt; &lt;cite&gt;Why Are There So Few Female Computer Scientists?&lt;/cite&gt;&lt;/a&gt;, by Ellen Spertus. &lt;/li&gt;&lt;/ul&gt; &lt;/li&gt;&lt;li&gt; &lt;a href="http://www.uark.edu/depts/comminfo/www/study.html"&gt; Study, Research, and Writing Skills&lt;/a&gt; web page from the American Communication Association. &lt;/li&gt;&lt;li&gt; &lt;a href="http://www.cs.umbc.edu/graduate/info.html"&gt; Information for current and prospective graduate students&lt;/a&gt; by Timothy Finin. &lt;/li&gt;&lt;li&gt; &lt;a href="http://www.public.iastate.edu/~pmohseni/grad.ps"&gt; A Guide for Applying to Graduate Schools&lt;/a&gt; by Piroz Mohseni. &lt;/li&gt;&lt;li&gt; Ivan Sutherland, "Technology and Courage," in CMU Computer Science: A 25th Anniversary Commemorative, ed. Richard F. Rashid. ACM Press, 1991. &lt;/li&gt;&lt;li&gt; Alan Jay Smith, "The task of the referee," IEEE Computer, April 1990, pp. 65-71. &lt;/li&gt;&lt;/ul&gt; &lt;h2&gt;Dissertation Advice&lt;/h2&gt; &lt;ul&gt; &lt;li&gt; &lt;a href="http://www.asgs.org/Diss_Nws.htm"&gt;Dissertation News&lt;/a&gt;, published by &lt;a href="http://www.asgs.org/"&gt; The Association for Support of Graduate Students&lt;/a&gt;. &lt;/li&gt;&lt;li&gt; &lt;a&gt; Resources for dissertation research&lt;/a&gt; (gopher) &lt;/li&gt;&lt;li&gt; &lt;a href="http://155.187.10.12/fun/burnout.html"&gt; How to cope with "burnout"&lt;/a&gt;, by Andreas Gehmeyr. &lt;/li&gt;&lt;li&gt; How to Complete and Survive a Doctoral Dissertation, by David Sternberg. St. Martin's Press, New York. ISBN 0-312-39606-6 &lt;/li&gt;&lt;li&gt; How to Get Control of Your Time and Your Life, by Alan Lakein. Signet Books. ISBN 0-451-16772-4 &lt;/li&gt;&lt;li&gt; Procrastination: Why you do it, what to do about it, by Jane Burka and Lenora Yuen. Addison-Wesley. ISBN 0-201-55089-X &lt;/li&gt;&lt;/ul&gt; &lt;h2&gt;Humor&lt;/h2&gt; &lt;ul&gt; &lt;li&gt; &lt;a href="http://www.cs.utah.edu/~lepreau/osdi94/keynote/abstract.html"&gt; How to Have a Bad Career in Research/Academia&lt;/a&gt; by David Patterson &lt;/li&gt;&lt;li&gt; &lt;a href="http://web.mit.edu/afs/athena.mit.edu/user/w/c/wchuang/News/college/MIT-views.html.gz"&gt;Burnout Prevention and Recovery at MIT&lt;/a&gt; &lt;/li&gt;&lt;li&gt; &lt;a href="http://www.best.com/~smurman/soga/misc/research.html"&gt; A Dictionary of Useful Research Phrases&lt;/a&gt; &lt;/li&gt;&lt;/ul&gt; &lt;hr&gt; &lt;address&gt;&lt;a href="https://www.cs.cmu.edu/afs/cs.cmu.edu/user/mleone/web/whois-mleone.html"&gt; mleone@cs.cmu.edu&lt;/a&gt;&lt;/address&gt; &lt;/div&gt;&lt;a href="https://www.cs.cmu.edu/~mleone/how-to.html"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Fri, 3 Apr 2020 18:08:12 UT
      </pubDate>
      <guid>
        https://www.cs.cmu.edu/~mleone/how-to.html
      </guid>
    </item>
    <item>
      <title>
        An Opinionated Guide to ML Research
      </title>
      <link>
        http://joschu.net/blog/opinionated-guide-ml-research.html
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt; &lt;h2&gt;An Opinionated Guide to ML Research&lt;/h2&gt; &lt;p&gt;Posted on 2020/01/24&lt;/p&gt; &lt;a href="http://joschu.net/blog.html"&gt;← back to blog index&lt;/a&gt; &lt;p&gt;&lt;em&gt;I originally wrote this guide in back in December 2017 for the &lt;a href="https://openai.com/blog/openai-fellows/"&gt;OpenAI Fellows program&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;In this essay, I provide some advice to up-and-coming researchers in machine learning (ML), based on my experience doing research and advising others. The advice covers how to choose problems and organize your time. I also recommend the following prior essays on similar topics:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="http://www.cs.virginia.edu/~robins/YouAndYourResearch.html"&gt;&lt;em&gt;You and Your Research&lt;/em&gt; by Richard Hamming&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="http://michaelnielsen.org/blog/principles-of-effective-research"&gt;&lt;em&gt;Principles of Effective Research&lt;/em&gt; by Michael Nielsen&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;My essay will cover similar ground, but it’s more tuned to the peculiar features of ML.&lt;/p&gt; &lt;p&gt;The keys to success are working on the right problems, making continual progress on them, and achieving continual personal growth. This essay is comprised of three sections, each covering one of these topics.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;. Before continuing, it’s useful to spend a few minutes about which findings and achievements in ML have been most interesting and informative to you. Think about what makes each one stand out—whether it's a groundbreaking result that changed your perspective on some problem; or an algorithmic idea that's reusable; or a deep insight about some recurring questions. You should aspire to produce results, algorithms, and insights of this caliber.&lt;/p&gt; &lt;h3 id="choosing-problems"&gt;Choosing Problems&lt;/h3&gt; &lt;h4 id="honing-your-taste"&gt;Honing Your Taste&lt;/h4&gt; &lt;p&gt;Your ability to choose the right problems to work on is even more important than your raw technical skill. This taste in problems is something you’ll develop over time by watching which ideas prosper and which ones are forgotten. You’ll see which ones serve as building blocks for new ideas and results, and which ones are ignored because they are too complicated or too fragile, or because the incremental improvement is too small.&lt;/p&gt; &lt;p&gt;You might be wondering if there’s a way to speed up the process of developing a good taste for what problems to work on. In fact, there are several good ways.&lt;/p&gt; &lt;ol type="1"&gt; &lt;li&gt;Read a lot of papers, and assess them critically. If possible, discuss them with others who have a deeper knowledge of the subject.&lt;/li&gt; &lt;li&gt;Work in a research group with other people working on similar topics. That way you can absorb their experiences as well as your own.&lt;/li&gt; &lt;li&gt;Seek advice from experienced researchers on what to work on. There’s no shame in working on ideas suggested by other people. Ideas are cheap, and there are lots of them in the air. Your skill comes in when you decide which one to work on, and how well you execute on it.&lt;/li&gt; &lt;li&gt;Spend time reflecting on what research is useful and fruitful. Think about questions like &lt;ol type="a"&gt; &lt;li&gt;When is theory useful?&lt;/li&gt; &lt;li&gt;When are empirical results transferable?&lt;/li&gt; &lt;li&gt;What causes some ideas to get wide uptake, whereas others are forgotten?&lt;/li&gt; &lt;li&gt;What are the trends in your field? Which lines of work will make the other ones obsolete?&lt;/li&gt; &lt;/ol&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Items 1-3 relate to optimizing your environment and getting input from other researchers, whereas item 4 is something you do alone. As empirical evidence for the importance of 1-3, consider how the biggests bursts of impactful work tend to be tightly clustered in a small number of research groups and institutions. That’s not because these people are dramatically smarter than everyone else, it’s because they have a higher density of expertise and perspective, which puts them a little ahead of the rest of the community, and thus they dominate in generating new results. If you’re not fortunate enough to be in an environment with high density of relevant expertise, don’t despair. You’ll just have to work extra-hard to get ahead of the pack, and it’s extra-important to specialize and develop your own unique perspective.&lt;/p&gt; &lt;h4 id="idea-driven-vs-goal-driven-research"&gt;Idea-Driven vs Goal-Driven Research&lt;/h4&gt; &lt;p&gt;Roughly speaking, there are two different ways that you might go about deciding what to work on next.&lt;/p&gt; &lt;ol type="1"&gt; &lt;li&gt;&lt;p&gt;Idea-driven. Follow some sector of the literature. As you read a paper showing how to do X, you have an idea of how to do X even better. Then you embark on a project to test your idea.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;Goal-driven. Develop a vision of some new AI capabilities you’d like to achieve, and solve problems that bring you closer to that goal. (Below, I give a couple case studies from my own research, including the goal of using reinforcement learning for 3D humanoid locomotion.) In your experimentation, you test a variety of existing methods from the literature, and then you develop your own methods that improve on them.&lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Of course, these two approaches are not mutually exclusive. Any given subfield ML is concerned with some goals (e.g., object detection). Any “idea-driven” project will represent progress towards the subfield’s goals, and thus in a sense, it’s an instance of goal-driven research. But here, I’ll take goal-driven research to mean that your goal is more specific than your whole subfield’s goal, and it’s more like &lt;em&gt;make X work for the first time&lt;/em&gt; than &lt;em&gt;make X work better&lt;/em&gt;.&lt;/p&gt; &lt;p&gt;I personally recommend goal-driven research for most people, and I’ve mostly followed this strategy myself.&lt;/p&gt; &lt;p&gt;One major downside of idea-driven research is that there’s a high risk of getting scooped or duplicating the work of others. Researchers around the world are reading the same literature, which leads them to similar ideas. To make breakthroughs with idea-driven research, you need to develop an exceptionally deep understanding of your subject, and a perspective that diverges from the rest of the community—some can do it, but it’s difficult.&lt;/p&gt; &lt;p&gt;On the other hand, with goal-driven research, your goal will give you a perspective that’s differentiated from the rest of the community. It will lead you to ask questions that no one else is asking, enabling you to make larger leaps of progress. Goal driven research can also be much more motivating. You can wake up every morning and imagine achieving your goal—what the result would look like and how you would feel. That makes it easier to stick to a long-running research program with ups and downs. Goals also make it possible for a team of researchers to work together and attack different aspects of the problem, whereas idea-driven research is most effectively carried out by “teams” of 1-2 people.&lt;/p&gt; &lt;h6 id="case-study-of-goal-driven-research-my-work-during-graduate-school"&gt;Case Study of Goal-Driven Research: My Work During Graduate School&lt;/h6&gt; &lt;p&gt;For the first half of my PhD, my goal was to enable robots to manipulate deformable objects—including surgical robots tying knots, and household robots folding clothes. While this goal was determined by my advisor, Pieter Abbeel, as the main goal for his lab, I developed my own opinion on how to achieve this goal—my approach was based on learning from human demonstrations, and I was going to start with the problem of getting the PR2 to tie knots in rope. Various unexpected subproblems arose, one of which was trajectory optimization, and my work on that subproblem ended up being the most influential product of the knot-tying project.&lt;/p&gt; &lt;p&gt;For the second half of my PhD, I became interested in reinforcement learning. While there are many problem domains in which reinforcement learning can be applied, I decided to focus on robotic locomotion, since the goal was concrete and the end result was exciting to me. Specifically, my goal was to get a 3D robot to learn how to run from scratch using reinforcement learning. After some initial exploration, I decided to focus on policy gradient methods, since they seemed most amenable to understanding and mathematical analysis, and I could leverage my strength in optimization. During this period, I developed TRPO and GAE and eventually achieved the original goal of 3D humanoid locomotion.&lt;/p&gt; &lt;p&gt;While I was working on locomotion and starting to get my first results with policy gradient methods, the DeepMind team presented the results using DQN on Atari. After this result, many people jumped on the bandwagon and tried to develop better versions of Q-learning and apply them to the Atari domain. However, I had already explored Q-learning and concluded that it wasn’t a good approach for the locomotion tasks I was working on, so I continued working on policy gradient methods, which led to TRPO, GAE, and later PPO—now my best known pieces of work. This example illustrates how choosing a different problem from the rest of the community can lead you to explore different ideas.&lt;/p&gt; &lt;h6 id="goal-driven-research-restrict-yourself-to-general-solutions"&gt;Goal Driven Research: Restrict Yourself to General Solutions&lt;/h6&gt; &lt;p&gt;One pitfall of goal-driven research is taking your goal too literally. If you have a specific capability in mind, there’s probably some way to achieve it in an uninteresting way that doesn’t advance the field of machine learning. You should constrain your search to solutions that seem general and can be applied to other problems.&lt;/p&gt; &lt;p&gt;For example, while working on robotic locomotion, I avoided incorporating domain information into the solution—the goal was to achieve locomotion in simulation, &lt;em&gt;in a way that was general and could be applied to other problems&lt;/em&gt;. I did a bit of feature engineering and reward shaping in order to see the first signs of life, but I was careful to keep my changes simple and not let them affect the algorithm I was developing. Now that I am using videogames as a testbed, I make sure that my algorithmic ideas are not specific to this setting—that they equally well could be applied to robotics.&lt;/p&gt; &lt;h4 id="aim-high-and-climb-incrementally-towards-high-goals"&gt;Aim High, and Climb Incrementally Towards High Goals&lt;/h4&gt; &lt;p&gt;Sometimes, people who are both exceptionally smart and hard-working fail to do great research. In my view, the main reason for this failure is that they work on unimportant problems. When you embark on a research project, you should ask yourself: how large is the potential upside? Will this be a 10% improvement or a 10X improvement? I often see researchers take on projects that seem sensible but could only possibly yield a small improvement to some metric.&lt;/p&gt; &lt;p&gt;Incremental work (those 10% improvements) are most useful in the context of a larger goal that you are trying to achieve. For example, the seminal paper on ImageNet classification using convolutional neural networks (Krizhevsky, Sutskever, &amp;amp; Hinton, 2012) does not contain any radically new algorithmic components, rather, it stacks up a large number of small improvements to achieve an unprecedented result that was surprising to almost everyone at the time (though we take it for granted now). During your day-to-day work, you’ll make incremental improvements in performance and in understanding. But these small steps should be moving you towards a larger goal that represents a non-incremental advance.&lt;/p&gt; &lt;p&gt;If you are working on incremental ideas, be aware that their usefulness depends on their complexity. A method that slightly improves on the baseline better be very simple, otherwise no one will bother using it—not even you. If it gives a 10% improvement, it better be 2 lines of code, whereas if it's a 50% improvement, it can add 10 lines of code, etc. (I’m just giving these numbers for illustration, the actual numbers will obviously depend on the domain.)&lt;/p&gt; &lt;p&gt;Go back and look at the list of machine learning achievements you admire the most. Does your long-term research plan have the potential to reach the level of those achievements? If you can’t see a path to something that you’d be proud of, then you should revise your plan so it does have that potential.&lt;/p&gt; &lt;h3 id="making-continual-progress"&gt;Making Continual Progress&lt;/h3&gt; &lt;p&gt;To develop new algorithms and insights in machine learning, you need to concentrate your efforts on a problem for a long period of time. This section is about developing effective habits for this long-term problem solving process, enabling you to continually build towards great results.&lt;/p&gt; &lt;h4 id="keep-a-notebook-and-review-it"&gt;Keep a Notebook, and Review It&lt;/h4&gt; &lt;p&gt;I strongly advise you to keep a notebook, where you record your daily ideas and experiments. I have done this through 5 years of grad school and 2 years at OpenAI, and I feel that it has been tremendously helpful.&lt;/p&gt; &lt;p&gt;I create an entry for each day. In this entry, I write down what I’m doing, ideas I have, and experimental results (pasting in plots and tables). Every 1 or 2 weeks, I do a review, where I read all of my daily entries and I condense the information into a summary. Usually my review contains sections for &lt;em&gt;experimental findings&lt;/em&gt;, &lt;em&gt;insights&lt;/em&gt; (which might come from me, my colleagues, or things I read), &lt;em&gt;code progress&lt;/em&gt; (what did I implement), and &lt;em&gt;next steps / future work&lt;/em&gt;. After I do my week in review, I often look at the previous week to see if I followed up on everything I thought of that week. Also, while doing this review, I sometimes transfer information into other sources of notes. (For example, I keep a list of backburner ideas and projects, separate from my notebook.)&lt;/p&gt; &lt;p&gt;What’s the value in keeping this notebook and doing the regular reviews?&lt;/p&gt; &lt;p&gt;First, the notebook is a good place to write down ideas as soon as you have them, so you can revisit them later. Often, when I revisit my journal entries during the week in review, I’ll fill in a missing piece in a puzzle, which didn’t occur to me at the time.&lt;/p&gt; &lt;p&gt;Second, the notebook helps you keep your experimental results in a unified place, so you can easily find the results later. It’s easy to forget about your conclusions, e.g., which hyperparameters made a difference, and you’ll want to revisit your old notebook entries.&lt;/p&gt; &lt;p&gt;Third, the notebook lets you monitor your use of time. You might wonder “where did last week go?”, and the notebook will help you answer that question. You might be disappointed with your throughput and realize you need to work on your time management. You also might look back at several months and realize that you’ve been jumping around between ideas too much—that you have a few half-finished projects but you didn’t follow any of these threads long enough to yield a notable result.&lt;/p&gt; &lt;h4 id="when-to-switch-problems"&gt;When to Switch Problems&lt;/h4&gt; &lt;p&gt;To solve a challenging problem, you need to spend a sufficient amount of time on it. But in empirical machine learning research, it’s hard to know if you’ve tried an idea hard enough. Sometimes the idea has the potential to work, but if you get one detail wrong, you’ll see no signs of life. But other ideas are simply doomed to fail no matter how hard you work on them.&lt;/p&gt; &lt;p&gt;In my experience, switching problems too frequently (and giving up on promising ideas) is a more common failure mode than not switching enough. Often, while you’re engaged in the long slog towards getting your current idea to work, another promising idea will come along, and you’ll want to jump to that idea. If your idea is quick to try and the potential upside is large, then go ahead and do it. But more commonly, your initial results on the new idea will be disappointing, and it’ll take a more sustained effort to yield significant results.&lt;/p&gt; &lt;p&gt;As a rule of thumb, when you look back at which projects you’ve been working on over a period of months, you should find that there have been lots of small dead ends, but the majority of your time has been directed towards projects that yielded a deliverable such as a paper or a blog post. If you look back at your time and see that a substantial fraction was spent on half-finished projects—which were not definite failures, but which you abandoned in favor of some newer idea—then you should make a stronger effort towards consistency and follow-through in the future.&lt;/p&gt; &lt;p&gt;One strategy, which I haven’t tried personally but makes a lot of sense upon reflection, is to devote some fixed time budget to trying out new ideas that diverge from your main line of work. Say, spend one day per week on something totally different from your main project. This would constitute a kind of epsilon-greedy exploration, and it would also help to broaden your knowledge.&lt;/p&gt; &lt;h3 id="personal-development"&gt;Personal Development&lt;/h3&gt; &lt;p&gt;No matter how you allocate your time during your research journey, you are bound to learn a lot. Each project will present new challenges, and you can pick up the background material and skills as you go along. However, you can significantly improve your chances to do great work in the long term by regularly setting aside time for your personal development. Specifically, you should allocate some fraction of your time towards improving your general knowledge of ML as opposed to working on your current project. If you don’t allocate this time, then your knowledge is likely to plateau after you learn the basics that you need for your day-to-day work. It’s easy to settle into a comfort zone of methods you understand well—you may need to expend active effort to expand this zone.&lt;/p&gt; &lt;p&gt;The main ways to build your knowledge of ML are to read textbooks, theses and papers; and to reimplement algorithms from these sources. Early on in your career, I recommend splitting your time about evenly between textbooks and papers. You should choose a small set of relevant textbooks and theses to gradually work through, and you should also reimplement the models and algorithms from your favorite papers.&lt;/p&gt; &lt;p&gt;Most students of machine learning don’t spend time reading textbooks after they finish their school courses. I think this is a mistake, since textbooks are a much more dense way to absorb knowledge than papers. Each conference paper typically contains one main new idea, along with a background section that’s too concise to learn anything from. There’s a lot of overhead, since you typically need to spend more time understanding the notation and terminology than the idea itself. On the other hand, good textbooks collect decades of ideas and present them in the proper order with the same notation. Besides reading the introductory machine learning textbooks, read other books in your areas of interest. A couple of my favorites were &lt;em&gt;Numerical Optimization&lt;/em&gt; by Nocedal &amp;amp; Wright, and &lt;em&gt;Elements of Information Theory&lt;/em&gt; by Cover &amp;amp; Thomas.&lt;/p&gt; &lt;p&gt;Besides textbooks, I recommend reading PhD theses of researchers whose work interests you. PhD theses in ML usually are ordered as follows: (1) introductory and background material, (2) several papers that were previously published at conferences (it’s said that you just have to “staple together” your papers to write your thesis), and (3) a conclusion and outlook. You’re likely to benefit most from parts (1) and (3), since they contain a unifying view of the past and future of the field, written by an expert. Recent theses are often the best place to find a literature review of an active field, but older theses also often contain valuable gems of insight.&lt;/p&gt; &lt;p&gt;Textbooks and theses are good for building up your foundational knowledge, but you’ll also need to read a lot of papers to bring your knowledge up to the frontier. When you are just starting your research career, I recommend spending a lot of time reimplementing ideas from papers, and comparing your results to the published ones. First of all, this gives you a much deeper understanding of the topic than you’d get by passively reading. Second, you’ll gain experience running experiments, and you’ll get much quicker feedback by reimplementing existing work (where the desired level of performance is known) than by doing original research. Once you can easily reproduce the state-of-the-art, you’ll be ready to go beyond it.&lt;/p&gt; &lt;p&gt;Besides reading seminal papers and reimplementing them, you should also keep track of the less exceptional papers being published in your field. Reading and skimming the incoming papers with a critical eye helps you notice the trends in your field (perhaps you notice that a lot of papers are using some new technique and getting good results—maybe you should investigate it). It also helps you build up your taste by observing the dependency graph of ideas—which ideas become widely used and open the door to other ideas.&lt;/p&gt; &lt;p&gt;Go forth and do great research!&lt;/p&gt; &lt;/div&gt;&lt;a href="http://joschu.net/blog/opinionated-guide-ml-research.html"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sat, 4 Apr 2020 10:00:43 UT
      </pubDate>
      <guid>
        http://joschu.net/blog/opinionated-guide-ml-research.html
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://medium.com/@jurgens_24580/reflections-on-strategies-for-successful-meetings-with-undergraduate-researchers-ae22306ecd8d
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;h2 id="e3d6"&gt;Or, how to have a good research meeting with your advisor&lt;/h2&gt;&lt;div&gt;&lt;p&gt;&lt;a href="https://medium.com/@jurgens_24580?source=post_page-----ae22306ecd8d--------------------------------" rel="noopener"&gt;&lt;img height="28" width="28" src="https://miro.medium.com/fit/c/56/56/1*sByu2SYJ_0tM4mJLc0aWmQ.png" alt="David Jurgens"&gt;&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;p id="9cf7"&gt;This summer I’ve had the good fortune to work with a large group of 13 new undergraduate researchers&lt;span id="rmm"&gt; &lt;/span&gt;in my lab. They are talented Michigan students who want to learn how to do world-class research but are just getting started along the path. One aspect of learning to do good research is learning how to do research with others — and in particular, when starting out, how to do research with an advisor. I wanted to touch on one small part of this process: &lt;em&gt;meetings with an advisor&lt;/em&gt;. Meetings are a critical part of the knowledge transfer process but not all of them are useful, let alone productive. What makes a good meeting and how should a new undergraduate researcher think about meetings?¹ Further, what kind of behavior should an advisor encourage to help their students grow as researchers?&lt;/p&gt;&lt;p id="e36e"&gt;My goal with this post is to help students recognize how to maximize the effectiveness of their meetings and, overall, my goal as an advisor is always to help students turn into the best researchers they can be. To talk about meetings, I’ll contrast two hypothetical examples of students: One, I’ll call the &lt;strong&gt;Pine&lt;/strong&gt; student (Michigan’s state tree²), and the other the &lt;strong&gt;Sapling&lt;/strong&gt; student. Both students start from the ground level and are often learning their computational craft at the same time as learning how to do good research. The Pine students have made the most of their opportunities and grown in their abilities and flourish. In contrast, the Sapling students certainly put in effort but haven’t seen much growth or much success — yet. To illustrate how these hypothetical students differ in their behavior, I’ll describe several general scenarios for meetings that can help lead one student to grow substantially as a researcher into a towering pine, whereas the other remains just a sapling.&lt;/p&gt;&lt;figure&gt;&lt;div&gt;&lt;p&gt;&lt;img height="400" width="600" src="https://miro.medium.com/max/60/1*AqgFehaL4dPLYigE6VOSIg.png?q=20" alt="Image for post"&gt;&lt;/p&gt;&lt;/div&gt;&lt;figcaption&gt;Look at all those aspiring young researchers — so much potential! (Image credit &lt;a rel="noopener nofollow" href="https://commons.wikimedia.org/w/index.php?title=User:Dleduc&amp;amp;action=edit&amp;amp;redlink=1"&gt;Dleduc&lt;/a&gt;, shared under a Creative Commons &lt;a rel="noopener nofollow" href="https://creativecommons.org/licenses/by/3.0/deed.en"&gt;Attribution 3.0 Unported&lt;/a&gt;&lt;a rel="noopener nofollow" href="http://creativecommons.org/licenses/by/2.0/"&gt; &lt;/a&gt;license)&lt;/figcaption&gt;&lt;/figure&gt;&lt;p id="5918"&gt;For context, my lab is structured so that undergraduate students typically work in groups. We use a few different tools for communicating about projects. Project meetings happen on an at-least weekly basis and provide low-level guidance on the research, including goal setting, staring at figures, and discussing ideas. Project meetings are scheduled by the students themselves in one or more 30 minute blocks using an appointment calendar; there’s generally enough time for two 30 minute meetings for each group spaced throughout the week. Weekly all-hands lab meetings provide more dissemination and allow students to share details and highlights from that week’s work. Between meetings, we use &lt;a rel="noopener nofollow" href="https://slack.com/"&gt;Slack&lt;/a&gt; to communicate for quick updates, questions, and showing off upcoming results to discuss at the next meeting. For some projects, we have also adopted &lt;a rel="noopener nofollow" href="http://asana.com/"&gt;Asana&lt;/a&gt; for managing project to-dos and keeping organized on what’s coming down the project pipeline. I also keep my door open for the occasional drop-by question or chat.&lt;/p&gt;&lt;p id="ed38"&gt;In different scenarios below, I outline hypothetical situations of how the Pine and the Sapling might differ in their meeting experiences. Before reading these, I want to be clear that I believe any Sapling student can become a Pine student. These are not permanent distinctions and in fact many of us (including me!) had these Sapling habits at one point. If you, as a student, recognize some part of yourself in a scenario, despair not! Recognizing a bad habit is an important step towards progress and improving that aspect. No student begins their research experience as an amazing PhD-level researcher; we all start somewhere close to ground level and work our way up from there. As an additional aside to the undergraduates in my lab (now and in the future), I am proud to have you as members and want to help you succeed; these scenarios are intended as guides to help you avoid potential pitfalls and shoot up into tall Pines as quickly as possible.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;figure&gt;&lt;div&gt;&lt;p&gt;&lt;img height="500" width="500" src="https://miro.medium.com/max/60/1*Bd8Rj5cjOdMrBN603tJCYg.png?q=20" alt="Image for post"&gt;&lt;/p&gt;&lt;/div&gt;&lt;figcaption&gt;The undergraduate researcher sits down to discuss research with their advisor (Image credit: &lt;a rel="noopener nofollow" href="https://www.flickr.com/photos/horsepunchkid/"&gt;Steven Severinghaus&lt;/a&gt;, shared under a &lt;a rel="noopener nofollow" href="https://creativecommons.org/licenses/by-nc-sa/2.0/"&gt;CC BY-NC-SA 2.0&lt;/a&gt; license)&lt;/figcaption&gt;&lt;/figure&gt;&lt;p id="1f9f"&gt;&lt;span&gt;S&lt;/span&gt;&lt;strong&gt;cenario&lt;/strong&gt;: a student has just arrived to a meeting they scheduled to discuss their project.&lt;/p&gt;&lt;p id="94a2"&gt;The &lt;em&gt;Sapling&lt;/em&gt; student will often arrive and ask what should we talk about or have nothing in particular to discuss. Sometimes this can be due to shyness (and not to being a Sapling student), so I may ask students to start by bringing me up to speed. In this case, a Sapling student may not have thought of how to summarize their progress and have trouble responding without more prompting. The meeting proceeds and we discuss as much as we can in the allotted time, which often runs out before we can wrap up.&lt;/p&gt;&lt;p id="2cb9"&gt;The &lt;em&gt;Pine&lt;/em&gt; student arrives with an agenda of all the points they want to discuss. Often this list is organized around different topics and prioritized so that if we run out of time, the most pressing issues are addressed first. We go through each with a full understanding of how much we have to talk about for the rest of the meeting.&lt;/p&gt;&lt;p id="2969"&gt;&lt;strong&gt;Reflection&lt;/strong&gt;: Having students create the meeting agenda provides an important sense of agency that they are driving the project and also leads to more efficient meetings. The Pine student’s effort in drafting an agenda is doubly worthwhile because it allows them to think big-picture about what they did and ask themselves which items need to be discussed first. When the agenda is created between students within the group, their discussions often help create a mental model of the project’s priorities that lead to more effective collaboration.&lt;/p&gt;&lt;p id="a0e1"&gt;The Sapling student’s meeting is more reactive to the advisor’s comments and generally leads to less productive meetings where the advisor drives everything or must use the socratic method to discover what has been done. The Sapling student’s meeting could turn into the Pine student’s meeting but it depends on the advisor knowing the agenda already and being able to quickly prioritize things. In projects where I’m very actively involved, I can typically do this, but only from the prospective of what I think has been accomplished. The new researcher is much closer to the day-to-day research and may have noticed or experience things that need to be on the agenda (unusual results, important questions, or new papers) that I won’t necessarily know about yet.&lt;/p&gt;&lt;p id="6d20"&gt;One side-effect of the Sapling meeting style is meeting spill-over. I eventually have to cut the meeting off to start the meeting after, which is often not at an ideal point for deciding on next steps and leaves the student potentially hurt that I couldn’t spend more time. I don’t like cutting off these meetings but I also don’t want to shortchange the next students who are coming in.&lt;/p&gt;&lt;p id="5cbb"&gt;For some projects, I’ve borrowed the strategy from my colleague &lt;a rel="noopener nofollow" href="http://www.libbyh.com/"&gt;Libby Hemphill&lt;/a&gt; and use Asana to drive the meetings. The project is laid out in Asana using an ever-growing number of current tasks and backlog of tasks that will need to be done. Students are assigned (or self-assign) tasks for that week and each meeting’s agenda is determined by what’s currently assigned in Asana. I find this strategy has worked well for some teams, though it does come with the overhead of maintaining a task list and actually getting everyone involved to use Asana (Slack integration with Asana has helped this though).&lt;/p&gt;&lt;p id="3272"&gt;Finally, sometimes it can be nice to have the occasional informal meeting where there is no set agenda. These meetings might be more brainstorming or have other kinds of discussions not focused on research. However, if I’m collaborating with a new student, having a focused meeting is a much better use of both of our time to help give them the feedback and direction they need to grow into a Pine student.&lt;/p&gt;&lt;p id="79fe"&gt;&lt;strong&gt;Suggestions on how to become a Pine:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li id="4e86"&gt;Come to a meeting with a prioritized agenda of what you want to discuss. This agenda can even be sent beforehand to everyone involved.&lt;/li&gt;&lt;li id="a17c"&gt;If you’re in a team, collaboratively come up with the agenda based on what each person is doing.&lt;/li&gt;&lt;li id="734b"&gt;Be aware of meeting time and ensure everything you want to discuss gets brought up before the allotted time runs out.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;&lt;figure&gt;&lt;div&gt;&lt;p&gt;&lt;img height="599" width="479" src="https://miro.medium.com/max/48/1*MSGOMpyZAmz16e82qAIXxw.png?q=20" alt="Image for post"&gt;&lt;/p&gt;&lt;/div&gt;&lt;figcaption&gt;The last reported sighting of an undergraduate researcher who is thought to be still debugging their code in parts unknown&lt;/figcaption&gt;&lt;/figure&gt;&lt;p id="397b"&gt;&lt;span&gt;S&lt;/span&gt;&lt;strong&gt;cenario&lt;/strong&gt;: the student has been working throughout the week but doesn’t feel like they have enough to discuss and hasn’t yet scheduled a weekly meeting with me.&lt;/p&gt;&lt;p id="ced4"&gt;There are many reasons not to have scheduled a meeting, but sometimes I have seen &lt;em&gt;Sapling&lt;/em&gt; students put off meetings out of a sense of shame for not doing enough or being successful enough. Occasionally, a Sapling student may also feel that weekly meetings are not a priority and that it is acceptable to slip to a later week.&lt;/p&gt;&lt;p id="f0d6"&gt;The &lt;em&gt;Pine&lt;/em&gt; student messages me (on Slack or email) saying that they have been working but currently don’t think they have enough to discuss and would like to know if a meeting will be useful. Further, the Pine students adds what has been blocking them from making progress (e.g., server has crashed; GPUs have been in use) and what steps they have proactively taken to resolve them. Based on the situation, we may still meet to discuss these issues or postpone with the knowledge that things are being done.&lt;/p&gt;&lt;p id="c6e6"&gt;&lt;strong&gt;Reflection: &lt;/strong&gt;Communication is the key here, along with an important acknowledgment that there is no shame in having your work not turn out like you thought — the process of research is never certain! Even when students don’t have results, we generally meet to discuss the process of research and how things might have been done differently (without blame) in light of what we learned from their effort. I sometimes find that a Sapling student has been working very hard on a problem that is difficult but either not central to our project’s goals or one that can easily be solved with a bit more experience to get them unblocked. Having a good communication channel can help such Sapling students reprioritize their effort and make progress again.&lt;/p&gt;&lt;p id="dc7b"&gt;&lt;strong&gt;Suggestions on how to become a Pine:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li id="eda2"&gt;Be open and honest with your advisor about your progress and raise attention for things blocking your progress.&lt;/li&gt;&lt;li id="c186"&gt;Meet weekly. If you find yourself without much to talk about, discuss why that is the case and aim to resolve it.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;&lt;figure&gt;&lt;div&gt;&lt;p&gt;&lt;img height="640" width="480" src="https://miro.medium.com/max/46/1*6gop67XSYUY2ABsbX2PoZg.png?q=20" alt="Image for post"&gt;&lt;/p&gt;&lt;/div&gt;&lt;figcaption&gt;Finding themself in unfamiliar territory, the undergraduate researcher has many new and exciting research questions — but realizes they have quite a bit of explaining to describe how they got there in the first place (Image credit &lt;a rel="noopener nofollow" href="http://www.geograph.org.uk/profile/32427"&gt;Paul Farmer&lt;/a&gt;, shared under a &lt;a rel="noopener nofollow" href="https://creativecommons.org/licenses/by-sa/3.0/deed.en"&gt;CC BY-SA 2.0&lt;/a&gt; license)&lt;/figcaption&gt;&lt;/figure&gt;&lt;p id="8f0b"&gt;&lt;span&gt;S&lt;/span&gt;&lt;strong&gt;cenario&lt;/strong&gt;: The meeting has just begun and the student is presenting the first results of the project.&lt;/p&gt;&lt;p id="f806"&gt;The &lt;em&gt;Sapling &lt;/em&gt;student often starts with deep technical details with minimal context, e.g., “So I was trying to run the sklearn code on the data but when I set this parameter to 3, the performance improved.” The next several minutes of the meeting are spent unpacking such statements to determine why they were doing something and what effect it has on the project.&lt;/p&gt;&lt;p id="b084"&gt;The &lt;em&gt;Pine&lt;/em&gt; student arrives and quickly summarizes the goals of the project as a whole and what research question they were trying to pursue within those goals, e.g., “we are trying to understand people’s reactions to memes on Twitter and this week I built a sentiment analysis classifier with sklearn to rate reactions.” This framing immediately sets expectations and helps me ensure that the student’s model of the project’s objectives are aligned with the project’s actual objectives.&lt;/p&gt;&lt;p id="d371"&gt;&lt;strong&gt;Reflection&lt;/strong&gt;: Advisors are busy and often one research meetings is immediately followed by another on a completely different topic. As a result, any effort the student can put in to helping quickly familiarize the advisor with the project is incredibly useful. The Sapling student isn’t wrong for going into details; this kind of discussion can be incredibly useful. However, the issue is immediately starting out in the weeds without context. Starting by re-iterating the problem allows the student and advisor to quickly get on the same page and make it through more of the meeting by not having to ask clarifying questions.&lt;/p&gt;&lt;p id="774d"&gt;&lt;strong&gt;Suggestions on how to become a Pine:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li id="bf35"&gt;Start any discussion of an agenda item with what problem you’re trying to solve. Describe the problem from a high level that everyone understands and then become more specific until you reach the details of what you’re doing.&lt;/li&gt;&lt;li id="1a04"&gt;If you need to spend all of the meeting on something very detailed, send an email the day before with the context and agenda so that the advisor is prepared to jump right into the details.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;&lt;figure&gt;&lt;div tabindex="0" role="button"&gt;&lt;p&gt;&lt;img height="600" width="800" src="https://miro.medium.com/max/60/1*R5hIvvScM9Zy65ylsbdG1A.png?q=20" alt="Image for post"&gt;&lt;/p&gt;&lt;/div&gt;&lt;figcaption&gt;“Huh, I could have sworn there was research paydirt around here just a second ago,” exclaimed one undergraduate researcher to another upon surveying their surroundings.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p id="5e90"&gt;&lt;span&gt;S&lt;/span&gt;&lt;strong&gt;cenario&lt;/strong&gt;: during the meeting, the student and advisor begin to look at the intermediate data produced over the previous few days.&lt;/p&gt;&lt;p id="90aa"&gt;The &lt;em&gt;Sapling&lt;/em&gt; student will pull up data they have just generated and possibly never looked at before. Often, there will be surprises in the data, e.g., blank entries, artifacts from encoding, or unexpected tab/newline insertions. The Sapling student will struggle to explain how these surprises came to be and pinpoint where they might come from during preprocessing. Often, results have been produced from this intermediate data (e.g., a classifier is trained on this data) without having looked at it, which raises additional questions about the validity of those results.&lt;/p&gt;&lt;p id="c8f8"&gt;The &lt;em&gt;Pine&lt;/em&gt; student will have generated the data before the meeting with enough time to go over the data themselves ask whether anything is useful. If they spotted something unusual, the Pine student corrects the error (or finds an explanation) and regenerates the results. The Pine student can typically point to which programs, scripts, and methods are responsible for producing the data, and can fully replicate the setup they used to produce the data if we want to try something on hand. In the best cases, the Pine student has made things like Jupyter notebooks or bash scripts (pick your favorite language) that are easily sharable within the lab and outside to others.&lt;/p&gt;&lt;p id="af5a"&gt;&lt;strong&gt;Reflection&lt;/strong&gt;: Looking seriously at all the data in your experiments is a critical step for a young researcher. Even as an expert, having a healthy skepticism about your own data and methods is important to building intuition about what phenomena you’re looking at and what your software is actually doing. One of my old advisors, &lt;a rel="noopener nofollow" href="http://wwwusers.di.uniroma1.it/~navigli/"&gt;Roberto Navigli&lt;/a&gt;, had a sixth sense for finding surprises in data and would call out random line numbers for us to look at, only to find the one line in thousands that had something weird. This skill was terrifying at first as a student (no one &lt;em&gt;wants&lt;/em&gt; to show bad data) and a great motivator for me and the other lab members to always double- and triple-check everything. You can only trust your results when you trust the data that led to them.&lt;/p&gt;&lt;p id="9eef"&gt;&lt;strong&gt;Suggestions on how to become a Pine:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li id="c981"&gt;Always, &lt;em&gt;always&lt;/em&gt; look at your data before the meeting and allow enough time that if you spot something wrong, you can fix it&lt;/li&gt;&lt;li id="a8d4"&gt;Look random parts of your data, not just the first few lines. Be sure there are no surprises&lt;/li&gt;&lt;li id="d29e"&gt;Meeting time is precious; have your data ready to go in a format easily accessible to all meeting participants. Google docs/sheets work great for this. For large files on servers that everyone has access to, send out the link to the file to everyone before the meeting.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;&lt;figure&gt;&lt;div tabindex="0" role="button"&gt;&lt;p&gt;&lt;img height="1500" width="2000" src="https://miro.medium.com/max/60/1*jU_w6FOe3ZUJmpMRHh42vg.png?q=20" alt="Image for post"&gt;&lt;/p&gt;&lt;/div&gt;&lt;figcaption&gt;The undergraduate researcher was close to results but hadn’t anticipated just how cold Michigan winters can be when it comes to getting into the lab for meetings.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p id="62e8"&gt;&lt;span&gt;S&lt;/span&gt;&lt;strong&gt;cenario&lt;/strong&gt;: the student has been hard at work on a project using a big dataset and wants to present their latest results at the meeting.&lt;/p&gt;&lt;p id="77ef"&gt;The &lt;em&gt;Sapling&lt;/em&gt; student will arrive and say they were hoping to present but ended up not having results, which often boils down to a few reasons&lt;/p&gt;&lt;ul&gt;&lt;li id="8e83"&gt;there was a bug in their program and it crashed over night&lt;/li&gt;&lt;li id="e4be"&gt;the data is too big and the program didn’t scale&lt;/li&gt;&lt;li id="be58"&gt;they got the results and generated the plot but realized something was wrong in the plot and didn’t save the results to quickly remake the plot&lt;/li&gt;&lt;/ul&gt;&lt;p id="4a35"&gt;The &lt;em&gt;Pine&lt;/em&gt; student arrives with their results, though not always with the full extent of what they had planned. The Pine student has done the back of the envelope calculation to determine how much time they have before the meeting and generated results for as much of the data as they could, using appropriate subsampling.&lt;/p&gt;&lt;p id="69e2"&gt;&lt;strong&gt;Reflection&lt;/strong&gt;: Many of the projects in my lab involve large datasets, sometimes tens of terabytes of data. Even some smaller datasets have millions of data points that are impractical to study if analyzed naively. This scale can pose a substantial challenge to the budding scientist, who up to this point has not worked at scale in their coursework? The reality is that we generally don’t need to use all of that data to get our initial results. If we have a billion data points, using a random sample of one million will probably give us a fairly close result to the full data, just with larger error bars. Getting small results quickly is important for building intuition on your research questions. Learning how to generate these results quickly — or discover a bug preventing you from scaling — is equally important in developing the craft of software development.&lt;/p&gt;&lt;p id="4af2"&gt;The critical skill here is planning to get results. Running a program is an important step, but the Pine student’s effort in estimating the time is an important earlier step. How long will the process take? Can we use less data now? If we need all the data, can we parallelize this somehow? Good communication with the advisor and peers in the lab can help significantly with planning as well — and possibly on how to strategize to speed things up.&lt;/p&gt;&lt;p id="8427"&gt;&lt;strong&gt;Suggestions on how to become a Pine:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li id="9ca9"&gt;Run your analysis on the smallest amount of data you can at first (maybe the first 1000 examples) to debug everything and to get a sense of how long it might take. Then try to run as much data as you can before the meeting.&lt;/li&gt;&lt;li id="5c25"&gt;Never launch a program to produce results on all the data without first checking that it works on a small batch of data first.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;&lt;figure&gt;&lt;div&gt;&lt;p&gt;&lt;img height="447" width="640" src="https://miro.medium.com/max/60/1*hYstZkdvHzmcIkFVklB_MQ.png?q=20" alt="Image for post"&gt;&lt;/p&gt;&lt;/div&gt;&lt;figcaption&gt;As you can see from this figure, most of the lines go up and to the right, meaning our method is working (Image credit &lt;a rel="noopener nofollow" href="https://commons.wikimedia.org/wiki/User:Cullen328"&gt;Cullen328&lt;/a&gt;, shared under Creative Commons&lt;a rel="noopener nofollow" href="https://creativecommons.org/licenses/by-sa/3.0/deed.en"&gt; Attribution-Share Alike 3.0 Unported&lt;/a&gt;)&lt;/figcaption&gt;&lt;/figure&gt;&lt;p id="325c"&gt;&lt;span&gt;S&lt;/span&gt;&lt;strong&gt;cenario&lt;/strong&gt;: the student has produced a new figure for us to look at about their project&lt;/p&gt;&lt;p id="f06b"&gt;The &lt;em&gt;Sapling&lt;/em&gt; student’s figures often have a few common issues:&lt;/p&gt;&lt;ul&gt;&lt;li id="6e28"&gt;no labels on axes or other interpretable visualizations, or a tiny font&lt;/li&gt;&lt;li id="ec0c"&gt;the data is oddly grouped or organized so that similar things are not visually distinguishable&lt;/li&gt;&lt;li id="1fdb"&gt;the data is heavily skewed but the figure isn’t drawn at log scale for the appropriate axes, making it difficult to read&lt;/li&gt;&lt;li id="b34c"&gt;the figure was generated in a way that makes it difficult for us to quickly fix these issues&lt;/li&gt;&lt;/ul&gt;&lt;p id="9f2d"&gt;The &lt;em&gt;Pine&lt;/em&gt; student’s figures are appropriately labeled and scaled. They have the code for generating the figure handy (e.g., in a Jupyter notebook) so that if we need to change anything, we can do it together. Pine students often have generated more figures than we have time to talk about by doing lots of little analyses, which lets them prioritize the ones we spend time on in our meetings.&lt;/p&gt;&lt;p id="74f4"&gt;&lt;strong&gt;Reflection&lt;/strong&gt;: Figure making is an important art in the process of communicating science. The &lt;em&gt;Sapling&lt;/em&gt; student often thinks of making the figure as the goal but the Pine student will realize that the true goal is having someone &lt;em&gt;other than them&lt;/em&gt; understand the figure as they themselves do. Learning how to generate high quality, interpretable figures can take time, so being able to quickly iterate is useful and saves time later when we need to generate the figures for the paper.&lt;/p&gt;&lt;p id="9f6a"&gt;&lt;strong&gt;Suggestions on how to become a Pine:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li id="e94d"&gt;Label your axes&lt;/li&gt;&lt;li id="d596"&gt;Make sure the code for generating your figure is readily available and easily runnable&lt;/li&gt;&lt;li id="ed67"&gt;Get the easy figure first (e.g., use Seaborn, Matplotlib, or Gnuplot with their defaults) and then go about the business of customizing. &lt;a rel="noopener nofollow" href="http://gnuplot.sourceforge.net/demo/"&gt;Example&lt;/a&gt; &lt;a rel="noopener nofollow" href="https://matplotlib.org/gallery/index.html"&gt;figure&lt;/a&gt; &lt;a rel="noopener nofollow" href="http://seaborn.pydata.org/examples/index.html"&gt;galleries&lt;/a&gt; can help show you possible ways to adjust — with code too.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;&lt;figure&gt;&lt;div&gt;&lt;p&gt;&lt;img height="500" width="375" src="https://miro.medium.com/max/46/1*aPVuy_D8BfgE2lQfrsQtRA.png?q=20" alt="Image for post"&gt;&lt;/p&gt;&lt;/div&gt;&lt;figcaption&gt;The undergraduate researcher writes a note to maintain a positive attitude with all the ups and downs of research (Image credit &lt;a rel="noopener nofollow" href="https://www.flickr.com/photos/gammaman/"&gt;Gamma Man&lt;/a&gt;, shared under a &lt;a rel="noopener nofollow" href="https://creativecommons.org/licenses/by/2.0/"&gt;CC by 2.0&lt;/a&gt; license)&lt;/figcaption&gt;&lt;/figure&gt;&lt;p id="0adb"&gt;&lt;span&gt;S&lt;/span&gt;&lt;strong&gt;cenario&lt;/strong&gt;: a long technical discussion is wrapping up by discussing the next steps for the project&lt;/p&gt;&lt;p id="8aa8"&gt;The &lt;em&gt;Sapling&lt;/em&gt; student will ask questions about the discussion but often not take notes; or, if the discussion has included drawing on the whiteboard, no record is taken of any diagrams. When asked if they understand some specific part of what we discussed, the Sapling student says yes (often to avoid admitting they didn’t understand).&lt;/p&gt;&lt;p id="07dc"&gt;The &lt;em&gt;Pine&lt;/em&gt; student takes notes in multiple formats. If anything is unclear, the Pine student will ask clarification questions. Often, pictures are taken of the white board discussion and posted to the appropriate Slack channel for the project for everyone to see. Following the advice from my colleague &lt;a rel="noopener nofollow" href="http://web.eecs.umich.edu/~wlasecki/"&gt;Walter Lasecki&lt;/a&gt;, I’ve been encouraging students to use their phone to record the whole audio of the meeting, which is then posted to Slack as well.&lt;/p&gt;&lt;p id="5389"&gt;&lt;strong&gt;Reflection&lt;/strong&gt;: Notes are critical. I’ve been impressed with the recorded meetings as well. When taking hand-written notes, it becomes a trade-off between writing down what’s being said and being an active participant. Recording the whole audio lets students go back and listen to any part they might have missed or need additional context for understanding.&lt;/p&gt;&lt;p id="989b"&gt;Moreover, in mixed-gender groups, recording audio eliminates the undesirable trend of having the female researcher end up as the notetaker and not participate as much. The audio recording ensures everyone can be an equal participant without having to worry about writing down what’s being said.&lt;/p&gt;&lt;p id="9a75"&gt;Some students have also taken to following up after each meeting with a meeting summary. These summaries are very useful, as they help drive the discussion at the next meeting and provide a moment of reflection for thinking about what is to be done next. I often have students in my lab send me brief weekly summaries of their work during the week and their plans for the next week. While the former part is useful for finding highlights for recommendation letters, the latter is actually the critical part in nudging students to think bigger picture on the project and what they want to accomplish. Pausing to reflect on what was done during the week is also useful for thinking about the process of research and what could be done different.&lt;/p&gt;&lt;p id="59c4"&gt;Beyond taking notes, being honest about what you do and don’t understand is essential for healthy discussions. There is no shame in admitting you don’t understand some part of the discussion and wanting more clarification. I have found that some students want to preserve the illusion of knowledge and avoid speaking up so they seem competent. Not knowing something can be intimidating — especially at the start of a project when most parts are unknown. One self-actualizing strategy I’ve liked from a student was to always add “yet” to the end of any sentence about not knowing something, e.g., “I don’t know how to train a neural language model &lt;em&gt;yet,&lt;/em&gt;” when asking a question. This positive mindset is critical going forward as a researcher; there will be much you won’t know and even more than you’ll never know but it is essential that you have faith in your ability to learn new things as they come up.&lt;/p&gt;&lt;p id="4762"&gt;After the meeting, if a Pine student realizes they didn’t understand something, they can potentially go back their notes or recording. For technical questions, I encourage students to ask their fellow labmates first for help and advice before reaching out to me. A main motivation for this is building lab knowledge; having to explain something or debug someone else’s code provides a valuable experience to both parties, who inevitably learn more. It also creates a culture of helping one another that lets problems get solved more quickly.&lt;/p&gt;&lt;p id="4b1b"&gt;&lt;strong&gt;Suggestions on how to become a Pine:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li id="8ded"&gt;Record the meeting audio and immediately post it to Slack so you and your teammates can go back over anything later.&lt;/li&gt;&lt;li id="e5d5"&gt;Take pictures of any diagrams on the whiteboard and upload these to Slack too for everyone in the group.&lt;/li&gt;&lt;li id="84a2"&gt;If you don’t understand something ask for clarification. One useful way to ask is to try to restate what you think is happening and ask if that’s right.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;&lt;figure&gt;&lt;div tabindex="0" role="button"&gt;&lt;p&gt;&lt;img height="853" width="1280" src="https://miro.medium.com/max/60/1*tA70Q9VWzfTg3X0mt2_zIQ.png?q=20" alt="Image for post"&gt;&lt;/p&gt;&lt;/div&gt;&lt;figcaption&gt;Undergraduate researchers taking their next steps towards achieving their research goals&lt;/figcaption&gt;&lt;/figure&gt;&lt;p id="6d52"&gt;&lt;span&gt;S&lt;/span&gt;&lt;strong&gt;cenario&lt;/strong&gt;: the meeting is wrapping up on time and the advisor and student have a few minutes left for discussion on what are the next steps they will be working on until the next meeting.&lt;/p&gt;&lt;p id="ecaf"&gt;In general, the &lt;em&gt;Sapling&lt;/em&gt; student will leave the meeting without solid understanding of the next steps. Often this vagueness is due to one or more of a few reasons:&lt;/p&gt;&lt;ul&gt;&lt;li id="44e1"&gt;the Sapling student has not taken notes during the meeting and can’t recall the specifics of what needs to be done or how it needs to be done&lt;/li&gt;&lt;li id="45b7"&gt;the objectives are specified somewhere (e.g., Asana) and the Sapling student has said they understand but upon further reflection realizes that they have more questions&lt;/li&gt;&lt;li id="fa2b"&gt;the Sapling student needs something to make progress (e.g., needs to figure out how to set up a Jupyter notebook) but hasn’t made this clear to the advisor, which blocks the effort on the actual next steps.&lt;/li&gt;&lt;/ul&gt;&lt;p id="ac4e"&gt;The Sapling student may also have a few ideas they have thought of that might be good next directions but won’t bring these up, usually assuming that because there are already several next-steps to be done, their ideas can wait.&lt;/p&gt;&lt;p id="4ece"&gt;The &lt;em&gt;Pine&lt;/em&gt; student concludes the meeting by suggesting what they think are the next steps and why. These suggestions include addressing things that are currently blocking the student. Then the advisor and the Pine student discuss the next steps together. The Pine student may also challenge the advisor’s next steps and suggest new directions for the project as a whole.&lt;/p&gt;&lt;p id="1a0d"&gt;&lt;strong&gt;Reflection&lt;/strong&gt;: One of the most powerful skills a new researcher can learn is to predict what their advisor would say. Instead of asking what are the next steps, a Pine student suggests what they think the advisor would suggest as the next steps. This role assumption helps students get unstuck on their own later by asking themselves what their advisor would say in the current predicament. In the case of project planning, a discussion of next steps helps the Pine student understand the connection between their current work and the goals of the project. While not everything the Pine student suggests is accepted, the advisor’s role is to help the student understand why certain things are re-prioritized or not done so that the student can learn about the process of science. As students grow in their understanding of the project, I appreciate being challenged to justify why one of my suggestions should be taken — healthy skepticism can lead to fruitful conversations about project goals and potentially new avenues for research. That said, lots of challenging can be exhausting.&lt;/p&gt;&lt;p id="dd1e"&gt;&lt;strong&gt;Suggestions on how to become a Pine:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li id="34c3"&gt;At the end of the meeting, suggest what you think should be the next steps for the project.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;&lt;figure&gt;&lt;div&gt;&lt;p&gt;&lt;img height="794" width="680" src="https://miro.medium.com/max/52/1*oQzahN3FKcVG13UQqLw1aQ.png?q=20" alt="Image for post"&gt;&lt;/p&gt;&lt;/div&gt;&lt;figcaption&gt;Several mature undergraduate researchers, standing proudly together in a field (Image Credit: U.S. Fish and Wildlife Service)&lt;/figcaption&gt;&lt;/figure&gt;&lt;p id="95ff"&gt;&lt;span&gt;M&lt;/span&gt;&lt;strong&gt;ore&lt;/strong&gt; generally, a part of the transition from &lt;em&gt;Sapling&lt;/em&gt; to &lt;em&gt;Pine&lt;/em&gt; is their reimagining of their work as &lt;em&gt;research&lt;/em&gt; rather than homework-like programming assignments. The latter leads to overly narrow questions and a mentality that all work on the project is driven by the advisor, e.g., determining next steps, setting meeting agendas, specifying how to make figures. Initially, this mentality might be necessary for the truly fresh students who is just learning what research means. However, the goal is to have the student take ownership of the research and drive both the research questions and goals in conjunction with the advisor.&lt;/p&gt;&lt;p id="43db"&gt;In nature, not all seeds, sprouts, and saplings wind up growing into full pines — those that do are the ones that have access to resources (water, light, space, freedom from predators/pests). As an advisor, my responsibility is to provide these as much and best as I can. By preparing for meetings, you can ensure that you, young Sapling, are well positioned to absorb the resources (guidance, feedback, advice) your advisor and labmates can offer.&lt;/p&gt;&lt;p id="f850"&gt;I hope this post has helped frame some of the opportunities for growth that I’ve seen in my own lab’s students and I welcome any discussion or suggestions from others!&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;p id="dbd0"&gt;¹ I’ve written this post with the undergraduate researcher in mind, but I suspect it would also apply broadly to new masters students and even the occasional PhD student.&lt;/p&gt;&lt;p id="ec08"&gt;² Specifically, it’s the &lt;a rel="noopener nofollow" href="https://en.wikipedia.org/wiki/Pinus_strobus"&gt;Eastern white pine&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;a href="https://medium.com/@jurgens_24580/reflections-on-strategies-for-successful-meetings-with-undergraduate-researchers-ae22306ecd8d"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sat, 4 Apr 2020 10:14:56 UT
      </pubDate>
      <guid>
        https://medium.com/@jurgens_24580/reflections-on-strategies-for-successful-meetings-with-undergraduate-researchers-ae22306ecd8d
      </guid>
    </item>
    <item>
      <title>
        Advice for Research Students (and others)
      </title>
      <link>
        http://www.cs.jhu.edu/~jason/advice/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;h2&gt;Advice for Research Students&lt;/h2&gt; &lt;p&gt;Over the years, I've written a lot of advice for students and others. Feel free to link to these pages.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="http://www.cs.jhu.edu/~jason/advice/prospective-students.html"&gt;For prospective graduate students&lt;/a&gt; &lt;/li&gt;&lt;li&gt;&lt;a href="http://www.cs.jhu.edu/~jason/advice/how-to-work-with-a-professor.html"&gt;For undergrads who want to get involved in research&lt;/a&gt; &lt;/li&gt;&lt;li&gt;&lt;a href="http://www.cs.jhu.edu/~jason/advice/how-to-ask-for-a-recommendation.html"&gt;How to ask for a recommendation letter&lt;/a&gt; &lt;/li&gt;&lt;li&gt;&lt;a href="http://www.quora.com/How-do-I-study-to-get-into-a-PhD-program-of-a-top-US-university-two-years-from-now/answer/Jason-Eisner?share=1"&gt;How should I prepare myself for grad school?&lt;/a&gt; &lt;/li&gt;&lt;li&gt;&lt;a href="http://www.quora.com/Is-there-a-success-or-performance-gap-between-Ph-D-students-who-go-directly-from-their-undergrad-vs-those-who-take-a-few-years-to-work-in-the-field/answer/Jason-Eisner?share=1"&gt;Should I go straight to grad school?&lt;/a&gt; &lt;/li&gt;&lt;li&gt;&lt;a href="http://www.cs.jhu.edu/~jason/advice/how-to-interview.html"&gt;How to think about grad school interviews&lt;/a&gt; &lt;br&gt;&amp;nbsp; &lt;/li&gt;&lt;li&gt;&lt;a href="http://www.quora.com/Do-professors-enjoy-answering-high-level-questions-more-than-low-level-ones/answer/Jason-Eisner?share=1"&gt;How to ask a question in class&lt;/a&gt; &lt;/li&gt;&lt;li&gt;&lt;a href="http://www.cs.jhu.edu/~jason/advice/how-to-read-a-paper.html"&gt;How to read a paper&lt;/a&gt; &lt;/li&gt;&lt;li&gt;&lt;a href="http://www.cs.jhu.edu/~jason/advice/how-to-present-a-paper.html"&gt;How to present a paper in reading group&lt;/a&gt; &lt;/li&gt;&lt;li&gt;&lt;a href="https://plus.google.com/109118176785250321075/posts/Dh79Nz6z1aU"&gt;How far to go with double-blind review&lt;/a&gt; &lt;/li&gt;&lt;li&gt;&lt;a href="http://www.cs.jhu.edu/~jason/advice/how-to-ta.html"&gt;How to be a teaching assistant&lt;/a&gt; &lt;br&gt;&amp;nbsp; &lt;/li&gt;&lt;li&gt;&lt;a href="http://www.cs.jhu.edu/~jason/advice/how-to-organize-your-files.html"&gt;How to organize your files&lt;/a&gt; &lt;/li&gt;&lt;li&gt;&lt;a href="http://www.cs.jhu.edu/~jason/advice/how-to-evaluate-an-advisor.html"&gt;How to evaluate an advisor&lt;/a&gt; &lt;/li&gt;&lt;li&gt;How to deal with an &lt;a href="http://www.quora.com/How-do-I-deal-with-an-advisor-whos-biased-and-doesnt-give-you-time/answer/Jason-Eisner?share=1"&gt;unresponsive&lt;/a&gt; or &lt;a href="http://www.quora.com/PhD-Careers/How-can-you-make-it-up-to-a-research-advisor-who-is-ready-to-disown-you/answer/Jason-Eisner?share=1"&gt;angry&lt;/a&gt; advisor &lt;/li&gt;&lt;li&gt;&lt;a href="http://www.cs.jhu.edu/~jason/advice/how-to-find-research-problems.html"&gt;How to find research problems&lt;/a&gt; &lt;br&gt;&amp;nbsp; &lt;/li&gt;&lt;li&gt;&lt;a href="http://www.cs.jhu.edu/~jason/advice/write-the-paper-first.html"&gt;Write the paper first&lt;/a&gt; (as an early step in the research) &lt;/li&gt;&lt;li&gt;&lt;a href="https://twitter.com/wittgen_ball/status/1097650012262027264"&gt;How to cite your own work without breaking anonymity&lt;/a&gt; &lt;/li&gt;&lt;li&gt;&lt;a href="http://www.cs.jhu.edu/~jason/advice/how-to-give-a-talk.html"&gt;How to prepare a talk&lt;/a&gt; &lt;/li&gt;&lt;li&gt;&lt;a href="https://www.quora.com/Should-I-meet-with-my-dissertation-committee-members-even-though-my-advisor-advises-against-it/answer/Jason-Eisner?share=1"&gt;How to meet with your dissertation committee&lt;/a&gt; &lt;/li&gt;&lt;li&gt;&lt;a href="http://www.cs.jhu.edu/~jason/advice/how-to-write-a-thesis.html"&gt;How to write up a Ph.D. dissertation&lt;/a&gt; &lt;/li&gt;&lt;li&gt;&lt;a href="http://www.cs.jhu.edu/~jason/advice/in-defense-of-footnotes.html"&gt;In defense of footnotes&lt;/a&gt; &lt;/li&gt;&lt;li&gt;&lt;a href="https://www.quora.com/Assuming-that-Ph-D-students-decide-to-apply-for-faculty-positions-how-much-should-their-research-proposal-differ-from-their-Ph-D-research/answer/Jason-Eisner?share=1"&gt;How to write an academic research statement&lt;/a&gt; (when applying for a faculty job) &lt;/li&gt;&lt;li&gt;&lt;a href="http://www.cs.jhu.edu/~jason/advice/how-to-chair-a-conference.html"&gt;How to serve as program chair of a conference&lt;/a&gt; &lt;/li&gt;&lt;li&gt;How to set up publication practices for a professional society: conferences/journals (&lt;a href="http://www.cs.jhu.edu/~jason/advice/ACLJournalConference-Eisner.pdf"&gt;2009&lt;/a&gt;, &lt;a href="http://www.cs.jhu.edu/~jason/advice/acl-publications.pdf"&gt;2010&lt;/a&gt;), &lt;a href="https://www.aclweb.org/adminwiki/index.php?title=ACL_Policies_for_Submission,_Review_and_Citation"&gt;preprint policies&lt;/a&gt; (&lt;a href="https://www.aclweb.org/adminwiki/images/e/e7/ACL_Guidelines_for_Submission%2C_Review_and_Citation.pdf"&gt;report 2017&lt;/a&gt;) &lt;br&gt;&amp;nbsp; &lt;/li&gt;&lt;li&gt;&lt;a href="http://www.cs.jhu.edu/~jason/advice/massagechair.html"&gt;How to use the CLSP massage chair&lt;/a&gt; &lt;/li&gt;&lt;/ul&gt; &lt;p&gt;I've also been &lt;a href="http://www.quora.com/Jason-Eisner/answers?share=1"&gt;answering questions on Quora&lt;/a&gt; lately. See also my &lt;a href="http://www.cs.jhu.edu/~jason/tutorials/"&gt;technical tutorials&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;A couple of writings that I like to recommend are Michael Nielsen's essay &lt;a href="https://michaelnielsen.org/blog/principles-of-effective-research/"&gt;Principles of Effective Research&lt;/a&gt; and Phil Agre's opus &lt;a href="https://homes.cs.washington.edu/~mernst/advice/agre-networking-on-the-network-20050814.html"&gt;Netwokring on the Network&lt;/a&gt;. This give a high-level perspective on how to build a research career: Nielsen writes about cultivating your own thinking, and Agre writes about cultivating your relationships with other researchers.&lt;/p&gt; &lt;p&gt;JHU students can also find a outdated collection of pointers to good advice (mostly compiled by me) &lt;a href="http://old-site.clsp.jhu.edu/wiki2/Student_Life_FAQ#How_can_I_be_a_successful_grad_student.3F"&gt;in the CLSP FAQ&lt;/a&gt;, and a bigger collection &lt;a href="http://web.engr.illinois.edu/~taoxie/advice.htm"&gt;here&lt;/a&gt; compiled by Tao Xie. And why not Google for &lt;a href="http://www.google.com/search?num=50&amp;amp;q=career+advice+computer+science+graduate+students"&gt;&lt;code&gt;career advice computer science graduate students&lt;/code&gt;&lt;/a&gt;?&lt;/p&gt; &lt;p&gt;&lt;b&gt;Use your undergraduate education:&lt;/b&gt; "But you go to a great school, not for knowledge so much as for arts and habits; for the habit of attention, for the art of expression, for the art of assuming at a moment's notice a new intellectual posture, for the art of entering quickly into another person's thoughts, for the habit of submitting to censure and refutation, for the art of indicating assent or dissent in graduated terms, for the habit of regarding minute points of accuracy, for the habit of working out what is possible in a given time, for taste, for discrimination, for mental courage and mental soberness." -William Johnson Cory (1861)&lt;/p&gt; &lt;hr&gt; This page online: &lt;code&gt;http://cs.jhu.edu/~jason/advice&lt;/code&gt; &lt;/div&gt;&lt;a href="http://www.cs.jhu.edu/~jason/advice/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sat, 4 Apr 2020 10:15:10 UT
      </pubDate>
      <guid>
        http://www.cs.jhu.edu/~jason/advice/
      </guid>
    </item>
    <item>
      <title>
        When debugging, your attitude matters
      </title>
      <link>
        https://jvns.ca/blog/debugging-attitude-matters/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt; &lt;p&gt;A while back I wrote &lt;a href="https://jvns.ca/blog/2019/06/23/a-few-debugging-resources/"&gt;What does debugging a program look like?&lt;/a&gt; on what to do when debugging (change one thing at a time! check your assumptions!).&lt;/p&gt; &lt;p&gt;But I was debugging some CSS last week, and I think that post is missing something important: &lt;strong&gt;your attitude&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;Now – I’m not a very good CSS developer yet. I’ve never written CSS professionally and I don’t understand a lot of basic CSS concepts (I think I finally understood for the first time recently how &lt;code&gt;position: absolute&lt;/code&gt; works). And last week I was working on the most complicated CSS project I’d ever attempted.&lt;/p&gt; &lt;p&gt;While I was debugging my CSS, I noticed myself doing some bad things that I normally would not! I was:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;making random changes to my code in the hopes that it would work&lt;/li&gt; &lt;li&gt;googling a lot of things and trying them without understanding what they did&lt;/li&gt; &lt;li&gt;if something broke, reverting my changes and starting again&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;This strategy was exactly as effective as you might imagine (not very effective!), and it was because of my attitude about CSS! I had this unusual-for-me belief that CSS was Too Hard and impossible for me to understand. So let’s talk about that attitude a bit!&lt;/p&gt; &lt;h3 id="the-problem-attitude-this-is-too-hard-for-me-to-understand"&gt;the problem attitude: “this is too hard for me to understand”&lt;/h3&gt; &lt;p&gt;One specific problem I was having was – I had 2 divs stacked on top of one another, and I wanted Div A to be on top of Div B. My model of CSS stacking order at the start of this was basically “if you want Thing A to be on top of Thing B, change the z-index to make it work”. So I changed the z-index of Div A to be 5 or something.&lt;/p&gt; &lt;p&gt;But it didn’t work! In Firefox, div A was on top, but in Chrome, Div B was on top. Argh! Why? CSS is impossible!!! (&lt;small&gt;if you want to see the exact actual situation I was in, I &lt;a href="https://codepen.io/jvns-css-fun/pen/zYGVLXj"&gt;reproduced the different-in-firefox-and-chrome thing here after the fact&lt;/a&gt;&lt;/small&gt;)&lt;/p&gt; &lt;p&gt;I googled a bit, and I found out that a possible reason z-index might not work was because Div A and Div B were actually in different “stacking contexts”. If that was true, even if I set the z-index of Div A to 999999 it would still not put it on top of Div B. (&lt;a href="https://codepen.io/jvns-css-fun/pen/YzXMMdQ"&gt;here’s a small example of what this z-index problem looks like, though I think my specific bug had some extra complications&lt;/a&gt;)&lt;/p&gt; &lt;p&gt;I thought “man, this stacking context thing seems really complicated, why is it different between Firefox and Chrome, I’m not going to be able to figure this out”. So I tried a bunch of random things a bunch of blog posts suggested, which as usual did not work.&lt;/p&gt; &lt;p&gt;Finally I gave up this “change random things and pray” strategy and thought “well, what if I just read the documentation on stacking order, maybe it’s not that bad”.&lt;/p&gt; &lt;p&gt;So I read the &lt;a href="https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Positioning/Understanding_z_index/Stacking_without_z-index"&gt;MDN page on stacking order&lt;/a&gt;, which says:&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;When the z-index property is not specified on any element, elements are stacked in the following order (from bottom to top): &lt;br&gt; 1. The background and borders of the root element &lt;br&gt; 2. Descendant non-positioned blocks, in order of appearance in the HTML &lt;br&gt; 3. Descendant positioned elements, in order of appearance in the HTML&lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt;This is SO SIMPLE! It just depends on the order in the HTML! I put Div A after Div B in the HTML (as a sibling) and it made everything work in both browsers.&lt;/p&gt; &lt;h3 id="better-attitude-let-s-learn-the-basics-and-see-if-that-helps"&gt;better attitude: “let’s learn the basics and see if that helps”&lt;/h3&gt; &lt;p&gt;This whole stacking problem turned out to really not be that complicated – all I needed to do was read a very short and simple documentation page to understand how stacking works!&lt;/p&gt; &lt;p&gt;Of course, computer things are not always this simple (and even in this specific case the &lt;a href="https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Positioning/Understanding_z_index/The_stacking_context"&gt;rules about what creates a new stacking context&lt;/a&gt; are pretty complicated.). But I did not need to understand those more complicated rules in order to put Div A on top of Div B! I only needed to know the much simpler 3 rules above.&lt;/p&gt; &lt;p&gt;So – calm down for a second, learn a few of the basics, and see if that helps.&lt;/p&gt; &lt;h3 id="watching-people-who-know-what-they-re-doing-is-inspiring"&gt;watching people who know what they’re doing is inspiring&lt;/h3&gt; &lt;p&gt;Another area of CSS that I thought was “too hard” for me to understand was this whole &lt;code&gt;position: absolute&lt;/code&gt; and &lt;code&gt;position: relative&lt;/code&gt; business. I kept seeing (and sometimes using!) examples where people made complicated CSS things with &lt;code&gt;position: absolute&lt;/code&gt; but I didn’t understand how they worked. Doesn’t &lt;code&gt;position: absolute&lt;/code&gt; mean that the element is always in the same place on the screen? Why are these &lt;code&gt;position: absolute&lt;/code&gt; things moving when I scroll like the rest of the document? (spoiler: no, that’s &lt;code&gt;position: fixed&lt;/code&gt;.)&lt;/p&gt; &lt;p&gt;But last week, I paired with someone who’s a lot better at CSS than me on some code, and I saw that they were just typing in &lt;code&gt;position: absolute&lt;/code&gt; and &lt;code&gt;position: relative&lt;/code&gt; confidently into their code without seeming confused about it!! Could that be me?&lt;/p&gt; &lt;p&gt;I looked up the &lt;a href="https://developer.mozilla.org/en-US/docs/Web/CSS/position"&gt;documentation on MDN&lt;/a&gt; on &lt;code&gt;position: absolute&lt;/code&gt;, and it said:&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;The element is removed from the normal document flow, and no space is created for the element in the page layout. It is positioned relative to its closest positioned ancestor… Its final position is determined by the values of top, right, bottom, and left.&lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt;So things with &lt;code&gt;position: absolute&lt;/code&gt; are positioned relative to their closest positioned ancestor! And you just use &lt;code&gt;top/bottom/right/left&lt;/code&gt; to pick where! That’s so simple!&lt;/p&gt; &lt;h3 id="documentation-that-you-can-trust-makes-a-big-difference"&gt;documentation that you can trust makes a big difference&lt;/h3&gt; &lt;p&gt;I think another big source of my frustration with CSS is that I didn’t have the best grasp of where to find accurate information &amp;amp; advice. I knew that MDN was a reliable reference, but MDN doesn’t really help answer questions like “ok but seriously how do I center a div???” and I found myself reading a lot of random Stack Overflow answers/blog posts that I wasn’t 100% sure were correct.&lt;/p&gt; &lt;p&gt;This week I learned about &lt;a href="https://css-tricks.com/"&gt;CSS Tricks&lt;/a&gt; which has a lot of GREAT articles like &lt;a href="https://css-tricks.com/centering-css-complete-guide/"&gt;Centering in CSS: A Complete Guide&lt;/a&gt; which seems very reputable and is written in a super clear way.&lt;/p&gt; &lt;h3 id="that-s-all"&gt;that’s all!&lt;/h3&gt; &lt;p&gt;I don’t really know why I started to believe that it was “impossible” to understand basic CSS concepts since I don’t believe that about computers in general. Maybe because I’ve been writing CSS at a beginner level for a very long time but hadn’t ever really tried to do a more involved CSS project than “let’s arrange some divs in a grid with flexbox”!&lt;/p&gt; &lt;p&gt;But this attitude really got in the way of me writing the CSS I wanted to write! And once I let go of it and used my normal debugging techniques I was able to get a lot more things to work the way I wanted.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://jvns.ca/blog/debugging-attitude-matters/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sun, 5 Apr 2020 16:17:55 UT
      </pubDate>
      <guid>
        https://jvns.ca/blog/debugging-attitude-matters/
      </guid>
    </item>
    <item>
      <title>
        Your configs suck? Try a real programming language. | beepb00p
      </title>
      <link>
        https://beepb00p.xyz/configs-suck.html
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt; &lt;article&gt; &lt;section id="post-title"&gt; &lt;p&gt;Or yet another rant about YAML &lt;/p&gt;&lt;/section&gt; &lt;section id="post-content"&gt; &lt;p&gt; In this post, I'll try to explain why I find most config formats frustrating to use and suggest that using a real programming language (i.e. general purpose one, like Python) is often (but &lt;a href="#cons"&gt;&lt;b&gt;not always&lt;/b&gt;&lt;/a&gt;) a feasible and more pleasant alternative for writing configs. &lt;/p&gt; &lt;div id="table-of-contents"&gt; &lt;h2&gt;Table of Contents&lt;/h2&gt; &lt;div&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="#configs_suck"&gt;1. Most modern config formats suck&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#workarounds"&gt;2. Workarounds&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#real_language"&gt;3. Use a real programming language&lt;/a&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="#cons"&gt;Downsides&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#why_python"&gt;Why Python?&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#who_else"&gt;Who else does it?&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;&lt;a href="#what_if_i_have_to"&gt;4. What if you don't have a choice?&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#links"&gt;5. Extra links&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#fin"&gt;6. --&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#ps"&gt;7. &lt;span&gt;&lt;span&gt;[2020-04-11]&lt;/span&gt;&lt;/span&gt; P.S.&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;div&gt; &lt;h2 id="configs_suck"&gt;&lt;a href="#configs_suck"&gt;¶&lt;/a&gt;&lt;span&gt;1&lt;/span&gt; Most modern config formats suck&lt;/h2&gt; &lt;div&gt; &lt;p&gt; In this section, I'm mostly referring to JSON/YAML/TOML/ini files, which are the most common config formats I encounter. &lt;/p&gt; &lt;p&gt; I'll refer to such configs as &lt;b&gt;&lt;span&gt;plain configs&lt;/span&gt;&lt;/b&gt;. Not sure if there is a better name for it, please let me know! &lt;/p&gt; &lt;p&gt; An incomplete list of my frustrations: &lt;/p&gt; &lt;ul&gt; &lt;li&gt;JSON &lt;b&gt;doesn't have comments&lt;/b&gt;, &lt;a href="https://stackoverflow.com/a/33963845/706389"&gt;by design&lt;/a&gt; 🤯&lt;/li&gt; &lt;li&gt;&lt;p&gt; bits of configs &lt;b&gt;can't be reused&lt;/b&gt; &lt;/p&gt; &lt;p&gt; For example, while YAML, in theory, supports reusing/including bits of the config (they call it &lt;a href="https://confluence.atlassian.com/bitbucket/yaml-anchors-960154027.html"&gt;anchors&lt;/a&gt;), some software like &lt;a href="https://github.community/t5/GitHub-Actions/Support-for-YAML-anchors/td-p/30336/page/3"&gt;Github Actions&lt;/a&gt; doesn't support it &lt;/p&gt; &lt;p&gt; Usually, you just don't have any means of reusing parts of your config and have to copy-paste. &lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;.gitconfig&lt;/code&gt; uses a &lt;a href="https://git-scm.com/docs/git-config#_includes"&gt;custom syntax&lt;/a&gt; for merging the configs&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt; can't contain &lt;b&gt;any logic&lt;/b&gt; &lt;/p&gt; &lt;p&gt; This is considered as a positive by many, but I would argue that when you can't define temporary variables, helper functions, substitute strings or concatenate lists, it's a bit fucked up. &lt;/p&gt; &lt;p&gt; The workarounds (if present) are usually pretty horrible and impose cognitive overhead. Programming language constructs are &lt;b&gt;reinvented from scratch&lt;/b&gt;: &lt;/p&gt; &lt;ul&gt; &lt;li&gt;variables and string interpolation &lt;ul&gt; &lt;li&gt;Ansible uses &lt;a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_templating.html"&gt;Jinja templates&lt;/a&gt; (!) for variable manipulations.&lt;/li&gt; &lt;li&gt;&lt;p&gt; Github Actions use a &lt;a href="https://help.github.com/en/actions/reference/context-and-expression-syntax-for-github-actions"&gt;custom syntax&lt;/a&gt; for that &lt;/p&gt; &lt;p&gt; In addition, they've got &lt;a href="https://help.github.com/en/actions/reference/context-and-expression-syntax-for-github-actions#functions"&gt;their own&lt;/a&gt; set of functions to manipulate the variables. Have fun learning a new language you never wanted to! &lt;/p&gt;&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt; scoping &lt;/p&gt; &lt;p&gt; I.e. there are several custom scopes for &lt;a href="https://help.github.com/en/actions/reference/workflow-syntax-for-github-actions#env"&gt;&lt;samp&gt;env&lt;/samp&gt; directive&lt;/a&gt; in Github Actions. &lt;/p&gt;&lt;/li&gt; &lt;li&gt;control flow &lt;ul&gt; &lt;li&gt;&lt;code&gt;for&lt;/code&gt; loop: build matrices and 'excludes' always give me a headache&lt;/li&gt; &lt;li&gt;&lt;code&gt;if&lt;/code&gt; statement: e.g. &lt;a href="https://circleci.com/docs/2.0/configuration-reference/#the-when-step-requires-version-21"&gt;&lt;samp&gt;when&lt;/samp&gt;&lt;/a&gt; in CircleCI&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt; &lt;a href="https://blog.atomist.com/in-defense-of-yaml"&gt;"This is not structured data. This is programming masquerading as configuration."&lt;/a&gt; &lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt; can't be validated &lt;/p&gt; &lt;p&gt; You can validate the config syntax itself (i.e. check JSON for correctness), but if you want more sophisticated semantic checks, you need to spend extra effort. &lt;/p&gt; &lt;p&gt; This is kind of a consequence of not having logic in the config files. Typically you'll have to write a supplementary program to check your configs and remember to call it before passing to a program. &lt;/p&gt; &lt;p&gt; Very few programs bother with that. Usually, your program crashes because of something that would be &lt;b&gt;trivial to catch with any simple type system&lt;/b&gt;. &lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt; YAML simply stands out with its implicit conversions and portability issues (e.g. "The NOrway Problem") &lt;/p&gt; &lt;p&gt; There are enough rants about it, so I'll just leave a link to a good one: &lt;a href="https://www.arp242.net/yaml-config.html"&gt;"YAML: probably not so great after all"&lt;/a&gt;. &lt;/p&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt; Summary: we spend time learning &lt;b&gt;useless syntax and reinventing programming constructs, instead of productive work&lt;/b&gt;. &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div&gt; &lt;h2 id="workarounds"&gt;&lt;a href="#workarounds"&gt;¶&lt;/a&gt;&lt;span&gt;2&lt;/span&gt; Workarounds&lt;/h2&gt; &lt;div&gt; &lt;p&gt; So what happens when people encounter these problems? Often they end up using a 'real' (i.e. general purpose, Turing complete) programming language anyway: &lt;/p&gt; &lt;ul&gt; &lt;li&gt;you write a program to filter out custom comment syntax&lt;/li&gt; &lt;li&gt;you write a program to merge configs or use a templating engine&lt;/li&gt; &lt;li&gt;&lt;p&gt; you write a program that 'evaluates' the config &lt;/p&gt; &lt;p&gt; Often, you &lt;b&gt;end up reimplementing an interpreter&lt;/b&gt; for a simple functional language in the process. &lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt; you write a program to validate the config &lt;/p&gt; &lt;p&gt; For the most part, it's boilerplate for type checking. You're not only working on a solved problem but in addition, end up with mediocre error messages as a result. &lt;/p&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt; All this stuff is unpleasant and distracts you from your main objective. &lt;/p&gt; &lt;p&gt; Perhaps you can see where I'm coming with this. &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div&gt; &lt;h2 id="real_language"&gt;&lt;a href="#real_language"&gt;¶&lt;/a&gt;&lt;span&gt;3&lt;/span&gt; Use a real programming language&lt;/h2&gt; &lt;div&gt; &lt;p&gt; The idea is to write your config in your target programming language. I'll have Python in mind here, but the same idea can be applied to &lt;b&gt;any dynamic enough language&lt;/b&gt; (e.g. Javascript/Ruby). &lt;/p&gt; &lt;p&gt; Then, you simply import/evaluate your config file and voila – you're done. That's it. &lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt; Toy example: &lt;/p&gt; &lt;p&gt; &lt;samp&gt;config.py&lt;/samp&gt; &lt;/p&gt; &lt;div&gt; &lt;pre&gt;&lt;span&gt;from&lt;/span&gt; typing &lt;span&gt;import&lt;/span&gt; NamedTuple &lt;span&gt;class&lt;/span&gt; &lt;span&gt;Person&lt;/span&gt;(NamedTuple): name: &lt;span&gt;str&lt;/span&gt; age: &lt;span&gt;int&lt;/span&gt; &lt;span&gt;PEOPLE&lt;/span&gt; = [ Person(&lt;span&gt;'Ann'&lt;/span&gt; , 22), Person(&lt;span&gt;'Roger'&lt;/span&gt;, 15), Person(&lt;span&gt;'Judy'&lt;/span&gt; , 49), ] &lt;/pre&gt; &lt;/div&gt; &lt;div&gt; &lt;pre&gt;&lt;span&gt;from&lt;/span&gt; pathlib &lt;span&gt;import&lt;/span&gt; Path &lt;span&gt;config&lt;/span&gt; = {} &lt;span&gt;exec&lt;/span&gt;(Path(&lt;span&gt;'config.py'&lt;/span&gt;).read_text(), config) &lt;span&gt;people&lt;/span&gt; = config[&lt;span&gt;'PEOPLE'&lt;/span&gt;] &lt;span&gt;print&lt;/span&gt;(people) &lt;/pre&gt; &lt;/div&gt; &lt;pre&gt;[Person(name='Ann', age=22), Person(name='Roger', age=15), Person(name='Judy', age=49)] &lt;/pre&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt; I find it pretty neat. Let's see how it helps us with the problems I described: &lt;/p&gt; &lt;ul&gt; &lt;li&gt;comments: duh&lt;/li&gt; &lt;li&gt;&lt;p&gt; includes: trivial, use imports &lt;/p&gt; &lt;p&gt; You can even import the very package you're configuring. So you can define a DSL for configuration, which will be imported and used in the config file. &lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt; logic &lt;/p&gt; &lt;p&gt; You have your language's syntax and libraries available to use. For example, something like &lt;a href="https://docs.python.org/3/library/pathlib.html"&gt;&lt;samp&gt;pathlib&lt;/samp&gt;&lt;/a&gt; alone can save you massive amounts of config duplication. &lt;/p&gt; &lt;p&gt; Of course, one could go crazy and make it incomprehensible. But personally I'd rather accept potential for abusing the power of the language rather than being restricted. &lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt; validation &lt;/p&gt; &lt;p&gt; You can keep validation logic right in the config, so it would be checked at the time of loading. Mature static analysis tools (i.e. JS flow/eslint/pylint/mypy) can be used to aid you. &lt;/p&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div&gt; &lt;h3 id="cons"&gt;&lt;a href="#cons"&gt;¶&lt;/a&gt;Downsides&lt;/h3&gt; &lt;div&gt; &lt;p&gt; Are there any problems with that approach? Sure: &lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt; interoperability &lt;/p&gt; &lt;blockquote&gt; &lt;p&gt; Okay, maybe if your program is in Python it makes sense. But what if it isn't, or you'll rewrite it to another language (i.e. compiled, like c++) later. &lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt; If you'll be running your software somewhere without an interpreter, then sure, good point. Modern &lt;a href="https://en.wikipedia.org/wiki/Foreign_function_interface"&gt;FFI&lt;/a&gt; is tedious and linking against your config is going to be pretty tricky. &lt;/p&gt; &lt;p&gt; In case of Python specifically, it's present in most modern OS distributions. So you might get away with the following: &lt;/p&gt; &lt;ol&gt; &lt;li&gt;make your Python config executable&lt;/li&gt; &lt;li&gt;&lt;p&gt; in the &lt;samp&gt;main()&lt;/samp&gt; function, build the config, convert to JSON and dump to the stdout &lt;/p&gt; &lt;p&gt; This step is possible with no boilerplate due to Python's dynamic nature. &lt;/p&gt;&lt;/li&gt; &lt;li&gt;in your c++ code, execute the Python config (i.e. use &lt;code&gt;popen()&lt;/code&gt;), read the raw JSON and process&lt;/li&gt; &lt;/ol&gt; &lt;p&gt; Yep, you will still have to manually deserialize config in the c++ code. But I think that's at least &lt;b&gt;not worse&lt;/b&gt; than only using JSON and editing it manually. &lt;/p&gt; &lt;p&gt; Obviously that has a performance hit (i.e. milliseconds taken to run the Python interpreter). Make your own judgment whether it's acceptable for you. If the tool you're configuring is running for hours, you're probably going to be fine, or you can always generate the config in advance/cache. &lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt; general-purpose programming languages are &lt;b&gt;harder to reason about&lt;/b&gt; &lt;/p&gt; &lt;p&gt; This is somewhat subjective. Personally, I'd be more likely overwhelmed by an overly verbose plain config. I'd always prefer a neat and compact DSL. &lt;/p&gt; &lt;p&gt; A large factor here is code style: I'm sure you can make your config file readable in almost any programming language, even for people not familiar with the language at all. &lt;/p&gt; &lt;p&gt; However, I appreciate that my experience is different from other engineers (i.e. sysadmins) who would not trade off flexibility for the increase of configuration complexity. &lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt; general-purpose languages are &lt;b&gt;hard to modify programmatically&lt;/b&gt; &lt;/p&gt; &lt;p&gt; To some extent it overlaps with the previous point. For example, &lt;samp&gt;git config&lt;/samp&gt; commands manipulates the &lt;samp&gt;.git/config&lt;/samp&gt; file. It's easy to modify an INI file, because it's basically a dictionary, so you only have to locate the key in the config file and change a single line. &lt;/p&gt; &lt;p&gt; If the config is (say) a Python program, the model can be much more complicated than a dictionary, and it might be tricky to modify settings programmatically. Most likely, you'll have to resort to only appending new code to the config, which may not always be enough. &lt;/p&gt; &lt;p&gt; To me, it's a very strong point against code as a config. As counter-points: &lt;/p&gt; &lt;ul&gt; &lt;li&gt;not many programs have (or need) TUI/GUI for editing settings&lt;/li&gt; &lt;li&gt;&lt;p&gt; the settings that belong to the UI are usually very simple, and possible to adjust by appending only &lt;/p&gt; &lt;p&gt; For example, Emacs customization interface is &lt;a href="https://www.gnu.org/software/emacs/manual/html_node/emacs/Saving-Customizations.html"&gt;backed by an Elisp config&lt;/a&gt;. &lt;/p&gt;&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt; &lt;a id="security"&gt;&lt;/a&gt;The most serious issues are probably security and termination checking: &lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt; security &lt;/p&gt; &lt;p&gt; I.e. if your config executes arbitrary code, then it may steal your passwords or format your hard drive. &lt;/p&gt; &lt;p&gt; Whether security is actually something you need to think about &lt;b&gt;depends on your threat model&lt;/b&gt;: &lt;/p&gt; &lt;ul&gt; &lt;li&gt;if your configs are supplied by third parties you don't trust, then I agree that plain configs are safer.&lt;/li&gt; &lt;li&gt;&lt;p&gt; however, often, especially for end-user software, it's not the case &lt;/p&gt; &lt;p&gt; Often the user controls their own config, and the program runs under the same permissions. &lt;/p&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt; In addition, this is something that can be potentially solved by sandboxing. Whether it's worth the effort depends on the nature of your project, but for something like CI executor &lt;b&gt;you need a sandbox anyway&lt;/b&gt;. &lt;/p&gt; &lt;p&gt; Also, note that using a plain config format doesn't necessarily save you from trouble. See &lt;a href="https://www.arp242.net/yaml-config.html#insecure-by-default"&gt;"YAML: insecure by default"&lt;/a&gt;. &lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt; termination checking &lt;/p&gt; &lt;p&gt; Even if you don't care about security, you don't want your config to hang the program. &lt;/p&gt; &lt;p&gt; Personally, I've never run into such issues, but here are some potential workarounds for that: &lt;/p&gt; &lt;ul&gt; &lt;li&gt;explicit timeout for loading the config&lt;/li&gt; &lt;li&gt;&lt;p&gt; using a subset of the language might help, for example, &lt;a href="https://docs.bazel.build/versions/master/skylark/language.html#differences-with-python"&gt;Skylark&lt;/a&gt; &lt;/p&gt; &lt;p&gt; Anyone knows examples of /conservative/static analysis tools that check for termination in general purpose languages? &lt;/p&gt; &lt;p&gt; Note this is not the same as the &lt;a href="https://en.wikipedia.org/wiki/Halting_problem"&gt;Halting problem&lt;/a&gt;. You don't want to determine whether &lt;b&gt;any&lt;/b&gt; program terminates, you want to figure out a &lt;b&gt;reasonable subset of the language&lt;/b&gt; that terminates. &lt;/p&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt; Even if your config language is Turing incomplete, you might have to resort to using timeouts anyway: &lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt; your config can take &lt;b&gt;very&lt;/b&gt; long time to evaluate, while taking finite time to complete in theory &lt;/p&gt; &lt;p&gt; See &lt;a href="http://www.haskellforall.com/2020/01/why-dhall-advertises-absence-of-turing.html"&gt;"Why Dhall advertises the absence of Turing-completeness"&lt;/a&gt; &lt;/p&gt; &lt;p&gt; While an &lt;a href="https://gist.github.com/Gabriel439/77f715350ecc0443eed5fa613ac6b78e"&gt;Ackermann&lt;/a&gt; function is a contrived example, that means that if you truly care about malicious inputs, you want to sandbox anyway. If your configs support some form of including, you can &lt;a href="https://lobste.rs/s/qyhvhc/your_configs_suck_try_real_programming#c_rtbmnp"&gt;very likely&lt;/a&gt; construct an input that will inflate it exponentially. &lt;/p&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt; Note that using a plain config doesn't mean it won't loop infinitely: &lt;/p&gt; &lt;ul&gt; &lt;li&gt;See &lt;a href="https://www.gwern.net/Turing-complete#accidentally-turing-complete"&gt;"Accidentally Turing complete"&lt;/a&gt; for an excellent overview&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;div&gt; &lt;h3 id="why_python"&gt;&lt;a href="#why_python"&gt;¶&lt;/a&gt;Why Python?&lt;/h3&gt; &lt;div&gt; &lt;p&gt; Some reasons I find Python specifically enjoyable for writing config files: &lt;/p&gt; &lt;ul&gt; &lt;li&gt;Python is present on almost all modern operating systems&lt;/li&gt; &lt;li&gt;Python syntax is considered simple (not a bad thing!), so hopefully Python configs aren't much harder to understand than plain configs&lt;/li&gt; &lt;li&gt;&lt;a href="https://docs.python.org/3/library/dataclasses.html"&gt;data classes&lt;/a&gt;, functions and generators form a basis for a compact DSL&lt;/li&gt; &lt;li&gt;&lt;a href="https://docs.python.org/3/library/typing.html"&gt;typing annotations&lt;/a&gt; serve as documentation and validation at the same time&lt;/li&gt; &lt;/ul&gt; &lt;p&gt; However, you can achieve a similarly pleasant experience in &lt;b&gt;most modern programming languages&lt;/b&gt; (provided they are dynamic enough). &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div&gt; &lt;h3 id="who_else"&gt;&lt;a href="#who_else"&gt;¶&lt;/a&gt;Who else does it?&lt;/h3&gt; &lt;div&gt; &lt;p&gt; Some projects that allow for using code as configuration: &lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://webpack.js.org/configuration"&gt;Webpack&lt;/a&gt;, web asset bundler, uses a Javascript as a config&lt;/li&gt; &lt;li&gt;&lt;p&gt; &lt;a href="https://setuptools.readthedocs.io/en/latest/setuptools.html#basic-use"&gt;setuptools&lt;/a&gt;, the standard way of installing Python packages &lt;/p&gt; &lt;p&gt; Allows using &lt;b&gt;both&lt;/b&gt; &lt;samp&gt;setup.cfg&lt;/samp&gt; and &lt;samp&gt;setup.py&lt;/samp&gt; files. That way if you can't achieve something solely with plain config, you can fix this in &lt;samp&gt;setup.py&lt;/samp&gt;, which gives you a balance between declarative and flexible. &lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt; &lt;a href="https://jupyter.org/"&gt;Jupiter&lt;/a&gt;, interactive computing tool &lt;/p&gt; &lt;p&gt; Uses a &lt;a href="https://github.com/jupyter/jupyter_core/blob/master/jupyter_core/tests/dotipython_empty/profile_default/ipython_nbconvert_config.py"&gt;python file&lt;/a&gt; to configure the export. &lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt; &lt;a href="https://www.gnu.org/software/emacs"&gt;Emacs&lt;/a&gt;: famously uses Elisp for its configuration &lt;/p&gt; &lt;p&gt; While I'm not a fan of Elisp at all, it does make Emacs very flexible and it's possible to achieve any configuration you want. &lt;/p&gt; &lt;p&gt; On the other hand, if you've ever read other people's Emacs setups, you can see it also demonstrates how things can get out of hand when you allow a general purpose language for configuration. &lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/brookhong/Surfingkeys#edit-your-own-settings"&gt;Surfingkeys&lt;/a&gt; browser extension: uses a Javascript DSL for configuration&lt;/li&gt; &lt;li&gt;&lt;a href="https://docs.gradle.org/current/userguide/tutorial_using_tasks.html#sec:build_scripts_are_code"&gt;Gradle&lt;/a&gt; provides Groovy and Kotlin DSLs for writing build files&lt;/li&gt; &lt;li&gt;&lt;a href="https://awesomewm.org/"&gt;Awesome Window Manager&lt;/a&gt; uses Lua for configuration&lt;/li&gt; &lt;li&gt;&lt;a href="https://guix.gnu.org/"&gt;Guix&lt;/a&gt; package manager: uses &lt;a href="https://www.gnu.org/software/guile"&gt;Guile Scheme&lt;/a&gt; for configuration&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/getpelican/pelican"&gt;Pelican&lt;/a&gt; static site generator: uses &lt;a href="https://raw.githubusercontent.com/getpelican/pelican/master/samples/pelican.conf.py"&gt;Python&lt;/a&gt; for configuration&lt;/li&gt; &lt;/ul&gt; &lt;p&gt; Some languages are designed specifically for configuration: &lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt; &lt;a href="https://docs.bazel.build/versions/master/skylark/language.html#differences-with-python"&gt;&lt;del&gt;Bazel&lt;/del&gt; Skylark&lt;/a&gt; uses a subset of Python for describing build rules &lt;/p&gt; &lt;p&gt; While it's deliberately restricted to ensure termination checking and determinism, configuring Bazel is orders of magnitude more pleasant than any other build system I've used. &lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://mesonbuild.com/Syntax.html"&gt;Meson build system&lt;/a&gt;: borrows the syntax from Python&lt;/li&gt; &lt;li&gt;&lt;p&gt; &lt;a href="https://nixos.wiki/wiki/Nix_Expression_Language"&gt;Nix&lt;/a&gt;: language designed specifically for the Nix package manager &lt;/p&gt; &lt;p&gt; While a completely new language feels like an overkill, it's still nicer to work with than plain configs. &lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt; &lt;a href="https://dhall-lang.org/"&gt;Dhall&lt;/a&gt;: language designed specifically for config files &lt;/p&gt; &lt;p&gt; Dhall advertises itself as "JSON + functions + types + imports". And indeed, it looks great, and solves most of the issues I listed. &lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt; &lt;a href="https://jsonnet.org/"&gt;Jsonnet&lt;/a&gt;: JSON + variables + control flow &lt;/p&gt; &lt;p&gt; See &lt;a href="https://jsonnet.org/articles/comparisons.html"&gt;comparison&lt;/a&gt; with other configuration languages &lt;/p&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt; Downsides of such languages is that they aren't widespread yet. If you don't have bindings for your target language, you'd end up parsing JSON again. However, at least it makes writing configs pleasant. &lt;/p&gt; &lt;p&gt; But again, if your program is written in Javascript and doesn't interact with other languages, why don't you just make the config Javascript? &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div&gt; &lt;h2 id="what_if_i_have_to"&gt;&lt;a href="#what_if_i_have_to"&gt;¶&lt;/a&gt;&lt;span&gt;4&lt;/span&gt; What if you don't have a choice?&lt;/h2&gt; &lt;div&gt; &lt;p&gt; Some ways I've found to minimize the frustration while using plain configs: &lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt; write as little in config files as possible &lt;/p&gt; &lt;p&gt; This typically applies to CI pipeline configs (i.e. Gitlab/Circle/Github Actions) or Dockerfiles. &lt;/p&gt; &lt;p&gt; Often such configs are &lt;b&gt;bloated with shell commands&lt;/b&gt;, which makes it impossible to run locally without copying line by line. And yeah, there &lt;a href="https://circleci.com/docs/2.0/local-cli"&gt;are&lt;/a&gt; &lt;a href="https://github.com/nektos/act"&gt;ways&lt;/a&gt; to debug, but they have a pretty slow feedback loop. &lt;/p&gt; &lt;ul&gt; &lt;li&gt;use tools that are better suited to set up local virtual environments, like &lt;a href="https://github.com/tox-dev/tox"&gt;tox-dev/tox&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt; prefer helper shell scripts and call them from your pipeline &lt;/p&gt; &lt;p&gt; It is a bit frustrating since it introduces indirection and scatters code around. But, as an upside, you can lint (e.g. &lt;a href="https://www.shellcheck.net/"&gt;shellcheck&lt;/a&gt;) your pipeline scripts, and make it easier to run locally. &lt;/p&gt; &lt;p&gt; Sometimes you can get away if your pipeline is short, so use your own judgment. &lt;/p&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt; Let the CI only handle setting up a VM/container for you, caching the dependencies, and publishing artifacts. &lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt; generate the config instead of writing manually &lt;/p&gt; &lt;p&gt; The downside is that the generated config may diverge if edited manually. &lt;/p&gt; &lt;p&gt; You can add the warning comment that the config is autogenerated with the link to the generator, and make the config file read-only to discourage manual editing. &lt;/p&gt; &lt;p&gt; In addition, if you're running CI, you can make the consistency check a part of the pipeline itself. &lt;/p&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;div&gt; &lt;h2&gt;&lt;a href="#links"&gt;¶&lt;/a&gt;&lt;span&gt;5&lt;/span&gt; Extra links&lt;/h2&gt; &lt;div&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt; &lt;a href="https://www.arp242.net/flags-config.html"&gt;(commandline) flags are great for configuration&lt;/a&gt; &lt;/p&gt; &lt;p&gt; Overall, I agree, but there are still cases when using flags isn't feasible. &lt;/p&gt; &lt;p&gt; It's also prone to leaking secrets (keys/tokens/passwords) – both in your shell history and via &lt;samp&gt;ps&lt;/samp&gt;. &lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt; &lt;a href="https://wiki.archlinux.org/index.php/Xmonad#Configuration"&gt;Xmonad&lt;/a&gt;: config &lt;b&gt;is&lt;/b&gt; the executable &lt;/p&gt; &lt;p&gt; Interesting approach, but not always feasible, e.g. you might not have the compiler installed. &lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/magefile/mage#about"&gt;Mage&lt;/a&gt;: a tool for writing makefiles in Go&lt;/li&gt; &lt;li&gt;Dhall wiki: &lt;a href="https://github.com/dhall-lang/dhall-lang/wiki/Programmable-configuration-files"&gt;Programmable configuration files&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://news.ycombinator.com/item?id=19108787"&gt;Why are we templating YAML? (HN)&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt; &lt;b&gt;Updates&lt;/b&gt; from the comments (thanks everyone!): &lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://www.lua.org/history.html"&gt;The evolution of an extension language: a history of Lua&lt;/a&gt;: apparently Lua has started as a config language&lt;/li&gt; &lt;li&gt;&lt;p&gt; &lt;a href="https://news.ycombinator.com/item?id=20847943"&gt;Cue&lt;/a&gt;: A language for defining, generating, and validating data &lt;/p&gt; &lt;p&gt; I've &lt;b&gt;really&lt;/b&gt; struggled to find a code example on the website, so &lt;a href="https://github.com/cuelang/cue/blob/master/doc/tutorial/kubernetes/README.md"&gt;here you go&lt;/a&gt;. &lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://news.ycombinator.com/item?id=14298715"&gt;The configuration complexity clock&lt;/a&gt;: a case for hard-coding&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;div&gt; &lt;h2 id="fin"&gt;&lt;a href="#fin"&gt;¶&lt;/a&gt;&lt;span&gt;6&lt;/span&gt; --&lt;/h2&gt; &lt;div&gt; &lt;p&gt; A followup question, which I don't have an answer for: why is it that way? I'm sure Ansible/CircleCI or Github Actions are developed by talented engineers who have considered pros and cons of using YAML. Do the pros really outweigh the cons? &lt;/p&gt; &lt;p&gt; Open to all feedback, and feel free to share your config pain and how are you solving it! &lt;/p&gt; &lt;p&gt; &lt;b&gt;Updates&lt;/b&gt;: &lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;span&gt;&lt;span&gt;[2020-04-11]&lt;/span&gt;&lt;/span&gt; Added P.S. section&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;div&gt; &lt;h2 id="ps"&gt;&lt;a href="#ps"&gt;¶&lt;/a&gt;&lt;span&gt;7&lt;/span&gt; &lt;span&gt;&lt;span&gt;[2020-04-11]&lt;/span&gt;&lt;/span&gt; P.S.&lt;/h2&gt; &lt;div&gt; &lt;p&gt; Thanks everyone for the discussions and comments! &lt;/p&gt; &lt;p&gt; There were some polar opinions involved, so I'd like to clarify the most common objections here: &lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt; "Programs as a config are a security nightmare" &lt;/p&gt; &lt;p&gt; I admit that I have a programmer's mindset (as opposed to sysadmin's), and very likely underestimate the security risks. &lt;/p&gt; &lt;p&gt; But again, &lt;a href="#security"&gt;I agree&lt;/a&gt; that executable configs are &lt;b&gt;not always&lt;/b&gt; a good idea. You can still have the best of both worlds by providing a DSL for generating a plain config and consuming the plain config. &lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt; "If your config is a program, it might end up arbitrarily complex and incomprehensible" &lt;/p&gt; &lt;p&gt; Sure, but again, it largely depends on the discipline. You can also make a plain config incomprehensible and hard to modify. &lt;/p&gt; &lt;p&gt; The best compromise here is probably configuration languages like Dhall. &lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt; "What happens in 20 years, when there is no &amp;lt;insert programming language&amp;gt; around" &lt;/p&gt; &lt;p&gt; That's a good point, but languages don't disappear in an eye blink. There will be plenty of time to adapt. In addition, if your software and config are written in the same language, the software will need to be rewritten anyway, which is a bigger problem. &lt;/p&gt; &lt;p&gt; Also even plain config formats come and go. 20 years ago XML was common for configuration; how many times you've seen it lately? Does your programming language even include XML parser in the standard library? &lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt; "If your config is so complex you need a DSL, your design has gone wrong and your software sucks" &lt;/p&gt; &lt;p&gt; Frankly, I've found many of such comments as very opinionated and not constructive, but I'll try to respond. &lt;/p&gt; &lt;p&gt; Software comes in very different shapes and while having the simplest configuration possible is desirable (ideally, none!), sometimes it would change the very nature of the thing you're trying to develop. Sure, you can stop calling it 'software' and start calling a 'library' at this point, but I don't feel it changes the point of the discussion. &lt;/p&gt; &lt;p&gt; Perhaps, my constructive takeaways from this argument would be: &lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt; think how flexible your configuration might have to be, and whether you need to give up on plain configs early &lt;/p&gt; &lt;p&gt; A good example of this would be some mail filtering systems, that started simple and ended as Turing complete. &lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt; in the rapid development phase, resort to having a flexible config &lt;/p&gt; &lt;p&gt; &lt;b&gt;When/if&lt;/b&gt; your software matures, think about supporting plain configs or/and using a special configuration language. &lt;/p&gt;&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/section&gt; &lt;section id="post-discussion"&gt; &lt;p&gt;Discussion:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://news.ycombinator.com/item?id=22787332"&gt;hackernews&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://lobste.rs/s/qyhvhc/your_configs_suck_try_real_programming"&gt;lobsters&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/section&gt;&lt;/article&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://beepb00p.xyz/configs-suck.html"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sun, 5 Apr 2020 16:19:47 UT
      </pubDate>
      <guid>
        https://beepb00p.xyz/configs-suck.html
      </guid>
    </item>
    <item>
      <title>
        250bpm
      </title>
      <link>
        http://250bpm.com/blog:158
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;p&gt;&lt;a href="http://250bpm.com/index.html"&gt;←&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Now, with billion people locked down in their homes, social contact over Internet becomes an increasingly important topic. Not only it allows people to stay in touch, it also lowers the incentives to &lt;a href="https://www.theguardian.com/world/2020/apr/04/uks-covid-19-lockdown-could-crumble-as-frustration-grows-police-warn"&gt;leave one's home and meet people in person&lt;/a&gt; and thus contributes to the public health.&lt;/p&gt; &lt;p&gt;I threw an online birthday party few days ago and in this article I would like to share some of my observations about how a party over Internet differs from one in the physical world and point out some implications and possible improvements for videoconferencing software.&lt;/p&gt; &lt;p&gt;To start with, existing videoconferencing software is geared towards business meetings. And the differences between a business meeting and a party are easy to spot: At a party, there's much less structure. While at a meeting it's typically just one person that speaks and everybody else listens, at a party people tend to speak in parallel. At a party, non-verbal communication (facial expressions, gestures) is crucial. At a business meeting, not so much. At a meeting one wants to maintain self-control. At a party, one often rather wants to get rid of it. And so on and so forth.&lt;/p&gt; &lt;p&gt;So, let's move directly to my observations:&lt;/p&gt; &lt;h3 id="everyoneshouldbevisible"&gt;Everyone should be visible&lt;/h3&gt; &lt;p&gt;Unlike with Google Hangouts where the person speaking is displayed in full-screen view and everyone else as a small icon on the side, at a party a want to see everyone in parallel. Sometimes, it's someone's non-verbal accompaniment of someone else's speech that's the real fun. But even when that's not the case, I still want to follow how everyone reacts to what is being said, whether they are laughing, paying attention, not paying attention, preparing a snack, drinking, smoking or whether they have left for a moment, leaving just a lonely chair visible in the window.&lt;/p&gt; &lt;p&gt;In short, I want to see all the participants of the party, side by side, all of them in equally sized windows. Size of the window is too expensive a piece of psychological real estate to waste on such an obvious thing as "who's speaking at the moment". More about that below.&lt;/p&gt; &lt;h3 id="lookingatpeople"&gt;Looking at people&lt;/h3&gt; &lt;p&gt;Maybe the most unpleasant part of social videoconferencing is not being able to follow who's looking at whom. Everyone just stares, indiscriminately, at the camera.&lt;/p&gt; &lt;p&gt;I have no idea of how reliably the existing eye-tracking software works. After browsing the web for a minute it seems that eye tracking is used mostly for… optimizing ads??? What a waste of resources!&lt;/p&gt; &lt;p&gt;Anyway, it doesn't matter. Whether the software uses webcam to trace your gaze or whether you use mouse to explicitly point to whomever you are looking at the implications are more or less the same: First, I want the window I am looking at to get larger. Second, I want the person on the other side to know that I am looking at them - not necessarily in any obtrusive manner, I just want them to be aware of it, presumably by making my image slightly larger.&lt;/p&gt; &lt;p&gt;To give a practical example: One of the participants at the party wears an amusing mask. I point to the corresponding window which makes it larger and allows me to inspect the details of the mask. The person in question sees that I am looking at them and that, possibly, others are looking as well. They may choose to react to that.&lt;/p&gt; &lt;p&gt;Taken together, one would see large image of the person they are looking at, somewhat smaller images of people looking at them and small images of everyone else. That, I think, more of less reflects how people perceive each other in real-world social interactions.&lt;/p&gt; &lt;h3 id="eyecontact"&gt;Eye contact&lt;/h3&gt; &lt;p&gt;If I look and someone and that person looks back at me, that's a powerful social signal and it should be reflected by the software. For example, in such a case we could get a special communication channel, where not only we see each other in large windows but also the talk by other people can be muffled so that we can hear each other well. (By the way, this protocol of looking and looking back is based on "&lt;a href="https://www.verytangostore.com/cabeceo.html"&gt;cabeceo&lt;/a&gt;" as practiced when dancing tango: You can invite a person to dance with you by looking at them and they may accept by looking back or refuse by looking away.)&lt;/p&gt; &lt;p&gt;In this post I am not going to speak about larger parties but the problem there is obvious: With many people present there are going to be many parallel conversations, resulting it too much noise and not being able to hear each other properly. Clearly, some kind of fluent separation of the party into subgroups is needed. And while this seems to be a hard problem, the eye contact protocol described above can be used at least as a starting point: Cabeceo protocol allows to create groups of two people. Can it be somehow generalized for groups of three or more?&lt;/p&gt; &lt;h3 id="kissing"&gt;Kissing&lt;/h3&gt; &lt;p&gt;In many cultures, kissing is an important part of social interaction. However, it doesn't lend itself well to communication over Internet.&lt;/p&gt; &lt;p&gt;Skype allows you to send an emoticon (e.g. a symbol of a heart) to your counterpart. But that doesn't really convey that feel of intimacy that the real kiss does. After all, emoticons were invented to be a substitute for non-verbal communication in the situations where people don't see each other (SMS, email) which makes them, in the context of videoconferencing, redundant at best and embarrassing at worst.&lt;/p&gt; &lt;p&gt;Obviously, sending a kiss through video can't be solved by purely technical means. It would require some social innovation. If Eskimos can kiss by rubbing their noses, why can't we devise a special Internet kiss? But if we do, the experience can be greatly improved by the software.&lt;/p&gt; &lt;p&gt;Consider the cabeceo protocol above. What if a kiss worked like this: I look at the other person. The other person looks at me. Our windows get larger, everyone else fades into background. Surrounding noises are muffled. Then we both touch cameras with our noses.&lt;/p&gt; &lt;p&gt;It would have to be tested in practice, but it kind of looks like it could feel quite intimate.&lt;/p&gt; &lt;p&gt;In the physical world there are many more ways to send social signals.&lt;/p&gt; &lt;p&gt;Consider, for example, the seating order. If I sit next to someone it may mean that I want to speak with them, or I may want to signal that I belong to a certain subgroup or maybe it was just the only empty chair left. (Note that many social signals are weak and ambiguous. But that's a feature, not a bug!)&lt;/p&gt; &lt;p&gt;Now, I've used seating order just as an example. Not everything that exists at a physical party has to be necessarily mimicked in an online party. However, if the developers of the videoconferencing software decide that seating order is worth mimicking, then it has implications for the product design. For example, ordering of windows on the screen would have to be the same for everyone. It can't be that you can rearrange them arbitrarily. Should sitting next to someone else come with some extras? Maybe I can whisper to a person sitting besides me. Etc.&lt;/p&gt; &lt;h3 id="miscellaneous"&gt;Miscellaneous&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt;There's a natural worry that seeing only people's faces is going to prevent a lot of non-verbal communication (gestures). However, my anecdotal evidence is that people, especially as the party progresses, subconsciously tend to move away from the camera making their entire upper body visible and thus improving non-verbal communication channels.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;Partying online is not all downsides. One upside is that, being at home, people have all kind of inventory at their disposal, which, at a meatspace party, they don't. In our case we've used a &lt;a href="https://en.wikipedia.org/wiki/Plague_doctor_costume#/media/File:Medico_peste.jpg"&gt;plague mask&lt;/a&gt;, a &lt;a href="https://images-na.ssl-images-amazon.com/images/I/91uTc7G0PoL.jpg"&gt;peacock feather&lt;/a&gt;, a &lt;a href="https://www.quien.net/wp-content/uploads/politica-quien-es/Subcomandante-Marcos.jpg"&gt;bandana&lt;/a&gt;. There may be no technological implications, but I think the behavior is worth mentioning anyway.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;It's unclear whether you should see yourself among the participants of the party. On one hand, seeing yourself leads to more self-control, which is not that desirable at a party. On the other hand, people do like the feature and would probably feel awkward if it was removed. Feedback from a friend: "If I am not on the screen it would feel like I am not present at the party."&lt;/p&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h3 id="conclusion"&gt;Conclusion&lt;/h3&gt; &lt;p&gt;These are just some random thoughts that I'm giving free to anyone who fancies to implement them. However, if you do, please do let me know! It would be really interesting to see how this works in practice.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;April 5th, 2020&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;a href="https://www.reddit.com/r/250bpm"&gt;Discussion Forum&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/div&gt;&lt;a href="http://250bpm.com/blog:158"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sun, 5 Apr 2020 22:30:07 UT
      </pubDate>
      <guid>
        http://250bpm.com/blog:158
      </guid>
    </item>
    <item>
      <title>
        How to Do Research With a Professor
      </title>
      <link>
        http://www.cs.jhu.edu/~jason/advice/how-to-work-with-a-professor.html
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt; &lt;h4&gt;by Jason Eisner (2012)&lt;/h4&gt; &lt;h2&gt;Summary&lt;/h2&gt; &lt;p&gt;This is a bit of advice for lucky students who get to do research with a professor.&lt;/p&gt; &lt;p&gt;Take this opportunity seriously. Either you make it your top priority, or you don't do it at all. That's the message. Read the rest of the page if you want to know why and how.&lt;/p&gt; &lt;h2&gt;Why This Webpage?&lt;/h2&gt; &lt;p&gt;I'd find it awkward to say these things directly to a nice undergrad or master's student I was starting to work with. It would feel like talking down to them, whereas I like my research collaborators—however junior—to talk with me comfortably as equals, have fun, and come up with half the ideas.&lt;/p&gt; &lt;p&gt;Still, it's important to understand up front what the pressures are on faculty-student collaborations. So here are some things to bear in mind.&lt;/p&gt; &lt;h2&gt;How the Professor Sees It&lt;/h2&gt; &lt;blockquote id="sexchange"&gt;&lt;i&gt;[If the professor is female/male, click &lt;u&gt;here&lt;/u&gt;.]&lt;/i&gt;&lt;/blockquote&gt; &lt;p&gt;Your research advisor doesn't get much credit for working with junior students, and would find it easier and safer to work with senior students. It's just that someone gave &lt;i&gt;him/her&lt;/i&gt; a chance once: that's how he/she ended up where he/she is today. He/She'd like to pay that debt forward.&lt;/p&gt; &lt;p&gt;But should it be paid forward to &lt;i&gt;you&lt;/i&gt;? Choosing you represents a substantial commitment on your advisor's part, and a vote of confidence in you.&lt;/p&gt; &lt;h3&gt;Time Investment&lt;/h3&gt; &lt;p&gt;The hours that your advisor spends with you, one-on-one, are hours that he/she no longer has available for&lt;/p&gt; &lt;ul&gt; &lt;li&gt; retaining the semblance of a plausible life (sleeping / eating / parenting / avoiding divorce) &lt;/li&gt;&lt;li&gt; consulting at rates of hundreds of dollars per hour &lt;/li&gt;&lt;li&gt; preparing for class &lt;/li&gt;&lt;li&gt; working on research with other students (grad or undergrad) or by himself/herself &lt;/li&gt;&lt;li&gt; staying current with the latest papers and techniques in the field &lt;/li&gt;&lt;li&gt; discharging many administrative and reviewing responsibilities &lt;/li&gt;&lt;li&gt; writing grant proposals to keep his/her Ph.D. students funded &lt;/li&gt;&lt;/ul&gt; &lt;p&gt;So he/she does expect that you'll pay him/her back, by working as hard as he/she did when he/she got his/her chance.&lt;/p&gt; &lt;h3&gt;Research Agenda Investment&lt;/h3&gt; &lt;p&gt;Your advisor is not only devoting time to you, but taking a risk. You are being entrusted with part of his/her research agenda. The goal is to make new discoveries and publish them on schedule. If you drop the ball, then your advisor and others in the lab will miss important publication deadlines, or will get scooped by researchers elsewhere, or will be unable to take the next step that was depending on you.&lt;/p&gt; &lt;p&gt;So, don't start doing research with the idea that it's something "extra" that may or may not work out. This is not an advanced course that you can just drop or do poorly in. Unless your advisor agrees otherwise, you are a critical player in the mission—you have a responsibility not to let others down. Remember, someone is taking a chance on you.&lt;/p&gt; &lt;h3&gt;Opportunity Cost&lt;/h3&gt; &lt;p&gt;I heard once that your boyfriend or girlfriend will ask increasingly tough questions as your relationship ages:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;"Am I getting something out of it?" &lt;/li&gt;&lt;li&gt;"Am I getting back as much as I'm putting in?" &lt;/li&gt;&lt;li&gt;"Am I getting as much as I'm worth?" &lt;/li&gt;&lt;/ol&gt; &lt;p&gt;Your advisor may also ask these questions. At first, he/she'll be happy that he/she attracted a smart student to work on a problem that needed working on. But he/she may sour if he/she comes to feel that he/she's wasting his/her time on you, or would have been wiser to assign the project to someone else.&lt;/p&gt; &lt;h2&gt;What Do You Get Out Of It?&lt;/h2&gt; &lt;p&gt;You too are giving up time from your other activities (including classwork!) to do this. So what do you get out of it?&lt;/p&gt; &lt;p&gt;Most important, you get research experience. This is &lt;b&gt;exceptionally important&lt;/b&gt; if you are considering doing a Ph.D.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt;The Ph.D. puts you on a track to focus on research for the next 5+ years and possibly for your whole life. Are you sure you want to get married to research? Maybe, but try dating research first before you commit.&lt;/p&gt; &lt;/li&gt;&lt;li&gt;&lt;p&gt;Ph.D. programs are &lt;a href="http://www.cs.jhu.edu/~jason/advice/prospective-students.html#criteria"&gt;looking for students&lt;/a&gt; who are already proven researchers. Grades are not so strongly correlated with research success. The &lt;b&gt;most crucial&lt;/b&gt; part of your application is letters from one or more credible faculty who can attest—with lots of supporting detail—that you have the creativity, intelligence, enthusiasm, productivity, technical background, and interpersonal and intrapersonal skills to do a great Ph.D. with your future advisor.&lt;/p&gt; &lt;/li&gt;&lt;/ul&gt; &lt;p&gt;A good friend of mine in college was taken under the wing of a senior professor in a different department. She was a demanding taskmaster, and my friend ended up spending much more time working in her lab than he expected. But it changed his life. She insisted that he apply to grad school in her field, and she &lt;a href="http://www.cs.jhu.edu/~jason/advice/how-to-ask-for-a-recommendation.html"&gt;got him accepted&lt;/a&gt; to a top Ph.D. program. He became a professor and is now the chairman of a department at a highly respected school, where he enjoys doing research with his own undergraduates.&lt;/p&gt; &lt;p&gt;Even if you are not considering a Ph.D., you will learn a great deal from working closely with a professor. Often you may be working with the world's leading expert on a particular topic—that's the main criterion for tenure here. (So our tenured faculty have passed this bar at some point, and most of our untenured faculty are successfully building a case that they will do so.)&lt;/p&gt; &lt;p&gt;Students don't always realize how respected and innovative our faculty are within their own subfields, but that's why you chose to attend a highly-ranked &lt;i&gt;research&lt;/i&gt; university. Your advisor may or may not be a great classroom teacher, but he/she has shown himself/herself to be extremely good at working with graduate students to produce papers that advance the field. What you'll learn from doing that is quite different from what you'll learn in the classroom.&lt;/p&gt; &lt;a name="succeed"&gt; &lt;h2&gt;What You Can Do to Succeed&lt;/h2&gt; &lt;p&gt;Here's some basic advice targeted at &lt;i&gt;new&lt;/i&gt; research students. There are also many webpages about how to be a "good grad student," which should also be useful to undergrads doing research.&lt;/p&gt; &lt;/a&gt;&lt;a name="time"&gt; &lt;h3&gt;Time Commitment&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt;&lt;i&gt;Make plenty of room.&lt;/i&gt; In order to make research your first priority, you may need to reduce your courseload or extracurriculars. This is worth discussing with both your academic advisor and your research advisor.&lt;/p&gt; &lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;i&gt;Find out what the deadlines are.&lt;/i&gt; For example, there may be a target for submitting a paper to a particular conference. When planning for deadlines, bear in mind that everything will take twice as long as you expect—or four times as long if you've never done it before. Often a paper takes roughly a year of work for a grad student (if it includes experiments), although they may be working on other things during that year as well.&lt;/p&gt; &lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;i&gt;Be honest.&lt;/i&gt; If you suspect that you may not have time to do justice to the project after all, don't string your advisor along. Take a deep breath, apologize, and explain the situation. Then your advisor can make an informed decision about whether to suspend the project, give it to someone else, get a grad student involved, etc. This is better than a slow burn of agitation on both sides.&lt;/p&gt; &lt;/li&gt;&lt;/ul&gt; &lt;/a&gt;&lt;a name="timemanagement"&gt; &lt;h3&gt;Time Management&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt;&lt;i&gt;Prepare for meetings.&lt;/i&gt; Establish a fixed time for weekly meetings with your advisor (and perhaps with senior students). Bring results, questions, and an agenda to your weekly meeting. &lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;i&gt;Make weekly progress.&lt;/i&gt; Set goalposts, and be sure you make real progress from week to week. Use your meeting time or email each week to make sure that you agree on what the goal for next week is.&lt;/p&gt; &lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;i&gt;Take the initiative.&lt;/i&gt; Be somewhat self-directed—find readings, play around with code, do mini-experiments. But do keep your advisor posted by email. &lt;/p&gt;&lt;/li&gt;&lt;/ul&gt; &lt;/a&gt;&lt;a name="writing"&gt; &lt;h3&gt;Writing&lt;/h3&gt; Writing is a form of thinking, a form of memory, and a form of communication. You should keep well-organized notes of several kinds. It is often useful to date your entries in such files and to keep them under version control. &lt;/a&gt;&lt;ul&gt;&lt;a name="writing"&gt; &lt;/a&gt;&lt;li&gt;&lt;a name="writing"&gt;&lt;/a&gt;&lt;p&gt;&lt;a name="writing"&gt;&lt;i&gt;"&lt;/i&gt;&lt;/a&gt;&lt;i&gt;&lt;a href="http://www.cs.jhu.edu/~jason/advice/write-the-paper-first.html"&gt;Write the paper first.&lt;/a&gt;"&lt;/i&gt; The evolving paper is a way of organizing and sharing your thoughts and hammering out details. New ideas (including future plans) can go into that document, or appendices to it.&lt;/p&gt; &lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;i&gt;Experimental logbook.&lt;/i&gt; This is a file recording the questions you asked, the experiments you ran to answer them (including the command-line details needed to reproduce them perfectly), the results, and your analysis of the results.&lt;/p&gt; &lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;i&gt;Notes on your reading,&lt;/i&gt; including reading you plan to do. This should be organized by paper and/or by topic, aimed at helping you quickly recover the important points.&lt;/p&gt; &lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;i&gt;Planning.&lt;/i&gt; Keep some kind of to-do list and time planning system that helps you set and discharge goals and track your effectiveness (see the &lt;a href="http://lifehacker.com/"&gt;LifeHacker&lt;/a&gt; website for some options). &lt;/p&gt;&lt;/li&gt;&lt;/ul&gt; &lt;a name="collab"&gt; &lt;h3&gt;Working With Others&lt;/h3&gt; &lt;/a&gt;&lt;ul&gt;&lt;a name="collab"&gt; &lt;li&gt;&lt;p&gt;&lt;i&gt;Again, be honest.&lt;/i&gt; Be very clear at all times about what you do and don't understand. Don't fake it. It's okay to say you're confused or don't know something; you need to ask questions to get unconfused. Also be clear about what you have and haven't done.&lt;/p&gt; &lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;i&gt;Pick a topic of mutual interest that you can handle.&lt;/i&gt; This is a matter for careful discussion at the start of the relationship.&lt;/p&gt; &lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;i&gt;Be explicit about what you need from your advisor.&lt;/i&gt; You can take some initiative in shaping the kind of advising relationship that will work best for you. Every advisor has a typical advising style, which is some compromise between his/her advising philosophy, his/her personality, your personality, and the realities of limited time. But if you need a different kind of guidance or a different way of organizing your relationship, ask for it. Most advisors will appreciate the initiative and can adapt to some extent.&lt;/p&gt; &lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;i&gt;Know how to ask for help.&lt;/i&gt; If you feel you would benefit from closer guidance, say: "Please tell me exactly what you want me to do by next Wednesday and I will have it done." If you get stuck technically, ask your advisor to help you get unstuck! He/She can write out a more detailed plan for you, give you things to read, ask a senior grad student to work with you, point you to software libraries, etc. Asking the right person can be 100 times faster than doing it yourself.&lt;/p&gt; &lt;p&gt;Your value to the project lies in how much you get done—it doesn't matter whether you invented it all yourself. This is not homework and getting help is not cheating. Anything that is already known in the field is fair game to reuse (with citations). And people can also help you invent the new stuff, as long as you acknowledge their help appropriately (possibly with co-authorship). Getting them to help you is part of the research.&lt;/p&gt; &lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;i&gt;Get right as much as you can.&lt;/i&gt; Before you hand off a piece of code or writing to someone else -- including another student, your advisor, or a reviewer -- you ought to catch all the problems you can catch by yourself. For a problem that you intend to fix later, include a note to this effect. This allows the other person to focus their limited time on spotting the problems that were beyond your own horizon.&lt;/p&gt; &lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;i&gt;Be a team player.&lt;/i&gt; If there are other people on the project, find out what they're working on. Ask plenty of questions. Get a broader sense of the project beyond your own little corner. Help out where you can.&lt;/p&gt; &lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;i&gt;Share what you do.&lt;/i&gt; Back up your work, comment your code, log your experiments, and be ready to hand off your code and notes at any time. The project may live on after you. It's not necessary to keep private files. The best plan is to keep everything valuable in a shared version control repository that you, your advisor, and any other collaborators can browse and edit at any time. (A &lt;tt&gt;README&lt;/tt&gt; file in the repository can describe the layout and list any additional resources, e.g., the URLs of a wiki, a Google Doc, etc.) An issue tracker is also useful. Discuss with your advisor how to set up this kind of project infrastructure, e.g., on github.&lt;/p&gt; &lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;i&gt;Avoid diffusion.&lt;/i&gt; As a matter of etiquette, try not to spread your work over many different local directories, repositories, email threads, chat logs, Google documents, etc. For example, when sending email, try to continue on an existing thread where appropriate, rather than starting a new one. Your advisor is juggling more email and projects than you, so will find it helpful to keep related things together.&lt;/p&gt; &lt;/li&gt;&lt;/a&gt;&lt;li&gt;&lt;a name="collab"&gt;&lt;/a&gt;&lt;p&gt;&lt;a name="collab"&gt;&lt;i&gt;Keep track of what you've done.&lt;/i&gt; You may want to keep some notes on your contributions. You can give these to your advisor when it is time for a &lt;/a&gt;&lt;a href="http://www.cs.jhu.edu/~jason/advice/how-to-ask-for-a-recommendation.html"&gt;letter of recommendation&lt;/a&gt;. &lt;/p&gt;&lt;/li&gt;&lt;/ul&gt; &lt;a name="looking"&gt; &lt;h2&gt;But I Don't Have a Project Yet!&lt;/h2&gt; &lt;p&gt;Now that you've read this page, you understand more about how to ask a professor about research opportunities.&lt;/p&gt; &lt;p&gt;&lt;i&gt;When to ask (not too early).&lt;/i&gt; Usually you'll need to have taken at least a 300- or 400-level course in the appropriate research area. If you don't know basic concepts and terms, then it is hard to even discuss the research problem. Don't expect the professor to teach you the basics in his/her office: that's what the course is for.&lt;/p&gt; &lt;p&gt;&lt;i&gt;Who to ask.&lt;/i&gt; If you are doing extremely well in an upper-level course, then talk to the professor about whether he/she knows of any research opportunities in that area. It helps if the professor already has a high opinion of you from good interactions in class and through office hours. (You did go to office hours just to chat about ideas, right?) Even if he/she doesn't have anything for you, he/she may be able to hook you up with a colleague.&lt;/p&gt; &lt;p&gt;&lt;i&gt;How to ask.&lt;/i&gt; Advice from Marie desJardins: "Ask the professor about his/her research. Professors &lt;i&gt;love&lt;/i&gt; to talk about their research. But don't just sit there and nod. Listen carefully to what he/she's saying, think about it, and respond." He/She is trying to get a conversation going to assess where you can contribute meaningfully.&lt;/p&gt; &lt;p&gt;To help the professor decide where to start the conversation, be sure to show him/her your resume and your transcript. Also describe the kinds of problems you excel at. Special skills or a remarkable track record may give you a foot in the door. For example, although my main research area is NLP, occasionally I do have problems that don't require much NLP knowledge. Rather, I'm looking for someone who can develop a particular theorem or algorithm, or build a solid piece of system software, or design a beautiful user interface. So in this case, I might consider working with a great student who hasn't taken my NLP course.&lt;/p&gt; &lt;p&gt;&lt;i&gt;How to ask early.&lt;/i&gt; If you're not ready to start research yet, it's certainly still okay to ask a professor (or a senior grad student) how you could &lt;i&gt;prepare&lt;/i&gt; to do research in his/her area. This might involve taking courses or MOOCs, reading a textbook or papers, or building certain mathematical or programming skills.&lt;/p&gt; &lt;p&gt;&lt;i&gt;When to ask (not too late).&lt;/i&gt; Timing is important. Research may not fit neatly into a semester. So approach the professor at least a year before you graduate. This gives you a couple of semesters plus summer and intersession. Hopefully, that's enough time for the professor to find an appropriate role for you and for you to get up to speed, define the problem and approach, do some initial work, refine the ideas, do some more work, fail, think hard, try again, succeed, write and submit a conference paper, revise the paper after acceptance, and present the paper at the conference. It's very common for a research project to take over a year even for a grad student who is doing research full-time!&lt;/p&gt; &lt;/a&gt;&lt;p&gt;&lt;a name="looking"&gt;I'll give the final word to Jorge Chan of &lt;/a&gt;&lt;a href="http://www.phdcomics.com/"&gt;PhD Comics&lt;/a&gt;:&lt;br&gt; &lt;/p&gt;&lt;center&gt;&lt;a href="http://www.phdcomics.com/comics/archive.php?comicid=1093"&gt;&lt;img src="http://www.phdcomics.com/comics/archive/phd110508s.gif"&gt;&lt;/a&gt;&lt;/center&gt; &lt;hr&gt; This page online: &lt;code&gt;http://cs.jhu.edu/~jason/advice/how-to-work-with-a-professor.html&lt;/code&gt; &lt;/div&gt;&lt;a href="http://www.cs.jhu.edu/~jason/advice/how-to-work-with-a-professor.html"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sun, 5 Apr 2020 22:30:09 UT
      </pubDate>
      <guid>
        http://www.cs.jhu.edu/~jason/advice/how-to-work-with-a-professor.html
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://towardsdatascience.com/feature-engineering-for-machine-learning-3a5e293a5114
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;&lt;p&gt;&lt;h2 id="602a"&gt;Fundamental Techniques of Feature Engineering for Machine Learning&lt;/h2&gt;&lt;/p&gt;&lt;div&gt;&lt;h2 id="d138"&gt;All required methods for comprehensive data preprocessing with Pandas examples.&lt;/h2&gt;&lt;div&gt;&lt;p&gt;&lt;a rel="noopener" href="https://medium.com/@emrerencberoglu?source=post_page-----3a5e293a5114--------------------------------"&gt;&lt;img height="28" width="28" src="https://miro.medium.com/fit/c/56/56/1*PFdJBI5MLv6iMemP3QtVlA.jpeg" alt="Emre Rençberoğlu"&gt;&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;figure&gt;&lt;div&gt;&lt;p&gt;&lt;img height="480" width="640" src="https://miro.medium.com/max/60/1*S2dke2xfpZYUCImIZziVsA.png?q=20" alt="Image for post"&gt;&lt;/p&gt;&lt;/div&gt;&lt;/figure&gt;&lt;h2 id="bc90"&gt;Introduction&lt;/h2&gt;&lt;p id="9728"&gt;What is a feature and why we need the engineering of it? Basically, all machine learning algorithms use some input data to create outputs. This input data comprise features, which are usually in the form of structured columns. Algorithms require features with some specific characteristic to work properly. Here, the need for &lt;strong&gt;feature engineering&lt;/strong&gt; arises. I think feature engineering efforts mainly have two goals:&lt;/p&gt;&lt;ul&gt;&lt;li id="2692"&gt;Preparing the proper input dataset, compatible with the machine learning algorithm requirements.&lt;/li&gt;&lt;li id="6d0f"&gt;Improving the performance of machine learning models.&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;&lt;p id="8a7b"&gt;The features you use influence more than everything else the result. No algorithm alone, to my knowledge, can supplement the information gain given by correct &lt;strong&gt;feature engineering&lt;/strong&gt;.&lt;/p&gt;&lt;p id="efb3"&gt;— Luca Massaron&lt;/p&gt;&lt;/blockquote&gt;&lt;p id="569c"&gt;According to a survey in Forbes, data scientists spend &lt;strong&gt;80%&lt;/strong&gt; of their time on &lt;strong&gt;data preparation:&lt;/strong&gt;&lt;/p&gt;&lt;figure&gt;&lt;div tabindex="0" role="button"&gt;&lt;p&gt;&lt;img height="409" width="960" src="https://miro.medium.com/max/60/0*-dn9U8gMVWjDahQV.jpg?q=20" alt="Image for post"&gt;&lt;/p&gt;&lt;/div&gt;&lt;figcaption&gt;&lt;a rel="noopener nofollow" href="https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/#1594bda36f63"&gt;Source: https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p id="8fb4"&gt;This metric is very &lt;span id="rmm"&gt;i&lt;/span&gt;mpressive to show the importance of feature engineering in data science. Thus, I decided to write this article, which summarizes the main techniques of feature engineering with their short descriptions. I also added some basic python scripts for every technique. You need to import &lt;strong&gt;Pandas&lt;/strong&gt; and &lt;strong&gt;Numpy&lt;/strong&gt; library to run them.&lt;/p&gt;&lt;pre&gt;&lt;span id="308c"&gt;import pandas as pd&lt;br&gt;import numpy as np&lt;/span&gt;&lt;/pre&gt;&lt;p id="bc9a"&gt;Some techniques above might work better with some algorithms or datasets, while some of them might be beneficial in all cases. This article does not aim to go so much deep in this aspect. Tough, it is possible to write an article for every method above, I tried to keep the explanations brief and informative. I think the best way to achieve expertise in feature engineering is practicing different techniques on various datasets and observing their effect on model performances.&lt;/p&gt;&lt;h2 id="d14e"&gt;List of Techniques&lt;/h2&gt;&lt;ul&gt;&lt;li id="7e02"&gt;&lt;a rel="noopener" href="https://medium.com/p/3a5e293a5114#3abe"&gt;1.Imputation&lt;/a&gt;&lt;/li&gt;&lt;li id="9d33"&gt;&lt;a rel="noopener" href="https://medium.com/p/3a5e293a5114#1c08"&gt;2.Handling Outliers&lt;/a&gt;&lt;/li&gt;&lt;li id="549d"&gt;&lt;a rel="noopener" href="https://medium.com/p/3a5e293a5114#7559"&gt;3.Binning&lt;/a&gt;&lt;/li&gt;&lt;li id="a3e8"&gt;&lt;a rel="noopener" href="https://medium.com/p/3a5e293a5114#199b"&gt;4.Log Transform&lt;/a&gt;&lt;/li&gt;&lt;li id="2911"&gt;&lt;a rel="noopener" href="https://medium.com/p/3a5e293a5114#7c18"&gt;5.One-Hot Encoding&lt;/a&gt;&lt;/li&gt;&lt;li id="c363"&gt;&lt;a rel="noopener" href="https://medium.com/p/3a5e293a5114#ad97"&gt;6.Grouping Operations&lt;/a&gt;&lt;/li&gt;&lt;li id="60d7"&gt;&lt;a rel="noopener" href="https://medium.com/p/3a5e293a5114#3149"&gt;7.Feature Split&lt;/a&gt;&lt;/li&gt;&lt;li id="1732"&gt;&lt;a rel="noopener" href="https://medium.com/p/3a5e293a5114#83e6"&gt;8.Scaling&lt;/a&gt;&lt;/li&gt;&lt;li id="7b89"&gt;&lt;a rel="noopener" href="https://medium.com/p/3a5e293a5114#8068"&gt;9.Extracting Date&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 id="3abe"&gt;1.Imputation&lt;/h2&gt;&lt;figure&gt;&lt;div&gt;&lt;p&gt;&lt;img height="272" width="240" src="https://miro.medium.com/max/52/0*t9IrGI06obl18hXP.jpg?q=20" alt="Image for post"&gt;&lt;/p&gt;&lt;/div&gt;&lt;/figure&gt;&lt;p id="c200"&gt;Missing values are one of the most common problems you can encounter when you try to prepare your data for machine learning. The reason for the missing values might be human errors, interruptions in the data flow, privacy concerns, and so on. Whatever is the reason, missing values affect the performance of the machine learning models.&lt;/p&gt;&lt;p id="7fba"&gt;Some machine learning platforms automatically drop the rows which include missing values in the model training phase and it decreases the model performance because of the reduced training size. On the other hand, most of the algorithms do not accept datasets with missing values and gives an error.&lt;/p&gt;&lt;p id="5772"&gt;The most simple solution to the missing values is to drop the rows or the entire column. There is not an optimum threshold for dropping but you can use &lt;strong&gt;70%&lt;/strong&gt; as an example value and try to drop the rows and columns which have missing values with higher than this threshold.&lt;/p&gt;&lt;pre&gt;&lt;span id="d893"&gt;threshold = 0.7&lt;/span&gt;&lt;span id="3f23"&gt;&lt;strong&gt;#Dropping columns with missing value rate higher than threshold&lt;/strong&gt;&lt;br&gt;data = data[data.columns[data.isnull().mean() &amp;lt; threshold]]&lt;p&gt;&lt;strong&gt;#Dropping rows with missing value rate higher than threshold&lt;/strong&gt;&lt;br&gt;data = data.loc[data.isnull().mean(axis=1) &amp;lt; threshold]&lt;/p&gt;&lt;/span&gt;&lt;/pre&gt;&lt;h2 id="b037"&gt;Numerical Imputation&lt;/h2&gt;&lt;p id="10b4"&gt;Imputation is a more preferable option rather than dropping because it preserves the data size. However, there is an important selection of what you impute to the missing values. I suggest beginning with considering a possible default value of missing values in the column. For example, if you have a column that only has &lt;strong&gt;1&lt;/strong&gt; and &lt;strong&gt;NA&lt;/strong&gt;, then it is likely that the &lt;strong&gt;NA&lt;/strong&gt; rows correspond to &lt;strong&gt;0&lt;/strong&gt;. For another example, if you have a column that shows the &lt;strong&gt;“customer visit count in last month”&lt;/strong&gt;, the missing values might be replaced with &lt;strong&gt;0&lt;/strong&gt; as long as you think it is a sensible solution.&lt;/p&gt;&lt;p id="a029"&gt;Another reason for the missing values is joining tables with different sizes and in this case, imputing &lt;strong&gt;0&lt;/strong&gt; might be reasonable as well.&lt;/p&gt;&lt;p id="a304"&gt;Except for the case of having a default value for missing values, I think the best imputation way is to use the &lt;strong&gt;medians&lt;/strong&gt; of the columns. As the averages of the columns are sensitive to the outlier values, while medians are more solid in this respect.&lt;/p&gt;&lt;pre&gt;&lt;span id="d787"&gt;&lt;strong&gt;#Filling all missing values with 0&lt;/strong&gt;&lt;br&gt;data = data.fillna(0)&lt;/span&gt;&lt;span id="e3fe"&gt;&lt;strong&gt;#Filling missing values with medians of the columns&lt;/strong&gt;&lt;br&gt;data = data.fillna(data.median())&lt;/span&gt;&lt;/pre&gt;&lt;h2 id="df75"&gt;Categorical Imputation&lt;/h2&gt;&lt;p id="bfcd"&gt;Replacing the missing values with the &lt;strong&gt;maximum occurred value&lt;/strong&gt; in a column is a good option for handling categorical columns. But if you think the values in the column are distributed uniformly and there is not a dominant value, imputing a category like “&lt;strong&gt;Other&lt;/strong&gt;” might be more sensible, because in such a case, your imputation is likely to converge a random selection.&lt;/p&gt;&lt;pre&gt;&lt;span id="b9ba"&gt;&lt;strong&gt;#Max fill function for categorical columns&lt;/strong&gt;&lt;br&gt;data['column_name'].fillna(data['column_name'].value_counts()&lt;br&gt;.idxmax(), inplace=True)&lt;/span&gt;&lt;/pre&gt;&lt;h2 id="1c08"&gt;2.Handling Outliers&lt;/h2&gt;&lt;p id="d192"&gt;Before mentioning how outliers can be handled, I want to state that the best way to detect the outliers is to demonstrate the data visually. All other statistical methodologies are open to making mistakes, whereas visualizing the outliers gives a chance to take a decision with high precision. Anyway, I am planning to focus visualization deeply in another article and let’s continue with statistical methodologies.&lt;/p&gt;&lt;p id="d4f5"&gt;Statistical methodologies are less precise as I mentioned, but on the other hand, they have a superiority, they are fast. Here I will list two different ways of handling outliers. These will detect them using &lt;strong&gt;standard deviation&lt;/strong&gt;, and &lt;strong&gt;percentiles&lt;/strong&gt;.&lt;/p&gt;&lt;h2 id="3dfa"&gt;Outlier Detection with Standard Deviation&lt;/h2&gt;&lt;p id="a07d"&gt;If a value has a distance to the average higher than &lt;strong&gt;&lt;em&gt;x * standard deviation&lt;/em&gt;, &lt;/strong&gt;it can be assumed as an outlier. Then what &lt;strong&gt;x &lt;/strong&gt;should be?&lt;/p&gt;&lt;p id="1962"&gt;There is no trivial solution for x, but usually, a value between 2 and 4 seems practical.&lt;/p&gt;&lt;pre&gt;&lt;span id="3baa"&gt;&lt;strong&gt;#Dropping the outlier rows with standard deviation&lt;/strong&gt;&lt;br&gt;factor = 3&lt;br&gt;upper_lim = data['column'].mean () + data['column'].std () * factor&lt;br&gt;lower_lim = data['column'].mean () - data['column'].std () * factor&lt;p&gt;data = data[(data['column'] &amp;lt; upper_lim) &amp;amp; (data['column'] &amp;gt; lower_lim)]&lt;/p&gt;&lt;/span&gt;&lt;/pre&gt;&lt;p id="eea5"&gt;In addition, &lt;strong&gt;z-score&lt;/strong&gt; can be used instead of the formula above. &lt;strong&gt;Z-score&lt;/strong&gt; (or standard score) standardizes the distance between a value and the mean using the standard deviation.&lt;/p&gt;&lt;h2 id="1fab"&gt;Outlier Detection with Percentiles&lt;/h2&gt;&lt;p id="00f8"&gt;Another mathematical method to detect outliers is to use percentiles. You can assume a certain percent of the value from the top or the bottom as an outlier. The key point is here to set the percentage value once again, and this depends on the distribution of your data as mentioned earlier.&lt;/p&gt;&lt;p id="d4a8"&gt;Additionally, a common mistake is using the percentiles according to the range of the data. In other words, if your data ranges from &lt;strong&gt;0&lt;/strong&gt; to &lt;strong&gt;100&lt;/strong&gt;, your top &lt;strong&gt;5%&lt;/strong&gt; is not the values between &lt;strong&gt;96&lt;/strong&gt; and &lt;strong&gt;100&lt;/strong&gt;. Top &lt;strong&gt;5%&lt;/strong&gt; means here the values that are out of the &lt;strong&gt;95th&lt;/strong&gt; percentile of data.&lt;/p&gt;&lt;pre&gt;&lt;span id="2d33"&gt;&lt;strong&gt;#Dropping the outlier rows with Percentiles&lt;/strong&gt;&lt;br&gt;upper_lim = data['column'].quantile(.95)&lt;br&gt;lower_lim = data['column'].quantile(.05)&lt;p&gt;data = data[(data['column'] &amp;lt; upper_lim) &amp;amp; (data['column'] &amp;gt; lower_lim)]&lt;/p&gt;&lt;/span&gt;&lt;/pre&gt;&lt;h2 id="dc3a"&gt;An Outlier Dilemma: Drop or Cap&lt;/h2&gt;&lt;p id="cd44"&gt;Another option for handling outliers is to &lt;strong&gt;cap&lt;/strong&gt; them instead of dropping. So you can keep your data size and at the end of the day, it might be better for the final model performance.&lt;/p&gt;&lt;p id="d179"&gt;On the other hand, capping can affect the distribution of the data, thus it better not to exaggerate it.&lt;/p&gt;&lt;pre&gt;&lt;span id="36ca"&gt;&lt;strong&gt;#Capping the outlier rows with Percentiles&lt;/strong&gt;&lt;br&gt;upper_lim = data['column'].quantile(.95)&lt;br&gt;lower_lim = data['column'].quantile(.05)&lt;/span&gt;&lt;span id="aadd"&gt;data.loc[(df[column] &amp;gt; upper_lim),column] = upper_lim&lt;br&gt;data.loc[(df[column] &amp;lt; lower_lim),column] = lower_lim&lt;/span&gt;&lt;/pre&gt;&lt;h2 id="7559"&gt;3.Binning&lt;/h2&gt;&lt;figure&gt;&lt;div tabindex="0" role="button"&gt;&lt;p&gt;&lt;img height="281" width="981" src="https://miro.medium.com/max/60/0*XWta_U67Nv9udfY-.png?q=20" alt="Image for post"&gt;&lt;/p&gt;&lt;/div&gt;&lt;figcaption&gt;Binning illustration of numerical data&lt;/figcaption&gt;&lt;/figure&gt;&lt;p id="32cf"&gt;Binning can be applied on both categorical and numerical data:&lt;/p&gt;&lt;pre&gt;&lt;span id="f69f"&gt;&lt;strong&gt;#Numerical Binning Example&lt;/strong&gt;&lt;/span&gt;&lt;span id="df2b"&gt;&lt;strong&gt;Value Bin&lt;/strong&gt; &lt;br&gt;0-30 -&amp;gt; Low &lt;br&gt;31-70 -&amp;gt; Mid &lt;br&gt;71-100 -&amp;gt; High&lt;/span&gt;&lt;span id="6017"&gt;&lt;strong&gt;#Categorical Binning Example&lt;/strong&gt;&lt;/span&gt;&lt;span id="43af"&gt;&lt;strong&gt;Value Bin&lt;/strong&gt; &lt;br&gt;Spain -&amp;gt; Europe &lt;br&gt;Italy -&amp;gt; Europe &lt;br&gt;Chile -&amp;gt; South America&lt;br&gt;Brazil -&amp;gt; South America&lt;/span&gt;&lt;/pre&gt;&lt;p id="acc1"&gt;The main motivation of binning is to make the model more &lt;strong&gt;robust&lt;/strong&gt; and prevent &lt;strong&gt;overfitting&lt;/strong&gt;, however, it has a cost to the performance. Every time you bin something, you sacrifice information and make your data more regularized. (Please see &lt;a href="https://towardsdatascience.com/regularization-in-machine-learning-76441ddcf99a" rel="noopener"&gt;regularization in machine learning&lt;/a&gt;)&lt;/p&gt;&lt;p id="fe79"&gt;The trade-off between &lt;strong&gt;performance&lt;/strong&gt; and &lt;strong&gt;overfitting&lt;/strong&gt; is the key point of the binning process. In my opinion, for numerical columns, except for some obvious overfitting cases, binning might be redundant for some kind of algorithms, due to its effect on model performance.&lt;/p&gt;&lt;p id="f741"&gt;However, for categorical columns, the labels with low frequencies probably affect the robustness of statistical models negatively. Thus, assigning a general category to these less frequent values helps to keep the robustness of the model. For example, if your data size is &lt;strong&gt;100,000 &lt;/strong&gt;rows, it might be a good option to unite the labels with a count less than &lt;strong&gt;100&lt;/strong&gt; to a new category like &lt;strong&gt;“Other”&lt;/strong&gt;.&lt;/p&gt;&lt;pre&gt;&lt;span id="3803"&gt;&lt;strong&gt;#Numerical Binning Example&lt;/strong&gt;&lt;/span&gt;&lt;span id="b953"&gt;data['bin'] = pd.cut(data['value'], bins=[0,30,70,100], labels=["Low", "Mid", "High"])&lt;/span&gt;&lt;span id="36b2"&gt;&lt;strong&gt; value bin&lt;/strong&gt;&lt;br&gt;0 2 Low&lt;br&gt;1 45 Mid&lt;br&gt;2 7 Low&lt;br&gt;3 85 High&lt;br&gt;4 28 Low&lt;/span&gt;&lt;span id="7161"&gt;&lt;strong&gt;#Categorical Binning Example&lt;/strong&gt;&lt;/span&gt;&lt;span id="b7c7"&gt; &lt;strong&gt;Country&lt;/strong&gt;&lt;br&gt;0 Spain&lt;br&gt;1 Chile&lt;br&gt;2 Australia&lt;br&gt;3 Italy&lt;br&gt;4 Brazil&lt;/span&gt;&lt;span id="9a8f"&gt;conditions = [&lt;br&gt; data['Country'].str.contains('Spain'),&lt;br&gt; data['Country'].str.contains('Italy'),&lt;br&gt; data['Country'].str.contains('Chile'),&lt;br&gt; data['Country'].str.contains('Brazil')]&lt;p&gt;choices = ['Europe', 'Europe', 'South America', 'South America']&lt;/p&gt;&lt;p&gt;data['Continent'] = np.select(conditions, choices, default='Other')&lt;/p&gt;&lt;/span&gt;&lt;span id="24b9"&gt; &lt;strong&gt;Country Continent&lt;/strong&gt;&lt;br&gt;0 Spain Europe&lt;br&gt;1 Chile South America&lt;br&gt;2 Australia Other&lt;br&gt;3 Italy Europe&lt;br&gt;4 Brazil South America&lt;/span&gt;&lt;/pre&gt;&lt;h2 id="199b"&gt;4.Log Transform&lt;/h2&gt;&lt;p id="9e23"&gt;Logarithm transformation (or log transform) is one of the most commonly used mathematical transformations in feature engineering. What are the benefits of log transform:&lt;/p&gt;&lt;ul&gt;&lt;li id="ae84"&gt;It helps to handle skewed data and after transformation, the distribution becomes more approximate to normal.&lt;/li&gt;&lt;li id="be9e"&gt;In most of the cases the magnitude order of the data changes within the range of the data. For instance, the difference between ages &lt;strong&gt;15&lt;/strong&gt; and &lt;strong&gt;20&lt;/strong&gt; is not equal to the ages &lt;strong&gt;65&lt;/strong&gt; and &lt;strong&gt;70&lt;/strong&gt;. In terms of years, yes, they are identical, but for all other aspects, &lt;strong&gt;5&lt;/strong&gt; years of difference in young ages mean a higher magnitude difference. This type of data comes from a multiplicative process and log transform normalizes the magnitude differences like that.&lt;/li&gt;&lt;li id="161c"&gt;It also decreases the effect of the outliers, due to the normalization of magnitude differences and the model become more robust.&lt;/li&gt;&lt;/ul&gt;&lt;p id="7a08"&gt;&lt;strong&gt;A critical note:&lt;/strong&gt; The data you apply log transform must have only positive values, otherwise you receive an error. Also, you can add &lt;strong&gt;1&lt;/strong&gt; to your data before transform it. Thus, you ensure the output of the transformation to be positive.&lt;/p&gt;&lt;blockquote&gt;&lt;p id="8869"&gt;&lt;strong&gt;Log(x+1)&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;pre&gt;&lt;span id="3667"&gt;&lt;strong&gt;#Log Transform Example&lt;/strong&gt;&lt;br&gt;data = pd.DataFrame({'value':[2,45, -23, 85, 28, 2, 35, -12]})&lt;/span&gt;&lt;span id="4904"&gt;data['log+1'] = (data['value']+1).transform(np.log)&lt;/span&gt;&lt;span id="d74c"&gt;&lt;strong&gt;#Negative Values Handling&lt;br&gt;#Note that the values are different&lt;br&gt;&lt;/strong&gt;data['log'] = (data['value']-data['value'].min()+1) .transform(np.log)&lt;/span&gt;&lt;span id="5e29"&gt; &lt;strong&gt;value log(x+1) log(x-min(x)+1)&lt;/strong&gt;&lt;br&gt;0 2 1.09861 3.25810&lt;br&gt;1 45 3.82864 4.23411&lt;br&gt;2 -23 nan 0.00000&lt;br&gt;3 85 4.45435 4.69135&lt;br&gt;4 28 3.36730 3.95124&lt;br&gt;5 2 1.09861 3.25810&lt;br&gt;6 35 3.58352 4.07754&lt;br&gt;7 -12 nan 2.48491&lt;/span&gt;&lt;/pre&gt;&lt;h2 id="7c18"&gt;5.&lt;strong&gt;One-hot encoding&lt;/strong&gt;&lt;/h2&gt;&lt;p id="efcb"&gt;&lt;strong&gt;One-hot encoding&lt;/strong&gt; is one of the most common encoding methods in machine learning. This method spreads the values in a column to multiple flag columns and assigns &lt;strong&gt;0&lt;/strong&gt; or &lt;strong&gt;1&lt;/strong&gt; to them. These binary values express the relationship between grouped and encoded column.&lt;/p&gt;&lt;p id="084b"&gt;This method changes your categorical data, which is challenging to understand for algorithms, to a numerical format and enables you to group your categorical data without losing any information. (For details please see the last part of &lt;strong&gt;Categorical Column Grouping&lt;/strong&gt;)&lt;/p&gt;&lt;figure&gt;&lt;div tabindex="0" role="button"&gt;&lt;p&gt;&lt;img height="310" width="1064" src="https://miro.medium.com/max/60/1*ZX99GOZ6-9_yJg6rZchTEA.png?q=20" alt="Image for post"&gt;&lt;/p&gt;&lt;/div&gt;&lt;figcaption&gt;One hot encoding example on City column&lt;/figcaption&gt;&lt;/figure&gt;&lt;p id="0a31"&gt;&lt;strong&gt;Why One-Hot?: &lt;/strong&gt;If you have &lt;strong&gt;N&lt;/strong&gt; distinct values in the column, it is enough to map them to&lt;strong&gt; N-1&lt;/strong&gt; binary columns, because the missing value can be deducted from other columns. If all the columns in our hand are equal to &lt;strong&gt;0&lt;/strong&gt;, the missing value must be equal to &lt;strong&gt;1&lt;/strong&gt;. This is the reason why it is called as &lt;strong&gt;one-hot encoding&lt;/strong&gt;. However, I will give an example using the &lt;strong&gt;get_dummies&lt;/strong&gt; function of Pandas. This function maps all values in a column to multiple columns.&lt;/p&gt;&lt;pre&gt;&lt;span id="14ff"&gt;encoded_columns = pd.get_dummies(data['column'])&lt;br&gt;data = data.join(encoded_columns).drop('column', axis=1)&lt;/span&gt;&lt;/pre&gt;&lt;h2 id="ad97"&gt;6.Grouping Operations&lt;/h2&gt;&lt;p id="f94c"&gt;In most machine learning algorithms, every instance is represented by a row in the training dataset, where every column show a different feature of the instance. This kind of data called &lt;strong&gt;“Tidy”&lt;/strong&gt;.&lt;/p&gt;&lt;blockquote&gt;&lt;p id="9b5b"&gt;Tidy datasets are easy to manipulate, model and visualise, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table.&lt;/p&gt;&lt;p id="bf17"&gt;— Hadley Wickham&lt;/p&gt;&lt;/blockquote&gt;&lt;p id="fae7"&gt;Datasets such as transactions rarely fit the definition of tidy data above, because of the multiple rows of an instance. In such a case, we group the data by the instances and then every instance is represented by only one row.&lt;/p&gt;&lt;p id="46b4"&gt;The key point of group by operations is to decide the aggregation functions of the features. For numerical features, average and sum functions are usually convenient options, whereas for categorical features it more complicated.&lt;/p&gt;&lt;h2 id="baa9"&gt;Categorical Column Grouping&lt;/h2&gt;&lt;p id="5a30"&gt;I suggest three different ways for aggregating categorical columns:&lt;/p&gt;&lt;ul&gt;&lt;li id="e1a5"&gt;The first option is to select the label with the &lt;strong&gt;highest frequency&lt;/strong&gt;. In other words, this is the &lt;strong&gt;max&lt;/strong&gt; operation for categorical columns, but ordinary max functions generally do not return this value, you need to use a lambda function for this purpose.&lt;/li&gt;&lt;/ul&gt;&lt;pre&gt;&lt;span id="a794"&gt;data.groupby('id').agg(lambda x: x.value_counts().index[0])&lt;/span&gt;&lt;/pre&gt;&lt;ul&gt;&lt;li id="0fee"&gt;Second option is to make a &lt;strong&gt;pivot table&lt;/strong&gt;. This approach resembles the encoding method in the preceding step with a difference. Instead of binary notation, it can be defined as aggregated functions for the values between grouped and encoded columns. This would be a good option if you aim to go beyond binary flag columns and merge multiple features into aggregated features, which are more informative.&lt;/li&gt;&lt;/ul&gt;&lt;figure&gt;&lt;div tabindex="0" role="button"&gt;&lt;p&gt;&lt;img height="288" width="1070" src="https://miro.medium.com/max/60/1*VWBbZRkTrHJQrQfWlPQWUg.png?q=20" alt="Image for post"&gt;&lt;/p&gt;&lt;/div&gt;&lt;figcaption&gt;Pivot table example: Sum of Visit Days grouped by Users&lt;/figcaption&gt;&lt;/figure&gt;&lt;pre&gt;&lt;span id="62d0"&gt;&lt;strong&gt;#Pivot table Pandas Example&lt;/strong&gt;&lt;/span&gt;&lt;span id="1eac"&gt;data.pivot_table(index='column_to_group', columns='column_to_encode', values='aggregation_column', aggfunc=np.sum, fill_value = 0)&lt;/span&gt;&lt;/pre&gt;&lt;ul&gt;&lt;li id="5007"&gt;Last categorical grouping option is to apply a &lt;strong&gt;group by&lt;/strong&gt; function after applying &lt;strong&gt;one-hot encoding&lt;/strong&gt;. This method preserves all the data -in the first option you lose some-, and in addition, you transform the encoded column from categorical to numerical in the meantime. You can check the next section for the explanation of &lt;strong&gt;numerical column grouping&lt;/strong&gt;.&lt;/li&gt;&lt;/ul&gt;&lt;h2 id="d8f4"&gt;Numerical Column Grouping&lt;/h2&gt;&lt;p id="af29"&gt;Numerical columns are grouped using &lt;strong&gt;sum&lt;/strong&gt; and &lt;strong&gt;mean&lt;/strong&gt; functions in most of the cases. Both can be preferable according to the meaning of the feature. For example, if you want to obtain &lt;strong&gt;ratio&lt;/strong&gt; columns, you can use the average of binary columns. In the same example, sum function can be used to obtain the total count either.&lt;/p&gt;&lt;pre&gt;&lt;span id="e429"&gt;#sum_cols: List of columns to sum&lt;br&gt;#mean_cols: List of columns to average&lt;/span&gt;&lt;span id="0458"&gt;grouped = data.groupby('column_to_group')&lt;p&gt;sums = grouped[sum_cols].sum().add_suffix('_sum')&lt;br&gt;avgs = grouped[mean_cols].mean().add_suffix('_avg')&lt;/p&gt;&lt;p&gt;new_df = pd.concat([sums, avgs], axis=1)&lt;/p&gt;&lt;/span&gt;&lt;/pre&gt;&lt;h2 id="3149"&gt;7.Feature Split&lt;/h2&gt;&lt;figure&gt;&lt;div tabindex="0" role="button"&gt;&lt;p&gt;&lt;img height="3456" width="5184" src="https://miro.medium.com/max/60/0*ypQVbxT8SYOQzh5w?q=20" alt="Image for post"&gt;&lt;/p&gt;&lt;/div&gt;&lt;figcaption&gt;Photo by &lt;a rel="noopener nofollow" href="https://unsplash.com/@jaxonlott?utm_source=medium&amp;amp;utm_medium=referral"&gt;Jaxon Lott&lt;/a&gt; on &lt;a rel="noopener nofollow" href="https://unsplash.com/?utm_source=medium&amp;amp;utm_medium=referral"&gt;Unsplash&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p id="2f68"&gt;Splitting features is a good way to make them useful in terms of machine learning. Most of the time the dataset contains string columns that violates &lt;a rel="noopener nofollow" href="http://vita.had.co.nz/papers/tidy-data.html"&gt;tidy data&lt;/a&gt; principles. By extracting the utilizable parts of a column into new features:&lt;/p&gt;&lt;ul&gt;&lt;li id="ff53"&gt;We enable machine learning algorithms to comprehend them.&lt;/li&gt;&lt;li id="8667"&gt;Make possible to bin and group them.&lt;/li&gt;&lt;li id="7730"&gt;Improve model performance by uncovering potential information.&lt;/li&gt;&lt;/ul&gt;&lt;p id="b9fc"&gt;&lt;strong&gt;Split&lt;/strong&gt; function is a good option, however, there is no one way of splitting features. It depends on the characteristics of the column, how to split it. Let’s introduce it with two examples. First, a simple split function for an ordinary name column:&lt;/p&gt;&lt;pre&gt;&lt;span id="789c"&gt;&lt;strong&gt;data.name&lt;/strong&gt;&lt;br&gt;0 Luther N. Gonzalez&lt;br&gt;1 Charles M. Young&lt;br&gt;2 Terry Lawson&lt;br&gt;3 Kristen White&lt;br&gt;4 Thomas Logsdon&lt;/span&gt;&lt;span id="788c"&gt;#Extracting first names&lt;strong&gt;&lt;br&gt;data.name.str.split(" ").map(lambda x: x[0])&lt;br&gt;&lt;/strong&gt;0 Luther&lt;br&gt;1 Charles&lt;br&gt;2 Terry&lt;br&gt;3 Kristen&lt;br&gt;4 Thomas&lt;/span&gt;&lt;span id="b02a"&gt;#Extracting last names&lt;strong&gt;&lt;br&gt;data.name.str.split(" ").map(lambda x: x[-1])&lt;br&gt;&lt;/strong&gt;0 Gonzalez&lt;br&gt;1 Young&lt;br&gt;2 Lawson&lt;br&gt;3 White&lt;br&gt;4 Logsdon&lt;/span&gt;&lt;/pre&gt;&lt;p id="a12b"&gt;The example above handles the names longer than two words by taking only the first and last elements and it makes the function robust for corner cases, which should be regarded when manipulating strings like that.&lt;/p&gt;&lt;p id="7d58"&gt;Another case for split function is to extract a string part between two chars. The following example shows an implementation of this case by using two split functions in a row.&lt;/p&gt;&lt;pre&gt;&lt;span id="5066"&gt;#String extraction example&lt;strong&gt;&lt;br&gt;data.title.head()&lt;/strong&gt;&lt;br&gt;0 Toy Story (1995)&lt;br&gt;1 Jumanji (1995)&lt;br&gt;2 Grumpier Old Men (1995)&lt;br&gt;3 Waiting to Exhale (1995)&lt;br&gt;4 Father of the Bride Part II (1995)&lt;/span&gt;&lt;span id="7815"&gt;&lt;strong&gt;data.title.str.split("(", n=1, expand=True)[1].str.split(")", n=1, expand=True)[0]&lt;br&gt;&lt;/strong&gt;0 1995&lt;br&gt;1 1995&lt;br&gt;2 1995&lt;br&gt;3 1995&lt;br&gt;4 1995&lt;/span&gt;&lt;/pre&gt;&lt;h2 id="83e6"&gt;8.Scaling&lt;/h2&gt;&lt;p id="a88c"&gt;In most cases, the numerical features of the dataset do not have a certain &lt;strong&gt;range&lt;/strong&gt; and they differ from each other. In real life, it is nonsense to expect &lt;strong&gt;age&lt;/strong&gt; and &lt;strong&gt;income&lt;/strong&gt; columns to have the same range. But from the machine learning point of view, how these two columns can be compared?&lt;/p&gt;&lt;p id="17f9"&gt;Scaling solves this problem. The continuous features become identical in terms of the range, after a scaling process. This process is not mandatory for many algorithms, but it might be still nice to apply. However, the algorithms based on &lt;strong&gt;distance&lt;/strong&gt; calculations such as &lt;strong&gt;k-NN &lt;/strong&gt;or &lt;strong&gt;k-Means&lt;/strong&gt; need to have scaled continuous features as model input.&lt;/p&gt;&lt;p id="a9b4"&gt;Basically, there are two common ways of scaling:&lt;/p&gt;&lt;h2 id="56fd"&gt;Normalization&lt;/h2&gt;&lt;figure&gt;&lt;div&gt;&lt;p&gt;&lt;img height="44" width="168" src="https://miro.medium.com/max/60/1*D3ORMiW9A7GoTezFYbL8LA.png?q=20" alt="Image for post"&gt;&lt;/p&gt;&lt;/div&gt;&lt;/figure&gt;&lt;p id="0002"&gt;Normalization (or &lt;strong&gt;min-max normalization&lt;/strong&gt;) scale all values in a fixed range between &lt;strong&gt;0&lt;/strong&gt; and &lt;strong&gt;1&lt;/strong&gt;. This transformation does not change the distribution of the feature and due to the decreased standard deviations, the effects of the &lt;strong&gt;outliers&lt;/strong&gt; increases. Therefore, before normalization, it is recommended to handle the outliers.&lt;/p&gt;&lt;pre&gt;&lt;span id="622e"&gt;data = pd.DataFrame({'value':[2,45, -23, 85, 28, 2, 35, -12]})&lt;p&gt;data['normalized'] = (data['value'] - data['value'].min()) / (data['value'].max() - data['value'].min())&lt;/p&gt;&lt;/span&gt;&lt;span id="91e6"&gt;&lt;strong&gt; value normalized&lt;/strong&gt;&lt;br&gt;0 2 0.23&lt;br&gt;1 45 0.63&lt;br&gt;2 -23 0.00&lt;br&gt;3 85 1.00&lt;br&gt;4 28 0.47&lt;br&gt;5 2 0.23&lt;br&gt;6 35 0.54&lt;br&gt;7 -12 0.10&lt;/span&gt;&lt;/pre&gt;&lt;h2 id="0c17"&gt;Standardization&lt;/h2&gt;&lt;p id="1786"&gt;Standardization (or &lt;strong&gt;z-score normalization&lt;/strong&gt;) scales the values while taking into account standard deviation. If the standard deviation of features is different, their range also would differ from each other. This reduces the effect of the outliers in the features.&lt;/p&gt;&lt;p id="b16b"&gt;In the following formula of standardization, the &lt;strong&gt;mean&lt;/strong&gt; is shown as &lt;strong&gt;&lt;em&gt;μ&lt;/em&gt;&lt;/strong&gt; and the &lt;strong&gt;standard&lt;/strong&gt; &lt;strong&gt;deviation&lt;/strong&gt; is shown as &lt;strong&gt;&lt;em&gt;σ&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;&lt;figure&gt;&lt;div&gt;&lt;p&gt;&lt;img height="39" width="82" src="https://miro.medium.com/max/60/1*BcNLM9loyAR3YQLt2hDqqg.png?q=20" alt="Image for post"&gt;&lt;/p&gt;&lt;/div&gt;&lt;/figure&gt;&lt;pre&gt;&lt;span id="760d"&gt;data = pd.DataFrame({'value':[2,45, -23, 85, 28, 2, 35, -12]})&lt;p&gt;data['standardized'] = (data['value'] - data['value'].mean()) / data['value'].std()&lt;/p&gt;&lt;/span&gt;&lt;span id="2c75"&gt; &lt;strong&gt;value standardized&lt;/strong&gt;&lt;br&gt;0 2 -0.52&lt;br&gt;1 45 0.70&lt;br&gt;2 -23 -1.23&lt;br&gt;3 85 1.84&lt;br&gt;4 28 0.22&lt;br&gt;5 2 -0.52&lt;br&gt;6 35 0.42&lt;br&gt;7 -12 -0.92&lt;/span&gt;&lt;/pre&gt;&lt;h2 id="8068"&gt;9.Extracting Date&lt;/h2&gt;&lt;p id="2ef6"&gt;Though date columns usually provide valuable information about the model target, they are neglected as an input or used nonsensically for the machine learning algorithms. It might be the reason for this, that dates can be present in numerous formats, which make it hard to understand by algorithms, even they are simplified to a format like &lt;strong&gt;"01–01–2017"&lt;/strong&gt;.&lt;/p&gt;&lt;p id="aeb9"&gt;Building an ordinal relationship between the values is very challenging for a machine learning algorithm if you leave the date columns without manipulation. Here, I suggest three types of preprocessing for dates:&lt;/p&gt;&lt;ul&gt;&lt;li id="0281"&gt;Extracting the parts of the date into different columns: Year, month, day, etc.&lt;/li&gt;&lt;li id="246b"&gt;Extracting the time period between the current date and columns in terms of years, months, days, etc.&lt;/li&gt;&lt;li id="7c84"&gt;Extracting some specific features from the date: Name of the weekday, Weekend or not, holiday or not, etc.&lt;/li&gt;&lt;/ul&gt;&lt;p id="5659"&gt;If you transform the date column into the extracted columns like above, the information of them become disclosed and machine learning algorithms can easily understand them.&lt;/p&gt;&lt;pre&gt;&lt;span id="bbf6"&gt;from datetime import date&lt;p&gt;data = pd.DataFrame({'date':&lt;br&gt;['01-01-2017',&lt;br&gt;'04-12-2008',&lt;br&gt;'23-06-1988',&lt;br&gt;'25-08-1999',&lt;br&gt;'20-02-1993',&lt;br&gt;]})&lt;/p&gt;&lt;p&gt;&lt;strong&gt;#Transform string to date&lt;/strong&gt;&lt;br&gt;data['date'] = pd.to_datetime(data.date, format="%d-%m-%Y")&lt;/p&gt;&lt;p&gt;&lt;strong&gt;#Extracting Year&lt;/strong&gt;&lt;br&gt;data['year'] = data['date'].dt.year&lt;/p&gt;&lt;p&gt;&lt;strong&gt;#Extracting Month&lt;/strong&gt;&lt;br&gt;data['month'] = data['date'].dt.month&lt;/p&gt;&lt;p&gt;&lt;strong&gt;#Extracting passed years since the date&lt;/strong&gt;&lt;br&gt;data['passed_years'] = date.today().year - data['date'].dt.year&lt;/p&gt;&lt;p&gt;&lt;strong&gt;#Extracting passed months since the date&lt;/strong&gt;&lt;br&gt;data['passed_months'] = (date.today().year - data['date'].dt.year) * 12 + date.today().month - data['date'].dt.month&lt;/p&gt;&lt;p&gt;&lt;strong&gt;#Extracting the weekday name of the date&lt;/strong&gt;&lt;br&gt;data['day_name'] = data['date'].dt.day_name()&lt;/p&gt;&lt;/span&gt;&lt;span id="25a7"&gt; &lt;strong&gt;date year month passed_years passed_months day_name&lt;/strong&gt;&lt;br&gt;0 2017-01-01 2017 1 2 26 Sunday&lt;br&gt;1 2008-12-04 2008 12 11 123 Thursday&lt;br&gt;2 1988-06-23 1988 6 31 369 Thursday&lt;br&gt;3 1999-08-25 1999 8 20 235 Wednesday&lt;br&gt;4 1993-02-20 1993 2 26 313 Saturday&lt;/span&gt;&lt;/pre&gt;&lt;h2 id="f8cd"&gt;Conclusion&lt;/h2&gt;&lt;figure&gt;&lt;div tabindex="0" role="button"&gt;&lt;p&gt;&lt;img height="439" width="371" src="https://miro.medium.com/max/50/0*eySmc2fSF96yXIW0.png?q=20" alt="Image for post"&gt;&lt;/p&gt;&lt;/div&gt;&lt;figcaption&gt;&lt;a rel="noopener nofollow" href="https://xkcd.com/1838/"&gt;https://xkcd.com/1838/&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p id="3fae"&gt;I tried to explain fundamental methods that can be beneficial in the feature engineering process. After this article, proceeding with other topics of data preparation such as &lt;strong&gt;feature selection, train/test splitting, &lt;/strong&gt;and&lt;strong&gt; sampling&lt;/strong&gt; might be a good option.&lt;/p&gt;&lt;p id="2624"&gt;You can check my &lt;a href="https://towardsdatascience.com/how-to-calibrate-undersampled-model-scores-8f3319c1ea5b" rel="noopener"&gt;other article about Oversampling&lt;/a&gt;.&lt;/p&gt;&lt;p id="1dc3"&gt;Lastly, I want to conclude the article with a reminder. These techniques are not magical tools. If your data tiny, dirty and useless, feature engineering may remain incapable. Do not forget &lt;em&gt;“&lt;/em&gt;&lt;strong&gt;&lt;em&gt;garbage in, garbage out!”&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;h2 id="67f8"&gt;References&lt;/h2&gt;&lt;ul&gt;&lt;li id="cb98"&gt;&lt;a rel="noopener nofollow" href="https://stackoverflow.com/"&gt;&lt;strong&gt;Stack Overflow&lt;/strong&gt;&lt;/a&gt; questions are very beneficial for every kind of feature engineering script.&lt;/li&gt;&lt;li id="a5b6"&gt;I highly recommend &lt;a rel="noopener nofollow" href="https://www.kaggle.com/"&gt;&lt;strong&gt;Kaggle&lt;/strong&gt;&lt;/a&gt; competitions and their discussion boards.&lt;/li&gt;&lt;li id="f2a2"&gt;&lt;a href="https://towardsdatascience.com/ways-to-detect-and-remove-the-outliers-404d16608dba" rel="noopener"&gt;&lt;strong&gt;Ways to Detect and Remove the Outliers&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;&lt;li id="528f"&gt;&lt;a href="https://towardsdatascience.com/understanding-feature-engineering-part-1-continuous-numeric-data-da4e47099a7b" rel="noopener"&gt;&lt;strong&gt;Understanding Feature Engineering (Part 1) — Continuous Numeric Data&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;&lt;li id="fc69"&gt;&lt;a href="https://towardsdatascience.com/understanding-feature-engineering-part-2-categorical-data-f54324193e63" rel="noopener"&gt;&lt;strong&gt;Understanding Feature Engineering (Part 2) — Categorical Data&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;&lt;li id="6459"&gt;&lt;a rel="noopener nofollow" href="https://www.r-statistics.com/2013/05/log-transformations-for-skewed-and-wide-distributions-from-practical-data-science-with-r/"&gt;&lt;strong&gt;Log Transformations for Skewed and Wide Distributions&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;&lt;li id="4c01"&gt;&lt;a rel="noopener nofollow" href="http://vita.had.co.nz/papers/tidy-data.html"&gt;&lt;strong&gt;Tidy data&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;&lt;li id="3062"&gt;&lt;a rel="noopener nofollow" href="https://sebastianraschka.com/Articles/2014_about_feature_scaling.html"&gt;&lt;strong&gt;About Feature Scaling and Normalization&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;a href="https://towardsdatascience.com/feature-engineering-for-machine-learning-3a5e293a5114"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Wed, 8 Apr 2020 11:57:40 UT
      </pubDate>
      <guid>
        https://towardsdatascience.com/feature-engineering-for-machine-learning-3a5e293a5114
      </guid>
    </item>
    <item>
      <title>
        Zuckerberg’s Jealousy Held Back Instagram and Drove Off Founders - Bloomberg
      </title>
      <link>
        https://www.bloomberg.com/news/features/2020-04-07/zuckerberg-s-jealousy-held-back-instagram-and-drove-off-founders
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt; &lt;p&gt;&lt;em&gt;Over the past decade, Instagram has become an engine of commerce and cultural influence with few peers—aside from its parent company, &lt;a href="https://www.bloomberg.com/quote/FB:US"&gt;Facebook Inc.&lt;/a&gt; Reporter Sarah Frier’s &lt;a rel="nofollow noopener" title="Redirects to the order site for Frier's book" href="http://smarturl.it/nofilterbook"&gt;inside look at Instagram&lt;/a&gt;, based on interviews with hundreds of the companies’ leaders, current and former employees, competitors, and stars, traces the union of Facebook and Instagram and the disintegration of the relationship between their chief executive officers. Facebook said in a statement that it has committed significant resources to fuel Instagram’s development and that “Instagram’s success is Facebook’s success.&lt;/em&gt;”&lt;/p&gt;&lt;p&gt;The Instagram event didn’t feel very Facebook. On a San Francisco street dotted with homeless encampments, press and the quasi celebrities known as influencers entered a former music venue through an archway made of balloons. Attendees received raspberry-cream-filled cruffins—croissants shaped like muffins—along with espresso drinks and multiple kinds of green juice. Enclaves in the space were designed specifically for selfie-taking, to encourage the influencers to hype the coming product announcement to their digital followers.&lt;/p&gt;&lt;p&gt;But the event was beset by technical difficulties. Someone misplaced the file for CEO Kevin Systrom’s presentation, so it had to be remade in a scramble while guests waited. During the delay, the corporate blog post announcing Instagram TV, a new standalone video app, went up as scheduled, ruining the surprise before Systrom arrived onstage. An hour after the event ended, his iPhone flashed. It was Chris Cox, the executive whom Facebook CEO Mark Zuckerberg had recently put in charge of all his company’s apps.&lt;/p&gt;&lt;figure data-type="image" data-image-size="column" data-id="360982996" data-align="left"&gt;&lt;div aria-label="Open image in viewer" role="button" tabindex="0"&gt;&lt;p&gt;&lt;img data-img-type="image" data-native-src="https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i6QTOCbfUvr4/v1/-1x-1.jpg" src="https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i6QTOCbfUvr4/v1/-1x-1.jpg" alt="relates to Zuckerberg’s Jealousy Held Back Instagram and Drove Off Founders"&gt;&lt;/p&gt;&lt;/div&gt;&lt;/figure&gt;&lt;p&gt;“We have a problem,” Cox said. “Mark’s very angry about your icon.”&lt;/p&gt;&lt;p&gt;“Are you serious?” Systrom asked. “What’s wrong?”&lt;/p&gt;&lt;p&gt;“It looks too much like the icon for Facebook Messenger,” Cox said, referring to Facebook’s chat service, which also had a horizontal lightning bolt shape in the center. Zuckerberg couldn’t stand that IGTV competed visually with a sister product.&lt;/p&gt;&lt;p&gt;The call was the latest in a string of reminders that, by 2018, Facebook saw even the slightest encroachment by Instagram as a threat. Systrom, who’d sold Instagram to Zuckerberg in 2012, had for years retained enough authority to wall off the parts of Facebook he didn’t like, often telling reporters he considered Zuckerberg to be more like a board member than a boss. Lately, though, Facebook was asserting more control, and Systrom found himself forced to satisfy the concerns of Zuckerberg and his lieutenants before adding products, hiring staff, or even making announcements about his app’s popularity.&lt;/p&gt;&lt;p&gt;It took months to get permission to release IGTV without any tie-ins to Facebook’s existing video product. Shortly before the event with the cruffins, Zuckerberg questioned whether Instagram should even disclose that its user count had topped 1 billion. The subtext wasn’t very sub: A Facebook property was reaching thresholds that made it look like the next Facebook, and the parent company wanted to make sure its namesake website and app didn’t suffer for the comparison.&lt;/p&gt;&lt;p&gt;Of course, Facebook’s suffering wasn’t Instagram’s fault. Zuckerberg was facing blowback from years of taking shortcuts to win his product attention and ad revenue, including abusing private user data to curry favor with software developers, allowing live broadcasts of murders and suicides, and turning a blind eye to meddling in the U.S. presidential election. Yet with a global #DeleteFacebook movement growing, Zuckerberg saw his other properties, the chat apps WhatsApp and Messenger as well as Instagram, as assets in a new sense—as an explicitly linked family of software.&lt;/p&gt;&lt;p&gt;Zuckerberg’s purchase of Instagram, considered wildly overpriced at $715 million in 2012, is worth more than $100 billion today. Instagram now delivers $20 billion in annual revenue, more than a quarter of Facebook’s total. And Zuckerberg’s promise to leave the Instagram team largely independent inspired other founders to join Facebook, too. In 2014 he bought WhatsApp for a then-stunning $22 billion, solidifying Facebook’s dominance over modern communication, and paid $2 billion for the virtual-reality company Oculus, whose hardware he hoped would lead the way into the future.&lt;/p&gt;&lt;p&gt;But in late 2018, the Instagram founders abandoned their creation, and the WhatsApp and Oculus founders left the same year. With Facebook in crisis, Zuckerberg had stopped seeing his acquisitions as a portfolio of subsidiaries that could grow into potential second acts. Instead, he would lean on Instagram to strengthen the Facebook app more directly, including by weaving the software together. Today, with his company &lt;a title="Facebook’s New FTC Probe Covers Wide Sphere But Faces Long Odds" href="https://www.bloomberg.com/news/articles/2019-07-24/facebook-says-it-s-being-investigated-by-the-ftc-over-antitrust"&gt; under investigation&lt;/a&gt; for anticompetitive behavior by the U.S. Department of Justice, the Federal Trade Commission, and 47 state attorneys general, Zuckerberg is consolidating his products’ data and building one big mega-network that will make Facebook proper look all the bigger. As one former Instagram executive complained: “Facebook was like the big sister that wants to dress you up for the party but does not want you to be prettier than she is.”&lt;/p&gt;&lt;p&gt;Systrom and co-founder Mike Krieger unveiled Instagram a decade ago as an iPhone app whose filters could quickly improve the low-quality pictures snapped on mobile devices, so anyone could feel like a professional photographer. They attracted 30 million users in 18 months, and by early 2012, their team of 12 could barely keep pace. Krieger was fixing service outages at all hours, bringing his laptop to movies, birthday parties, bars, and, in one instance, a campsite. So when Zuckerberg reached out about acquiring the company, Instagram’s founders were ready to listen. During negotiations over Easter weekend, Zuckerberg said all the right things. In exchange for what was, at the time, more money than anyone had paid for a mobile app, he would extend Facebook’s engineering and operational largesse but leave Systrom and Krieger firmly in charge.&lt;/p&gt; &lt;p&gt;Soon after the Instagram employees moved into a small room at Facebook’s Menlo Park, Calif., headquarters, they began to realize their new colleagues weren’t as eager to share as Zuckerberg had promised. In one early meeting, Facebook’s growth team told the Instagram staffers that before they could help, they needed to figure out whether Instagram’s popularity made people less likely to post photos on Facebook. Their study proved inconclusive but served as a warning to Instagram not to expect its software to be treated as equal.&lt;/p&gt;&lt;p&gt;Still, Zuckerberg and Systrom developed a mutual respect over monthly strategy dinners at Zuckerberg’s Palo Alto home. On paper they were extremely similar. Born just five months apart, both were raised in comfortable suburban American towns by tightknit Northeastern families. Both attended boarding schools (Zuckerberg captained the Exeter fencing team; Systrom, Middlesex lacrosse) and elite universities (Harvard and Stanford), where they nursed passions for history as well as engineering. Zuckerberg was obsessed with the ancient Greeks and Romans; Systrom loved art history.&lt;/p&gt;&lt;p&gt;Their competitive streaks manifested in different ways. When they went on a ski trip to bond shortly after the acquisition, Systrom preferred the unpredictability of backcountry trails, while Zuckerberg just wanted to race black diamonds to the bottom. No matter the stakes, Zuckerberg was win-at-all-costs. Once, when he lost a Scrabble match to a friend’s teenage daughter, he created a simple software program to cheat for him. Systrom fancied himself a Renaissance man, with a passion for self-improvement matched only by his expensive tastes for Italian leather, bespoke mountain bikes, and dinner with celebrities. In 2018, around the time Zuckerberg testified to Congress about one of Facebook’s data-sharing scandals, Systrom passed his wine sommelier exam and sat with the Kardashians at the Met Gala.&lt;/p&gt;&lt;p&gt;Instagram’s success earned Zuckerberg’s respect, but not a place on the short list of Facebook executives he counted as confidants and friends. Zuckerberg couldn’t relate to Systrom’s obsession over each contour of Instagram’s design, which slowed product development. Systrom worried that Facebook’s hard-sell approach—sending spammy emails to push users to log in, for example, or using red dots in the interface to create anxiety about missed messages—might cost Instagram the relative trust it enjoyed as a friendlier-looking social network. Still, he believed that keeping Zuckerberg happy would require him to show that Instagram remained valuable to Facebook’s future. He assumed Zuckerberg would continue to honor Instagram’s independence as long as it grew quickly—and crushed the competition.&lt;/p&gt;&lt;figure data-type="image" data-image-size="column" data-id="360983042" data-align="center"&gt;&lt;div aria-label="Open image in viewer" role="button" tabindex="0"&gt;&lt;p&gt;&lt;img data-img-type="image" data-native-src="https://assets.bwbx.io/images/users/iqjWHBFdfxIU/ivSuzObFQ0dQ/v1/-1x-1.jpg" src="https://assets.bwbx.io/images/users/iqjWHBFdfxIU/ivSuzObFQ0dQ/v1/-1x-1.jpg" alt="relates to Zuckerberg’s Jealousy Held Back Instagram and Drove Off Founders"&gt;&lt;/p&gt;&lt;/div&gt;&lt;figcaption&gt;&lt;p&gt;Photo Illustration by 731. Photos: Getty Images (7)&lt;/p&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Zuckerberg thought there was little use doing something unless you were doing it for as many people as possible. With Facebook, he had created the largest network of humans ever, and steadily worked to capture more of their time. His opponents included Twitter, Snapchat, Google, and anyone else competing for attention. He wasn’t shy about copying a competitor’s popular features, either, whether that meant incorporating more official news sources into Facebook’s news feed, like Twitter, or making a half-dozen attempts to add Snapchat-style disappearing photos. (Snapchat rejected his $3 billion buyout offer in 2013.) This bolt-on strategy often left Facebook looking less than refined, especially next to Instagram.&lt;/p&gt;&lt;p&gt;Where the viral sharing on Facebook could seem to represent the nadir of the internet, Instagram appeared to reward the beautiful and interesting for doing cool stuff. Systrom’s community, and its cultural influence, expanded as he nurtured emerging stars and pursued relationships with A-list celebrities. Systrom was less comfortable with Zuckerberg pushing him into the world of advertising. When Instagram rolled out its first ads at the end of 2013, Systrom said there should only be one sponsor allowed per day, and that he wanted to personally review each ad. (Once, he took it upon himself to edit a promotional photo of fries to make them look crispier.) Zuckerberg insisted that he abandon the white-glove model and transition to Facebook’s system, which allowed anyone with a credit card to purchase as many ads as they liked. It was the right call, in terms of dollars. Instagram reached $1 billion in annual revenue by the end of 2015.&lt;/p&gt;&lt;p&gt;Yet the news that Instagram’s growth was accelerating while Facebook’s was slowing didn’t sit well with Zuckerberg. Systrom had done his job too well.&lt;/p&gt;&lt;p&gt;By the end of 2016, just as his company was facing its first controversies related to Donald Trump’s election, Zuckerberg was focused on a different kind of threat. Typical Facebook users were posting fewer of their own thoughts and photos, and Zuckerberg suspected Instagram’s successful copying of Snapchat Stories was to blame. (The success came as a surprise even to Zuckerberg, who unbeknownst to Systrom had again tried and failed to buy Snapchat shortly before Instagram Stories debuted.) He enlisted his most trusted data scientists to study whether Instagram was becoming a Facebook alternative and threatening its dominance. Zuckerberg thought the research showed that Instagram would start eating into Facebook’s user base within six months. The word “cannibalization” started to creep into his management meetings.&lt;/p&gt;&lt;p&gt;Systrom disagreed with Zuckerberg’s assessment of the data. “This is not Instagram taking away from the Facebook pie to add to the Instagram pie,” he told Zuckerberg at a weekly Monday leadership meeting. “The total pie is getting bigger.” It wasn’t just Instagram vs. Facebook. It was all of these Facebook properties vs. every other choice in the world, like Netflix, Snapchat, Twitter, and, you know, sleep. Others in the room sided with Systrom. They were puzzled by Zuckerberg’s apparent jealousy of Instagram’s success. Zuckerberg had always said Facebook should reinvent itself before a competitor got the chance and that the company should make the decisions about how to do so based on data. “If we don’t create the thing that kills Facebook, someone else will,” the booklet passed out at employee orientation reads.&lt;/p&gt; &lt;p&gt;Yet Zuckerberg couldn’t seem to bear the idea that Instagram might outshine Facebook. He told Systrom he believed Instagram Stories was successful not because of its design, but because they’d happened to release the feature ahead of Facebook Stories. Facebook had helped Instagram long enough, he decided. In 2018, Instagram would have to start giving back.&lt;/p&gt;&lt;p&gt;Instagram users barely noticed Zuckerberg’s first change. He ordered Systrom to build a prominent link within the Instagram app that would send his users to Facebook. Around the same time, he had his own engineers remove the prominent link to Instagram on Facebook’s site.&lt;/p&gt;&lt;p&gt;Zuckerberg’s willingness to expand Instagram’s team had waned, too. He balked at adding engineers to facilitate the release of IGTV, even though Instagram was on track to hit 1 billion users and $10 billion in revenue that year. He allowed Systrom and Krieger to hire 93 more employees, bringing their count to around 800—still far short of what they felt they needed. Instagram’s co-founders were shocked; Zuckerberg granted Oculus, which was losing money, more than 600 new employees. Krieger dug up the numbers and learned that Facebook, which hired 8,000 people in 2018, had six times as many employees as Instagram when it added its billionth user.&lt;/p&gt;&lt;p&gt;Instagram now felt like a Facebook product arm, not an independent operation. Zuckerberg made this new order official with a massive reorg emphasizing that Facebook’s properties were to be a “family of apps.” Systrom would now be reporting to Cox, who was previously just in charge of the Facebook app. “Let’s be straight with each other,” Systrom told Cox. “I need independence. I need resources. And when something happens, I know I’m not always going to agree with it, but I need honesty. That’s what’s going to keep me here.”&lt;/p&gt;&lt;p&gt;Cox knew he couldn’t afford to lose Systrom or Krieger, especially as Facebook’s and Zuckerberg’s public images were souring. He resolved to prioritize retaining the Instagram co-founders. Soon, though, Facebook was facing a different crisis after the &lt;em&gt;Guardian&lt;/em&gt;, the U.K.’s Channel 4, and the &lt;em&gt;New York Times&lt;/em&gt; published whistleblower testimony that Cambridge Analytica, a Republican political consulting firm, had collected the private data of tens of millions of American Facebook users and attempted to influence the U.S. presidential election while Facebook looked the other way. Suddenly, all of Facebook’s problems were up for public debate. Zuckerberg made plans to hire thousands of people to work on issues of “integrity.” Systrom requested hires to address Instagram-specific concerns (anonymous users, less-visible dangerous communities), but Zuckerberg said no. Instagram would have to manage its problems with existing resources or the central integrity team.&lt;/p&gt;&lt;p&gt;After Instagram reached 1 billion users, Zuckerberg directed Javier Olivan, Facebook’s head of growth, to draw up a list of all the ways Instagram was supported by the Facebook app. Then he ordered the supporting tools turned off. Instagram would no longer be promoted in Facebook’s news feed. Sure enough, Instagram’s growth slowed to a halt.&lt;/p&gt;&lt;p&gt;Systrom had never been one to criticize Zuckerberg in front of his employees. But after months of what he saw as obstruction and bigfooting, he wrote a long internal message to his team saying he disagreed vehemently with Zuckerberg’s undercutting of Instagram. By the fall of 2018, Systrom started confiding to his close friends that if Zuckerberg wanted to run Instagram like a mere department of Facebook, maybe it was time to let him. In the name of growth, Instagram adopted some of the strategies Systrom had blocked in the past, including pushing out frequent app notifications and aggressively promoting suggested people to follow. Time spent on the app returned to its typical levels; the Facebook strategies, which had seemed so cheap and anti-Instagram, worked.&lt;/p&gt; &lt;p&gt;Not long after the IGTV debut, when his first child was about six months old, Systrom went on paternity leave. He was expected back at the end of July, but extended his leave by a month, then another. When he came back in late September, he and Krieger gathered their top staff in a conference room. They were &lt;a title="Instagram Founders Depart Facebook After Clashes With Zuckerberg" href="https://www.bloomberg.com/news/articles/2018-09-25/instagram-founders-depart-facebook-after-clashes-with-zuckerberg"&gt; both resigning&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Systrom was diplomatic, explaining that after six years within Facebook, it was time to try other things. But he didn’t hold back with Facebook management. Earlier that morning he’d reminded Cox that he’d asked for resources, independence, and trust. “None of the things I asked for have happened,” he told Cox.&lt;/p&gt;&lt;p&gt;In the 18 months since its founders left, Instagram has grown more in Facebook’s image than ever, prioritizing integration with Facebook over its own product development. Most Instagram users still don’t know Facebook owns the app, even though it’s been &lt;a title="Facebook Adds More Corporate Branding to Instagram, WhatsApp" href="https://www.bloomberg.com/news/articles/2019-11-04/facebook-adds-more-corporate-branding-to-instagram-whatsapp"&gt; rebranded as “Instagram from Facebook.”&lt;/a&gt; More obvious has been the increased frequency of advertising on Instagram.&lt;/p&gt;&lt;p&gt;Zuckerberg hasn’t disclosed an updated number of Instagram users since 2018. Eventually, he says, Facebook’s total user number won’t be broken out, either. The company will just report one number—total users of the Facebook “family,” including Facebook, WhatsApp, Instagram, and Messenger. The overall number sits at 2.9 billion, accounting for duplicates between the apps. Using an overall number will allow Zuckerberg to mask any slowdown in the core Facebook app’s growth. It will also make it tougher for antitrust-minded regulators to recognize that Facebook owns the world’s top Facebook alternative.&lt;/p&gt;&lt;p&gt;Cox, too, left the company in 2019 after disagreeing with Zuckerberg’s push for greater encryption across the app family. Instagram’s new top boss is Adam Mosseri, who formerly ran Facebook’s news feed. His title is “Head of Instagram.” These days, Facebook only has room for one CEO.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Excerpted from the book &lt;/em&gt;NO FILTER: The Inside Story of Instagram&lt;em&gt;, by Sarah Frier. Copyright 2020 by Sarah Frier. Reprinted with permission of Simon &amp;amp; Schuster, Inc. All rights reserved.&lt;/em&gt;&lt;/p&gt; &lt;ol&gt;&lt;/ol&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://www.bloomberg.com/news/features/2020-04-07/zuckerberg-s-jealousy-held-back-instagram-and-drove-off-founders"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Wed, 8 Apr 2020 20:04:48 UT
      </pubDate>
      <guid>
        https://www.bloomberg.com/news/features/2020-04-07/zuckerberg-s-jealousy-held-back-instagram-and-drove-off-founders
      </guid>
    </item>
    <item>
      <title>
        Coronavirus &amp;amp; China: Origin in Wuhan Lab Unproven, But Denials Unconvincing | National Review
      </title>
      <link>
        https://www.nationalreview.com/2020/04/coronavirus-china-trail-leading-back-to-wuhan-labs/amp/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt; &lt;p&gt;&lt;span&gt;There’s no proof the coronavirus accidentally escaped from a laboratory, but we can’t take the Chinese government’s denials at face value.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; &lt;span id="nrplus-badge-left"&gt; &lt;span&gt;&lt;/span&gt; &lt;span&gt;NRPLUS MEMBER ARTICLE&lt;/span&gt; &lt;/span&gt; &lt;span&gt;I&lt;/span&gt; &lt;/span&gt;&lt;span&gt;t&lt;/span&gt; is understandable that many would be wary of the notion that the origin of the coronavirus could be discovered by some &lt;a rel="noopener noreferrer" href="https://www.imdb.com/name/nm8426798/bio"&gt;documentary filmmaker&lt;/a&gt; who used to live in China. Matthew Tye, who creates YouTube videos, &lt;a rel="noopener noreferrer" href="https://www.youtube.com/watch?v=bpQFCcSI0pU&amp;amp;feature=youtu.be"&gt;contends he has identified the source of the coronavirus&lt;/a&gt; — and a great deal of the information that he presents, obtained from public records posted on the Internet, checks out.&lt;/p&gt; &lt;p&gt;&lt;a rel="noopener noreferrer" href="http://www.whiov.cas.cn/105341/"&gt;The Wuhan Institute of Virology in China indeed posted a job opening&lt;/a&gt; on November 18, 2019, “asking for scientists to come research the relationship between the coronavirus and bats.”&lt;/p&gt; &lt;p&gt;The &lt;a rel="noopener noreferrer" href="http://www.whiov.cas.cn/105341/201911/t20191118_5438006.html"&gt;Google translation of the job posting is&lt;/a&gt;: “Taking bats as the research object, I will answer the molecular mechanism that can coexist&amp;nbsp;with Ebola and&amp;nbsp;SARS-&amp;nbsp;associated coronavirus for a&amp;nbsp;long time&amp;nbsp;without disease, and its relationship with flight and longevity.&amp;nbsp;Virology, immunology, cell biology, and multiple omics are used to compare the differences between humans and other mammals.” (“Omics” is a term for a subfield within biology, such as genomics or glycomics.)&lt;/p&gt; &lt;p&gt;On December 24, 2019, the Wuhan Institute of Virology &lt;a rel="noopener noreferrer" href="http://www.whiov.cas.cn/105341/201912/t20191224_5471634.html"&gt;posted a second job posting&lt;/a&gt;. The translation of that posting includes the declaration, “long-term research on the pathogenic biology of bats carrying important viruses has confirmed the&amp;nbsp;origin of bats of major new human and livestock infectious diseases such as&amp;nbsp;SARS&amp;nbsp;and&amp;nbsp;SADS,&amp;nbsp;and a large number of new bat and rodent new viruses have been discovered and identified.”&lt;/p&gt; &lt;p&gt;Tye contends that that posting meant, “we’ve discovered a new and terrible virus, and would like to recruit people to come deal with it.” He also contends that “news didn’t come out about coronavirus until ages after that.” Doctors in Wuhan &lt;a rel="noopener noreferrer" href="https://www.nationalreview.com/the-morning-jolt/chinas-devastating-lies/"&gt;knew that they were dealing with a cluster of pneumonia cases as December progressed&lt;/a&gt;, but it is accurate to say that a very limited number of people knew about this particular strain of coronavirus and its severity at the time of that job posting. By December 31, about three weeks after doctors first noticed the cases, the Chinese government notified the World Health Organization and the &lt;a rel="noopener noreferrer" href="https://www.scmp.com/news/china/politics/article/3044050/mystery-illness-hits-chinas-wuhan-city-nearly-30-hospitalised"&gt;first media reports&lt;/a&gt; about a “mystery pneumonia” appeared outside China.&lt;/p&gt; &lt;p&gt;&lt;em&gt;Scientific American&lt;/em&gt; &lt;a rel="noopener noreferrer" href="https://www.scientificamerican.com/article/how-chinas-bat-woman-hunted-down-viruses-from-sars-to-the-new-coronavirus1/"&gt;verifies much of the information&lt;/a&gt; Tye mentions about Shi Zhengli, the Chinese virologist nicknamed “Bat Woman” for her work with that species.&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;Shi — a virologist who is often called China’s “bat woman” by her colleagues because of her virus-hunting expeditions in bat caves over the past 16 years — walked out of the conference she was attending in Shanghai and hopped on the next train back to Wuhan. “I wondered if [the municipal health authority] got it wrong,” she says. “I had never expected this kind of thing to happen in Wuhan, in central China.” Her studies had shown that the southern, subtropical areas of Guangdong, Guangxi and Yunnan have the greatest risk of coronaviruses jumping to humans from animals — &lt;em&gt;particularly bats, a known reservoir for many viruses. If coronaviruses were the culprit, she remembers thinking, “could they have come from our lab?”&lt;/em&gt;&lt;/p&gt; &lt;p&gt;. . . By January 7 the Wuhan team determined that the new virus had indeed caused the disease those patients suffered — a conclusion based on results from polymerase chain reaction analysis, full genome sequencing, antibody tests of blood samples and the virus’s ability to infect human lung cells in a petri dish. The genomic sequence of the virus — now officially called SARS-CoV-2 because it is related to the SARS pathogen — was 96 percent identical to that of a coronavirus the researchers had identified in horseshoe bats in Yunnan, they reported in a&amp;nbsp;&lt;a rel="noopener noreferrer" href="https://www.nature.com/articles/s41586-020-2012-7"&gt;paper&lt;/a&gt;&amp;nbsp;published last month in&amp;nbsp;&lt;em&gt;Nature&lt;/em&gt;. “It’s crystal clear that bats, once again, are the natural reservoir,” says Daszak, who was not involved in the study.&lt;strong&gt;&lt;br&gt; &lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;Some scientists aren’t convinced that the virus jumped straight from bats to human beings, but &lt;a rel="noopener noreferrer" href="https://www.newyorker.com/science/elements/from-bats-to-human-lungs-the-evolution-of-a-coronavirus"&gt;there are a few problems with the theory that some other animal was an intermediate transmitter of COVID-19&lt;/a&gt; from bats to humans:&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;Analyses of the&amp;nbsp;&lt;em&gt;SARS&lt;/em&gt;-CoV-2 genome indicate a single spillover event, meaning the virus jumped only once from an animal to a person, which makes it likely that the virus was circulating among people before December. Unless more information about the animals at the Wuhan market is released, the transmission chain may never be clear. There are, however, numerous possibilities. A bat hunter or a wildlife trafficker might have brought the virus to the market. Pangolins happen to carry a coronavirus, which they might have picked up from bats years ago, and which is, in one crucial part of its genome, virtually identical to&amp;nbsp;&lt;em&gt;SARS&lt;/em&gt;-CoV-2. But no one has yet found evidence that pangolins were at the Wuhan market, or even that venders there trafficked pangolins.&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;On February 4 — one week before the World Health Organization &lt;a rel="noopener noreferrer" href="https://www.who.int/emergencies/diseases/novel-coronavirus-2019/technical-guidance/naming-the-coronavirus-disease-(covid-2019)-and-the-virus-that-causes-it"&gt;decided to officially name this virus “COVID-19”&lt;/a&gt; — &lt;a rel="noopener noreferrer" href="https://www.nature.com/articles/s41422-020-0282-0"&gt;the journal&lt;em&gt;&amp;nbsp;Cell Research&lt;/em&gt;&lt;/a&gt; posted a notice written by scientists at the Wuhan Institute of Virology about the virus, concluding, “our findings reveal that remdesivir and chloroquine are highly effective in the control of 2019-nCoV infection in vitro. Since these compounds have been used in human patients with a safety track record and shown to be effective against various ailments, we suggest that they should be assessed in human patients suffering from the novel coronavirus disease.” One of the authors of that notice was the “bat woman,” Shi Zhengli.&lt;/p&gt; &lt;p&gt;In his YouTube video, Tye focuses his attention on a &lt;a rel="noopener noreferrer" href="https://www.researchgate.net/scientific-contributions/2035568207_Yanling_Huang"&gt;researcher at the Wuhan Institute of Virology&lt;/a&gt; named Huang Yanling: “Most people believe her to be patient zero, and most people believe she is dead.”&lt;/p&gt; &lt;p&gt;There was enough discussion of rumors about Huang Yanling online in China to &lt;a rel="noopener noreferrer" href="http://www.whiov.ac.cn/tzgg_105342/202002/t20200216_5500201.html"&gt;spur an official denial&lt;/a&gt;. On February 16, the Wuhan Institute of Virology denied that patient zero was one of their employees, and interestingly named her specifically: “Recently there has been fake information about Huang Yanling, a graduate from our institute, claiming that she was patient zero in the novel coronavirus.” &lt;a rel="noopener noreferrer" href="https://www.scmp.com/news/china/society/article/3050872/chinese-research-lab-denies-rumours-links-first-coronavirus"&gt;Press accounts quote the institute as saying&lt;/a&gt;, “Huang was a graduate student at the institute until 2015, when she left the province and had not returned since. Huang was in good health and had not been diagnosed with disease, it added.” None of her publicly available &lt;a rel="noopener noreferrer" href="https://www.researchgate.net/scientific-contributions/2035568207_Yanling_Huang"&gt;research papers&lt;/a&gt; are dated after 2015.&lt;/p&gt; &lt;p&gt;The &lt;a rel="noopener noreferrer" href="http://159.226.126.127:8082/web/17190/20"&gt;web page for the Wuhan Institute of Virology’s Lab of Diagnostic Microbiology&lt;/a&gt; does indeed still have “Huang Yanling” listed as a 2012 graduate student, and her picture and biography appear to have been recently removed — as have those of two other graduate students from 2013, Wang Mengyue and Wei Cuihua.&lt;/p&gt; &lt;p&gt;Her name still has a hyperlink, &lt;a rel="noopener noreferrer" href="http://159.226.126.127:8082/web/17190/46"&gt;but the linked page is blank&lt;/a&gt;. The pages for Wang Mengyue and Wei Cuihua are blank as well.&lt;/p&gt; &lt;p&gt;(For what it is worth, the &lt;em&gt;South China Morning Post&lt;/em&gt; — a newspaper seen &lt;a rel="noopener noreferrer" href="https://www.nytimes.com/2018/03/31/world/asia/south-china-morning-post-hong-kong-alibaba.html"&gt;as being generally pro-Beijing&lt;/a&gt; — &lt;a rel="noopener noreferrer" href="https://www.scmp.com/news/china/society/article/3074991/coronavirus-chinas-first-confirmed-covid-19-case-traced-back"&gt;reported on March 13&lt;/a&gt; that “according to the government data seen by the&amp;nbsp;Post, a 55 year-old from Hubei province could have been the first person to have contracted Covid-19 on November 17.”)&lt;/p&gt; &lt;p&gt;On February 17, Zhen Shuji, a Hong Kong correspondent &lt;a rel="noopener noreferrer" href="http://www.rfi.fr/cn/%E4%B8%AD%E5%9B%BD/20200217-%E6%AD%A6%E6%B1%89%E7%A0%94%E7%A9%B6%E6%89%80%E5%A4%96%E6%B3%84%E7%97%85%E6%AF%92%E4%BC%A0%E8%A8%80%E6%9C%AA%E6%AD%A2%E5%8F%88%E6%9C%89%E6%B6%88%E6%81%AF%E6%8C%87-%E9%9B%B6%E5%8F%B7%E7%97%85%E4%BA%BA-%E6%98%AF%E7%A0%94%E7%A9%B6%E5%91%98"&gt;from the French public-radio service Radio France Internationale, reported&lt;/a&gt;: “when a reporter from the Beijing News of the Mainland asked the institute for rumors about patient zero, the institute first denied that there was a researcher Huang Yanling, but after learning that the name of the person on the Internet did exist, acknowledged that the person had worked at the firm but has now left the office and is unaccounted for.”&lt;/p&gt; &lt;p&gt;Tye says, “everyone on the Chinese internet is searching for [Huang Yanling] but most believe that her body was quickly cremated and the people working at the crematorium were perhaps infected as they were not given any information about the virus.” (The U.S. Centers for Disease Control and Prevention says that &lt;a rel="noopener noreferrer" href="https://www.cdc.gov/coronavirus/2019-ncov/faq.html"&gt;handling the body of someone who has died of coronavirus is safe&lt;/a&gt; — including embalming and cremation — as long as the standard safety protocols for handing a decedent are used. It’s anyone’s guess as to whether those safety protocols were sufficiently used in China before the outbreak’s scope was known.)&lt;/p&gt; &lt;p&gt;As Tye observes, a public appearance by Huang Yanling would dispel a lot of the public rumors, and is the sort of thing the Chinese government would quickly arrange in normal circumstances — presuming that Huang Yanling was still alive. Several officials at the Wuhan Institute of Virology issued public statements that Huang was in good health and that no one at the institute has been infected with COVID-19. In any case, the mystery around Huang Yanling may be moot, but it does point to the lab covering up something about her.&lt;/p&gt; &lt;p&gt;China Global Television Network, a state-owned television broadcaster, &lt;a rel="noopener noreferrer" href="https://news.cgtn.com/news/2020-02-23/Rumors-stop-with-the-wise-OjMaO0RjGM/index.html"&gt;illuminated another rumor&lt;/a&gt; while attempting to dispel it in a February 23 report entitled “Rumors Stop With the Wise”:&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;On February 17, a Weibo user who claimed herself to be Chen Quanjiao, a researcher at the Wuhan Institute of Virology, reported to the public that the Director of the Institute was responsible for leaking the novel coronavirus. The Weibo post threw a bomb in the cyberspace and the public was shocked. Soon Chen herself stepped out and declared that she had never released any report information and expressed great indignation at such identity fraud on Weibo. It has been confirmed that that particular Weibo account had been shut down several times due to the spread of misinformation about COVID-19.&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;That Radio France Internationale report on February 17 also mentioned the next key part of the Tye’s YouTube video. “Xiaobo Tao, a scholar from South China University of Technology, recently published a report that researchers at Wuhan Virus Laboratory were splashed with bat blood and urine, and then quarantined for 14 days.” HK01, another Hong Kong-based news site, &lt;a rel="noopener noreferrer" href="https://www.hk01.com/%E7%A4%BE%E6%9C%83%E6%96%B0%E8%81%9E/435123/%E6%AD%A6%E6%BC%A2%E8%82%BA%E7%82%8E-%E6%AD%A6%E6%BC%A2%E7%96%BE%E6%8E%A7%E7%A0%94%E7%A9%B6%E5%93%A1%E6%9B%BE%E8%A2%AB%E8%9D%99%E8%9D%A0%E8%A5%B2%E6%93%8A-%E5%85%A7%E5%9C%B0%E5%AD%B8%E8%80%85%E8%B3%AA%E7%96%91%E7%97%85%E6%AF%92%E6%B4%A9%E6%BC%8F"&gt;reported the same claim&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;This doctor’s name is spelled in English as both “Xiaobo Tao” and “Botao Xiao.” From 2011 to 2013, Botao Xiao was a &lt;a rel="noopener noreferrer" href="https://www2.scut.edu.cn/biology_en/2017/0614/c5951a169022/page.htm"&gt;postdoctoral research fellow at Harvard Medical School and Boston Children’s Hospital&lt;/a&gt;, and his &lt;a rel="noopener noreferrer" href="https://www2.scut.edu.cn/biology_en/2017/0614/c5951a169022/page.htm"&gt;biography is still on the web site of the South China University of Technology.&lt;/a&gt;&lt;/p&gt; &lt;p&gt;At some point in February, Botao Xiao posted a research paper onto ResearchGate.net, “&lt;a rel="noopener noreferrer" href="https://web.archive.org/web/20200214144447/https:/www.researchgate.net/publication/339070128_The_possible_origins_of_2019-nCoV_coronavirus"&gt;The Possible Origins of 2019-nCoV coronavirus.”&lt;/a&gt; He is listed as one author, along with Lei Xiao from Tian You Hospital, which is &lt;a rel="noopener noreferrer" href="https://www.wheto.gov.hk/filemanager/content/pdf/contact_information_public_private_hospitals_e.pdf"&gt;affiliated with the Wuhan University of Science and Technology&lt;/a&gt;. The paper was removed a short time after it was posted, but archived images of its pages can be found &lt;a rel="noopener noreferrer" href="https://web.archive.org/web/20200214144447/https:/www.researchgate.net/publication/339070128_The_possible_origins_of_2019-nCoV_coronavirus"&gt;here&lt;/a&gt; and &lt;a rel="noopener noreferrer" href="https://www.zerohedge.com/health/smoking-gun-chinese-scientist-finds-killer-coronavirus-probably-originated-laboratory-wuhan"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;The first conclusion of Botao Xiao’s paper is that the bats suspected of carrying the virus are extremely unlikely to be found naturally in the city, and despite the stories of “bat soup,” they conclude that bats were not sold at the market and were unlikely to be deliberately ingested.&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;The bats carrying CoV ZC45 were originally found in Yunnan or Zhejiang province, both of which were more than 900 kilometers away from the seafood market. Bats were normally found to live in caves and trees. But the seafood market is in a densely-populated district of Wuhan, a metropolitan [area] of ~15 million people. The probability was very low for the bats to fly to the market. According to municipal reports and the testimonies of 31 residents and 28 visitors, the bat was never a food source in the city, and no bat was traded in the market.&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;The U.S. Centers for Disease Control and Prevention and the World Health Organization &lt;a rel="noopener noreferrer" href="https://www.wsj.com/articles/scientists-link-china-virus-to-intersection-of-humans-and-wildlife-11580997600"&gt;could not confirm&lt;/a&gt; if bats were present at the market. Botao Xiao’s paper theorizes that the coronavirus originated from bats being used for research at either one of two research laboratories in Wuhan.&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;We screened the area around the seafood market and identified two laboratories conducting research on bat&amp;nbsp;coronavirus. Within ~ 280 meters from the market, there was the Wuhan Center for Disease Control &amp;amp; Prevention. WHCDC hosted animals in laboratories for research purpose, one of&amp;nbsp;which was specialized in pathogens collection and identification. In one of their studies, 155 bats including &lt;em&gt;Rhinolophus affinis&lt;/em&gt; were captured in Hubei province, and other 450 bats were captured in Zhejiang province. The expert in Collection was noted in the Author Contributions (JHT). Moreover, he was broadcasted for collecting viruses on nation-wide newspapers and websites in 2017 and 2019. He described that he was once by attacked by bats and the blood of a bat shot on his skin. He knew the extreme danger of the infection so he quarantined&amp;nbsp;himself for 14 days. In another accident, he quarantined himself again because bats peed on&amp;nbsp;him.&lt;/p&gt; &lt;p&gt;Surgery was performed on the caged animals and the tissue samples were collected for DNA and RNA extraction and sequencing. The tissue samples and contaminated trashes were source of pathogens.&amp;nbsp;They were only ~280 meters from the seafood market.&amp;nbsp;The WHCDC was also adjacent to the Union Hospital (Figure 1, bottom) where the first group of doctors were infected during this epidemic.&amp;nbsp;It is plausible that the virus leaked around and some of them contaminated the initial patients in this epidemic, though solid proofs are needed in future study.&lt;/p&gt; &lt;p&gt;The second laboratory was ~12 kilometers from the seafood market and belonged to Wuhan Institute of Virology, Chinese Academy of Sciences . . .&lt;/p&gt; &lt;p&gt;In summary, somebody was entangled with the evolution of 2019-nCoV coronavirus.&amp;nbsp;In addition to origins of natural recombination and intermediate host, the killer coronavirus probably originated from a laboratory in Wuhan. Safety level may need to be reinforced in high risk biohazardous laboratories. Regulations may be taken to relocate these laboratories far away from city center and other densely populated places.&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;However, Xiao has &lt;a rel="noopener noreferrer" href="https://www.wsj.com/articles/coronavirus-epidemic-draws-scrutiny-to-labs-handling-deadly-pathogens-11583349777"&gt;told the &lt;em&gt;Wall Street Journal&lt;/em&gt; that he has withdrawn his paper&lt;/a&gt;. “The speculation about the possible origins in the post was based on published papers and media, and was not supported by direct proofs,” he said in a brief email on February 26.&lt;/p&gt; &lt;p&gt;The bat researcher that Xiao’s report refers to is virologist Tian Junhua, who works at the Wuhan Centre for Disease Control. In 2004, the World Health Organization determined that an outbreak of the SARS virus had been caused by two separate leaks at the Chinese Institute of Virology in Beijing. The Chinese government said that the leaks were a result of “negligence” and the responsible officials had been punished.&lt;/p&gt; &lt;p&gt;In 2017, the Chinese state-owned Shanghai Media Group made a &lt;a rel="noopener noreferrer" href="https://www.youtube.com/watch?v=ovnUyTRMERI&amp;amp;feature=emb_logo"&gt;seven-minute documentary&lt;/a&gt; about Tian Junhua, entitled “Youth in the Wild: Invisible Defender.” Videographers followed Tian Junhua as he traveled deep into caves to collect bats. “Among all known creatures, the bats are rich with various viruses inside,” he says in Chinese. “You can find most viruses responsible for human diseases, like rabies virus, SARS, and Ebola. Accordingly, the caves frequented by bats became our main battlefields.” He emphasizes, “bats usually live in caves humans can hardly reach. Only in these places can we find the most ideal virus vector samples.”&lt;/p&gt; &lt;p&gt;One of his last statements on the video is: “In the past ten-plus years, we have visited every corner of Hubei Province. We explored dozens of undeveloped caves and studied more than 300 types of virus vectors. But I do hope these virus samples will only be preserved for scientific research and will never be used in real life. Because humans need not only the vaccines, but also the protection from the nature.”&lt;/p&gt; &lt;p&gt;The description of Tian Junhua’s self-isolation came from a May 2017 report by Xinhua News Agency, &lt;a rel="noopener noreferrer" href="https://www.jqknews.com/news/393098-Latest_overseas_research_bats_carrying_new_coronavirus_may_directly_infect_people.html"&gt;repeated by the Chinese news site JQKNews.com&lt;/a&gt;:&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;The environment for collecting bat samples is extremely bad. There is a stench in the bat cave. Bats carry a large number of viruses in their bodies. If they are not careful, they are at risk of infection. But Tian Junhua is not afraid to go to the mountain with his wife to catch Batman.&lt;/p&gt; &lt;p&gt;Tian Junhua summed up the experience that the most bats can be caught by using the sky cannon and pulling the net. But in the process of operation, Tian Junhua forgot to take protective measures. Bat urine dripped on him like raindrops from the top. If he was infected, he could not find any medicine. It was written in the report.&lt;/p&gt; &lt;p&gt;The wings of bats carry sharp claws. When the big bats are caught by bat tools, they can easily spray blood. Several times bat blood was sprayed directly on Tians skin, but he didn’t flinch at all. After returning home, Tian Junhua took the initiative to isolate for half a month. As long as the incubation period of 14 days does not occur, he will be lucky to escape, the report said.&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;Bat urine and blood can &lt;a rel="noopener noreferrer" href="https://www.sciencedaily.com/releases/2020/02/200210144854.htm"&gt;carry&lt;/a&gt; viruses. How likely is it that bat urine or blood got onto a researcher at either Wuhan Center for Disease Control &amp;amp; Prevention or the Wuhan Institute of Virology? Alternatively, what are the odds that some sort of medical waste or other material from the bats was not properly disposed of, and that was the initial transmission vector to a human being?&lt;/p&gt; &lt;p&gt;Virologists have been &lt;a rel="noopener noreferrer" href="https://www.livescience.com/coronavirus-not-human-made-in-lab.html"&gt;vehemently skeptical of the theory that COVID-19 was engineered or deliberately constructed in a laboratory&lt;/a&gt;; the director of the National Institutes of Health has &lt;a rel="noopener noreferrer" href="https://directorsblog.nih.gov/2020/03/26/genomic-research-points-to-natural-origin-of-covid-19/"&gt;written&lt;/a&gt;&amp;nbsp;that recent genomic research “debunks such claims by providing scientific evidence that this novel coronavirus arose naturally.” And none of the above is definitive proof that COVID-19 originated from a bat at either the Wuhan Center for Disease Control &amp;amp; Prevention or the Wuhan Institute of Virology. Definitive proof would require much broader access to information about what happened in those facilities in the time period before the epidemic in the city.&lt;/p&gt; &lt;p&gt;But it is a remarkable coincidence that the Wuhan Institute of Virology was researching Ebola and&amp;nbsp;SARS-associated coronaviruses in bats before the pandemic outbreak, and that in the month when Wuhan doctors were treating the first patients of COVID-19, the institute announced in a hiring notice that “a large number of new bat and rodent new viruses have been discovered and identified.” And the fact that the Chinese government spent six weeks insisting that COVID-19 could not be spread from person to person means that its denials about Wuhan laboratories cannot be accepted without independent verification.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://www.nationalreview.com/2020/04/coronavirus-china-trail-leading-back-to-wuhan-labs/amp/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sun, 12 Apr 2020 13:34:02 UT
      </pubDate>
      <guid>
        https://www.nationalreview.com/2020/04/coronavirus-china-trail-leading-back-to-wuhan-labs/amp/
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://news.ycombinator.com/item?id=22848450
      </link>
      <description>
        &lt;a href="https://news.ycombinator.com/item?id=22848450"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sun, 12 Apr 2020 16:38:20 UT
      </pubDate>
      <guid>
        https://news.ycombinator.com/item?id=22848450
      </guid>
    </item>
    <item>
      <title>
        The Devastating Decline of a Brilliant Young Coder | WIRED
      </title>
      <link>
        https://www.wired.com/story/lee-holloway-devastating-decline-brilliant-young-coder/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;&lt;div&gt;&lt;figure&gt;&lt;/figure&gt;&lt;p&gt;&lt;span&gt;On Friday, September&lt;/span&gt; 13, 2019, Matthew Prince and Michelle Zatlyn, cofounders of the San Francisco &lt;a href="https://www.wired.com/tag/cloudflare/"&gt;internet security firm Cloudflare&lt;/a&gt;, stood on a slim marble balcony overlooking the floor of the New York Stock Exchange. A cluster of the company's executives stood near Prince, ready to shout out a countdown. “Louder! Loud!” Prince urged them. “Five! Four! Three! …” At 9:30 am sharp, the founders reached down to ring the exchange's famous bell, kicking off the day's trading and offering their 10-year-old company on the public market. It was a rite of passage and also their payday, a moment that unlocked many millions of dollars in newfound wealth.&lt;/p&gt;&lt;p&gt;More than 100 employees and investors cheered from the trading floor below, their phones held high to capture the scene. Kristin Holloway, employee number 11, looked up at the balcony and snapped photos, then popped them into a text to her husband, Lee Holloway, the company's third cofounder. He was home in California. Every so often, a familiar face pushed through the throng to say to her, “Lee should be here.”&lt;/p&gt;&lt;p&gt;In Cloudflare's early years, Lee Holloway had been the resident genius, the guy who could focus for hours, code pouring from his fingertips while death metal blasted in his headphones. He was the master architect whose vision had guided what began as a literal sketch on a napkin into a tech giant with some 1,200 employees and 83,000 paying customers. He laid the groundwork for a system that now handles more than 10 percent of all internet requests and &lt;a href="https://www.wired.com/story/cloudflare-matthew-prince-wired25/"&gt;blocks billions of cyberthreats&lt;/a&gt; per day. Much of the architecture he dreamed up is still in place.&lt;/p&gt;&lt;p&gt;But some years before the IPO, his behavior began to change. He lost interest in his projects and coworkers. He stopped paying attention in meetings. His colleagues noticed he was growing increasingly rigid and belligerent, resisting others' ideas, and ignoring their feedback.&lt;/p&gt;&lt;p&gt;Lee's rudeness perplexed his old friends. He had built his life around Cloudflare, once vowing to not cut his hair until the startup's web traffic surpassed that of Yahoo. (It took a few short months, or about 4 inches of hair.) He had always been easygoing, happy to mentor his colleagues or hang out over lunch. At a birthday party for Zatlyn, he enchanted some children, regaling them with stories about the joys of coding. The idea of Lee picking fights simply didn't compute.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;p&gt;He was becoming erratic in other ways too. Some of his colleagues were surprised when Lee separated from his first wife and soon after paired up with a coworker. They figured his enormous success and wealth must have gone to his head. “All of us were just thinking he made a bunch of money, married his new girl,” Prince says. “He kind of reassessed his life and had just become a jerk.”&lt;/p&gt;&lt;p&gt;The people close to Lee felt tossed aside. They thought he'd chosen to shed his old life. In fact, it was anything but a choice. Over the next few years, Lee's personality would warp and twist even more, until he became almost unrecognizable to the people who knew him best. Rooting out the cause took years of detective work—and forced his family to confront the trickiest questions of selfhood.&lt;/p&gt;&lt;p&gt;On the floor of the stock exchange that September morning, Lee's younger brother Alaric weathered the morning in a state of low-grade panic. He snapped selfies with early employees and fired them off in texts to his brother. Alaric had never worked at Cloudflare, and he knew barely anyone there. But his dark hair flopped over his forehead with the same distinctive swoop as his brother's, and his long, tapering face had the same dark eyes and olive skin. “It was surreal,” Alaric says. “People kept looking at me like they knew me.”&lt;/p&gt;&lt;p&gt;At home with his parents in San Jose, Lee, 38, was restless. He paced the rooms and hallways of the 1,550-square-foot house, a loop he'd been tracing since he'd moved in with them two years earlier. He didn't speak. His parents had the TV on, and they called him over whenever Prince or Zatlyn appeared onscreen.&lt;/p&gt;&lt;p&gt;Later, he paused at the family's Roku to search YouTube for videos of Cloudflare. Then he resumed his circuit: walking the halls, buzzing his lips, snacking on cashews.&lt;/p&gt;&lt;figure&gt;&lt;figcaption&gt;&lt;span&gt;Lee Holloway spends time with his youngest son at home on California's Central Coast.&lt;/span&gt;&lt;span&gt;Artwork by Amy Friend; Photograph by Jack Bool&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;span&gt;What makes you&lt;/span&gt; &lt;em&gt;you&lt;/em&gt;? The question cuts to the core of who we are, the things that make us special in this universe. The converse of the question raises another kind of philosophical dilemma: If a person &lt;em&gt;isn't&lt;/em&gt; himself, who is he?&lt;/p&gt;&lt;p&gt;Countless philosophers have taken a swing at this elusive piñata. In the 17th century, John Locke pinned selfhood &lt;a href="https://www.wired.com/tag/memory/"&gt;on memory&lt;/a&gt;, using recollections as the thread connecting a person's past with their present. That holds some intuitive appeal: Memory, after all, is how most of us register our continued existence. But memory is unreliable. Writing in the 1970s, renowned philosopher Derek Parfit recast Locke's idea to argue that personhood emerges from a more complex view of psychological connectedness across time. He suggested that a host of mental phenomena—memories, intentions, beliefs, and so on—forge chains that bind us to our past selves. A person today has many of the same psychological states as that person a day ago. Yesterday's human enjoys similar overlap with an individual of two days prior. Each memory or belief is a chain that stretches back through time, holding a person together in the face of inevitable flux.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;p&gt;The gist, then, is that someone is “himself” because countless mental artifacts stay firm from one day to the next, anchoring that person's character over time. It's a less crisp definition than the old idea of a soul, offering no firm threshold where selfhood breaks down. It doesn't pinpoint, for example, how many psychological chains you can lose before you stop being yourself. &lt;a href="https://www.wired.com/tag/neuroscience/"&gt;Neuroscience&lt;/a&gt; also offers only a partial answer to the question of what makes you &lt;em&gt;you&lt;/em&gt;.&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.wired.com/tag/neural-networks/"&gt;Neural networks&lt;/a&gt; encode our mental artifacts, which together form the foundation of behavior. A stimulus enters the brain, and electrochemical signals swoosh through your neurons, culminating in an action: Hug a friend. Sit and brood. Tilt your head up at the sun and smile. Losing some brain cells here or there is no big deal; the networks are resilient enough to keep a person's behaviors and sense of self consistent.&lt;/p&gt;&lt;p&gt;But not always. Mess with the biological Jell-O in just the right ways and the structure of the self reveals its fragility.&lt;/p&gt;&lt;p&gt;Lee's personality had been consistent for decades—until it wasn't.&lt;/p&gt;&lt;p&gt;From an early age, he was a person who could visualize sprawling structures in his mind. Growing up in the 1990s in Cupertino, where his dad worked at Apple, Lee had early access to the latest computers, and he and his brother grew up bingeing on videogames. As a gamer, he was legendary among his friends for being able to read a complex situation, rapidly adjust strategies, and win match after match. And it wasn't just videogames. His childhood friend Justin Powell remembers Lee strolling into a middle school chess club tournament cold. He wasn't a member of the club, but he won the tournament anyway. Lee avoided becoming insufferable by channeling his wit into snarky commentary. “Watching a movie with him was like a version of &lt;em&gt;Mystery Science Theater 3000&lt;/em&gt;,” Powell says. “His very presence challenged you to keep up with him.”&lt;/p&gt;&lt;p&gt;Lee and his friends would cart their computers to each other's houses to play games together. He became curious about the machines themselves and started learning computer science, first in high school, then at a local community college and UC Santa Cruz, where an unlikely set of circumstances connected him with Matthew Prince.&lt;/p&gt;&lt;p&gt;Then a young entrepreneur, Prince was pursuing an idea for an antispam software tool when he encountered Arthur Keller, a UC Santa Cruz computer science professor. Keller and his students had already worked out a very similar concept. Prince and Keller agreed to share a patent, along with Keller's students. One of those students was Lee, and Prince hired him on the spot. “I had no idea this school project would turn into something much bigger,” Lee later said in a video interview with a group called Founderly.&lt;/p&gt;&lt;p&gt;Prince set up the company, Unspam Technologies, in Park City, Utah, about a mile from a cluster of slopes where he could indulge his passion for skiing. Lee moved into Prince's basement, at first working for free in exchange for food and housing. But Lee and the other Unspam engineers grew restless, and they started spinning up side projects, including one called Project Honey Pot, which tracked spammers as they crawled the web. That's all it did—it collected and published data on spammers, but it didn't do anything to stop them. Still, the project quickly amassed a loyal following.&lt;/p&gt;&lt;p&gt;In 2007, Prince left Utah to start business school at Harvard, and Lee moved to California to live with his girlfriend, Alexandra Carey. They'd known each other as undergrads, when she was a teaching assistant in his computer architecture class. Lee had goofed off in that class, once pranking the professor by scrawling childish notes on the transparencies of an overhead projector. Alexandra had been amused, but it wasn't until after college that a relationship bloomed. Living in different cities, they fell for each other while playing and chatting within a multiplayer videogame called &lt;em&gt;Savage&lt;/em&gt;. Now, with Prince leaving Utah, it seemed a natural time for Lee to join Alexandra. They married in 2008.&lt;/p&gt;&lt;div&gt;&lt;p&gt;&lt;span&gt;&lt;picture&gt;&lt;img sizes="100vw" srcset="https://media.wired.com/photos/5c098e5fd146d62d209935fc/master/w_775%2Cc_limit/Data-Breaches.png 775w, https://media.wired.com/photos/5c098e5fd146d62d209935fc/master/w_775%2Cc_limit/Data-Breaches.png 775w, https://media.wired.com/photos/5c098e5fd146d62d209935fc/master/w_768%2Cc_limit/Data-Breaches.png 768w, https://media.wired.com/photos/5c098e5fd146d62d209935fc/master/w_768%2Cc_limit/Data-Breaches.png 768w, https://media.wired.com/photos/5c098e5fd146d62d209935fc/master/w_640%2Cc_limit/Data-Breaches.png 640w" src="https://media.wired.com/photos/5c098e5fd146d62d209935fc/master/w_775%2Cc_limit/Data-Breaches.png" alt="This image may contain Electronics, Computer, and Pc"&gt;&lt;/picture&gt;&lt;/span&gt;&lt;/p&gt;&lt;div&gt;&lt;h3&gt;&lt;a href="https://www.wired.com/story/wired-guide-to-data-breaches"&gt;The WIRED Guide to Data Breaches&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Everything you ever wanted to know about Equifax, Mariott, and the problem with social security numbers.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Lee and Prince kept working at Unspam from their respective cities, but as Prince was wrapping up business school, Lee called to tell him he was considering other job offers. Prince countered with a new and rather audacious pitch: He and a classmate, Michelle Zatlyn, had hit on a startup idea they thought had potential. What if they expanded Project Honey Pot to not just recognize spammers and hackers but also fight back against them? The plan was to build out massive networks of servers around the world, convince website owners to route their traffic through those servers, and gather enough data to detect malicious requests amid the good ones. That might give them the tools they needed to stop even the world's biggest denial of service attack. But Prince needed a technical cofounder, and his about-to-defect employee was his top choice.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;p&gt;Prince talked for an hour straight. At the end of this spiel, Lee's side of the line was quiet. “I was like, ‘Are you still on the phone?’ ” Prince recalls. “Then he said, ‘Yeah, that'll work, let's do that.’ ” And that was it.&lt;/p&gt;&lt;p&gt;They whipped together a demo and in late 2009 raised a little over $2 million from two venture capital firms. It was enough to rent a converted two-bedroom apartment above a nail salon in Palo Alto, where they could start building their idea in earnest. Lee would show up every day wearing the same Calvin Klein jeans, leather jacket, and beanie on his head, and lugging a giant ThinkPad laptop nicknamed the Beast. “We had this shared vision,” Zatlyn says. “And Lee was the architect behind it. He just obsessed over it.”&lt;/p&gt;&lt;p&gt;The following year, Prince talked his way into TechCrunch Disrupt, an onstage competition for startups that can lead to big funding rounds. As Disrupt approached, Prince and Zatlyn grew nervous. Lee had missed a lot of days of work due to migraines. He didn't seem anywhere close to finishing a demo. When the day of the event arrived, Prince and Zatlyn walked onstage praying that the software they were presenting would actually work.&lt;/p&gt;&lt;p&gt;Prince started his pitch. “I'm Matthew Prince, this is Michelle Zatlyn, Lee Holloway is in the back of the room. We're the three cofounders of Cloudflare,” he boomed, stabbing the air with his finger as he spoke. In fact, Lee was backstage furiously fixing a long list of bugs. Prince held his breath when he ran the software, and, perhaps miraculously, it worked. It really worked. In the hour after he walked onstage, Cloudflare got 1,000 new customers, doubling in size.&lt;/p&gt;&lt;p&gt;They earned second place at Disrupt. “In the next couple of weeks, all these somewhat mythical VCs that we'd heard of and read about all called us,” Prince says. Under the onslaught of attention, Prince, Holloway, and one early hire, Sri Rao, rolled out constant fixes to hold the system together. “We launched in September, and in a month we had 10,000 websites on us,” Lee said in the Founderly interview. “If I'd known, we would have had eight data centers instead of five.”&lt;/p&gt;&lt;p&gt;With customers now multiplying, Ian Pye, another early engineer, hollowed out a toaster, tucked an Arduino board inside, and hooked it up to the network. Whenever a website signed up for Cloudflare services, the toaster sang a computerized tune Pye had composed. “It was horribly insecure,” Pye says. “But what were they going to do, hack our toaster?” The toaster lasted two weeks before the singing became too frequent and annoying and they unplugged it.&lt;/p&gt;&lt;p&gt;Cloudflare was growing fast, and Lee worked long days, often from home in Santa Cruz. He and Alexandra now had an infant son. During the first few months of the baby's life, Lee and Alexandra still made time to play videogames together. Alexandra remembers cracking up when Lee co-opted a nursing pillow to support his neck while he sat at his computer. Several of his old friends came over once a week to play the board game version of &lt;em&gt;Game of Thrones&lt;/em&gt; or the multiplayer videogame &lt;em&gt;Team Fortress 2&lt;/em&gt;. Alexandra focused on childcare, but she made sure the players had food. “I was doing it for him,” she says.&lt;/p&gt;&lt;p&gt;But around 2011 she started noticing that Lee was growing distant and forming some odd new habits. He spent a lot more time asleep, for one. After long workdays, she recalls, he'd walk in the door, take off his shoes, and immediately pass out on the floor. Their cat sometimes curled up and napped on his chest. His son, not yet 2, would clamber over him, trying and failing to rouse him to play.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;p&gt;When people invited them to parties, Lee refused to go. Alexandra started attending her friends' weddings by herself. It hurt her to see everyone else there as a couple, while the chair next to her sat empty. At home she'd cook dinner, and he'd look at it and say he was ordering pizza. On a weeklong family trip to France, he spent three days sleeping in the hotel room. “I'd say, ‘What's going on, we're going to these places—are you coming?’ ” Alexandra says. He'd insist he was too tired. She was finishing up a master's degree and shouldering the bulk of childcare; she, too, was tired. Alexandra begged him to go to therapy and cajoled him to play with their son, but he didn't engage. “After a while you think, well, this is the person I'm with,” she says.&lt;/p&gt;&lt;p&gt;In 2012, Alexandra told him she was taking an internship in Southern California, at NASA, and she was planning to take their son with her. She says his response was to calmly ask her to file for divorce before she left. “I was crushed. I said, ‘Maybe it doesn't have to be that way,’ ” she recalls. “He said, ‘No, no, it does.’ ”&lt;/p&gt;&lt;p&gt;When Lee told Prince and Zatlyn about his divorce, they both expressed their shock and gave their condolences, but Lee seemed to barely acknowledge the change. Prince and Zatlyn found his behavior tremendously odd. Still, they could rationalize it away. Relationships end for many reasons. Alexandra and Lee had married young, and both had worked long hours; perhaps they had grown apart. Besides, Lee was thriving at the company, so they didn't press.&lt;/p&gt;&lt;figure&gt;&lt;figcaption&gt;&lt;span&gt;Lee and his Cloudflare cofounders, Michelle Zatlyn and Matthew Prince, attend a holiday party in 2011.&lt;/span&gt;&lt;span&gt;Artwork by Amy Friend; Photograph courtesy of Cloudflare&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;span&gt;Some months after&lt;/span&gt; Alexandra moved away, Lee was sitting at a table with a couple of coworkers, including Kristin Tarr, who ran communications at Cloudflare. She'd just published a blog post describing how customers could enable &lt;a href="https://www.wired.com/story/two-factor-authentication-apps-authy-google-authenticator/"&gt;two-factor authentication&lt;/a&gt; on their accounts. He turned to her and said, “I read your blog post. It was really good.” A friend saw the interaction and teased her: Lee's flirting with you!&lt;/p&gt;&lt;p&gt;Lee and Kristin started spending time together. On one of their first dates, Lee took her to see his favorite metal band, the Swedish group Opeth. He revved up her interest in basketball, and they became Golden State Warriors junkies, watching every game. Kristin brought her own interests and energy into the relationship. She convinced him to trade in his old jeans-and-leather-jacket uniform for nicer shirts from Rag &amp;amp; Bone. He still wore beanies and hoodies, but now they came from Lululemon, where Kristin, a running freak, had a weekend gig as a brand ambassador. Sometimes he refused to get out of bed or retreated with a migraine; Kristin responded by signing him up for 5K races and coaxing him into training for them. Their coworkers marveled that their lead engineer had become so athletic.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;p&gt;Within a few months they had moved in together. She whisked him off on adventures, pulling him away from his computer and his videogames. They went tubing on the Truckee River. They played endless rounds of Bang! and Settlers of Catan with board-game-loving coworkers. Both nearsighted, they pretended they were moles, snuggled up in their burrow of a home. As their fortunes grew, they upgraded their digs, moving from Mole Hole to Mole Tower to Mole Terrace. They gave their friends animal identities too; Prince was a mongoose, while another executive was a swan. In May 2014, Kristin quit Cloudflare, and the next day they left for a vacation in Italy. They got engaged in Rome.&lt;/p&gt;&lt;p&gt;At work, Lee was still the star engineer. At the end of the summer of 2014, he took on a project that earned Cloudflare its first bout of internet fame: The company would help websites become encrypted for free. (It was not yet standard for company websites to be encrypted.)&lt;/p&gt;&lt;p&gt;Lee agreed to build the necessary software by the end of September. As the date approached, Prince asked for updates, but Lee blew him off. Then, on the day before the new system was supposed to go live, he pulled his hoodie down low on his head, put on his headphones, and sat down to bang out the code.&lt;/p&gt;&lt;p&gt;It was a Sunday, but the office was packed with people writing up the pending announcement or delivering coffee and food. Lee's coding, though, was the main event. “And he is typing, typing, and I don't think anyone dared to interrupt,” says John Graham-Cumming, then an engineer and now Cloudflare's chief technology officer. “His hoodie is on, he's in the zone, he's doing brain surgery on this thing.”&lt;/p&gt;&lt;p&gt;Then, late in the night, Lee stood up. He announced that he'd finished, and he wandered away. “It was like, bzhzhzhzh, type-type-type, ‘I'm done!’” Graham-Cumming says.&lt;/p&gt;&lt;p&gt;The other engineers immediately started reviewing his code. By the morning, the debugging process began for real. The gambit worked, and all of their existing customers suddenly got encryption. It was a proud moment. Says Graham-Cumming: “The size of the encrypted web doubled overnight.”&lt;/p&gt;&lt;figure&gt;&lt;figcaption&gt;&lt;span&gt;Lee and his wife, Kristin Holloway, on vacation in Rome in 2014. He proposed to her hours after this photo was taken.&lt;/span&gt;&lt;span&gt;Artwork by Amy Friend; Photograph courtesy of Kristin Holloway&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;span&gt;As Lee and&lt;/span&gt; Kristin planned their wedding, he decided to address a health problem he'd long ignored. Lee had been born with a heart issue, a leaky aortic valve, and some doctors thought it might be contributing to his migraines. “If you put your head on his chest, you could hear it,” Kristin says. “We called it his squishy heart.” Doctors were split on how serious his condition was, but in January 2015 a surgeon at Stanford insisted he get surgery right away. Lee went in for the six-hour procedure. As he lay on his hospital bed, he recorded a video to his son: “I love you! I'll see you soon with a brand-new heart.” He signed off with a smile and a wave. &lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;p&gt;Kristin now sees the surgery as a grim turning point. Lee's heart came out of the procedure stronger than ever, but mentally he never seemed to recover. He slept all the time. He'd taken a leave from work to have the surgery, but he extended his leave by a month, and then another, until he finally returned to the office in the late spring.&lt;/p&gt;&lt;p&gt;In June they got married, in Hawaii, in front of a crowd of friends and family. Kristin noticed that he seemed subdued. It was as if someone had washed the color out of his personality. Prince noticed too but chalked it up to a slow recovery from the surgery.&lt;/p&gt;&lt;p&gt;Not long after, Lee and Kristin took a trip to Europe, spending a few days in France, just as Lee and Alexandra had years earlier. Kristin had never been to Paris, and she was excited to explore the city. She ended up doing that on her own, while Lee again spent days asleep in their hotel room. “This is so weird,” Kristin remembers thinking. On their trip to Italy, he'd been eager to jump out of bed and visit museums and cafés, and walk around. She was puzzled, but between his migraines and his heart issue, there was always an explanation at hand.&lt;/p&gt;&lt;p&gt;At the office, he was becoming impossible to work with. He would lash out at people, and then in meetings he would zone out, openly playing games on his phone. During one meeting, Prince texted him: “Are you playing a game? People are noticing.” Then: “Not a great leadership signal.”&lt;/p&gt;&lt;p&gt;Prince and Zatlyn confronted him about his behavior, and Lee promised to do better. But his responses seemed rote. “I was like, why is he so disengaged? Why doesn't he seem to care?” Zatlyn recalls. They figured he must be burned out. Still, it hurt; it felt as if Lee was breaking up with them. She'd paid attention to the stories of startup founders who split up, the mess of their breakups sometimes dragging their companies down with them. “So I'm thinking, well, I guess that's what that feels like.”&lt;/p&gt;&lt;p&gt;They put their friend on an official performance-improvement plan. Over many weekly lunches, Zatlyn and Prince tried to get through to him. Nothing seemed to stick. “For several years,” Prince says, “the thing that was causing me just incredible anxiety was that I had all this loyalty to this person, but they're becoming a jerk.”&lt;/p&gt;&lt;p&gt;Eventually, in 2016, they decided Lee had to leave the company. “He kind of just said, yup, that sounds about right,” Prince says. They threw him a going-away party that July. Prince thanked him in a speech with tears streaming down his cheeks. Lee stood beside him with a beer in hand, a thin smile on his face.&lt;/p&gt;&lt;figure&gt;&lt;figcaption&gt;&lt;span&gt;Lee (center) gathered with his family for Thanksgiving in 2016, including (from left) his brother Alaric; his wife, Kristin; his older son; his mother, Kathy; his younger son; and his father, Rendon.&lt;/span&gt;&lt;span&gt;Artwork by Amy Friend; Photograph courtesy of Kristin Holloway&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;div&gt;&lt;p&gt;&lt;span&gt;Now that he&lt;/span&gt; wasn't working, Lee napped constantly. Kristin was seven months pregnant, and they agreed that after the baby's birth, Lee would be a stay-at-home dad, at least until he figured out what to do next. In the meantime, they would live off their savings and Kristin's salary from a new job at an ad tech firm. &lt;/p&gt;&lt;p&gt;Lee's actions, however, only grew more bizarre. He watched &lt;em&gt;Home Alone&lt;/em&gt; several nights a week. He wore his beanie all day, every day, pulling it lower and lower. When Kristin went into labor, he slept through most of the two-day ordeal, first slumbering at home and then resuming his nap at the hospital. When he woke up, he insisted, against Kristin's wishes, that she not get an epidural, which provoked a heated argument with one of the doctors. After their son was born, Kristin's mom says the doctor pulled her aside and commented that she'd never seen an expectant dad react that way. Kristin confronted him about his behavior later, and he promised her, “I'll do better.”&lt;/p&gt;&lt;p&gt;In those heady first months of parenthood, he failed. He took copious naps. Sometimes she'd cook him dinner, and he'd reject it and order a burrito. “I was like, what is happening?” Kristin says. “Everything felt so strange and out of control.”&lt;/p&gt;&lt;p&gt;Distraught at his lack of interest in their son, she decided to stage a moment of parenting normalcy. If she couldn't coax him into engaging with their child, she'd settle for its illusion. While Lee lay on the couch, she handed him the infant and grabbed her phone to record the scene. “You're standing, and you're so cute!” he coos as he props up the baby on his chest. “You're smiling and making a sound!” He dotes on his baby for less than a minute before handing him back to Kristin.&lt;/p&gt;&lt;p&gt;She kept trying to probe what was on his mind, and he kept replying, “I'll do better.” The repetitiveness of his answers struck her as robotic. It seemed of a piece with the way he now touched every tree he passed on their walks. “I think deep down I knew something was wrong,” Kristin says. She thought maybe he'd developed PTSD after the surgery or was struggling with a bout of depression. She'd been asking him to see a counselor with her. Finally, as she prepared to return to work, she threatened to leave him if he didn't. Lee agreed.&lt;/p&gt;&lt;p&gt;In the couples' therapy session, Kristin cried openly and talked about how her husband didn't seem to care about their new baby. “Lee was just blank,” she recalls, and she wondered why he wasn't reaching out to comfort her. Suddenly he stood up, announced he'd forgotten to return the therapist's office bathroom key, and wandered out of the room to put it back, returning a few minutes later.&lt;/p&gt;&lt;p&gt;When her maternity leave came to an end, Kristin hired a nanny and went back to work, but her alarm was mounting. She started booking appointments with every specialist she could think of while Lee spent his days in bed. “So I'm cajoling him out of bed, getting him into the car, making sure my son is out with his nanny, covering my own work somehow,” and then shuttling him from appointment to appointment. “It was like that for three months.”&lt;/p&gt;&lt;p&gt;In mid-March of 2017, Kristin and Lee went to a neurologist to get the results of an MRI. To Kristin, it seemed that the neurologist had initially been skeptical of her concerns. Lee was young, healthy, and communicative.&lt;/p&gt;&lt;p&gt;The MRI told a different story: There was atrophy in the brain inconsistent with the age of the patient, the neurologist reported to them. When Kristin asked her what that meant, she said Lee had a neurodegenerative disease of some kind, but they'd need to do more tests to get a specific diagnosis. One of their doctors suggested they go to the Memory and Aging Center at UC San Francisco.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;p&gt;That evening, Kristin started Googling. She pulled up the website of the Memory and Aging Center and started reading the descriptions of brain atrophy diseases. She knew immediately the neurologist was right. And in that moment she glimpsed the future: This was going to kill her husband.&lt;/p&gt;&lt;p&gt;She remembers sitting with her son that night. “Until that point, I'd held out hope. We have the resources, the best doctors, I can fly him to get him the best care,” she says. “But to be in this position where nothing can be done is just … It's so awful.” She quit her job the next day.&lt;/p&gt;&lt;p&gt;A few weeks later, Kristin and Lee, their parents, and Alaric all gathered in a conference room on the UCSF campus with a panel of experts. “Do you know why you're here?” the lead neurologist asked Lee. He replied, “My wife organized this.”&lt;/p&gt;&lt;p&gt;“Do you know that you're sick?”&lt;/p&gt;&lt;p&gt;“I get migraines a lot,” he said. “And I had heart surgery.”&lt;/p&gt;&lt;p&gt;The neurologists delivered their verdict: He appeared to have a textbook case of frontotemporal dementia—known by the shorthand FTD—specifically, the behavioral variant of that disease. It targets a network of brain regions sometimes described as underpinning one's sense of self. As the pathological process advanced, it was carving a different person out of Lee's raw substance.&lt;/p&gt;&lt;p&gt;The term &lt;em&gt;frontotemporal dementia&lt;/em&gt; refers to a cluster of neurodegenerative diseases that affect a person's behavior or speech while leaving memory largely intact, at least early on. Unlike Alzheimer's disease, FTD isn't well known. It is a rare disease, affecting roughly one in 5,000 people, though many of the neurologists who study it believe it is underdiagnosed. What is known is that for people under the age of 60, it is the most common form of dementia. Still, as a man in his thirties, Lee was unusually young to be afflicted. For some patients, one of several genetic mutations turns out to be the likely cause, and a subset of patients have a family history of neurodegenerative diseases. But nothing in the neurologists' investigations turned up even a hint as to why Lee had been struck down.&lt;/p&gt;&lt;p&gt;Regardless of cause, the prognosis is grim. There's no treatment. Lee's doctors warned that his symptoms would grow worse, and that over time he would likely stop talking, become immobile, and struggle to swallow, until eventually an infection or injury would likely turn fatal. The best the doctors could recommend was eating a balanced diet and getting exercise.&lt;/p&gt;&lt;p&gt;The family sat stunned at the neurologist's words. The brain scans were undeniable. On a wall-mounted screen the doctors showed a cross-section of the four lobes of Lee's brain. In a healthy brain, the familiar, loopy folds of tissue appear white or gray and push up against the edges of the cranium, filling every available space. Lee's brain looked nothing like that.&lt;/p&gt;&lt;p&gt;Black voids pocked his frontal lobe, areas where brain tissue had gone dead. Seeing it, Kristin gasped. “There were huge dark spots in his brain,” Alaric says. “That's what … that made it concrete.”&lt;/p&gt;&lt;p&gt;Lee received his death sentence with pure calm. While his family cried beside him, he complimented a doctor for having a nice wedding ring. At that, Alaric looked at him and realized for the first time the depths of his brother's transformation.&lt;/p&gt;&lt;figure&gt;&lt;figcaption&gt;&lt;span&gt;Lee still takes part in some activities with his wife and children, including working on jigsaw puzzles.&lt;/span&gt;&lt;span&gt;Artwork by Amy Friend; Photograph by Jack Bool&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;div&gt;&lt;p&gt;&lt;span&gt;Few disorders ravage&lt;/span&gt; their victims' selfhood with the intensity of the behavioral variant of FTD. It takes all the things that define a person—hobbies and interests, the desire to connect with others, everyday habits—and shreds them. Over time, the disease transforms its victims into someone unrecognizable, a person with all the same memories but an alarming new set of behaviors. Then it hollows them out and shaves away their mobility, language, and recollections. &lt;/p&gt;&lt;p&gt;Because it is relatively unknown and can resemble Alzheimer's or a psychiatric disorder, FTD is often hard to diagnose. As in Lee's case, the early stages can be misinterpreted as signs of nothing more serious than a midlife crisis. Patients can spend years shuttling to marriage counselors, human resources departments, therapists, and psychologists. By the time patients learn the name of their disorder, they are often unable to grasp the gravity of their situation.&lt;/p&gt;&lt;p&gt;Depending on where in the brain the disease first strikes, the symptoms can be jarring. Some sufferers become deeply religious, undergo wild shifts in political identity, or have a sharp change in interests or style of dress. One stockbroker, for example, started wearing all-lavender clothes and developed a sudden obsession with painting. As his disease progressed, he engaged in petty theft and swam nude in public pools.&lt;/p&gt;&lt;p&gt;The loss of embarrassment is common among some FTD patients, leading them to act in ways that might have horrified their former selves. Urinating in public, shoplifting, running red lights, making inappropriate sexual advances, digging through trash cans for food—all can be symptoms. Patients can lose the ability to evaluate social situations too, making them hard to interact with. In one extreme case, a patient's wife nearly severed her finger while using a pair of borrowed gardening shears. She shrieked to her husband, who had FTD, that she needed to go to the hospital. He replied by saying they had to first return the shears to their neighbor.&lt;/p&gt;&lt;p&gt;These behaviors all arise because neurons are dying off in the frontal and temporal lobes, two large areas of the brain. Particularly vulnerable within these broad continents is a dispersed set of regions known as the salience network, which sifts through a barrage of sensations, memories, and emotions to focus a person's attention on what matters most in that moment. When this network breaks down, people may fail to grasp the emotional impact of their actions on others. “Emotions drive most choices in life, so if you don't have those systems, you're not the same person,” says Virginia Sturm, a neuropsychologist and neuroscientist at UCSF. “There are no tight anchors to your sense of self anymore, and the boundaries of self become loose.”&lt;/p&gt;&lt;p&gt;Eventually, many FTD patients end up as apathetic as Lee, the light of their personhood dimmed to a pale flicker. Apathy also leads to incontinence, as patients lose the desire to take even basic care of themselves.&lt;/p&gt;&lt;p&gt;In the months after Lee's diagnosis, Kristin spent as much time with her husband as she could. His decline had been steady so far, and she realized he would only slip further away. They spent the summer of 2017 going on long walks together. They took family trips. She found herself scrutinizing every interaction: Was that his last joke? His last laugh? His last hug? She never knew. He started leaving the apartment without saying anything, and she'd have to grab the baby and chase him down San Francisco's busy streets.&lt;/p&gt;&lt;p&gt;Lee was quickly becoming unmanageable. Once the baby learned to crawl, Kristin installed a gate at the top of the stairs to keep him from falling down the steps. But whenever Lee walked past the gate, he'd reach down and unlatch it. He started blasting music videos in the living room at 11 o'clock at night, despite the small child asleep in an adjacent room. Sometimes he'd stay up all night, walking around in circles. Kristin struggled to take care of her son while making sure her husband didn't duck out the door unnoticed.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;p&gt;She and Lee's parents grew increasingly worried he could get lost or mugged or wander into traffic. His parents, who are in their sixties, volunteered to take over Lee's care, and in the fall of 2017, Kristin agreed it was time for him to move in with them in San Jose while they figured out a long-term plan. “It's too hard to keep him safe in San Francisco,” his father, Rendon Holloway, says. “He has to have his walks.” Kristin was working full-time in San Francisco; she and their son stayed behind. Lee would visit them a few days a month.&lt;/p&gt;&lt;p&gt;Kristin and their son spent many of their weekends in San Jose. In the first year, his mother, Kathy Holloway, recalls, when Lee saw the two of them arrive, “he always ran to his bedroom and grabbed his suitcase.” He would say, “I want to go back to San Francisco.”&lt;/p&gt;&lt;p&gt;Lee often tried to leave the house. His parents eventually added an alarm that chimed loudly whenever the front door opened. They hid his shoes. He'd hunt for them, and if he found them he'd lace up and bolt out the door.&lt;/p&gt;&lt;p&gt;When he wasn't trying to escape, Lee settled into a rhythm of scrolling through family photos on his phone, playing &lt;em&gt;Mario Kart&lt;/em&gt;, or watching YouTube videos, all in roughly 30-second spurts. He'd search YouTube for “Cloudflare,” “Kristin Holloway,” or his favorite bands and watch snippets of their music videos. Then he'd pace heavily around the house, loud footfalls thudding at all hours of the day. Kathy lined the floors with rubber mats to deaden the sound.&lt;/p&gt;&lt;p&gt;As the months passed, he spoke less and less. In one video from July 2018, Lee has his arm wrapped around his son while he reads him a bedtime book. Lee mumbles the words unevenly, without inflection, and hurries through the paperboard pages.&lt;/p&gt;&lt;p&gt;From behind her phone's camera lens, Kristin saw that this might be the last bedtime story he read their son. Still, she kept recording, and she ended it with a “Good job!” to them both.&lt;/p&gt;&lt;p&gt;Conversations soon became impossible. Lee started chattering in repetitive, unceasing loops. He would tell Kristin: “We met at Cloudflare. We got engaged in Rome. We got married in Maui, Hawaii.” He repeated it hundreds of times a day. Then the loops got shorter, more cryptic. He spoke fewer sentences, instead muttering sequences of numbers or letters.&lt;/p&gt;&lt;p&gt;In September 2018, Prince and Zatlyn went to visit him while he was on one of his trips to San Francisco. Seeing Lee for the first time in many months, they thought he looked like a zombie, trooping aimlessly from room to room with empty eyes. At intervals during their visit he'd sit down in the living room, turn on the TV, and flip through the channels, never watching any one thing for more than a minute. Then he'd wander off again, all the while whispering numbers: 1 2 3 4 5 6 7. 1 2 3 4 5 6 7.&lt;/p&gt;&lt;p&gt;He was both present and absent, a combination that kept his family on edge. When I visited his parents' house in April 2019, Kristin and Alaric were also there for the day. We were clustered in the front hallway while his mother slipped into the kitchen to make tea. Lee, dressed in a Henley shirt and sweatpants, emerged from the back of the house. He stood tall and silent, and his arms hung heavily at his sides. He looked at Kristin, expressionless, as she introduced me and explained I'd come to write a story about his life. He turned to wander into the living room and kitchen, where he leaned his elbows on the counter and reached a hand out to his mother, wordlessly requesting a snack. Then Kristin and Alaric went out with him for a walk, while I sat down with his parents.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;p&gt;As we sat in the family's living room, Kathy described caring for her son, even as he grew increasingly distant. She misses the warmth in their daily interactions. “He used to come give me a hug and say, ‘I love you, Mom,’ ” she says. “No more.”&lt;/p&gt;&lt;p&gt;Kathy is not the only one struggling to accept Lee for who he is—whoever he is. Managing his decline has strained the family, and his relatives sometimes clash over who should take care of him and how he should live. Kristin has spent many hours in therapy working through her grief and her feelings of guilt over deciding to live apart from Lee. She says she has felt alone in their relationship for years, and she's determined to give her son a relatively normal childhood. Alexandra, Lee's first wife, wonders whether her marriage fell apart because of the disease or their incompatibility. Was Lee simply someone who could sleep through European vacations and reject a homemade meal, or were those early incidents symptoms?&lt;/p&gt;&lt;p&gt;There's no way to know for sure. Who was he then? Who is he now? How tightly knit is any person's selfhood across time? The philosopher Derek Parfit might have approached the issue by asking how many psychological chains bind Lee today to Lee in the past. His links are more tenuous than most people's. But they persist.&lt;/p&gt;&lt;p&gt;In January 2019, Kristin was driving in a grocery store parking lot when her phone rang. She glimpsed the screen and froze. Lee was calling. There on the screen was his face, an old photo from when they had just started dating. She hadn't seen the photo in almost two years—it had been that long since he had called her.&lt;/p&gt;&lt;p&gt;She answered, and the words tumbled out of her. “Baby, I love you so much, I miss you,” she cried. “Are you OK? Do you need anything?” He didn't say anything, but she could hear his breathing on the other end.&lt;/p&gt;&lt;p&gt;He hung up.&lt;/p&gt;&lt;p&gt;In that instant she realized how desperately she missed hearing his voice. “I'd been in this process of losing him, then to have this moment of him reaching out from wherever he is,” she says. “It blew my mind.”&lt;/p&gt;&lt;p&gt;The Cloudflare IPO in September raised $525 million. Lee, as one of the founders, suddenly became a whole lot richer. With his financial future now secure, Kristin set in motion the plan for his long-term care. She bought a 5,000-square-foot house on an acre of California's Central Coast, a spot they chose in the hope that his father, Rendon, could walk with him along the shore. She worked with a landscape architect to tailor the outdoor space to Lee's needs. There are zigzagging paths on which Lee can roam and a fence to keep him safely inside. Nontoxic plants only. No nut or fruit trees allowed; those could be choking hazards once he develops difficulty swallowing, as his doctors anticipate he will.&lt;/p&gt;&lt;p&gt;Lee and his parents have moved there, and he has full-time care assistance too. Kristin shipped some of the furniture they'd bought together to make the house feel more familiar to him, and she blanketed a wall in family photos. She, Alexandra, and their sons visit occasionally.&lt;/p&gt;&lt;p&gt;Kristin hopes she has designed the perfect environment. Most FTD patients aren't so fortunate, if you can call it that, to wind down their lives on a personalized estate with a staff dedicated to keeping them safe and calm. Their families don't always have a choice in how involved they want to be. Still, all the money in the world can't answer the question of who, really, is living in that house.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;p&gt;On rare occasions, Lee still surprises his parents with an affectionate pat on the back. He calls people from time to time, even if he never speaks a word. An old colleague recently saw that he'd liked a post on LinkedIn. However diminished, a person lingers in the shattered roadways of his mind.&lt;/p&gt;&lt;p&gt;Some months ago, Lee sent Kristin a series of text messages. In them were photos she'd shared with him earlier: she and their son on Halloween, a trip to the park, Christmastime. At the end, he'd typed the words: “the love.”&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;strong&gt;SANDRA UPSON&lt;/strong&gt; &lt;em&gt;&lt;a rel="nofollow noopener" href="http://www.twitter.com/sandraupson" data-event-click="{&amp;quot;element&amp;quot;:&amp;quot;ExternalLink&amp;quot;,&amp;quot;outgoingURL&amp;quot;:&amp;quot;http://www.twitter.com/sandraupson&amp;quot;}"&gt;(@sandraupson)&lt;/a&gt; is a senior editor at&lt;/em&gt; WIRED. &lt;em&gt;This is her first feature story for the magazine&lt;/em&gt;.&lt;/p&gt;&lt;p&gt;&lt;em&gt;This article appears in the May issue. &lt;a href="https://subscribe.wired.com/subscribe/splits/wired/WIR_Edit_Hardcoded?source=ArticleEnd_CMlink"&gt;Subscribe now&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;Let us know what you think about this article. Submit a letter to the editor at &lt;a href="mailto:mail@wired.com"&gt;mail@wired.com&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;More Great WIRED Stories&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Build cities for &lt;a href="https://www.wired.com/story/cities-without-cars-san-francisco-jeff-tumlin/?itm_campaign=BottomRelatedStories_Sections_1&amp;amp;itm_content=footer-recirc"&gt;bikes, buses, and feet&lt;/a&gt;—not cars&lt;/li&gt;&lt;li&gt;A one-time poultry farmer invents &lt;a href="https://www.wired.com/story/refrigeration-global-warming-food-preservation/?itm_campaign=BottomRelatedStories_Sections_1&amp;amp;itm_content=footer-recirc"&gt;the future of refrigeration&lt;/a&gt;&lt;/li&gt;&lt;li&gt;OK, Zoomer! How to become a &lt;a href="https://www.wired.com/story/tips-for-using-zoom/?itm_campaign=BottomRelatedStories_Sections_1&amp;amp;itm_content=footer-recirc"&gt;videoconferencing power user&lt;/a&gt;&lt;/li&gt;&lt;li&gt;Disney+ should offer &lt;a href="https://www.wired.com/story/put-original-star-wars-on-disney-plus/?itm_campaign=BottomRelatedStories_Sections_1&amp;amp;itm_content=footer-recirc"&gt;the Star Wars original cuts&lt;/a&gt;—all of them&lt;/li&gt;&lt;li&gt;Why don’t we just &lt;a href="https://www.wired.com/story/why-dont-we-just-ban-targeted-advertising/?itm_campaign=BottomRelatedStories_Sections_1&amp;amp;itm_content=footer-recirc"&gt;ban targeted advertising&lt;/a&gt;?&lt;/li&gt;&lt;li&gt;👁 Why can't AI &lt;a href="https://www.wired.com/story/ai-smart-cant-grasp-cause-effect/?itm_campaign=BottomRelatedStories_Sections_1&amp;amp;itm_content=footer-recirc"&gt;grasp cause and effect&lt;/a&gt;? Plus: &lt;a href="https://www.wired.com/category/business/artificial-intelligence/?itm_campaign=BottomRelatedStories_Sections_1&amp;amp;itm_content=footer-recirc"&gt;Get the latest AI news&lt;/a&gt;&lt;/li&gt;&lt;li&gt;🏃🏽‍♀️ Want the best tools to get healthy? Check out our Gear team’s picks for the &lt;a href="https://www.wired.com/gallery/best-fitness-tracker/?itm_campaign=BottomRelatedStories&amp;amp;itm_content=footer-recirc"&gt;best fitness trackers&lt;/a&gt;, &lt;a href="https://www.wired.com/gallery/best-running-gear/?itm_campaign=BottomRelatedStories&amp;amp;itm_content=footer-recirc"&gt;running gear&lt;/a&gt; (including &lt;a href="https://wired.com/gallery/best-trail-running-shoes-round-up/?itm_campaign=BottomRelatedStories&amp;amp;itm_content=footer-recirc"&gt;shoes&lt;/a&gt; and &lt;a href="https://www.wired.com/gallery/best-running-socks/?itm_campaign=BottomRelatedStories&amp;amp;itm_content=footer-recirc"&gt;socks&lt;/a&gt;), and &lt;a href="https://www.wired.com/gallery/best-headphones-under-100/?itm_campaign=BottomRelatedStories&amp;amp;itm_content=footer-recirc"&gt;best headphones&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;a href="https://www.wired.com/story/lee-holloway-devastating-decline-brilliant-young-coder/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Wed, 15 Apr 2020 11:36:36 UT
      </pubDate>
      <guid>
        https://www.wired.com/story/lee-holloway-devastating-decline-brilliant-young-coder/
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://medium.com/better-marketing/10-skills-to-becoming-a-millionaire-in-5-years-or-less-e16b8b20500c
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;&lt;div&gt;&lt;p id="0dbe"&gt;It doesn’t matter where you currently are in your financial situation — whether just starting out or already making lots of money.&lt;/p&gt;&lt;p id="a5ba"&gt;Most people, no matter what their income, are treading water. As a person’s income rises, so does their spending.&lt;/p&gt;&lt;p id="dbd7"&gt;Few people understand how to continually increase their income, lifestyle, and joy at the same time.&lt;/p&gt;&lt;p id="c74b"&gt;In this article, you will learn:&lt;/p&gt;&lt;ul&gt;&lt;li id="0536"&gt;How to become wealthy&lt;/li&gt;&lt;li id="c904"&gt;How to build a life that continually increases your level of confidence and joy&lt;/li&gt;&lt;li id="a3b5"&gt;How to continually expand, learn, grow, and succeed as a person&lt;/li&gt;&lt;li id="3b36"&gt;How to develop mentorships, friendships, and strategic partnerships with nearly anyone you want&lt;/li&gt;&lt;/ul&gt;&lt;p id="39ab"&gt;If these things are not interesting to you, then this article was not written for you.&lt;/p&gt;&lt;p id="5365"&gt;Here’s how it works.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;h2 id="484b"&gt;1. Create a wealth vision&lt;/h2&gt;&lt;blockquote&gt;&lt;p id="bed5"&gt;“When riches begin to come they come so quickly, in such great abundance, that one wonders where they have been hiding during all those lean years.” — Napoleon Hill&lt;/p&gt;&lt;/blockquote&gt;&lt;p id="e838"&gt;St&lt;span id="rmm"&gt;e&lt;/span&gt;p one of becoming financially successful is to actually create a vision for yourself financially. Einstein said that imagination is more important than knowledge. Arden said creativity is more important than experience.&lt;/p&gt;&lt;p id="a001"&gt;How much imagination do you have for your future?&lt;/p&gt;&lt;p id="17bb"&gt;Do you see huge potential and possibility for your life?&lt;/p&gt;&lt;p id="58bc"&gt;Or, do you see a pretty average life?&lt;/p&gt;&lt;p id="cfad"&gt;Creating a vision is an iterative process. You don’t just create a vision once and then never look at it again.&lt;/p&gt;&lt;p id="8dff"&gt;You continually create and write your vision — every single day.&lt;/p&gt;&lt;p id="2861"&gt;Look at any area of your life in which you’re doing well, and you’ll find it’s because you see something beyond what you currently have. By that same token, look at any area of your life that isn’t exceptional, and you’ll find that you don’t see something beyond what you currently have.&lt;/p&gt;&lt;p id="2f81"&gt;Most people are living in and repeating the past.&lt;/p&gt;&lt;p id="3668"&gt;Having a vision is focused on the future.&lt;/p&gt;&lt;p id="0e5f"&gt;Your life and behavior immediately shift when you begin imagining a different future and stridently strive for it.&lt;/p&gt;&lt;p id="77f6"&gt;In order to do this, you must obliterate your need for consistency. From a psychological perspective, people generally feel the need to be viewed by others as consistent. This need causes people to retain behavioral patterns, environments, and relationships that are ultimately destructive and unsatisfying for far too long.&lt;/p&gt;&lt;p id="0326"&gt;Instead, you could abandon your need to be viewed as consistent by others. You can be OK with the fact that you’re not perfect. You can be OK with messing up. You can be OK with having values you stand for and goals you want to accomplish, regardless of what those around you think.&lt;/p&gt;&lt;p id="5a49"&gt;Having a vision for your life means you no longer care what other people think of you. It means you’re ready to begin actually living the life you want. It means you’re no longer going to just go with the flow, as you have for most of your life. It means that regardless of what your parents, peers, and social environment have presented to you thus far, you’re going to create the life you want.&lt;/p&gt;&lt;p id="7fd4"&gt;The more detailed your vision the better. The more quantifiable your vision the better.&lt;/p&gt;&lt;p id="514a"&gt;Your brain really loves numbers and events. These are tangible. Thus, your vision should center around specific numbers and key events.&lt;/p&gt;&lt;p id="aba9"&gt;For example:&lt;/p&gt;&lt;ul&gt;&lt;li id="8226"&gt;“I will be making $1,000,000/year by January 1, 2022.”&lt;/li&gt;&lt;li id="e810"&gt;“I will get a check for over $100,000 by October 2020.”&lt;/li&gt;&lt;li id="9b64"&gt;“I will take a six week vacation in Thailand in the next six months.”&lt;/li&gt;&lt;/ul&gt;&lt;p id="750d"&gt;Quantify it.&lt;/p&gt;&lt;p id="c86c"&gt;Measure it.&lt;/p&gt;&lt;p id="0763"&gt;Get excited by it.&lt;/p&gt;&lt;p id="b6e5"&gt;The more detailed the vision in your mind, the more believable it will be to you.&lt;/p&gt;&lt;p id="37f8"&gt;It’s OK if you don’t know&lt;em&gt; exactly &lt;/em&gt;what you want right now. Having more money, creating powerful experiences, and continually growing as a person are all goals that will push you in the right direction.&lt;/p&gt;&lt;p id="0fb5"&gt;As you build confidence through successive, small wins over time, your vision and imagination will expand.&lt;/p&gt;&lt;p id="20b2"&gt;Thus, in order for your vision to become clarified and congruent with your values and genuine desires, you’ll need to start building confidence.&lt;/p&gt;&lt;p id="30cb"&gt;That’s where the next step comes in.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;h2 id="8888"&gt;2. Develop a 90-day system for measuring progress/future pacing&lt;/h2&gt;&lt;p id="c810"&gt;The following are four questions Dan Sullivan, founder of Strategic Coach, has his clients answer every 90 days:&lt;/p&gt;&lt;blockquote&gt;&lt;p id="a1ae"&gt;&lt;strong&gt;“Winning Achievements?&lt;/strong&gt; Looking back over the past quarter, what are the things that make you the proudest about what you have achieved?”&lt;/p&gt;&lt;p id="a5b7"&gt;&lt;strong&gt;“What’s Hot?&lt;/strong&gt; When you look at everything that’s going on today, which areas of focus and progress are making you the most confident?”&lt;/p&gt;&lt;p id="2099"&gt;&lt;strong&gt;“Bigger and Better&lt;/strong&gt;? Now, looking ahead at the next quarter, what new things are giving you the greatest sense of excitement?”&lt;/p&gt;&lt;p id="097c"&gt;“What are the five new ‘jumps’ you can now achieve that will make your next 90 days a great quarter regardless of what else happens?”&lt;/p&gt;&lt;/blockquote&gt;&lt;p id="e4a7"&gt;Every 90 days, you want to review the previous 90 days and then set measurable and challenging goals for the next 90 days.&lt;/p&gt;&lt;p id="08c7"&gt;In the book “The Art of Learning,” Josh Waitzkin said:&lt;/p&gt;&lt;blockquote&gt;&lt;p id="66c0"&gt;“Short-term goals can be useful developmental tools if they are balanced within a nurturing long-term philosophy. Too much sheltering from results can be stunting.”&lt;/p&gt;&lt;/blockquote&gt;&lt;p id="ddbb"&gt;Short-term goals are how you build progress. Working toward a timeline is crucial for productivity. Focusing on only a few key milestones each 90 days is how you build momentum.&lt;/p&gt;&lt;p id="5c1b"&gt;Every 90 days, when you look back on the previous 90 days, you want a system for tracking your learning and progress. You want to get out of your routine environment and take a recovery break. Tim Ferriss calls this mini-retirements.&lt;/p&gt;&lt;p id="ece8"&gt;Every 90 days, you want to take a few days off. You want to get away where you can ponder, reflect, think, visualize, strategize, and play.&lt;/p&gt;&lt;p id="a44c"&gt;During this recovery session, you want to pull out your journal and take time to reflect on the previous 90 days.&lt;/p&gt;&lt;p id="9001"&gt;What went well?&lt;/p&gt;&lt;p id="9bbb"&gt;What were your key wins?&lt;/p&gt;&lt;p id="d621"&gt;What did you learn?&lt;/p&gt;&lt;p id="fab3"&gt;What has you most excited?&lt;/p&gt;&lt;p id="5477"&gt;Where do you need to pivot?&lt;/p&gt;&lt;p id="8fc1"&gt;Given what you’ve done and what you’ve learned, what do you want to do in the next 90 days?&lt;/p&gt;&lt;p id="7bb4"&gt;What two to five jumps or wins will make the biggest difference toward your ideal vision?&lt;/p&gt;&lt;p id="0ef0"&gt;Every 90 days, when you review your progress, you could be&lt;em&gt; increasing your confidence&lt;/em&gt;, because confidence comes from watching yourself succeed.&lt;/p&gt;&lt;p id="a285"&gt;Very few people truly take time to reflect on what they’ve actually done. We’re very good at seeing where we’re coming up short. We are less reflective of where we’ve succeeded.&lt;/p&gt;&lt;p id="c725"&gt;Chances are, you don’t even remember what you ate for lunch three days ago.&lt;/p&gt;&lt;p id="c88d"&gt;Chances are, you don’t recognize all of the good things you’ve done in the past 90 days. However, you can train your brain to notice, focus, and pay attention to the progress you’re making. When you begin seeing progress, you’ll start to feel excited.&lt;/p&gt;&lt;p id="386c"&gt;These feelings are very important.&lt;/p&gt;&lt;p id="a218"&gt;Feeling movement and momentum gives confidence.&lt;/p&gt;&lt;p id="25ed"&gt;Confidence is the bedrock of imagination, action, and power.&lt;/p&gt;&lt;p id="8e1d"&gt;Want more confidence?&lt;/p&gt;&lt;p id="36ff"&gt;Start setting short-term goals (every 30–90 days), track your progress, count your wins, recover, reset, and start again.&lt;/p&gt;&lt;p id="9cab"&gt;When you have a big vision, you don’t need to make HUGE progress every day. You only need to take a step or two forward daily. You then track that progress and watch as the compounding effects take over.&lt;/p&gt;&lt;p id="8570"&gt;Every 90 days, track the key areas of your life.&lt;/p&gt;&lt;p id="39f8"&gt;Track your money.&lt;/p&gt;&lt;p id="b29f"&gt;Track your health.&lt;/p&gt;&lt;p id="cf17"&gt;Track your time.&lt;/p&gt;&lt;p id="c7bb"&gt;Track the progress in the areas you want to succeed.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;h2 id="bcff"&gt;3. Develop a daily routine to live in a flow/peak state&lt;/h2&gt;&lt;blockquote&gt;&lt;p id="3a82"&gt;“Assume the feeling of your wish fulfilled.” — Neville Goddard&lt;/p&gt;&lt;/blockquote&gt;&lt;p id="f92e"&gt;Alright — so you’ve created a big picture vision that inspires you.&lt;/p&gt;&lt;p id="672c"&gt;You’ve also set 90-day short-term goals to help you build confidence and keep you progressing on that path.&lt;/p&gt;&lt;p id="a618"&gt;Now, you need a daily routine to keep yourself in flow.&lt;/p&gt;&lt;p id="3bae"&gt;If you can get yourself into a flow-state every single day, and live in and operate from that flow state, you’re going to feel really good.&lt;/p&gt;&lt;p id="a695"&gt;It is your responsibility to organize your life so you can be in flow as much as possible. In positive psychology, a flow state, also known as being in the zone, is the mental state in which you are fully immersed in a feeling of energized focus, full involvement, and enjoyment.&lt;/p&gt;&lt;p id="de8f"&gt;In essence, flow is characterized by complete absorption in what one does, and a resulting loss in one’s sense of space and time.&lt;/p&gt;&lt;p id="ce54"&gt;That’s a great way to live.&lt;/p&gt;&lt;p id="e159"&gt;Flow creates high performance.&lt;/p&gt;&lt;p id="4ea3"&gt;High performance creates confidence.&lt;/p&gt;&lt;p id="8ec3"&gt;Confidence creates imagination and excitement.&lt;/p&gt;&lt;p id="10f3"&gt;Imagination and excitement lead you to thinking bigger and differently about yourself and your life.&lt;/p&gt;&lt;p id="6464"&gt;With that in mind, it’s key to look at why most people are not in flow most of the time. Not surprisingly, it starts first thing in the morning. Momentum is activated with the first decision of your day. Rather than proactively putting themselves into a flow state, most people put themselves into an unconsciously reactive state.&lt;/p&gt;&lt;p id="7111"&gt;People are not the product of habits, they are the product of environments (see point four below). According to Stanford psychologist and behavior expert, BJ Fogg, design beats willpower. Design is about how you’ve set things up. Most people have not designed their environment for flow. Instead, most people’s environment and life have been set up for continual distraction, which is the opposite of flow.&lt;/p&gt;&lt;p id="8bfa"&gt;Flow is something that must be designed for.&lt;/p&gt;&lt;p id="b711"&gt;You have to&lt;em&gt; decide&lt;/em&gt; to live in flow. You have to commit to it. The reason flow is so commonplace in extreme sports is because extreme sports require a great deal of commitment, risk, and focus.&lt;/p&gt;&lt;p id="e821"&gt;If a motocross rider loses focus while trying a back flip over a 100-foot dirt jump, they could die. Therefore, the situation evokes deep flow.&lt;/p&gt;&lt;p id="8dc4"&gt;Flow comes by not over-thinking it.&lt;/p&gt;&lt;p id="9f14"&gt;Flow comes when you just let it happen.&lt;/p&gt;&lt;p id="bd58"&gt;For example, when I’m writing a blog post, my best writing is when I stop thinking altogether. I just let it rip.&lt;/p&gt;&lt;p id="8351"&gt;That’s how high performance works. You put in the preparation, then you just let your body take over.&lt;/p&gt;&lt;p id="773f"&gt;When it comes to morning routines, the primary purpose is to put yourself into a flow or peak state. There are some useful activities for putting yourself into flow.&lt;/p&gt;&lt;p id="eacc"&gt;First, you want to change your environment to change your mindset. Begin visualizing and &lt;em&gt;imagining &lt;/em&gt;your desired future. Affirm powerfully to yourself that you are going to achieve that future. Florence Shinn stated, “Faith knows it has already received and acts accordingly.”&lt;/p&gt;&lt;p id="6181"&gt;That’s what morning routines are all about. You put your mind into the mode of your future. You emotionally commit and connect with that future. You then &lt;em&gt;be &lt;/em&gt;that future self.&lt;/p&gt;&lt;p id="df07"&gt;You act as that future-self would act.&lt;/p&gt;&lt;p id="84ed"&gt;This is why the need for consistency needs to drop from your life.&lt;/p&gt;&lt;p id="fc7b"&gt;Instead of being consistent with who you’ve been, you want to be consistent with who you’re going to be. If you’re going to be a millionaire, you need to start acting like one now.&lt;/p&gt;&lt;p id="c7a3"&gt;&lt;a rel="noopener nofollow" href="https://bigthink.com/surprising-science/method-actors-brain-activity?rebelltitem=1#rebelltitem1"&gt;Recent research&lt;/a&gt; studied the brains of actors with MRI machines. What they found is that, when the actors were in character, their brains showed significant change.&lt;/p&gt;&lt;p id="fa3f"&gt;In other words, acting a different role changes your brain. And this is actually what you want to do every morning in your morning routine.&lt;/p&gt;&lt;p id="d9c9"&gt;Rather than triggering the brain of your former self and addictions, you want to trigger the brain of your desired self, or character.&lt;/p&gt;&lt;p id="987f"&gt;Who do you want to be?&lt;/p&gt;&lt;p id="e3ac"&gt;Imagine that self.&lt;/p&gt;&lt;p id="623b"&gt;Feel that self.&lt;/p&gt;&lt;p id="10c9"&gt;Assume the feeling of your wish fulfilled.&lt;/p&gt;&lt;p id="1b1c"&gt;Affirm the reality of that self.&lt;/p&gt;&lt;p id="8998"&gt;Know that what you want, you can have.&lt;/p&gt;&lt;p id="b481"&gt;Commit big.&lt;/p&gt;&lt;p id="d3c3"&gt;Invest yourself in that reality.&lt;/p&gt;&lt;p id="e86d"&gt;Begin, right now, acting consistent with that reality.&lt;/p&gt;&lt;p id="1d56"&gt;Enjoy the rush of flow that comes from being present and congruent.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;h2 id="fc60"&gt;4. Design your environment for clarity, recovery, and creativity&lt;/h2&gt;&lt;blockquote&gt;&lt;p id="6b6a"&gt;“A lot of people think we are creatures of habit but we’re not. We are creatures of environment.” — Roger Hamilton&lt;/p&gt;&lt;/blockquote&gt;&lt;p id="b2fe"&gt;In order to truly upgrade your life, you can’t just set goals, build morning routines, and begin acting differently.&lt;/p&gt;&lt;p id="cc39"&gt;You need to reshape your environment.&lt;/p&gt;&lt;p id="5085"&gt;You need an environment that matches the future you plan to create.&lt;/p&gt;&lt;p id="51d3"&gt;You need an environment that not only resonates with your values and vision, but also propels your values and vision.&lt;/p&gt;&lt;p id="eb06"&gt;Most people’s environment is like a rushing river, going the opposite direction of where they want to go. It takes a lot of willpower to tread upstream. It’s exhausting. Instead, you want your environment to pull you in the direction you want to go.&lt;/p&gt;&lt;p id="2a2f"&gt;You want to proactively surround yourself with people who inspire you.&lt;/p&gt;&lt;p id="cdc5"&gt;How many role models do you regularly encounter?&lt;/p&gt;&lt;p id="6cc8"&gt;How many role models are you helping?&lt;/p&gt;&lt;p id="3744"&gt;Different environments have different purposes. You want separate environments for rest and rejuvenation, for focus and work, for meditation and clarity, and for excitement and fun.&lt;/p&gt;&lt;p id="9c42"&gt;The more mindful you become as a person, the more you realize that you and your environment are two parts of the same whole. You cannot disconnect yourself from your environment. Therefore, you want to be mindful and intentional about your environment.&lt;/p&gt;&lt;p id="5f25"&gt;This means that you do not contaminate recovery environments with things like cellphones. If you’re going to go to the beach to relax, don’t ruin that amazing opportunity by bringing your phone.&lt;/p&gt;&lt;p id="c1ea"&gt;When you change a part, you change the whole system. Don’t spoil the whole barrel with one bad apple.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;h2 id="8388"&gt;5. Focus on results, not habits or processes&lt;/h2&gt;&lt;blockquote&gt;&lt;p id="5282"&gt;“In polite conversation, most of us will say we admire successful people for their hard work, positive habits, and ironclad principles. That’s not really true. It doesn’t take much digging to uncover a major disconnect between what most of us say we respect and how most of the icons of our age actually behave… Keep in mind that the only thing most people really care about is the score on the board. Everything else is hype.” — Forbes&lt;/p&gt;&lt;/blockquote&gt;&lt;p id="0b7e"&gt;It’s quite hilarious, really. Nowadays, you hear people talking about how goals and results don’t matter.&lt;/p&gt;&lt;p id="7f60"&gt;This is totally nonsense.&lt;/p&gt;&lt;p id="607f"&gt;It’s also a lie.&lt;/p&gt;&lt;p id="fb6e"&gt;It’s not about habits or processes. It’s about results.&lt;/p&gt;&lt;p id="957f"&gt;The reason we admire certain people is because of the results they get. There are countless other people who have habits that are just as inspiring,” but who fail to produce powerful results.&lt;/p&gt;&lt;p id="ef8e"&gt;Tim Ferriss, in his book “The 4-Hour Body,” defines what he calls “minimum viable dose.” Basically, this is the minimum amount of effort to produce the desired result. 212 degrees is all that is needed to boil an egg. Anything beyond that is wasted effort.&lt;/p&gt;&lt;p id="c3a1"&gt;Therefore, what result do you desire?&lt;/p&gt;&lt;p id="375b"&gt;What is the most effective way to get that result?&lt;/p&gt;&lt;p id="a65d"&gt;Rather than obsessing about the habits and processes, you want to gain clarity on the result you want, and then reverse-engineer how to achieve it.&lt;/p&gt;&lt;p id="0185"&gt;It is the goal that determines the process, not the other way around. Moreover, it’s the results that also determine the process. If you’re not getting the desired result, then you need to adjust your process. Don’t be insane, doing the same things over and over and expecting different results.&lt;/p&gt;&lt;p id="e322"&gt;Even still, we live in a culture that is obsessed with habits, hacks, and processes. None of these things make any sense in and of themselves. They only make sense in the context of a specific goal.&lt;/p&gt;&lt;p id="f9c5"&gt;My process won’t look like your process, because my goals aren’t the same as your goals. My goals are what determine my process.&lt;/p&gt;&lt;p id="f3a5"&gt;My habits won’t look like your habits, because my goals aren’t the same as your goals. My goals are what determine my habits.&lt;/p&gt;&lt;p id="8b3f"&gt;When you get serious about big results, you stop obsessing about process altogether. Big and bold goals require ingenuity. They require courage to attempt stuff that might not work. They require going above and beyond anything you’ve ever done.&lt;/p&gt;&lt;p id="8424"&gt;In reality, your goal &lt;em&gt;is &lt;/em&gt;the process. You set a goal and that goal organizes your life. Once you hit it, you then set a new goal that re-organizes your life.&lt;/p&gt;&lt;p id="56f3"&gt;Goals are the means, not the end. They are means to growth and progress. Once you hit a goal, you take what you’ve learned and continue expanding.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;h2 id="dfa1"&gt;6. Identify ideal mentors/partners&lt;/h2&gt;&lt;blockquote&gt;&lt;p id="50bd"&gt;“Everybody wants to be somebody’s Yoda.” — Aminah Mae Safi&lt;/p&gt;&lt;/blockquote&gt;&lt;p id="e2f5"&gt;Don’t just look for a job. Instead, create a job.&lt;/p&gt;&lt;p id="d715"&gt;How?&lt;/p&gt;&lt;p id="b2e9"&gt;You create a job by providing opportunities to ideal people you want to learn from and work with.&lt;/p&gt;&lt;p id="d8eb"&gt;This is how you can come to work very closely with your ideal mentors.&lt;/p&gt;&lt;p id="9665"&gt;Wealthy people work to learn. Poor people work for money.&lt;/p&gt;&lt;p id="2cf6"&gt;So, who do you admire?&lt;/p&gt;&lt;p id="ecb3"&gt;Who is a role model to you?&lt;/p&gt;&lt;p id="717f"&gt;Who is doing work you absolutely love?&lt;/p&gt;&lt;p id="f4a3"&gt;Who has a life you want to emulate?&lt;/p&gt;&lt;p id="6c12"&gt;How can you help them achieve their goals?&lt;/p&gt;&lt;p id="63f1"&gt;How can you use your skills and abilities to enhance and improve what they are doing?&lt;/p&gt;&lt;p id="9273"&gt;It is really so easy to get close to just about anyone. I’ve observed this over and over in my life. I’ve been able to develop very close relationships with anyone I’ve wanted.&lt;/p&gt;&lt;p id="06e7"&gt;It started with a vision.&lt;/p&gt;&lt;p id="44c1"&gt;I wrote down that I was going to learn from and work with certain people.&lt;/p&gt;&lt;p id="08af"&gt;I studied their work.&lt;/p&gt;&lt;p id="f122"&gt;I developed skills that would be useful to them.&lt;/p&gt;&lt;p id="cb3a"&gt;I got myself into their environment.&lt;/p&gt;&lt;p id="cdc3"&gt;I offered my skills to them in the form of an opportunity, one in which would help them further succeed.&lt;/p&gt;&lt;p id="1960"&gt;I spent my time and effort helping them and learning a great deal in the process.&lt;/p&gt;&lt;p id="5017"&gt;I became part of the inner-circle.&lt;/p&gt;&lt;p id="3cc1"&gt;Being in the inner-circle, I’m now afforded rare knowledge, experiences, and opportunities.&lt;/p&gt;&lt;p id="aa17"&gt;This is what you want.&lt;/p&gt;&lt;p id="e555"&gt;You develop mentorships and partnerships by being useful. You dedicate your thoughts and efforts to helping them. By helping them, you position yourself in a unique place. In this unique new position, making lots of money becomes easy.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;h2 id="0f5d"&gt;7. Become a brilliant listener and observer&lt;/h2&gt;&lt;blockquote&gt;&lt;p id="5643"&gt;“Listening is such a simple act. It requires us to be present, and that takes practice, but we don’t have to do anything else. We don’t have to advise, or coach, or sound wise. We just have to be willing to sit there and listen.” — Margaret Wheatley&lt;/p&gt;&lt;p id="9fd0"&gt;“Seek first to understand, then to be understood.” — Stephen Covey&lt;/p&gt;&lt;/blockquote&gt;&lt;p id="8e67"&gt;Interestingly, in helping ideal mentors and role models, I’ve seen time and again how people overly value their own “wisdom.”&lt;/p&gt;&lt;p id="9cc0"&gt;Recently, I was on a call with one of my mentors. There were three of us on the call. The mentor, myself, and one other. We were all discussing my mentor’s goals and plans for expanding their business and simplifying their life.&lt;/p&gt;&lt;p id="c821"&gt;The conversation lasted about 90 minutes.&lt;/p&gt;&lt;p id="9457"&gt;60 of those minutes were the other person spouting endless ideas without clear context. They were trying too hard to be useful or smart.&lt;/p&gt;&lt;p id="336f"&gt;It wasn’t helpful.&lt;/p&gt;&lt;p id="571d"&gt;Instead, it’s better to ask thoughtful questions.&lt;/p&gt;&lt;p id="0f84"&gt;What are they really trying to accomplish?&lt;/p&gt;&lt;p id="38c4"&gt;What are the current challenges?&lt;/p&gt;&lt;p id="652e"&gt;What do you feel needs to happen?&lt;/p&gt;&lt;p id="4aab"&gt;Why do you want to make these changes?&lt;/p&gt;&lt;p id="2414"&gt;Once you understand the context, then and only then will your words be useful. When it comes to relationships and communication, sometimes the stakes are very high. In these cases, you want to measure ten times and cut once. In other words, you want your words to be relevant and on-point. You want it to be obvious that you’re there for them, and not to boost your own ego.&lt;/p&gt;&lt;p id="af6b"&gt;If it’s really about them, then make it about them. Ask questions before providing ideas.&lt;/p&gt;&lt;p id="f4b0"&gt;Help them get clarity themselves through their own talking.&lt;/p&gt;&lt;p id="b248"&gt;Make sure they understand what is really going on in their head by helping them clarify.&lt;/p&gt;&lt;p id="b138"&gt;Then, when you feel you could provide insight, do it in the context of what they’ve already said.&lt;/p&gt;&lt;p id="7bb2"&gt;They will then know that you are truly listening to them and that you’re truly trying to help them. They will love and respect you, because unlike most people, you are genuine. You’re a listener.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;h2 id="270e"&gt;8. Focus on who instead of how&lt;/h2&gt;&lt;blockquote&gt;&lt;p id="698c"&gt;“Stop asking ‘how’ and start asking ‘who.’” — Dan Sullivan&lt;/p&gt;&lt;/blockquote&gt;&lt;p id="7a31"&gt;Part of becoming a millionaire, or financially successful in whatever way you define that, is by evolving beyond what Dan Sullivan calls “rugged individualism.”&lt;/p&gt;&lt;p id="cfa5"&gt;When ambitious people set goals, they often ask themselves, “How do I do this?”&lt;/p&gt;&lt;p id="c450"&gt;When you’re first starting out, this is a fine question. But when your vision expands and your time becomes more valuable, you start asking a different question.&lt;/p&gt;&lt;p id="bc17"&gt;“Who can either do this for me or help me do this?”&lt;/p&gt;&lt;p id="9490"&gt;Rather than trying to do the &lt;em&gt;how &lt;/em&gt;yourself, you find the &lt;em&gt;who &lt;/em&gt;to take care of the how.&lt;/p&gt;&lt;p id="0303"&gt;Hiring people or even using services like Upwork is so easy these days. There are people all over the world with time and skills who are ready and waiting. Utilize these people.&lt;/p&gt;&lt;p id="473c"&gt;You get the best people on board with whatever you’re trying to accomplish by powerfully and clearly conveying the what and the why.&lt;/p&gt;&lt;p id="67b0"&gt;What are you trying to accomplish?&lt;/p&gt;&lt;p id="8d9f"&gt;Why is it so important?&lt;/p&gt;&lt;p id="89f4"&gt;This is how you get people excited and committed. Simon Sinek, an expert of work culture, explains that everyone needs more from work than simply a paycheck. We all want to feel like we are a part of something important, meaningful, and worthwhile.&lt;/p&gt;&lt;p id="f06e"&gt;You offer that to people through the what and the why.&lt;/p&gt;&lt;p id="8aba"&gt;You may not see yourself as an entrepreneur. And you certainly don’t have to be one. But if you want to start making more money, you’ll need to stop doing everything by yourself.&lt;/p&gt;&lt;p id="4e8a"&gt;Becoming a millionaire doesn’t happen by being a one-person show.&lt;/p&gt;&lt;p id="63ae"&gt;You need to start building a team. And like everything else, you want to do that before you feel ready. Because in truth, you’re never ready before you start. You’re never pre-qualified to do anything. It is always the leap itself and then working through the process that qualifies you.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;h2 id="bb81"&gt;9. Continually update your values/definition of success&lt;/h2&gt;&lt;blockquote&gt;&lt;p id="c257"&gt;“If you’re not [different from] who you were 12 months ago, you didn’t learn enough.” — Alain De B0tton&lt;/p&gt;&lt;/blockquote&gt;&lt;p id="a680"&gt;Transformative experiences can change your life. Similarly, transformative relationships can change your life.&lt;/p&gt;&lt;p id="7ec2"&gt;You want to regularly have experiences and engage with people who upgrade your current approach and perspective of life.&lt;/p&gt;&lt;p id="0d39"&gt;Right now, you see the world a particular way based on your environment, your goals, and what you’ve been conditioned to focus on.&lt;/p&gt;&lt;p id="7b01"&gt;You can only see what is relevant and meaningful to you. Psychologists call this selective attention. What you focus on expands.&lt;/p&gt;&lt;p id="923c"&gt;Right now, what you focus on may be different from what you were focusing on two to three years ago.&lt;/p&gt;&lt;p id="49cd"&gt;When you were young, you were focused on what your friends thought about you. As you got older, your focus shifted.&lt;/p&gt;&lt;p id="5595"&gt;Peak experiences are a certain type of experience that bring something that has been out of focus into focus. When you have these experiences that shift your focus and attention, you begin to see the world differently.&lt;/p&gt;&lt;p id="7826"&gt;You want to continually shine the focus of your attention on things that are meaningful and valuable to you.&lt;/p&gt;&lt;p id="477b"&gt;How much of your time and attention is on things that don’t really matter?&lt;/p&gt;&lt;p id="ea4a"&gt;How much energy to you put into stuff that isn’t serving you?&lt;/p&gt;&lt;p id="418c"&gt;What could you be focused on, that would be way more worth you time?&lt;/p&gt;&lt;p id="a501"&gt;I recently met a person who helped me focus way more directly on my relationship with my kids. He told me a story that really changed my perspective. I was really listening and receptive to what he was saying.&lt;/p&gt;&lt;p id="a27c"&gt;The story he told me hit upon things I’d already heard before, but that weren’t strong enough signals to shift my attention. But his story and the whole experience really made it real for me, enough so that it changed my values and goals.&lt;/p&gt;&lt;p id="645d"&gt;There are things you’ve heard before which went in one ear and out the other. Those are things you know, but don’t do. Stephen Covey said, “To know and not do is really not to know.”&lt;/p&gt;&lt;p id="b18a"&gt;Just because you’re aware of something doesn’t mean you pay attention to it. Becoming emotionally connected to something is how you begin paying more attention to it. As you engage in something, and begin to identify with it, it becomes a bigger part of your life.&lt;/p&gt;&lt;p id="25b8"&gt;Right now, look at your health. How much attention do you give it? You’ve heard a million times that your health is important. You’re aware, but are you paying attention? Or, is your attention on other things?&lt;/p&gt;&lt;p id="3277"&gt;Your attention can be measured by what triggers you in your environment. Hence, people who are addicted to alcohol are triggered by many things in their environment to think about alcohol.&lt;/p&gt;&lt;p id="0f2e"&gt;What triggers you?&lt;/p&gt;&lt;p id="2de3"&gt;That’s what you’re focused on. That’s what you identify with. That’s what is meaningful to you. That’s where your story of yourself lies.&lt;/p&gt;&lt;p id="d731"&gt;You can design your focus so that your external environment triggers&lt;em&gt; what you want to see&lt;/em&gt;.&lt;/p&gt;&lt;p id="176c"&gt;Similar to attention, there are things you know are valuable, but that you personally don’t value.&lt;/p&gt;&lt;p id="873a"&gt;For example, you probably believe that good health is something worth valuing, but your behavior demonstrates what you really value. What you pay attention to is what you value.&lt;/p&gt;&lt;p id="7c9a"&gt;So, you want to have experiences that shift what you could value to what you do value. You want to truly value things that will make the biggest difference in your life. You want to stop valuing the things that are sabotaging your success.&lt;/p&gt;&lt;p id="8929"&gt;You want to set goals around the values you aspire to have. You want to create routines and an environment that bring those values to the forefront of your attention. Your input shapes your outlook. You then want to live out those values daily. Then, you want to regularly have experiences which upgrade, expand, and refine those values.&lt;/p&gt;&lt;p id="58a0"&gt;If your definition of “success” hasn’t changed in the past 12 months, then you haven’t learned very much. If your definition of success hasn’t changed, then you haven’t been having powerful experiences.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;h2 id="599f"&gt;10. Don’t wait too long when you know it’s time to change&lt;/h2&gt;&lt;blockquote&gt;&lt;p id="ddee"&gt;“What got you here won’t get you there.” — Dr. Marshall Goldsmith&lt;/p&gt;&lt;p id="e630"&gt;“Insanity is doing the same thing over and over again and expecting different results.” — Albert Einstein&lt;/p&gt;&lt;p id="4051"&gt;“The way to enjoy life best is to wrap up one goal and start right on the next one. Don’t linger too long at the table of success, the only way to enjoy another meal is to get hungry.” — Jim Rohn&lt;/p&gt;&lt;/blockquote&gt;&lt;p id="af18"&gt;Goals are means, not ends. Once you’ve achieved something big, don’t get stuck there just because it worked before.&lt;/p&gt;&lt;p id="2441"&gt;Everything you’ve done has brought you to this point.&lt;/p&gt;&lt;p id="6f80"&gt;What is the next big adventure?&lt;/p&gt;&lt;p id="22e9"&gt;What does the situation call for?&lt;/p&gt;&lt;p id="ea9b"&gt;What does your imagination inspire?&lt;/p&gt;&lt;p id="2223"&gt;What’s the next big mountain?&lt;/p&gt;&lt;p id="3d91"&gt;One of the fundamental problems with success is that it becomes a trap. People who have succeeded big get stuck living in their past. They continue to explain themselves based on what they’ve done, rather than what they’re doing.&lt;/p&gt;&lt;p id="25c3"&gt;Elon Musk is a powerful exception. You never hear Elon Musk talk about the Paypal days. Instead, you hear him talking about the problems he’s currently solving and the vision he is currently pursuing.&lt;/p&gt;&lt;p id="94ab"&gt;He’s not stuck in the past. Instead, he’s using all of his past experiences to propel bigger and bigger results and goals and challenges.&lt;/p&gt;&lt;p id="9e25"&gt;He’s always growing, transforming, changing, striving. This is a very healthy approach to life.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;h2 id="65a9"&gt;Conclusion&lt;/h2&gt;&lt;p id="cce9"&gt;It’s not hard.&lt;/p&gt;&lt;p id="b126"&gt;You just need to know what you want and then become the person that gets it.&lt;/p&gt;&lt;p id="ce35"&gt;You can become a millionaire.&lt;/p&gt;&lt;p id="5557"&gt;It may take five years. But five years of focused attention on something can take you a really long way.&lt;/p&gt;&lt;p id="0e71"&gt;What’s the minimum viable dose for the results you want?&lt;/p&gt;&lt;p id="d1d3"&gt;Becoming a millionaire will require you to change. But as Albert Einstein said, “The measure of intelligence is the ability to change.” Jim Rohn said it best: “Become a millionaire not for the million dollars, but for what it will make of you to achieve it.”&lt;/p&gt;&lt;p id="843e"&gt;Here’s the reality: you are currently fixated and focused on&lt;em&gt; something&lt;/em&gt;. That’s a fact. If you want to understand who you are, all you need to do is discover where your current focus and attention lies.&lt;/p&gt;&lt;p id="8547"&gt;A fundamental part of conscious evolution is learning to control and direct your attention — so that you can shine that spotlight onto what you want, rather than what you’ve been conditioned to want. Fundamental to that is updating your environment and values, since these things center your attention.&lt;/p&gt;&lt;p id="c72f"&gt;What are you currently focused on?&lt;/p&gt;&lt;p id="726d"&gt;What is currently meaningful to you?&lt;/p&gt;&lt;p id="499a"&gt;What could be meaningful to you?&lt;/p&gt;&lt;p id="d9ba"&gt;What could you value?&lt;/p&gt;&lt;p id="cb88"&gt;Who could you be?&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;a href="https://medium.com/better-marketing/10-skills-to-becoming-a-millionaire-in-5-years-or-less-e16b8b20500c"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Thu, 16 Apr 2020 14:51:16 UT
      </pubDate>
      <guid>
        https://medium.com/better-marketing/10-skills-to-becoming-a-millionaire-in-5-years-or-less-e16b8b20500c
      </guid>
    </item>
    <item>
      <title>
        404 - Page not found
      </title>
      <link>
        https://www.brent-jensen.com/blog/dopamine-fasting
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;&lt;p&gt;&lt;img src="https://uploads-ssl.webflow.com/5663ece1cdf237d35fd4480c/5663f7d42900ed96701ee150_404-2.png" width="206" alt="404 page"&gt;&lt;/p&gt;&lt;h2&gt;Page not found&lt;/h2&gt; &lt;p&gt;The page you are looking for doesn't exist or has been moved.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://www.brent-jensen.com/blog/dopamine-fasting"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Fri, 17 Apr 2020 12:27:10 UT
      </pubDate>
      <guid>
        https://www.brent-jensen.com/blog/dopamine-fasting
      </guid>
    </item>
    <item>
      <title>
        David Thorpe - Kick The Shit Out Of Procrastination
      </title>
      <link>
        https://davidthorpe.dev/kick-the-shit-out-of-procrastination/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt; &lt;article&gt; &lt;a href="https://davidthorpe.dev/blog"&gt;&lt;small&gt;&lt;i&gt;&lt;/i&gt; Back To List&lt;/small&gt;&lt;/a&gt; &lt;h2&gt;Kick The Shit Out Of Procrastination&lt;/h2&gt; &lt;p&gt;I think I’ve spent my whole career trying out the next cool productivity software or system. It almost always fails. I tried as many of these things as I could but it just falls by the wayside. Basecamp, Reminders, Todoist, Trello, Bullet Journal, Post-It Notes… Jira. I’m joking on that last one; who would voluntarily use that…&lt;/p&gt; &lt;p&gt;Constantly checking feeds, Twitter, Hackernews, Reddit, BBC. It becomes a feedback loop where you get that hit of dopamine every once in a while when you visit a site. Holy shit a new notification on Twitter. This is the shit I live for!&lt;/p&gt; &lt;p&gt;Before I know it, my energy is sapped. The chance of me getting any meaningful work done is as slim as that fucking guy across the road who is really into fitness and makes me feel bad about how I’m not. Anyway, I digress…&lt;/p&gt; &lt;h2 id="its-not-about-routines"&gt;It’s Not About Routines&lt;/h2&gt; &lt;p&gt;I thought for a long time my occasional forays into procrastination filled days were a fundamental problem with my mind.&lt;/p&gt; &lt;p&gt;I read articles, saw people exclaim I must have ADHD, I listened to podcasts and I wondered why I’m such a terrible person. Why can’t I get as much shit done as that super-productive developer I see on Twitter always knocking stuff out? Why am I feeling like I have to keep treading water just to keep my clients/boss happy? I’ve tried every fucking morning routine going and I’m still feeling like a dick.&lt;/p&gt; &lt;p&gt;&lt;img alt="Sad Clown" src="https://davidthorpe.dev/img/blog-media/sad-clown.jpg"&gt;&lt;/p&gt; &lt;p&gt;Only when we have learned about the weaknesses of our own procrastination can we kick the shit out of it. You can’t beat an opponent without knowing it intimately. We’ll get to know your procrastination intimately, and just when it begins to trust you we’ll take it out back like a loyal aged dog and pop it right in the back of the head.&lt;/p&gt; &lt;h2 id="step-1-stop-using-your-phone"&gt;Step 1: Stop Using Your Phone&lt;/h2&gt; &lt;p&gt;Let’s start reducing the time you spend on screens. To do that, let’s remove anything from your phone that doesn’t provide &lt;strong&gt;real value&lt;/strong&gt; to you in your real life. This should include (all may not apply to you specifically of course):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Social media apps&lt;/li&gt; &lt;li&gt;Newsfeeds&lt;/li&gt; &lt;li&gt;Slack&lt;/li&gt; &lt;li&gt;Email (if you can)&lt;/li&gt; &lt;li&gt;Games&lt;/li&gt; &lt;li&gt;Notifications&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;If you find yourself picking up your phone to “check-in” on something. Delete it straight away. It’s not a good use of your time and is probably part of an addiction to checking things rather than something that you really need to do.&lt;/p&gt; &lt;h3 id="browser-woes"&gt;Browser Woes&lt;/h3&gt; &lt;p&gt;Your smartphone probably has a browser that can help you re-access all of the above if you really wanted to. This was a problem for me. I use Screen Time to enable content restrictions that block every single website except Google (since this provides me real value for looking up local businesses etc).&lt;/p&gt; &lt;p&gt;&lt;img alt="Screen Time" src="https://davidthorpe.dev/img/blog-media/st.png"&gt;&lt;/p&gt; &lt;p&gt;My wife is the only one with the 4 digit passcode that will disable it. No impulsive disabling / checking anymore.&lt;/p&gt; &lt;h3 id="hide-the-apps"&gt;Hide The Apps&lt;/h3&gt; &lt;p&gt;On my iPhone I move every single application into a folder named “.”. I then move that onto the second screen.&lt;/p&gt; &lt;p&gt;My phone dock has four apps: Phone, Headspace, Things and SMS:&lt;/p&gt; &lt;p&gt;&lt;img alt="Simple Phone" src="https://davidthorpe.dev/img/blog-media/simple-phone.png"&gt;&lt;/p&gt; &lt;h3 id="your-phone-now-works-for-you"&gt;Your Phone Now Works For You&lt;/h3&gt; &lt;p&gt;You’ll find your phone should be something that now reflects that things you truly want to spend your time on. In my case, this is mostly, but not limited to:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Taking photos&lt;/li&gt; &lt;li&gt;Listening to music&lt;/li&gt; &lt;li&gt;Listening to audiobooks&lt;/li&gt; &lt;li&gt;Headspace meditation app&lt;/li&gt; &lt;li&gt;Banking apps&lt;/li&gt; &lt;li&gt;Parking apps&lt;/li&gt; &lt;li&gt;Maps&lt;/li&gt; &lt;li&gt;Guitar tuner&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;What you’ve done now is to ensure that your phone is reflective of your true needs and genuine interests. You can go monk-level crazy with this stuff and I may go into detail here about what I do in a video one day. For now you get the point I guess.&lt;/p&gt; &lt;h3 id="what-does-this-have-to-do-with-procrastination"&gt;What Does This Have To Do With Procrastination?&lt;/h3&gt; &lt;p&gt;I want you to have as clear a mind as possible that isn’t cluttered with potential distractions from devices that can be controlled. You probably already have many other distractions in your life already, so keep the ones you can control to a bare minimum.&lt;/p&gt; &lt;h2 id="step-2-block-distractions-on-the-computer"&gt;Step 2: Block Distractions On The Computer&lt;/h2&gt; &lt;p&gt;I will keep this one short. Try your utmost best to block distracting websites on your computer using something like freedom.to or by just manually editing your /etc/hosts file (if you’re on a proper computer).&lt;/p&gt; &lt;p&gt;&lt;img alt="Hosts File" src="https://davidthorpe.dev/img/blog-media/hosts.png"&gt;&lt;/p&gt; &lt;p&gt;This is gonna suck. It’s going to hurt and you will quickly realise and be able to recognise the feeling that led you to want to visit that attention destroying content source.&lt;/p&gt; &lt;p&gt;One of the biggest things that can get you drawn into procrastinating is to go into a crazy website checking loop where you loop through Twitter, Hackernews, Reddit, BBC, etc in the hope for a new bit of information that probably has no real relevance to your life.&lt;/p&gt; &lt;p&gt;If we can stop this feedback loop we can start to become more aware of when it’s happening and ultimately why it’s happening. That’s the end goal. It’s that understanding of procrastination that allows us to kick the shit out of it. That mother-fucker!&lt;/p&gt; &lt;h2 id="step-3-love-your-brain"&gt;Step 3: Love Your Brain&lt;/h2&gt; &lt;p&gt;I’m going to list two things here that I’ve found to have a profound impact on my ability to stay more on-task and to notice when I’m drifting. I of course recommend paying due attention to both:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Sleep:&lt;/strong&gt; When I don’t have a good amount of sleep, my brain just can’t muster the energy to focus on heavy work. This is really important and now that you’ve blocked access to time-wasting things on your phone, this should be a bit easier.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Meditation:&lt;/strong&gt; This is where the magic happens. It’s not a quick fix, but learning to meditate and sticking to it as-daily-as-possible will help you notice your mind wandering off-task and will help you associate the emotion you’ve got that caused that mind wandering.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;For meditation, I use the app “Headspace”. It’s truly incredible although I might be biased because the CEO has a British accent and I’m a bit a little bit patriotic 🇬🇧. I’m hoping with enough meditation I’ll be as spiritual as this guy:&lt;/p&gt; &lt;p&gt;For sleep, I use alcohol. Just kidding. I think. Sometimes. Don’t judge me.&lt;/p&gt; &lt;p&gt;With these three steps in place you can now start to devise your battle plan against procrastination.&lt;/p&gt; &lt;h2 id="step-4-get-to-work"&gt;Step 4: Get To Work&lt;/h2&gt; &lt;p&gt;Now go about your daily working life like normal. Except this time when you instinctively go to grab your phone to check a feed or to visit a distracting website try to right there and then stop yourself and think: How do I feel?&lt;/p&gt; &lt;p&gt;For me it seems to have been a combination of the two emotions “Fear” and “Boredom”. The latter is now getting much easier to manage since by not having access to junk food content, I have started reading more and my brain is getting more attuned to staying focused for long amounts of time.&lt;/p&gt; &lt;p&gt;For the former, fear seems to crop up when I approach a task that is daunting or that I don’t really know enough about. Whenever I used to read about that and people recommended to “break it down to small chunks”, I’d always think “Fuck off (wo)man, you just don’t get it”.&lt;/p&gt; &lt;p&gt;In a sense this is still a problem I face although in a lesser capacity, but I’m now aware of that. Procrastination is actually my mind trying to tell me something that I’m not attuned enough to realise in the first place. Maybe that means I may &lt;strong&gt;actually&lt;/strong&gt; need to break things down a bit more. Maybe it means I need to &lt;strong&gt;understand&lt;/strong&gt; the problem a bit more. At least I now have something a bit more actionable in my arsenal in order to battle this psychologically interesting phenomena.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; I think procrastination is quite normal and I don’t think you should see this article as one of those “always being productive” things because I think they’re really damaging. We all need downtime, if you’re trying these things but still just can’t make progress, maybe you need some time off to rebuild your energy and enthusiasm for your work.&lt;/p&gt; &lt;h2 id="what-are-your-tips"&gt;What Are Your Tips?&lt;/h2&gt; &lt;p&gt;If anyone reading this has some tips of their own, I’d be really interested in hearing them since I want to focus on this topic a considerable amount through audio / video content that you can ironically consume when you should be working.&lt;/p&gt; &lt;p&gt;Feel free to email me your thoughts on the subject since I would very much appreciate it:&lt;/p&gt; &lt;p&gt;&lt;a href="mailto:blog@davidthorpe.dev"&gt;blog@davidthorpe.dev&lt;/a&gt;&lt;/p&gt; &lt;/article&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://davidthorpe.dev/kick-the-shit-out-of-procrastination/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Mon, 20 Apr 2020 10:45:30 UT
      </pubDate>
      <guid>
        https://davidthorpe.dev/kick-the-shit-out-of-procrastination/
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://www.intel.com/content/dam/www/program/education/us/en/documents/project-design/strategies/dep-question-socratic.pdf
      </link>
      <description>
        &lt;a href="https://www.intel.com/content/dam/www/program/education/us/en/documents/project-design/strategies/dep-question-socratic.pdf"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 21 Apr 2020 14:48:15 UT
      </pubDate>
      <guid>
        https://www.intel.com/content/dam/www/program/education/us/en/documents/project-design/strategies/dep-question-socratic.pdf
      </guid>
    </item>
    <item>
      <title>
        Web Login Service | The Ohio State University
      </title>
      <link>
        https://osu.instructure.com/courses/71145/pages/week-15-class-31
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div role="main" tabindex="-1" id="page"&gt; &lt;p&gt;You may be seeing this page because you waited an extended period of time to submit the login form. After a set period, the server abandons your original request to save resources, and you'll need to return where you started from and try and login again.&lt;/p&gt; &lt;p&gt;You may also be seeing this page because you used the Back button while browsing a secure web site or application, causing the original web request for login to be "replayed". Alternatively, you may have mistakenly bookmarked the web login form instead of the actual web site you wanted to bookmark, or used a link created by somebody else who made the same mistake.&lt;/p&gt; &lt;p&gt;Left alone, this can cause errors on some browsers (such as Safari) or result in you returning to the web site you tried to leave, so this page is presented instead so that you can continue safely with your online activities. Note that you may need to hit the Back button multiple times to skip over all of the login-related pages in your history list.&lt;/p&gt; &lt;p&gt;If the problem is a bookmark, you'll probably notice that the bookmarked location contains a long URL that starts with &lt;code&gt;https://webauth.service.ohio-state.edu....&lt;/code&gt; If so, you should delete and recreate (or edit) the bookmark to contain the web address of the site you want to access. For example, to bookmark the Carmen web site, you would create a bookmark for &lt;code&gt;https://carmen.osu.edu&lt;/code&gt;&lt;/p&gt; &lt;p&gt;If you're unable to avoid seeing this message, please contact the maintainer of the web site containing the link you're starting from so that they can investigate the problem. Be sure to provide the surrounding context and explain what you're trying to access so that they can find and correct the offending link.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Remember to &lt;a href="https://osuitsm.service-now.com/selfservice/kb_view.do?sys_kb_id=c591b3680a0a3c05014c37aec7538c29"&gt;clear your browser history&lt;/a&gt; to avoid improper access to whatever web sites you've been using if this is a shared machine, and never leave your own machine unlocked and unattended.&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://osu.instructure.com/courses/71145/pages/week-15-class-31"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 21 Apr 2020 18:37:08 UT
      </pubDate>
      <guid>
        https://osu.instructure.com/courses/71145/pages/week-15-class-31
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://medium.com/@rakyll/things-i-wished-more-developers-knew-about-databases-2d0178464f78
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;&lt;div&gt;&lt;p&gt;&lt;a href="https://medium.com/?source=post_page-----2d0178464f78--------------------------------" rel="noopener"&gt;&lt;img height="28" width="28" src="https://miro.medium.com/fit/c/56/56/1*O8Ky4z8o_t8K0EwfnJ-M1A.jpeg" alt="Jaana Dogan"&gt;&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;p id="a19d"&gt;A large majority of computer systems have some state and are likely to depend on a storage system. My knowledge on databases accumulated over time, but along the way our design mistakes caused data loss and outages. In data-heavy systems, databases are at the core of system design goals and tradeoffs. Even though it is impossible to ignore how databases work, the problems that application developers foresee and experience will often be just the tip of the iceberg. In this series, I’m sharing a few insights I specifically found useful for developers who are not specialized in this domain.&lt;/p&gt;&lt;ol&gt;&lt;li id="9192"&gt;You are lucky if 99.999% of the time network is not a problem.&lt;/li&gt;&lt;li id="f7f3"&gt;ACID has many meanings.&lt;/li&gt;&lt;li id="befb"&gt;Each database has different consistency and isolation capabilities.&lt;/li&gt;&lt;li id="79f6"&gt;Optimistic locking is an option when you can’t hold a lock.&lt;/li&gt;&lt;li id="ea70"&gt;There are anomalies other than dirty reads and data loss.&lt;/li&gt;&lt;li id="f27c"&gt;My database and I don’t always agree on ordering.&lt;/li&gt;&lt;li id="c6ee"&gt;Application-level sharding can live outside the application.&lt;/li&gt;&lt;li id="5f5c"&gt;AUTOINCREMENT’ing can be harmful.&lt;/li&gt;&lt;li id="6b34"&gt;Stale data can be useful and lock-free.&lt;/li&gt;&lt;li id="9ddd"&gt;Clock skews happen between any clock sources.&lt;/li&gt;&lt;li id="05b5"&gt;Latency has many meanings.&lt;/li&gt;&lt;li id="7f9c"&gt;Evaluate performance requirements per transaction.&lt;/li&gt;&lt;li id="8918"&gt;Nested transactions can be harmful.&lt;/li&gt;&lt;li id="eb84"&gt;Transactions shouldn’t maintain application state.&lt;/li&gt;&lt;li id="0c07"&gt;Query planners can tell a lot about databases.&lt;/li&gt;&lt;li id="4871"&gt;Online migrations are complex but possible.&lt;/li&gt;&lt;li id="0dd8"&gt;Significant database growth introduces unpredictability.&lt;/li&gt;&lt;/ol&gt;&lt;p id="3995"&gt;&lt;em&gt;T&lt;span id="rmm"&gt;h&lt;/span&gt;anks much to Emmanuel Odeke, Rein Henrichs and others for their review and feedback on an earlier version this article.&lt;/em&gt;&lt;/p&gt;&lt;h2 id="8842"&gt;You are lucky if 99.999% of the time network is not a problem.&lt;/h2&gt;&lt;p id="eaaa"&gt;It’s an open debate how reliable today’s networking is and how commonly systems experience downtime because of networking outages. The available research is limited and is often dominated by large organizations who have dedicated networking with custom hardware, as well as specialized staff.&lt;/p&gt;&lt;p id="afe1"&gt;With 99.999% service availability, Google cites only &lt;a rel="noopener nofollow" href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/45855.pdf"&gt;7.6%&lt;/a&gt; of Spanner (Google’s globally distributed database) issues are caused by networking even though it keeps crediting its dedicated networking as a core reason behind its availability. &lt;a rel="noopener nofollow" href="https://cacm.acm.org/magazines/2014/9/177925-the-network-is-reliable/fulltext"&gt;Bailis’ and Kingsbury’s survey&lt;/a&gt; from 2014 is challenging one of the &lt;a rel="noopener nofollow" href="https://en.wikipedia.org/wiki/Fallacies_of_distributed_computing"&gt;Fallacies of Distributed Computing&lt;/a&gt; coined by Peter Deutsch in 1994. Is network really reliable?&lt;/p&gt;&lt;p id="e091"&gt;We don’t have comprehensive survey outside of giants or over the public Internet. There is also not enough data from major providers how much of their customers issues can be traced back to networking problems. We often experience outages in large cloud provider’s networking stack can take parts of the Internet down for hours but these are only the high-impact events where a large number of visible customers are impacted. Networking outages might be affecting more cases even though not all events are making much noise. Cloud customers don’t necessarily have visibility into their problems either. When there is an outage, identifying it as a networking error caused in the provider is not possible. To them, third-party services are black boxes. Estimating the impact without being a major provider is not possible.&lt;/p&gt;&lt;p id="08f8"&gt;In comparison to what major players report on their systems, it might be safe to say you are lucky if networking issues represents a small percentage of your potential problems that cause outage. Networking still suffer from conventional issues such as hardware failures, topology changes, administrative configuration changes and power failures. But I recently learned that newly discovered problems such as &lt;a rel="noopener nofollow" href="https://twitter.com/rakyll/status/1249891472993693696"&gt;SHARK BITES&lt;/a&gt; (yes, shark bites) are a reality.&lt;/p&gt;&lt;h2 id="d8f0"&gt;ACID has many meanings.&lt;/h2&gt;&lt;p id="ad33"&gt;ACID stands for atomicity, consistency, isolation, durability. These are the properties database transactions need to guarantee to their users for validity even in the event of crash, error, hardware failures and similar. Without ACID or similar contracts, application developers wouldn’t have a guidance on what’s their responsibility versus what the databases provide. Most relational transactional databases are trying to be ACID-compliant, but new approaches such as NoSQL movement gave birth to many databases without ACID transactions because they are expensive to implement.&lt;/p&gt;&lt;p id="041a"&gt;When I was new in the industry, our tech lead was arguing whether ACID is an obsolete concept or not. It is fair to say ACID is considered a loose description instead of a strict implementation standard. Today, I find it mostly useful because it provides a category of problems (and a category of possible solutions).&lt;/p&gt;&lt;p id="aac4"&gt;NOT every database is ACID-compliant and among ACID-compliant databases, ACID can be interpreted differently. One of the reasons why ACID is implemented differently is the number of tradeoffs involved in implementing ACID capabilities. Databases might advertise themselves as ACID but might still have different interpretation in edge cases or how they handle “unlikely” events. Developers can at least learn at a high-level how databases implement things in order to have a proper understanding of fail modes and design tradeoffs.&lt;/p&gt;&lt;p id="f34c"&gt;One well-known debate is how ACID MongoDB is even after v4. MongoDB didn’t have &lt;a rel="noopener nofollow" href="https://www.mongodb.com/blog/post/what-about-durability"&gt;journaling&lt;/a&gt; support for a long time even though it was not committing data files to disk not more frequently (every 60 seconds) by default. Consider the following scenario, application makes two writes (w1 and w2). MongoDB was able to persist the change for the first write, but it fails to do it for w2 because it crashes due to a hardware failure.&lt;/p&gt;&lt;figure&gt;&lt;div&gt;&lt;p&gt;&lt;img height="163" width="585" src="https://miro.medium.com/max/60/1*2QPkOUcin02S3zX9BDz3qw.png?q=20" alt="Image for post"&gt;&lt;/p&gt;&lt;/div&gt;&lt;figcaption&gt;An illustration of data loss if MongoDB crashes before it writes to the physical disk.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p id="0cb3"&gt;Committing to disk is an expensive process and by avoiding commits, they were claiming to be performant in writes while sacrificing durability. As of today, MongoDB has journaling but dirty writes still can affect the durability of data because they are committing journals at every 100ms by default. The same scenario is still possible for the durability of the journals and changes represented in those logs even though the risk is significantly less.&lt;/p&gt;&lt;h2 id="47cb"&gt;Each database has different consistency and isolation capabilities.&lt;/h2&gt;&lt;p id="e63e"&gt;Among ACID properties, consistency and isolation have the widest spectrum of different implementation details because the spectrum of tradeoffs is wider. Consistency and isolation are expensive capabilities. They require coordination and are increasing contention in order to keep data consistent. When having to horizontally scale among data centers (especially among different geographic regions), the problems become significantly harder. Providing high levels of consistency can be extremely hard as availability decreases and networking partitions happen more often. See the &lt;a rel="noopener nofollow" href="https://en.wikipedia.org/wiki/CAP_theorem"&gt;CAP theorem&lt;/a&gt; for a more general explanation of this phenomena. It is worth to also note that applications can handle a bit of inconsistency or programmers might have enough insights about the problem to add additional logic in the application to handle it without heavily relying on their database.&lt;/p&gt;&lt;p id="6dcf"&gt;Databases often provide a variety of isolation layers so the application developers can pick the most cost effective one based on their tradeoffs. Weaker isolation can be faster but may introduce data races. Stronger isolation eliminates some potential data races but will be slower and might introduce contention that will slow down the database to a point it may cause outages.&lt;/p&gt;&lt;figure&gt;&lt;a href="https://jepsen.io/consistency"&gt;&lt;div&gt;&lt;p&gt;&lt;img height="514" width="759" src="https://miro.medium.com/max/60/1*x95aVFq-wMB6VrI9AD4k8Q.png?q=20" alt="Image for post"&gt;&lt;/p&gt;&lt;/div&gt;&lt;/a&gt;&lt;figcaption&gt;An overview of the existing concurrency models and the relationships between them.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p id="7544"&gt;The SQL standard only defines four isolation levels even though there are more levels theoretically and practically available. &lt;a rel="noopener nofollow" href="https://jepsen.io/consistency"&gt;jepson.io&lt;/a&gt; provides a compelling overview of the existing concurrency models if you need further reading. For example, Google’s Spanner guarantee external serializability with clock synchronization and even though this is a stricter isolation layer, it is not defined in the standard isolation layers.&lt;/p&gt;&lt;p id="d831"&gt;The isolation levels mentioned in the SQL standard are:&lt;/p&gt;&lt;ul&gt;&lt;li id="89ca"&gt;&lt;strong&gt;Serializable&lt;/strong&gt; (most strict, expensive): A serializable execution produces the same effect as some serial execution of those transactions. A serial execution is one in which each transaction executes to completion before the next transaction begins. One note about &lt;em&gt;Serializable&lt;/em&gt; level is that it is often implemented as “snapshot isolation” (e.g. Oracle) due to differences in interpretation and “snapshot isolation” is not represented in the SQL standard.&lt;/li&gt;&lt;li id="9b7b"&gt;&lt;strong&gt;Repeatable reads&lt;/strong&gt;: Uncommitted reads in the current transaction are visible to the current transaction but changes made by other transactions (such as newly inserted rows) won’t be visible.&lt;/li&gt;&lt;li id="7987"&gt;&lt;strong&gt;Read committed&lt;/strong&gt;: Uncommitted reads are not visible to the transactions. Only committed writes are visible but the phantom reads may happen. If another transaction inserts and commits new rows, the current transaction can see them when querying.&lt;/li&gt;&lt;li id="08dd"&gt;&lt;strong&gt;Read uncommitted&lt;/strong&gt; (least strict, cheap): Dirty reads are allowed, transactions can see not-yet-committed changes made by other transactions. In practice, this level could be useful to return approximate aggregates, such as COUNT(*) queries on a table.&lt;/li&gt;&lt;/ul&gt;&lt;p id="1278"&gt;Serializable level allows least opportunities for data races to happen although being the most expensive and introduces the most contention to the system. Other isolation levels are cheaper but increases the possibility of data races. Some databases allow you to set your isolation level, some databases are more opinionated about them and not necessarily supporting all of them.&lt;/p&gt;&lt;p id="d9f7"&gt;Even though databases advertise their support for these isolation levels, a careful examination of their behavior may provide more insights on what the actually do.&lt;/p&gt;&lt;figure&gt;&lt;div tabindex="0" role="button"&gt;&lt;p&gt;&lt;img height="514" width="927" src="https://miro.medium.com/max/60/1*UUEYw0PyXpyGFcT9OsDeuA.png?q=20" alt="Image for post"&gt;&lt;/p&gt;&lt;/div&gt;&lt;figcaption&gt;An overview of concurrency anomalies at different isolation levels per database.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p id="6073"&gt;Martin Kleppmann’s &lt;a rel="noopener nofollow" href="https://github.com/ept/hermitage"&gt;hermitage&lt;/a&gt; provides an overview of different concurrency anomalies and whether a database is able to handle it at a particular isolation level. Kleppmann’s research shows how isolation levels can be interpreted differently by database designers.&lt;/p&gt;&lt;h2 id="00db"&gt;Optimistic locking is an option when you can’t hold a lock.&lt;/h2&gt;&lt;p id="fd0e"&gt;Locks can be extremely expensive not only because they introduce more contention in your database but they might require consistent connections from your application servers to the database. Exclusive locks can be effected by network partitions more significantly and cause deadlocks that are hard to identify and resolve. In cases where being able to hold exclusive locks is not easy, optimistic locking is an option.&lt;/p&gt;&lt;p id="668d"&gt;&lt;a rel="noopener nofollow" href="https://convincedcoder.com/2018/09/01/Optimistic-pessimistic-locking-sql/#optimistic-locking-using-where"&gt;Optimistic locking&lt;/a&gt; is a method when you read a row, you take note of a version number, last modified timestamps or its checksum. Then you can check the version hasn’t changed atomically before you mutate the record.&lt;/p&gt;&lt;pre&gt;&lt;span id="6769"&gt;UPDATE products&lt;br&gt;SET name = 'Telegraph receiver', version = 2 &lt;br&gt;WHERE id = 1 AND version = 1&lt;/span&gt;&lt;/pre&gt;&lt;p id="77ba"&gt;Update to products table is going to affect 0 rows if another update has changed this row earlier. If no earlier updates have been done, it will affect 1 row and we can tell our update has succeeded.&lt;/p&gt;&lt;h2 id="a53b"&gt;There are anomalies other than dirty reads and data loss.&lt;/h2&gt;&lt;p id="5aac"&gt;When we are talking about data consistency, we primarily pay a lot of attention to possible race conditions that can lead to dirty reads and data loss. But anomalies with data are not just limited to them.&lt;/p&gt;&lt;p id="de38"&gt;An example of this type of anomalies is write skews. Write skews are harder to identify because we are not actively looking for them. Write skews are caused not when dirty reads happen on writes or lost but logical constraints on data is compromised.&lt;/p&gt;&lt;p id="0b31"&gt;For example, assume a monitoring application that requires one person among their operators to be oncall all the times.&lt;/p&gt;&lt;pre&gt;&lt;span id="73b7"&gt;BEGIN tx1; BEGIN tx2;&lt;/span&gt;&lt;span id="4063"&gt;SELECT COUNT(*) &lt;br&gt;FROM operators&lt;br&gt;WHERE oncall = true;&lt;br&gt;0 SELECT COUNT(*)&lt;br&gt; FROM operators&lt;br&gt; WHERE oncall = TRUE;&lt;br&gt; 0&lt;/span&gt;&lt;span id="261d"&gt;UPDATE operators UPDATE operators&lt;br&gt;SET oncall = TRUE SET oncall = TRUE&lt;br&gt;WHERE userId = 4; WHERE userId = 2;&lt;/span&gt;&lt;span id="4163"&gt;COMMIT tx1; COMMIT tx2;&lt;/span&gt;&lt;/pre&gt;&lt;p id="1639"&gt;In the situation above, there will be a write skew if two of the transactions successfully commit. Even though no dirty read or data loss happened, the integrity of data is lost because there are two people assigned to be oncall.&lt;/p&gt;&lt;p id="f31c"&gt;Serializable isolation, schema design or database constraints can be helpful to eliminate write skews. Developers need to be able to identify such anomalies during development to avoid data anomalies in production. Having said that, identifying write skews in code bases can be extremely hard. Especially in large systems, if different teams are responsible for building features based on same tables without talking to each other and examining how they access the data.&lt;/p&gt;&lt;h2 id="b6a1"&gt;My database and I don’t always agree on ordering.&lt;/h2&gt;&lt;p id="7f27"&gt;One of the core capabilities databases offer is the ordering guarantees but ordering may be surprising to the application developer. Databases see transactions in the order they receive them not in the programming order developers see them. The order of the transaction execution is hard to predict especially in high-volume concurrent systems.&lt;/p&gt;&lt;p id="41b2"&gt;In development time, especially when working with non-blocking libraries, poor style and readability may contribute to the problem where users think transactions are executed sequentially even though they can arrive at the database at any order. The program below makes it look like T1 and T2 are going to be invoked sequentially, but if these functions are non-blocking and return immediately with a promise, the order of the invocation will be up to the time they have received at the database.&lt;/p&gt;&lt;pre&gt;&lt;span id="d46e"&gt;result1 = T1() // results are actually promises&lt;br&gt;result2 = T2()&lt;/span&gt;&lt;/pre&gt;&lt;p id="fc7a"&gt;If atomicity is required (to either fully commit or abort all operations) and the sequence matter, the operations in T1 and T2 should run in a single database transaction.&lt;/p&gt;&lt;h2 id="86a9"&gt;Application-level sharding can live outside the application.&lt;/h2&gt;&lt;p id="66b4"&gt;Sharding is a way to horizontally partition your database. Even though some databases can automatically partition data horizontally, some don’t or may not be good at it. When data architects/developers can predict how data is going to be accessed, they might create horizontal partitions at the user-land instead of delegating this work to their database. This is called application-level sharding.&lt;/p&gt;&lt;p id="8aa8"&gt;The name, application-level sharding, often gives the wrong impression that sharding should live in the application services. Sharding capabilities can be implemented as a layer in front of your database. Depending on data growth and schema iterations, sharding requirements might get complicated. Being able to iterate on some strategies without having to redeploy application servers may be useful.&lt;/p&gt;&lt;figure&gt;&lt;div&gt;&lt;p&gt;&lt;img height="217" width="529" src="https://miro.medium.com/max/60/1*8_yDPQbGxMb7Zv_UBs4pTQ.png?q=20" alt="Image for post"&gt;&lt;/p&gt;&lt;/div&gt;&lt;figcaption&gt;An example architecture where application servers are decoupled from the sharding service..&lt;/figcaption&gt;&lt;/figure&gt;&lt;p id="0ce7"&gt;Having sharding as a separate service can increase your capabilities on iterating on sharding strategies without having to redeploy your applications. One such example of an application-level sharding system is &lt;a rel="noopener nofollow" href="https://youtu.be/OCS45iy5v1M?t=204"&gt;Vitess&lt;/a&gt;. Vitess provides horizontal sharding for MySQL and allows clients to connect to it via the MySQL protocol and it shards the data on various MySQL nodes that don’t know about each other.&lt;/p&gt;&lt;h2 id="04fb"&gt;AUTOINCREMENT’ing can be harmful.&lt;/h2&gt;&lt;p id="b136"&gt;AUTOINCREMENT’ing is a common way of generating primary keys. It’s not uncommon to see cases where databases are used as ID generators and there are ID-generation designated tables in a database. There are a few reasons why generating primary keys via auto-incrementing may not be not ideal:&lt;/p&gt;&lt;ul&gt;&lt;li id="3286"&gt;In distributed database systems, auto-incrementing is a hard problem. A global lock would be needed to be able to generate an ID. If you can generate a UUID instead, it would not require any collaboration between database nodes. Auto-incrementing with locks may introduce contention and may significantly downgrade the performance for insertions in distributed situations. Some databases like MySQL may require specific &lt;a rel="noopener nofollow" href="https://www.percona.com/blog/2011/01/12/conflict-avoidance-with-auto_increment_incremen-and-auto_increment_offset/"&gt;configuration&lt;/a&gt; and more attention to get things right in master-master replication. The configuration is easy to mess up and can lead to write outages.&lt;/li&gt;&lt;li id="9fcb"&gt;Some databases have partitioning algorithms based on primary keys. Sequential IDs may cause unpredictable hotspots and may overwhelm some partitions while others stay idle.&lt;/li&gt;&lt;li id="09dd"&gt;The fastest way to access to a row in a database is by its primary key. If you have better ways to identify records, sequential IDs may make the most significant column in tables a meaningless value. Please pick a globally unique natural primary key (e.g. a username) where possible.&lt;/li&gt;&lt;/ul&gt;&lt;p id="6037"&gt;Please consider the impacts of auto-incremented IDs vs UUIDs on indexing, partitioning and sharding before you decide on what works better for you.&lt;/p&gt;&lt;h2 id="d43b"&gt;Stale data can be useful and lock-free.&lt;/h2&gt;&lt;p id="7695"&gt;Multi-version concurrency control (MVCC) enables a lot of the consistency features we briefly discussed above. Some databases (e.g. Postgres, Spanner) uses MVCC to allow each transaction to see a snapshot, an older version of the database. Transactions against snapshots still can be serializable for consistency. When reading from an old snapshot, you read stale data.&lt;/p&gt;&lt;p id="26d0"&gt;Reading slightly stale data would be useful, for example when you are generating analytics from your data or calculating approximate aggregate values.&lt;/p&gt;&lt;p id="4c13"&gt;The first advantage of reading stale data would be latency (especially if your database is distributed among different geographical regions). The second advantage of a MVCC database is that it would allow read-only transactions to to be lock-free. A major advantage in a read-heavy application if the stale data can be tolerated.&lt;/p&gt;&lt;figure&gt;&lt;div tabindex="0" role="button"&gt;&lt;p&gt;&lt;img height="348" width="749" src="https://miro.medium.com/max/60/1*ePJGd32VU4esxofh5LP69Q.png?q=20" alt="Image for post"&gt;&lt;/p&gt;&lt;/div&gt;&lt;figcaption&gt;Application server reads 5-second old stale data from local replica even though the latest version is available on the other side of the Pacific Ocean.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p id="6762"&gt;Databases sweep the old versions automatically and in some cases, they allow you to do that on demand. For example, Postgres allows users to &lt;code&gt;VACUUM&lt;/code&gt; on demand as well as automatically vacuuming once a while, and Spanner runs a garbage collector to get rid of the versions older than an hour.&lt;/p&gt;&lt;h2 id="0f3a"&gt;Clock skews happen between any clock sources.&lt;/h2&gt;&lt;p id="4117"&gt;The most well-hidden secret in computing is that all time APIs lie. Our machines don’t accurately know what the current time is. Our computers all contain a quartz crystal that produces a signal to tick time. But quartz crystals can’t accurately tick and drift in time, either faster or slower than the actual clock. Drift could be up to 20 seconds a day. The time on our computers need to be synchronized by the actual time every now and then for accuracy.&lt;/p&gt;&lt;p id="b823"&gt;NTP servers are used for synchronization but synchronization itself could be delayed due to network. When synchronizing with an NTP server in the same data center can take time, syncing with a public NTP server may cause more skew.&lt;/p&gt;&lt;p id="8efb"&gt;Atomic and GPS clocks are better sources to determine the current time but they are expensive and need complicated setup that they cannot be installed on every machine. Given the limitations, in data centers, a multi-tiered approach is used. While atomic and/or GPS clocks are providing accurate timing, their time is broadcasted to the rest of the machines via secondary servers. This means every machine will be drifted from the actual current time with some magnitude.&lt;/p&gt;&lt;p id="cc30"&gt;There is more… Applications and databases often live in different machines (if not in different centers). Not just that database nodes distributed in a few machines won’t be able to agree on what the time is, application server clock and a database node clock won’t agree either.&lt;/p&gt;&lt;p id="e002"&gt;Google’s TrueTime is following a different approach here. Most people think Google’s progress in clocks can be attributed to their use of atomic and GPS clocks, but that’s only the part of the story. This is what TrueTime does:&lt;/p&gt;&lt;ul&gt;&lt;li id="c6fd"&gt;TrueTime uses two different sources: GPS and atomic clocks. These clocks have different fail modes, hence using both of them is increasing the reliability.&lt;/li&gt;&lt;li id="e674"&gt;TrueTime has an unconventional API. It returns the time as an interval. The time could be in fact anywhere between the lower bound and the upper bound. Google’s distributed database Spanner then can wait until it is certain the current time is beyond a particular time. This method adds some latency to the system especially when the uncertainty advertised by masters are high but provides correctness even in a globally distributed situation.&lt;/li&gt;&lt;/ul&gt;&lt;figure&gt;&lt;div&gt;&lt;p&gt;&lt;img height="97" width="687" src="https://miro.medium.com/max/60/1*PT3Xi-fBznMiYtH9_EmJUA.png?q=20" alt="Image for post"&gt;&lt;/p&gt;&lt;/div&gt;&lt;figcaption&gt;Spanner components use TrueTime where TT.now() returns an interval, so Spanner can inject sleeps to ensure the current time has passed a particular timestamp.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p id="6346"&gt;As the confidence on the current time decreases, it means Spanner operations might take more time. This is why even though having accurate clocks would be impossible, it is still important to keep the confidence high for performance.&lt;/p&gt;&lt;h2 id="02bc"&gt;Latency has many meanings.&lt;/h2&gt;&lt;p id="d902"&gt;If you ask ten people in a room what “latency” means, they may all have different answers. In databases, latency is often referred to “database latency” but not the latency client perceives. Client will see a latency of database latency and network latency. Being able to identify client and database latency is critical when debugging escalating problems. When collecting and displaying metrics, always consider having both.&lt;/p&gt;&lt;h2 id="add2"&gt;Evaluate performance requirements per transaction.&lt;/h2&gt;&lt;p id="5c24"&gt;Sometimes databases advertise their performance characteristics and limitations in terms of write and read throughput and latency. Although this may give a high level overview of the major blockers, when evaluating a new database for performance, a more comprehensive approach is to evaluate critical operations (per query and/or per transaction) separately. Examples:&lt;/p&gt;&lt;ul&gt;&lt;li id="8fc9"&gt;Write throughput and latency when inserting a new row in to table X (with 50M rows) with given constraints and populating rows in related tables.&lt;/li&gt;&lt;li id="7747"&gt;Latency when querying the friends of friends of a user when average number of friends is 500.&lt;/li&gt;&lt;li id="007f"&gt;Latency of retrieving the top 100 records for the user timeline when user is subscribed to 500 accounts which has X entries per hour.&lt;/li&gt;&lt;/ul&gt;&lt;p id="3903"&gt;Evaluation and experimentation might contain such critical cases until you are confident that a database will be able to serve your performance requirements. A similar thumb of rule is also considering this breakdown when collecting latency metrics and setting SLOs.&lt;/p&gt;&lt;p id="0717"&gt;Be careful about high cardinality when collecting metrics per operation. Use logs, even collection or distributed tracing if you need high cardinality debugging data. See &lt;a rel="noopener" href="https://medium.com/observability/want-to-debug-latency-7aa48ecbe8f7"&gt;Want to Debug Latency?&lt;/a&gt; for an overview on latency debugging methodologies.&lt;/p&gt;&lt;h2 id="e14c"&gt;Nested transactions can be harmful.&lt;/h2&gt;&lt;p id="f945"&gt;Not every database supports nested transactions but when they do, nested transactions may cause surprising programming errors that are not always easy to identify until it becomes clear that you are seeing anomalies.&lt;/p&gt;&lt;p id="8b0a"&gt;If you’d like to avoid nested transactions, client libraries can do work to detect and avoid nested transactions. If you can’t avoid them, you have to pay attention to avoid ending up surprising situations where committed transactions are accidentally aborted due to a child transaction.&lt;/p&gt;&lt;p id="9545"&gt;Encapsulating transactions in different layers can contribute to surprising nested transaction cases and from a readability point-of-view, it might be hard to understand the intend. Take a look at the following program:&lt;/p&gt;&lt;pre&gt;&lt;span id="7727"&gt;with newTransaction():&lt;br&gt; Accounts.create("609-543-222")&lt;/span&gt;&lt;span id="60d3"&gt; with newTransaction():&lt;br&gt; Accounts.create("775-988-322")&lt;br&gt; throw Rollback();&lt;/span&gt;&lt;/pre&gt;&lt;p id="ff90"&gt;What’s going to be the result of the code above? Is it going to rollback both of the transactions or only the inner one? What happens if we were relying on multiple layers of libraries that were encapsulating the transaction creation from us. Would we be able to identify and improve such cases?&lt;/p&gt;&lt;p id="b477"&gt;Imagine a data-layer with several operations (e.g. newAccount) already is implemented in their own transactions. What happens when you run them in higher level business logic that runs in it own transaction? What would be the isolation and consistency characteristics would be?&lt;/p&gt;&lt;pre&gt;&lt;span id="0a86"&gt;function newAccount(id string) {&lt;br&gt; with newTransaction():&lt;br&gt; Accounts.create(id)&lt;br&gt;}&lt;/span&gt;&lt;/pre&gt;&lt;p id="934c"&gt;Instead of dealing with such open-ended questions, avoid nested transactions. Your data layer can still implement high level operations without creating their own transactions. Then, business logic can start transactions, run the operations on the transaction, commit or abort.&lt;/p&gt;&lt;pre&gt;&lt;span id="db55"&gt;function newAccount(id string) {&lt;br&gt; Accounts.create(id)&lt;br&gt;}&lt;/span&gt;&lt;span id="96da"&gt;// In main application:&lt;/span&gt;&lt;span id="7274"&gt;with newTransaction():&lt;br&gt; // Read some data from database for configuration.&lt;br&gt; // Generate an ID from the ID service.&lt;br&gt; Accounts.create(id)&lt;/span&gt;&lt;span id="4a16"&gt; Uploads.create(id) // create upload queue for the user.&lt;/span&gt;&lt;/pre&gt;&lt;h2 id="e9bb"&gt;Transactions shouldn’t maintain application state.&lt;/h2&gt;&lt;p id="bf95"&gt;Application developers might want to use application state in transactions to update certain values or tweaks the query parameters. One critical thing to consider is to having the scope right. Clients often retry the transactions when networking issues happen. If a transaction is relying on state that is mutated elsewhere, it might pick the wrong value depending on the possibility of the data races in the problem. Transactions should be careful about in-application data races.&lt;/p&gt;&lt;pre&gt;&lt;span id="4c92"&gt;var seq int64&lt;/span&gt;&lt;span id="af3d"&gt;with newTransaction():&lt;br&gt; newSeq := atomic.Increment(&amp;amp;seq)&lt;br&gt; Entries.query(newSeq)&lt;/span&gt;&lt;span id="c061"&gt; // Other operations...&lt;/span&gt;&lt;/pre&gt;&lt;p id="601f"&gt;The transaction above will increase the sequence number each time it runs regardless of its end result. If commit fails due to network, on the second retry, it will query with a different sequence number.&lt;/p&gt;&lt;h2 id="7918"&gt;Query planners can tell about databases.&lt;/h2&gt;&lt;p id="40cc"&gt;Query planners determine how your query is going to be executed in the database. They also analyze the queries and optimize them before running. Planners can only provide some possible estimations based on signals it has. How to tell how to find the results for the following query:&lt;/p&gt;&lt;pre&gt;&lt;span id="93c0"&gt;SELECT * FROM articles where author = "rakyll" order by title;&lt;/span&gt;&lt;/pre&gt;&lt;p id="79c1"&gt;There are two ways to retrieve the results:&lt;/p&gt;&lt;ul&gt;&lt;li id="7b9d"&gt;&lt;strong&gt;Full table scan&lt;/strong&gt;: We can go through every entry on the table and return the articles where author name is matching, then order.&lt;/li&gt;&lt;li id="2b03"&gt;&lt;strong&gt;Index scan&lt;/strong&gt;: We can use an index to find the matching IDs, retrieve those rows and then order.&lt;/li&gt;&lt;/ul&gt;&lt;p id="02e5"&gt;Query planner’s role is to determine which strategy is the best option. Query planners have limited signals about what they can predict and might result in poor decisions. DBAs or developers can use them to diagnose and fine tune poorly performing queries. New releases of databases can tweak query planners and self-diagnosing them can help you when upgrading your database if new version introduces performance problems. Reports such as the slow query logs, latency problems, or stats on execution times could be useful to determine the queries to optimize.&lt;/p&gt;&lt;p id="d6dc"&gt;Some metrics the query planner provides could be noisy, especially when it estimates latency or CPU time. As a supplement to query planners, tracing and execution path tools can be more useful to diagnose these issues even though not every database provides such tools.&lt;/p&gt;&lt;h2 id="d262"&gt;Online migrations are complex but possible.&lt;/h2&gt;&lt;p id="7f25"&gt;Online, realtime or live migrations mean migrating from one database to another without downtime and compromising data correctness. Live migrations are easier if you you are migrating to the same database/engine, but can get more complicated when migrating to a new database with different performance characteristics and schema requirements.&lt;/p&gt;&lt;p id="22b8"&gt;There are different models when it comes to online migrations, here is &lt;a rel="noopener nofollow" href="http://www.aviransplace.com/2015/12/15/safe-database-migration-pattern-without-downtime/#ixzz3vsEunxmA"&gt;one&lt;/a&gt;:&lt;/p&gt;&lt;ul&gt;&lt;li id="d079"&gt;Start doing dual writes to both databases. At this stage, new database won’t have all the data but will start seeing the new ones. Once you are confident about this step, you can move on to the second.&lt;/li&gt;&lt;li id="5c27"&gt;Start enabling the read path to use both databases.&lt;/li&gt;&lt;li id="5bed"&gt;Use the new database primarily for reads and writes.&lt;/li&gt;&lt;li id="597b"&gt;Stop writing to the old database although keep reading from the old database. At this point, new database still doesn’t have all the new data and you might need to fallback to the old database for old records.&lt;/li&gt;&lt;li id="0103"&gt;At this point, old database is read-only. Backfill the new database with the missing data from the old database. Once migration is complete, all the read and write paths can use the new database and the old database can be removed from your system.&lt;/li&gt;&lt;/ul&gt;&lt;p id="5cce"&gt;If you need more caste studies, see Stripe‘s comprehensive &lt;a rel="noopener nofollow" href="https://stripe.com/blog/online-migrations"&gt;article&lt;/a&gt; on their migration strategy that follows this model.&lt;/p&gt;&lt;h2 id="8540"&gt;Significant database growth introduces unpredictability.&lt;/h2&gt;&lt;p id="85e5"&gt;Database growth makes you experience unpredictable scale issues. The more we know about the internals of our databases, the less we might predict how they might scale but there are things we can’t predict.&lt;/p&gt;&lt;p id="6fbe"&gt;With growth, previous assumptions or expectations on data size and network capacity requirements can become obsolete. This is when large scheme rewrites, large-scale operational improvements, capacity issues, deployment reconsiderations or migrating to other databases happen to avoid outage.&lt;/p&gt;&lt;p id="4480"&gt;Don’t assume knowing a lot about the internals of your current database is the only thing you need, scale will introduce new unknowns. Unpredictable hotspots, uneven distribution of data, unexpected capacity and hardware problems, ever growing traffic and new network partitions will make you reconsider your database, your data model, your deployment model and the size of your deployment.&lt;/p&gt;&lt;p id="505e"&gt;—&lt;/p&gt;&lt;p id="3aa0"&gt;When I mentioned about potentially publishing this article, I already had five more items on my initial draft. Then, I received an overwhelming amount of new &lt;a rel="noopener nofollow" href="https://twitter.com/rakyll/status/1249771259023392768"&gt;ideas&lt;/a&gt; on what else to capture. I tried keep the scope limited to the least obvious problems that need the most attention. This doesn’t mean I won’t get to write more on this topic and won’t keep updating this document.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;a href="https://medium.com/@rakyll/things-i-wished-more-developers-knew-about-databases-2d0178464f78"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Wed, 22 Apr 2020 11:31:08 UT
      </pubDate>
      <guid>
        https://medium.com/@rakyll/things-i-wished-more-developers-knew-about-databases-2d0178464f78
      </guid>
    </item>
    <item>
      <title>
        Understanding BERT and Search Relevance - OpenSource Connections
      </title>
      <link>
        https://opensourceconnections.com/blog/2019/11/05/understanding-bert-and-search-relevance/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;article id="post-1542"&gt;&lt;div&gt;&lt;figure&gt;&lt;img alt="Complexity" data-src="/images/complex-664440_1280.jpg" src="https://opensourceconnections.com/images/complex-664440_1280.jpg"&gt;&lt;/figure&gt;&lt;p&gt;There is a growing topic in search these days. The hype of BERT is all around us, and while it is an amazing breakthrough in contextual representation of unstructured text, newcomers to natural language processing (NLP) are left scratching their heads wondering how and why it is changing the field. Many of the examples are tailored for tasks such as text classification, language understanding, multiple choice, and question answering. So what about just plain-old findin’ stuff? This article gives an overview into the opportunities and challenges when applying advanced transformer models such as BERT to search.&lt;/p&gt;&lt;h2 id="whats-bert-and-why-is-it-important"&gt;What’s BERT and why is it important?&lt;/h2&gt;&lt;p&gt;BERT, which stands for Bidirectional Encoder Representations from Transformers is a deep learning architecture developed by Google for NLP. It is one of several approaches that leverages &lt;em&gt;transformer&lt;/em&gt; architecture. Transformers address a gap in previous architectures such as recurrent and long short-term memory neural networks, with the key difference being the focus on maintaining attention during training using a bidirectional encoder. Plenty of articles have been written about this recently. So, I won’t dive into the details of how or why this works, but I’ve added links at the bottom for further reading if you want to learn more. The important part for the practitioner is that pre-trained models and open source libraries have been released to the public for use by anyone. You don’t need to train your own model and you can use these as they are, or for transfer learning (referred to as fine-tuning in BERT).&lt;/p&gt;&lt;p&gt;What happens when you use these models is what we’ll focus on here. When you, for example, pass a document’s text through a pre-trained model using a transformer network, you get back a tensor, which is comprised of a vector representation for each token. One pre-trained large uncased model for BERT uses a feature vector of 768 floating point values. 768 features for a token, yielded from such a sophisticated model, contains a highly accurate dense contextual representation of the meaning of that token that can be further used. Also importantly, if the document has 234 words in it, you’ll get a tensor with the dimension of 234×768. If your document has 172 words, your tensor is 172×768, and so on.&lt;/p&gt;&lt;p&gt;Traditional search in inverted indexes such as Lucene maintains &lt;em&gt;zero&lt;/em&gt; context for each token – as all the words are all usually analyzed in isolation. Relevance engineers spend lots of time working around this problem. Without linguistic context, it is very difficult to associate any meaning to the words, and so search becomes a manually tuned matching system, with statistical tools for ranking.&lt;/p&gt;&lt;h2 id="how-can-we-use-bert-for-search"&gt;How can we use BERT for search?&lt;/h2&gt;&lt;p&gt;So what can you do with this tensor information? Well that’s the question at hand for many search engineers these days. We’ve been given this immensely powerful tool, and are trying to figure out how we can apply it to make relevance tuning easier and less prone to silly language issues we commonly face. Before you jump out of your chair shouting this is a solution looking for a problem, remember, the problem is that search in its current form has no connection to language and meaning. So we need to see how these two match up for a better future together.&lt;/p&gt;&lt;p&gt;The main area of exploration for search with BERT is similarity. Similarity between documents for recommendations, and similarity between &lt;em&gt;queries and documents&lt;/em&gt; for returning and ranking search results. Why? Because search relevance can be phrased as a similarity problem. What documents are most similar to what the user is trying to convey with their query? If you can use similarity to solve this problem with highly accurate results, then you’ve got a pretty great search for your product or application.&lt;/p&gt;&lt;p&gt;Commonly, the approach is to use a nearest neighbor algorithm. This takes two or more vectors, and calculates the distance (or similarity) between them in an efficient manner. To use a simple example, let’s say we’ve got two people – Alice, standing 5 meters away from a water fountain, and Bob, standing 7 meters away from the water fountain. Who is standing closest to the fountain? Alice of course. Now Carrie joins the group and stands 8 meters from the fountain. So who is Carrie standing closest to? Alice or Bob? Well, that’s easy – it’s Bob. That’s similarity with a vector of one feature. We can also have a vector of two features, such as latitude and longitude coordinates, and use that calculate who is standing closest to the fountain and who are standing in groups close to each other.&lt;/p&gt;&lt;p&gt;When we need to do this with more features, such as 3, 10, or even 768, across thousands or millions of words and documents, things get complicated. So we turn to approximate nearest neighbor algorithms to efficiently calculate this similarity as fast as possible across all these dimensions.&lt;/p&gt;&lt;p&gt;And that brings us to where much of the recent practical development has been focusing on: Efforts to apply this type of nearest neighbor calculation to documents that we index in a search engine, and also the queries that people use in the search bar. Because if you can represent all your documents as rich sets of vectors that contain embedded meaning, and cross reference those with a query also represented by a rich set of vectors, you can see which documents are most similar to the query!&lt;/p&gt;&lt;h2 id="making-progress-with-some-obstacles"&gt;Making progress, with some obstacles&lt;/h2&gt;&lt;p&gt;There’s some great stuff happening to make the above nearest neighbor tools available for use inside of search engines. Several approaches are being built to allow arbitrary vectors to be indexed inside of Lucene, and Vespa already supports indexing vectors. However, the sizes noted above are not really practical. For example, vectorizing short (three or four sentence) overview text data from 28000 movie documents balloons the representative size from 5MB to 5GB! That’s a whopping 1000x increase in size! And 28000 really isn’t very many documents.&lt;/p&gt;&lt;p&gt;There are investigations underway to distill these huge document tensors into a more maintainable size. Areas of research include fine-tuning by using another model on top of BERT for a smaller representation, or just trying to average some of the dimensions together. The problem with these approaches is as you shrink or compress the size, you lose more of the context that the original model provided. So careful testing for each dataset needs to be performed to ensure the accuracy stays reasonable as the representation is compressed.&lt;/p&gt;&lt;p&gt;This is also a very different way of doing things than most search teams are used to. Handling large models that need GPUs for effective speed, and querying across vectors instead of terms, requires a shift in technology, infrastructure, and practice. Also, debugging such a system becomes exceedingly difficult. These models are black boxes, and explainable AI is an open area of research that is out of reach for most practitioners. When you get a strange result from Lucene, you can dig down and see exactly why the result was returned. But when a document or query yields a tensor, knowing why that tensor was produced and what it means is more or less impossible.&lt;/p&gt;&lt;h2 id="the-problem-with-queries"&gt;The problem with queries&lt;/h2&gt;&lt;p&gt;All the above is wonderful, but there’s another problem – how people search. Think yourself about how you search, when approached with a need to get information from a website or from a web search engine like Google. Do you type an elaborately crafted sentence as if you were asking another person? Of course not. You type one or two words, typically a noun phrase, for what you want to find. Don’t feel bad – everyone does this, even me! People usually don’t give enough context to search engines for most of their queries. But you can’t blame people for this problem – we’ve been doing this for years because that’s how search engines usually work.&lt;/p&gt;&lt;p&gt;When you perform a similarity between those short queries and lots of documents, you are faced with the same age-old information retrieval problem: ambiguity. No matter how advanced your technology is, if people don’t provide enough context to search on, your engine is going to have a difficult time returning exactly what they were thinking. You will get documents back that reflect the meaning of the terms better, but they might not be ranked the way you expect.&lt;/p&gt;&lt;h2 id="tradeoffs-and-next-steps"&gt;Tradeoffs and next steps&lt;/h2&gt;&lt;p&gt;Search is full of trade-offs. How much time can you reasonably spend to get search right? How much money is worth improving search for 10% of your queries? Everyone has deadlines. Everyone has budgetary restrictions. Lots of smart people are working hard to make this technology cheaply available and accessible to search teams who can use it to benefit customers. Keep an eye out for more updates, as this represents the biggest shift search has seen in years, so you’re likely to see many more articles, tutorials, software, and training soon.&lt;/p&gt;&lt;h4&gt;If you’re interested in learning about and potentially applying some of the techniques described above to empower your search team, please &lt;a href="https://opensourceconnections.com/contact/"&gt;contact us&lt;/a&gt;!&lt;/h4&gt;&lt;h2 id="further-reading"&gt;Further reading&lt;/h2&gt;&lt;p&gt;These links below provide more in depth information for the concepts explained above.&lt;/p&gt;&lt;h3 id="academic-papers-on-bert-and-attention-models"&gt;Academic papers on BERT and attention models&lt;/h3&gt;&lt;p&gt;&lt;a href="https://arxiv.org/abs/1810.04805"&gt;BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://arxiv.org/pdf/1706.03762.pdf"&gt;Attention Is All You Need&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://nlp.seas.harvard.edu/2018/04/03/attention.html"&gt;The Annotated Transformer&lt;/a&gt;&lt;/p&gt;&lt;h3 id="articles-explaining-bert-in-simpler-overviews"&gt;Articles explaining BERT in simpler overviews&lt;/h3&gt;&lt;p&gt;&lt;a href="https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270"&gt;BERT explained&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.analyticsvidhya.com/blog/2019/09/demystifying-bert-groundbreaking-nlp-framework/"&gt;Demystifying BERT&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://blog.google/products/search/search-language-understanding-bert/"&gt;Understanding searches better than ever before&lt;/a&gt;&lt;/p&gt;&lt;h3 id="libraries-for-using-bert-and-other-transformers"&gt;Libraries for using BERT and other transformers&lt;/h3&gt;&lt;p&gt;&lt;a href="https://huggingface.co/transformers/"&gt;Huggingface Transformers&lt;/a&gt;&lt;/p&gt;&lt;h3 id="investigations-of-berts-true-practicality"&gt;Investigations of BERT’s true practicality&lt;/h3&gt;&lt;p&gt;&lt;a href="https://thegradient.pub/nlps-clever-hans-moment-has-arrived/"&gt;NLP’s Clever Hans Moment Has Arrived&lt;/a&gt;&lt;/p&gt;&lt;h3 id="arbitrarily-dense-vector-search"&gt;Arbitrarily dense vector search&lt;/h3&gt;&lt;p&gt;&lt;a href="https://github.com/o19s/hangry"&gt;https://github.com/o19s/hangry&lt;/a&gt;&lt;br&gt;&lt;a href="https://github.com/castorini/anserini/blob/master/docs/approximate-nearestneighbor.md"&gt;https://github.com/castorini/anserini/blob/master/docs/approximate-nearestneighbor.md&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://arxiv.org/abs/1910.10208"&gt;https://arxiv.org/abs/1910.10208&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://github.com/jobergum/dense-vector-ranking-performance"&gt;https://github.com/jobergum/dense-vector-ranking-performance&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://docs.vespa.ai/documentation/reference/tensor.html"&gt;Tensors in Vespa&lt;/a&gt;&lt;/p&gt;&lt;h4 id="attributions"&gt;Attributions&lt;/h4&gt;&lt;p&gt;Image by Pete Linforth&lt;/p&gt;&lt;/div&gt;&lt;/article&gt;&lt;/div&gt;&lt;a href="https://opensourceconnections.com/blog/2019/11/05/understanding-bert-and-search-relevance/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Wed, 22 Apr 2020 12:21:44 UT
      </pubDate>
      <guid>
        https://opensourceconnections.com/blog/2019/11/05/understanding-bert-and-search-relevance/
      </guid>
    </item>
    <item>
      <title>
        98.css - A design system for building faithful recreations of old UIs
      </title>
      <link>
        https://jdan.github.io/98.css/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt; &lt;h2&gt;98.css&lt;/h2&gt; &lt;hr&gt; &lt;p&gt;A design system for building faithful recreations of old UIs.&lt;/p&gt; &lt;p&gt; &lt;a rel="nofollow" href="http://npm.im/98.css"&gt; &lt;img src="https://98badges.now.sh/api/version" alt="npm"&gt; &lt;/a&gt; &lt;a rel="nofollow" href="https://unpkg.com/98.css"&gt; &lt;img src="https://98badges.now.sh/api/size" alt="gzip size"&gt; &lt;/a&gt; &lt;/p&gt; &lt;h2 id="intro"&gt;Intro&lt;/h2&gt; &lt;p&gt; 98.css is a CSS library for building interfaces that look like Windows 98. See more &lt;a href="https://github.com/jdan/98.css"&gt;on GitHub&lt;/a&gt;. &lt;/p&gt; &lt;p&gt; This library relies on the usage of &lt;strong&gt;semantic HTML&lt;/strong&gt;. To make a button, you'll need to use a &lt;code&gt;&amp;lt;button&amp;gt;&lt;/code&gt;. Input elements require labels. Icon buttons rely on &lt;code&gt;aria-label&lt;/code&gt;. This page will guide you through that process, but accessibility is a primary goal of this project. &lt;/p&gt; &lt;p&gt; You can override many of the styles of your elements while maintaining the appearance provided by this library. Need more padding on your buttons? Go for it. Need to add some color to your input labels? Be our guest. &lt;/p&gt; &lt;p&gt; &lt;strong&gt;This library does not contain any JavaScript&lt;/strong&gt;, it merely styles your HTML with some CSS. This means 98.css is compatible with your frontend framework of choice. &lt;/p&gt; &lt;p&gt; Here is an example of &lt;a href="https://codesandbox.io/s/objective-chandrasekhar-t5t6h?file=/src/index.js"&gt;98.css used with React&lt;/a&gt;, and &lt;a href="https://codesandbox.io/s/late-sound-miqho?file=/index.html"&gt;an example with vanilla JavaScript&lt;/a&gt;. The fastest way to use 98.css is to import it from unpkg. &lt;/p&gt; &lt;pre&gt;&lt;code&gt;&amp;lt;link rel="stylesheet" href="https://unpkg.com/98.css" &amp;gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt; You can install 98.css from the &lt;a href="https://github.com/jdan/98.css/releases"&gt;GitHub releases page&lt;/a&gt;, or &lt;a href="https://www.npmjs.com/package/98.css"&gt;from npm&lt;/a&gt;. &lt;/p&gt; &lt;pre&gt;&lt;code&gt;npm install 98.css&lt;/code&gt;&lt;/pre&gt; &lt;h2 id="components"&gt;Components&lt;/h2&gt; &lt;section&gt; &lt;h3 id="button"&gt;Button&lt;/h3&gt; &lt;div&gt; &lt;blockquote&gt; A &lt;em&gt;command button&lt;/em&gt;, also referred to as a push button, is a control that causes the application to perform some action when the user clicks it. &lt;/blockquote&gt; &lt;p&gt; A standard button measures 75px wide and 23px tall, with a raised outer and inner border. They are given 12px of horizontal padding by default. &lt;/p&gt; &lt;div&gt; &lt;details&gt; &lt;summary&gt;Show code&lt;/summary&gt; &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt;Click me&lt;span&gt;&amp;lt;/&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/details&gt; &lt;/div&gt; &lt;p&gt; When buttons are clicked, the raised borders become sunken. The following button is simulated to be in the pressed (active) state. &lt;/p&gt; &lt;div&gt; &lt;details&gt; &lt;summary&gt;Show code&lt;/summary&gt; &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt;I am being pressed&lt;span&gt;&amp;lt;/&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/details&gt; &lt;/div&gt; &lt;p&gt; Disabled buttons maintain the same raised border, but have a "washed out" appearance in their label. &lt;/p&gt; &lt;div&gt; &lt;details&gt; &lt;summary&gt;Show code&lt;/summary&gt; &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;button&lt;/span&gt; &lt;span&gt;disabled&lt;/span&gt;&amp;gt;&lt;/span&gt;I cannot be clicked&lt;span&gt;&amp;lt;/&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/details&gt; &lt;/div&gt; &lt;p&gt; Button focus is communicated with a dotted border, set 4px within the contents of the button. The following example is simulated to be focused. &lt;/p&gt; &lt;div&gt; &lt;details&gt; &lt;summary&gt;Show code&lt;/summary&gt; &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt;I am focused&lt;span&gt;&amp;lt;/&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/details&gt; &lt;/div&gt; &lt;/div&gt; &lt;/section&gt; &lt;section&gt; &lt;h3 id="checkbox"&gt;Checkbox&lt;/h3&gt; &lt;div&gt; &lt;blockquote&gt; A &lt;em&gt;check box&lt;/em&gt; represents an independent or non-exclusive choice. &lt;/blockquote&gt; &lt;p&gt; Checkboxes are represented with a sunken panel, populated with a "check" icon when selected, next to a label indicating the choice. &lt;/p&gt; &lt;p&gt; Note: You &lt;strong&gt;must&lt;/strong&gt; include a corresponding label &lt;strong&gt;after&lt;/strong&gt; your checkbox, using the &lt;code&gt;&amp;lt;label&amp;gt;&lt;/code&gt; element with a &lt;code&gt;for&lt;/code&gt; attribute pointed at the &lt;code&gt;id&lt;/code&gt; of your input. This ensures the checkbox is easy to use with assistive technologies, on top of ensuring a good user experience for all (navigating with the tab key, being able to click the entire label to select the box). &lt;/p&gt; &lt;div&gt; &lt;p&gt; &lt;label for="example1"&gt;This is a checkbox&lt;/label&gt;&lt;/p&gt;&lt;details&gt; &lt;summary&gt;Show code&lt;/summary&gt; &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"checkbox"&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"example1"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"example1"&lt;/span&gt;&amp;gt;&lt;/span&gt;This is a checkbox&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/details&gt; &lt;/div&gt; &lt;p&gt; Checkboxes can be selected and disabled with the standard &lt;code&gt;checked&lt;/code&gt; and &lt;code&gt;disabled&lt;/code&gt; attributes. &lt;/p&gt; &lt;p&gt; When grouping inputs, wrap each input in a container with the &lt;code&gt;field-row&lt;/code&gt; class. This ensures a consistent spacing between inputs. &lt;/p&gt; &lt;div&gt; &lt;p&gt; &lt;label for="example2"&gt;I am checked&lt;/label&gt; &lt;/p&gt; &lt;p&gt; &lt;label for="example3"&gt;I am inactive&lt;/label&gt; &lt;/p&gt; &lt;p&gt; &lt;label for="example4"&gt;I am inactive but still checked&lt;/label&gt; &lt;/p&gt; &lt;details&gt; &lt;summary&gt;Show code&lt;/summary&gt; &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;checked&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"checkbox"&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"example2"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"example2"&lt;/span&gt;&amp;gt;&lt;/span&gt;I am checked&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;disabled&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"checkbox"&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"example3"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"example3"&lt;/span&gt;&amp;gt;&lt;/span&gt;I am inactive&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;checked&lt;/span&gt; &lt;span&gt;disabled&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"checkbox"&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"example4"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"example4"&lt;/span&gt;&amp;gt;&lt;/span&gt;I am inactive but still checked&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/details&gt; &lt;/div&gt; &lt;/div&gt; &lt;/section&gt; &lt;section&gt; &lt;h3 id="option-button"&gt;OptionButton&lt;/h3&gt; &lt;div&gt; &lt;blockquote&gt; An &lt;em&gt;option button&lt;/em&gt;, also referred to as a radio button, represents a single choice within a limited set of mutually exclusive choices. That is, the user can choose only one set of options. &lt;/blockquote&gt; &lt;p&gt; Option buttons can be used via the &lt;code&gt;radio&lt;/code&gt; type on an input element. &lt;/p&gt; &lt;p&gt; Option buttons can be grouped by specifying a shared &lt;code&gt;name&lt;/code&gt; attribute on each input. Just as before: when grouping inputs, wrap each input in a container with the &lt;code&gt;field-row&lt;/code&gt; class to ensure a consistent spacing between inputs. &lt;/p&gt; &lt;div&gt; &lt;p&gt; &lt;label for="radio5"&gt;Yes&lt;/label&gt; &lt;/p&gt; &lt;p&gt; &lt;label for="radio6"&gt;No&lt;/label&gt; &lt;/p&gt; &lt;details&gt; &lt;summary&gt;Show code&lt;/summary&gt; &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"radio5"&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"radio"&lt;/span&gt; &lt;span&gt;name&lt;/span&gt;=&lt;span&gt;"first-example"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"radio5"&lt;/span&gt;&amp;gt;&lt;/span&gt;Yes&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"radio6"&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"radio"&lt;/span&gt; &lt;span&gt;name&lt;/span&gt;=&lt;span&gt;"first-example"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"radio6"&lt;/span&gt;&amp;gt;&lt;/span&gt;No&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/details&gt; &lt;/div&gt; &lt;p&gt; Option buttons can also be &lt;code&gt;checked&lt;/code&gt; and &lt;code&gt;disabled&lt;/code&gt; with their corresponding HTML attributes. &lt;/p&gt; &lt;div&gt; &lt;p&gt; &lt;label for="radio7"&gt;Peanut butter should be smooth&lt;/label&gt; &lt;/p&gt; &lt;p&gt; &lt;label for="radio8"&gt;I understand why people like crunchy peanut butter&lt;/label&gt; &lt;/p&gt; &lt;p&gt; &lt;label for="radio9"&gt;Crunchy peanut butter is good&lt;/label&gt; &lt;/p&gt; &lt;details&gt; &lt;summary&gt;Show code&lt;/summary&gt; &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"radio7"&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"radio"&lt;/span&gt; &lt;span&gt;name&lt;/span&gt;=&lt;span&gt;"second-example"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"radio7"&lt;/span&gt;&amp;gt;&lt;/span&gt;Peanut butter should be smooth&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;checked&lt;/span&gt; &lt;span&gt;disabled&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"radio8"&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"radio"&lt;/span&gt; &lt;span&gt;name&lt;/span&gt;=&lt;span&gt;"second-example"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"radio8"&lt;/span&gt;&amp;gt;&lt;/span&gt;I understand why people like crunchy peanut butter&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;disabled&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"radio9"&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"radio"&lt;/span&gt; &lt;span&gt;name&lt;/span&gt;=&lt;span&gt;"second-example"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"radio9"&lt;/span&gt;&amp;gt;&lt;/span&gt;Crunchy peanut butter is good&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/details&gt; &lt;/div&gt; &lt;/div&gt; &lt;/section&gt; &lt;section&gt; &lt;h3 id="group-box"&gt;GroupBox&lt;/h3&gt; &lt;div&gt; &lt;blockquote&gt; A &lt;em&gt;group box&lt;/em&gt; is a special control you can use to organize a set of controls. A group box is a rectangular frame with an optional label that surrounds a set of controls. &lt;/blockquote&gt; &lt;p&gt; A group box can be used by wrapping your elements with the &lt;code&gt;fieldset&lt;/code&gt; tag. It contains a sunken outer border and a raised inner border, resembling an engraved box around your controls. &lt;/p&gt; &lt;div&gt; &lt;details&gt; &lt;summary&gt;Show code&lt;/summary&gt; &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;fieldset&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row"&lt;/span&gt;&amp;gt;&lt;/span&gt;Select one:&lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"radio10"&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"radio"&lt;/span&gt; &lt;span&gt;name&lt;/span&gt;=&lt;span&gt;"fieldset-example"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"radio10"&lt;/span&gt;&amp;gt;&lt;/span&gt;Diners&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"radio11"&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"radio"&lt;/span&gt; &lt;span&gt;name&lt;/span&gt;=&lt;span&gt;"fieldset-example"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"radio11"&lt;/span&gt;&amp;gt;&lt;/span&gt;Drive-Ins&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"radio12"&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"radio"&lt;/span&gt; &lt;span&gt;name&lt;/span&gt;=&lt;span&gt;"fieldset-example"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"radio12"&lt;/span&gt;&amp;gt;&lt;/span&gt;Dives&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;fieldset&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/details&gt; &lt;/div&gt; &lt;p&gt; You can provide your group with a label by placing a &lt;code&gt;legend&lt;/code&gt; element within the &lt;code&gt;fieldset&lt;/code&gt;. &lt;/p&gt; &lt;div&gt; &lt;details&gt; &lt;summary&gt;Show code&lt;/summary&gt; &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;fieldset&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;legend&lt;/span&gt;&amp;gt;&lt;/span&gt;Today's mood&lt;span&gt;&amp;lt;/&lt;span&gt;legend&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"radio13"&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"radio"&lt;/span&gt; &lt;span&gt;name&lt;/span&gt;=&lt;span&gt;"fieldset-example2"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"radio13"&lt;/span&gt;&amp;gt;&lt;/span&gt;Claire Saffitz&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"radio14"&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"radio"&lt;/span&gt; &lt;span&gt;name&lt;/span&gt;=&lt;span&gt;"fieldset-example2"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"radio14"&lt;/span&gt;&amp;gt;&lt;/span&gt;Brad Leone&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"radio15"&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"radio"&lt;/span&gt; &lt;span&gt;name&lt;/span&gt;=&lt;span&gt;"fieldset-example2"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"radio15"&lt;/span&gt;&amp;gt;&lt;/span&gt;Chris Morocco&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"radio16"&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"radio"&lt;/span&gt; &lt;span&gt;name&lt;/span&gt;=&lt;span&gt;"fieldset-example2"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"radio16"&lt;/span&gt;&amp;gt;&lt;/span&gt;Carla Lalli Music&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;fieldset&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/details&gt; &lt;/div&gt; &lt;/div&gt; &lt;/section&gt; &lt;section&gt; &lt;h3 id="text-box"&gt;TextBox&lt;/h3&gt; &lt;div&gt; &lt;blockquote&gt; A &lt;em&gt;text box&lt;/em&gt; (also referred to as an edit control) is a rectangular control where the user enters or edits text. It can be defined to support a single line or multiple lines of text. &lt;/blockquote&gt; &lt;p&gt; Text boxes can rendered by specifying a &lt;code&gt;text&lt;/code&gt; type on an &lt;code&gt;input&lt;/code&gt; element. As with checkboxes and radio buttons, you should provide a corresponding label with a properly set &lt;code&gt;for&lt;/code&gt; attribute, and wrap both in a container with the &lt;code&gt;field-row&lt;/code&gt; class. &lt;/p&gt; &lt;div&gt; &lt;p&gt;&lt;label for="text17"&gt;Occupation&lt;/label&gt; &lt;/p&gt; &lt;details&gt; &lt;summary&gt;Show code&lt;/summary&gt; &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"text17"&lt;/span&gt;&amp;gt;&lt;/span&gt;Occupation&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"text17"&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"text"&lt;/span&gt; /&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/details&gt; &lt;/div&gt; &lt;p&gt; Additionally, you can make use of the &lt;code&gt;field-row-stacked&lt;/code&gt; class to position your label above the input instead of beside it. &lt;/p&gt; &lt;div&gt; &lt;p&gt;&lt;label for="text18"&gt;Address (Line 1)&lt;/label&gt; &lt;/p&gt; &lt;p&gt;&lt;label for="text19"&gt;Address (Line 2)&lt;/label&gt; &lt;/p&gt; &lt;details&gt; &lt;summary&gt;Show code&lt;/summary&gt; &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row-stacked"&lt;/span&gt; &lt;span&gt;style&lt;/span&gt;=&lt;span&gt;"width: 200px"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"text18"&lt;/span&gt;&amp;gt;&lt;/span&gt;Address (Line 1)&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"text18"&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"text"&lt;/span&gt; /&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row-stacked"&lt;/span&gt; &lt;span&gt;style&lt;/span&gt;=&lt;span&gt;"width: 200px"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"text19"&lt;/span&gt;&amp;gt;&lt;/span&gt;Address (Line 2)&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"text19"&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"text"&lt;/span&gt; /&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/details&gt; &lt;/div&gt; &lt;p&gt; To support multiple lines in the user's input, use the &lt;code&gt;textarea&lt;/code&gt; element instead. &lt;/p&gt; &lt;div&gt; &lt;p&gt;&lt;label for="text20"&gt;Additional notes&lt;/label&gt; &lt;/p&gt; &lt;details&gt; &lt;summary&gt;Show code&lt;/summary&gt; &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row-stacked"&lt;/span&gt; &lt;span&gt;style&lt;/span&gt;=&lt;span&gt;"width: 200px"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"text20"&lt;/span&gt;&amp;gt;&lt;/span&gt;Additional notes&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;textarea&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"text20"&lt;/span&gt; &lt;span&gt;rows&lt;/span&gt;=&lt;span&gt;"8"&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;lt;/&lt;span&gt;textarea&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/details&gt; &lt;/div&gt; &lt;/div&gt; &lt;/section&gt; &lt;section&gt; &lt;h3 id="slider"&gt;Slider&lt;/h3&gt; &lt;div&gt; &lt;blockquote&gt; A &lt;em&gt;slider&lt;/em&gt;, sometimes called a trackbar control, consists of a bar that defines the extent or range of the adjustment and an indicator that shows the current value for the control... &lt;/blockquote&gt; &lt;p&gt; Sliders can rendered by specifying a &lt;code&gt;range&lt;/code&gt; type on an &lt;code&gt;input&lt;/code&gt; element. &lt;/p&gt; &lt;div&gt; &lt;p&gt;&lt;label for="range21"&gt;Volume:&lt;/label&gt; &lt;label for="range22"&gt;Low&lt;/label&gt; &lt;label for="range23"&gt;High&lt;/label&gt; &lt;/p&gt; &lt;details&gt; &lt;summary&gt;Show code&lt;/summary&gt; &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row"&lt;/span&gt; &lt;span&gt;style&lt;/span&gt;=&lt;span&gt;"width: 300px"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"range21"&lt;/span&gt;&amp;gt;&lt;/span&gt;Volume:&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"range22"&lt;/span&gt;&amp;gt;&lt;/span&gt;Low&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"range22"&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"range"&lt;/span&gt; &lt;span&gt;min&lt;/span&gt;=&lt;span&gt;"1"&lt;/span&gt; &lt;span&gt;max&lt;/span&gt;=&lt;span&gt;"11"&lt;/span&gt; &lt;span&gt;value&lt;/span&gt;=&lt;span&gt;"5"&lt;/span&gt; /&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"range23"&lt;/span&gt;&amp;gt;&lt;/span&gt;High&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/details&gt; &lt;/div&gt; &lt;p&gt; You can make use of the &lt;code&gt;has-box-indicator&lt;/code&gt; class replace the default indicator with a box indicator, furthermore the slider can be wrapped with a &lt;code&gt;div&lt;/code&gt; using &lt;code&gt;is-vertical&lt;/code&gt; to display the input vertically. &lt;/p&gt; &lt;p&gt; Note: To change the length of a vertical slider, the &lt;code&gt;input&lt;/code&gt; width and &lt;code&gt;div&lt;/code&gt; height. &lt;/p&gt; &lt;div&gt; &lt;details&gt; &lt;summary&gt;Show code&lt;/summary&gt; &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"field-row"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;label&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;=&lt;span&gt;"range24"&lt;/span&gt;&amp;gt;&lt;/span&gt;Cowbell&lt;span&gt;&amp;lt;/&lt;span&gt;label&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"is-vertical"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;input&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;=&lt;span&gt;"range24"&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"has-box-indicator"&lt;/span&gt; &lt;span&gt;type&lt;/span&gt;=&lt;span&gt;"range"&lt;/span&gt; &lt;span&gt;min&lt;/span&gt;=&lt;span&gt;"1"&lt;/span&gt; &lt;span&gt;max&lt;/span&gt;=&lt;span&gt;"3"&lt;/span&gt; &lt;span&gt;step&lt;/span&gt;=&lt;span&gt;"1"&lt;/span&gt; &lt;span&gt;value&lt;/span&gt;=&lt;span&gt;"2"&lt;/span&gt; /&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/details&gt; &lt;/div&gt; &lt;/div&gt; &lt;/section&gt; &lt;section&gt; &lt;h3 id="dropdown"&gt;Dropdown&lt;/h3&gt; &lt;div&gt; &lt;blockquote&gt; A &lt;em&gt;drop-down list box&lt;/em&gt; allows the selection of only a single item from a list. In its closed state, the control displays the current value for the control. The user opens the list to change the value. &lt;/blockquote&gt; &lt;p&gt; Dropdowns can be rendered by using the &lt;code&gt;select&lt;/code&gt; and &lt;code&gt;option&lt;/code&gt; elements. &lt;/p&gt; &lt;div&gt; &lt;details&gt; &lt;summary&gt;Show code&lt;/summary&gt; &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;select&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;option&lt;/span&gt;&amp;gt;&lt;/span&gt;5 - Incredible!&lt;span&gt;&amp;lt;/&lt;span&gt;option&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;option&lt;/span&gt;&amp;gt;&lt;/span&gt;4 - Great!&lt;span&gt;&amp;lt;/&lt;span&gt;option&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;option&lt;/span&gt;&amp;gt;&lt;/span&gt;3 - Pretty good&lt;span&gt;&amp;lt;/&lt;span&gt;option&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;option&lt;/span&gt;&amp;gt;&lt;/span&gt;2 - Not so great&lt;span&gt;&amp;lt;/&lt;span&gt;option&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;option&lt;/span&gt;&amp;gt;&lt;/span&gt;1 - Unfortunate&lt;span&gt;&amp;lt;/&lt;span&gt;option&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;select&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/details&gt; &lt;/div&gt; &lt;p&gt; By default, the first option will be selected. You can change this by giving one of your &lt;code&gt;option&lt;/code&gt; elements the &lt;code&gt;selected&lt;/code&gt; attribute. &lt;/p&gt; &lt;div&gt; &lt;details&gt; &lt;summary&gt;Show code&lt;/summary&gt; &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;select&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;option&lt;/span&gt;&amp;gt;&lt;/span&gt;5 - Incredible!&lt;span&gt;&amp;lt;/&lt;span&gt;option&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;option&lt;/span&gt;&amp;gt;&lt;/span&gt;4 - Great!&lt;span&gt;&amp;lt;/&lt;span&gt;option&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;option&lt;/span&gt; &lt;span&gt;selected&lt;/span&gt;&amp;gt;&lt;/span&gt;3 - Pretty good&lt;span&gt;&amp;lt;/&lt;span&gt;option&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;option&lt;/span&gt;&amp;gt;&lt;/span&gt;2 - Not so great&lt;span&gt;&amp;lt;/&lt;span&gt;option&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;option&lt;/span&gt;&amp;gt;&lt;/span&gt;1 - Unfortunate&lt;span&gt;&amp;lt;/&lt;span&gt;option&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;select&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/details&gt; &lt;/div&gt; &lt;/div&gt; &lt;/section&gt; &lt;h3 id="window"&gt;Window&lt;/h3&gt; &lt;p&gt; The following components illustrate how to build complete windows using 98.css. &lt;/p&gt; &lt;section&gt; &lt;h4 id="title-bar"&gt;Title Bar&lt;/h4&gt; &lt;div&gt; &lt;blockquote&gt; At the top edge of the window, inside its border, is the title bar (also reffered to as the caption or caption bar), which extends across the width of the window. The title bar identifies the contents of the window. &lt;/blockquote&gt; &lt;blockquote&gt; Include command buttons associated with the common commands of the primary window in the title bar. These buttons act as shortcuts to specific window commands. &lt;/blockquote&gt; &lt;p&gt; You can build a complete title bar by making use of three classes, &lt;code&gt;title-bar&lt;/code&gt;, &lt;code&gt;title-bar-text&lt;/code&gt;, and &lt;code&gt;title-bar-controls&lt;/code&gt;. &lt;/p&gt; &lt;div&gt; &lt;details&gt; &lt;summary&gt;Show code&lt;/summary&gt; &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar-text"&lt;/span&gt;&amp;gt;&lt;/span&gt;A Title Bar&lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar-controls"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;button&lt;/span&gt; &lt;span&gt;aria-label&lt;/span&gt;=&lt;span&gt;"Close"&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;lt;/&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/details&gt; &lt;/div&gt; &lt;p&gt; We make use of &lt;code&gt;aria-label&lt;/code&gt; to render the Close button, to let assistive technologies know the intent of this button. You may also use "Minimize", "Maximize", "Restore" and "Help" like so: &lt;/p&gt; &lt;div&gt; &lt;br&gt; &lt;br&gt; &lt;details&gt; &lt;summary&gt;Show code&lt;/summary&gt; &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar-text"&lt;/span&gt;&amp;gt;&lt;/span&gt;A Title Bar&lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar-controls"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;button&lt;/span&gt; &lt;span&gt;aria-label&lt;/span&gt;=&lt;span&gt;"Minimize"&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;lt;/&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;button&lt;/span&gt; &lt;span&gt;aria-label&lt;/span&gt;=&lt;span&gt;"Maximize"&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;lt;/&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;button&lt;/span&gt; &lt;span&gt;aria-label&lt;/span&gt;=&lt;span&gt;"Close"&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;lt;/&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;br&lt;/span&gt; /&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar-text"&lt;/span&gt;&amp;gt;&lt;/span&gt;A Maximized Title Bar&lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar-controls"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;button&lt;/span&gt; &lt;span&gt;aria-label&lt;/span&gt;=&lt;span&gt;"Minimize"&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;lt;/&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;button&lt;/span&gt; &lt;span&gt;aria-label&lt;/span&gt;=&lt;span&gt;"Restore"&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;lt;/&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;button&lt;/span&gt; &lt;span&gt;aria-label&lt;/span&gt;=&lt;span&gt;"Close"&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;lt;/&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;br&lt;/span&gt; /&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar-text"&lt;/span&gt;&amp;gt;&lt;/span&gt;A Helpful Bar&lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar-controls"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;button&lt;/span&gt; &lt;span&gt;aria-label&lt;/span&gt;=&lt;span&gt;"Help"&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;lt;/&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;button&lt;/span&gt; &lt;span&gt;aria-label&lt;/span&gt;=&lt;span&gt;"Close"&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;lt;/&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/details&gt; &lt;/div&gt; &lt;p&gt; You can make a title bar "inactive" by adding &lt;code&gt;inactive&lt;/code&gt; class, useful when making more than one window. &lt;/p&gt; &lt;div&gt; &lt;details&gt; &lt;summary&gt;Show code&lt;/summary&gt; &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar inactive"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar-text"&lt;/span&gt;&amp;gt;&lt;/span&gt;An inactive title bar&lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar-controls"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;button&lt;/span&gt; &lt;span&gt;aria-label&lt;/span&gt;=&lt;span&gt;"Close"&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;lt;/&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/details&gt; &lt;/div&gt; &lt;/div&gt; &lt;/section&gt; &lt;section&gt; &lt;h4 id="window-contents"&gt;Window contents&lt;/h4&gt; &lt;div&gt; &lt;blockquote&gt; Every window has a boundary that defines its shape. &lt;/blockquote&gt; &lt;p&gt; To give our title bar a home, we make use of the &lt;code&gt;window&lt;/code&gt; class. This provides a raised outer and inner border, as well as some padding. We can freely resize the window by specifying a width in the container style. &lt;/p&gt; &lt;div&gt; &lt;details&gt; &lt;summary&gt;Show code&lt;/summary&gt; &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"window"&lt;/span&gt; &lt;span&gt;style&lt;/span&gt;=&lt;span&gt;"width: 300px"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar-text"&lt;/span&gt;&amp;gt;&lt;/span&gt;A Complete Window&lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar-controls"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;button&lt;/span&gt; &lt;span&gt;aria-label&lt;/span&gt;=&lt;span&gt;"Minimize"&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;lt;/&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;button&lt;/span&gt; &lt;span&gt;aria-label&lt;/span&gt;=&lt;span&gt;"Maximize"&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;lt;/&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;button&lt;/span&gt; &lt;span&gt;aria-label&lt;/span&gt;=&lt;span&gt;"Close"&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;lt;/&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/details&gt; &lt;/div&gt; &lt;p&gt; To draw the contents of the window, we use the &lt;code&gt;window-body&lt;/code&gt; class under the title bar. &lt;/p&gt; &lt;div&gt; &lt;div&gt; &lt;div&gt; &lt;p&gt;A Window With Stuff In It&lt;/p&gt; &lt;/div&gt; &lt;p&gt;There's so much room for activities!&lt;/p&gt; &lt;/div&gt; &lt;details&gt; &lt;summary&gt;Show code&lt;/summary&gt; &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"window"&lt;/span&gt; &lt;span&gt;style&lt;/span&gt;=&lt;span&gt;"width: 300px"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar-text"&lt;/span&gt;&amp;gt;&lt;/span&gt;A Window With Stuff In It&lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"title-bar-controls"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;button&lt;/span&gt; &lt;span&gt;aria-label&lt;/span&gt;=&lt;span&gt;"Minimize"&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;lt;/&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;button&lt;/span&gt; &lt;span&gt;aria-label&lt;/span&gt;=&lt;span&gt;"Maximize"&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;lt;/&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;button&lt;/span&gt; &lt;span&gt;aria-label&lt;/span&gt;=&lt;span&gt;"Close"&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;lt;/&lt;span&gt;button&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"window-body"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;p&lt;/span&gt;&amp;gt;&lt;/span&gt;There's so much room for activities!&lt;span&gt;&amp;lt;/&lt;span&gt;p&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;div&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/details&gt; &lt;/div&gt; &lt;/div&gt; &lt;/section&gt; &lt;section&gt; &lt;h3 id="tree-view"&gt;TreeView&lt;/h3&gt; &lt;div&gt; &lt;blockquote&gt; A &lt;em&gt;tree view control&lt;/em&gt; is a special list box control that displays a set of objects as an indented outline based on their logical hierarchical relationship. &lt;/blockquote&gt; &lt;p&gt; To render a tree view, use an &lt;code&gt;ul&lt;/code&gt; element with the &lt;code&gt;tree-view&lt;/code&gt; class. The children of this list (&lt;code&gt;li&lt;/code&gt; elements), can contain whatever you'd like. &lt;/p&gt; &lt;div&gt; &lt;ul&gt; &lt;li&gt;We can put&lt;/li&gt; &lt;li&gt;&lt;strong&gt;✨ Whatever ✨&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;We want in here&lt;/li&gt; &lt;/ul&gt; &lt;details&gt; &lt;summary&gt;Show code&lt;/summary&gt; &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;ul&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"tree-view"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;We can put&lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;span&gt;strong&lt;/span&gt; &lt;span&gt;style&lt;/span&gt;=&lt;span&gt;"color: purple"&lt;/span&gt;&amp;gt;&lt;/span&gt;✨ Whatever ✨&lt;span&gt;&amp;lt;/&lt;span&gt;strong&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;We want in here&lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;ul&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/details&gt; &lt;/div&gt; &lt;p&gt; To make this a tree, we can nest further &lt;code&gt;ul&lt;/code&gt; elements (no class needed on these). This will provide them with a nice dotted border and indentation to illustrate the structure of the tree. &lt;/p&gt; &lt;p&gt; To create expandable sections, wrap child lists inside of &lt;code&gt;details&lt;/code&gt; elements. &lt;/p&gt; &lt;div&gt; &lt;ul&gt; &lt;li&gt;Table of Contents&lt;/li&gt; &lt;li&gt;What is web development?&lt;/li&gt; &lt;li&gt; CSS &lt;ul&gt; &lt;li&gt;Selectors&lt;/li&gt; &lt;li&gt;Specificity&lt;/li&gt; &lt;li&gt;Properties&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt; &lt;details open=""&gt; &lt;summary&gt;JavaScript&lt;/summary&gt; &lt;ul&gt; &lt;li&gt;Avoid at all costs&lt;/li&gt; &lt;li&gt; &lt;details&gt; &lt;summary&gt;Unless&lt;/summary&gt; &lt;ul&gt; &lt;li&gt;Avoid&lt;/li&gt; &lt;li&gt; &lt;details&gt; &lt;summary&gt;At&lt;/summary&gt; &lt;ul&gt; &lt;li&gt;Avoid&lt;/li&gt; &lt;li&gt;At&lt;/li&gt; &lt;li&gt;All&lt;/li&gt; &lt;li&gt;Cost&lt;/li&gt; &lt;/ul&gt; &lt;/details&gt; &lt;/li&gt; &lt;li&gt;All&lt;/li&gt; &lt;li&gt;Cost&lt;/li&gt; &lt;/ul&gt; &lt;/details&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/details&gt; &lt;/li&gt; &lt;li&gt;HTML&lt;/li&gt; &lt;li&gt;Special Thanks&lt;/li&gt; &lt;/ul&gt; &lt;details&gt; &lt;summary&gt;Show code&lt;/summary&gt; &lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;ul&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;"tree-view"&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;Table of Contents&lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;What is web development?&lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt; CSS &lt;span&gt;&amp;lt;&lt;span&gt;ul&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;Selectors&lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;Specificity&lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;Properties&lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;ul&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;details&lt;/span&gt; &lt;span&gt;open&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;summary&lt;/span&gt;&amp;gt;&lt;/span&gt;JavaScript&lt;span&gt;&amp;lt;/&lt;span&gt;summary&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;ul&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;Avoid at all costs&lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;details&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;summary&lt;/span&gt;&amp;gt;&lt;/span&gt;Unless&lt;span&gt;&amp;lt;/&lt;span&gt;summary&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;ul&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;Avoid&lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;details&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;summary&lt;/span&gt;&amp;gt;&lt;/span&gt;At&lt;span&gt;&amp;lt;/&lt;span&gt;summary&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;ul&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;Avoid&lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;At&lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;All&lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;Cost&lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;ul&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;details&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;All&lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;Cost&lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;ul&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;details&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;ul&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;details&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;HTML&lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt;Special Thanks&lt;span&gt;&amp;lt;/&lt;span&gt;li&lt;/span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;/&lt;span&gt;ul&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/details&gt; &lt;/div&gt; &lt;/div&gt; &lt;/section&gt; &lt;h2 id="issues-contributing-etc"&gt;Issues, Contributing, etc.&lt;/h2&gt; &lt;p&gt; 98.css is &lt;a href="https://github.com/jdan/98.css/blob/main/LICENSE"&gt;MIT licensed&lt;/a&gt;. &lt;/p&gt; &lt;p&gt; Refer to &lt;a href="https://github.com/jdan/98.css/issues"&gt;the GitHub issues page&lt;/a&gt; to see bugs in my CSS or report new ones. I'd really like to see your pull requests (especially those new to open-source!) and will happily provide code review. 98.css is a fun, silly project and I'd like to make it a fun place to build your open-source muscle. &lt;/p&gt; &lt;p&gt; Thank you for checking my little project out, I hope it brought you some joy today. Consider &lt;a href="https://github.com/jdan/98.css/stargazers"&gt;starring/following along on GitHub&lt;/a&gt; and maybe subscribing to more fun things on &lt;a href="https://twitter.com/jdan"&gt;my twitter&lt;/a&gt;. 👋 &lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://jdan.github.io/98.css/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Wed, 22 Apr 2020 12:25:16 UT
      </pubDate>
      <guid>
        https://jdan.github.io/98.css/
      </guid>
    </item>
    <item>
      <title>
        Incremental Regular Expressions &amp;mdash; Incremental regular expressions
      </title>
      <link>
        http://jkff.info/articles/ire/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div id="incremental-regular-expressions"&gt; &lt;h2&gt;Incremental Regular Expressions&lt;a title="Permalink to this headline" href="#incremental-regular-expressions"&gt;¶&lt;/a&gt;&lt;/h2&gt; &lt;p&gt;&lt;em&gt;By Eugene Kirpichov &amp;lt;ekirpichov@gmail.com&amp;gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;&lt;em&gt;Code available at github:&lt;/em&gt; &lt;a href="http://github.com/jkff/ire"&gt;http://github.com/jkff/ire&lt;/a&gt;&lt;/p&gt; &lt;p&gt;This article was originally published in the Russian functional programming journal &lt;a href="http://fprog.ru/"&gt;http://fprog.ru/&lt;/a&gt; and this translation was intended to be published in Peter Seibel’s &lt;a href="http://codequarterly.com/"&gt;http://codequarterly.com/&lt;/a&gt; journal, but as Peter eventually decided not to proceed with the journal, I am publishing it on my personal space.&lt;/p&gt; &lt;p&gt;I would like to thank Peter for his multitude of extremely valuable comments that have helped me greatly improve the clarity and flow of the article.&lt;/p&gt; &lt;div id="introduction"&gt; &lt;h2&gt;Introduction&lt;a title="Permalink to this headline" href="#introduction"&gt;¶&lt;/a&gt;&lt;/h2&gt; &lt;p&gt;The problem of regular expression matching is a well-known one, with a multitude of solutions.&lt;/p&gt; &lt;p&gt;The corresponding algorithms are very beautiful, motivating many curious programmers to write their own regular expression engines for fun.&lt;/p&gt; &lt;p&gt;The approaches to this problem are quite different in their area of application. Here are some questions that the developer of an engine has to answer.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Supported operators&lt;/strong&gt;: capturing groups, backreferences, execution of arbitrary code, greedy matching? The more features are supported, the harder it is to implement the engine efficiently; most of the features rule out whole classes of matching algorithms.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Number and kind of regular expressions:&lt;/strong&gt; How many regexes shall we test for? How big shall they be? Shall they be small expressions for data validation, or are we talking about a full-fledged lexer with dozens of tokens specified by their regular expressions?&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Pattern of usage:&lt;/strong&gt; How many times is matching against a single expression performed? Is it OK to spend a lot of time compiling it but match very quickly afterwards?&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Size of change of matched text:&lt;/strong&gt; How big is the matched text and how often does it change?&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Let us list some of the existing approaches and engines.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt;&lt;tt&gt;&lt;span&gt;awk&lt;/span&gt;&lt;/tt&gt;, &lt;tt&gt;&lt;span&gt;grep&lt;/span&gt;&lt;/tt&gt;, &lt;a href="http://code.google.com/p/re2/"&gt;re2&lt;/a&gt; use the so called “automata-theoretic” approach, which allows them to guarantee linear matching time, however some features (for example, backreferences) cannot be implemented at all within their approach, and others (such as capturing groups) are quite hard to implement efficiently.&lt;/p&gt; &lt;p&gt;Also, with this approach it is difficult to control memory overhead while retaining high efficiency — even re2 at times suffers from exponentially large memory consumption, though it is designed to avoid such situations.&lt;/p&gt; &lt;p&gt;Besides, this approach allows for certain curious uses, for example, re2 uses automata theory to compute the minimal and maximal possible strings matching the regular expression, thus making Google Code Search possible by greatly reducing the amount of code to be actually matched against the expression when processing a query.&lt;/p&gt; &lt;/li&gt; &lt;li&gt;&lt;p&gt;Modified automata-theoretic approach, “tagged” automata: &lt;a href="http://laurikari.net/tre"&gt;libtre&lt;/a&gt;, &lt;a href="http://hackage.haskell.org/package/regex-tdfa"&gt;regex-tdfa&lt;/a&gt; — linear matching time is also guaranteed; it is possible to do approximate search;&lt;/p&gt; &lt;/li&gt; &lt;li&gt;&lt;p&gt;Semiring-based approach: &lt;a href="http://sebfisch.github.com/haskell-regexp"&gt;weighted-regexp&lt;/a&gt; — also linear matching time and constant memory consumption; a very simple, beautiful and efficient implementation;&lt;/p&gt; &lt;/li&gt; &lt;li&gt;&lt;p&gt;Recursive descent: most of the other engines (Perl and PCRE-compatible engines, Java, irregexp etc.)—the whole range of features, but “pathological” cases are possible where matching time sharply increases.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;In a fantastic &lt;a href="http://blog.sigfpe.com/2009/01/fast-incremental-regular-expression.html"&gt;blog post&lt;/a&gt; Dan Piponi &lt;a id="id1" href="#f1"&gt;[1]&lt;/a&gt; outlined yet another approach using monoids and finger trees.&lt;/p&gt; &lt;p&gt;This approach only works for “true” regular expressions (i.e. we only have character classes, braces and the operators &lt;em&gt;+, *, ?, |&lt;/em&gt;) but it allows to perform the matching &lt;strong&gt;incrementally&lt;/strong&gt;: after small changes of the input string we can recompute the result very quickly without scanning the whole string. These changes include concatenating two strings and cutting a string in two pieces. Obviously these two operations form a basis for many others (insertion into the middle, appending or prepending a character etc).&lt;/p&gt; &lt;p&gt;In this article we further develop Piponi’s approach, which employs a number of beautiful algorithmic techniques from the world of functional programming, to build a Java library for incremental regular expression matching. This is also an interesting investigation into how the functional approach blends together with an imperative language.&lt;/p&gt; &lt;p&gt;There were several reasons to choose Java:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Increase the probability that this library will be indeed used and will not remain a purely academical toy because of difficulties with its integration with existing projects;&lt;/li&gt; &lt;li&gt;Facilitate understanding of the presented ideas for the (currently) quite broad community of imperative programmers;&lt;/li&gt; &lt;li&gt;Show that studying the functional ideas and approaches is fruitful also for programming in non-functional languages.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Where could such an approach to regular expression matching be useful?&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt;The ability to quickly recompute the result after changes of the input string would be useful in text editors for incremental highlighting of arbitrary syntax, with tokens specified by their regular expressions (vim, for instance, allows rather flexible definition of syntax rules, but does not always do the highlighting and re-highlighting correctly, because it uses a rather naive approach to highlighting).&lt;/p&gt; &lt;p&gt;Unfortunately, the engine developed in this article has performance characteristics that do not allow it to serve this purpose — however, not all hope is lost: some possible improvements will be outlined.&lt;/p&gt; &lt;/li&gt; &lt;li&gt;&lt;p&gt;One could imagine a problem in bioinformatics where one assembles a DNA sequence, say, using a genetic algorithm, from some “basis” sequences using glue and scissors (concatenations and cuts), and optimizes a function depending on the presence and position of particular patterns in the sequence.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;div id="problem-statement"&gt; &lt;h3&gt;Problem statement&lt;a title="Permalink to this headline" href="#problem-statement"&gt;¶&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;The problem that we’re going to solve is incremental matching of strings against regular expressions. There are several ambiguities to resolve here, however. Let us outline the major features of our engine: they are basically the same as those in Dan Piponi’s article.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;The regular expression (or set of regular expressions) is fixed:&lt;/strong&gt; once we fix the expressions, we obtain a way to do incremental matching of strings against them.&lt;/li&gt; &lt;li&gt;“Incremental” means “match result is efficiently maintained under certain operations”, where the operations include &lt;strong&gt;concatenating two strings and splitting a string in part around an index&lt;/strong&gt;. Obviously, these two operations form a basis for all kinds of rearrangements, such as inserting or deleting a word from the middle of a string, or appending characters to its back or front, etc.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;There is one more ambiguity to resolve: whether to make the “incremental” interface pure or impure in the mathematical sense: whether concatenation and splitting modify their arguments or create new results.&lt;/p&gt; &lt;p&gt;We choose the &lt;strong&gt;pure&lt;/strong&gt; option (concatenation and splitting are mathematical functions), because, as it is the case with nearly any kind of data structures having both a “pure” and “impure” implementation, it turns out dramatically easier to reason about mathematically and declaratively, and also dramatically easier to implement, debug and test. We shall elaborate more on the importance of this design decision in the section ‘The importance of purity’ section.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id="the-automata-theoretic-approach"&gt; &lt;h2&gt;The automata-theoretic approach&lt;a title="Permalink to this headline" href="#the-automata-theoretic-approach"&gt;¶&lt;/a&gt;&lt;/h2&gt; &lt;p&gt;The most well-known approach to regular expression matching is based on finite automata and is studied in most university courses on compiler construction. You can throuroughly familiarize yourself with it, for example, in &lt;a href="http://swtch.com/~rsc/regexp/regexp1.html"&gt;the article&lt;/a&gt; by Russ Cox. Let us provide just a quick refresher of the most basic concepts of how finite automata are used for matching text. Incrementalization will follow in a surprisingly simple fashion.&lt;/p&gt; &lt;div id="constructing-the-automaton"&gt; &lt;h3&gt;Constructing the automaton&lt;a title="Permalink to this headline" href="#constructing-the-automaton"&gt;¶&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;Given a regular expression, one uses, for example, the “Thompson’s construction” (due Ken Thompson), and builds a finite automaton where one state is declared “initial”, one is declared “final” (though in theory nothing prevents having more than one initial or final state, and we shall use this opportunity in our algorithm), and some states are connected to each other by edges.&lt;/p&gt; &lt;p&gt;An edge from &lt;span&gt;\(A\)&lt;/span&gt; to &lt;span&gt;\(B\)&lt;/span&gt; with subscript &lt;span&gt;\(c\)&lt;/span&gt; means: “If state &lt;span&gt;\(A\)&lt;/span&gt; is active and the character &lt;span&gt;\(c\)&lt;/span&gt; is input, then state &lt;span&gt;\(B\)&lt;/span&gt; becomes active instead of &lt;span&gt;\(A\)&lt;/span&gt;”. There are also ε (epsilon)-edges: if &lt;span&gt;\(A\)&lt;/span&gt; is connected to &lt;span&gt;\(B\)&lt;/span&gt; by an ε-edge, then, upon activation of &lt;span&gt;\(A\)&lt;/span&gt;, &lt;span&gt;\(B\)&lt;/span&gt; is also immediately activated.&lt;/p&gt; &lt;p&gt;Epsilon edges are needed, for example, when constructing an automaton for the “?” (“optional”) construction: given an automaton for R, you can insert an epsilon transition from the initial to the final state, giving an automaton for “R?”. If no edge from state &lt;span&gt;\(A\)&lt;/span&gt; fits the input, then it is simply deactivated.&lt;/p&gt; &lt;p&gt;The automaton is called “non-deterministic” because, given a state and a character, you can’t determine which edge to follow, because there can be several of them. Instead, you follow all of them at once and therefore, at any given moment, several states may be active.&lt;/p&gt; &lt;/div&gt; &lt;div id="the-matching-process"&gt; &lt;h3&gt;The matching process&lt;a title="Permalink to this headline" href="#the-matching-process"&gt;¶&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;To perform matching, the initial states are activated and each character of the sequence is fed as input in turn. If in the end at least one “final” state is active, then the matching is declared successful.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; The regular expression “&lt;tt&gt;&lt;span&gt;.*a(b*a|bc+)a&lt;/span&gt;&lt;/tt&gt;”.&lt;/p&gt; &lt;p&gt;An automaton for this expression is shown on the picture below (somewhat simplified with respect to the Thompson’s construction, by removing several redundant nodes and epsilon edges), and here is the sequence of its active states upon feeding it with the string “&lt;tt&gt;&lt;span&gt;aabcca&lt;/span&gt;&lt;/tt&gt;”.&lt;/p&gt; &lt;div&gt; &lt;p&gt;&lt;img src="http://jkff.info/articles/ire/_images/nfa.png" alt="_images/nfa.png"&gt;&lt;/p&gt;&lt;p&gt;A non-deterministic automaton for the regular expression “&lt;tt&gt;&lt;span&gt;.*a(b*a|bc+)a&lt;/span&gt;&lt;/tt&gt;”&lt;/p&gt; &lt;/div&gt; &lt;table&gt; &lt;colgroup&gt; &lt;col width="34%"&gt; &lt;col width="66%"&gt; &lt;/colgroup&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;String seen so far&lt;/td&gt; &lt;td&gt;Active states&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt; &lt;td&gt;&lt;span&gt;\(s_1\)&lt;/span&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt;&lt;td&gt;&lt;strong&gt;a&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;&lt;span&gt;\(s_1, s_2, s_3, s_4\)&lt;/span&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt;&lt;td&gt;a &lt;strong&gt;a&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;&lt;span&gt;\(s_1, s_2, s_3, s_4, s_5, s_8\)&lt;/span&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt;&lt;td&gt;aa &lt;strong&gt;b&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;&lt;span&gt;\(s_1, s_3, s_6\)&lt;/span&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt;&lt;td&gt;aab &lt;strong&gt;c&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;&lt;span&gt;\(s_1, s_6, s_7, s_8\)&lt;/span&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt;&lt;td&gt;aabc &lt;strong&gt;c&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;&lt;span&gt;\(s_1, s_6, s_7, s_8\)&lt;/span&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt;&lt;td&gt;aabcc &lt;strong&gt;a&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;&lt;span&gt;\(s_1, s_2, s_3, s_4, s_9\)&lt;/span&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;Since in the end the active set contains a final state, &lt;span&gt;\(s_9\)&lt;/span&gt;, the matching is declared successful.&lt;/p&gt; &lt;/div&gt; &lt;div id="shrinking-the-automaton"&gt; &lt;h3&gt;Shrinking the automaton&lt;a title="Permalink to this headline" href="#shrinking-the-automaton"&gt;¶&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;To speed up matching, one sometimes eliminates ε-edges and performs &lt;em&gt;determinization&lt;/em&gt; of the automaton (each state can have at most 1 out-going edge with a given subscript) &lt;a id="id2" href="#f2"&gt;[2]&lt;/a&gt;. As a result, a completely different automaton is obtained, which, however, corresponds to the same regular expression.&lt;/p&gt; &lt;p&gt;In a deterministic automaton, at any given moment, exactly one state is active, which allows for a more efficient implementation of the matching procedure.&lt;/p&gt; &lt;p&gt;However we won’t use determinization because as a result, the automaton may blow up exponentially &lt;a id="id3" href="#f3"&gt;[3]&lt;/a&gt;, which, as we’ll later see, is completely unacceptable in our case.&lt;/p&gt; &lt;p&gt;We shall use only the first part, namely &lt;strong&gt;elimination of ε-edges&lt;/strong&gt;: it can only decrease the size of the automaton (compare the NFA above and below).&lt;/p&gt; &lt;p&gt;The algorithm is very simple: take “shortcuts” through ε-edges, i.e. whenever one node is reachable from another through a chain of ε-edges, copy edges from the second node to the first. Then remove all ε-edges (since they’re now unnecessary) and nodes that became redundant (unreachable) as a result of this.&lt;/p&gt; &lt;div&gt; &lt;p&gt;&lt;img src="http://jkff.info/articles/ire/_images/nfa-ne.png" alt="_images/nfa-ne.png"&gt;&lt;/p&gt;&lt;p&gt;The non-deterministic automaton corresponding to the expression “&lt;tt&gt;&lt;span&gt;.*a(b*a|bc+)a&lt;/span&gt;&lt;/tt&gt;”, after removing ε-edges&lt;/p&gt; &lt;/div&gt; &lt;p&gt;Thus we have outlined the approach to testing whether a string matches a regular expression using finite automata. Finding match positions and capturing groups is more difficult, and we direct the reader to &lt;a href="http://swtch.com/~rsc/regexp/regexp3.html"&gt;Russ Cox’ article&lt;/a&gt; for a more thourough treatment — we do not present the traditional approach here ourselves, because we shall use a different one.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id="approach-to-incremental-matching"&gt; &lt;h2&gt;Approach to incremental matching&lt;a title="Permalink to this headline" href="#approach-to-incremental-matching"&gt;¶&lt;/a&gt;&lt;/h2&gt; &lt;p&gt;Now let us gradually arrive to the basic ideas of incremental matching.&lt;/p&gt; &lt;p&gt;First, let us depict this automaton in a slightly different way.&lt;/p&gt; &lt;p&gt;Every possible input character has a “transition function”: “What will be the next states of the automaton after feeding this character to the input, if its current state is &lt;span&gt;\(S\)&lt;/span&gt;?” It can also be seen that the notion of such a “transition function” makes sense not only for individual characters, but for whole strings. &lt;strong&gt;Strings have transition functions, too!&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Given a string’s transition function, however long this string might be, we can emulate feeding it to the automaton’s input without even looking at its characters. A string’s transition function is computed from the transition functions of its characters (which is also shown on the picture below); in the same way, given transition functions for two strings, we can compute the transition function of their concatenation.&lt;/p&gt; &lt;div&gt; &lt;p&gt;&lt;img src="http://jkff.info/articles/ire/_images/nfa-composition.png" alt="_images/nfa-composition.png"&gt;&lt;/p&gt;&lt;p&gt;Transition functions of a non-deterministic automaton and their composition&lt;/p&gt; &lt;/div&gt; &lt;p&gt;Note that the transition function of a concatenation of two strings is the composition of their transition functions, in a slighty unusual sense.&lt;/p&gt; &lt;p&gt;If we were speaking of deterministic automata, then transition functions would be regular mathematical functions from &lt;span&gt;\(S\)&lt;/span&gt; to &lt;span&gt;\(S\)&lt;/span&gt;, where &lt;span&gt;\(S\)&lt;/span&gt; is the automaton’s set of states.&lt;/p&gt; &lt;p&gt;Given two strings &lt;span&gt;\(p\)&lt;/span&gt; and &lt;span&gt;\(q\)&lt;/span&gt; with corresponding transition functions &lt;span&gt;\(f\)&lt;/span&gt; and &lt;span&gt;\(g\)&lt;/span&gt;, feeding &lt;span&gt;\(pq\)&lt;/span&gt; to the automaton will take &lt;span&gt;\(s\)&lt;/span&gt; to &lt;span&gt;\(f(s)\)&lt;/span&gt; and then to &lt;span&gt;\(g(f(s))\)&lt;/span&gt;, which means that the transition function of &lt;span&gt;\(pq\)&lt;/span&gt; is &lt;span&gt;\(g \circ f\)&lt;/span&gt;.&lt;/p&gt; &lt;p&gt;However, we’re using NFAs, and transition functions of characters and strings take states to &lt;em&gt;sets&lt;/em&gt; of states. Note that we do &lt;em&gt;not&lt;/em&gt; say that the &lt;em&gt;inputs&lt;/em&gt; of these functions are also sets of states: it suffices to define them only at individual “singleton” states: applying a transition function to a set of states means applying it to each of these states individually and taking a union of the results (imagine that a simulation of the automaton occurs simultaneously for all these states).&lt;/p&gt; &lt;p&gt;So suppose again that the transition functions of &lt;span&gt;\(p\)&lt;/span&gt; and &lt;span&gt;\(q\)&lt;/span&gt; are &lt;span&gt;\(f\)&lt;/span&gt; and &lt;span&gt;\(g\)&lt;/span&gt;. Then if the automaton’s initial state is &lt;span&gt;\(s\)&lt;/span&gt; (some individual state), then &lt;span&gt;\(pq\)&lt;/span&gt; will take the automaton first to &lt;span&gt;\(f(s)\)&lt;/span&gt; (a set of states) and then to &lt;span&gt;\(\bigcup_{r \leftarrow f(s)}{g(r)}\)&lt;/span&gt;.&lt;/p&gt; &lt;p&gt;This is the definition of composition for transition functions of non-deterministic automata: &lt;span&gt;\((f \circ g)(s) = \bigcup_{r \leftarrow f(s)}{g(r)}\)&lt;/span&gt;.&lt;/p&gt; &lt;p&gt;This definition is curious because it has several interpretations.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt;The interpretation given just now;&lt;/p&gt; &lt;/li&gt; &lt;li&gt;&lt;p&gt;The graphical interpretation as connectivity in a two-layer graph, as on the picture above;&lt;/p&gt; &lt;/li&gt; &lt;li&gt;&lt;p&gt;Multiplication of boolean matrices: if we represent the transition function &lt;span&gt;\(f\)&lt;/span&gt; as an &lt;span&gt;\(N x N\)&lt;/span&gt; boolean matrix (where &lt;span&gt;\(N\)&lt;/span&gt; is the number of states in the automaton) with &lt;span&gt;\(1\)&lt;/span&gt; in cell &lt;span&gt;\(s,t\)&lt;/span&gt; if &lt;span&gt;\(t \in f(s)\)&lt;/span&gt;.&lt;/p&gt; &lt;p&gt;Then we may rephrase the definition &lt;span&gt;\((f \circ g)(s) = \bigcup_{r \leftarrow f(s)}{g(r)}\)&lt;/span&gt; as follows: &lt;span&gt;\((f \circ g)(s,t) = \bigvee_{r \leftarrow f(s)}{t \in g(r)} = \bigvee_{r \leftarrow 1..N}{(s,r) \in f \wedge (r,t) \in g}\)&lt;/span&gt; .&lt;/p&gt; &lt;p&gt;Note the extreme similarity with matrix multiplication: &lt;span&gt;\((AB)[i,j] = \sum_{k \leftarrow 1..N}{A[i,k]*B[k,j]}\)&lt;/span&gt;: only summation is replaced with logical “or” (&lt;span&gt;\(\vee\)&lt;/span&gt;) and multiplication is replaced with logical “and” (&lt;span&gt;\(\wedge\)&lt;/span&gt;).&lt;/p&gt; &lt;p&gt;This interpretation is of course not new; it is a well-known fact shown in most textbooks on graph theory that connectivity in graphs may be computed using multiplication of boolean matrices corresponding to their incidence matrices. However, it opens some opportunities for optimization by employing well-known algorithms for fast matrix multiplication.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;div id="making-use-of-transition-functions"&gt; &lt;h3&gt;Making use of transition functions&lt;a title="Permalink to this headline" href="#making-use-of-transition-functions"&gt;¶&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;Let us now consider how this knowledge of transition function multiplication helps us implement incremental matching.&lt;/p&gt; &lt;p&gt;We shall start with a simpler problem: &lt;strong&gt;match testing&lt;/strong&gt;, i.e. answering the question “Does the string &lt;span&gt;\(s\)&lt;/span&gt; match regular expression &lt;span&gt;\(R\)&lt;/span&gt;?”&lt;/p&gt; &lt;p&gt;This is by definition equivalent to the question “Does the transition function of &lt;span&gt;\(s\)&lt;/span&gt; take &lt;span&gt;\(R\)&lt;/span&gt;‘s automaton to a final state?”. So, if we maintain transition functions of strings under the incremental operations (concatenations and splits), we’ll be able to also maintain the answer to this question.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Handling concatenations is simple&lt;/strong&gt;: given that we’ve learnt to rapidly compute transition functions of string concatenations, we’ve essentially learnt to rapidly recompute results of “yes/no”-style match tests after concatenations.&lt;/p&gt; &lt;p&gt;Therefore, if we carry with each string its transition function (a device for rapidly performing a match test), then when concatenating two strings, we’d compose their functions, yielding again a device for rapidly testing their concatenation for a match.&lt;/p&gt; &lt;/div&gt; &lt;div id="reducing-splits-to-concatenation"&gt; &lt;h3&gt;Reducing splits to concatenation&lt;a title="Permalink to this headline" href="#reducing-splits-to-concatenation"&gt;¶&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Handling splits is harder&lt;/strong&gt;: it is not obvious how to get the transition function of a part of a string, knowing only that of the whole string.&lt;/p&gt; &lt;p&gt;However, this problem of splitting is, curiously, &lt;em&gt;reduced to the problem of concatenation&lt;/em&gt;: if we represent a string as an hierarchical concatenation (a tree) of several smaller parts (chunks), then parts of this string will be concatenations of some of these chunks. More precisely, a part of the string equals the concatenation of all complete subtrees fully enclosed within that part, with incomplete chunks giving birth to new tiny but complete subtrees — see picture below.&lt;/p&gt; &lt;div&gt; &lt;p&gt;&lt;img src="http://jkff.info/articles/ire/_images/split-as-concatenation.png" alt="_images/split-as-concatenation.png"&gt;&lt;/p&gt;&lt;p&gt;Representing a part of a string as the concatenation of its smaller parts&lt;/p&gt; &lt;/div&gt; &lt;p&gt;If a split goes through the middle of a chunk, we’ll still have to recompute the transition function for the resulting “sub-chunks” character by character, but most of the chunks or bigger parts of the hierarchy will remain intact and &lt;strong&gt;we won’t have to recompute their transition functions&lt;/strong&gt;, thus saving most of the computation.&lt;/p&gt; &lt;p&gt;All that remains is to choose a good way of representing a string as many chunks, so that concatenation and splitting are efficient, and memory overhead is not too high. This is what we consider in the next section.&lt;/p&gt; &lt;p&gt;Note again that &lt;strong&gt;this still does not allow finding positions of matches&lt;/strong&gt; — only whether the string matches the expression or not. This is perhaps the most interesting algorithmic problem in this article, and we shall address it later when more background is given.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id="putting-it-together"&gt; &lt;h2&gt;Putting it together&lt;a title="Permalink to this headline" href="#putting-it-together"&gt;¶&lt;/a&gt;&lt;/h2&gt; &lt;p&gt;Now, before going to the technical and most interesting parts, let us recap on the basic idea of incremental matching.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;We represent strings as trees of chunks (small “atomic” strings).&lt;/li&gt; &lt;li&gt;With each string (actually with each node in a tree representing a string) we carry its transition function with respect to the regular expression of interest.&lt;/li&gt; &lt;li&gt;To perform a match test, we simply take the transition function, apply it to the automaton’s initial state and check whether we hit a final state. We don’t even look at the string per se.&lt;/li&gt; &lt;li&gt;When concatenating two strings, we multiply their transition functions.&lt;/li&gt; &lt;li&gt;When splitting a string into parts, we reduce that to concatenation of some of its nodes — remember that we keep the transition functions for all the nodes.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;An example of such a datastructure is illustrated on the picture below.&lt;/p&gt; &lt;div&gt; &lt;p&gt;&lt;img src="http://jkff.info/articles/ire/_images/rope-nfa.png" alt="_images/rope-nfa.png"&gt;&lt;/p&gt;&lt;p&gt;Example representation with cached transition functions for the string &lt;span&gt;\(bcabbccabcccab\)&lt;/span&gt;&lt;/p&gt; &lt;/div&gt; &lt;div id="ropes-strings-with-fast-concatenation"&gt; &lt;h3&gt;Ropes: Strings with fast concatenation&lt;a title="Permalink to this headline" href="#ropes-strings-with-fast-concatenation"&gt;¶&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;This data structure, which is a tree of small arrays, is called a “rope”, and ropes are frequently used for representing strings where efficient concatenation and splitting are needed while preserving reasonably low memory overhead (e.g. having a balanced tree of individual &lt;em&gt;characters&lt;/em&gt; is not an option because it blows up memory usage).&lt;/p&gt; &lt;p&gt;Ropes are a long-known datastructure and there are many varieties of them, usually differing in the kind of balanced trees they use. One of these varieties is described in the article &lt;a href="http://dx.doi.org/10.1002/spe.4380251203"&gt;Ropes: An alternative to strings&lt;/a&gt; by Hans-J. Boehm, Russ Atkinson, and Michael Plass, but we’ll use a different one, to be shown later in the article.&lt;/p&gt; &lt;p&gt;Maintaining the transition functions of rope nodes at concatenations and splits is simple for every variety of ropes: exactly as we assemble new nodes from old nodes during rebalancing, we assemble the transition functions of new nodes from transition functions of old nodes (by composing them).&lt;/p&gt; &lt;p&gt;Even the definition of rebalancing operations doesn’t have to be modified, just the constructor for composite nodes (nodes with children) has to multiply the children’s transition functions to obtain one for the parent, and the constructor for chunks has to assemble the transition function from transition functions of characters.&lt;/p&gt; &lt;/div&gt; &lt;div id="generalizing-ropes"&gt; &lt;h3&gt;Generalizing ropes&lt;a title="Permalink to this headline" href="#generalizing-ropes"&gt;¶&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;Note that there is not much special about transition functions that allows us to maintain them under splits and concatenations. The only reason why we could do so is because we can compute the transition function for a concatenation of two strings from their transition functions.&lt;/p&gt; &lt;p&gt;So, essentially ropes allow us to maintain absolutely any kind of “additive” characteristic (and we’re of course not restricted to speaking about strings, i.e. lists of characters — for example, lists of numbers are just as fine). There is just one restriction: in order for the additivity to make any sense, it must not be dependent on the order in which we add up the items to obtain the whole; this property is called &lt;strong&gt;associativity&lt;/strong&gt;: since for concatenation holds &lt;span&gt;\(a(bc) = (ab)c\)&lt;/span&gt;, the additive characteristic &lt;span&gt;\(f\)&lt;/span&gt; must obey &lt;span&gt;\(f(a(bc)) = f((ab)c)\)&lt;/span&gt;, that is, if the additivity is expressed as &lt;span&gt;\(f(ab) = g(f(a), f(b))\)&lt;/span&gt;, then &lt;span&gt;\(g\)&lt;/span&gt; must obey &lt;span&gt;\(g(g(x,y),z) = g(x,g(y,z))\)&lt;/span&gt;.&lt;/p&gt; &lt;p&gt;Here are some examples of additive (associative) characteristics:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The sum of a list of numbers&lt;/li&gt; &lt;li&gt;The maximum and minimum number&lt;/li&gt; &lt;li&gt;The sum of squares of a list of numbers&lt;/li&gt; &lt;li&gt;The sum and size of a list of numbers (allowing to maintain the average, e.g. for answering “range average” queries)&lt;/li&gt; &lt;li&gt;The number of times a given character occurs in the string (for example, the newline character)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;There are many more examples, you can find them near the end of the article, in the section “Monoids”.&lt;/p&gt; &lt;p&gt;Below is an example of a rope of numbers maintaining the minimum and maximum — the combining operation here is &lt;span&gt;\(g((m_1,M_1), (m_2,M_2)) = (min(m_1,m_2), max(M_1,M_2))\)&lt;/span&gt;&lt;/p&gt; &lt;div&gt; &lt;p&gt;&lt;img src="http://jkff.info/articles/ire/_images/rope-minmax.png" alt="_images/rope-minmax.png"&gt;&lt;/p&gt;&lt;p&gt;A rope of numbers with “cached” minimums and maximums.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id="monotone-split-operation"&gt; &lt;h3&gt;Monotone split operation&lt;a title="Permalink to this headline" href="#monotone-split-operation"&gt;¶&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;In addition to splitting at a position, one may implement one more very important and beautiful operation on ropes: splitting on a monotone predicate. We shall need this operation when we get from “testing for a match” to “locating matches”, but we first provide an abstract setting, because it will be a lot easier to understand how locating matches can be done using this abstract algorithm, than to go in the opposite direction (recognize its beauty inside the full complicated algorithm for locating matches).&lt;/p&gt; &lt;p&gt;Suppose &lt;span&gt;\(f\)&lt;/span&gt; is a predicate on strings. Suppose that &lt;span&gt;\(f\)&lt;/span&gt; is such that a string may only &lt;em&gt;gain&lt;/em&gt; (but not lose) the property &lt;span&gt;\(f\)&lt;/span&gt; when symbols are appended to it on the right, i.e., &lt;span&gt;\(\forall s_1, f(s_1) \Rightarrow \forall s_2, f(s_1 + s_2)\)&lt;/span&gt;. In this case let us call &lt;span&gt;\(f\)&lt;/span&gt; &lt;strong&gt;monotone&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;Then obviously each string &lt;span&gt;\(s\)&lt;/span&gt; satisfying the property &lt;span&gt;\(f\)&lt;/span&gt; has a &lt;em&gt;minimal prefix&lt;/em&gt; satisfying &lt;span&gt;\(f\)&lt;/span&gt;. Let us illustrate this notion and the algorithm for its efficient computation on a rope:&lt;/p&gt; &lt;div&gt; &lt;p&gt;&lt;img src="http://jkff.info/articles/ire/_images/split-sum-squares.png" alt="_images/split-sum-squares.png"&gt;&lt;/p&gt;&lt;p&gt;Splitting a rope of numbers by the monotone predicate “Sum of squares exceeds 140”&lt;/p&gt; &lt;/div&gt; &lt;p&gt;This picture shows a rope of numbers, storing in each node the sum of squares of numbers within this node, and it also shows how the rope is split to find &lt;em&gt;the minimal prefix whose sum of squares is greater than 140&lt;/em&gt;. The algorithm resembles &lt;strong&gt;a “hot and cold” game&lt;/strong&gt;; the figure shows sums of squares of prefixes before and after various edges and (when scanning a leaf chunk) individual numbers; those that do not yet satisfy the condition are marked with “cold” blue color, and those that do are marked with “hot” red. This picture also shows that when scanning through a leaf chunk, we have to recompute and add up the squares of numbers, i.e. the information stored in nodes of the rope is not sufficient.&lt;/p&gt; &lt;p&gt;On this picture &lt;strong&gt;an edge is marked red if the predicate is true for the prefix which ends where this edge ends&lt;/strong&gt;. To find the split point, we have to descend from the root of the rope to a leaf chunk, doing steps downward or to the right, at each level scanning edges left-to-right until we find a red edge (this is similar to a binary search procedure), and finally split the leaf chunk, this time using regular linear search.&lt;/p&gt; &lt;p&gt;Since we only move downward or to the right, at any moment the edges that have been considered cover together an ever-growing prefix of the original rope, and &lt;strong&gt;each new scanned edge appends the rope covered by this edge&lt;/strong&gt; to this prefix. If the predicate is not true before scanning an edge but becomes true after scanning it, this means that it becomes true somewhere inside the part of the rope covered by the destination node of this edge, and we have to descend downward into this node in order to find the split point.&lt;/p&gt; &lt;p&gt;In order to be constantly aware of whether the predicate is true, we should be able to &lt;strong&gt;quickly compute&lt;/strong&gt; &lt;span&gt;\(f(ps)\)&lt;/span&gt;, &lt;strong&gt;given&lt;/strong&gt; &lt;span&gt;\(f(p)\)&lt;/span&gt; &lt;strong&gt;and&lt;/strong&gt; &lt;span&gt;\(f(s)\)&lt;/span&gt; for any two ropes &lt;span&gt;\(p\)&lt;/span&gt; and &lt;span&gt;\(s\)&lt;/span&gt;, since when moving downward or to the right, we increase the “current prefix” (&lt;span&gt;\(p\)&lt;/span&gt;) with sub-ropes covered with each scanned edge (&lt;span&gt;\(s\)&lt;/span&gt;), and when we get to the leaf chunks, during linear search we increase &lt;span&gt;\(p\)&lt;/span&gt; with single-element sub-ropes corresponding to elements of the chunk.&lt;/p&gt; &lt;p&gt;Now note that match testing also sometimes fits this pattern:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Given transition functions for &lt;span&gt;\(p\)&lt;/span&gt; and &lt;span&gt;\(s\)&lt;/span&gt;, we can quickly compute the transition function of &lt;span&gt;\(ps\)&lt;/span&gt;, and given that transition function, we know the answer to the match test.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Some regular expressions are monotone&lt;/strong&gt;, i.e. if a string matches the expression, then appending characters on the right won’t make it lose this property. One class of such regular expressions is expressions of the form &lt;tt&gt;&lt;span&gt;.*R.*&lt;/span&gt;&lt;/tt&gt; for any &lt;tt&gt;&lt;span&gt;R&lt;/span&gt;&lt;/tt&gt;, because they correspond to the question “Is there a match of &lt;tt&gt;&lt;span&gt;R&lt;/span&gt;&lt;/tt&gt; somewhere in the string?”, which obviously is monotone.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;So, we can use this “monotone split” procedure to find the &lt;strong&gt;smallest prefix of the string containing a match&lt;/strong&gt; of our regex.&lt;/p&gt; &lt;div&gt; &lt;p&gt;&lt;img src="http://jkff.info/articles/ire/_images/tree-split-pred.png" alt="_images/tree-split-pred.png"&gt;&lt;/p&gt;&lt;p&gt;Splitting a rope for the string &lt;tt&gt;&lt;span&gt;acabaabacabccaaba&lt;/span&gt;&lt;/tt&gt; on the monotone predicate “matches &lt;tt&gt;&lt;span&gt;.*bcc.*&lt;/span&gt;&lt;/tt&gt; ”&lt;/p&gt; &lt;/div&gt; &lt;p&gt;This is key to finding match positions.&lt;/p&gt; &lt;/div&gt; &lt;div id="finding-match-positions"&gt; &lt;h3&gt;Finding match positions&lt;a title="Permalink to this headline" href="#finding-match-positions"&gt;¶&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;Suppose we have to find a match of &lt;span&gt;\(R\)&lt;/span&gt; in the string. This problem can partly be reformulated as testing the string against the expression “&lt;span&gt;\(.*R.*\)&lt;/span&gt;”, but this only tells us the answer to the question “is there a match of &lt;span&gt;\(R\)&lt;/span&gt; somewhere in the string?”, but not to “where is the match?”&lt;/p&gt; &lt;p&gt;Two key ideas will help us find the match positions.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;As said above, the answer to the first question (the presence of a match) is “monotone”. That is, starting from some prefix of the string, the answer will be positive for all subsequent prefixes. &lt;strong&gt;The first occurrence of&lt;/strong&gt; &lt;span&gt;\(R*\)&lt;/span&gt; &lt;strong&gt;ends exactly where the first such prefix ends&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;It is known &lt;a id="id4" href="#f4"&gt;[4]&lt;/a&gt; that, given a regular expression &lt;span&gt;\(R\)&lt;/span&gt; or its corresponding automaton &lt;span&gt;\(A\)&lt;/span&gt;, one can build a regular expression &lt;span&gt;\(R′\)&lt;/span&gt; and the automaton &lt;span&gt;\(A′\)&lt;/span&gt; which recognize reverses of the strings recognized by &lt;span&gt;\(R\)&lt;/span&gt; and &lt;span&gt;\(A\)&lt;/span&gt;, simply by reversing all sequences inside &lt;span&gt;\(R\)&lt;/span&gt; and, correspondingly, all arrows in &lt;span&gt;\(A\)&lt;/span&gt;. For example, the expression &lt;span&gt;\(a+(b|c*d)x*\)&lt;/span&gt; recognizes the string &lt;span&gt;\(abbdxx\)&lt;/span&gt;, and the expression &lt;span&gt;\(x*(b|dc*)a+\)&lt;/span&gt; recognizes &lt;span&gt;\(xxdbba\)&lt;/span&gt;. Therefore, &lt;strong&gt;we can find the beginning of the match by launching the reversed (“backward”) automaton&lt;/strong&gt; (automaton for the reversed expression) backward over the string, starting from where the match ends.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;So, we use the “split on monotone predicate” operation to find the end of the first match, and use it again, but this time in backward direction and with the backward automaton, to find its beginning. If the expression is such that strings matching it are usually small, we can just run the backward automaton character by character; if not, we can also have the nodes of the rope store transition functions not only for the “forward” automaton, but also transition functions of reversed parts of the string with respect to the “backward” automaton.&lt;/p&gt; &lt;p&gt;It’s easy to see that all rope operations change trivially — instead of composing one pair of transition functions, we compose two: &lt;span&gt;\((f_1,b_1) \circ (f_2,b_2) = (f_2 \circ f_1, b_1 \circ b_2)\)&lt;/span&gt; — note that the order of composition for backward transition functions is reversed because for strings if &lt;span&gt;\(a=bc\)&lt;/span&gt;, then &lt;span&gt;\(reverse(a)=reverse(c)reverse(b)\)&lt;/span&gt;.&lt;/p&gt; &lt;p&gt;There is actually a number of complications here, related to possible overlaps of occurrences of different items from the given system of regular expressions (or even self-overlaps), but the main idea is the same: split to find the end of the match, split backward to find the beginning. The curious reader is directed &lt;a href="https://github.com/jkff/ire/blob/master/src/main/java/org/jkff/ire/DFAMatcher.java"&gt;to the source code&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div&gt; &lt;h2&gt;Implementation&lt;a title="Permalink to this headline" href="#implementation"&gt;¶&lt;/a&gt;&lt;/h2&gt; &lt;p&gt;Let us put together the presented algorithms and overview the structure of the whole program. Graphically this structure is shown on the pictures below. This kind of diagrams is called “concept maps”, drawn with &lt;a href="http://cmap.ihmc.us/"&gt;IHMC CmapTools&lt;/a&gt; software.&lt;/p&gt; &lt;div id="program-structure-overview"&gt; &lt;h3&gt;Program structure overview&lt;a title="Permalink to this headline" href="#program-structure-overview"&gt;¶&lt;/a&gt;&lt;/h3&gt; &lt;div&gt; &lt;p&gt;&lt;img src="http://jkff.info/articles/ire/_images/ire-overview.png" alt="_images/ire-overview.png"&gt;&lt;/p&gt;&lt;p&gt;Program structure overview&lt;/p&gt; &lt;/div&gt; &lt;p&gt;The user specifies several regular expressions as strings, which through compilation (parsing and converting to a finite automaton) get transformed to an object of type &lt;a href="https://github.com/jkff/ire/blob/master/src/main/java/org/jkff/ire/PatternSet.java"&gt;PatternSet&lt;/a&gt;. Such an object is capable of “indexing” regular strings, yielding objects of type &lt;a href="https://github.com/jkff/ire/blob/master/src/main/java/org/jkff/ire/IndexedString.java"&gt;IndexedString&lt;/a&gt;. They, in turn, are capable of efficiently searching for all matches of the patterns in themselves, and they can also efficiently be concatenated or split (on a monotone predicate). These are of course the very ropes maintaining transition functions.&lt;/p&gt; &lt;/div&gt; &lt;div id="ropes-and-additive-measures"&gt; &lt;h3&gt;Ropes and additive measures&lt;a title="Permalink to this headline" href="#ropes-and-additive-measures"&gt;¶&lt;/a&gt;&lt;/h3&gt; &lt;div&gt; &lt;p&gt;&lt;img src="http://jkff.info/articles/ire/_images/ire-rope.png" alt="_images/ire-rope.png"&gt;&lt;/p&gt;&lt;p&gt;Program structure: ropes and additive measures&lt;/p&gt; &lt;/div&gt; &lt;p&gt;“Indexed strings” are implemented with ropes (&lt;a href="https://github.com/jkff/ire/blob/master/src/main/java/org/jkff/ire/rope/Rope.java"&gt;Rope&lt;/a&gt;). The program implements only ropes over characters, because further generalization was not necessary within the scope of our problem and the Java type system would cause the generic implementation to have a lot of syntactic garbage. A rope is a string that knows its “measure” of type &lt;tt&gt;&lt;span&gt;M&lt;/span&gt;&lt;/tt&gt;. The measure is computed as the sum of measures of individual characters (&lt;tt&gt;&lt;span&gt;Function&amp;lt;Character,M&amp;gt;&lt;/span&gt;&lt;/tt&gt;) under an arbitrary additive measure (&lt;a href="https://github.com/jkff/ire/blob/master/src/main/java/org/jkff/ire/util/Reducer.java"&gt;Reducer&lt;/a&gt;). Ropes are implemented with a special kind of balanced trees that will be described later in the article. During rebalancing operations measures of new nodes are summed from measures of old nodes using this additive operation. For regular expression matching, the additive operation composition of transition functions for the expression’s automaton (more precisely, for two automata: forward and reverse).&lt;/p&gt; &lt;/div&gt; &lt;div id="finite-automata"&gt; &lt;h3&gt;Finite automata&lt;a title="Permalink to this headline" href="#finite-automata"&gt;¶&lt;/a&gt;&lt;/h3&gt; &lt;div&gt; &lt;p&gt;&lt;img src="http://jkff.info/articles/ire/_images/ire-fa.png" alt="_images/ire-fa.png"&gt;&lt;/p&gt;&lt;p&gt;Program structure: finite automata&lt;/p&gt; &lt;/div&gt; &lt;p&gt;Automata are implemented in a way that facilitates representing and computing their “transition functions”. An automaton can tell its transition function for any given character, and the transition function is a function from the automaton’s state type to the same type. A value of the state type is a “black box” that only tells what patterns are “terminated” by this state: if after scanning a string, the automaton’s state terminates certain patterns, then there are occurrences of these patterns ending at the end of this string. Transition functions are represented not as arbitrary functions but as a special kind of objects with efficient composition &lt;a id="id5" href="#f5"&gt;[5]&lt;/a&gt;. These objects are placed into the ropes used as “indexed strings”.&lt;/p&gt; &lt;/div&gt; &lt;div id="relationship-between-dfas-and-nfas"&gt; &lt;h3&gt;Relationship between DFAs and NFAs&lt;a title="Permalink to this headline" href="#relationship-between-dfas-and-nfas"&gt;¶&lt;/a&gt;&lt;/h3&gt; &lt;div&gt; &lt;p&gt;&lt;img src="http://jkff.info/articles/ire/_images/ire-dfa-nfa.png" alt="_images/ire-dfa-nfa.png"&gt;&lt;/p&gt;&lt;p&gt;Program structure: the connection between deterministic and non-deterministic automata&lt;/p&gt; &lt;/div&gt; &lt;p&gt;The notion of an automaton is used in the program in two ways: for deterministic and non-deterministic automata. The state type of a deterministic automaton &lt;a id="id6" href="#f6"&gt;[6]&lt;/a&gt; is the set of integer numbers from &lt;span&gt;\(0\)&lt;/span&gt; to some &lt;span&gt;\(N\)&lt;/span&gt;; correspondingly, transition functions are functions from &lt;span&gt;\(0 … N\)&lt;/span&gt; to &lt;span&gt;\(0 … N\)&lt;/span&gt;. They are implemented as one-dimensional &lt;tt&gt;&lt;span&gt;int[]&lt;/span&gt;&lt;/tt&gt; arrays, and their composition is computed as easily as &lt;tt&gt;&lt;span&gt;c[i]&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;b[a[i]]&lt;/span&gt;&lt;/tt&gt;.&lt;/p&gt; &lt;p&gt;In the case of non-deterministic automata, values of the state type are subsets of some “basis” state set, and a transition function is determined by the way in which it transforms each individual basis state to several other basis state, i.e. it is specified by a transformation of the form &lt;tt&gt;&lt;span&gt;int&lt;/span&gt;&lt;/tt&gt; → &lt;tt&gt;&lt;span&gt;int[]&lt;/span&gt;&lt;/tt&gt;. Composition of such functions is expressed as &lt;span&gt;\(c[i] = \bigcup_{j \leftarrow a[i]} b[j]\)&lt;/span&gt; (thread the second function through all the outputs of the first function). For the sake of efficiency, this transformation is implemented by a boolean matrix with every element represented as one bit in a single array &lt;a id="id7" href="#f7"&gt;[7]&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div id="multiple-regular-expressions"&gt; &lt;h3&gt;Multiple regular expressions&lt;a title="Permalink to this headline" href="#multiple-regular-expressions"&gt;¶&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;The aforementioned datastructure allows to match a string against a single regular expression. It is natural to demand a more practically useful generalization: matching against multiple expressions (there exist also other approaches to this problem, see for example the article “Compact DFA structure for multiple regular expressions matching” by Lin, Tang et al.). The result of such a match is a set of facts of the form “The portion &lt;span&gt;\(i..j\)&lt;/span&gt; matched expression &lt;span&gt;\(k\)&lt;/span&gt; ”.&lt;/p&gt; &lt;p&gt;The problem of matching against multiple regular expressions is solved quite easily: we build an automaton for their union, &lt;span&gt;\(R_1|R_2|...\)&lt;/span&gt;, but we distinguish between final states for different expressions, i.e. a state of the resulting automaton is not simply “final” or “non-final”, but it has an associated bitset: for which of the expressions it is final.&lt;/p&gt; &lt;p&gt;This change only slightly influences other parts of the program, such as automata minimization or finding match positions.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id="examples-and-benchmarks"&gt; &lt;h2&gt;Examples and benchmarks&lt;a title="Permalink to this headline" href="#examples-and-benchmarks"&gt;¶&lt;/a&gt;&lt;/h2&gt; &lt;p&gt;Let us show an example of usage of the library.:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;PatternSet pat = RegexCompiler.compile("007","008") IndexedString s1 = pat.match("as00haklsdjhfla00"); IndexedString s2 = pat.match("7jhd7dsh008dsfa"); System.out.println(s1.append(s2).getMatches());&lt;/pre&gt; &lt;/div&gt; &lt;p&gt;The program prints:&lt;/p&gt; &lt;p&gt;This means that occurrences of the first and second pattern were found correspondingly in positions 15–17 and 25–27.&lt;/p&gt; &lt;p&gt;This code uses the following aspects of the API:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://github.com/jkff/ire/blob/master/src/main/java/org/jkff/ire/regex/RegexCompiler.java"&gt;RegexCompiler.compile&lt;/a&gt; — compile several regular expressions to an automaton recognizing any of them.&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/jkff/ire/blob/master/src/main/java/org/jkff/ire/PatternSet.java"&gt;PatternSet.match&lt;/a&gt; — index a “regular” string, preparing it to searching for the given patterns.&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/jkff/ire/blob/master/src/main/java/org/jkff/ire/IndexedString.java"&gt;IndexedString.append&lt;/a&gt; — compute the concatenation of two strings indexed by the same pattern set.&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/jkff/ire/blob/master/src/main/java/org/jkff/ire/IndexedString.java"&gt;IndexedString.getMatches&lt;/a&gt; — find matches of the pattern set in an indexed string.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Now let us discuss the library’s performance.&lt;/p&gt; &lt;p&gt;This discussion won’t be a simple one, because the performance is influenced by a large number of factors.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Size of the automaton&lt;/strong&gt;, which depends approximately linearly on the number and size of individual regular expressions: it linearly influences both the performance of all operations and the memory consumption (larger is worse). The program uses an algorithm for minimization of non-deterministic automata described in the article “On NFA reductions” by Ilie and Navarro. (however, the implementation is extremely inefficient, but this doesn’t influence matching performance because minimization is only done in &lt;a href="https://github.com/jkff/ire/blob/master/src/main/java/org/jkff/ire/regex/RegexCompiler.java"&gt;RegexCompiler.compile&lt;/a&gt;), but it usually shrinks the automaton just by several dozen percents.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Size of the leaf chunks&lt;/strong&gt; in ropes linearly influences search performance (larger is slower), has almost no influence at all on concatenation performance, and linearly influences memory consumption (the larger the chunks, the fewer the memory overhead).&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Features of the particular regular expression&lt;/strong&gt; influence the automaton’s “shape”, which in turn influences the speed of operations on it (“hairy” expressions lead to dense boolean matrices for transition functions, which are slower to multiply in the current implementation).&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Number of matches&lt;/strong&gt; linearly influences the search time in the current implementation (larger is worse), but there is room for optimization here.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;It is also necessary to balance the share of time devoted to indexing the string, doing concatenations/splits and searching. Indexing is done quite slowly, and one needs a large number of concatenations/splits and search to overweight it and to get an advantage over a “traditional” regular expression engine.&lt;/p&gt; &lt;div id="test-setup"&gt; &lt;h3&gt;Test setup&lt;a title="Permalink to this headline" href="#test-setup"&gt;¶&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;In light of the above, let us consider just a single test and analyze its performance. Take the set of regular expressions from the &lt;a href="http://shootout.alioth.debian.org/u32q/performance.php?test=regexdna"&gt;regex-dna&lt;/a&gt; problem from the Language Shooutout and consider performance of matching operations compared to the standard regular expression engine bundled with Java (&lt;a href="http://download.oracle.com/javase/1.5.0/docs/api/java/util/regex/Pattern.html"&gt;java.util.regex.Pattern&lt;/a&gt;), varying length of the input DNA string (but keeping constant the total number of matches) and size of the leaf chunks: 8, 16, 32, … 512 characters.&lt;/p&gt; &lt;p&gt;We do not measure splitting performance separately, because splitting is used during search, and we do not measure concatenation performance because it is so fast (allocate a few objects and compose a few transition functions) that it is difficult to imagine a scenario where it would be the bottleneck.&lt;/p&gt; &lt;p&gt;Here is the pattern set:&lt;/p&gt; &lt;div&gt;&lt;pre&gt;[cgt]gggtaaa|tttaccc[acg] a[act]ggtaaa|tttacc[agt]t ag[act]gtaaa|tttac[agt]ct agg[act]taaa|ttta[agt]cct aggg[acg]aaa|ttt[cgt]ccct agggt[cgt]aa|tt[acg]accct agggta[cgt]a|t[acg]taccct agggtaa[cgt]|[acg]ttaccct&lt;/pre&gt; &lt;/div&gt; &lt;p&gt;Let us generate the input as a random sequence of the characters “ &lt;tt&gt;&lt;span&gt;a&lt;/span&gt;&lt;/tt&gt;, &lt;tt&gt;&lt;span&gt;g&lt;/span&gt;&lt;/tt&gt;, &lt;tt&gt;&lt;span&gt;c&lt;/span&gt;&lt;/tt&gt;, &lt;tt&gt;&lt;span&gt;t&lt;/span&gt;&lt;/tt&gt; ” of length &lt;span&gt;\(50000 N\)&lt;/span&gt; (&lt;span&gt;\(N\)&lt;/span&gt; will vary from 1 to 10) where any two consequent characters are distinct (therefore the aforementioned patterns can’t occur there), choose 100 random positions in the sequence and insert there occurrences of strings randomly chosen from the set of &lt;span&gt;\(8 × 2 × 3 = 48\)&lt;/span&gt; strings defined by the given pattern set (8 patterns, each with 2 alternatives, each alternative matching 3 different strings). The program will compute the occurrence count of each pattern.&lt;/p&gt; &lt;/div&gt; &lt;div id="benchmark-results-and-interpretation"&gt; &lt;h3&gt;Benchmark results and interpretation&lt;a title="Permalink to this headline" href="#benchmark-results-and-interpretation"&gt;¶&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;Results of the benchmark are shown on the pictures below. The performance characteristics of each of the two programs (our engine and the standard Java engine) are shown in the terms that are most appropriate for them: for our engine it is the indexing speed (in characters per second, because indexing speed is proportional to the number of characters) and search speed (in occurrences per second, because search speed is proportional to the number of occurrences). For the Java engine a more appropriate characteristic is “characters processed per second”; it is displayed on the same graph with our engine’s “indexing speed’, though this comparison is somewhat flawed.&lt;/p&gt; &lt;p&gt;On graphs in the left part of the picture, different curves correspond to different &lt;em&gt;base sizes of chunks&lt;/em&gt; in the rope datastructure, and the bold curve corresponds to the Java engine.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;The question “When is our engine better than the Java engine?” is best answered by the top left graph&lt;/strong&gt;, which shows the dependency of search speed on the string length. It can be seen that the Java engine’s search time is proportional to the length of the string, and our engine’s time is proportional to the number of occurrences. With small base chunk sizes (4–32 characters) our engine is much faster for large strings.&lt;/p&gt; &lt;p&gt;On graphs in the right part of the picture, different curves correspond to different &lt;em&gt;lengths&lt;/em&gt; of the input string. They are displayed to show how the base chunk size influences search and indexing speed. It can be seen that with increase of this chunk size indexing speed increases rapidly (but with a limit) and search speed decreases just as rapidly.&lt;/p&gt; &lt;p&gt;We can conclude that &lt;strong&gt;for large strings with a small number of occurrences our engine is more efficient&lt;/strong&gt;, especially if tuned for a small base chunk size. However, in this case there is a sharp increase in memory consumption: memory consumption per leaf chunk does not depend on the chunk size, but there are 128 times more of 4-character chunks in a string then there are 512-character chunks, therefore the memory consumption is also 128 times larger.&lt;/p&gt; &lt;div&gt; &lt;p&gt;&lt;img src="http://jkff.info/articles/ire/_images/benchmark.png" alt="_images/benchmark.png"&gt;&lt;/p&gt;&lt;p&gt;Performance benchmarks&lt;/p&gt; &lt;/div&gt; &lt;div&gt; &lt;p&gt;&lt;img src="http://jkff.info/articles/ire/_images/memory-overhead.png" alt="_images/memory-overhead.png"&gt;&lt;/p&gt;&lt;p&gt;Memory overhead&lt;/p&gt; &lt;/div&gt; &lt;p&gt;&lt;strong&gt;Almost all the time is spent composing transition functions of characters&lt;/strong&gt; (which is done through boolean matrix multiplication) for recomputing transition functions of leaf chunks during splits, and almost all the memory overhead is devoted to storing these boolean matrices.&lt;/p&gt; &lt;p&gt;We haven’t considered how performance depends on the complexity of regular expressions and on the number of occurrences. A comprehensive treatment of performance questions would take up too much space; curious readers are encouraged to play with the library themselves.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id="what-s-next"&gt; &lt;h2&gt;What’s next?&lt;a title="Permalink to this headline" href="#what-s-next"&gt;¶&lt;/a&gt;&lt;/h2&gt; &lt;p&gt;The current implementation has a number of drawbacks. It is not yet clear which of these can be fixed and which can’t, but in any case, they are interesting algorithmic problems worth thinking about.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The questions of match semantics, such as “greediness” etc. are not considered in the program at all. It is unclear which of the popular solutions (POSIX, Perl, …) are efficiently implementable within the automata-theoretic approach.&lt;/li&gt; &lt;li&gt;Capturing groups are not supported. The article &lt;a href="http://swtch.com/~rsc/regexp/regexp3.html"&gt;Regular Expression Matching in the Wild&lt;/a&gt; describes a way to support them with automata, but the proposed solution does not fit well with our approach.&lt;/li&gt; &lt;li&gt;Multiplication of boolean matrices (used for computing the composition of transition functions) uses a well-optimized but rather naive algorithm; perhaps in some scenarios other algorithms would be faster (for example, ones using sparse matrices).&lt;/li&gt; &lt;li&gt;During matching using splits, a lot of unneeded work is done: for example, during the backward split (which is used to find the &lt;em&gt;beginning&lt;/em&gt; of a match) there’s no need to compute the transition function for the two resulting strings. Fixing this problem would increase performance by a couple dozen percents.&lt;/li&gt; &lt;li&gt;Matching time is proportional to the number of occurrences, the leaf chunk size and the automaton’s size. This makes the program nearly useless as an efficient incremental lexer, because in lexing problems the number of occurrences is very large. One of the ways to fix this problem is to modify the “split by monotone predicate” algorithm to split not into two, but into many parts, for example, on the “edges” of a monotone integer-valued function.&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div id="conclusion"&gt; &lt;h2&gt;Conclusion&lt;a title="Permalink to this headline" href="#conclusion"&gt;¶&lt;/a&gt;&lt;/h2&gt; &lt;p&gt;So, we’ve built a library that does incremental matching of strings against a set of regular expressions using balanced trees and monoids. The library is very efficient in the case of long strings, few expressions, few occurrences, frequent incremental recomputation and a lot of free memory, and is quite inefficient in other cases. It’s hard to say, for which of the cases it is at all possible to make it efficient: for example, whether it is possible to create a high-performance incremental lexer with it, and whether we can at all name this experiment an algorithmic success. The author hopes at least that the presented techniques will inspire the algorithmically inclined readers for new research and will prove of use to them in other problems.&lt;/p&gt; &lt;p&gt;In any case, we can say that this development is an interesting and successful experience of blending the functional and imperative approaches.&lt;/p&gt; &lt;p&gt;Let us list the used techniques, ideas and traditions from functional programming, and discuss how well they fit with the imperative nature of the target language (Java).&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The main datastructure, the rope, is pure (immutable). This decision went very well with the Java language and dramatically simplified development and debugging, despite the absence of language features such as algebraic datatypes and pattern matching.&lt;/li&gt; &lt;li&gt;Nearly all of the library’s API is pure (doesn’t have side effects). However, mutable state and side effects are abandoned only on an architectural level, but the implementation has quite a few usages of mutable state, both for the sake of performance (multiplication of boolean matrices) and, paradoxically, readability (building an automaton from a regular expression). See the source code for, correspondingly, &lt;tt&gt;&lt;span&gt;PowerIntTable&lt;/span&gt;&lt;/tt&gt; and &lt;tt&gt;&lt;span&gt;RegexCompiler&lt;/span&gt;&lt;/tt&gt; for details. All in all, this means that the purely functional approach to programming fits well with imperative languages and doesn’t prevent us from using mutable state in the cases where it brings more use than harm.&lt;/li&gt; &lt;li&gt;Contrary to the common myth “functional programming is inefficient and leads to excessive memory consumption”, the only performance bottleneck is in the imperative algorithm of transition function multiplication, and memory is used for storing these transition functions for rope nodes as bitmasks. Apparently there is no connection between the overheads and the pure nature of the algorithms &lt;a id="id9" href="#f8"&gt;[8]&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;The core of the program is manipulation of higher-order functions: ropes are parameterized by monoids, and their most important operation, splitting, is parameterized by a predicate. Since Java does not have a compact syntax for function definition (such as lambda expressions) and type inference, usage of these entities causes quite a lot of syntactic garbage (especially types in declarations). However, though their usage is extremely important for the program as a whole, it is concentrated in a rather small region of the code, isolated from the library’s end users. However, if the Java type system were a bit more powerful and a bit less verbose, it would be possible to generalize the library, without loss of performance, to searching not just strings but arbitrary sequences.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The author would like to thank Dmitry Demeschchuk, Julia Astakhova, Alexey Ott and other reviewers of the original Russian version of this article for their feedback.&lt;/p&gt; &lt;p&gt;The project is published on GitHub at &lt;a href="http://github.com/jkff/ire"&gt;http://github.com/jkff/ire&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div id="appendix-1-implementation-of-ropes"&gt; &lt;h2&gt;Appendix 1: Implementation of ropes&lt;a title="Permalink to this headline" href="#appendix-1-implementation-of-ropes"&gt;¶&lt;/a&gt;&lt;/h2&gt; &lt;p&gt;It has already been said that, when representing a string by a balanced tree, in order to keep memory usage reasonable, one should associate each leaf of the tree not with one character but with a chunk. Therefore, the datastructure suggested in &lt;a href="http://blog.sigfpe.com/2009/01/fast-incremental-regular-expression.html"&gt;Dan’s post&lt;/a&gt; (finger trees, described, for example, &lt;a href="http://apfelmus.nfshost.com/monoid-fingertree.html"&gt;by Heinrich Apfelmus&lt;/a&gt; and in the &lt;a href="http://www.soi.city.ac.uk/~ross/papers/FingerTree.html"&gt;original paper&lt;/a&gt;) is not a good fit: it assumes one node per element of the sequence (string).&lt;/p&gt; &lt;p&gt;We should choose one of the kinds of balanced trees satisfying our requirements. Let us list the requirements.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;It should be possible for the nodes to store the sum of their subtree with respect to an arbitrary additive measure;&lt;/li&gt; &lt;li&gt;It should be cheap to update this sum during rebalancing operations (and there should be few of them);&lt;/li&gt; &lt;li&gt;The tree’s height should be logarithmic in the number of elements;&lt;/li&gt; &lt;li&gt;Concatenation and splitting operations should be efficient.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;One of the simplest (in terms of implementation) but nevertheless quite efficient balanced trees are &lt;strong&gt;trees of constant height&lt;/strong&gt;, for example “2–3-trees” and “B-trees” (which are frequently used for DBMS indices).&lt;/p&gt; &lt;p&gt;In such trees, the length of the path from root to each leaf is the same, therefore (since each non-leaf node has at least 2 children) the height is logarithmic. Usually they are used for a quite different class of problems, namely that of representing sets and searching them, but they are also a perfect fit for representing sequences (strings). The basic idea is that a node is allowed to have &lt;span&gt;\(K\)&lt;/span&gt; to &lt;span&gt;\(2K-1\)&lt;/span&gt; children (for some &lt;span&gt;\(K\)&lt;/span&gt;) and most operations, such as insertion, splitting and concatenation, preserve this property; and when they don’t, a rebalancing occurs: either an overflown node is split into two, or two underflown nodes are merged into one.&lt;/p&gt; &lt;p&gt;We shall use a variation on this theme: 2–3 trees with chunks in leaves, where the chunk size may vary from &lt;span&gt;\(N\)&lt;/span&gt; to &lt;span&gt;\(2N-1\)&lt;/span&gt;, and all data is stored in leaves, not in nodes &lt;a id="id10" href="#f9"&gt;[9]&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;The next picture illustrates the implementations of all operations on such trees. Essentially two operations suffice: splitting and concatenation, all others can be expressed through them. When digesting the pictures, it is important to remember that we’re dealing with trees of constant height. Note also that the chunk size invariant may be broken, but only in the case where there are less than &lt;span&gt;\(N\)&lt;/span&gt; elements total: in this case the tree is represented by a single underflown chunk.&lt;/p&gt; &lt;div&gt; &lt;p&gt;&lt;img src="http://jkff.info/articles/ire/_images/rope-ops.png" alt="_images/rope-ops.png"&gt;&lt;/p&gt;&lt;p&gt;Rope operations&lt;/p&gt; &lt;/div&gt; &lt;p&gt;Let us explain these pictures briefly in the order in which they appear, top to bottom, left to right:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Concatenating a rope of height &lt;span&gt;\(h+1\)&lt;/span&gt; and a rope of heigh &lt;span&gt;\(h\)&lt;/span&gt; has two cases: when the first one is a 2-node and a 3-node respectively.&lt;/li&gt; &lt;li&gt;Concatenating a 2-node of height &lt;span&gt;\(h+1\)&lt;/span&gt;, which is a 2-node with children of height &lt;span&gt;\(h\)&lt;/span&gt; and another rope of height &lt;span&gt;\(h\)&lt;/span&gt; simply makes a 3-node.&lt;/li&gt; &lt;li&gt;Concatenating a 3-node of height &lt;span&gt;\(h+1\)&lt;/span&gt; with a node of height &lt;span&gt;\(h\)&lt;/span&gt; is the only case where a rope’s height increases: we put those 4 &lt;span&gt;\(h\)&lt;/span&gt;-high nodes into a 2-node of 2-nodes.&lt;/li&gt; &lt;li&gt;Concatenating a rope (2-node or 3-node) of height &lt;span&gt;\(h+1\)&lt;/span&gt; and a rope with height smaller than &lt;span&gt;\(h\)&lt;/span&gt; is reduced, through the associativity of concatenation, to recursively concatenating the last &lt;span&gt;\(h\)&lt;/span&gt;-node of the first rope with the second rope, and concatenating the remainder of the first rope with the result.&lt;/li&gt; &lt;li&gt;Concatenating two ropes of equal height is the simplest case: they make a 2-node.&lt;/li&gt; &lt;li&gt;Concatenating two chunks is the only slightly non-trivial case: if their total size is smaller than the maximum chunk size (i.e. &lt;span&gt;\(2N\)&lt;/span&gt;), then we simply concatenate the arrays and form a new chunk. If it’s bigger than &lt;span&gt;\(2N-1\)&lt;/span&gt; (though it can’t be bigger than &lt;span&gt;\(4N-2\)&lt;/span&gt;), then half of this number is between &lt;span&gt;\(N\)&lt;/span&gt; and &lt;span&gt;\(2N-1\)&lt;/span&gt;, which allows us to perfectly make a 2-node of halves of their concatenation.&lt;/li&gt; &lt;li&gt;Splitting a 2-node or 3-node is done by summing its 2 or 3 children until the predicate of the sum becomes true, and then descending into the child that caused this, because the split point must be somewhere inside it. Then we assemble the splitting result of the original node from its other children and parts of the split child. An example is drawn for the case where already the sum of the first child satisfies the predicate.&lt;/li&gt; &lt;li&gt;Splitting chunks is done in a most straightforward linear fashion.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;One of the most important aspects of this datastructure is its “purity”: operations on it do not change an existing instance but form a new one instead, i.e. they are functions in the mathematical sense.&lt;/p&gt; &lt;p&gt;We have already mentioned the importance of the decision to make the incremental interface “pure”, but now it is time to elaborate.&lt;/p&gt; &lt;div id="the-importance-of-purity"&gt; &lt;h3&gt;The importance of purity&lt;a title="Permalink to this headline" href="#the-importance-of-purity"&gt;¶&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;There are many advantages to using a pure approach to algorithms and datastructures, which have manifested themselves during the implementation of this program, particularly in the implementation of ropes.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Exceptional ease of implementation.&lt;/strong&gt; Essentially we can take the diagrams drawn on the picture above and translate them mechanically to code. Lack of mutability causes the code to be a lot simpler, and its correctness (or lack thereof) becomes more obvious, because the code doesn’t have the &lt;em&gt;time&lt;/em&gt; dimension anymore, and in order to understand how it works, one does not need to mentally trace a sequence of intermediate steps &lt;a id="id11" href="#f10"&gt;[10]&lt;/a&gt;: the code is just an enumeration of various cases where for each branch it is declared that “such and such input yields such and such output”. And indeed, to the author’s surprise, after the first successful compilation only 1 or 2 silly mistakes were fixed before the code passed all the tests.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Ease of debugging.&lt;/strong&gt; During debugging one often wants to look at the values of some expressions “in advance” in order to understand whether it is necessary to step into them, or their result is correct and the error is somewhere later in the code &lt;a id="id12" href="#f11"&gt;[11]&lt;/a&gt; When these expressions are “pure” (i.e., don’t have side effects), such an approach is possible. If side effects are present, then evaluating the expression in the debugger will change the program’s internal state and further debugging will be pointless.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Complete thread safety.&lt;/strong&gt; It is well known that most standard mutable datastructures do not allow concurrent reading and modification, and one must synchronize access to them in a multi-threaded program. However, it is often desirable to provide non-blocking read access, even if not the most current state of the datastructure will be read. There exist tricks allowing to do that for mutable datastructure (see, for example, the implementation of the &lt;a href="http://www.docjar.com/html/api/java/util/concurrent/ConcurrentHashMap.java.html"&gt;ConcurrentHashMap&lt;/a&gt; or the &lt;a href="http://www.docjar.com/html/api/java/util/concurrent/ConcurrentSkipListMap.java.html"&gt;ConcurrentSkipListMap&lt;/a&gt; classes in the Java standard library), but for immutable datastructures no tricks are necessary, because every instance can be safely read without worrying about it being concurrently modified: it cannot be modified at all.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;High performance and low memory consumption in certain scenarios&lt;/strong&gt;. There exist situations where it is useful to preserve the “original” version of a datastructure after applying an operation to it (for example, to preserve access to two ropes after computing their concatenation). Most importantly, these situations arise in backtracking enumeration algorithms and genetic algorithms (for example, when it is possible to combine two genomes in several ways, when one wants to keep both the genomes and the result of their crossover). Of course, one might just copy the original datastructure, but that might be very inefficient, especially if the structure is large. On the contrary, for pure datastructures there’s no need to copy, and we get a performance advantage. Also, as shown on the picture above, many operations on ropes allocate minuscule (constant or logarithmic) amounts of extra memory. The picture below shows the object graph for two ropes and their concatenation. It can be seen that most of the memory is used in a shared fashion, but each object is nevertheless accessible independently.&lt;/p&gt; &lt;div&gt; &lt;p&gt;&lt;img src="http://jkff.info/articles/ire/_images/rope-append-sharing.png" alt="_images/rope-append-sharing.png"&gt;&lt;/p&gt;&lt;p&gt;Sharing of memory after rope concatenation.&lt;/p&gt; &lt;/div&gt; &lt;p&gt;To even better explain how rope concatenation and splitting work, and why they are so easy to implement correctly, let us simply show the code.&lt;/p&gt; &lt;div&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;div&gt;&lt;pre&gt; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td&gt;&lt;div&gt;&lt;pre&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;left&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;right&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; &lt;span&gt;blockSize&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;factory&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;getBlockSize&lt;/span&gt;&lt;span&gt;();&lt;/span&gt; &lt;span&gt;Reducer&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;reducer&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;factory&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;getReducer&lt;/span&gt;&lt;span&gt;();&lt;/span&gt; &lt;span&gt;M&lt;/span&gt; &lt;span&gt;sum&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;reducer&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;compose&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;sum&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;right&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;sum&lt;/span&gt;&lt;span&gt;);&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;h&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;right&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;h&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;// Case "Two non-leaves of equal height"&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;h&lt;/span&gt; &lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;right&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;sum&lt;/span&gt;&lt;span&gt;);&lt;/span&gt; &lt;span&gt;// Case "Two leaves, both large enough to be children of a 2-node"&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(!&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;isUnderflownBlock&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span&gt;!&lt;/span&gt;&lt;span&gt;right&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;isUnderflownBlock&lt;/span&gt;&lt;span&gt;())&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;right&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;sum&lt;/span&gt;&lt;span&gt;);&lt;/span&gt; &lt;span&gt;// Case "Two leaf chunks, rebalancing needed"&lt;/span&gt; &lt;span&gt;String&lt;/span&gt; &lt;span&gt;bigBlock&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;block&lt;/span&gt; &lt;span&gt;+&lt;/span&gt; &lt;span&gt;right&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;block&lt;/span&gt;&lt;span&gt;;&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;bigBlock&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;length&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;&amp;lt;=&lt;/span&gt; &lt;span&gt;2&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; &lt;span&gt;blockSize&lt;/span&gt; &lt;span&gt;-&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;factory&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;bigBlock&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;sum&lt;/span&gt;&lt;span&gt;);&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;(&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;factory&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;bigBlock&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;substring&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;blockSize&lt;/span&gt;&lt;span&gt;)),&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;factory&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;bigBlock&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;substring&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;blockSize&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;bigBlock&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;length&lt;/span&gt;&lt;span&gt;())),&lt;/span&gt; &lt;span&gt;sum&lt;/span&gt;&lt;span&gt;);&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;span&gt;else&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;h&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;right&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;h&lt;/span&gt; &lt;span&gt;+&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;c&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;null&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;// 2-node of h + h -&amp;gt; 3-node&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;a&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;b&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;right&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;sum&lt;/span&gt;&lt;span&gt;);&lt;/span&gt; &lt;span&gt;else&lt;/span&gt; &lt;span&gt;// 3-node of h + h -&amp;gt; 2-node of 2-nodes&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;(&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;a&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;b&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;reducer&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;compose&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;a&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;sum&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;b&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;sum&lt;/span&gt;&lt;span&gt;)),&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;c&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;right&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;reducer&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;compose&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;c&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;sum&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;right&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;sum&lt;/span&gt;&lt;span&gt;)),&lt;/span&gt; &lt;span&gt;sum&lt;/span&gt;&lt;span&gt;);&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;span&gt;else&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;right&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;h&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;h&lt;/span&gt; &lt;span&gt;+&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;// Symmetrical&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;span&gt;else&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;h&lt;/span&gt; &lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;right&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;h&lt;/span&gt; &lt;span&gt;+&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;// Break the larger tree into nodes, regroup using associativity&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;c&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;null&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;a&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;b&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;right&lt;/span&gt;&lt;span&gt;));&lt;/span&gt; &lt;span&gt;else&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;a&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;b&lt;/span&gt;&lt;span&gt;)).&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;left&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;c&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;right&lt;/span&gt;&lt;span&gt;));&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;span&gt;else&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;// right.h &amp;gt; left.h + 1&lt;/span&gt; &lt;span&gt;// Symmetrical&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;/pre&gt;&lt;/div&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt; &lt;p&gt;And then the splitting code, with a slightly curious interface. This function splits a rope into two, given a monotone function on the string represented by the rope. Monotonicity is exploited by requiring to provide functions that compute &lt;span&gt;\(f(a+b)\)&lt;/span&gt; given &lt;span&gt;\(f(a)\)&lt;/span&gt; and &lt;span&gt;\(b\)&lt;/span&gt;, where &lt;span&gt;\(b\)&lt;/span&gt; is either a string (represented by a rope) or a single character (for finding the rising edge within a leaf-level rope chunk).&lt;/p&gt; &lt;div&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;div&gt;&lt;pre&gt; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td&gt;&lt;div&gt;&lt;pre&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;S&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;Pair&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;,&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span&gt;splitAfterRise&lt;/span&gt;&lt;span&gt;(&lt;/span&gt; &lt;span&gt;S&lt;/span&gt; &lt;span&gt;seed&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Function2&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;S&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;,&lt;/span&gt; &lt;span&gt;S&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;addChunk&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Function2&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;S&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Character&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;S&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;addChar&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Predicate&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;S&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;toBool&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;block&lt;/span&gt; &lt;span&gt;!=&lt;/span&gt; &lt;span&gt;null&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;// Simple linear search inside the chunk&lt;/span&gt; &lt;span&gt;S&lt;/span&gt; &lt;span&gt;s&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;seed&lt;/span&gt;&lt;span&gt;;&lt;/span&gt; &lt;span&gt;for&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;int&lt;/span&gt; &lt;span&gt;i&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;;&lt;/span&gt; &lt;span&gt;i&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;/span&gt; &lt;span&gt;block&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;length&lt;/span&gt;&lt;span&gt;();&lt;/span&gt; &lt;span&gt;++&lt;/span&gt;&lt;span&gt;i&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;toBool&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;isTrueFor&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;s&lt;/span&gt;&lt;span&gt;))&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;Pair&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;of&lt;/span&gt;&lt;span&gt;(&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;(&lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;factory&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;block&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;substring&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;i&lt;/span&gt;&lt;span&gt;)),&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;(&lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;factory&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;block&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;substring&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;i&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;block&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;length&lt;/span&gt;&lt;span&gt;())));&lt;/span&gt; &lt;span&gt;s&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;addChar&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;applyTo&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;s&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;block&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;charAt&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;i&lt;/span&gt;&lt;span&gt;));&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;toBool&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;isTrueFor&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;s&lt;/span&gt;&lt;span&gt;))&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;Pair&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;of&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;(&lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;factory&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;""&lt;/span&gt;&lt;span&gt;));&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;null&lt;/span&gt;&lt;span&gt;;&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;span&gt;else&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;// Start from seed&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;toBool&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;isTrueFor&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;seed&lt;/span&gt;&lt;span&gt;))&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;Pair&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;of&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;(&lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;factory&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;""&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;);&lt;/span&gt; &lt;span&gt;S&lt;/span&gt; &lt;span&gt;afterA&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;addChunk&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;applyTo&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;seed&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;a&lt;/span&gt;&lt;span&gt;);&lt;/span&gt; &lt;span&gt;// If adding node A made the condition true, descend into A&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;toBool&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;isTrueFor&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;afterA&lt;/span&gt;&lt;span&gt;))&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;// Split A and assemble result from b, c and parts of a&lt;/span&gt; &lt;span&gt;Pair&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;,&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span&gt;sa&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;a&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;splitAfterRise&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;seed&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;addChunk&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;addChar&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;toBool&lt;/span&gt;&lt;span&gt;);&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;c&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;null&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;?&lt;/span&gt; &lt;span&gt;Pair&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;of&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;sa&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;first&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;sa&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;second&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;b&lt;/span&gt;&lt;span&gt;))&lt;/span&gt; &lt;span&gt;:&lt;/span&gt; &lt;span&gt;Pair&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;of&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;sa&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;first&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;sa&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;second&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;b&lt;/span&gt;&lt;span&gt;).&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;c&lt;/span&gt;&lt;span&gt;));&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;span&gt;// Same for B&lt;/span&gt; &lt;span&gt;S&lt;/span&gt; &lt;span&gt;afterB&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;addChunk&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;applyTo&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;afterA&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;b&lt;/span&gt;&lt;span&gt;);&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;toBool&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;isTrueFor&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;afterB&lt;/span&gt;&lt;span&gt;))&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;Pair&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;,&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span&gt;sb&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;b&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;splitAfterRise&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;afterA&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;addChunk&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;addChar&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;toBool&lt;/span&gt;&lt;span&gt;);&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;c&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;null&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;?&lt;/span&gt; &lt;span&gt;Pair&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;of&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;a&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;sb&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;first&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;sb&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;second&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;:&lt;/span&gt; &lt;span&gt;Pair&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;of&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;a&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;sb&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;first&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;sb&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;second&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;c&lt;/span&gt;&lt;span&gt;));&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;span&gt;// Same for C, if this is a 3-node&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;c&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;null&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;null&lt;/span&gt;&lt;span&gt;;&lt;/span&gt; &lt;span&gt;S&lt;/span&gt; &lt;span&gt;afterC&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;addChunk&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;applyTo&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;afterB&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;c&lt;/span&gt;&lt;span&gt;);&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;toBool&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;isTrueFor&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;afterC&lt;/span&gt;&lt;span&gt;))&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;Pair&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;,&lt;/span&gt; &lt;span&gt;Rope&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span&gt;sc&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;c&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;splitAfterRise&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;afterB&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;addChunk&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;addChar&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;toBool&lt;/span&gt;&lt;span&gt;);&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;Pair&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;of&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;a&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;b&lt;/span&gt;&lt;span&gt;).&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;sc&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;first&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;sc&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;second&lt;/span&gt;&lt;span&gt;);&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;null&lt;/span&gt;&lt;span&gt;;&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;/pre&gt;&lt;/div&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id="appendix-2-monoids"&gt; &lt;h2&gt;Appendix 2: Monoids&lt;a title="Permalink to this headline" href="#appendix-2-monoids"&gt;¶&lt;/a&gt;&lt;/h2&gt; &lt;p&gt;Remember how, given a finite automaton, we can associate every string with a “transition function” with respect to this automaton, and when concatenating two strings their transition functions are composed (let us denote the composition of &lt;span&gt;\(f_1\)&lt;/span&gt; and &lt;span&gt;\(f_2\)&lt;/span&gt; as &lt;span&gt;\(f_1 \circ f_2\)&lt;/span&gt;.&lt;/p&gt; &lt;p&gt;Composition of transition functions (similarly to concatenation of strings) has a few simple and useful properties:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;For any transition functions &lt;span&gt;\(f\)&lt;/span&gt;, &lt;span&gt;\(g\)&lt;/span&gt; and &lt;span&gt;\(h\)&lt;/span&gt; holds &lt;span&gt;\(f \circ (g \circ h) = (f \circ g) \circ h\)&lt;/span&gt;. This property of the “&lt;span&gt;\(\circ\)&lt;/span&gt; ” operator is called “associativity”.&lt;/li&gt; &lt;li&gt;There exists a special transition function &lt;span&gt;\(u\)&lt;/span&gt; that maps every state of the automaton to itself. It is called the “unit” of the “ &lt;span&gt;\(\circ\)&lt;/span&gt; ” operator because, just as &lt;span&gt;\(1 ⋅ x = x ⋅ 1 = x\)&lt;/span&gt; holds for the multiplication operator, for &lt;span&gt;\(\circ\)&lt;/span&gt; holds &lt;span&gt;\(u \circ f = f \circ u = f\)&lt;/span&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;These two properties allow us to say that transition functions of a finite automaton form a &lt;em&gt;monoid&lt;/em&gt;.&lt;/p&gt; &lt;p&gt;More precisely, it is said that the set &lt;span&gt;\(M\)&lt;/span&gt;, the operation &lt;span&gt;\(⊗\)&lt;/span&gt; and the element &lt;span&gt;\(u ∈ M\)&lt;/span&gt; (called the “unit” of this operation) form a monoid if the aforementioned two properties hold.&lt;/p&gt; &lt;p&gt;Since the notion of a monoid is so simple and general, it is unsurprising that upon a close look at the “casual” objects in programming one may see dozens of monoids. Some of them are listed in the table below. Some applications of monoids to programming are also listed in Dan Piponi’s article &lt;a href="http://blog.sigfpe.com/2009/01/haskell-monoids-and-their-uses.html"&gt;Monoids and their uses&lt;/a&gt;.&lt;/p&gt; &lt;table&gt; &lt;caption&gt;Monoids&lt;/caption&gt; &lt;colgroup&gt; &lt;col width="20%"&gt; &lt;col width="20%"&gt; &lt;col width="20%"&gt; &lt;col width="40%"&gt; &lt;/colgroup&gt; &lt;thead&gt; &lt;tr&gt;&lt;th&gt;The set &lt;span&gt;\(M\)&lt;/span&gt;&lt;/th&gt; &lt;th&gt;Operation ⊗&lt;/th&gt; &lt;th&gt;Unit &lt;span&gt;\(u\)&lt;/span&gt;&lt;/th&gt; &lt;th&gt;Comment&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Numbers&lt;/td&gt; &lt;td&gt;+&lt;/td&gt; &lt;td&gt;0&lt;/td&gt; &lt;td&gt;Natural, integer, real, complex, quaternions…&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Numbers&lt;/td&gt; &lt;td&gt;×&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&amp;nbsp;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Integers&lt;/td&gt; &lt;td&gt;LCM&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&amp;nbsp;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Polynomials&lt;/td&gt; &lt;td&gt;LCM&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;&amp;nbsp;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Numbers, strings…&lt;/td&gt; &lt;td&gt;MIN, MAX&lt;/td&gt; &lt;td&gt;Maximal and minimal element&lt;/td&gt; &lt;td&gt;&amp;nbsp;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Booleans&lt;/td&gt; &lt;td&gt;AND&lt;/td&gt; &lt;td&gt;TRUE&lt;/td&gt; &lt;td&gt;&amp;nbsp;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Booleans&lt;/td&gt; &lt;td&gt;OR&lt;/td&gt; &lt;td&gt;FALSE&lt;/td&gt; &lt;td&gt;&amp;nbsp;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Matrices&lt;/td&gt; &lt;td&gt;+&lt;/td&gt; &lt;td&gt;0&lt;/td&gt; &lt;td&gt;Over numbers (+, ×), over numbers (+, MIN), over booleans (OR, AND), …&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Sets&lt;/td&gt; &lt;td&gt;Union&lt;/td&gt; &lt;td&gt;Empty set&lt;/td&gt; &lt;td&gt;&amp;nbsp;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Sets&lt;/td&gt; &lt;td&gt;Intersection&lt;/td&gt; &lt;td&gt;Complete set&lt;/td&gt; &lt;td&gt;Restricted to subsets of the “complete” set&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Lists, strings…&lt;/td&gt; &lt;td&gt;Concatenation&lt;/td&gt; &lt;td&gt;Empty sequence&lt;/td&gt; &lt;td&gt;&amp;nbsp;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Dictionaries&lt;/td&gt; &lt;td&gt;Union&lt;/td&gt; &lt;td&gt;Empty dictionary&lt;/td&gt; &lt;td&gt;“Conflicts” are resolved in another monoid: &lt;span&gt;\((dic_1 ⊗ dic_2)[key] = dic_1[key] ⊕ dic_2[key]\)&lt;/span&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Functions of type A → B&lt;/td&gt; &lt;td&gt;&lt;span&gt;\((f ⊗ g)(a)=f(a) ⊕ g(a)\)&lt;/span&gt;&lt;/td&gt; &lt;td&gt;&lt;span&gt;\(e(a) = e_B\)&lt;/span&gt;&lt;/td&gt; &lt;td&gt;&lt;span&gt;\((B,⊕,e_B)\)&lt;/span&gt; is a monoid&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Permutations&lt;/td&gt; &lt;td&gt;Multiplication&lt;/td&gt; &lt;td&gt;Identity permutation&lt;/td&gt; &lt;td&gt;&amp;nbsp;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Functions&lt;/td&gt; &lt;td&gt;Composition&lt;/td&gt; &lt;td&gt;Identity function&lt;/td&gt; &lt;td&gt;&amp;nbsp;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Tuples &lt;span&gt;\((x,y)\)&lt;/span&gt; where &lt;span&gt;\(x ∈ X, y ∈ Y\)&lt;/span&gt;&lt;/td&gt; &lt;td&gt;&lt;span&gt;\((x_1, y_1) ⊗ (x_2, y_2) = (x_1 ⊕_X x_2, y_1 ⊕_Y y_2)\)&lt;/span&gt;&lt;/td&gt; &lt;td&gt;&lt;span&gt;\((u_X, u_Y)\)&lt;/span&gt;&lt;/td&gt; &lt;td&gt;If &lt;span&gt;\((X, ⊕_X, u_X)\)&lt;/span&gt; and &lt;span&gt;\((Y, ⊕_Y, u_Y)\)&lt;/span&gt; form monoids&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt;&lt;td&gt;…&lt;/td&gt; &lt;td&gt;…&lt;/td&gt; &lt;td&gt;…&lt;/td&gt; &lt;td&gt;&amp;nbsp;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;table id="f1"&gt; &lt;colgroup&gt;&lt;col&gt;&lt;col&gt;&lt;/colgroup&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;&lt;a href="#id1"&gt;[1]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Dan Piponi is a specialist on computer graphics, having participated in the creation of all three “Matrices”, “Star Trek” and some other movies.&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;table id="f2"&gt; &lt;colgroup&gt;&lt;col&gt;&lt;col&gt;&lt;/colgroup&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;&lt;a href="#id2"&gt;[2]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;There exist several algorithms for determinization, described, for example, in the article “An &lt;span&gt;\(O(n log n)\)&lt;/span&gt; algorithm for minimizing the states in a finite automaton” by Hopcroft or see the Brzozowski’s algorithm.&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;table id="f3"&gt; &lt;colgroup&gt;&lt;col&gt;&lt;col&gt;&lt;/colgroup&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;&lt;a href="#id3"&gt;[3]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;For example, any deterministic automaton for an expression of the form &lt;tt&gt;&lt;span&gt;(0|(01*)(01*)(01*)…&lt;/span&gt; &lt;span&gt;0)*&lt;/span&gt;&lt;/tt&gt; will have size &lt;span&gt;\(O(2^n)\)&lt;/span&gt;, where &lt;span&gt;\(n\)&lt;/span&gt; is the number of repetitions of &lt;tt&gt;&lt;span&gt;(01*)&lt;/span&gt;&lt;/tt&gt;.&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;table id="f4"&gt; &lt;colgroup&gt;&lt;col&gt;&lt;col&gt;&lt;/colgroup&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;&lt;a href="#id4"&gt;[4]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;This idea has been taken from the article &lt;a href="http://swtch.com/~rsc/regexp/regexp3.html"&gt;Regular Expression Matching in the Wild&lt;/a&gt; by Russ Cox and is used in his &lt;tt&gt;&lt;span&gt;re2&lt;/span&gt;&lt;/tt&gt; engine.&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;table id="f5"&gt; &lt;colgroup&gt;&lt;col&gt;&lt;col&gt;&lt;/colgroup&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;&lt;a href="#id5"&gt;[5]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;There’s a similar situation in graphics programming: coordinate transformations are also represented not with arbitrary functions but with matrices of numbers that can be efficiently multiplied (composed).&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;table id="f6"&gt; &lt;colgroup&gt;&lt;col&gt;&lt;col&gt;&lt;/colgroup&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;&lt;a href="#id6"&gt;[6]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Actually we don’t need deterministic automata in the final program; they were only used during testing and encouraged creating the automaton abstraction, of which these two are particular cases.&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;table id="f7"&gt; &lt;colgroup&gt;&lt;col&gt;&lt;col&gt;&lt;/colgroup&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;&lt;a href="#id7"&gt;[7]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Curiously, composition of such transformations is then also captured by multiplication of such boolean matrices.&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;table id="f8"&gt; &lt;colgroup&gt;&lt;col&gt;&lt;col&gt;&lt;/colgroup&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;&lt;a href="#id9"&gt;[8]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;In the early stages of development there was a problem where computing the transition function for a chunk of &lt;span&gt;\(N\)&lt;/span&gt; characters would require &lt;span&gt;\(N\)&lt;/span&gt; intermediate matrices, but this problem was easily solved with a small API change without sacrificing its purity.&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;table id="f9"&gt; &lt;colgroup&gt;&lt;col&gt;&lt;col&gt;&lt;/colgroup&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;&lt;a href="#id10"&gt;[9]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;A similar datastructure is used for a similar purpose in the “&lt;tt&gt;&lt;span&gt;Data.Sequence&lt;/span&gt;&lt;/tt&gt;” module in the Haskell standard library.&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;table id="f10"&gt; &lt;colgroup&gt;&lt;col&gt;&lt;col&gt;&lt;/colgroup&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;&lt;a href="#id11"&gt;[10]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;It is instructive to look, for comparison, at some implementation of rebalancing in mutable red-black trees.&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;table id="f11"&gt; &lt;colgroup&gt;&lt;col&gt;&lt;col&gt;&lt;/colgroup&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;&lt;a href="#id12"&gt;[11]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;However, it’s not a secret to anyone that Real Programmers don’t use debuggers: unfortunately, they won’t be able to appreciate this particular advantage.&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="http://jkff.info/articles/ire/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Wed, 22 Apr 2020 19:37:29 UT
      </pubDate>
      <guid>
        http://jkff.info/articles/ire/
      </guid>
    </item>
    <item>
      <title>
        On the shoulders of the giants | A learning journal
      </title>
      <link>
        https://www.lpalmieri.com/posts/2020-03-08-on-the-shoulders-of-the-giants/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;section&gt; &lt;article&gt; &lt;ul id="frontmatter"&gt; &lt;li&gt; &lt;time datetime="2020-03-08T01:05:57.74Z"&gt;March 08, 2020&lt;/time&gt; &lt;/li&gt; &lt;span&gt;&lt;/span&gt; &lt;li&gt; 2062 words &lt;/li&gt; &lt;span&gt;&lt;/span&gt; &lt;li&gt; 11 min &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;img alt="books" src="https://media.giphy.com/media/VcizxCUIgaKpa/giphy.gif"&gt;&lt;/p&gt; &lt;p&gt;My journey in the world of software has been quite brief.&lt;/p&gt; &lt;p&gt;I joined the industry roughly three years ago, as a not-yet-graduated mathematician converted to ML practioner. It took me another two years to find myself in a position where building software was my main occupation.&lt;/p&gt; &lt;p&gt;I owe loads to many awesome individuals I have met and worked with along this short walk of life.&lt;br&gt; I owe loads as well to many others who I will probably never meet - the authors of the books I fed upon along the way.&lt;/p&gt; &lt;p&gt;First-hand experience is extremely powerful, nonetheless time is finite.&lt;br&gt; Books gave me a chance to tap into the compressed mastery of other practiotioners, a mastery built over thousands and thousands of hours of work. If you could only absorb 10% of that knowledge by reading it would still be a bargain.&lt;/p&gt; &lt;p&gt;As I find myself moving from the mentee to the mentor seat in some of my professional relationships, I do happen to share more and more often lists of titles that I found useful on my own journey. &lt;/p&gt; &lt;p&gt;Publishing this list as a public blog post will likely increase its reach and prove useful to many others.&lt;/p&gt; &lt;p&gt;&lt;em&gt;&lt;strong&gt;Themes&lt;/strong&gt;&lt;/em&gt;:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://lpalmieri.com/posts/2020-03-08-on-the-shoulders-of-the-giants/#architecture"&gt;Architecture&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://lpalmieri.com/posts/2020-03-08-on-the-shoulders-of-the-giants/#design"&gt;Design&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://lpalmieri.com/posts/2020-03-08-on-the-shoulders-of-the-giants/#testing"&gt;Testing&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://lpalmieri.com/posts/2020-03-08-on-the-shoulders-of-the-giants/#epic"&gt;Epic&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://lpalmieri.com/posts/2020-03-08-on-the-shoulders-of-the-giants/#software-development-lifecycle"&gt;Software development lifecycle&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://lpalmieri.com/posts/2020-03-08-on-the-shoulders-of-the-giants/#management-frameworks"&gt;Management frameworks&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h2 id="architecture"&gt;Architecture&lt;/h2&gt; &lt;p&gt;&lt;img title="Designing Data-Intensive Applications" alt="Designing Data-Intensive Applications" src="https://www.lpalmieri.com/image/uploads/ddia.png"&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://www.amazon.co.uk/Designing-Data-Intensive-Applications-Reliable-Maintainable/dp/1449373321"&gt;Designing Data-Intensive Applications: The Big Ideas Behind Reliable, Scalable, and Maintainable Systems&lt;/a&gt; &lt;em&gt;by Martin Kleppmann&lt;/em&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;This book is &lt;strong&gt;dense&lt;/strong&gt;.&lt;br&gt; It's packed with foundational material and it manages to combine a first-principles approach with a focus on the impact of those decisions on the engineering choices behind real-world large-scale distributed systems.&lt;br&gt; I do go back to it from time to time, to re-read a chapter, re-study a set of concepts.&lt;br&gt; I just love it.&lt;/p&gt; &lt;p&gt;&lt;img title="Cloud Native Patterns" alt="Cloud Native Patterns" src="https://www.lpalmieri.com/image/uploads/davis-cnp-hi.png"&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://www.amazon.com/Cloud-Native-Designing-change-tolerant-software/dp/1617294292"&gt;Cloud Native Patterns: Designing change-tolerant software&lt;/a&gt; &lt;em&gt;by Cornelia Davis&lt;/em&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;I never believed the &lt;em&gt;&lt;a href="https://en.wikipedia.org/wiki/Digital_native"&gt;digital native&lt;/a&gt;&lt;/em&gt; narrative, but it's indeed true that as a software engineer I am Cloud native. All the systems I have been working with have always been designed, hosted and operated in the Cloud since day 0.&lt;br&gt; Cornelia Davis did a very good job at putting together a primer on the patterns and techniques that you should have in your toolbox when designing increasingly-complex Cloud native applications.&lt;br&gt; I recommend it often as a first read on real-world distributed systems.&lt;/p&gt; &lt;h2 id="design"&gt;Design&lt;/h2&gt; &lt;p&gt;&lt;img title="DDD" alt="DDD" src="https://www.lpalmieri.com/image/uploads/ddd.jpeg"&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://www.amazon.co.uk/Domain-Driven-Design-Tackling-Complexity-Software/dp/0321125215"&gt;Domain-Driven Design: Tackling Complexity in the Heart of Software&lt;/a&gt; &lt;em&gt;by Eric Evans&lt;/em&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;The&lt;/strong&gt; book on DDD, also known as &lt;em&gt;The &lt;strong&gt;Big&lt;/strong&gt; Blue Book&lt;/em&gt;.&lt;br&gt; It's long but it covers an insane amount of material: if you are in the business of &lt;a href="https://docs.google.com/presentation/d/1r5CsiHwqABOTsrN5Dlbf4gCyhcL46NTv7qv9m5mBv-o/edit?usp=sharing"&gt;writing enterprise software&lt;/a&gt;, it's a must-read.&lt;br&gt; Translating the rules and the mental model of a complex business domain into sofware is indeed the core of the challenge when writing enterprise software.&lt;br&gt; The techniques and the terminology introduced by Evans will pay dividends as the complexity of the domain you are tackling and the organisation you are working in increases. Different people have suggested me a shorter introduction to the subject, &lt;a href="https://www.amazon.co.uk/Domain-Driven-Design-Distilled-Vaughn-Vernon/dp/0134434420"&gt;Domain-Driven Design Distilled&lt;/a&gt; by Vaughn Vernon, but I haven't read it first hand.&lt;/p&gt; &lt;p&gt;&lt;img title="Domain modelling made functional" alt="Domain modelling made functional" src="https://www.lpalmieri.com/image/uploads/dmmf.jpg"&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://www.amazon.co.uk/Domain-Modeling-Made-Functional-Domain-Driven/dp/1680502549"&gt;Domain Modeling Made Functional&lt;/a&gt; &lt;em&gt;by Scott Wlaschin&lt;/em&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;I discovered this book looking up the author from &lt;a href="https://www.youtube.com/watch?v=PLFl95c-IiU"&gt;a talk of his&lt;/a&gt; - I loved the talk and I loved the book.&lt;br&gt; It's on its own a good introduction to DDD as well as to the broader topic of &lt;em&gt;type-driven development&lt;/em&gt;. &lt;/p&gt; &lt;p&gt;In a nutshell, we can leverage the type system to represent the constraints of our domain, making incorrect state difficult or impossible to represent.&lt;/p&gt; &lt;p&gt;The book presents the idea in the context of functional programming, but it's indeed viable even with non-strictly-functional programming languages as long as they have a rich typesystem (e.g. Rust).&lt;br&gt; If you find the idea interesting, the &lt;a href="https://fsharpforfunandprofit.com/"&gt;author's website&lt;/a&gt; is a gold mine.&lt;br&gt; If you want a blog-sized introduction to the topic, check &lt;em&gt;&lt;a href="https://lexi-lambda.github.io/blog/2019/11/05/parse-don-t-validate/"&gt;Parse, don't validate&lt;/a&gt;&lt;/em&gt; by Alexis King.&lt;/p&gt; &lt;h2 id="testing"&gt;Testing&lt;/h2&gt; &lt;p&gt;&lt;img title="TDD by example" alt="TDD by example" src="https://www.lpalmieri.com/image/uploads/tdd-by-example.jpg"&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://www.amazon.co.uk/Test-Driven-Development-Addison-Wesley-Signature/dp/0321146530"&gt;Test Driven Development: by Example&lt;/a&gt; &lt;em&gt;by Kent Beck&lt;/em&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;There is a general appreciation in our industry around Test Driven Development. Nonetheless, I haven't met many practioners who actually run it by the book, for all sorts of reasons.&lt;br&gt; Before taking a stance on the matter I wanted to see it done &lt;em&gt;religiously&lt;/em&gt;. Short on neighbours, I turned to the author himself: Kent Beck is the creator of XP (&lt;a href="https://en.wikipedia.org/wiki/Extreme_programming"&gt;&lt;strong&gt;X&lt;/strong&gt;treme &lt;strong&gt;P&lt;/strong&gt;rogramming&lt;/a&gt;), one the main voices of TDD as well as one of the authours of the &lt;a href="https://agilemanifesto.org/"&gt;Agile manifesto&lt;/a&gt;.&lt;br&gt; The book is nothing more nothing less than a long pair programming session with him, as he works his way using TDD through a problem (i.e. writing a testing framework - there is a meta element at play here).&lt;br&gt; You are an observer - as a reader you don't get to play &lt;a href="https://wiki.c2.com/?PairProgrammingPingPongPattern"&gt;ping-pong&lt;/a&gt; with him; yet, it's worth reading to actually &lt;em&gt;see&lt;/em&gt; what TDD looks and feels like.&lt;/p&gt; &lt;p&gt;&lt;img title="Working effectively with legacy code" alt="Working effectively with legacy code" src="https://www.lpalmieri.com/image/uploads/working-with-legacy-code.jpg"&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://www.amazon.co.uk/Working-Effectively-Legacy-Michael-Feathers/dp/0131177052"&gt;Working Effectively with Legacy Code&lt;/a&gt; &lt;em&gt;by Michael Feathers&lt;/em&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;I have come to appreciate that software is more often read than written. As it often goes, the author has generally moved on (either in another area of the business or somewhere else entirely). Yet the system keeps running in production, hopefully producing value, and it needs to be maintained.&lt;/p&gt; &lt;p&gt;As it happens, not all of its behaviour is covered by automated tests - it's &lt;em&gt;legacy&lt;/em&gt; code. And most engineers will spend most of their careers working on such code (that includes code they wrote themselves six or twelve months earlier). I spent a fair share of my short software career doing so already.&lt;/p&gt; &lt;p&gt;Feathers put together a series of useful techniques to tame the beast - documenting existing behaviour using tests in order to make it possible to evolve the system itself to satisfy new requirements.&lt;br&gt; Extremely useful as a reference when working on gnarly legacy beasts.&lt;/p&gt; &lt;p&gt;&lt;img title="xUnit Test Patterns" alt="xUnit Test Patterns" src="https://www.lpalmieri.com/image/uploads/xunit-test-patterns.jpg"&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://www.amazon.co.uk/xUnit-Test-Patterns-Refactoring-Signature/dp/0131495054"&gt;xUnit Test Patterns: Refactoring Test Code&lt;/a&gt; &lt;em&gt;by Gerard Meszaros&lt;/em&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;As you approach a new project armed with the two books above, you will try to stick to a disciplined testing approach.&lt;br&gt; I sure did when given the chance to start a greenfield service.&lt;br&gt; After a while, our test coverage started to decrease: new code was less thoroughly tested than the code we wrote at the very beginning of the project. Did we do it on purpose?&lt;br&gt; No - if you asked, the whole team would have probably re-stated their faith in the importance of testing. Nonetheless, it was happening.&lt;br&gt; The truth was that our tests had started to slow us a down - it was getting cumbersome to write and maintain them as the codebase evolved. As a result, we were writing less and less tests, without acknowledging it.&lt;br&gt; If we kept at it without changing direction, we would have probably joined the faction of those who see tests as a hindrance more than an asset. Instead, I found this book and a significant refactor of our test suite brought us back to our previous development speed without compromising on our testing practices.&lt;/p&gt; &lt;p&gt;The book is a bit dated, but it's a useful reference for a bunch of important techniques to keep the development tax of your comprehensive test suite under control. It was indeed instrumental for ours.&lt;br&gt; I don't suggest to read it cover to cover - it's quite repetitive and way too long.&lt;/p&gt; &lt;h2 id="epic"&gt;Epic&lt;/h2&gt; &lt;p&gt;&lt;img title="The Soul of a New Machine" alt="The Soul of a New Machine" src="https://www.lpalmieri.com/image/uploads/soul.png"&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://www.amazon.co.uk/Soul-New-Machine-Tracy-Kidder/dp/0316491977"&gt;The Soul of A New Machine&lt;/a&gt; &lt;em&gt;by Tracy Kidder&lt;/em&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;A novel - what is it doing here?&lt;br&gt; Well, it takes quite the effort to digest the material I linked so far. Why bother? What is it that makes it worthwhile to go through all these hurdles? &lt;em&gt;(Tech money aside, perfectly legit motivation)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;&lt;em&gt;The Soul of A New Machine&lt;/em&gt; resonates.&lt;br&gt; With the part of me that loved reading about Wiles' proof of the &lt;a href="https://en.wikipedia.org/wiki/Fermat%27s_Last_Theorem_(book)"&gt;Fermat's Last Theorem&lt;/a&gt;.&lt;br&gt; With that part of me that is fascinated by people losing themselves in the quest to solve problems that are bigger than them, almost all-consuming.&lt;/p&gt; &lt;p&gt;On that note, I can't avoid recommending &lt;a href="http://dtrace.org/blogs/bmc/2019/02/10/reflecting-on-the-soul-of-a-new-machine/"&gt;Bryan Cantrill's review&lt;/a&gt; of the &lt;em&gt;The Soul of A New Machine&lt;/em&gt; with almost the same fervor of my recommendation for the book itself.&lt;/p&gt; &lt;h2 id="software-development-lifecycle"&gt;Software development lifecycle&lt;/h2&gt; &lt;p&gt;&lt;img title="CD" alt="CD" src="https://www.lpalmieri.com/image/uploads/cd.jpg"&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://www.amazon.co.uk/Continuous-Delivery-Deployment-Automation-Addison-Wesley/dp/0321601912"&gt;Continuous Delivery: Reliable Software Releases through Build, Test, and Deployment Automation&lt;/a&gt; &lt;em&gt;by Jez Humble and David Farley&lt;/em&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;A deep-dive into the world of &lt;strong&gt;CD&lt;/strong&gt;, &lt;strong&gt;C&lt;/strong&gt;ontinuous &lt;strong&gt;D&lt;/strong&gt;elivery.&lt;br&gt; The book is 10 years old, but it has withstood the test of time: technologies might have changed, but the principles and the challenges highlighted here are still relevant when designing (and automating) the release pipelines of contemporary systems.&lt;/p&gt; &lt;p&gt;&lt;img title="Accelerate" alt="Accelerate" src="https://www.lpalmieri.com/image/uploads/accelerate.jpg"&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://www.amazon.co.uk/Accelerate-Software-Performing-Technology-Organizations/dp/1942788339"&gt;Accelerate: The Science of Lean Software and Devops&lt;/a&gt; &lt;em&gt;by Nicole Fosgren, Jez Humble and Gene Kim&lt;/em&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Why should you go through all the trouble of implementing what the previous book details?&lt;br&gt; &lt;em&gt;Accelerate&lt;/em&gt; doesn't necessarily introduce a set of revolutionary metholodogies in software delivery, but it provides solid datapoints and robust research &lt;strong&gt;proving&lt;/strong&gt; that some of those methodologies (Lean, DevOps, etc.) have indeed a &lt;strong&gt;measurable impact&lt;/strong&gt; on the &lt;strong&gt;business&lt;/strong&gt; performance of an organisation.&lt;br&gt; The &lt;a href="https://www.thoughtworks.com/radar/techniques/four-key-metrics"&gt;four key metrics&lt;/a&gt; are extremely useful to measure the health of an engineering team.&lt;/p&gt; &lt;p&gt;The yearly &lt;em&gt;&lt;a href="https://www.devops-research.com/research.html"&gt;State of DevOps&lt;/a&gt;&lt;/em&gt; report complements &lt;em&gt;Accelerate&lt;/em&gt; and provides updates on the state of the industry.&lt;/p&gt; &lt;h2 id="management-frameworks"&gt;Management frameworks&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://www.amazon.co.uk/Turn-Ship-Around-Building-Breaking/dp/0241250943"&gt;Turn The Ship Around!&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.amazon.co.uk/Manager%60s-Path-Camille-Fournier/dp/1491973897"&gt;The Manager's Path&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.amazon.co.uk/Elegant-Puzzle-Systems-Engineering-Management-ebook/dp/B07QYCHJ7V"&gt;An Elegant Puzzle: Systems of Engineering Management&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;There is more to software than code.&lt;br&gt; Code is often the easy bit - people are the tough nut to crack.&lt;/p&gt; &lt;p&gt;Core skills and leadership are often neglected when describing the minimal toolset needed by a software engineer to be effective.&lt;br&gt; While competency is key, it's being capable to work with others that makes it or breaks it.&lt;br&gt; The jury is out on the existence of 10x engineers, but I am sure of the existence of 10x (and 0.1x!) teams.&lt;/p&gt; &lt;p&gt;It goes beyond the individuals - it's a mix of practices, processes, vision, values.&lt;br&gt; You can freestyle it as a team of 5 or 6, but it will soon spiral out of control when the organisation grows.&lt;/p&gt; &lt;p&gt;These three books are the one I found the most interesting among the many I touched in the "management" section - they are principled, clear-written and insightful. They deserve a spot in an engineering curriculum as much as the fundamentals of testing and domain design.&lt;/p&gt; &lt;p&gt;&lt;em&gt;Turn The Ship Around!&lt;/em&gt;, in particular, is a written account of the wonders of decentralised decision-making and high mutual-trust in an environment used to a strict &lt;em&gt;Command/Control&lt;/em&gt; management-style (the US Navy!).&lt;/p&gt; &lt;p&gt;Empowering every single individual to channel their best version of themselves should be the goal of every (engineering) organisation.&lt;/p&gt; &lt;/article&gt; &lt;/section&gt;&lt;/div&gt;&lt;a href="https://www.lpalmieri.com/posts/2020-03-08-on-the-shoulders-of-the-giants/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Thu, 23 Apr 2020 10:11:58 UT
      </pubDate>
      <guid>
        https://www.lpalmieri.com/posts/2020-03-08-on-the-shoulders-of-the-giants/
      </guid>
    </item>
    <item>
      <title>
        Deep Learning
      </title>
      <link>
        https://www.deeplearningbook.org/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;h2&gt;&lt;a href="https://www.deeplearningbook.org/front_matter.pdf"&gt;Deep Learning&lt;/a&gt;&lt;/h2&gt; &lt;h2&gt;An MIT Press book&lt;/h2&gt; &lt;h3&gt;Ian Goodfellow and Yoshua Bengio and Aaron Courville&lt;/h3&gt; &lt;p&gt; &lt;center&gt; &lt;a href="https://www.deeplearningbook.org/exercises.html"&gt;Exercises&lt;/a&gt; &amp;nbsp; &lt;a href="https://www.deeplearningbook.org/lecture_slides.html"&gt;Lectures&lt;/a&gt; &amp;nbsp; &lt;a href="https://www.deeplearningbook.org/external.html"&gt;External Links&lt;/a&gt; &amp;nbsp; &lt;/center&gt; &lt;/p&gt; &lt;p&gt; The Deep Learning textbook is a resource intended to help students and practitioners enter the field of machine learning in general and deep learning in particular. The online version of the book is now complete and will remain available online for free. &lt;/p&gt; &lt;p&gt;The deep learning textbook can now be ordered on &lt;a href="https://www.amazon.com/Deep-Learning-Adaptive-Computation-Machine/dp/0262035618/ref=sr_1_1?ie=UTF8&amp;amp;qid=1472485235&amp;amp;sr=8-1&amp;amp;keywords=deep+learning+book"&gt;Amazon&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;For up to date announcements, join our &lt;a href="https://groups.google.com/forum/#!forum/deeplearningbook"&gt;mailing list&lt;/a&gt;. &lt;/p&gt; &lt;h2&gt;Citing the book&lt;/h2&gt; To cite this book, please use this bibtex entry: &lt;tt&gt; &lt;pre&gt;@book{Goodfellow-et-al-2016, title={Deep Learning}, author={Ian Goodfellow and Yoshua Bengio and Aaron Courville}, publisher={MIT Press}, note={\url{http://www.deeplearningbook.org}}, year={2016} } &lt;/pre&gt; &lt;/tt&gt; &lt;p&gt; To write your own document using our LaTeX style, math notation, or to copy our notation page, download our &lt;a href="https://github.com/goodfeli/dlbook_notation"&gt;template&lt;/a&gt; files. &lt;/p&gt; &lt;p&gt; &lt;a href="https://docs.google.com/document/d/1ABlp7FluwZ0B82_fjNOFVQ2uOZkfuF8elbofhZmNXag/edit?usp=sharing"&gt;Errata in published editions&lt;/a&gt; &lt;/p&gt; &lt;h2&gt;Deep Learning&lt;/h2&gt; &lt;ul&gt; &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/TOC.html"&gt;Table of Contents&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.deeplearningbook.org/contents/acknowledgements.html"&gt;Acknowledgements&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.deeplearningbook.org/contents/notation.html"&gt;Notation&lt;/a&gt;&lt;/li&gt; &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/intro.html"&gt;1 Introduction&lt;/a&gt;&lt;/li&gt; &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/part_basics.html"&gt;Part I: Applied Math and Machine Learning Basics&lt;/a&gt;&lt;/li&gt; &lt;ul&gt; &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/linear_algebra.html"&gt;2 Linear Algebra&lt;/a&gt;&lt;/li&gt; &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/prob.html"&gt;3 Probability and Information Theory&lt;/a&gt;&lt;/li&gt; &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/numerical.html"&gt;4 Numerical Computation&lt;/a&gt;&lt;/li&gt; &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/ml.html"&gt;5 Machine Learning Basics&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/part_practical.html"&gt;Part II: Modern Practical Deep Networks&lt;/a&gt;&lt;/li&gt; &lt;ul&gt; &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/mlp.html"&gt;6 Deep Feedforward Networks&lt;/a&gt;&lt;/li&gt; &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/regularization.html"&gt;7 Regularization for Deep Learning&lt;/a&gt;&lt;/li&gt; &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/optimization.html"&gt;8 Optimization for Training Deep Models&lt;/a&gt;&lt;/li&gt; &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/convnets.html"&gt;9 Convolutional Networks&lt;/a&gt;&lt;/li&gt; &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/rnn.html"&gt;10 Sequence Modeling: Recurrent and Recursive Nets&lt;/a&gt;&lt;/li&gt; &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/guidelines.html"&gt;11 Practical Methodology&lt;/a&gt;&lt;/li&gt; &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/applications.html"&gt;12 Applications&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/part_research.html"&gt;Part III: Deep Learning Research&lt;/a&gt;&lt;/li&gt; &lt;ul&gt; &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/linear_factors.html"&gt;13 Linear Factor Models&lt;/a&gt;&lt;/li&gt; &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/autoencoders.html"&gt;14 Autoencoders&lt;/a&gt;&lt;/li&gt; &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/representation.html"&gt;15 Representation Learning&lt;/a&gt;&lt;/li&gt; &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/graphical_models.html"&gt;16 Structured Probabilistic Models for Deep Learning&lt;/a&gt;&lt;/li&gt; &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/monte_carlo.html"&gt;17 Monte Carlo Methods&lt;/a&gt;&lt;/li&gt; &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/partition.html"&gt;18 Confronting the Partition Function&lt;/a&gt;&lt;/li&gt; &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/inference.html"&gt;19 Approximate Inference&lt;/a&gt;&lt;/li&gt; &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/generative_models.html"&gt;20 Deep Generative Models&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/ul&gt; &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/bib.html"&gt;Bibliography&lt;/a&gt;&lt;/li&gt; &lt;li&gt; &lt;a href="https://www.deeplearningbook.org/contents/index-.html"&gt;Index&lt;/a&gt;&lt;/li&gt; &lt;h2&gt;FAQ&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Can I get a PDF of this book? &lt;p&gt;No, our contract with MIT Press forbids distribution of too easily copied electronic formats of the book. &lt;/p&gt; &lt;/li&gt; &lt;li&gt;Why are you using HTML format for the web version of the book? &lt;p&gt;This format is a sort of weak DRM required by our contract with MIT Press. It's intended to discourage unauthorized copying/editing of the book. &lt;/p&gt;&lt;/li&gt; &lt;li&gt;What is the best way to print the HTML format? &lt;p&gt;Printing seems to work best printing directly from the browser, using Chrome. Other browsers do not work as well. &lt;/p&gt; &lt;/li&gt; &lt;li&gt;Can I translate the book into Chinese?&lt;/li&gt; &lt;p&gt;Posts and Telecom Press has purchased the rights. &lt;/p&gt; &lt;/ul&gt; &lt;p&gt; If you notice any typos (besides the known issues listed below) or have suggestions for exercises to add to the website, do not hesitate to contact the authors directly by e-mail at: feedback@deeplearningbook.org &lt;/p&gt; &lt;p&gt; Since the book is complete and in print, we do not make large changes, only small corrections. &lt;/p&gt; &lt;p&gt;Known issues: In outdated versions of the Edge browser, the "does not equal" sign sometimes appears as the "equals" sign. This may be resolved by updating to the latest version. &lt;/p&gt; &lt;/div&gt;&lt;a href="https://www.deeplearningbook.org/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sun, 26 Apr 2020 13:41:14 UT
      </pubDate>
      <guid>
        https://www.deeplearningbook.org/
      </guid>
    </item>
    <item>
      <title>
        Writing things right | David R. MacIver
      </title>
      <link>
        https://www.drmaciver.com/2009/01/writing-things-right/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt; &lt;p&gt;OO has contributed many big and important innovations to programming. Among these, the foremost is that you write functions after rather than before their argument.&lt;/p&gt; &lt;p&gt;No, really.&lt;/p&gt; &lt;p&gt;It’s not just OO languages of course. Concatenative languages do the same thing. There’s a long history of mathematicians doing it as well (though we don’t like to talk about them. The cool mathematicians all write their functions on the left).&lt;/p&gt; &lt;p&gt;It’s funny how attached people get to this fact though.&lt;/p&gt; &lt;p&gt;Consider the following piece of Scala code:&lt;/p&gt; &lt;pre&gt;object StringUtils{ /** * Trims whitespace from the end of s. */ def rtrim(s : String) = ... }&lt;/pre&gt; &lt;p&gt;We can invoke this as StringUtils.rtrim(myString). Or if we import StringUtils, just rtrim(myString);&lt;/p&gt; &lt;p&gt;People get very upset if you ask them to do so though, and they go to all sorts of lengths to avoid it.&lt;br&gt; Consider the following three examples from different languages:&lt;/p&gt; &lt;pre&gt;Scala: object StringUtils{ implicit def string2RTrim(s : String) = new { def rtrim = ...; } } Ruby: class String def rtrim ... end end C#: class StringUtils{ public static String rtrim(this String s) { &amp;nbsp;... } }&lt;/pre&gt; &lt;p&gt;What do these achieve over the previous version? Simple: You can write myString.rtrim instead of rtrim(myString). That’s it. (Actually the Ruby and Scala versions both *can* allow you to do different things than that. It’s just that here and in 90% of the use cases they aren’t used for anything else. The C# version literally doesn’t do anything else).&lt;/p&gt; &lt;p&gt;The thing is, while I’m making fun of this to a certain degree, it’s actually a perfectly reasonable thing to want to do. Designing things in noun-verb order is a good principle of UI design, and it works for programming as well. Things chain better – when you want to add new functions to a pipeline you add them at the point your cursor is naturally at and it matches well with thinking of it as a pipeline of “take this thing, do this to it, do that to it, do this other thing to it, get this value out”. Also you write far fewer brackets. :-) (compare Haskell’s foo . bar . baz $ thing idiom for a similar bracket avoidance tool).&lt;/p&gt; &lt;p&gt;Of these, I’d say that the Ruby solution is the most obvious (it just uses the fact that classes are open to add a new method to String), but it comes with the possibility of amusingly non-obvious runtime errors when someone else defines a conflicting method. The C# solution seems the best to me – it’s relatively little overhead over writing the utility method as you would otherwise and comes with the option to invoke it either as myString.rtrim or StringUtils.rtrim(myString), so when namespacing conflicts inevitably occur you have an easy fallback. But of course it uses a language feature specifically added to do this, while the other two are functions of more general language features. The Scala solution is, to my mind, decidedly the worst of the three.It’s syntactically noisy and comes with a significant additional runtime overhead.&lt;/p&gt; &lt;p&gt;But honestly I’m not particularly happy with any of these solutions. The Scala and Ruby solutions come with disproportionate costs to the benefit they give and the C# solution requires an additional language feature. Moreoever, each of these solutions requires effort at each definition site in order to make something available that you always want at the use site. Wouldn’t it be better if for every utility function you automatically had the option to write it on the right?&lt;/p&gt; &lt;p&gt;Let’s take a digression. What language is the following (rather pointless) code written in?&lt;/p&gt; &lt;pre&gt;[1, 2, 3].sort.length&lt;/pre&gt; &lt;p&gt;Ruby, right?&lt;/p&gt; &lt;p&gt;Actually, no. It’s Haskell.&lt;/p&gt; &lt;p&gt;Wait, what?&lt;/p&gt; &lt;p&gt;Well, it’s Haskell if you do something slightly evil and redefine the (.) operator (which normally means composition):&lt;/p&gt; &lt;pre&gt;Prelude Data.List&amp;gt; let (.) x f = f x&lt;/pre&gt; &lt;pre&gt;Prelude Data.List&amp;gt; [1, 2, 3].sort.length&lt;/pre&gt; &lt;pre&gt;3&lt;/pre&gt; &lt;p&gt;I saw this trick a while ago (the author was amusingly apologetic for it). It’s evil Haskell code because of the way it redefines an operator that normally means something else (this is totally typesafe of course – existing code will continue to use the old operator definition). But it’s a perfectly valid operator definition, and a rather nice one.&lt;/p&gt; &lt;p&gt;It works well with additional arguments to functions too:&lt;/p&gt; &lt;p&gt;Prelude Data.List&amp;gt; [1, 2, 3].sortBy(compare).length&lt;br&gt; 3&lt;/p&gt; &lt;p&gt;The reason this works is that sortBy takes the list argument curried as its last argument, so sortBy(compare) gives something of type [Int] -&amp;gt; [Int] which we can then apply as above (Haskell’s precedence rules make this work).&lt;/p&gt; &lt;p&gt;So this is a nice trick, but how is it useful to you? Well, it’s probably not. I can’t think of any low noise way of making it work in any of the other languages mentioned so far (the best I can come up with is an evil evil hack in Ruby that would make god go on a kitten killing spree and a mildly nasty hack with operators and implicit conversions in Scala that’s much too noisy to really use), and using it in Haskell will make other Haskell programmers very unhappy with you. But it’s an interesting trick, and I’ll be sure to bear it in mind if I ever get around to creating DRMacIverLang.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://www.drmaciver.com/2009/01/writing-things-right/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Mon, 27 Apr 2020 15:15:46 UT
      </pubDate>
      <guid>
        https://www.drmaciver.com/2009/01/writing-things-right/
      </guid>
    </item>
    <item>
      <title>
        No, seriously, why Scala? | David R. MacIver
      </title>
      <link>
        https://www.drmaciver.com/2007/12/no-seriously-why-scala/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt; &lt;p&gt;Recently an article called &lt;a href="http://ociweb.com/jnb/jnbDec2007.html"&gt;Why Scala?&lt;/a&gt; was &lt;a href="https://programming.reddit.com/info/62udw/comments/"&gt;posted on reddit&lt;/a&gt;. It’s an ok introduction to the language, but the very fair observation was made that it’s much more of a “What is Scala?” than a “Why Scala?”. I thought I’d share my thoughts on the subject. Mainly because I like hearing (reading) myself talk (write). :-)&lt;/p&gt; &lt;p&gt;Quick background: I initially learned to program in standard ML while at university (self taught, mostly, with the help of some friends doing computer science. I was doing maths). On graduating I then switched tracks entirely and started doing Java web development in a small software firm in London (I’ve since switched again, but I’m still doing Java professionally). I’ve also dabbled and read a lot with computer science and programming languages in my spare time since then, filling in the gaps that not having done any real computer science at university left me.&lt;/p&gt; &lt;p&gt;My train of thought on the language switch from ML to Java was basically:&lt;/p&gt; &lt;p&gt;a) Wow, this is different.&lt;br&gt; b) Ugh. Where are my higher order functions?&lt;br&gt; c) Where are all these random exceptions coming from?? I’ve compiled the code successfully, isn’t it supposed to work now?&lt;br&gt; d) Hmm. But there’s some useful stuff here too.&lt;/p&gt; &lt;p&gt;Scala’s a nice way to scratch both itches, and adds some very interesting features and functionality of its own. It’s not my favourite language (I don’t really have one. All languages suck. It’s just that some of them suck less in interesting ways), but it has a lot I like. Here’s a brain dump of some of it.&lt;/p&gt; &lt;h4&gt;Things I like:&lt;/h4&gt; &lt;h5&gt;Object oriented programming&lt;/h5&gt; &lt;p&gt;I know, it’s so entrenched it’s past even bothering with its buzzword status. But object oriented programming has a lot of advantages for medium to large scale composition. It has some disadvantages, and frankly sucks at small scale composition of functionality (which is where functional programming shines), but it allows for some very nice pluggability.&lt;/p&gt; &lt;h5&gt;Module oriented programming&lt;/h5&gt; &lt;p&gt;ML has higher order modules. I never really used them much when I was programming it more often (mostly because I was only writing enough code to do some simple maths projects. I never wrote anything large scale), but having looked into them in more details since they’re really powerful. They’re essentially a different take on the composition that object orientation provides. Where object orientation resolves everything dynamically, ML’s higher order modules resolve everything statically. This introduces some limitations in flexibility but makes up for them in power and type safety – they provide a much more flexible and interesting abstraction over a type than mere subclassing and interfaces can.&lt;/p&gt; &lt;p&gt;Scala has both. Further, it has both and lo and behold they are the same thing. Objects are modules, and can declare their own types (note: This is much more than just declaring an inner class in Java is), imported, etc. Modules are objects and can be instantiated at runtime, extended, etc. You lose a bit of the static guarantees that ML modules but you gain a lot of flexibility from both sides.&lt;/p&gt; &lt;h5&gt;Static Typing&lt;/h5&gt; &lt;p&gt;I’ve written too much Java to not like static typing.&lt;/p&gt; &lt;p&gt;Wait, I know that sounds like a non sequitur, but read on.&lt;/p&gt; &lt;p&gt;I’ve written too much Java and &lt;em&gt;seen flagrantly stupid and really subtle runtime errors that should never have made it past the compiler&lt;/em&gt; coming out of it to not like static typing. NullPointerException, ClassCastException, argh. &lt;/p&gt; &lt;p&gt;If you’ve written enough code in a language like ML, OCaml or Haskell you will know that the compiler is your friend. And, like all good friends, it will yell at you if you do something stupid and then help you pick up the pieces. &lt;/p&gt; &lt;p&gt;Scala doesn’t quite manage that. If you write code in just the right way you can achieve that level of guarantee (and &lt;a href="https://unenterprise.blogspot.com/2007/12/statically-checked-range-types-in-scala.html"&gt;in some cases&lt;/a&gt;, more. But that tends to be the result of abuse of the type system by deranged maniacs), but the combination of subtyping and some Java interoperability decisions mean that it’s not quite as good. It’s not bad though.&lt;/p&gt; &lt;p&gt;So: I like object oriented programming, I like static typing. It logically follows that I must like statically typed object oriented languages, right? Well, in principle, yes. But Scala is the first one I’ve met with a type system that didn’t suck. Scala’s traits (a sort of mixin) are so much better to work with than interfaces, the generics work properly, provide variance annotations, etc. A reasonable subset of the types are inferred. Compared to the type systems of Java, C# and C++ it’s a dream (it’s not as nice as the type systems of the statically typed functional languages I know of. Subtyping seems to cause issues, with a lot of research still needed to make it work well, and Scala seems to have largely ignored what prior work there was Hindley-Milner style type systems with subtyping)&lt;/p&gt; &lt;h5&gt;Functional programming&lt;/h5&gt; &lt;p&gt;You’ve all been dreading this section. “Oh no. Now he’s going to enthuse about how marvelous functional programming is and how it’s going to cure cancer”. Nope. Can’t be bothered. Functional programming is nice. If you don’t believe that, I’m not going to try to convince you of it. Scala’s support for functional programming is ok. It has some warts, but it also has some nice points, and it generally works well and isn’t too verbose. I’m not going to get any more excited about its presence than I am about the fact that my bike has wheels (but I’d be pretty pissed off if my bike didn’t have wheels). Higher order functions, pattern matching, etc. It’s all there. It works. Moving on swiftly…&lt;/p&gt; &lt;h5&gt;Implicits&lt;/h5&gt; &lt;p&gt;Scala offers a bag of features under the keyword ‘implicit’. This is one of those things that makes you go “Oh, that’s cute” when you first see it and then go “Wow, that’s &lt;em&gt;powerful&lt;/em&gt;” six months later. &lt;/p&gt; &lt;p&gt;Essentially implicits give you statically guaranteed and provided dynamic scoping. You say “I need a Foo. I don’t care where it comes from”, the compiler says “Here you go” or “Sorry, no Foos today”. These can be objects, implicit conversions between types (You know the way Ints get implicitly converted to longs, double, etc in Java? Scala does that too, but it’s all programmer definable. They’re just library functions in scala.Predefined). If you remember what I said about Scala objects being modules and you’ve read &lt;a href="https://www.cse.unsw.edu.au/~chak/papers/mtc-tr-long.pdf"&gt;this paper&lt;/a&gt; a little light might just have gone on in your brain. If you haven’t read it and don’t want to, here’s the summary version: Implicit function arguments + first class modules gives you something that looks and quacks very much like Haskell type classes (yes, I know this isn’t actually what the paper says, but it follows from it). Mmm. &lt;/p&gt; &lt;p&gt;These are the big things to like about Scala. Here are a few little things:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Sane constructor/class semantics. If you’ve written a lot of Java there’s a good chance you hate its constructor system. Scala’s is much nicer.&lt;/li&gt; &lt;li&gt;Expression oriented code. Everything is an expression. You can form compound expressions trivially – { val foo = bar(); baz(foo, foo); } is an expression which evaluates to baz(foo, foo).&lt;/li&gt; &lt;li&gt;Sanely uniform scope. Pretty much anything you can do inside a method you can do inside an object and vice versa. Things are for the most part lexically scoped in the right way.&lt;/li&gt; &lt;li&gt;The primitive/object divide is much less irritating. Primitives get a few special treatments at the language level, but mostly they’re just objects. When things should compile to use primitives, they do. When the primitives need to be boxed, they will be. It’s almost entirely transparent.&lt;/li&gt; &lt;li&gt;Performance. Scala generates very good (well. ‘good’. Java-like) bytecode, which means it gets to take advantage of most of the optimizations the JVM is willing to throw its way. Further it puts a reasonable amount of its own work into performing optimisations on the bytecode, etc so you get those nice juicy abstractions without much overhead. There’s &lt;a href="http://shootout.alioth.debian.org/debian/benchmark.php?test=all&amp;amp;lang=scala&amp;amp;lang2=java"&gt;essentiall y no performance penalty&lt;/a&gt; for choosing Scala over Java&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;etc.&lt;/p&gt; &lt;p&gt;Scala’s far from perfect. It has some syntactic weirdnesses, a few issues carried over from Java, a moderately buggy compiler and a host of little features and edge cases that are really hard to keep in your head. However, I find that these issues don’t actually do more than annoy you from time to time. The core language is powerful and very useful for just sitting down and writing good code in.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://www.drmaciver.com/2007/12/no-seriously-why-scala/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Mon, 27 Apr 2020 15:15:48 UT
      </pubDate>
      <guid>
        https://www.drmaciver.com/2007/12/no-seriously-why-scala/
      </guid>
    </item>
    <item>
      <title>
        Second-guessing the modern web - macwright.com
      </title>
      <link>
        https://macwright.org/2020/05/10/spa-fatigue.html
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;&lt;p&gt;The emerging norm for web development is to build a React single-page application, with server rendering. The two key elements of this architecture are something like:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;The main UI is built &amp;amp; updated in JavaScript using React or something similar.&lt;/li&gt;&lt;li&gt;The backend is an API that that application makes requests against.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;This idea has really swept the internet. It started with a few major popular websites and has crept into corners like marketing sites and blogs.&lt;/p&gt;&lt;p&gt;I’m increasingly skeptical of it.&lt;/p&gt;&lt;p&gt;There is a sweet spot of React: in moderately interactive interfaces. Complex forms that require immediate feedback, UIs that need to move around and react instantly. That’s where it excels. I helped build the editors in &lt;a href="https://www.mapbox.com/mapbox-studio/"&gt;Mapbox Studio&lt;/a&gt; and &lt;a href="https://observablehq.com/"&gt;Observable&lt;/a&gt; and for the most part, React was a great choice.&lt;/p&gt;&lt;p&gt;But there’s a lot on either side of that sweet spot.&lt;/p&gt;&lt;p&gt;The high performance parts aren’t React. &lt;a href="https://docs.mapbox.com/mapbox-gl-js/api/"&gt;Mapbox GL&lt;/a&gt;, for example, is vanilla JavaScript and probably should be forever. The level of abstraction that React works on is too high, and the cost of using React - in payload, parse time, and so on - is too much for any company to include it as part of an SDK. Same with the &lt;a href="https://github.com/observablehq/runtime"&gt;Observable runtime&lt;/a&gt;, the juicy center of that product: it’s very performance-intensive and would barely benefit from a port.&lt;/p&gt;&lt;p&gt;The less interactive parts don’t benefit much from React. Listing pages, static pages, blogs - these things are increasingly built in React, but the benefits they accrue are extremely narrow. A lot of the optimizations we’re deploying to speed up these things, things like bundle splitting, server-side rendering, and prerendering, are triangulating what we had before the rise of React.&lt;/p&gt;&lt;p&gt;And they’re kind of messy optimizations. Here are some examples.&lt;/p&gt;&lt;h3 id="bundle-splitting"&gt;Bundle splitting.&lt;/h3&gt;&lt;p&gt;As your React application grows, the application bundle grows. Unlike with a traditional multi-page app, that growth affects &lt;em&gt;every visitor&lt;/em&gt;: you download the whole app the first time that you visit it. At some point, this becomes a real problem. Someone who lands on the About page is also downloading 20 other pages in the same application bundle. Bundle splitting ‘solves’ this problem by creating many JavaScript bundles that can lazily load each other. So you load the About page and what your browser downloads is an ‘index’ bundle, and then that ‘index’ bundle loads the ‘about page’ bundle.&lt;/p&gt;&lt;p&gt;This &lt;em&gt;sort of&lt;/em&gt; solves the problem, but it’s not great. Most bundle splitting techniques require you to load that ‘index bundle’, and then only once that JavaScript is loaded and executed does your browser know which ‘page bundle’ it needs. So you need two round-trips to start rendering.&lt;/p&gt;&lt;p&gt;And then there’s the question of updating code-split bundles. User sessions are surprisingly long: someone might have your website open in a tab for weeks at a time. I’ve seen it happen. So if they open the ‘about page’, keep the tab open for a week, and then request the ‘home page’, then the home page that they request is dictated by &lt;em&gt;the index bundle that they downloaded last week&lt;/em&gt;. This is a deeply weird and under-discussed situation. There are essentially two solutions to it:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;You keep all generated JavaScript around, forever, and people will see the version of the site that was live at the time of their first page request.&lt;/li&gt;&lt;li&gt;You create a system that alerts users when you’ve deployed a new version of the site, and prompt them to reload.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;The first solution has a drawback that might not be immediately obvious. In those intervening weeks between loading the site and clicking a link, you might’ve deployed a new API version. So the user will be using an old version of your JavaScript frontend with a new version of your API backend, and they’ll trigger errors that none of your testing knows about, because you’ll usually be testing current versions of each.&lt;/p&gt;&lt;p&gt;And the second solution, while it works (and is what we implemented for Mapbox Studio), is a bizarre way for a web application to behave. Prompting users to ‘update’ is something from the bad old days of desktop software, not from the shiny new days of the web.&lt;/p&gt;&lt;p&gt;Sure: traditional non-SPA websites are not immune to this pitfall. Someone might load your website, have a &lt;em&gt;form&lt;/em&gt; open for many weeks, and then submit it after their session expired or the API changed. But that’s a much more limited exposure to failure than in the SPA case.&lt;/p&gt;&lt;h3 id="server-side-rendering"&gt;Server-Side Rendering&lt;/h3&gt;&lt;p&gt;Okay, so the theory here is that SPAs are initially a blank page, which is then filled out by React &amp;amp; JavaScript. That’s bad for performance: HTML pages don’t &lt;em&gt;need&lt;/em&gt; to be blank initially. So, Server-Side Rendering runs your JavaScript frontend code on the backend, creating a filled-out HTML page. The user loads the page, which now has pre-rendered content, and then the JavaScript loads and makes the page interactive.&lt;/p&gt;&lt;p&gt;A great optimization, but again, caveats.&lt;/p&gt;&lt;p&gt;The first is that the page you initially render is dead: you’ve created the &lt;a href="https://web.dev/interactive/"&gt;Time To Interactive&lt;/a&gt; metric. It’s your startup’s homepage, and it has a “Sign up” button, but until the JavaScript loads, that button doesn’t do anything. So you need to compensate. Either you omit some interactive elements on load, or you try really hard to make sure that the JavaScript loads faster than users will click, or you make some elements not require JavaScript to work - like making them normal links or forms. Or some combination of those.&lt;/p&gt;&lt;p&gt;And then there’s the authentication story. If you do SSR on any pages that are custom to the user, then you need to forward any cookies or authentication-relevant information to your API backend and make sure that you never cache the server-rendered result. Your formerly-lightweight application server is now doing quite a bit of labor, running React &amp;amp; making API requests in order to do this pre-rendering.&lt;/p&gt;&lt;h3 id="apis"&gt;APIs&lt;/h3&gt;&lt;p&gt;The dream of APIs is that you have generic, flexible endpoints upon which you can build any web application. That idea breaks down pretty fast.&lt;/p&gt;&lt;p&gt;Most interactive web applications start to triangulate on “one query per page.” API calls being generic or reusable never seems to persist as a value in infrastructure. This is because a large portion of web applications are, at their core, query &amp;amp; transformation interfaces on top of databases. The hardest performance problems they tend to have are query problems and transfer problems.&lt;/p&gt;&lt;p&gt;For example: a generically-designed REST API that tries not to mix ‘concerns’ will produce a frontend application that has to make lots of requests to display a page. And then a new-age GraphQL application will suffer under the &lt;a href="https://engineering.shopify.com/blogs/engineering/solving-the-n-1-problem-for-graphql-through-batching"&gt;N+1 query problem&lt;/a&gt; at the database level until an optimization arrives. And a traditional “make a query and put it on a page” application will just, well, try to write some good queries.&lt;/p&gt;&lt;p&gt;None of these solutions are silver bullets: I’ve worked with overly-strict REST APIs, optimization-hungry GraphQL APIs, and hand-crafted SQL APIs. But no option really lets a web app be careless about its data-fetching layer. Web applications can’t sit on top of independently-designed APIs: to have a chance at performance, the application and its datasource need to be designed as one.&lt;/p&gt;&lt;h3 id="data-fetching"&gt;Data fetching&lt;/h3&gt;&lt;p&gt;Speaking of data fetching. It’s really important and really bizarre in React land. Years ago, I expected that some good patterns would emerge. Frankly, they didn’t.&lt;/p&gt;&lt;p&gt;There are decent patterns in the form of GraphQL, but for a React component that loads data with fetch from an API, the solutions have only gotten weirder. There’s great documentation for everything else, but old-fashioned data loading is relegated to one example of how to mock out ‘fetch’ for testing, and lots of Medium posts of varying quality.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;Don’t read this as anti-React. I still think React is pretty great, and for a particular set of use cases it’s the best tool you can find. And I explicitly want to say that –&amp;nbsp;from what I’ve seen –&amp;nbsp;most other Single-Page-Application tools share most of these problems. They’re issues with the pattern, not the specific frameworks used to implement it. React alternatives have some great ideas, and they might be better, but they are ultimately really similar.&lt;/p&gt;&lt;p&gt;But I’m at the point where I look at where the field is and what the alternative patterns are –&amp;nbsp;taking a second look at unloved, unpopular, uncool things like Django, Rails, Laravel –&amp;nbsp;and think &lt;em&gt;what the heck is happening&lt;/em&gt;. We’re layering optimizations upon optimizations in order to get the SPA-like pattern to fit every use case, and I’m not sure that it is, well, worth it.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;And it should be easy to do a good job.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Frameworks should lure people into the &lt;a href="https://blog.codinghorror.com/falling-into-the-pit-of-success/"&gt;pit of success&lt;/a&gt;, where following the normal rules and using normal techniques is the winning approach.&lt;/p&gt;&lt;p&gt;I don’t think that React, in this context, really is that pit of success. A naïvely implemented React SPA isn’t stable, or efficient, and it doesn’t naturally scale to significant complexity.&lt;/p&gt;&lt;p&gt;You can add optimizations on top of it that fix those problems,&amp;nbsp;or you can use a framework like Next.js that will include those optimizations by default. That’ll help you get pretty far. But then you’ll be lured by all of the easy one-click ways to add bloat and complexity. You’ll be responsible for keeping some of these complex, finicky optimizations working properly.&lt;/p&gt;&lt;p&gt;And for what? Again - there is a swath of use cases which would be hard without React and which aren’t complicated enough to push beyond React’s limits. But there are also a &lt;em&gt;lot&lt;/em&gt; of problems for which I can’t see any concrete benefit to using React. Those are things like blogs, shopping-cart-websites, mostly-&lt;a href="https://en.wikipedia.org/wiki/Create,_read,_update_and_delete"&gt;CRUD&lt;/a&gt;-and-forms-websites. For these things, all of the fancy optimizations are trying to get you closer to &lt;em&gt;the performance you would’ve gotten if you just hadn’t used so much technology&lt;/em&gt;.&lt;/p&gt;&lt;p&gt;I can, for example, guarantee that this blog is faster than &lt;em&gt;any Gatsby blog&lt;/em&gt; (and much love to the Gatsby team) because there is nothing that a React static site can do that will make it faster than a non-React static site.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;But the cultural tides are &lt;em&gt;strong&lt;/em&gt;. Building a company on Django in 2020 seems like the equivalent of driving a PT Cruiser and blasting Faith Hill’s “Breathe” on a CD while your friends are listening to The Weeknd in their Teslas. Swimming against this current isn’t easy, and not in a trendy contrarian way.&lt;/p&gt;&lt;p&gt;I don’t think that everyone’s using the SPA pattern for no reason. For large corporations, it allows teams to work independently: the “frontend engineers” can “consume” “APIs” from teams that probably work in a different language and can only communicate through the hierarchy. For heavily interactive applications, it has real benefits in modularity, performance, and structure. And it’s beneficial for companies to shift computing requirements from their servers to their customers browsers: a real win for reducing their spend on infrastructure.&lt;/p&gt;&lt;p&gt;But I think there are a lot of problems that are better solved some other way. There’s no category winner like React as an alternative. Ironically, backends are churning through technology even faster than frontends, which have been loyal to one programming language for decades. There are some age-old technologies like Rails, Django, and Laravel, and there are a few halfhearted attempts to do templating and “serve web pages” from Go, Node, and other new languages. If you go this way, you’re beset by the cognitive dissonance of following in the footsteps of enormous projects - Wikipedia rendering web pages in PHP, Craigslist rendering webpages in Perl - but being far outside the norms of &lt;em&gt;modern web development&lt;/em&gt;. If Wikipedia were started today, it’d be React. Maybe?&lt;/p&gt;&lt;p&gt;What if everyone’s wrong? We’ve been wrong before.&lt;/p&gt;&lt;details&gt;&lt;summary&gt;Follow-ups &amp;amp; commmentary&lt;/summary&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://dev.to/richharris/in-defense-of-the-modern-web-2nia"&gt;"In defense of the modern web", Rich Harris&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://dev.to/devplebs/friday-night-deploys-22-a-brief-discussion-on-the-state-of-the-modern-web-2961"&gt;Friday Night Deploys (Podcast) #22: A Brief Discussion On The State Of The Modern Web&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://frontendfirst.fm/episodes/read-and-discuss-second-guessing-the-modern-web"&gt;Frontend First (Podcast): Read &amp;amp; Discuss&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://medium.com/@kevinkirchner/a-ready-to-try-concept-in-response-to-second-guessing-the-modern-web-6946ec4d0598"&gt;A Ready-To-Try Concept in Response to “Second-guessing the modern web”&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/details&gt;&lt;/div&gt;&lt;/div&gt;&lt;a href="https://macwright.org/2020/05/10/spa-fatigue.html"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Mon, 11 May 2020 16:06:42 UT
      </pubDate>
      <guid>
        https://macwright.org/2020/05/10/spa-fatigue.html
      </guid>
    </item>
    <item>
      <title>
        rust-blog/learning-rust-in-2020.md at master · pretzelhammer/rust-blog · GitHub
      </title>
      <link>
        https://github.com/pretzelhammer/rust-blog/blob/master/posts/learning-rust-in-2020.md
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div id="readme"&gt; &lt;article&gt;&lt;h2&gt;Learning Rust in 2020&lt;/h2&gt; &lt;p&gt;&lt;em&gt;May 9th, 2020 · 15 minute read · #rust&lt;/em&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="#intro"&gt;Intro&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#tldr"&gt;TL;DR&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#practical-rust-resource-reviews"&gt;Practical Rust Resource Reviews&lt;/a&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="#hackerrank"&gt;HackerRank&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#project-euler"&gt;Project Euler&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#leetcode"&gt;LeetCode&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#codewars"&gt;Codewars&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#advent-of-code"&gt;Advent of Code&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#rustlings"&gt;Rustlings&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#xxercism"&gt;Exercism&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;&lt;a href="#conclusion"&gt;Conclusion&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#discuss"&gt;Discuss&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#notifications"&gt;Notifications&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#further-reading"&gt;Further Reading&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Intro&lt;/h2&gt; &lt;p&gt;When I started learning Rust I made the mistake of following the advice to read &lt;a rel="nofollow" href="https://doc.rust-lang.org/book/title-page.html"&gt;The Book&lt;/a&gt; first. While it's a great resource, it's pretty overwhelming for a beginner to get told &lt;em&gt;"If you'd like to learn this programming language the best way to start is to read this 20 chapter book!"&lt;/em&gt; Most people give up before they even get started when they get advice like this. Nobody ever told someone to read a 20 chapter book just to get started with Javascript or Python. Rust's learning curve is no joke but you gotta give the people what they want, and they want to program, not read about programming. Programming is fun and reading about programming is not as fun.&lt;/p&gt; &lt;p&gt;The first 10% of this article is gonna be me giving you advice on how to learn Rust in 2020 following a &lt;em&gt;practical hands-on coding&lt;/em&gt; approach. This is the good part of the article. You can safely exit after this part (I'll tell you when). The remaining 90% of this article is me ranting about how most online coding challenge sites have poor support for Rust.&lt;/p&gt; &lt;h2&gt;TL;DR&lt;/h2&gt; &lt;p&gt;If you're a total Rust newbie and want to learn as much as possible in just one day you should read fasterthanlime's excellent &lt;a rel="nofollow" href="https://fasterthanli.me/blog/2020/a-half-hour-to-learn-rust/"&gt;A half-hour to learn Rust&lt;/a&gt; and then checkout the awesome &lt;a href="https://github.com/rust-lang/rustlings"&gt;Rustlings&lt;/a&gt; repo and complete the exercises.&lt;/p&gt; &lt;p&gt;If you're a Rust beginner you should get started on &lt;a rel="nofollow" href="https://exercism.io/tracks/rust"&gt;Exercism's Rust Track&lt;/a&gt;. If you get stuck you should ask your friends Google and StackOverflow for help. I recommend taking the time to get comfortable reading and navigating the &lt;a rel="nofollow" href="https://doc.rust-lang.org/std/"&gt;Rust Standard Library Docs&lt;/a&gt; which is amazing and has simple practical examples for how to use everything inside of it. &lt;a rel="nofollow" href="https://doc.rust-lang.org/rust-by-example/"&gt;Rust by Example&lt;/a&gt; is also a really good high-level reference that you can use to quickly learn Rust syntax and features. If you want to gain a deeper understanding of a certain Rust concept only then do I recommend finding the appropriate chapter in &lt;a rel="nofollow" href="https://doc.rust-lang.org/book/title-page.html"&gt;The Book&lt;/a&gt; to read. The best part of completing an exercise on Exercism is that you get access to all the solutions by other members which you can sort by most-starred to see particularly idiomatic or clever solutions. This is a great way to learn!&lt;/p&gt; &lt;p&gt;At this point you're probably an advanced beginner and can find your own path. If you need more guidance and would like to continue working on small simple programs I recommend doing the exercises from the &lt;a rel="nofollow" href="https://adventofcode.com/2018"&gt;Advent of Code 2018 Calendar&lt;/a&gt;. The reason why I specifically recommended the 2018 calendar is because once you're finished with an exercise you can compare your solution to &lt;a href="https://github.com/BurntSushi/advent-of-code"&gt;BurntSushi's Advent of Code 2018 Rust solutions&lt;/a&gt;. BurntSushi writes really clean, readable, idiomatic Rust code. Reading the code of an experienced Rustacean will teach you as much as the exercises themselves.&lt;/p&gt; &lt;p&gt;Exit now, the good part of the article is over.&lt;/p&gt; &lt;h2&gt;Practical Rust Resource Reviews&lt;/h2&gt; &lt;p&gt;&lt;em&gt;Alternative title: Reviews of Free Online Resources a Rust Beginner can use to Practice Writing Small Simple Rust Programs&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Most of these resources weren't specifically created for the purpose of teaching Rust, however they can all be used to learn and practice Rust and many of them explicitly support Rust submissions and provide Rust-specific versions of problems.&lt;/p&gt; &lt;p&gt;The resources are ordered from worst to best.&lt;/p&gt; &lt;h3&gt;&lt;a rel="nofollow" href="https://www.hackerrank.com/"&gt;HackerRank&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;Rust is a supported language on HackerRank except you aren't allowed to submit Rust solutions to most of the problems on their site. I tried to upload my solution directly and they refused it:&lt;/p&gt; &lt;p&gt;&lt;a href="https://github.com/pretzelhammer/rust-blog/blob/master/assets/hackerrank-more-like-failrank.png" rel="noopener noreferrer"&gt;&lt;img alt="hackerrank more like failrank" src="https://github.com/pretzelhammer/rust-blog/raw/master/assets/hackerrank-more-like-failrank.png"&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;This is really strange because I was able to browse Rust solutions for the problem above submitted by other HackerRank users, so it's possible to submit a Rust solution somehow. I tried Googling this issue but Google didn't return any useful results. There's no way for me to evaluate HackerRank other than to tell you not to waste your time with it like I did.&lt;/p&gt; &lt;h3&gt;&lt;a rel="nofollow" href="https://projecteuler.net/archives"&gt;Project Euler&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;When I first started to learn programming back in 2012 I commonly heard &lt;em&gt;"If you wanna get up to speed quickly in a new programming language solve some Project Euler problems with it!"&lt;/em&gt; which was okay advice at the time since there were not many other alternatives but in my opinion Project Euler has very little to do with programming. Project Euler problems are more math problems than they are programming problems. Their challenge lies almost entirely in the mathematical reasoning required to reach the solution as the programming required is usually trivial. I would not recommend solving Project Euler problems as a way to learn Rust unless you're very mathematically inclined and have some nostalgia for the site.&lt;/p&gt; &lt;h3&gt;&lt;a rel="nofollow" href="https://leetcode.com/problemset/all/"&gt;LeetCode&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;Rust is a supported language on LeetCode. For every problem on LeetCode you get a solution template which usually contains a single unimplemented function which you then have to implement and submit in order to solve the problem. For more involved problems the solution template might include a &lt;code&gt;struct&lt;/code&gt; and an &lt;code&gt;impl&lt;/code&gt; block with several unimplemented methods. Unfortunately, these solution templates are not created by humans, they are automatically generated, which results in a lot of really awkward and unidiomatic Rust code. Examples:&lt;/p&gt; &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;LeetCode generated Rust&lt;/th&gt; &lt;th&gt;Idiomatic Rust&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;tree problems represent links as &lt;code&gt;Option&amp;lt;Rc&amp;lt;RefCell&amp;lt;Node&amp;gt;&amp;gt;&amp;gt;&lt;/code&gt;&lt;/td&gt; &lt;td&gt;&lt;code&gt;Option&amp;lt;Rc&amp;lt;RefCell&amp;lt;Node&amp;gt;&amp;gt;&amp;gt;&lt;/code&gt; is overkill for tree links and &lt;code&gt;Option&amp;lt;Box&amp;lt;Node&amp;gt;&amp;gt;&lt;/code&gt; works just as well and is much easier to work with&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;methods which obviously mutate self still borrow it immutably, e.g. &lt;code&gt;fn insert(&amp;amp;self, val: i32)&lt;/code&gt;&lt;/td&gt; &lt;td&gt;methods that mutate self need to borrow it mutably, e.g. &lt;code&gt;fn insert(&amp;amp;mut self, val: i32)&lt;/code&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;signed 32-bit integers are used for all numbers, even if the problem is undefined for negative integers, e.g. &lt;code&gt;fn nth_fib(n: i32) -&amp;gt; i32&lt;/code&gt;&lt;/td&gt; &lt;td&gt;problems which are undefined for negative integers should use unsigned integers, e.g. &lt;code&gt;fn nth_fib(n: u32) -&amp;gt; u32&lt;/code&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;functions always take ownership of their arguments, even if it's unnecessary, e.g. &lt;code&gt;fn sum(nums: Vec&amp;lt;i32&amp;gt;) -&amp;gt; i32&lt;/code&gt;&lt;/td&gt; &lt;td&gt;if you don't need ownership then borrow &lt;code&gt;fn sum(nums: &amp;amp;[i32]) -&amp;gt; i32&lt;/code&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;functions sometimes ignore basic error cases, e.g. for &lt;code&gt;fn get_max(nums: Vec&amp;lt;i32&amp;gt;) -&amp;gt; i32&lt;/code&gt; what &lt;code&gt;i32&lt;/code&gt; should be returned if &lt;code&gt;nums&lt;/code&gt; is empty?&lt;/td&gt; &lt;td&gt;if a result might be undefined the return type should be wrapped in an &lt;code&gt;Option&lt;/code&gt;, e.g. &lt;code&gt;fn get_max(nums: &amp;amp;[i32]) -&amp;gt; Option&amp;lt;i32&amp;gt;&lt;/code&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;Other LeetCode issues, specific to Rust:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;LeetCode doesn't allow you to pull in 3rd-party dependencies in solutions. Normally I think this is okay for most languages but Rust in particular has a pretty slim standard library which doesn't even include regex support so a lot of the more complex string parsing problems on LeetCode are pointlessly difficult to solve in Rust but have otherwise trivial solutions in other languages which have regex support in their standard libraries.&lt;/li&gt; &lt;li&gt;None of the problems in the &lt;code&gt;concurrency&lt;/code&gt; category accept solutions in Rust. What? Fearless concurrency is one of Rust's major selling points!&lt;/li&gt; &lt;li&gt;After solving a problem you can go to the problem's comments section to see other user's solutions (as many users like to publish their solutions there) but because Rust isn't very popular on LeetCode sometimes you won't find any Rust solutions ;(&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;General LeetCode issues:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;LeetCode has a surprising amount of very low quality problems. Problems can be liked and disliked by users but problems are never removed even if they hit very high dislike ratios. I've seen lots of problems with 100+ votes and 80%+ dislike ratios and I don't understand why they are kept on the site.&lt;/li&gt; &lt;li&gt;Problem difficulty ratings are kinda off. Problems are rated as Easy, Medium, or Hard but there are many Easy problems with lower solve rates than many Hard problems.&lt;/li&gt; &lt;li&gt;Not all problems accept solutions in all languages, and you can't filter problems by which languages they accept. None of the graph problems on LeetCode accept Rust solutions, for example.&lt;/li&gt; &lt;li&gt;LeetCode blocks "premium" problems behind a steep monthly paywall but doesn't offer any kind of premium free-trial so there's no telling if the quality is actually any better than the free problems.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Things LeetCode does right:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Solutions to problems are tested against a suite of secret unit tests, but if you fail a particular test case they show you the failed case.&lt;/li&gt; &lt;li&gt;All of the generated Rust code at least follows rustfmt conventions.&lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;&lt;a rel="nofollow" href="https://www.codewars.com/join?language=rust"&gt;Codewars&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;Codewars is a misleading name. There's no war going on at Codewars. There's no time limit to solve problems and your solutions aren't judged on their speed of execution or memory usage. You aren't in competition with anyone else. This isn't a bad thing, just worth pointing out.&lt;/p&gt; &lt;p&gt;Rust is a supported language on Codewars. For every problem on Codewars you get a solution template which usually contains a single unimplemented function which you then have to implement and submit in order to solve the problem. These solution templates are created by humans, including humans who aren't familiar with Rust, so you occasionally get some awkward and unidiomatic Rust. Examples:&lt;/p&gt; &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Codewars' Rust Problems&lt;/th&gt; &lt;th&gt;Idiomatic Rust&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;sometimes don't follow rustfmt conventions, e.g. &lt;code&gt;fn makeUppercase(s:&amp;amp;str)-&amp;gt;String&lt;/code&gt;&lt;/td&gt; &lt;td&gt;always follows rustfmt conventions, e.g. &lt;code&gt;fn make_uppercase(s: &amp;amp;str) -&amp;gt; String&lt;/code&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;sometimes takes signed integer arguments for problems that aren't defined for negative integers, e.g. &lt;code&gt;fn nth_fib(n: i32) -&amp;gt; i32&lt;/code&gt;&lt;/td&gt; &lt;td&gt;if a problem isn't defined for negative integers use unsigned integer arguments, e.g. &lt;code&gt;fn nth_fib(n: u32) -&amp;gt; u32&lt;/code&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;sometimes a problem asks you to return &lt;code&gt;-1&lt;/code&gt; for the null case, e.g. &lt;code&gt;fn get_index(needle: i32, haystack: &amp;amp;[i32]) -&amp;gt; i32&lt;/code&gt;&lt;/td&gt; &lt;td&gt;if a result can be null the return type should be wrapped in an &lt;code&gt;Option&lt;/code&gt;, e.g. &lt;code&gt;fn get_index(needle: i32, haystack: &amp;amp;[i32]) -&amp;gt; Option&amp;lt;usize&amp;gt;&lt;/code&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;sometimes don't take advantage of deref coercion, e.g. &lt;code&gt;fn do_stuff(s: &amp;amp;String, list: &amp;amp;Vec&amp;lt;i32&amp;gt;)&lt;/code&gt;&lt;/td&gt; &lt;td&gt;takes advantage of deref coercion, e.g. &lt;code&gt;fn do_stuff(s: &amp;amp;str, list: &amp;amp;[i32])&lt;/code&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;All of the issues above only happen sometimes since there are Rustaceans of various skill-levels on Codewars translating problems to Rust. This is a huge step up from LeetCode where all of the generated Rust problem code is consistently unidiomatic. However, the Rust community on Codewars as a whole might lean towards the inexperienced side since I've seen some highly upvoted "idiomatic" solutions that were also a bit on the awkward side. Examples:&lt;/p&gt; &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Codewars' highest upvoted Rust solutions&lt;/th&gt; &lt;th&gt;Idiomatic Rust&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;sometimes use an explicit return at the end of a function block, e.g. &lt;code&gt;return result;&lt;/code&gt;&lt;/td&gt; &lt;td&gt;blocks are evaluated as expressions and implicitly return their last item, an explicit return at the end of a function block is unnecessary, e.g. &lt;code&gt;result&lt;/code&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;often use compact formatting to make the solution look more concise&lt;/td&gt; &lt;td&gt;should follow rustfmt conventions&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;sometimes make unnecessary allocations, e.g. &lt;code&gt;str_slice.to_string().chars()&lt;/code&gt;&lt;/td&gt; &lt;td&gt;if you don't need to allocate then don't, e.g. &lt;code&gt;str_slice.chars()&lt;/code&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;often try to solve the problem using nothing but iterators at the cost of everything else&lt;/td&gt; &lt;td&gt;iterators are expressive and idiomatic, but if you have to chain 15 of them in a row and there are multiple levels of nested iterators in-between then perhaps you should consider refactoring to use some helper functions, intermediate variables, and maybe even a for-loop&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;Again, the issues above only happen sometimes. An experienced Rustacean can spot them easily but there are a lot of Rust newbies on these sites who have no clue they are learning anti-patterns.&lt;/p&gt; &lt;p&gt;Other Codewars issues, specific to Rust:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Rust doesn't seem that popular on Codewars, the site has 9000 exercises but only 300 of them have been translated to Rust ;(&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Other general Codewars issues:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Your solution is tested against a suite of secret unit tests, if you fail one of the secret unit tests you aren't shown the failed test case. This is especially annoying if the test case tests for an edge case that wasn't clearly communicated in the problem description.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Things Codewars does right:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;There's a small whitelist of 3rd-party dependencies you can use to help solve problems with Rust. This whitelist includes: rand, chrono, regex, serde, itertools, and lazy_static which helps round out Rust's standard library and puts it more on par with other languages.&lt;/li&gt; &lt;li&gt;You can filter problems by language.&lt;/li&gt; &lt;li&gt;Submitting a solution to a problem also automatically publishes the solution. You can view and upvote other members' solutions. You can sort solutions by most upvotes to see particularly concise and clever solutions, which sometimes will also be very idiomatic (but sometimes not, as explained above).&lt;/li&gt; &lt;li&gt;Problem difficulty grading is pretty good! Instead of grading problems as Easy, Medium, or Hard like LeetCode, Codewars chooses to grade problems from easiest to hardest as: 8 kyu, 7 kyu, 6 kyu, 5 kyu, 4 kyu, 3 kyu, 2 kyu, 1 kyu. I completed 60 problems in the 8 kyu - 4 kyu range and every level felt a little more difficult than the last, which aligned with my expectations.&lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;&lt;a rel="nofollow" href="https://adventofcode.com/"&gt;Advent of Code&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;Advent of Code is totally language-agnostic. This would seem like a minus at first but seeing how horribly HackerRank, LeetCode, and Codewars handle their support for Rust on their sites it's actually a plus. Advent of Code also gets placed above the previously mentioned sites because AoC's exercises are really interesting, diverse, and high quality in my opinion.&lt;/p&gt; &lt;p&gt;General AoC issues:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;After you finish an exercise there's no way to see other people's Rust solutions unless you search from them on Google, and even after you find some there's no telling how good or idiomatic they are.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;To solve the above issue I recommend going through the 2018 Calendar problems and comparing your solutions to &lt;a href="https://github.com/BurntSushi/advent-of-code"&gt;BurntSushi's AoC 2018 Rust solutions&lt;/a&gt;. BurntSushi writes really clean, readable, idiomatic Rust code. If you want to go through the 2019 Calendar then I recommend comparing your solutions to &lt;a href="https://github.com/bcmyers/aoc2019"&gt;bcmyers' AoC 2019 Rust solutions&lt;/a&gt;. The reason I specifically suggest bcmyers' is because he made a &lt;a rel="nofollow" href="https://www.youtube.com/playlist?list=PLQXBtq4j4Ozkx3r4eoMstdkkOG98qpBfg"&gt;youtube playlist of him coding up the solutions&lt;/a&gt; and he does a great job of explaining his thought process and why he's doing what he's doing while he's coding.&lt;/p&gt; &lt;p&gt;Things AoC got right:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;High quality, interesting, curated exercises that are tied together with a narrative.&lt;/li&gt; &lt;li&gt;Language agnostic, so while it doesn't teach you any Rust patterns it at least doesn't teach you any Rust anti-patterns either.&lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;&lt;a href="https://github.com/rust-lang/rustlings"&gt;Rustlings&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;Rustlings is sooo good. All Rustlings exercises are hand-crafted for Rust with love and it's a wonderful breath of fresh air. Finally, a set of exercises that really teach you idiomatic Rust!&lt;/p&gt; &lt;p&gt;If you're a total Rust newbie you should absolutely checkout &lt;a href="https://github.com/rust-lang/rustlings"&gt;Rustlings&lt;/a&gt; and get started on the exercises. I highly recommend reading fasterthanlime's &lt;a rel="nofollow" href="https://fasterthanli.me/blog/2020/a-half-hour-to-learn-rust/"&gt;A half-hour to learn Rust&lt;/a&gt; first as it'll get you up to speed on a lot of Rust syntax and concepts super quickly.&lt;/p&gt; &lt;p&gt;I have only 1 tiny Rustlings criticism: there are some sudden difficulty spikes in the "error-handling" and "conversions" exercises that I could see some users getting overwhelmed by. I assume most probably make it through, or at least I hope.&lt;/p&gt; &lt;p&gt;I also have 1 tiny non-criticism: it's too short. This is a non-criticism because it's one of Rustlings design goals to be a quick and gentle introduction to Rust but it's so good that of course I wish it was somehow longer.&lt;/p&gt; &lt;h3&gt;&lt;a rel="nofollow" href="https://exercism.io/tracks/rust"&gt;Exercism&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;Exercism has a Rust track, which is a collection of exercises roughly ordered by subject and difficulty. The Rust track shares a lot of exercises in common with other tracks, but all of the exercises were translated to Rust by experienced Rustaceans and don't suffer from any of the awkward unidiomatic Rust issues that are common on LeetCode and Codewars. There are about a dozen Rust-specific problems that require you to implement a standard library trait, or write a macro, or write a parallel solution using multiple threads, or write unsafe Rust code. These exercises are by far the highlights of the track and I wish there were more of them. Exercism is second only to Rustlings as a resource for learning Rust. The only reason I placed it above Rustlings is Rustlings can be completed in an evening and Exercism's Rust track will take at least a month to complete so it just has a lot more content.&lt;/p&gt; &lt;p&gt;Exercism issues, specific to the Rust track:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;"Mentored mode" is useless, as most of the Rust mentors on the site are inactive, and the students heavily outnumber them, so it's much better to go through a track in "practice mode".&lt;/li&gt; &lt;li&gt;There are 92 exercises but a good chunk of them don't really teach you anything new so they kinda feel like busywork. They could probably cut ~20 exercises from the track to make it feel a lot tighter.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Things Exercism does right:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;All problems are translated to Rust or written for Rust by experienced Rustaceans.&lt;/li&gt; &lt;li&gt;There are problems which specifically teach Rust's idioms, design patterns, and unique features.&lt;/li&gt; &lt;li&gt;Problem difficulties are fairly graded, easy problems are easy, medium problems are medium, hard problems are hard.&lt;/li&gt; &lt;li&gt;You can include whatever 3rd-party dependencies that you want in your solutions.&lt;/li&gt; &lt;li&gt;All unit tests are public, if you're failing a test you know exactly why.&lt;/li&gt; &lt;li&gt;After you submit a solution you can browse other user's solutions, and you can sort solutions by which received the most stars.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;Same as the &lt;a href="#tldr"&gt;TL;DR&lt;/a&gt; :)&lt;/p&gt; &lt;h2&gt;Discuss&lt;/h2&gt; &lt;p&gt;Discuss this article on&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a rel="nofollow" href="https://www.reddit.com/r/learnrust/comments/ggj8tf/learning_rust_in_2020/"&gt;learnrust subreddit&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a rel="nofollow" href="https://users.rust-lang.org/t/blog-post-learning-rust-in-2020/42373"&gt;official Rust users forum&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a rel="nofollow" href="https://twitter.com/pretzelhammer/status/1259897499122360322"&gt;Twitter&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a rel="nofollow" href="https://www.reddit.com/r/rust/comments/gie64f/learning_rust_in_2020/"&gt;rust subreddit&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a rel="nofollow" href="https://news.ycombinator.com/item?id=23160975"&gt;Hackernews&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/pretzelhammer/rust-blog/discussions"&gt;Github&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Notifications&lt;/h2&gt; &lt;p&gt;Get notified when the next blog post get published by&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a rel="nofollow" href="https://twitter.com/pretzelhammer"&gt;Following pretzelhammer on Twitter&lt;/a&gt; or&lt;/li&gt; &lt;li&gt;Watching this repo's releases (click &lt;code&gt;Watch&lt;/code&gt; -&amp;gt; click &lt;code&gt;Custom&lt;/code&gt; -&amp;gt; select &lt;code&gt;Releases&lt;/code&gt; -&amp;gt; click &lt;code&gt;Apply&lt;/code&gt;)&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Further Reading&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://github.com/pretzelhammer/rust-blog/blob/master/posts/common-rust-lifetime-misconceptions.md"&gt;Common Rust Lifetime Misconceptions&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/pretzelhammer/rust-blog/blob/master/posts/sizedness-in-rust.md"&gt;Sizedness in Rust&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/pretzelhammer/rust-blog/blob/master/posts/too-many-brainfuck-compilers.md"&gt;Learn Assembly with Entirely Too Many Brainfuck Compilers&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/article&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://github.com/pretzelhammer/rust-blog/blob/master/posts/learning-rust-in-2020.md"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 12 May 2020 19:14:43 UT
      </pubDate>
      <guid>
        https://github.com/pretzelhammer/rust-blog/blob/master/posts/learning-rust-in-2020.md
      </guid>
    </item>
    <item>
      <title>
        Work 2.0 - the interruptible programmer &amp;middot; SteveStreeting.com
      </title>
      <link>
        https://www.stevestreeting.com/2010/09/04/work-2-0/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt; &lt;p&gt;I’m 37, and I’ve been a (professional) developer for 16 years. You would have thought that in that time, I’d have figured out an effective work style which delivered the desired outcomes (code cut, products shipped etc) without causing detrimental knock-on effects - but, sadly, you’d be wrong. I think the&amp;nbsp;style in which I practiced my craft for the first 15 years of my career was much the same as every other enthusiastic developer: you put a &lt;strong&gt;ton&lt;/strong&gt; of hours in. 12-16+ hour days, evening and weekend coding marathons, pizza in the keyboard, crunch times, 3am debugging sessions where you just can’t go to bed because you can &lt;em&gt;feel the source of that bug just beyond your fingertips, dammit,&lt;/em&gt; desperate last-minute sprints to deadlines where you manage to slot that last piece in, Jack Bauer-like, just before the world goes to hell. If you’re in the demographic I’m talking about, you’re nodding sagely, and probably grinning a little too, reminiscing on past trials and glories. This sort of crazy dedication is respected in our circles, and is pretty much expected of any developer who has claimed to earn their stripes.&lt;/p&gt; &lt;p&gt;But, it turns out this kind of thing is not good for your health - who knew? Those of you who know me or keep up with my blog know that I’ve been dragged kicking and screaming away from my old ways, because of back issues that I initially ignored, then tried to cope with using token accommodations, and finally succumbed to in a big way. Being self-employed, this was a major problem. Crawling out of the pit I dug for myself took a long time and a lot of frustration - I read quite a few productivity books on the subject to try to find answers on how to keep working, and in the end found that the answers you mould for yourself tend to be the best ones. I’d like to share one of the things I learned along the way.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;But I’m ‘In The Zone’!!&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;So, I want to talk about the biggest problem I encountered: concentration periods. I can’t sit at a desk for longer than about an hour at a time now; if I don’t get up and walk around, do some gentle stretching etc, at least this often, I’ll pay for it badly once I do move, and probably over the next few days too. I also can’t realistically work more than a standard 8 hour day without pain any more. The problem with this was that, as a programmer, the&amp;nbsp;style which I developed over 15+ years involved getting gradually ‘Into The Zone’ and coding for very long periods at a time, uninterrupted. This is a common theme among coders, who like to shut themselves away for hours at a time, wear headphones to avoid distractions, have ‘quiet times’ and so on - and it’s also why we tend to react really badly when interrupted. Programming requires concentration, and concentration seems to run on a valve system - it takes time to warm up, and once it’s going, you don’t want to turn it off because starting it up again is a major hassle.&lt;/p&gt; &lt;p&gt;I thought there was no way around this, and had begun to resign myself to just being less productive because of it. However, over the last 6 &amp;nbsp;months in particular, I’ve discovered that, far from being an intractable problem, this ‘slow warm up, long uninterrupted focus time’ approach is to a large degree a learned behaviour, and it’s possible to re-train yourself to cope with things differently. It’s a little like when people learn to adopt&amp;nbsp;&lt;a href="http://www.everything2.com/index.pl?node_id=892542"&gt;polyphasic sleep patterns&lt;/a&gt; - it’s not that you can’t do it, it’s just that when you’ve become accustomed to doing things a certain way, changing that is initially very, very hard. But it’s not impossible, given the right amount of motivation and time to adjust.&lt;/p&gt; &lt;p&gt;So, my goal was to acclimatise myself to many shorter work chunks during the day instead of a few very large ones, while still maintaining productivity. The key to this was to learn how to get back ‘In The Zone’ in the shortest time possible - much like the way polyphasic sleepers train themselves to achieve REM sleep more quickly. I’m mostly there now, or at least way better at it than I was, so, what techniques did I use to make this transition?&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;&lt;strong&gt;Embrace interruptions&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;This is less of a technique and more of a deliberate psychological adjustment which cuts across all the practical approaches I’ll cover next. Instead of being the typical coder who avoids&amp;nbsp;interruptions at all costs, you need to accept them, and learn to manage them better. It’s hard - you have to try to set aside years of resisting interruptions and initially, until you adjust, you’ll feel like you can’t get enough done. Many people will probably want to give up, unless there’s something specific motivating them to push through it - for me, daily pain was a great motivator. My main message here is that the transition is just a phase, and that it &lt;strong&gt;is&lt;/strong&gt; possible to be an interruptable programmer who still gets things done. But you have to learn not to fight against it, hence why this is the first point.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;strong&gt;Maintain context outside of your head at all times&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Much of the problem with interruptions is that of losing context. When you’re in that Zone, you’re juggling a whole bunch of context in your head, adjusting it on the fly, and maintaining and tweaking connections between issues constantly. Interruptions make you drop all that, and it takes time to pick it all up again. My answer to this was to externalise as much as possible, on as many levels as possible:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;**Maintain a running commentary on your current task&lt;/p&gt; &lt;p&gt;&lt;span&gt;I am my very own chronicler. &lt;/span&gt;** I write notes on what I’m doing all the time, whether it’s adding a comment line to a ticket, committing frequently and writing detailed commit notes (you do use a DVCS to make light commits more practical, right? ;)) scribbling a drawing on (ordered) pieces of paper. This really isn’t that onerous, and in fact externalising your thoughts can often help you clarify them. Basically the guide is that roughly every 30 minutes, I should have generated some new piece of context which is stored somewhere other than my head. If I haven’t, then that’s context I’d have more trouble re-building mentally if I’m interrupted. It doesn’t take much time to do, and it has other benefits too such as recording your thought &amp;amp; decision process.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;**Ruthlessly ignore tangental issues&lt;/p&gt; &lt;p&gt;&lt;span&gt;You might have noticed that in the last bullet, I used the words ‘current task’, &lt;em&gt;singular&lt;/em&gt;. Not ‘tasks’. There is no such thing as having more than one ‘current task’ - there is only the one task you’re actually working on, and &lt;em&gt;distractions&lt;/em&gt;.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;We probably all use bug trackers / ticket systems to track bugs and feature requests, but when you’re working on a ticket, it’s very common to spot a new bug, or identify an opportunity for improvement, or think of a cool new feature. How many of us go ahead and deal with that right away, because it’s in the area we’re already in, or it’s ‘trivial’, or it’s a cool idea that you want to try right now? &amp;nbsp;I know I did - but I don’t any more; any tangental issues not related to what I’m currently doing get dumped into the ticket system and immediately forgotten until I’m done with the current task, regardless of their size, relevance or priority.&amp;nbsp;It sounds simple and obvious, and this might even be official procedure in your organisation, but I challenge most coders to say that they actually do this all the time. The benefit is that even the tiniest of distractions add an extra level of context that you have to maintain, which is then harder to pick up again after an interruption.&lt;br&gt; For this to work, you need a ticket system which is fast, lightweight, and doesn’t require you to be anal about how much detail you put in initially. You need to be in &amp;amp; out of there in 30 seconds so you can offload that thought without getting distracted - you can flesh it out later. &lt;/span&gt;**&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;Always know what you’re doing next&lt;/strong&gt;&lt;br&gt; This is one from GTD (‘Next actions’), but it’s a good one. When you come back from a break or interruption, you should spend no time at all figuring out what you need to be doing next. Your ticket system will help you here, and so will the running commentary that hopefully you’ve been keeping on your active task. If you’ve been forced to switch gears or projects, so long as you’ve maintained this external context universally, you should have no issue knowing what the next actions on each item are. The important thing is to have &lt;em&gt;one&lt;/em&gt; next action on each project. If you have several, you’ll have to spend time choosing between them, and that’s wasted time (see the next section on prioritisation). At any one time, you should not only have just one current task, but &lt;em&gt;one&lt;/em&gt; unambiguous next action on that task. Half the problem of working effectively is knowing what you’re doing next.&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt; &lt;/ol&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;strong&gt;Prioritise Negatively&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;I mentioned next actions in the previous section, but how do you decide what comes next? A lot of time can be frittered away agonising over priorities, and I used to struggle with it; I would plan on the assumption that I wanted to do everything on the list, and I just needed to figure out which I needed to do first. I discovered that I could cut the amount of time I spent on planning, and also get better, less ambiguous priorities by inverting the decision making process - to assume a baseline that I wouldn’t do &lt;em&gt;any&lt;/em&gt; of the tasks, and assessing the negative outcomes of&amp;nbsp;&lt;em&gt;not&lt;/em&gt; doing each one. So instead of ‘which of feature A or B is more important to have?’, it became ‘Let’s assume we ship without feature A and B. What are the issues caused by omitting them in each case?’. It might appear to be a subtle difference, but having to justify inclusion entirely, rather than trying to establish a relative ordering assuming they all get done eventually, tends to tease out more frank evaluations in my experience.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;strong&gt;Recognise the benefits of breaks&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Much of the above is about limiting the negative aspects of taking breaks, but the fact is, that they have many work-related benefits too. I’m willing to bet that all coders have stayed late at work, or late into the night, trying to fix a problem, only to find that they fix it within 15 minutes the next day, or think of the answer in some unlikely place like the shower. The reason for this is very simple - extended periods of concentration seem productive, and can be on operational / sequential thinking, but for anything else such as creative thinking or problem solving, it’s very often exactly the opposite. Not only do tired minds think less clearly, but often the answer to a problem lies not in more extensive thinking down the current path which you’ve been exploring in vain for the last few hours, but in looking at the problem from a completely different perspective. Long periods of concentration tend to ‘lock in’ current trains of thought, making inspiration and strokes of genius all too rare. Creativity always happens when you’re not trying, and it’s an often under-appreciated but vital element of the programming toolbox. Interrupting that train of thought can actually be a very good thing indeed.&lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;There’s more I could talk about, but that’s quite enough for now I think. I hope someone finds this interesting or useful 😀&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://www.stevestreeting.com/2010/09/04/work-2-0/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Thu, 14 May 2020 00:05:39 UT
      </pubDate>
      <guid>
        https://www.stevestreeting.com/2010/09/04/work-2-0/
      </guid>
    </item>
    <item>
      <title>
        Stop Trying to Make Hard Work Easy - Superorganizers - Every
      </title>
      <link>
        https://superorganizers.substack.com/p/stop-trying-to-make-hard-work-easy
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt; &lt;div&gt; &lt;p&gt;&lt;a href="https://superorganizers.substack.com/"&gt; &lt;img src="https://every.to/assets/every-logo-b75354dcdc13d1d15c92a2c92b5f3b02dbcaaf13d271b12afae101e7bee2c98c.svg"&gt; &lt;/a&gt;&lt;/p&gt; &lt;div&gt; &lt;div&gt; &lt;p&gt;&lt;a href="https://superorganizers.substack.com/subscribe"&gt;Subscribe&lt;/a&gt; &lt;/p&gt;&lt;/div&gt; &lt;div&gt; &lt;p&gt;≡&lt;/p&gt; &lt;div&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://superorganizers.substack.com/about"&gt;About&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://superorganizers.substack.com/letter"&gt;Founders‘ Letter&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://superorganizers.substack.com/publications"&gt;Our Publications&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://superorganizers.substack.com/collections"&gt;Collections&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://superorganizers.substack.com/write"&gt;Write With Us&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://superorganizers.substack.com/cdn-cgi/l/email-protection#3f575a5353507f5a495a4d46114b50"&gt;Contact Us&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://superorganizers.substack.com/login"&gt;Login&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div&gt; &lt;div&gt; &lt;div&gt; &lt;p&gt;&lt;a href="https://superorganizers.substack.com/superorganizers"&gt; &lt;img src="https://d24ovhgu8s7341.cloudfront.net/uploads/publication/logo/4/small_EVERY_SUPERORGANIZERS.png"&gt; &lt;span&gt;Superorganizers&lt;/span&gt; &lt;/a&gt; &lt;/p&gt;&lt;/div&gt; &lt;div&gt; &lt;p&gt;Nir Eyal, author of Indistractable, explains how to cope even when work is hard.&lt;/p&gt; &lt;div&gt; &lt;p&gt;May 5, 2020&lt;/p&gt; &lt;p&gt;&lt;span&gt;♥ 1&lt;/span&gt; &lt;/p&gt;&lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div data-post-id="1026" id="feedback-box"&gt; &lt;div&gt; &lt;h4&gt;What did you think of this post?&lt;/h4&gt; &lt;div&gt; &lt;p&gt;&lt;a href="#" data-rating="amazing"&gt;Amazing&lt;/a&gt; &lt;a href="#" data-rating="good"&gt;Good&lt;/a&gt; &lt;a href="#" data-rating="meh"&gt;Meh&lt;/a&gt; &lt;a href="#" data-rating="bad"&gt;Bad&lt;/a&gt; &lt;/p&gt;&lt;/div&gt; &lt;/div&gt; &lt;div&gt; &lt;p&gt; You need to &lt;a href="https://superorganizers.substack.com/login"&gt;login&lt;/a&gt; before you can leave your feedback.&lt;br&gt; Don't have an account? &lt;a href="https://superorganizers.substack.com/subscribe"&gt;Sign up!&lt;/a&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div&gt; &lt;h3&gt;Like this?&lt;br&gt;Become a subscriber.&lt;/h3&gt; &lt;p&gt;&lt;a href="https://superorganizers.substack.com/subscribe"&gt;Subscribe →&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Or, &lt;a href="https://superorganizers.substack.com/"&gt;learn more&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div id="comments-box"&gt; &lt;h2&gt;Comments&lt;/h2&gt; &lt;div&gt; &lt;p&gt;&lt;img height="40" width="40" src="https://superorganizers.substack.com/assets/fallback/user-cce04c6651b9d1bdfd37301d7541c98e1e35ddc0624912f1bf3682c1761e3b13.png"&gt; &lt;/p&gt; &lt;/div&gt; &lt;div&gt; &lt;p&gt;&lt;img height="40" width="40" src="https://superorganizers.substack.com/assets/fallback/user-cce04c6651b9d1bdfd37301d7541c98e1e35ddc0624912f1bf3682c1761e3b13.png"&gt; &lt;/p&gt; &lt;/div&gt; &lt;p&gt; You need to &lt;a href="https://superorganizers.substack.com/login"&gt;login&lt;/a&gt; before you can comment.&lt;br&gt; Don't have an account? &lt;a href="https://superorganizers.substack.com/subscribe"&gt;Sign up!&lt;/a&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://superorganizers.substack.com/p/stop-trying-to-make-hard-work-easy"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Thu, 14 May 2020 00:06:05 UT
      </pubDate>
      <guid>
        https://superorganizers.substack.com/p/stop-trying-to-make-hard-work-easy
      </guid>
    </item>
    <item>
      <title>
        Tips for Founders Sales: Lessons From Starting Two B2B Startups &amp;#8211; Phil Strazzulla&amp;#039;s Blog
      </title>
      <link>
        http://philstrazzulla.com/2020/04/06/tips-for-founders-sales-lessons-from-starting-two-b2b-startups/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div id="content"&gt; &lt;main role="main" id="main"&gt; &lt;article id="post-584"&gt; &lt;div&gt; &lt;p&gt;Thus far I’ve founded two bootstrapped B2B startups, and led sales on both.&amp;nbsp; One is off to the races, profitable, and growing.&amp;nbsp; We even hired a general manager so that I can free myself up to work on other projects.&amp;nbsp; The &lt;a href="http://selectsoftwarereviews.com/"&gt;other&lt;/a&gt; is slightly more nascent, and just barely at ramen profitability.&lt;/p&gt; &lt;p&gt;It’s really hard to get started with founder led selling.&amp;nbsp; I’m a (slight) introvert, and had basically no sales experience before starting my first business.&amp;nbsp; While I have a business mind, and an MBA in addition to my programming skills, it was still very challenging for me to get started.&lt;/p&gt; &lt;p&gt;I used to view sales as this dark art that I could never master.&amp;nbsp; I’m not “salesy.”&amp;nbsp; I’m much more of a steak than sizzle person.&amp;nbsp; I’m too honest.&amp;nbsp; I don’t look, talk or act like the various stereotypes of a sales person.&amp;nbsp; And so, I thought it was basically unattainable for me to be successful with sales for the first year of my first business.&lt;/p&gt; &lt;p&gt;I’m proud to say that through a lot of struggle and learning, I’ve actually become a decent sales person.&amp;nbsp; For whatever I lacked in initial extroversion and unblended confidence, I make up for in understanding of strategy and product.&amp;nbsp; I’m even fairly confident I could hit quota for any post product/market fit b2b SaaS startup out there.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;What I’ve learned about b2b founder sales&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;It’s been nearly five years now since I started the first business.&amp;nbsp; As a result, I get introduced to other founders every month or two who are starting to sell their products and want advice.&amp;nbsp; Coming out of these conversations, I find myself repeating the same themes.&lt;/p&gt; &lt;p&gt;So, in no particular order, here’s my advice when starting to do B2B sales at your startup:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Find a sales mentor who’s done pre-product/market fit selling before.&amp;nbsp; It’s essential that someone has done the selling at the earliest stages of a company’s lifecycle.&amp;nbsp; Even someone who led sales at a Series A company won’t have the proper mindset or experience to help you through this.&amp;nbsp; Ideally, it’s another founder who’s been through it, and actually done the selling vs the strategy behind sales.&amp;nbsp; Another bonus is if they’ve sold to the exact customer persona you’re trying to reach.&lt;/li&gt;&lt;li&gt;Network with account executives who sell into a similar persona.&amp;nbsp; Ask them to walk you through their entire sales process, from initial outreach to demo.&amp;nbsp; Give them your sales pitch, and listen to their feedback.&amp;nbsp; You’ll get good practice demo’ing, and some advice.&amp;nbsp; However, you should realize that most sales reps selling a post product/market fit product will have very little understanding of why someone buys their product, that’s really up to you to figure out.&lt;/li&gt;&lt;li&gt;Record your first 50 demos and listen to them each within 24 hours of the pitch.&amp;nbsp; You will start to make small adjustments in messaging, in how long you answer questions, etc.&amp;nbsp; Be your own coach and try to look objectively at your pitch.&lt;/li&gt;&lt;li&gt;Ask for demos for software you are thinking about buying.&amp;nbsp; Think about what the sales reps do well, and what they don’t do well.&amp;nbsp; Mainly do this because you will realize 90% of sales reps are pretty mediocre. They don’t show up on time.&amp;nbsp; They ramble. They don’t do any research.&amp;nbsp; They are too aggressive.&amp;nbsp; You can be 10x better than they are as a sales person, even if you’ve never sold before.&amp;nbsp; And, you’ll have to be to get started without a brand, and a product that is probably half complete.&lt;/li&gt;&lt;li&gt;Ask sales people you admire what books and blogs they read.&amp;nbsp; My recommendations: &lt;a href="https://firstround.com/review/sales/"&gt;FirstRound Review&lt;/a&gt;’s articles, this &lt;a href="https://docs.google.com/document/d/1ZHCSm5yUAGhdpDH9VFTPS271LZ-RgF3YHkvZQePxGnM/edit"&gt;book&lt;/a&gt; on founding sales, and the &lt;a href="https://www.amazon.com/Challenger-Sale-Control-Customer-Conversation/dp/1591844355"&gt;Challenger Sale&lt;/a&gt; are good places to start.&amp;nbsp; There is also a &lt;a href="https://www.instagram.com/corporate.bro/?hl=en"&gt;hilarious instagram&lt;/a&gt; account you will start empathizing with.&lt;/li&gt;&lt;li&gt;Spend as much time in person with your prospects as possible.&amp;nbsp; That means demos, as well as conferences, dinners, coffee, whatever you can.&amp;nbsp; This will allow you to build trust, and learn a lot faster about your customer than doing calls or even video calls. Working out of one of their offices side by side is a great way to hear how they talk, what they care about, etc. This is great for product development, and even better for sales.&lt;/li&gt;&lt;li&gt;Sales calls will probably become the most important way you will get feedback on your product in the next 6-18 months.&amp;nbsp; Keep track of the themes you hear, and start to think about how you can build those into your offering / start charging for them. Record the closed/lost reasons for no-sale in a structured way so you can see what % fell out of the funnel due to pricing, competitors, etc.&lt;/li&gt;&lt;li&gt;Sales can be a grind.&amp;nbsp; I used to get nervous before calls, and found that creating a routine pre-demo really helped – jumping jacks, review the script, and believe that the product I’m offering will help the person on the other end of the phone.&amp;nbsp; You also need to let go of any ego or expectations of being treated like a human being. &amp;nbsp;Most people view sales people as a nuisance.&amp;nbsp; You will get let down a lot by your prospects every single day, but that makes the wins so much sweeter.&amp;nbsp; Plus, it’s a thing that happens to everyone, not just you.&lt;/li&gt;&lt;li&gt;It’s going to take you a few months to make your first sales (assuming your product is &amp;gt;$1k/yr).&amp;nbsp; Don’t get discouraged.&amp;nbsp; Don’t think “we need to change the pitch/outreach/etc.”&amp;nbsp; If you’ve been thoughtful about your process from the get-go, just keep building your pipeline.&lt;/li&gt;&lt;li&gt;Celebrate the wins.&amp;nbsp; I’m so bad at this and have some sort of Catholic guilt about it.&amp;nbsp; When someone says “yes” – celebrate.&amp;nbsp; When someone signs the contract – celebrate.&amp;nbsp; When someone goes live – celebrate. &amp;nbsp;High five your co-founder.&amp;nbsp; Get a beer after work.&amp;nbsp;&amp;nbsp; Tell your significant other.&amp;nbsp; Enjoy the moment and pat yourself on your back.&lt;/li&gt;&lt;/ul&gt; &lt;p&gt;There are a million nuances to sales.&amp;nbsp; My &lt;a href="http://nextwavehire.com/"&gt;first&lt;/a&gt; business was straight B2B SaaS where we were selling HR a product to help with their recruiting.&amp;nbsp; Getting headspace was tough.&amp;nbsp; Getting budget was tough.&amp;nbsp; Getting them to think about their job in a new way was tough.&lt;/p&gt; &lt;p&gt;In my &lt;a href="https://selectsoftwarereviews.com/"&gt;new business&lt;/a&gt;, I’m selling to marketing.&amp;nbsp; It’s a completely different buyer that has more budget and is more likely to experiment with new products.&amp;nbsp; I also have an advantage in that I’m putting reviews of their software online, which means they care a lot more than if I was selling them a tool they can ignore.&amp;nbsp; This allows me to cut through the noise more effectively.&amp;nbsp; Of course, it comes with many other challenges, and some I haven’t even run into yet.&lt;/p&gt; &lt;p&gt;I hope you enjoy your journey to becoming an A+ sales person, which is a very attainable goal for any founder.&amp;nbsp; My journey has helped me build win new business, think deeper about product, and kickstarted my personal branding efforts.&amp;nbsp; &lt;/p&gt; &lt;p&gt;Good luck, and feel free to &lt;a href="http://twitter.com/philstrazzulla"&gt;connect&lt;/a&gt; if I can be helpful in your journey!&lt;/p&gt; &lt;/div&gt; &lt;/article&gt; &lt;/main&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="http://philstrazzulla.com/2020/04/06/tips-for-founders-sales-lessons-from-starting-two-b2b-startups/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 19 May 2020 10:14:38 UT
      </pubDate>
      <guid>
        http://philstrazzulla.com/2020/04/06/tips-for-founders-sales-lessons-from-starting-two-b2b-startups/
      </guid>
    </item>
    <item>
      <title>
        Diving into Go by building a CLI application | Eryb's Space
      </title>
      <link>
        https://eryb.space/2020/05/27/diving-into-go-by-building-a-cli-application.html
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;article&gt; &lt;p&gt;&lt;a href="https://howtorecover.me/pogruzhenie-v-go-putem-sozdaniya-prilozheniya-cli"&gt;Russian Version&lt;/a&gt;&lt;/p&gt; &lt;p&gt;You have wrapped your head around the Go syntax and practised them one by one, however you won’t feel comfortable writing applications in Go unless you build one.&lt;/p&gt; &lt;p&gt;In this blog post we’ll build a CLI application in Go, which we’ll call &lt;strong&gt;go-grab-xkcd&lt;/strong&gt;. This application fetches comics from &lt;a href="https://xkcd.com/"&gt;XKCD&lt;/a&gt; and provides you with various options through command-line arguments.&lt;/p&gt; &lt;p&gt;We’ll use no external dependencies and will build the entire app using only the Go standard library.&lt;/p&gt; &lt;p&gt;The application idea looks silly but the aim is to get comfortable writing production (sort of) code in Go and not to get acquired by Google.&lt;/p&gt; &lt;h6 id="there-is-also-a-bash-bonus-at-the-end"&gt;There is also a Bash Bonus at the end.&lt;/h6&gt; &lt;p&gt;&lt;em&gt;Note: This post assumes that the reader is familiar with Go syntax and terminologies and is somewhere between a beginner and an intermediate.&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Let’s first run the application and see it in action-&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;$ &lt;/span&gt;go-grab-xkcd &lt;span&gt;--help&lt;/span&gt; Usage of go-grab-xkcd: &lt;span&gt;-n&lt;/span&gt; int Comic number to fetch &lt;span&gt;(&lt;/span&gt;default latest&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-o&lt;/span&gt; string Print output &lt;span&gt;in &lt;/span&gt;format: text/json &lt;span&gt;(&lt;/span&gt;default &lt;span&gt;"text"&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-s&lt;/span&gt; Save image to current directory &lt;span&gt;-t&lt;/span&gt; int Client &lt;span&gt;timeout &lt;/span&gt;&lt;span&gt;in &lt;/span&gt;seconds &lt;span&gt;(&lt;/span&gt;default 30&lt;span&gt;)&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;$ &lt;/span&gt;go-grab-xkcd &lt;span&gt;-n&lt;/span&gt; 323 Title: Ballmer Peak Comic No: 323 Date: 1-10-2007 Description: Apple uses automated schnapps IVs. Image: https://imgs.xkcd.com/comics/ballmer_peak.png &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;$ &lt;/span&gt;go-grab-xkcd &lt;span&gt;-n&lt;/span&gt; 323 &lt;span&gt;-o&lt;/span&gt; json &lt;span&gt;{&lt;/span&gt; &lt;span&gt;"title"&lt;/span&gt;: &lt;span&gt;"Ballmer Peak"&lt;/span&gt;, &lt;span&gt;"number"&lt;/span&gt;: 323, &lt;span&gt;"date"&lt;/span&gt;: &lt;span&gt;"1-10-2007"&lt;/span&gt;, &lt;span&gt;"description"&lt;/span&gt;: &lt;span&gt;"Apple uses automated schnapps IVs."&lt;/span&gt;, &lt;span&gt;"image"&lt;/span&gt;: &lt;span&gt;"https://imgs.xkcd.com/comics/ballmer_peak.png"&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;You can try rest of the options by downloading and running the application for your computer.&lt;/p&gt; &lt;p&gt;After the end of this tutorial you’ll be comfortable with the following topics-&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Accepting command line arguments&lt;/li&gt; &lt;li&gt;Interconversion between JSON and Go Structs&lt;/li&gt; &lt;li&gt;Making API calls&lt;/li&gt; &lt;li&gt;Creating files (Downloading and saving from Internet)&lt;/li&gt; &lt;li&gt;String Manipulation&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Below is the project structure-&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;$ &lt;/span&gt;tree go-grab-xkcd go-grab-xkcd ├── client │ └── xkcd.go └── model └── comic.go ├── main.go └── go.mod &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;go.mod&lt;/code&gt; - &lt;em&gt;Go Modules&lt;/em&gt; file used in Go for package management&lt;/li&gt; &lt;li&gt;&lt;code&gt;main.go&lt;/code&gt; - Main entrypoint of the application&lt;/li&gt; &lt;li&gt;&lt;code&gt;comic.go&lt;/code&gt; - Go representation of the data as a &lt;code&gt;struct&lt;/code&gt; and operations on it&lt;/li&gt; &lt;li&gt;&lt;code&gt;xkcd.go&lt;/code&gt; - xkcd client for making HTTP calls to the API, parsing response and saving to disk&lt;/li&gt; &lt;/ul&gt; &lt;h2 id="1-initialize-the-project"&gt;1: Initialize the project&lt;/h2&gt; &lt;p&gt;Create a &lt;code&gt;go.mod&lt;/code&gt; file-&lt;/p&gt; &lt;p&gt;This will help in package management (think package.json in JS).&lt;/p&gt; &lt;h2 id="2-xkcd-api"&gt;2: xkcd API&lt;/h2&gt; &lt;p&gt;xkcd is amazing, you don’t require any signups or access keys to use their API. Open the xkcd &lt;a href="https://xkcd.com/json.html"&gt;API “documentation”&lt;/a&gt; and you’ll find that there are 2 endpoints-&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;code&gt;http://xkcd.com/info.0.json&lt;/code&gt; - GET latest comic&lt;/li&gt; &lt;li&gt;&lt;code&gt;http://xkcd.com/614/info.0.json&lt;/code&gt; - GET specific comic by comic number&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Following is the JSON response from these endpoints-&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;{&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;"num"&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;2311&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;"month"&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;"5"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;"day"&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;"25"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;"year"&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;"2020"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;"title"&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;"Confidence Interval"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;"alt"&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;"The worst part is that's the millisigma interval."&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;"img"&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;"https://imgs.xkcd.com/comics/confidence_interval.png"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;"safe_title"&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;"Confidence Interval"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;"link"&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;""&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;"news"&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;""&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;"transcript"&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;""&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;}&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;Relevant &lt;a href="https://xkcd.com/1481/"&gt;xkcd&lt;/a&gt;&lt;/p&gt; &lt;h2 id="2-create-model-for-the-comic"&gt;2: Create model for the Comic&lt;/h2&gt; &lt;p&gt;Based on the above JSON response, we create a &lt;code&gt;struct&lt;/code&gt; called &lt;code&gt;ComicResponse&lt;/code&gt; in &lt;code&gt;comic.go&lt;/code&gt; inside the &lt;code&gt;model&lt;/code&gt; package&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;type&lt;/span&gt; &lt;span&gt;ComicResponse&lt;/span&gt; &lt;span&gt;struct&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;Month&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; &lt;span&gt;`json:"month"`&lt;/span&gt; &lt;span&gt;Num&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; &lt;span&gt;`json:"num"`&lt;/span&gt; &lt;span&gt;Link&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; &lt;span&gt;`json:"link"`&lt;/span&gt; &lt;span&gt;Year&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; &lt;span&gt;`json:"year"`&lt;/span&gt; &lt;span&gt;News&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; &lt;span&gt;`json:"news"`&lt;/span&gt; &lt;span&gt;SafeTitle&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; &lt;span&gt;`json:"safe_title"`&lt;/span&gt; &lt;span&gt;Transcript&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; &lt;span&gt;`json:"transcript"`&lt;/span&gt; &lt;span&gt;Alt&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; &lt;span&gt;`json:"alt"`&lt;/span&gt; &lt;span&gt;Img&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; &lt;span&gt;`json:"img"`&lt;/span&gt; &lt;span&gt;Title&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; &lt;span&gt;`json:"title"`&lt;/span&gt; &lt;span&gt;Day&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; &lt;span&gt;`json:"day"`&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;You can use the &lt;a href="https://mholt.github.io/json-to-go/"&gt;JSON-to-Go&lt;/a&gt; tool to automatically generate the struct from JSON.&lt;/p&gt; &lt;p&gt;Also create another struct which will be used to output data from our application.&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;type&lt;/span&gt; &lt;span&gt;Comic&lt;/span&gt; &lt;span&gt;struct&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;Title&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; &lt;span&gt;`json:"title"`&lt;/span&gt; &lt;span&gt;Number&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; &lt;span&gt;`json:"number"`&lt;/span&gt; &lt;span&gt;Date&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; &lt;span&gt;`json:"date"`&lt;/span&gt; &lt;span&gt;Description&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; &lt;span&gt;`json:"description"`&lt;/span&gt; &lt;span&gt;Image&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; &lt;span&gt;`json:"image"`&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;Add the below two methods to &lt;code&gt;ComicResponse&lt;/code&gt; struct-&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;// FormattedDate formats individual date elements into a single string&lt;/span&gt; &lt;span&gt;func&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;cr&lt;/span&gt; &lt;span&gt;ComicResponse&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;FormattedDate&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;fmt&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Sprintf&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"%s-%s-%s"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;cr&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Day&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;cr&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Month&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;cr&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Year&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;// Comic converts ComicResponse that we receive from the API to our application's output format, Comic&lt;/span&gt; &lt;span&gt;func&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;cr&lt;/span&gt; &lt;span&gt;ComicResponse&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;Comic&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;Comic&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;Comic&lt;/span&gt;&lt;span&gt;{&lt;/span&gt; &lt;span&gt;Title&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;cr&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Title&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Number&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;cr&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Num&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Date&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;cr&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;FormattedDate&lt;/span&gt;&lt;span&gt;(),&lt;/span&gt; &lt;span&gt;Description&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;cr&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Alt&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Image&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;cr&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Img&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;Then add the following two methods to the &lt;code&gt;Comic&lt;/code&gt; struct-&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;// PrettyString creates a pretty string of the Comic that we'll use as output&lt;/span&gt; &lt;span&gt;func&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;c&lt;/span&gt; &lt;span&gt;Comic&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;PrettyString&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;p&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;fmt&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Sprintf&lt;/span&gt;&lt;span&gt;(&lt;/span&gt; &lt;span&gt;"Title: %s&lt;/span&gt;&lt;span&gt;\n&lt;/span&gt;&lt;span&gt;Comic No: %d&lt;/span&gt;&lt;span&gt;\n&lt;/span&gt;&lt;span&gt;Date: %s&lt;/span&gt;&lt;span&gt;\n&lt;/span&gt;&lt;span&gt;Description: %s&lt;/span&gt;&lt;span&gt;\n&lt;/span&gt;&lt;span&gt;Image: %s&lt;/span&gt;&lt;span&gt;\n&lt;/span&gt;&lt;span&gt;"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;c&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Title&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;c&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Number&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;c&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Date&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;c&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Description&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;c&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Image&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;p&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;// JSON converts the Comic struct to JSON, we'll use the JSON string as output&lt;/span&gt; &lt;span&gt;func&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;c&lt;/span&gt; &lt;span&gt;Comic&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;JSON&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;cJSON&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;json&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Marshal&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;c&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;!=&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;""&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;string&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;cJSON&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;h2 id="3-setup-xkcd-client-for-making-request-parsing-response-and-saving-to-disk"&gt;3: Setup xkcd client for making request, parsing response and saving to disk&lt;/h2&gt; &lt;p&gt;Create &lt;code&gt;xkcd.go&lt;/code&gt; file inside the &lt;code&gt;client&lt;/code&gt; package.&lt;/p&gt; &lt;p&gt;First define a custom type called &lt;code&gt;ComicNumber&lt;/code&gt; as an &lt;code&gt;int&lt;/code&gt;&lt;/p&gt; &lt;p&gt;Define constants-&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;const&lt;/span&gt; &lt;span&gt;(&lt;/span&gt; &lt;span&gt;// BaseURL of xkcd&lt;/span&gt; &lt;span&gt;BaseURL&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;"https://xkcd.com"&lt;/span&gt; &lt;span&gt;// DefaultClientTimeout is time to wait before cancelling the request&lt;/span&gt; &lt;span&gt;DefaultClientTimeout&lt;/span&gt; &lt;span&gt;time&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Duration&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;30&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; &lt;span&gt;time&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Second&lt;/span&gt; &lt;span&gt;// LatestComic is the latest comic number according to the xkcd API&lt;/span&gt; &lt;span&gt;LatestComic&lt;/span&gt; &lt;span&gt;ComicNumber&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;0&lt;/span&gt; &lt;span&gt;)&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;Create a struct &lt;code&gt;XKCDClient&lt;/code&gt;, it will be used to make requests to the API.&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;// XKCDClient is the client for XKCD&lt;/span&gt; &lt;span&gt;type&lt;/span&gt; &lt;span&gt;XKCDClient&lt;/span&gt; &lt;span&gt;struct&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;client&lt;/span&gt; &lt;span&gt;*&lt;/span&gt;&lt;span&gt;http&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Client&lt;/span&gt; &lt;span&gt;baseURL&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;span&gt;// NewXKCDClient creates a new XKCDClient&lt;/span&gt; &lt;span&gt;func&lt;/span&gt; &lt;span&gt;NewXKCDClient&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;*&lt;/span&gt;&lt;span&gt;XKCDClient&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;&amp;amp;&lt;/span&gt;&lt;span&gt;XKCDClient&lt;/span&gt;&lt;span&gt;{&lt;/span&gt; &lt;span&gt;client&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;&amp;amp;&lt;/span&gt;&lt;span&gt;http&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Client&lt;/span&gt;&lt;span&gt;{&lt;/span&gt; &lt;span&gt;Timeout&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;DefaultClientTimeout&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;},&lt;/span&gt; &lt;span&gt;baseURL&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;BaseURL&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;Add the following 4 methods to &lt;code&gt;XKCDClient&lt;/code&gt;-&lt;/p&gt; &lt;ol&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;SetTimeout()&lt;/code&gt;&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;// SetTimeout overrides the default ClientTimeout&lt;/span&gt; &lt;span&gt;func&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;hc&lt;/span&gt; &lt;span&gt;*&lt;/span&gt;&lt;span&gt;XKCDClient&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;SetTimeout&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;d&lt;/span&gt; &lt;span&gt;time&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Duration&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;hc&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;client&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Timeout&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;d&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;Fetch()&lt;/code&gt;&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;// Fetch retrieves the comic as per provided comic number&lt;/span&gt; &lt;span&gt;func&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;hc&lt;/span&gt; &lt;span&gt;*&lt;/span&gt;&lt;span&gt;XKCDClient&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;Fetch&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;n&lt;/span&gt; &lt;span&gt;ComicNumber&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;save&lt;/span&gt; &lt;span&gt;bool&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;model&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Comic&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;error&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;resp&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;hc&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;client&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Get&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;hc&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;buildURL&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;n&lt;/span&gt;&lt;span&gt;))&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;!=&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;model&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Comic&lt;/span&gt;&lt;span&gt;{},&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;span&gt;defer&lt;/span&gt; &lt;span&gt;resp&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Body&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Close&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;var&lt;/span&gt; &lt;span&gt;comicResp&lt;/span&gt; &lt;span&gt;model&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;ComicResponse&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;json&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;NewDecoder&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;resp&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Body&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Decode&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;&amp;amp;&lt;/span&gt;&lt;span&gt;comicResp&lt;/span&gt;&lt;span&gt;);&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;!=&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;model&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Comic&lt;/span&gt;&lt;span&gt;{},&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;save&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;hc&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;SaveToDisk&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;comicResp&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Img&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;"."&lt;/span&gt;&lt;span&gt;);&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;!=&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;fmt&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Println&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"Failed to save image!"&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;comicResp&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Comic&lt;/span&gt;&lt;span&gt;(),&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;SaveToDisk()&lt;/code&gt;&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;// SaveToDisk downloads and saves the comic locally&lt;/span&gt; &lt;span&gt;func&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;hc&lt;/span&gt; &lt;span&gt;*&lt;/span&gt;&lt;span&gt;XKCDClient&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;SaveToDisk&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;url&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;savePath&lt;/span&gt; &lt;span&gt;string&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;error&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;resp&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;http&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Get&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;url&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;!=&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;span&gt;defer&lt;/span&gt; &lt;span&gt;resp&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Body&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Close&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;absSavePath&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;_&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;filepath&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Abs&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;savePath&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;filePath&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;fmt&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Sprintf&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"%s/%s"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;absSavePath&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;path&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Base&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;url&lt;/span&gt;&lt;span&gt;))&lt;/span&gt; &lt;span&gt;file&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;os&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Create&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;filePath&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;!=&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;span&gt;defer&lt;/span&gt; &lt;span&gt;file&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Close&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;_&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;io&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Copy&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;file&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;resp&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Body&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;!=&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;buildURL()&lt;/code&gt;&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;hc&lt;/span&gt; &lt;span&gt;*&lt;/span&gt;&lt;span&gt;XKCDClient&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;buildURL&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;n&lt;/span&gt; &lt;span&gt;ComicNumber&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;var&lt;/span&gt; &lt;span&gt;finalURL&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;n&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;LatestComic&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;finalURL&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;fmt&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Sprintf&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"%s/info.0.json"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;hc&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;baseURL&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;span&gt;else&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;finalURL&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;fmt&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Sprintf&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;"%s/%d/info.0.json"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;hc&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;baseURL&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;n&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;finalURL&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;/li&gt; &lt;/ol&gt; &lt;h2 id="4-connect-everything"&gt;4: Connect everything&lt;/h2&gt; &lt;p&gt;Inside the &lt;code&gt;main()&lt;/code&gt; function we connect all the wires-&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Read command arguments&lt;/li&gt; &lt;li&gt;Instantiate the &lt;code&gt;XKCDClient&lt;/code&gt;&lt;/li&gt; &lt;li&gt;Fetch from API using the &lt;code&gt;XKCDClient&lt;/code&gt;&lt;/li&gt; &lt;li&gt;Output&lt;/li&gt; &lt;/ul&gt; &lt;h5 id="read-command-arguments-"&gt;Read command arguments-&lt;/h5&gt; &lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;comicNo&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;flag&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Int&lt;/span&gt;&lt;span&gt;(&lt;/span&gt; &lt;span&gt;"n"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;int&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;client&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;LatestComic&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;"Comic number to fetch (default latest)"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;)&lt;/span&gt; &lt;span&gt;clientTimeout&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;flag&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Int64&lt;/span&gt;&lt;span&gt;(&lt;/span&gt; &lt;span&gt;"t"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;int64&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;client&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;DefaultClientTimeout&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Seconds&lt;/span&gt;&lt;span&gt;()),&lt;/span&gt; &lt;span&gt;"Client timeout in seconds"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;)&lt;/span&gt; &lt;span&gt;saveImage&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;flag&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Bool&lt;/span&gt;&lt;span&gt;(&lt;/span&gt; &lt;span&gt;"s"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;false&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;"Save image to current directory"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;)&lt;/span&gt; &lt;span&gt;outputType&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;flag&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;String&lt;/span&gt;&lt;span&gt;(&lt;/span&gt; &lt;span&gt;"o"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;"text"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;"Print output in format: text/json"&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;)&lt;/span&gt; &lt;span&gt;flag&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Parse&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;h5 id="instantiate-the-xkcdclient"&gt;Instantiate the &lt;code&gt;XKCDClient&lt;/code&gt;&lt;/h5&gt; &lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;xkcdClient&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;client&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;NewXKCDClient&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;xkcdClient&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;SetTimeout&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;time&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Duration&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;*&lt;/span&gt;&lt;span&gt;clientTimeout&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; &lt;span&gt;time&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Second&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;h5 id="fetch-from-api-using-the-xkcdclient"&gt;Fetch from API using the &lt;code&gt;XKCDClient&lt;/code&gt;&lt;/h5&gt; &lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;comic&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;xkcdClient&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Fetch&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;client&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;ComicNumber&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;*&lt;/span&gt;&lt;span&gt;comicNo&lt;/span&gt;&lt;span&gt;),&lt;/span&gt; &lt;span&gt;*&lt;/span&gt;&lt;span&gt;saveImage&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;!=&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;log&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Println&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;err&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;h5 id="output"&gt;Output&lt;/h5&gt; &lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;if&lt;/span&gt; &lt;span&gt;*&lt;/span&gt;&lt;span&gt;outputType&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;"json"&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;fmt&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Println&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;comic&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;JSON&lt;/span&gt;&lt;span&gt;())&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;span&gt;else&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;fmt&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Println&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;comic&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;PrettyString&lt;/span&gt;&lt;span&gt;())&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;Run the program as follows-&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;$ &lt;/span&gt;go run main.go &lt;span&gt;-n&lt;/span&gt; 323 &lt;span&gt;-o&lt;/span&gt; json &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;Or build it as an executable binary for your laptop and then run-&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;$ &lt;/span&gt;go build &lt;span&gt;.&lt;/span&gt; &lt;span&gt;$ &lt;/span&gt;./go-grab-xkcd &lt;span&gt;-n&lt;/span&gt; 323 &lt;span&gt;-s&lt;/span&gt; &lt;span&gt;-o&lt;/span&gt; json &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;Find the complete source code in the Github Repository - &lt;a href="https://github.com/erybz/go-grab-xkcd"&gt;go-grab-xkcd&lt;/a&gt;&lt;/p&gt; &lt;h2 id="bash-bonus"&gt;Bash Bonus&lt;/h2&gt; &lt;p&gt;Download multiple comics serially by using this simple shell magic-&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;$ &lt;/span&gt;&lt;span&gt;for &lt;/span&gt;i &lt;span&gt;in&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;1..10&lt;span&gt;}&lt;/span&gt;&lt;span&gt;;&lt;/span&gt; &lt;span&gt;do&lt;/span&gt; ./go-grab-xkcd &lt;span&gt;-n&lt;/span&gt; &lt;span&gt;$i&lt;/span&gt; &lt;span&gt;-s&lt;/span&gt;&lt;span&gt;;&lt;/span&gt; &lt;span&gt;done&lt;/span&gt;&lt;span&gt;;&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;The above shell code simple calls our &lt;code&gt;go-grab-xkcd&lt;/code&gt; command in a &lt;code&gt;for&lt;/code&gt; loop, and the &lt;code&gt;i&lt;/code&gt; value is substituted as comic number since xkcd uses serial integers as comic number/ID.&lt;/p&gt; &lt;/article&gt;&lt;/div&gt;&lt;a href="https://eryb.space/2020/05/27/diving-into-go-by-building-a-cli-application.html"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Wed, 27 May 2020 10:37:39 UT
      </pubDate>
      <guid>
        https://eryb.space/2020/05/27/diving-into-go-by-building-a-cli-application.html
      </guid>
    </item>
    <item>
      <title>
        TwoHardThings
      </title>
      <link>
        https://martinfowler.com/bliki/TwoHardThings.html
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt; &lt;blockquote&gt; &lt;p&gt;There are only two hard things in Computer Science: cache invalidation and naming things.&lt;/p&gt; &lt;p&gt;-- Phil Karlton&lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt;Long a favorite saying of mine, one for which I couldn't find a satisfactory URL.&lt;/p&gt; &lt;p&gt;Like many good phrase, it's had a host of riffs on it. A couple of them I feel are worth adding to the page&lt;/p&gt; &lt;div&gt; &lt;blockquote lang="en"&gt; There are 2 hard problems in computer science: cache invalidation, naming things, and off-by-1 errors. &lt;a href="https://twitter.com/secretGeek/status/7269997868"&gt;-- Leon Bambrick&lt;/a&gt;&lt;/blockquote&gt; &lt;/div&gt; &lt;div&gt; &lt;blockquote lang="en"&gt; There are only two hard problems in distributed systems: 2. Exactly-once delivery 1. Guaranteed order of messages 2. Exactly-once delivery &lt;a href="https://twitter.com/mathiasverraes/status/632260618599403520"&gt;-- Mathias Verraes&lt;/a&gt;&lt;/blockquote&gt; &lt;/div&gt; &lt;div&gt; &lt;h2&gt;Revisions&lt;/h2&gt; &lt;p&gt;2009-07-14: original post&lt;/p&gt; &lt;p&gt;2010-12-21: added off-by-one variation (unattributed)&lt;/p&gt; &lt;p&gt;2015-08-14: added distributed tweet&lt;/p&gt; &lt;p&gt;2017-03-30: added proper tweet for off-by-one and mention of Tim Bray's source&lt;/p&gt; &lt;p&gt;2017-12-22: added the Phillip Scott Bowden tweet&lt;/p&gt; &lt;/div&gt; &lt;div&gt; &lt;h2&gt;Acknowledgements&lt;/h2&gt;&lt;p&gt; Leon Bambrick let me know about better sources. &lt;/p&gt;&lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://martinfowler.com/bliki/TwoHardThings.html"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Fri, 29 May 2020 00:26:49 UT
      </pubDate>
      <guid>
        https://martinfowler.com/bliki/TwoHardThings.html
      </guid>
    </item>
    <item>
      <title>
        Recovering From a Computer Science Education
      </title>
      <link>
        https://prog21.dadgum.com/123.html
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div id="c1"&gt;&lt;h2&gt;Recovering From a Computer Science Education&lt;/h2&gt;&lt;p&gt;I was originally going to call this "Undoing the Damage of a Computer Science Education," but that was too link-baity and too extreme. There's real value in a computer science degree. For starters, you can easily get a good paying job. More importantly, you've gained the ability to make amazing and useful things. But there's a downside, too, in that you can get so immersed in the technical and theoretical that you forget how wonderful it is to make amazing and useful things. At least that's what happened to me, and it took a long time to recover.&lt;/p&gt;&lt;p&gt;This is a short list of things that helped me and might help you too.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Stay out of technical forums unless it's directly relevant to something you're working on.&lt;/b&gt; It's far too easy to get wrapped up in discussions of the validity of functional programming or whether or not Scheme can be used to make commercial applications or how awful PHP is. The deeper you get into this, the more you lose touch.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Keep working on real projects related to your area of interest.&lt;/b&gt; If you like designing games, write games. If you like photography, write a photo organizer or camera app. Don't approach things wrong-way-around, thinking that "a photo organizer in Haskell" is more important than "a photo organizer which solves a particular problem with photo organizers."&lt;/p&gt;&lt;p&gt;&lt;b&gt;If you find yourself repeatedly putting down a technology, then take some time to actually learn and use it.&lt;/b&gt; All the jokes and snide remarks aside, Perl is tremendously useful. Ditto for PHP and Java and C++. Who wins, the person who has been slamming Java online for ten years or the author of Minecraft who just used the language and made tens of millions of dollars?&lt;/p&gt;&lt;p&gt;&lt;b&gt;Don't become an advocate.&lt;/b&gt; This is the flipside of the previous item. If Linux or Android or Scala are helpful with what you're building, then great! That you're relying on it is a demonstration of its usefulness. No need to insist that everyone else use it, too.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Have a hobby where you focus the end results and not the "how."&lt;/b&gt; Woodworkers can become tool collectors. &lt;a href="https://prog21.dadgum.com/118.html"&gt;Photographers&lt;/a&gt; can become spec comparison addicts. Forget all of that and concern yourself with what you're making.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Do something artistic&lt;/b&gt;. Write songs or short stories, sketch, learn to do pixel art. Most of these also have the benefit of much shorter turnaround times than any kind of software project.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Be widely read.&lt;/b&gt; There are endless books about architecture, books by naturalists, both classic and popular modern novels, and most of them have absolutely nothing to do with computers or programming or science fiction.&lt;/p&gt;&lt;p&gt;&lt;a id="perm" href="https://prog21.dadgum.com/123.html"&gt;permalink&lt;/a&gt; &lt;i&gt;January 15, 2012&lt;/i&gt;&lt;/p&gt;&lt;h2&gt;previously&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://prog21.dadgum.com/122.html"&gt;Follow-up to "A Programming Idiom You've Never Heard Of"&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://prog21.dadgum.com/121.html"&gt;A Programming Idiom You've Never Heard Of&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://prog21.dadgum.com/120.html"&gt;2011 Retrospective&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://prog21.dadgum.com/119.html"&gt;User Experience Intrusions in iOS 5&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://prog21.dadgum.com/118.html"&gt;Photography as a Non-Technical Hobby&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;a href="https://prog21.dadgum.com/123.html"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Wed, 3 Jun 2020 01:08:47 UT
      </pubDate>
      <guid>
        https://prog21.dadgum.com/123.html
      </guid>
    </item>
    <item>
      <title>
        Politeness
      </title>
      <link>
        https://www.cs.cornell.edu/~cristian/Politeness.html
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt; &lt;p&gt;A computational approach to politeness with application to social factors &lt;br&gt;&lt;/p&gt; &lt;p&gt;Cristian Danescu-Niculescu-Mizil, Moritz Sudhof, Dan Jurafsky, Jure Leskovec, Christopher Potts&lt;br&gt;&lt;/p&gt; &lt;p&gt;Proceedings of ACL, 2013.&lt;br&gt;&lt;/p&gt; &lt;p&gt;Nominated for the Best Paper Award&lt;br&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://www.cs.cornell.edu/~cristian/Politeness_files/politeness.pdf" title="Politeness_files/politeness.pdf"&gt;PDF&lt;/a&gt;&lt;br&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://www.cs.cornell.edu/~cristian/Politeness_files/politeness_talk.pdf" title="Politeness_files/politeness_talk.pdf"&gt;Talk slides&lt;/a&gt;&lt;br&gt;&lt;/p&gt; &lt;p&gt;Fun: &lt;span&gt;Check how polite your requests are using our &lt;/span&gt;&lt;a href="http://politeness.cornell.edu/" title="http://politeness.cornell.edu"&gt;Politeness Web App&lt;/a&gt;&lt;br&gt;&lt;/p&gt; &lt;p&gt;Data and Code: &lt;a href="http://convokit.cornell.edu/" title="http://convokit.cornell.edu"&gt;ConvoKit&lt;/a&gt;&amp;nbsp;&amp;nbsp; (legacy code: &lt;a href="https://github.com/sudhof/politeness" title="https://github.com/sudhof/politeness"&gt;Stanford Politeness API&lt;/a&gt;, legacy data:&amp;nbsp; &lt;a href="https://www.cs.cornell.edu/~cristian/Politeness_files/Readme.txt" title="Politeness_files/Readme.txt"&gt;Stanford Politeness Corpus&lt;/a&gt;)&lt;br&gt;&lt;/p&gt; &lt;p&gt;Related research:&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;br&gt;&lt;/p&gt; &lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;a href="https://www.cs.cornell.edu/~cristian/Conversations.html" title="Conversations.html"&gt;Conversational Behavior&lt;/a&gt;&lt;br&gt;&lt;/p&gt; &lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;a href="https://www.cs.cornell.edu/~cristian/Antisocial.html" title="Antisocial.html"&gt;Anti-Social Computing&lt;br&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Teaser:&lt;br&gt;&lt;/p&gt; &lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; Politeness and status: successful and failed candidates before and after elections.&lt;br&gt;&lt;/p&gt; &lt;div&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;p&gt;&lt;img alt="" src="https://www.cs.cornell.edu/~cristian/Politeness_files/statuschange.jpg"&gt;&lt;/p&gt;&lt;br&gt;&lt;/div&gt; &lt;div&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;div id="id1"&gt;&lt;p&gt;Editors that will eventually succeed (diamond marker) are significantly more polite than those that will fail (circle markers). Following the elections, successful editors become less polite while unsuccessful editors become more polite.&lt;/p&gt;&lt;/div&gt;&lt;br&gt;&lt;/div&gt; &lt;p&gt;ABSTRACT: &lt;br&gt;&lt;/p&gt; &lt;div&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;div id="id2"&gt;&lt;p&gt;We propose a computational framework for identifying linguistic aspects of politeness. Our starting point is a new corpus of requests annotated for politeness, which we use to evaluate aspects of politeness theory and to uncover new interactions between politeness markers and context. These findings guide our construction of a classifier with domain-independent lexical and syntactic features operationalizing key components of politeness theory, such as indirection, deference, impersonalization and modality. Our classifier achieves close to human performance and is effective across domains.&amp;nbsp; We use our framework to study the relationship between politeness and social power, showing that polite Wikipedia editors are more likely to achieve high status through elections, but, once elevated, they become less polite.&amp;nbsp; We see a similar negative correlation between politeness and power on Stack Exchange, where users at the top of the reputation scale are less polite than those at the bottom.&amp;nbsp; Finally, we apply our classifier to a preliminary analysis of politeness variation by gender and community.&lt;/p&gt;&lt;/div&gt;&lt;br&gt;&lt;/div&gt; &lt;p&gt;BibTeX ENTRY:&lt;br&gt;&lt;/p&gt; &lt;div&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;div id="id3"&gt;&lt;p&gt;@InProceedings{Danescu-Niculescu-Mizil+al:13b,&lt;br&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp; author={Cristian Danescu-Niculescu-Mizil and Moritz Sudhof and Dan Jurafsky &lt;br&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp; and Jure Leskovec and Christopher Potts},&lt;br&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp; title={A computational approach to politeness with application to social factors},&lt;br&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp; booktitle={Proceedings of ACL},&lt;br&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp; year={2013}&lt;br&gt;&lt;/p&gt;&lt;p&gt;}&lt;/p&gt;&lt;/div&gt;&lt;br&gt;&lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://www.cs.cornell.edu/~cristian/Politeness.html"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Fri, 12 Jun 2020 12:02:40 UT
      </pubDate>
      <guid>
        https://www.cs.cornell.edu/~cristian/Politeness.html
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://arxiv.org/pdf/1904.01596.pdf
      </link>
      <description>
        &lt;a href="https://arxiv.org/pdf/1904.01596.pdf"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Fri, 12 Jun 2020 12:03:11 UT
      </pubDate>
      <guid>
        https://arxiv.org/pdf/1904.01596.pdf
      </guid>
    </item>
    <item>
      <title>
        Language from police body camera footage shows racial disparities in officer respect | PNAS
      </title>
      <link>
        https://www.pnas.org/content/114/25/6521
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div class="page" id="page" role="main"&gt; &lt;div id="block-panels-mini-whats-new-in"&gt;&lt;div&gt; &lt;p&gt; &lt;h2&gt;New&amp;nbsp;Research&amp;nbsp;In&lt;/h2&gt; &lt;/p&gt; &lt;/div&gt; &lt;div&gt; &lt;h3&gt;&lt;span&gt;Physical Sciences&lt;/span&gt;&lt;/h3&gt; &lt;div id="pnas-physical-sciences"&gt; &lt;h4&gt;Featured Portals&lt;/h4&gt; &lt;h4&gt;Articles by Topic&lt;/h4&gt; &lt;/div&gt; &lt;/div&gt; &lt;div&gt; &lt;h3&gt;&lt;span&gt;Biological Sciences&lt;/span&gt;&lt;/h3&gt; &lt;div id="pnas-biological-sciences"&gt; &lt;h4&gt;Featured Portals&lt;/h4&gt; &lt;h4&gt;Articles by Topic&lt;/h4&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id="block-system-main"&gt;&lt;div&gt; &lt;p&gt;&lt;a data-target="crossmark"&gt;&lt;img alt="" src="https://crossmark-cdn.crossref.org/widget/v2.0/logos/CROSSMARK_Color_square.svg"&gt;&lt;/a&gt;&lt;/p&gt; &lt;/div&gt; &lt;div data-hw-author-tooltip-instance="highwire_author_tooltip" data-apath="/pnas/114/25/6521.atom" data-pisa-master="pnas;1702413114" data-pisa="pnas;114/25/6521" id="node3349" data-node-nid="3349"&gt; &lt;p&gt;&lt;span&gt;Research Article&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;, &lt;span data-delta="1"&gt;Nicholas P. Camp&lt;/span&gt;, &lt;span data-delta="2"&gt;Vinodkumar Prabhakaran&lt;/span&gt;, &lt;span data-delta="3"&gt;William L. Hamilton&lt;/span&gt;, &lt;span data-delta="4"&gt;Rebecca C. Hetey&lt;/span&gt;, &lt;span data-delta="5"&gt;Camilla M. Griffiths&lt;/span&gt;, &lt;span data-delta="6"&gt;David Jurgens&lt;/span&gt;, &lt;span data-delta="7"&gt;Dan Jurafsky&lt;/span&gt;, and &lt;span data-delta="8"&gt;Jennifer L. Eberhardt&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/div&gt; &lt;div id="content-block-markup" xmlns="http://www.w3.org/1999/xhtml"&gt;&lt;ol&gt;&lt;li id="fn-1"&gt;&lt;p id="p-1"&gt;Contributed by Jennifer L. Eberhardt, March 26, 2017 (sent for review February 14, 2017; reviewed by James Pennebaker and Tom Tyler)&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt; &lt;div id="panels-ajax-tab-container-highwire_article_tabs" data-panels-ajax-tab-preloaded="jnl_pnas_tab_art"&gt;&lt;div data-highwire-cite-ref-tooltip-instance="highwire_reflinks_tooltip" id="content-block-markup" xmlns="http://www.w3.org/1999/xhtml"&gt;&lt;div&gt;&lt;h2&gt;Significance&lt;/h2&gt;&lt;p id="p-6"&gt;Police officers speak significantly less respectfully to black than to white community members in everyday traffic stops, even after controlling for officer race, infraction severity, stop location, and stop outcome. This paper presents a systematic analysis of officer body-worn camera footage, using computational linguistic techniques to automatically measure the respect level that officers display to community members. This work demonstrates that body camera footage can be used as a rich source of data rather than merely archival evidence, and paves the way for developing powerful language-based tools for studying and potentially improving police–community relations.&lt;/p&gt;&lt;/div&gt;&lt;div id="abstract-2"&gt;&lt;h2&gt;Abstract&lt;/h2&gt;&lt;p id="p-7"&gt;Using footage from body-worn cameras, we analyze the respectfulness of police officer language toward white and black community members during routine traffic stops. We develop computational linguistic methods that extract levels of respect automatically from transcripts, informed by a thin-slicing study of participant ratings of officer utterances. We find that officers speak with consistently less respect toward black versus white community members, even after controlling for the race of the officer, the severity of the infraction, the location of the stop, and the outcome of the stop. Such disparities in common, everyday interactions between police and the communities they serve have important implications for procedural justice and the building of police–community trust.&lt;/p&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;a rel="nofollow" href="https://www.pnas.org/keyword/racial-disparities"&gt;racial disparities&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a rel="nofollow" href="https://www.pnas.org/keyword/natural-language-processing"&gt;natural language processing&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a rel="nofollow" href="https://www.pnas.org/keyword/procedural-justice"&gt;procedural justice&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a rel="nofollow" href="https://www.pnas.org/keyword/traffic-stops"&gt;traffic stops&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a rel="nofollow" href="https://www.pnas.org/keyword/policing"&gt;policing&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p id="p-8"&gt;Over the last several years, our nation has been rocked by an onslaught of incidents captured on video involving police officers’ use of force with black suspects. The images from these cases are disturbing, both exposing and igniting police–community conflict all over the country: in New York, Missouri, Ohio, South Carolina, Maryland, Illinois, Wisconsin, Louisiana, Oklahoma, and North Carolina. These images have renewed conversations about modern-day race relations and have led many to question how far we have come (&lt;a href="#ref-1" id="xref-ref-1-1"&gt;1&lt;/a&gt;). In an effort to increase accountability and transparency, law enforcement agencies are adopting body-worn cameras at an extremely rapid pace (&lt;a href="#ref-2" id="xref-ref-2-1"&gt;2&lt;/a&gt;, &lt;a href="#ref-3" id="xref-ref-3-1"&gt;3&lt;/a&gt;).&lt;/p&gt;&lt;p id="p-9"&gt;Despite the rapid proliferation of body-worn cameras, no law enforcement agency has systematically analyzed the massive amounts of footage these cameras produce. Instead, the public and agencies alike tend to focus on the fraction of videos involving high-profile incidents, using footage as evidence of innocence or guilt in individual encounters.&lt;/p&gt;&lt;p id="p-10"&gt;Left unexamined are the common, everyday interactions between the police and the communities they serve. By best estimates, more than one quarter of the public (ages 16 y and over) comes into contact with the police during the course of a year, most frequently as the result of a police-initiated traffic stop (&lt;a href="#ref-4" id="xref-ref-4-1"&gt;4&lt;/a&gt;, &lt;a href="#ref-5" id="xref-ref-5-1"&gt;5&lt;/a&gt;). Here, we examine body-worn camera footage of routine traffic stops in the large, racially diverse city of Oakland, CA.&lt;/p&gt;&lt;p id="p-11"&gt;Routine traffic stops are not only common, they are consequential, each an opportunity to build or erode public trust in the police. Being treated with respect builds trust in the fairness of an officer’s behavior, whereas rude or disrespectful treatment can erode trust (&lt;a href="#ref-6" id="xref-ref-6-1"&gt;6&lt;/a&gt;, &lt;a href="#ref-7" id="xref-ref-7-1"&gt;7&lt;/a&gt;). Moreover, a person’s experiences of respect or disrespect in personal interactions with police officers play a central role in their judgments of how procedurally fair the police are as an institution, as well as their willingness to support or cooperate with the police (&lt;a href="#ref-8" id="xref-ref-8-1"&gt;8&lt;/a&gt;, &lt;a href="#ref-9" id="xref-ref-9-1"&gt;9&lt;/a&gt;).&lt;/p&gt;&lt;p id="p-12"&gt;Blacks report more negative experiences in their interactions with the police than other groups (&lt;a href="#ref-10" id="xref-ref-10-1"&gt;10&lt;/a&gt;). Across numerous studies, for example, blacks report being treated less fairly and respectfully in their contacts with the police than whites (&lt;a href="#ref-6" id="xref-ref-6-2"&gt;6&lt;/a&gt;, &lt;a href="#ref-11" id="xref-ref-11-1"&gt;11&lt;/a&gt;). Indeed, some have argued that racial disparities in perceived treatment during routine encounters help fuel the mistrust of police in the controversial officer-involved shootings that have received such great attention. However, do officers treat white community members with a greater degree of respect than they afford to blacks?&lt;/p&gt;&lt;p id="p-13"&gt;We address this question by analyzing officers’ language during vehicle stops of white and black community members. Although many factors may shape these interactions, an officer’s words are undoubtedly critical: Through them, the officer can communicate respect and understanding of a citizen’s perspective, or contempt and disregard for their voice. Furthermore, the language of those in positions of institutional power (police officers, judges, work superiors) has greater influence over the course of the interaction than the language used by those with less power (&lt;a href="#ref-12" id="xref-ref-12-1"&gt;12&lt;/a&gt;&lt;a href="#ref-13" id="xref-ref-13-1"&gt;&lt;span&gt;⇓&lt;/span&gt;&lt;/a&gt;&lt;a href="#ref-14" id="xref-ref-14-1"&gt;&lt;span&gt;⇓&lt;/span&gt;&lt;/a&gt;&lt;a href="#ref-15" id="xref-ref-15-1"&gt;&lt;span&gt;⇓&lt;/span&gt;&lt;/a&gt;–&lt;a href="#ref-16" id="xref-ref-16-1"&gt;16&lt;/a&gt;). Measuring officer language thus provides a quantitative lens on one key aspect of the quality or tone of police–community interactions, and offers new opportunities for advancing police training.&lt;/p&gt;&lt;p id="p-14"&gt;Previous research on police–community interactions has relied on citizens’ recollection of past interactions (&lt;a href="#ref-10" id="xref-ref-10-2"&gt;10&lt;/a&gt;) or researcher observation of officer behavior (&lt;a href="#ref-17" id="xref-ref-17-1"&gt;17&lt;/a&gt;&lt;a href="#ref-18" id="xref-ref-18-1"&gt;&lt;span&gt;⇓&lt;/span&gt;&lt;/a&gt;&lt;a href="#ref-19" id="xref-ref-19-1"&gt;&lt;span&gt;⇓&lt;/span&gt;&lt;/a&gt;–&lt;a href="#ref-20" id="xref-ref-20-1"&gt;20&lt;/a&gt;) to assess procedural fairness. Although these methods are invaluable, they offer an indirect view of officer behavior and are limited to a small number of interactions. Furthermore, the very presence of researchers may influence the police behavior those researchers seek to measure (&lt;a href="#ref-21" id="xref-ref-21-1"&gt;21&lt;/a&gt;).&lt;/p&gt;&lt;p id="p-15"&gt;In study 1, human participants rated officer utterances on several overlapping dimensions of respect. With a high degree of agreement, participants inferred these dimensions from officer language. Even though they were not told the race of the stopped driver, participants judged officer language directed toward black motorists to be less respectful than language directed toward whites. In study 2, we build statistical models capable of predicting aspects of respect based on linguistic features derived from theories of politeness, power, and social distance. We discuss the linguistic features that contribute to each model, finding that particular forms of politeness are implicated in perceptions of respect. In study 3, we apply these models to all vehicle stop interactions between officers of the Oakland Police Department and black/white community members during the month of April 2014. We find strong evidence that utterances spoken to white community members are consistently more respectful, even after controlling for contextual factors such as the severity of the offense or the outcome of the stop.&lt;/p&gt;&lt;div id="sec-1"&gt;&lt;h2&gt;Data&lt;/h2&gt;&lt;p id="p-16"&gt;Our dataset consists of transcribed body camera footage from vehicle stops of white and black community members conducted by the Oakland Police Department during the month of April 2014. We examined 981 stops of black (&lt;em&gt;N&lt;/em&gt; = 682) and white (&lt;em&gt;N&lt;/em&gt; = 299) drivers from this period, 68.1% of the 1,440 stops of white and black drivers in this period. These 981 stops were conducted by 245 different officers (see &lt;a href="http://www.pnas.org/lookup/suppl/doi:10.1073/pnas.1702413114/-/DCSupplemental/pnas.1702413114.sapp.pdf"&gt;&lt;em&gt;SI Appendix&lt;/em&gt;, &lt;em&gt;Data Sampling Process&lt;/em&gt;&lt;/a&gt; for inclusion criteria). Per Oakland Police Department policy, officers turn on their cameras before making contact with the driver and record for the duration of the stop. From the 183 h of footage in these interactions, we obtain 36,738 usable officer utterances for our analysis.&lt;/p&gt;&lt;div id="sec-2"&gt;&lt;h3&gt;Study 1: Perceptions of Officer Treatment from Language.&lt;/h3&gt;&lt;p id="p-17"&gt;We first test whether human raters can reliably judge respect from officers’ language, and whether these judgments reveal differences in officer respect toward black versus white community members.&lt;/p&gt;&lt;p id="p-18"&gt;Respect is a complex and gradient perception, incorporating elements of a number of correlated constructs like friendliness and formality. Therefore, in this study, we ask participants to rate transcribed utterances spoken by officers along five conceptually overlapping folk notions related to respect and officer treatment. We randomly sampled 414 unique officer utterances (1.1% of all usable utterances in the dataset) directed toward black (&lt;em&gt;N&lt;/em&gt; = 312) or white (&lt;em&gt;N&lt;/em&gt; = 102) community members. On each trial, participants viewed the text of an officer utterance, along with the driver’s utterance that immediately preceded it. All proper names and places were anonymized, and participants were not told the race or gender of the driver. Participants indicated on four-point Likert scales how respectful, polite, friendly, formal, and impartial the officer was in each exchange. Each utterance was rated by at least 10 participants.&lt;/p&gt;&lt;p id="p-19"&gt;Could participants reliably glean these qualities from such brief exchanges? Previous work has demonstrated that different perceivers can arrive at similar judgments from “thin slices” of behavior (&lt;a href="#ref-22" id="xref-ref-22-1"&gt;22&lt;/a&gt;). In a similar vein, participants showed consistency in their perceptions of officer language, with reliability for each item ranging from moderate (Cronbach’s &lt;span id="inline-formula-1"&gt;&lt;span&gt;α&lt;/span&gt;&lt;/span&gt; = 0.73) to high (&lt;span id="inline-formula-2"&gt;&lt;span&gt;α&lt;/span&gt;&lt;/span&gt; = 0.91) agreement (see &lt;a href="http://www.pnas.org/lookup/suppl/doi:10.1073/pnas.1702413114/-/DCSupplemental/pnas.1702413114.sapp.pdf"&gt;&lt;em&gt;SI Appendix&lt;/em&gt;, &lt;em&gt;Annotator Agreement&lt;/em&gt;&lt;/a&gt;). These results demonstrate that transcribed language provides a sufficient and consensual signal of officer communication, enough to gain a picture of the dynamics of an interaction at a given point in time.&lt;/p&gt;&lt;p id="p-20"&gt;To test whether participant ratings uncovered racial group differences, we averaged scores across raters to calculate a single rating on each dimension for each utterance, then built a linear mixed-effects regression model to estimate the fixed effect of community member race across interactions, controlling for variance of a random effect at the interaction level. Officer utterances directed toward black drivers were perceived as less respectful [&lt;em&gt;b&lt;/em&gt; = −0.23, 95% confidence interval (−0.34, −0.11)], polite [&lt;em&gt;b&lt;/em&gt; = −0.23 (−0.35, −0.12)], friendly [&lt;em&gt;b&lt;/em&gt; = −0.24 (−0.36, −0.12)], formal [&lt;em&gt;b&lt;/em&gt; = −0.16 (−0.30, −0.03)], and impartial [&lt;em&gt;b&lt;/em&gt; = −0.26 (−0.39, −0.12)] than language directed toward white drivers (&lt;a href="#F1" id="xref-fig-1-1"&gt;Fig. 1&lt;/a&gt;). These differences persisted even when controlling for the age and sex of the driver (see &lt;a href="http://www.pnas.org/lookup/suppl/doi:10.1073/pnas.1702413114/-/DCSupplemental/pnas.1702413114.sapp.pdf"&gt;&lt;em&gt;SI Appendix&lt;/em&gt;, &lt;em&gt;Model Outputs for Each Rated Dimension&lt;/em&gt;&lt;/a&gt;).&lt;/p&gt;&lt;div id="F1"&gt;&lt;div&gt;&lt;div&gt;&lt;p&gt;&lt;a data-hide-link-title="0" data-icon-position="" data-figure-caption="&lt;div class=&amp;quot;highwire-markup&amp;quot;&gt;&lt;div xmlns=&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;&gt;(&lt;em&gt;Left&lt;/em&gt;) Differences in raw participant ratings between interactions with black and white community members. (&lt;em&gt;Right&lt;/em&gt;) When collapsed to two uncorrelated components, Respect and Formality, we find a significant difference for Respect but none for Formality. Error bars represent 95% confidence intervals. PC, principal component.&lt;/div&gt;&lt;/div&gt;" rel="gallery-fragment-images-35030243" title="(Left) Differences in raw participant ratings between interactions with black and white community members. (Right) When collapsed to two uncorrelated components, Respect and Formality, we find a significant difference for Respect but none for Formality. Error bars represent 95% confidence intervals. PC, principal component." href="https://www.pnas.org/content/pnas/114/25/6521/F1.large.jpg?width=800&amp;amp;height=600&amp;amp;carousel=1"&gt;&lt;span&gt;&lt;img height="232" width="440" data-src="https://www.pnas.org/content/pnas/114/25/6521/F1.medium.gif" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="Fig. 1."&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;a data-hide-link-title="0" data-icon-position="" title="Download Fig. 1." href="https://www.pnas.org/content/pnas/114/25/6521/F1.large.jpg?download=true"&gt;Download figure&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a data-hide-link-title="0" data-icon-position="" href="https://www.pnas.org/content/pnas/114/25/6521/F1.large.jpg"&gt;Open in new tab&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a data-hide-link-title="0" data-icon-position="" href="https://www.pnas.org/highwire/powerpoint/19752"&gt;Download powerpoint&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;/div&gt;&lt;div&gt;&lt;p&gt;&lt;span&gt;Fig. 1.&lt;/span&gt;&lt;/p&gt;&lt;p id="p-21"&gt;(&lt;em&gt;Left&lt;/em&gt;) Differences in raw participant ratings between interactions with black and white community members. (&lt;em&gt;Right&lt;/em&gt;) When collapsed to two uncorrelated components, Respect and Formality, we find a significant difference for Respect but none for Formality. Error bars represent 95% confidence intervals. PC, principal component.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;p id="p-22"&gt;Given the expected conceptual overlap in the five perceptual categories we presented to the participants, we used principal component analysis to decompose the ratings into their underlying components. Two principal components explained 93.2% of the variance in the data (see &lt;a href="http://www.pnas.org/lookup/suppl/doi:10.1073/pnas.1702413114/-/DCSupplemental/pnas.1702413114.sapp.pdf"&gt;&lt;em&gt;SI Appendix&lt;/em&gt;, &lt;em&gt;Principal Component Analysis (PCA) Loadings&lt;/em&gt;&lt;/a&gt; for loadings). The first component, explaining 71.3% of the variance and composed of positive loadings on the impartial, respectful, friendly, and polite dimensions with some loading on the formal dimension, we characterize as Respect, broadly construed. The second, explaining 21.9% of the variance and composed primarily of a very high positive loading on the formal dimension and a weak negative loading on the friendly dimension, we characterize as Formality. This component captures formality as distinct from respect more generally, and is likely related to social distance.&lt;/p&gt;&lt;p id="p-23"&gt;Standardizing these factor scores as outcome variables in mixed-effects models, we find that officers were equal in Formality with white and black drivers [&lt;span id="inline-formula-3"&gt;&lt;span&gt;β&lt;/span&gt;&lt;/span&gt; = −0.01 (−0.19, 0.16)], but higher in Respect with white drivers [&lt;span id="inline-formula-4"&gt;&lt;span&gt;β&lt;/span&gt;&lt;/span&gt; = 0.17 (0.00, 0.33)] (&lt;a href="#F1" id="xref-fig-1-2"&gt;Fig. 1&lt;/a&gt;).&lt;/p&gt;&lt;p id="p-24"&gt;Study 1 demonstrates that key features of police treatment can be reliably gleaned from officer speech. Participant ratings from thin slices of police–community interactions reveal racial disparities in how respectful, impartial, polite, friendly, and formal officers’ language to community members was perceived. Such differences were driven by differences in the Respect officers communicated toward drivers rather than the Formality with which officers addressed them.&lt;/p&gt;&lt;/div&gt;&lt;div id="sec-3"&gt;&lt;h3&gt;Study 2: Linguistic Correlates of Respect.&lt;/h3&gt;&lt;p id="p-25"&gt;The methods of study 1 (human coding of 414 individual utterances), although effective at discovering racial disparities in officer respect toward community members in our dataset, cannot offer a general solution to the analysis of body camera data. One problem is scale: Each year, on the order of 26 million vehicle stops are made (&lt;a href="#ref-5" id="xref-ref-5-2"&gt;5&lt;/a&gt;). Furthermore, using only a small sample of individual utterances makes it impossible to study how police treatment varies over officers, or how the interaction progresses across time in each stop.&lt;/p&gt;&lt;p id="p-26"&gt;In this study, we therefore develop computational linguistic models of respect and formality and tune them on the 414 individual utterances; in study 3, we apply these models to our full dataset of 36,738 utterances. Our method is based on linguistic theories of respect that model how speakers use respectful language (apologizing, giving agency, softening of commands, etc.) to mitigate “face-threatening acts.” We use computational linguistic methods (e.g., refs. &lt;a href="#ref-23" id="xref-ref-23-1"&gt;23&lt;/a&gt;&lt;a href="#ref-24" id="xref-ref-24-1"&gt;&lt;span&gt;⇓&lt;/span&gt;&lt;/a&gt;&lt;a href="#ref-25" id="xref-ref-25-1"&gt;&lt;span&gt;⇓&lt;/span&gt;&lt;/a&gt;–&lt;a href="#ref-26" id="xref-ref-26-1"&gt;26&lt;/a&gt;) to extract features of the language of each officer utterance. The log-transformed counts of these features are then used as independent variables in two linear regression models predicting the perceptual ratings of Respect and Formality from study 1.&lt;/p&gt;&lt;p id="p-27"&gt;Our model-assigned ratings agree with the average human from study 1 about as well as humans agree with each other. Our model for Respect obtains an adjusted &lt;em&gt;R&lt;/em&gt;&lt;sup&gt;2&lt;/sup&gt; of 0.258 on the perceptual ratings obtained in study 1, and a root-mean-square error (RMSE) of 0.840, compared with an RMSE of 0.842 for the average rater relative to other raters. Our model for Formality obtains an adjusted &lt;em&gt;R&lt;/em&gt;&lt;sup&gt;2&lt;/sup&gt; of 0.190, and an RMSE of 0.882 compared with 0.764 for the average rater (see &lt;a href="http://www.pnas.org/lookup/suppl/doi:10.1073/pnas.1702413114/-/DCSupplemental/pnas.1702413114.sapp.pdf"&gt;&lt;em&gt;SI Appendix&lt;/em&gt;, &lt;em&gt;Model Comparison to Annotators&lt;/em&gt;&lt;/a&gt; for more details on how these values were calculated). These results indicate that, despite the sophisticated social and psychological cues participants are likely drawing upon in rating officers’ utterances, a constrained set of objectively measurable linguistic features can explain a meaningful portion of the variance in these ratings.&lt;/p&gt;&lt;p id="p-28"&gt;&lt;a href="#F2" id="xref-fig-2-1"&gt;Fig. 2&lt;/a&gt; lists the linguistic features that received significant weights in our model of Respect (arranged by their model coefficients). For example, apologizing, gratitude, and expressions of concern for citizen safety are all associated with respect. The bars on the right show the log-odds of the relative proportion of interactions in our dataset taken up by each feature, where negative numbers mean that a feature comprised a larger proportion of officers’ speech in interactions with black community members and positive numbers mean the same for interactions with white community members. Example utterances containing instances of the highest-weighted features for the Respect model are shown in &lt;a href="#F3" id="xref-fig-3-1"&gt;Fig. 3&lt;/a&gt;. See &lt;a href="http://www.pnas.org/lookup/suppl/doi:10.1073/pnas.1702413114/-/DCSupplemental/pnas.1702413114.sapp.pdf"&gt;&lt;em&gt;SI Appendix&lt;/em&gt;, &lt;em&gt;Study 2&lt;/em&gt;&lt;/a&gt; for full regression outputs and more detailed discussion of particular linguistic findings.&lt;/p&gt;&lt;div id="F2"&gt;&lt;div&gt;&lt;div&gt;&lt;p&gt;&lt;a data-hide-link-title="0" data-icon-position="" data-figure-caption="&lt;div class=&amp;quot;highwire-markup&amp;quot;&gt;&lt;div xmlns=&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;&gt;(&lt;em&gt;Left&lt;/em&gt;) Respect weights assigned by final model to linguistic features and (&lt;em&gt;Right&lt;/em&gt;) the corresponding log-odds of those features occurring in officer speech directed toward black versus white community members, calculated using Fisher’s exact test. &lt;sup&gt;†&lt;/sup&gt;&lt;em&gt;P&lt;/em&gt; &lt; 0.1; &lt;sup&gt;∗&lt;/sup&gt;&lt;em&gt;P&lt;/em&gt; &lt; 0.05; &lt;sup&gt;∗∗&lt;/sup&gt;&lt;em&gt;P&lt;/em&gt; &lt; 0.01; &lt;sup&gt;∗∗∗&lt;/sup&gt;&lt;em&gt;P&lt;/em&gt; &lt; 0.001.&lt;/div&gt;&lt;/div&gt;" rel="gallery-fragment-images-35030243" title="(Left) Respect weights assigned by final model to linguistic features and (Right) the corresponding log-odds of those features occurring in officer speech directed toward black versus white community members, calculated using Fisher’s exact test. †P &lt; 0.1; ∗P &lt; 0.05; ∗∗P &lt; 0.01; ∗∗∗P &lt; 0.001." href="https://www.pnas.org/content/pnas/114/25/6521/F2.large.jpg?width=800&amp;amp;height=600&amp;amp;carousel=1"&gt;&lt;span&gt;&lt;img height="440" width="420" data-src="https://www.pnas.org/content/pnas/114/25/6521/F2.medium.gif" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="Fig. 2."&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;a data-hide-link-title="0" data-icon-position="" title="Download Fig. 2." href="https://www.pnas.org/content/pnas/114/25/6521/F2.large.jpg?download=true"&gt;Download figure&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a data-hide-link-title="0" data-icon-position="" href="https://www.pnas.org/content/pnas/114/25/6521/F2.large.jpg"&gt;Open in new tab&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a data-hide-link-title="0" data-icon-position="" href="https://www.pnas.org/highwire/powerpoint/19754"&gt;Download powerpoint&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;/div&gt;&lt;div&gt;&lt;p&gt;&lt;span&gt;Fig. 2.&lt;/span&gt;&lt;/p&gt;&lt;p id="p-29"&gt;(&lt;em&gt;Left&lt;/em&gt;) Respect weights assigned by final model to linguistic features and (&lt;em&gt;Right&lt;/em&gt;) the corresponding log-odds of those features occurring in officer speech directed toward black versus white community members, calculated using Fisher’s exact test. &lt;sup&gt;†&lt;/sup&gt;&lt;em&gt;P&lt;/em&gt; &amp;lt; 0.1; &lt;sup&gt;∗&lt;/sup&gt;&lt;em&gt;P&lt;/em&gt; &amp;lt; 0.05; &lt;sup&gt;∗∗&lt;/sup&gt;&lt;em&gt;P&lt;/em&gt; &amp;lt; 0.01; &lt;sup&gt;∗∗∗&lt;/sup&gt;&lt;em&gt;P&lt;/em&gt; &amp;lt; 0.001.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id="F3"&gt;&lt;div&gt;&lt;div&gt;&lt;p&gt;&lt;a data-hide-link-title="0" data-icon-position="" data-figure-caption="&lt;div class=&amp;quot;highwire-markup&amp;quot;&gt;Sample sentences with automatically generated Respect scores. Features in blue have positive coefficients in the model and connote respect, such as offering reassurance (“no problem”) or mentioning community member well-being (“drive safe”). Features in red have negative coefficients in the model and connote disrespect, like informal titles (“my man”), or disfluencies (“that- that’s”).&lt;/div&gt;" rel="gallery-fragment-images-35030243" title="Sample sentences with automatically generated Respect scores. Features in blue have positive coefficients in the model and connote respect, such as offering reassurance (“no problem”) or mentioning community member well-being (“drive safe”). Features in red have negative coefficients in the model and connote disrespect, like informal titles (“my man”), or disfluencies (“that- that’s”)." href="https://www.pnas.org/content/pnas/114/25/6521/F3.large.jpg?width=800&amp;amp;height=600&amp;amp;carousel=1"&gt;&lt;span&gt;&lt;img height="440" width="321" data-src="https://www.pnas.org/content/pnas/114/25/6521/F3.medium.gif" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="Fig. 3."&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;a data-hide-link-title="0" data-icon-position="" title="Download Fig. 3." href="https://www.pnas.org/content/pnas/114/25/6521/F3.large.jpg?download=true"&gt;Download figure&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a data-hide-link-title="0" data-icon-position="" href="https://www.pnas.org/content/pnas/114/25/6521/F3.large.jpg"&gt;Open in new tab&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a data-hide-link-title="0" data-icon-position="" href="https://www.pnas.org/highwire/powerpoint/19756"&gt;Download powerpoint&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;/div&gt;&lt;div&gt;&lt;p&gt;&lt;span&gt;Fig. 3.&lt;/span&gt;&lt;/p&gt;&lt;p id="p-30"&gt;Sample sentences with automatically generated Respect scores. Features in blue have positive coefficients in the model and connote respect, such as offering reassurance (“no problem”) or mentioning community member well-being (“drive safe”). Features in red have negative coefficients in the model and connote disrespect, like informal titles (“my man”), or disfluencies (“that- that’s”).&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id="sec-4"&gt;&lt;h3&gt;Study 3: Racial Disparities in Respect.&lt;/h3&gt;&lt;p id="p-31"&gt;Having demonstrated that people can reliably infer features of procedural justice from officer speech (study 1), and that these ratings can be reliably predicted from statistical models of linguistic features (study 2), we are now able to address our central question: Controlling for contextual factors of the interaction, is officers’ language more respectful when speaking to white as opposed to black community members?&lt;/p&gt;&lt;p id="p-32"&gt;We apply our models from study 2 to the entire corpus of transcribed interactions to generate predicted scores for Respect and Formality for each of the 36,738 utterances in our dataset. We then build linear mixed-effects models for Respect and Formality over these utterances. We include, as covariates in our primary model, community member race, age, and gender; officer race; whether a search was conducted; and the result of the stop (warning, citation, or arrest). We include random intercepts for interactions nested within officers.&lt;/p&gt;&lt;p id="p-33"&gt;Controlling for these contextual factors, utterances spoken by officers to white community members score higher in Respect [&lt;span id="inline-formula-5"&gt;&lt;span&gt;β&lt;/span&gt;&lt;/span&gt; = 0.05 (0.03, 0.08)]. Officer utterances were also higher in Respect when spoken to older [&lt;span id="inline-formula-6"&gt;&lt;span&gt;β&lt;/span&gt;&lt;/span&gt; = 0.07 (0.05, 0.09)] community members and when a citation was issued [&lt;span id="inline-formula-7"&gt;&lt;span&gt;β&lt;/span&gt;&lt;/span&gt; = 0.04 (0.02, 0.06)]; Respect was lower in stops where a search was conducted [&lt;span id="inline-formula-8"&gt;&lt;span&gt;β&lt;/span&gt;&lt;/span&gt; = −0.08 (−0.11, −0.05)]. Officer race did not contribute a significant effect. Furthermore, in an additional model on 965 stops for which geographic information was available, neither the crime rate nor density of businesses in the area of the stop were significant, although a higher crime rate was indicative of increased Formality [&lt;span id="inline-formula-9"&gt;&lt;span&gt;β&lt;/span&gt;&lt;/span&gt; = 0.03 (0.01, 0.05)].&lt;/p&gt;&lt;p id="p-34"&gt;One might consider the hypothesis that officers were less respectful when pulling over community members for more severe offenses. We tested this by running another model on a subset of 869 interactions for which we obtained ratings of offense severity on a four-point Likert scale from Oakland Police Department officers, including these ratings as a covariate in addition to those mentioned above. We found that the offense severity was not predictive of officer respect levels, and did not substantially change the results described above.&lt;/p&gt;&lt;p id="p-35"&gt;To consider whether this disparity persists in the most “everyday” interactions, we also reran our analyses on the subset of interactions that did not involve arrests or searches (&lt;em&gt;N&lt;/em&gt; = 781), and found the results from our earlier models were fundamentally unchanged. Full regression tables for all models described above are given in &lt;a href="http://www.pnas.org/lookup/suppl/doi:10.1073/pnas.1702413114/-/DCSupplemental/pnas.1702413114.sapp.pdf"&gt;&lt;em&gt;SI Appendix&lt;/em&gt;, &lt;em&gt;Study 3&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p id="p-36"&gt;Another hypothesis is that the racial disparities might have been caused by officers being more formal to white community members, and more informal or colloquial to black community members. However, we found that race was not associated with the formality of officers’ utterances. Instead, utterances were higher in Formality in interactions with older [&lt;span id="inline-formula-10"&gt;&lt;span&gt;β&lt;/span&gt;&lt;/span&gt; = 0.05 (0.03, 0.07)] and female [&lt;span id="inline-formula-11"&gt;&lt;span&gt;β&lt;/span&gt;&lt;/span&gt; = 0.02 (0.00, 0.04)] community members.&lt;/p&gt;&lt;p id="p-37"&gt;Are the racial disparities in the respectfulness of officer speech we observe driven by a small number of officers? We calculated the officer-level difference between white and black stops for every officer (&lt;em&gt;N&lt;/em&gt; = 90) in the dataset who had interactions with both blacks and whites (&lt;a href="#F4" id="xref-fig-4-1"&gt;Fig. 4&lt;/a&gt;). We find a roughly normal distribution of these deltas for officers of all races. This contrasts with the case of stop-and-frisk, where individual outlier officers account for a substantial proportion of racial disparities (&lt;a href="#ref-27" id="xref-ref-27-1"&gt;27&lt;/a&gt;); the disparities we observe here cannot be explained by a small number of extreme officers.&lt;/p&gt;&lt;div id="F4"&gt;&lt;div&gt;&lt;div&gt;&lt;p&gt;&lt;a data-hide-link-title="0" data-icon-position="" data-figure-caption="&lt;div class=&amp;quot;highwire-markup&amp;quot;&gt;&lt;div xmlns=&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;&gt;Kernel density estimate of individual officer-level differences in Respect when talking to white as opposed to black community members, for the 90 officers in our dataset who have interactions with both blacks and whites. More positive numbers on the &lt;em&gt;x&lt;/em&gt; axis represent a greater positive shift in Respect toward white community members.&lt;/div&gt;&lt;/div&gt;" rel="gallery-fragment-images-35030243" title="Kernel density estimate of individual officer-level differences in Respect when talking to white as opposed to black community members, for the 90 officers in our dataset who have interactions with both blacks and whites. More positive numbers on the x axis represent a greater positive shift in Respect toward white community members." href="https://www.pnas.org/content/pnas/114/25/6521/F4.large.jpg?width=800&amp;amp;height=600&amp;amp;carousel=1"&gt;&lt;span&gt;&lt;img height="166" width="440" data-src="https://www.pnas.org/content/pnas/114/25/6521/F4.medium.gif" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="Fig. 4."&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;a data-hide-link-title="0" data-icon-position="" title="Download Fig. 4." href="https://www.pnas.org/content/pnas/114/25/6521/F4.large.jpg?download=true"&gt;Download figure&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a data-hide-link-title="0" data-icon-position="" href="https://www.pnas.org/content/pnas/114/25/6521/F4.large.jpg"&gt;Open in new tab&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a data-hide-link-title="0" data-icon-position="" href="https://www.pnas.org/highwire/powerpoint/19758"&gt;Download powerpoint&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;/div&gt;&lt;div&gt;&lt;p&gt;&lt;span&gt;Fig. 4.&lt;/span&gt;&lt;/p&gt;&lt;p id="p-38"&gt;Kernel density estimate of individual officer-level differences in Respect when talking to white as opposed to black community members, for the 90 officers in our dataset who have interactions with both blacks and whites. More positive numbers on the &lt;em&gt;x&lt;/em&gt; axis represent a greater positive shift in Respect toward white community members.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;p id="p-39"&gt;Because our model is able to generate scores across all utterances in our dataset, we can also consider aspects of the trajectory of interactions beyond the mean level of respect (&lt;a href="#F5" id="xref-fig-5-1"&gt;Fig. 5&lt;/a&gt;). Growth-curve analyses revealed that officers spoke with greater Respect [&lt;span id="inline-formula-12"&gt;&lt;span&gt;b&lt;/span&gt;&lt;/span&gt; = 0.35 (0.29, 0.40)] and reduced Formality [&lt;span id="inline-formula-13"&gt;&lt;span&gt;b&lt;/span&gt;&lt;/span&gt; = −0.57 (−0.62, −0.53)] as interactions progressed. However, these trajectories varied by community member race: Although stops of white and black drivers converged in the Formality expressed during the interaction [&lt;span id="inline-formula-14"&gt;&lt;span&gt;b&lt;/span&gt;&lt;/span&gt; = −0.09 (−0.13, −0.05)], the gap in Respect increased over time [&lt;span id="inline-formula-15"&gt;&lt;span&gt;b&lt;/span&gt;&lt;/span&gt; = 0.10 (0.05, 0.15)]. That is, officer Respect increased more quickly in interactions with white drivers [&lt;span id="inline-formula-16"&gt;&lt;span&gt;b&lt;/span&gt;&lt;/span&gt; = 0.45 (0.38, 0.54)] than in interactions with black drivers [&lt;span id="inline-formula-17"&gt;&lt;span&gt;b&lt;/span&gt;&lt;/span&gt; =  0.24 (0.19, 0.29)].&lt;/p&gt;&lt;div id="F5"&gt;&lt;div&gt;&lt;div&gt;&lt;p&gt;&lt;a data-hide-link-title="0" data-icon-position="" data-figure-caption="&lt;div class=&amp;quot;highwire-markup&amp;quot;&gt;&lt;div xmlns=&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;&gt;Loess-smoothed estimates of the (&lt;em&gt;Left&lt;/em&gt;) Respect and (&lt;em&gt;Right&lt;/em&gt;) Formality of officers’ utterances relative to the point in an interaction at which they occur. Respect tends to start low and increase over an interaction, whereas the opposite is true for Formality. The race discrepancy in Respect is consistent throughout the interactions in our dataset.&lt;/div&gt;&lt;/div&gt;" rel="gallery-fragment-images-35030243" title="Loess-smoothed estimates of the (Left) Respect and (Right) Formality of officers’ utterances relative to the point in an interaction at which they occur. Respect tends to start low and increase over an interaction, whereas the opposite is true for Formality. The race discrepancy in Respect is consistent throughout the interactions in our dataset." href="https://www.pnas.org/content/pnas/114/25/6521/F5.large.jpg?width=800&amp;amp;height=600&amp;amp;carousel=1"&gt;&lt;span&gt;&lt;img height="127" width="440" data-src="https://www.pnas.org/content/pnas/114/25/6521/F5.medium.gif" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="Fig. 5."&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;a data-hide-link-title="0" data-icon-position="" title="Download Fig. 5." href="https://www.pnas.org/content/pnas/114/25/6521/F5.large.jpg?download=true"&gt;Download figure&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a data-hide-link-title="0" data-icon-position="" href="https://www.pnas.org/content/pnas/114/25/6521/F5.large.jpg"&gt;Open in new tab&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a data-hide-link-title="0" data-icon-position="" href="https://www.pnas.org/highwire/powerpoint/19760"&gt;Download powerpoint&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;/div&gt;&lt;div&gt;&lt;p&gt;&lt;span&gt;Fig. 5.&lt;/span&gt;&lt;/p&gt;&lt;p id="p-40"&gt;Loess-smoothed estimates of the (&lt;em&gt;Left&lt;/em&gt;) Respect and (&lt;em&gt;Right&lt;/em&gt;) Formality of officers’ utterances relative to the point in an interaction at which they occur. Respect tends to start low and increase over an interaction, whereas the opposite is true for Formality. The race discrepancy in Respect is consistent throughout the interactions in our dataset.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id="sec-5"&gt;&lt;h3&gt;Discussion.&lt;/h3&gt;&lt;p id="p-41"&gt;Despite the formative role officer respect plays in establishing or eroding police legitimacy (&lt;a href="#ref-7" id="xref-ref-7-2"&gt;7&lt;/a&gt;), it has been impossible to measure how police officers communicate with the public, let alone gauge racial disparities in officer respect. However, body-worn cameras capture such interactions every day. Computational linguistic techniques let us examine police–community contacts in a manner powerful enough to scale to any number of interactions, but sensitive enough to capture the interpersonal qualities that matter to the police and public alike.&lt;/p&gt;&lt;p id="p-42"&gt;In doing so, we first showed that people make consistent judgments about such interactions from officers’ language, and we identified two underlying, uncorrelated constructs perceived by participants: Respect and Formality. We then built computational linguistic models of these constructs, identifying crucial positive and negative politeness strategies in the police–community interactional context. Applying these models to an entire month of vehicle stops, we showed strong evidence for racial disparities in Respect, but not in Formality: Officers’ language is less respectful when speaking to black community members.&lt;/p&gt;&lt;p id="p-43"&gt;Indeed, we find that white community members are 57% more likely to hear an officer say one of the most respectful utterances in our dataset, whereas black community members are 61% more likely to hear an officer say one of the least respectful utterances in our dataset. (Here we define the top 10% of utterances to be most respectful and the bottom 10% to be least respectful.)&lt;/p&gt;&lt;p id="p-44"&gt;This work demonstrates the power of body camera footage as an important source of data, not just as evidence, addressing limitations with methodologies that rely on citizens’ recollection of past interactions (&lt;a href="#ref-10" id="xref-ref-10-3"&gt;10&lt;/a&gt;) or direct researcher observation of police behavior (&lt;a href="#ref-17" id="xref-ref-17-2"&gt;17&lt;/a&gt;&lt;a href="#ref-18" id="xref-ref-18-2"&gt;&lt;span&gt;⇓&lt;/span&gt;&lt;/a&gt;&lt;a href="#ref-19" id="xref-ref-19-2"&gt;&lt;span&gt;⇓&lt;/span&gt;&lt;/a&gt;–&lt;a href="#ref-20" id="xref-ref-20-2"&gt;20&lt;/a&gt;). However, studying body camera footage presents numerous hurdles, including privacy concerns and the raw scale of the data. The computational linguistic models presented here offer a path toward addressing both these concerns, allowing for the analysis of transcribed datasets of any size, and generating reliable ratings of respect automatically. These models have the potential to allow for useful information about an interaction to be extracted while maintaining officer and community member privacy.&lt;/p&gt;&lt;p id="p-45"&gt;The racial disparities in officer respect are clear and consistent, yet the causes of these disparities are less clear. It is certainly possible that some of these disparities are prompted by the language and behavior of the community members themselves, particularly as historical tensions in Oakland and preexisting beliefs about the legitimacy of the police may induce fear, anger, or stereotype threat. However, community member speech cannot be the sole cause of these disparities. Study 1 found racial disparities in police language even when annotators judged that language in the context of the community member’s utterances. We observe racial disparities in officer respect even in police utterances from the initial 5% of an interaction, suggesting that officers speak differently to community members of different races even before the driver has had the opportunity to say much at all.&lt;/p&gt;&lt;p id="p-46"&gt;Regardless of cause, we have found that police officers’ interactions with blacks tend to be more fraught, not only in terms of disproportionate outcomes (as previous work has shown) but also interpersonally, even when no arrest is made and no use of force occurs. These disparities could have adverse downstream effects, as experiences of respect or disrespect in personal interactions with police officers play a central role in community members’ judgments of how procedurally fair the police are as an institution, as well as the community’s willingness to support or cooperate with the police (&lt;a href="#ref-8" id="xref-ref-8-2"&gt;8&lt;/a&gt;, &lt;a href="#ref-9" id="xref-ref-9-2"&gt;9&lt;/a&gt;).&lt;/p&gt;&lt;p id="p-47"&gt;We now have a method for quantifying these troubled interactions. Although the circumstances of any particular stop can vary dramatically, our approach allows us to measure aggregate department-level trends, revealing disparities across hundreds of interactions. These disparities are part of a constellation of differences in officer language spoken toward black versus white community members; a simple classifier trained on only the words used by officers is able to correctly predict the race of the community member in over two thirds of the interactions (see &lt;a href="http://www.pnas.org/lookup/suppl/doi:10.1073/pnas.1702413114/-/DCSupplemental/pnas.1702413114.sapp.pdf"&gt;&lt;em&gt;SI Appendix&lt;/em&gt;, &lt;em&gt;Linguistic Classification Accuracy of Race&lt;/em&gt;&lt;/a&gt;).&lt;/p&gt;&lt;p id="p-48"&gt;Future research could expand body camera analysis beyond text to include information from the audio such as speech intonation and emotional prosody, and video, such as the citizen’s facial expressions and body movement, offering even more insight into how interactions progress and can sometimes go awry. In addition, footage analysis could help us better understand what linguistic acts lead interactions to go well, which can inform police training and quantify its impacts over time.&lt;/p&gt;&lt;p id="p-49"&gt;The studies presented here open a path toward these future opportunities and represent an important area of research for the study of policing: Computational, large-scale analyses of language give us a way to examine and improve police–community interaction that we have never had before.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id="sec-6"&gt;&lt;h2&gt;Materials and Methods&lt;/h2&gt;&lt;div id="sec-7"&gt;&lt;h3&gt;Data and Processing.&lt;/h3&gt;&lt;p id="p-50"&gt;The video for each traffic stop was transcribed into text by professional transcribers, who transcribed while listening to audio and watching the video. Extensive measures were taken to preserve privacy; data were kept on a central server, and transcribers (as well as all researchers) underwent background checks with the Oakland Police Department. Transcribers also “diarized” the text (labeling who was speaking at each time point). We used the diarization to automatically remove all officer speech to the dispatcher or to other officers, leaving only speech from the officer directed toward the community member. After transcription, transcripts were manually cleaned up, heuristically fixing transcriber diarization errors, and correcting typographical errors involving utterance timing so that all transcripts were automatically readable. Every utterance in the dataset was processed with Stanford CoreNLP 3.4.1 (&lt;a href="#ref-28" id="xref-ref-28-1"&gt;28&lt;/a&gt;) to generate sentence and word segmentation, part-of-speech tags, and dependency parses used for feature extraction and analysis.&lt;/p&gt;&lt;p id="p-51"&gt;The raw video footage associated with this paper was available for our research purposes with the cooperation of the Oakland Police Department, and naturally cannot be publicly distributed. However, we make available deidentified data frames for each study described here, so that other researchers can replicate our results. We also release all of the code for the computational linguistic models, as well as pretrained models that can be run on arbitrary text.&lt;/p&gt;&lt;/div&gt;&lt;div id="sec-8"&gt;&lt;h3&gt;Human Annotation of Utterances.&lt;/h3&gt;&lt;p id="p-52"&gt;A subset of 420 exchanges, consisting of one officer utterance (defined as a “turn” of one or more sentences by transcribers) and, if applicable, the immediately preceding community member utterance were sampled from the corpus for annotation. Utterances were sampled with the constraint that at least 15 words were spoken between the two speakers, and that at least five words were spoken by the officer. These utterances were grouped into seven “batches” of 60 utterances apiece. Due to a data error, six duplicate utterances were annotated, but were excluded from subsequent analyses, resulting in 414 unique utterances toward black (&lt;em&gt;N&lt;/em&gt; = 312) and white (&lt;em&gt;N&lt;/em&gt; = 102) community members.&lt;/p&gt;&lt;p id="p-53"&gt;Each of 70 participants (39 female, &lt;span id="inline-formula-18"&gt;&lt;span&gt;Mage&lt;/span&gt;&lt;/span&gt; = 25.3) rated a batch of 60 of these utterances, such that each utterance was rated by at least 10 participants. On each trial, participants viewed the text of an exchange between a police officer and a community member: the text of the officer utterance, as well as the text of the community member utterance that immediately preceded it, if there was one. They then indicated, on four-point bipolar Likert scales, how respectful, polite, friendly, formal, and impartial the officer was in each exchange. Participants were allowed to indicate that they could not rate an utterance on a particular dimension, but were encouraged to nonetheless indicate their best guess. Participants had no other information about the interaction besides the officer’s utterance and the immediately preceding community member utterance.&lt;/p&gt;&lt;p id="p-54"&gt;All research was approved by the Stanford University Institutional Review Board, and written informed consent was obtained from all raters before their participation.&lt;/p&gt;&lt;/div&gt;&lt;div id="sec-9"&gt;&lt;h3&gt;Computational Annotation of Utterances.&lt;/h3&gt;&lt;p id="p-55"&gt;Our model draws on linguistic theories of politeness; the technical term “politeness” refers to how concepts like respect, formality, and social distance take shape in language. These theories suggest that speakers use polite or respectful language to mitigate face-threatening acts (&lt;a href="#ref-29" id="xref-ref-29-1"&gt;29&lt;/a&gt;&lt;a href="#ref-30" id="xref-ref-30-1"&gt;&lt;span&gt;⇓&lt;/span&gt;&lt;/a&gt;–&lt;a href="#ref-31" id="xref-ref-31-1"&gt;31&lt;/a&gt;).&lt;/p&gt;&lt;p id="p-56"&gt;Negative politeness is used to mitigate direct commands or other impositions that limit the freedom of action of the listener, for example, by minimizing the imposition or emphasizing the agency of the interlocutor. Such strategies are central to police–community interactions because of the inherently coercive nature of a traffic stop. For instance, the use of the word “please” can soften requests and provide a sense of agency or choice; apologizing (“sorry,” “excuse me”) can admit regret on the part of the officer that some request is necessary; the use of hedges (“may,” “kinda,” “probably”) may reduce the perception of imposition.&lt;/p&gt;&lt;p id="p-57"&gt;Positive politeness is used to show that the speaker values the interlocutor and their interests, or to minimize the impact of actions that could damage such a perception. Positive politeness strategies are also crucial for police–community interactions, where the inherently unequal social roles at play may necessitate a particular sensitivity to the community member’s positive face. For instance, greetings and introductions can establish a friendly context at the beginning of an interaction and convey openness. Expressions of reassurance (“no big deal,” “don’t worry”) seek to assuage the community member’s potential concerns in tense circumstances, and expressions of gratitude (“thank you”) serve to reduce the perceived power differential by deferring to the actions of the community member. Mentions of safety (“Drive safely now”) explicitly acknowledge concern for the community member’s personal well-being. Referring expressions are another important component of positive politeness; formal titles (“sir,” “ma’am,” “Mr.,” “Ms.”) and surnames may convey a contrast with informal titles (“dude,” “bro,” “bud”) and first names (&lt;a href="#ref-31" id="xref-ref-31-2"&gt;31&lt;/a&gt;&lt;a href="#ref-32" id="xref-ref-32-1"&gt;&lt;span&gt;⇓&lt;/span&gt;&lt;/a&gt;–&lt;a href="#ref-33" id="xref-ref-33-1"&gt;33&lt;/a&gt;).&lt;/p&gt;&lt;p id="p-58"&gt;We also include features we expect to capture officer anxiety, such as speech disfluencies (“w- well”) and commands to keep “hands on the wheel,” which may contribute to a community member’s perception of disrespect. These are of a different character than the politeness strategies discussed above, but we found that all analyses presented here hold true even if these features are not included.&lt;/p&gt;&lt;p id="p-59"&gt;We use standard techniques to automatically extract features from the text of each utterance (&lt;a href="#ref-23" id="xref-ref-23-2"&gt;23&lt;/a&gt;&lt;a href="#ref-24" id="xref-ref-24-2"&gt;&lt;span&gt;⇓&lt;/span&gt;&lt;/a&gt;&lt;a href="#ref-25" id="xref-ref-25-2"&gt;&lt;span&gt;⇓&lt;/span&gt;&lt;/a&gt;–&lt;a href="#ref-26" id="xref-ref-26-2"&gt;26&lt;/a&gt;). These features include lexicons (lists of words). For example, to detect informal titles, we used an augmented version of a word list from ref. &lt;a href="#ref-34" id="xref-ref-34-1"&gt;34&lt;/a&gt;. We also used regular expressions, such as for detecting tag questions (“do that for me, will you?”), and syntactic parse features, such as a feature that detects when “just” is used in constructions as an adverbial modifier.&lt;/p&gt;&lt;p id="p-60"&gt;Features were modeled as log-transformed counts in each utterance, and were used as independent variables in two linear regression models predicting the human perceptual ratings of respect and formality obtained in study 1. They were introduced into the regression using stepwise forward selection by &lt;em&gt;R&lt;/em&gt;&lt;sup&gt;2&lt;/sup&gt; to remove features that don’t substantially contribute to the model’s accuracy.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id="ack-1"&gt;&lt;h2&gt;Acknowledgments&lt;/h2&gt;&lt;p id="p-61"&gt;This research was supported by the John D. and Catherine T. MacArthur Foundation, with additional support from the Stanford Institute for Research in the Social Sciences, the Stanford School of Humanities and Sciences, and the Stanford Data Science Initiative. We also thank the City of Oakland and the Oakland Police Department for their support and cooperation.&lt;/p&gt;&lt;/div&gt;&lt;div id="fn-group-1"&gt;&lt;h2&gt;Footnotes&lt;/h2&gt;&lt;ul&gt;&lt;li id="fn-2"&gt;&lt;p id="p-2"&gt;Author contributions: R.V., N.P.C., D. Jurafsky, and J.L.E. designed research; R.V. and N.P.C. performed research; V.P., W.L.H., R.C.H., C.M.G., and D. Jurgens contributed new reagents/analytic tools; R.V. and N.P.C. analyzed data; R.V., N.P.C., D. Jurafsky, and J.L.E. wrote the paper; and D. Jurafsky and J.L.E. served as PI on this project.&lt;/p&gt;&lt;/li&gt;&lt;li id="fn-3"&gt;&lt;p id="p-3"&gt;Reviewers: J.P., University of Texas at Austin; and T.T., Yale Law School.&lt;/p&gt;&lt;/li&gt;&lt;li id="fn-4"&gt;&lt;p id="p-62"&gt;Conflict of interest statement: J.L.E. was invited by a federal judge and monitor to serve as a Subject Matter Expert to assist with the Oakland Police Department’s reform efforts. The assignment began prior to the studies reported here.&lt;/p&gt;&lt;/li&gt;&lt;li id="fn-5"&gt;&lt;p id="p-63"&gt;This article contains supporting information online at &lt;a href="http://www.pnas.org/lookup/suppl/doi:10.1073/pnas.1702413114/-/DCSupplemental"&gt;www.pnas.org/lookup/suppl/doi:10.1073/pnas.1702413114/-/DCSupplemental&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;&lt;a data-hide-link-title="0" data-icon-position="" href="https://www.pnas.org/content/114/25/6521.abstract"&gt;View Abstract&lt;/a&gt;&lt;/p&gt;&lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://www.pnas.org/content/114/25/6521"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Fri, 12 Jun 2020 12:04:00 UT
      </pubDate>
      <guid>
        https://www.pnas.org/content/114/25/6521
      </guid>
    </item>
    <item>
      <title>
        A Survival Guide to a PhD
      </title>
      <link>
        https://karpathy.github.io/2016/09/07/phd/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;article&gt; &lt;p&gt;This guide is patterned after my &lt;a href="http://cs.stanford.edu/people/karpathy/advice.html"&gt;“Doing well in your courses”&lt;/a&gt;, a post I wrote a long time ago on some of the tips/tricks I’ve developed during my undergrad. I’ve received nice comments about that guide, so in the same spirit, now that my PhD has come to an end I wanted to compile a similar retrospective document in hopes that it might be helpful to some. Unlike the undergraduate guide, this one was much more difficult to write because there is significantly more variation in how one can traverse the PhD experience. Therefore, many things are likely contentious and a good fraction will be specific to what I’m familiar with (Computer Science / Machine Learning / Computer Vision research). But disclaimers are boring, lets get to it!&lt;/p&gt; &lt;h3 id="preliminaries"&gt;Preliminaries&lt;/h3&gt; &lt;p&gt;&lt;img src="https://karpathy.github.io/assets/phd/phds.jpg"&gt; &lt;/p&gt; &lt;p&gt;First, should you want to get a PhD? I was in a fortunate position of knowing since young age that I really wanted a PhD. Unfortunately it wasn’t for any very well-thought-through considerations: First, I really liked school and learning things and I wanted to learn as much as possible, and second, I really wanted to be like &lt;a href="https://en.wikipedia.org/wiki/Gordon_Freeman"&gt;Gordon Freeman&lt;/a&gt; from the game Half-Life (who has a PhD from MIT in theoretical physics). I loved that game. But what if you’re more sensible in making your life’s decisions? Should you want to do a PhD? There’s a very nice &lt;a href="https://www.quora.com/I-got-a-job-offer-from-Google-Facebook-Microsoft-and-I-also-got-accepted-into-the-PhD-in-Computer-Science-program-at-MIT-Stanford-Berkeley-What-factors-should-I-consider-while-making-a-choice-between-the-two"&gt;Quora thread&lt;/a&gt; and in the summary of considerations that follows I’ll borrow/restate several from Justin/Ben/others there. I’ll assume that the second option you are considering is joining a medium-large company (which is likely most common). Ask yourself if you find the following properties appealing:&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Freedom.&lt;/strong&gt; A PhD will offer you a lot of freedom in the topics you wish to pursue and learn about. You’re in charge. Of course, you’ll have an adviser who will impose some constraints but in general you’ll have much more freedom than you might find elsewhere.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Ownership.&lt;/strong&gt; The research you produce will be yours as an individual. Your accomplishments will have your name attached to them. In contrast, it is much more common to “blend in” inside a larger company. A common feeling here is becoming a “cog in a wheel”.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Exclusivity&lt;/strong&gt;. There are very few people who make it to the top PhD programs. You’d be joining a group of a few hundred distinguished individuals in contrast to a few tens of thousands (?) that will join some company.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Status.&lt;/strong&gt; Regardless of whether it should be or not, working towards and eventually getting a PhD degree is culturally revered and recognized as an impressive achievement. You also get to be a Doctor; that’s awesome.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Personal freedom.&lt;/strong&gt; As a PhD student you’re your own boss. Want to sleep in today? Sure. Want to skip a day and go on a vacation? Sure. All that matters is your final output and no one will force you to clock in from 9am to 5pm. Of course, some advisers might be more or less flexible about it and some companies might be as well, but it’s a true first order statement.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Maximizing future choice.&lt;/strong&gt; Joining a PhD program doesn’t close any doors or eliminate future employment/lifestyle options. You can go one way (PhD -&amp;gt; anywhere else) but not the other (anywhere else -&amp;gt; PhD -&amp;gt; academia/research; it is statistically less likely). Additionally (although this might be quite specific to applied ML), you’re strictly more hirable as a PhD graduate or even as a PhD dropout and many companies might be willing to put you in a more interesting position or with a higher starting salary. More generally, maximizing choice for the future you is a good heuristic to follow.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Maximizing variance.&lt;/strong&gt; You’re young and there’s really no need to rush. Once you graduate from a PhD you can spend the next ~50 years of your life in some company. Opt for more variance in your experiences.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Personal growth.&lt;/strong&gt; PhD is an intense experience of rapid growth (you learn a lot) and personal self-discovery (you’ll become a master of managing your own psychology). PhD programs (especially if you can make it into a good one) also offer a &lt;em&gt;high density&lt;/em&gt; of exceptionally bright people who will become your best friends forever.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Expertise.&lt;/strong&gt; PhD is probably your only opportunity in life to really drill deep into a topic and become a recognized leading expert &lt;em&gt;in the world&lt;/em&gt; at something. You’re exploring the edge of our knowledge as a species, without the burden of lesser distractions or constraints. There’s something beautiful about that and if you disagree, it could be a sign that PhD is not for you.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;The disclaimer&lt;/strong&gt;. I wanted to also add a few words on some of the potential downsides and failure modes. The PhD is a very specific kind of experience that deserves a large disclaimer. You will inevitably find yourself working very hard (especially before paper deadlines). You need to be okay with the suffering and have enough mental stamina and determination to deal with the pressure. At some points you will lose track of what day of the week it is and go on a diet of leftover food from the microkitchens. You’ll sit exhausted and alone in the lab on a beautiful, sunny Saturday scrolling through Facebook pictures of your friends having fun on exotic trips, paid for by their 5-10x larger salaries. You will have to throw away 3 months of your work while somehow keeping your mental health intact. You’ll struggle with the realization that months of your work were spent on a paper with a few citations while your friends do exciting startups with TechCrunch articles or push products to millions of people. You’ll experience identity crises during which you’ll question your life decisions and wonder what you’re doing with some of the best years of your life. As a result, you should be quite certain that you can thrive in an unstructured environment in the pursuit research and discovery for science. If you’re unsure you should lean slightly negative by default. Ideally you should consider getting a taste of research as an undergraduate on a summer research program before before you decide to commit. In fact, one of the primary reasons that research experience is so desirable during the PhD hiring process is not the research itself, but the fact that the student is more likely to know what they’re getting themselves into.&lt;/p&gt; &lt;p&gt;I should clarify explicitly that this post is not about convincing anyone to do a PhD, I’ve merely tried to enumerate some of the common considerations above. The majority of this post focuses on some tips/tricks for navigating the experience once if you decide to go for it (which we’ll see shortly, below).&lt;/p&gt; &lt;p&gt;Lastly, as a random thought I heard it said that you should only do a PhD if you want to go into academia. In light of all of the above I’d argue that a PhD has strong intrinsic value - it’s an end by itself, not just a means to some end (e.g. academic job).&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Getting into a PhD program: references, references, references.&lt;/strong&gt; Great, you’ve decided to go for it. Now how do you get into a good PhD program? The first order approximation is quite simple - by far most important component are strong reference letters. The ideal scenario is that a well-known professor writes you a letter along the lines of: “Blah is in top 5 of students I’ve ever worked with. She takes initiative, comes up with her own ideas, and gets them to work.” The worst letter is along the lines of: “Blah took my class. She did well.” A research publication under your belt from a summer research program is a very strong bonus, but not absolutely required provided you have strong letters. In particular note: grades are quite irrelevant but you generally don’t want them to be too low. This was not obvious to me as an undergrad and I spent a lot of energy on getting good grades. This time should have instead been directed towards research (or at the very least personal projects), as much and as early as possible, and if possible under supervision of multiple people (you’ll need 3+ letters!). As a last point, what won’t help you too much is pestering your potential advisers out of the blue. They are often incredibly busy people and if you try to approach them too aggressively in an effort to impress them somehow in conferences or over email this may agitate them.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Picking the school&lt;/strong&gt;. Once you get into some PhD programs, how do you pick the school? It’s easy, join Stanford! Just kidding. More seriously, your dream school should 1) be a top school (not because it looks good on your resume/CV but because of feedback loops; top schools attract other top people, many of whom you will get to know and work with) 2) have a few potential advisers you would want to work with. I really do mean the “few” part - this is very important and provides a safety cushion for you if things don’t work out with your top choice for any one of hundreds of reasons - things in many cases outside of your control, e.g. your dream professor leaves, moves, or spontaneously disappears, and 3) be in a good environment physically. I don’t think new admits appreciate this enough: you will spend 5+ years of your really good years living near the school campus. Trust me, this is a long time and your life will consist of much more than just research.&lt;/p&gt; &lt;h3 id="adviser"&gt;Adviser&lt;/h3&gt; &lt;div&gt; &lt;p&gt;&lt;img src="https://karpathy.github.io/assets/phd/adviser.gif"&gt;&lt;/p&gt; &lt;/div&gt; &lt;p&gt;&lt;strong&gt;Student adviser relationship&lt;/strong&gt;. The adviser is an extremely important person who will exercise a lot of influence over your PhD experience. It’s important to understand the nature of the relationship: the adviser-student relationship is a symbiosis; you have your own goals and want something out of your PhD, but they also have their own goals, constraints and they’re building their own career. Therefore, it is very helpful to understand your adviser’s incentive structures: how the tenure process works, how they are evaluated, how they get funding, how they fund you, what department politics they might be embedded in, how they win awards, how academia in general works and specifically how they gain recognition and respect of their colleagues. This alone will help you avoid or mitigate a large fraction of student-adviser friction points and allow you to plan appropriately. I also don’t want to make the relationship sound too much like a business transaction. The advisor-student relationship, more often that not, ends up developing into a lasting one, predicated on much more than just career advancement.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Pre-vs-post tenure&lt;/strong&gt;. Every adviser is different so it’s helpful to understand the axes of variations and their repercussions on your PhD experience. As one rule of thumb (and keep in mind there are many exceptions), it’s important to keep track of whether a potential adviser is pre-tenure or post-tenure. The younger faculty members will usually be around more (they are working hard to get tenure) and will usually be more low-level, have stronger opinions on what you should be working on, they’ll do math with you, pitch concrete ideas, or even look at (or contribute to) your code. This is a much more hands-on and possibly intense experience because the adviser will need a strong publication record to get tenure and they are incentivised to push you to work just as hard. In contrast, more senior faculty members may have larger labs and tend to have many other commitments (e.g. committees, talks, travel) other than research, which means that they can only afford to stay on a higher level of abstraction both in the area of their research and in the level of supervision for their students. To caricature, it’s a difference between “you’re missing a second term in that equation” and “you may want to read up more in this area, talk to this or that person, and sell your work this or that way”. In the latter case, the low-level advice can still come from the senior PhD students in the lab or the postdocs.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Axes of variation&lt;/strong&gt;. There are many other axes to be aware of. Some advisers are fluffy and some prefer to keep your relationship very professional. Some will try to exercise a lot of influence on the details of your work and some are much more hands off. Some will have a focus on specific models and their applications to various tasks while some will focus on tasks and more indifference towards any particular modeling approach. In terms of more managerial properties, some will meet you every week (or day!) multiple times and some you won’t see for months. Some advisers answer emails right away and some don’t answer email for a week (or ever, haha). Some advisers make demands about your work schedule (e.g. you better work long hours or weekends) and some won’t. Some advisers generously support their students with equipment and some think laptops or old computers are mostly fine. Some advisers will fund you to go to a conferences even if you don’t have a paper there and some won’t. Some advisers are entrepreneurial or applied and some lean more towards theoretical work. Some will let you do summer internships and some will consider internships just a distraction.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Finding an adviser&lt;/strong&gt;. So how do you pick an adviser? The first stop, of course, is to talk to them in person. The student-adviser relationship is sometimes referred to as a marriage and you should make sure that there is a good fit. Of course, first you want to make sure that you can talk with them and that you get along personally, but it’s also important to get an idea of what area of “professor space” they occupy with respect to the aforementioned axes, and especially whether there is an intellectual resonance between the two of you in terms of the problems you are interested in. This can be just as important as their management style.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Collecting references&lt;/strong&gt;. You should also collect references on your potential adviser. One good strategy is to talk to their students. If you want to get actual information this shouldn’t be done in a very formal way or setting but in a relaxed environment or mood (e.g. a party). In many cases the students might still avoid saying bad things about the adviser if asked in a general manner, but they will usually answer truthfully when you ask specific questions, e.g. “how often do you meet?”, or “how hands on are they?”. Another strategy is to look at where their previous students ended up (you can usually find this on the website under an alumni section), which of course also statistically informs your own eventual outcome.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Impressing an adviser&lt;/strong&gt;. The adviser-student matching process is sometimes compared to a marriage - you pick them but they also pick you. The ideal student from their perspective is someone with interest and passion, someone who doesn’t need too much hand-holding, and someone who takes initiative - who shows up a week later having done not just what the adviser suggested, but who went beyond it; improved on it in unexpected ways.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Consider the entire lab&lt;/strong&gt;. Another important point to realize is that you’ll be seeing your adviser maybe once a week but you’ll be seeing most of their students every single day in the lab and they will go on to become your closest friends. In most cases you will also end up collaborating with some of the senior PhD students or postdocs and they will play a role very similar to that of your adviser. The postdocs, in particular, are professors-in-training and they will likely be eager to work with you as they are trying to gain advising experience they can point to for their academic job search. Therefore, you want to make sure the entire group has people you can get along with, people you respect and who you can work with closely on research projects.&lt;/p&gt; &lt;h3 id="research-topics"&gt;Research topics&lt;/h3&gt; &lt;div&gt; &lt;p&gt;&lt;img src="https://karpathy.github.io/assets/phd/arxiv-papers.png"&gt;&lt;/p&gt;&lt;p&gt;t-SNE visualization of a small subset of human knowledge (from &lt;a href="http://paperscape.org/"&gt;paperscape&lt;/a&gt;). Each circle is an arxiv paper and size indicates the number of citations.&lt;/p&gt; &lt;/div&gt; &lt;p&gt;So you’ve entered a PhD program and found an adviser. Now what do you work on?&lt;/p&gt; &lt;p&gt;&lt;strong&gt;An exercise in the outer loop.&lt;/strong&gt; First note the nature of the experience. A PhD is simultaneously a fun and frustrating experience because you’re constantly operating on a meta problem level. You’re not just solving problems - that’s merely the simple inner loop. You spend most of your time on the outer loop, figuring out what problems are worth solving and what problems are ripe for solving. You’re constantly imagining yourself solving hypothetical problems and asking yourself where that puts you, what it could unlock, or if anyone cares. If you’re like me this can sometimes drive you a little crazy because you’re spending long hours working on things and you’re not even sure if they are the correct things to work on or if a solution exists.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Developing taste&lt;/strong&gt;. When it comes to choosing problems you’ll hear academics talk about a mystical sense of “taste”. It’s a real thing. When you pitch a potential problem to your adviser you’ll either see their face contort, their eyes rolling, and their attention drift, or you’ll sense the excitement in their eyes as they contemplate the uncharted territory ripe for exploration. In that split second a lot happens: an evaluation of the problem’s importance, difficulty, its &lt;em&gt;sexiness&lt;/em&gt;, its historical context (and possibly also its fit to their active grants). In other words, your adviser is likely to be a master of the outer loop and will have a highly developed sense of &lt;em&gt;taste&lt;/em&gt; for problems. During your PhD you’ll get to acquire this sense yourself.&lt;/p&gt; &lt;p&gt;In particular, I think I had a terrible taste coming in to the PhD. I can see this from the notes I took in my early PhD years. A lot of the problems I was excited about at the time were in retrospect poorly conceived, intractable, or irrelevant. I’d like to think I refined the sense by the end through practice and apprenticeship.&lt;/p&gt; &lt;p&gt;Let me now try to serialize a few thoughts on what goes into this sense of taste, and what makes a problem interesting to work on.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;A fertile ground.&lt;/strong&gt; First, recognize that during your PhD you will dive deeply into one area and your papers will very likely chain on top of each other to create a body of work (which becomes your thesis). Therefore, you should always be thinking several steps ahead when choosing a problem. It’s impossible to predict how things will unfold but you can often get a sense of how much room there could be for additional work.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Plays to your adviser’s interests and strengths&lt;/strong&gt;. You will want to operate in the realm of your adviser’s interest. Some advisers may allow you to work on slightly tangential areas but you would not be taking full advantage of their knowledge and you are making them less likely to want to help you with your project or promote your work. For instance, (and this goes to my previous point of understanding your adviser’s job) every adviser has a “default talk” slide deck on their research that they give all the time and if your work can add new exciting cutting edge work slides to this deck then you’ll find them much more invested, helpful and involved in your research. Additionally, their talks will promote and publicize your work.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Be ambitious: the sublinear scaling of hardness.&lt;/strong&gt; People have a strange bug built into psychology: a 10x more important or impactful problem intuitively &lt;em&gt;feels&lt;/em&gt; 10x harder (or 10x less likely) to achieve. This is a fallacy - in my experience a 10x more important problem is at most 2-3x harder to achieve. In fact, in some cases a 10x harder problem may be easier to achieve. How is this? It’s because thinking 10x forces you out of the box, to confront the real limitations of an approach, to think from first principles, to change the strategy completely, to innovate. If you aspire to improve something by 10% and work hard then you will. But if you aspire to improve it by 100% you are still quite likely to, but you will do it very differently.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Ambitious but with an attack.&lt;/strong&gt; At this point it’s also important to point out that there are plenty of important problems that don’t make great projects. I recommend reading &lt;a href="https://karpathy.github.io/2016/09/07/phd/You%20and%20Your%20Research"&gt;You and Your Research&lt;/a&gt; by Richard Hamming, where this point is expanded on:&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;If you do not work on an important problem, it’s unlikely you’ll do important work. It’s perfectly obvious. Great scientists have thought through, in a careful way, a number of important problems in their field, and they keep an eye on wondering how to attack them. Let me warn you, `important problem’ must be phrased carefully. The three outstanding problems in physics, in a certain sense, were never worked on while I was at Bell Labs. By important I mean guaranteed a Nobel Prize and any sum of money you want to mention. We didn’t work on (1) time travel, (2) teleportation, and (3) antigravity. They are not important problems because we do not have an attack. It’s not the consequence that makes a problem important, it is that you have a reasonable attack. That is what makes a problem important.&lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt;&lt;strong&gt;The person who did X&lt;/strong&gt;. Ultimately, the goal of a PhD is to not only develop a deep expertise in a field but to also make your mark upon it. To steer it, shape it. The ideal scenario is that by the end of the PhD you own some part of an important area, preferably one that is also easy and fast to describe. You want people to say things like “she’s the person who did X”. If you can fill in a blank there you’ll be successful.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Valuable skills.&lt;/strong&gt; Recognize that during your PhD you will become an expert at the area of your choosing (as fun aside, note that [5 years]x[260 working days]x[8 hours per day] is 10,400 hours; if you believe Gladwell then a PhD is exactly the amount of time to become an expert). So imagine yourself 5 years later being a world expert in this area (the 10,000 hours will ensure that regardless of the academic impact of your work). Are these skills exciting or potentially valuable to your future endeavors?&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Negative examples.&lt;/strong&gt; There are also some problems or types of papers that you ideally want to avoid. For instance, you’ll sometimes hear academics talk about &lt;em&gt;“incremental work”&lt;/em&gt; (this is the worst adjective possible in academia). Incremental work is a paper that enhances something existing by making it more complex and gets 2% extra on some benchmark. The amusing thing about these papers is that they have a reasonably high chance of getting accepted (a reviewer can’t point to anything to kill them; they are also sometimes referred to as “&lt;em&gt;cockroach papers&lt;/em&gt;”), so if you have a string of these papers accepted you can feel as though you’re being very productive, but in fact these papers won’t go on to be highly cited and you won’t go on to have a lot of impact on the field. Similarly, finding projects should ideally not include thoughts along the lines of “there’s this next logical step in the air that no one has done yet, let me do it”, or “this should be an easy poster”.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Case study: my thesis&lt;/strong&gt;. To make some of this discussion more concrete I wanted to use the example of how my own PhD unfolded. First, fun fact: my entire thesis is based on work I did in the last 1.5 years of my PhD. i.e. it took me quite a long time to wiggle around in the metaproblem space and find a problem that I felt very excited to work on (the other ~2 years I mostly meandered on 3D things (e.g. Kinect Fusion, 3D meshes, point cloud features) and video things). Then at one point in my 3rd year I randomly stopped by Richard Socher’s office on some Saturday at 2am. We had a chat about interesting problems and I realized that some of his work on images and language was in fact getting at something very interesting (of course, the area at the intersection of images and language goes back quite a lot further than Richard as well). I couldn’t quite see all the papers that would follow but it seemed heuristically very promising: it was highly fertile (a lot of unsolved problems, a lot of interesting possibilities on grounding descriptions to images), I felt that it was very cool and important, it was easy to explain, it seemed to be at the boundary of possible (Deep Learning has just started to work), the datasets had just started to become available (Flickr8K had just come out), it fit nicely into Fei-Fei’s interests and even if I were not successful I’d at least get lots of practice with optimizing interesting deep nets that I could reapply elsewhere. I had a strong feeling of a tsunami of checkmarks as everything clicked in place in my mind. I pitched this to Fei-Fei (my adviser) as an area to dive into the next day and, with relief, she enthusiastically approved, encouraged me, and would later go on to steer me within the space (e.g. Fei-Fei insisted that I do image to sentence generation while I was mostly content with ranking.). I’m happy with how things evolved from there. In short, I meandered around for 2 years stuck around the outer loop, finding something to dive into. Once it clicked for me what that was based on several heuristics, I dug in.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Resistance&lt;/strong&gt;. I’d like to also mention that your adviser is by no means infallible. I’ve witnessed and heard of many instances in which, in retrospect, the adviser made the wrong call. If you feel this way during your phd you should have the courage to sometimes ignore your adviser. Academia generally celebrates independent thinking but the response of your specific adviser can vary depending on circumstances. I’m aware of multiple cases where the bet worked out very well and I’ve also personally experienced cases where it did not. For instance, I disagreed strongly with some advice Andrew Ng gave me in my very first year. I ended up working on a problem he wasn’t very excited about and, surprise, he turned out to be very right and I wasted a few months. Win some lose some :)&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Don’t play the game.&lt;/strong&gt; Finally, I’d like to challenge you to think of a PhD as more than just a sequence of papers. You’re not a paper writer. You’re a member of a research community and your goal is to push the field forward. Papers are one common way of doing that but I would encourage you to look beyond the established academic game. Think for yourself and from first principles. Do things others don’t do but should. Step off the treadmill that has been put before you. I tried to do some of this myself throughout my PhD. This blog is an example - it allows me communicate things that wouldn’t ordinarily go into papers. The ImageNet human reference experiments are an example - I felt strongly that it was important for the field to know the ballpark human accuracy on ILSVRC so I took a few weeks off and evaluated it. The academic search tools (e.g. arxiv-sanity) are an example - I felt continuously frustrated by the inefficiency of finding papers in the literature and I released and maintain the site in hopes that it can be useful to others. Teaching CS231n twice is an example - I put much more effort into it than is rationally advisable for a PhD student who should be doing research, but I felt that the field was held back if people couldn’t efficiently learn about the topic and enter. A lot of my PhD endeavors have likely come at a cost in standard academic metrics (e.g. h-index, or number of publications in top venues) but I did them anyway, I would do it the same way again, and here I am encouraging others to as well. To add a pitch of salt and wash down the ideology a bit, based on several past discussions with my friends and colleagues I know that this view is contentious and that many would disagree.&lt;/p&gt; &lt;h3 id="writing-papers"&gt;Writing papers&lt;/h3&gt; &lt;p&gt;&lt;img src="https://karpathy.github.io/assets/phd/latex.png"&gt; &lt;/p&gt; &lt;p&gt;Writing good papers is an essential survival skill of an academic (kind of like making fire for a caveman). In particular, it is very important to realize that papers are a specific thing: they look a certain way, they flow a certain way, they have a certain structure, language, and statistics that the other academics expect. It’s usually a painful exercise for me to look through some of my early PhD paper drafts because they are quite terrible. There is a lot to learn here.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Review papers.&lt;/strong&gt; If you’re trying to learn to write better papers it can feel like a sensible strategy to look at many good papers and try to distill patterns. This turns out to not be the best strategy; it’s analogous to only receiving positive examples for a binary classification problem. What you really want is to also have exposure to a large number of bad papers and one way to get this is by reviewing papers. Most good conferences have an acceptance rate of about 25% so most papers you’ll review are bad, which will allow you to build a powerful binary classifier. You’ll read through a bad paper and realize how unclear it is, or how it doesn’t define it’s variables, how vague and abstract its intro is, or how it dives in to the details too quickly, and you’ll learn to avoid the same pitfalls in your own papers. Another related valuable experience is to attend (or form) journal clubs - you’ll see experienced researchers critique papers and get an impression for how your own papers will be analyzed by others.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Get the gestalt right.&lt;/strong&gt; I remember being impressed with Fei-Fei (my adviser) once during a reviewing session. I had a stack of 4 papers I had reviewed over the last several hours and she picked them up, flipped through each one for 10 seconds, and said one of them was good and the other three bad. Indeed, I was accepting the one and rejecting the other three, but something that took me several hours took her seconds. Fei-Fei was relying on the &lt;em&gt;gestalt&lt;/em&gt; of the papers as a powerful heuristic. Your papers, as you become a more senior researcher take on a characteristic look. An introduction of ~1 page. A ~1 page related work section with a good density of citations - not too sparse but not too crowded. A well-designed pull figure (on page 1 or 2) and system figure (on page 3) that were not made in MS Paint. A technical section with some math symbols somewhere, results tables with lots of numbers and some of them bold, one additional cute analysis experiment, and the paper has exactly 8 pages (the page limit) and not a single line less. You’ll have to learn how to endow your papers with the same gestalt because many researchers rely on it as a cognitive shortcut when they judge your work.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Identify the core contribution&lt;/strong&gt;. Before you start writing anything it’s important to identify the single core contribution that your paper makes to the field. I would especially highlight the word &lt;em&gt;single&lt;/em&gt;. A paper is not a random collection of some experiments you ran that you report on. The paper sells a single thing that was not obvious or present before. You have to argue that the thing is important, that it hasn’t been done before, and then you support its merit experimentally in controlled experiments. The entire paper is organized around this core contribution with surgical precision. In particular it doesn’t have any additional fluff and it doesn’t try to pack anything else on a side. As a concrete example, I made a mistake in one of my earlier papers on &lt;a href="https://cs.stanford.edu/people/karpathy/deepvideo/deepvideo_cvpr2014.pdf"&gt;video classification&lt;/a&gt; where I tried to pack in two contributions: 1) a set of architectural layouts for video convnets and an unrelated 2) multi-resolution architecture which gave small improvements. I added it because I reasoned first that maybe someone could find it interesting and follow up on it later and second because I thought that contributions in a paper are additive: two contributions are better than one. Unfortunately, this is false and very wrong. The second contribution was minor/dubious and it diluted the paper, it was distracting, and no one cared. I’ve made a similar mistake again in my &lt;a href="https://cs.stanford.edu/people/karpathy/deepimagesent/"&gt;CVPR 2014 paper&lt;/a&gt; which presented two separate models: a ranking model and a generation model. Several good in-retrospect arguments could be made that I should have submitted two separate papers; the reason it was one is more historical than rational.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;The structure.&lt;/strong&gt; Once you’ve identified your core contribution there is a default recipe for writing a paper about it. The upper level structure is by default Intro, Related Work, Model, Experiments, Conclusions. When I write my intro I find that it helps to put down a coherent top-level narrative in latex comments and then fill in the text below. I like to organize each of my paragraphs around a single concrete point stated on the first sentence that is then supported in the rest of the paragraph. This structure makes it easy for a reader to skim the paper. A good flow of ideas is then along the lines of 1) X (+define X if not obvious) is an important problem 2) The core challenges are this and that. 2) Previous work on X has addressed these with Y, but the problems with this are Z. 3) In this work we do W (?). 4) This has the following appealing properties and our experiments show this and that. You can play with this structure a bit but these core points should be clearly made. Note again that the paper is surgically organized around your exact contribution. For example, when you list the challenges you want to list exactly the things that you address later; you don’t go meandering about unrelated things to what you have done (you can speculate a bit more later in conclusion). It is important to keep a sensible structure throughout your paper, not just in the intro. For example, when you explain the model each section should: 1) explain clearly what is being done in the section, 2) explain what the core challenges are 3) explain what a baseline approach is or what others have done before 4) motivate and explain what you do 5) describe it.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Break the structure.&lt;/strong&gt; You should also feel free (and you’re encouraged to!) play with these formulas to some extent and add some spice to your papers. For example, see this amusing paper from &lt;a href="https://arxiv.org/abs/1403.6382"&gt;Razavian et al. in 2014&lt;/a&gt; that structures the introduction as a dialog between a student and the professor. It’s clever and I like it. As another example, a lot of papers from &lt;a href="https://people.eecs.berkeley.edu/~efros/"&gt;Alyosha Efros&lt;/a&gt; have a playful tone and make great case studies in writing fun papers. As only one of many examples, see this paper he wrote with Antonio Torralba: &lt;a href="https://people.csail.mit.edu/torralba/publications/datasets_cvpr11.pdf"&gt;Unbiased look at dataset bias&lt;/a&gt;. Another possibility I’ve seen work well is to include an FAQ section, possibly in the appendix.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Common mistake: the laundry list.&lt;/strong&gt; One very common mistake to avoid is the “laundry list”, which looks as follows: “Here is the problem. Okay now to solve this problem first we do X, then we do Y, then we do Z, and now we do W, and here is what we get”. You should try very hard to avoid this structure. Each point should be justified, motivated, explained. Why do you do X or Y? What are the alternatives? What have others done? It’s okay to say things like this is common (add citation if possible). Your paper is not a report, an enumeration of what you’ve done, or some kind of a translation of your chronological notes and experiments into latex. It is a highly processed and very focused discussion of a problem, your approach and its context. It is supposed to teach your colleagues something and you have to justify your steps, not just describe what you did.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;The language.&lt;/strong&gt; Over time you’ll develop a vocabulary of good words and bad words to use when writing papers. Speaking about machine learning or computer vision papers specifically as concrete examples, in your papers you never “study” or “investigate” (there are boring, passive, bad words); instead you “develop” or even better you “propose”. And you don’t present a “system” or, &lt;em&gt;shudder&lt;/em&gt;, a “pipeline”; instead, you develop a “model”. You don’t learn “features”, you learn “representations”. And god forbid, you never “combine”, “modify” or “expand”. These are incremental, gross terms that will certainly get your paper rejected :).&lt;/p&gt; &lt;p&gt;&lt;strong&gt;An internal deadlines 2 weeks prior&lt;/strong&gt;. Not many labs do this, but luckily Fei-Fei is quite adamant about an internal deadline 2 weeks before the due date in which you must submit at least a 5-page draft with all the final experiments (even if not with final numbers) that goes through an internal review process identical to the external one (with the same review forms filled out, etc). I found this practice to be extremely useful because forcing yourself to lay out the full paper almost always reveals some number of critical experiments you must run for the paper to flow and for its argument flow to be coherent, consistent and convincing.&lt;/p&gt; &lt;p&gt;Another great resource on this topic is &lt;a href="https://cs.stanford.edu/people/widom/paper-writing.html"&gt;Tips for Writing Technical Papers&lt;/a&gt; from Jennifer Widom.&lt;/p&gt; &lt;h3 id="writing-code"&gt;Writing code&lt;/h3&gt; &lt;p&gt;&lt;img src="https://karpathy.github.io/assets/phd/code.jpg"&gt; &lt;/p&gt; &lt;p&gt;A lot of your time will of course be taken up with the &lt;em&gt;execution&lt;/em&gt; of your ideas, which likely involves a lot of coding. I won’t dwell on this too much because it’s not uniquely academic, but I would like to bring up a few points.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Release your code&lt;/strong&gt;. It’s a somewhat surprising fact but you can get away with publishing papers and not releasing your code. You will also feel a lot of incentive to not release your code: it can be a lot of work (research code can look like spaghetti since you iterate very quickly, you have to clean up a lot), it can be intimidating to think that others might judge you on your at most decent coding abilities, it is painful to maintain code and answer questions from other people about it (forever), and you might also be concerned that people could spot bugs that invalidate your results. However, it is precisely for some of these reasons that you should commit to releasing your code: it will force you to adopt better coding habits due to fear of public shaming (which will end up saving you time!), it will force you to learn better engineering practices, it will force you to be more thorough with your code (e.g. writing unit tests to make bugs much less likely), it will make others much more likely to follow up on your work (and hence lead to more citations of your papers) and of course it will be much more useful to everyone as a record of exactly what was done for posterity. When you do release your code I recommend taking advantage of &lt;a href="https://www.docker.com/"&gt;docker containers&lt;/a&gt;; this will reduce the amount of headaches people email you about when they can’t get all the dependencies (and their precise versions) installed.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Think of the future you&lt;/strong&gt;. Make sure to document all your code very well for yourself. I guarantee you that you will come back to your code base a few months later (e.g. to do a few more experiments for the camera ready version of the paper), and you will feel &lt;em&gt;completely&lt;/em&gt; lost in it. I got into the habit of creating very thorough readme.txt files in all my repos (for my personal use) as notes to future self on how the code works, how to run it, etc.&lt;/p&gt; &lt;h3 id="giving-talks"&gt;Giving talks&lt;/h3&gt; &lt;p&gt;&lt;img src="https://karpathy.github.io/assets/phd/talk.jpg"&gt; &lt;/p&gt; &lt;p&gt;So, you published a paper and it’s an oral! Now you get to give a few minute talk to a large audience of people - what should it look like?&lt;/p&gt; &lt;p&gt;&lt;strong&gt;The goal of a talk&lt;/strong&gt;. First, that there’s a common misconception that the goal of your talk is to tell your audience about what you did in your paper. This is incorrect, and should only be a second or third degree design criterion. The goal of your talk is to 1) get the audience really excited about the &lt;strong&gt;problem&lt;/strong&gt; you worked on (they must appreciate it or they will not care about your solution otherwise!) 2) teach the audience something (ideally while giving them a taste of your insight/solution; don’t be afraid to spend time on other’s related work), and 3) entertain (they will start checking their Facebook otherwise). Ideally, by the end of the talk the people in your audience are thinking some mixture of “wow, I’m working in the wrong area”, “I have to read this paper”, and “This person has an impressive understanding of the whole area”.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;A few do’s:&lt;/strong&gt; There are several properties that make talks better. For instance, Do: Lots of pictures. People Love pictures. Videos and animations should be used more sparingly because they distract. Do: make the talk actionable - talk about something someone can &lt;em&gt;do&lt;/em&gt; after your talk. Do: give a live demo if possible, it can make your talk more memorable. Do: develop a broader intellectual arch that your work is part of. Do: develop it into a story (people love stories). Do: cite, cite, cite - a lot! It takes very little slide space to pay credit to your colleagues. It pleases them and always reflects well on you because it shows that you’re humble about your own contribution, and aware that it builds on a lot of what has come before and what is happening in parallel. You can even cite related work published at the same conference and briefly advertise it. Do: practice the talk! First for yourself in isolation and later to your lab/friends. This almost always reveals very insightful flaws in your narrative and flow.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Don’t: texttexttext&lt;/strong&gt;. Don’t crowd your slides with text. There should be very few or no bullet points - speakers sometimes try to use these as a crutch to remind themselves what they should be talking about but the slides are not for you they are for the audience. These should be in your speaker notes. On the topic of crowding the slides, also avoid complex diagrams as much as you can - your audience has a fixed bit bandwidth and I guarantee that your own very familiar and “simple” diagram is not as simple or interpretable to someone seeing it for the first time.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Careful with: result tables:&lt;/strong&gt; Don’t include dense tables of results showing that your method works better. You got a paper, I’m sure your results were decent. I always find these parts boring and unnecessary unless the numbers show something interesting (other than your method works better), or of course unless there is a large gap that you’re very proud of. If you do include results or graphs build them up slowly with transitions, don’t post them all at once and spend 3 minutes on one slide.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Pitfall: the thin band between bored/confused&lt;/strong&gt;. It’s actually quite tricky to design talks where a good portion of your audience &lt;em&gt;learns&lt;/em&gt; something. A common failure case (as an audience member) is to see talks where I’m painfully bored during the first half and completely confused during the second half, learning nothing by the end. This can occur in talks that have a very general (too general) overview followed by a technical (too technical) second portion. Try to identify when your talk is in danger of having this property.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Pitfall: running out of time&lt;/strong&gt;. Many speakers spend too much time on the early intro parts (that can often be somewhat boring) and then frantically speed through all the last few slides that contain the most interesting results, analysis or demos. Don’t be that person.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Pitfall: formulaic talks&lt;/strong&gt;. I might be a special case but I’m always a fan of non-formulaic talks that challenge conventions. For instance, I &lt;em&gt;despise&lt;/em&gt; the outline slide. It makes the talk so boring, it’s like saying: “This movie is about a ring of power. In the first chapter we’ll see a hobbit come into possession of the ring. In the second we’ll see him travel to Mordor. In the third he’ll cast the ring into Mount Doom and destroy it. I will start with chapter 1” - Come on! I use outline slides for much longer talks to keep the audience anchored if they zone out (at 30min+ they inevitably will a few times), but it should be used sparingly.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Observe and learn&lt;/strong&gt;. Ultimately, the best way to become better at giving talks (as it is with writing papers too) is to make conscious effort to pay attention to what great (and not so great) speakers do and build a binary classifier in your mind. Don’t just enjoy talks; analyze them, break them down, learn from them. Additionally, pay close attention to the audience and their reactions. Sometimes a speaker will put up a complex table with many numbers and you will notice half of the audience immediately look down on their phone and open Facebook. Build an internal classifier of the events that cause this to happen and avoid them in your talks.&lt;/p&gt; &lt;h3 id="attending-conferences"&gt;Attending conferences&lt;/h3&gt; &lt;p&gt;&lt;img src="https://karpathy.github.io/assets/phd/posters.jpg"&gt; &lt;/p&gt; &lt;p&gt;On the subject of conferences:&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Go.&lt;/strong&gt; It’s very important that you go to conferences, especially the 1-2 top conferences in your area. If your adviser lacks funds and does not want to pay for your travel expenses (e.g. if you don’t have a paper) then you should be willing to pay for yourself (usually about $2000 for travel, accommodation, registration and food). This is important because you want to become part of the academic community and get a chance to meet more people in the area and gossip about research topics. Science might have this image of a few brilliant lone wolfs working in isolation, but the truth is that research is predominantly a highly social endeavor - you stand on the shoulders of many people, you’re working on problems in parallel with other people, and it is these people that you’re also writing papers to. Additionally, it’s unfortunate but each field has knowledge that doesn’t get serialized into papers but is instead spread across a shared understanding of the community; things such as what are the next important topics to work on, what papers are most interesting, what is the inside scoop on papers, how they developed historically, what methods work (not just on paper, in reality), etcetc. It is very valuable (and fun!) to become part of the community and get direct access to the hivemind - to learn from it first, and to hopefully influence it later.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Talks: choose by speaker&lt;/strong&gt;. One conference trick I’ve developed is that if you’re choosing which talks to attend it can be better to look at the speakers instead of the topics. Some people give better talks than others (it’s a skill, and you’ll discover these people in time) and in my experience I find that it often pays off to see them speak even if it is on a topic that isn’t exactly connected to your area of research.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;The real action is in the hallways&lt;/strong&gt;. The speed of innovation (especially in Machine Learning) now works at timescales much faster than conferences so most of the relevant papers you’ll see at the conference are in fact old news. Therefore, conferences are primarily a social event. Instead of attending a talk I encourage you to view the hallway as one of the main events that doesn’t appear on the schedule. It can also be valuable to stroll the poster session and discover some interesting papers and ideas that you may have missed.&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;It is said that there are three stages to a PhD. In the first stage you look at a related paper’s reference section and you haven’t read most of the papers. In the second stage you recognize all the papers. In the third stage you’ve shared a beer with all the first authors of all the papers.&lt;/p&gt; &lt;/blockquote&gt; &lt;h3 id="closing-thoughts"&gt;Closing thoughts&lt;/h3&gt; &lt;p&gt;I can’t find the quote anymore but I heard Sam Altman of YC say that there are no shortcuts or cheats when it comes to building a startup. You can’t expect to win in the long run by somehow gaming the system or putting up false appearances. I think that the same applies in academia. Ultimately you’re trying to do good research and push the field forward and if you try to game any of the proxy metrics you won’t be successful in the long run. This is especially so because academia is in fact surprisingly small and highly interconnected, so anything shady you try to do to pad your academic resume (e.g. self-citing a lot, publishing the same idea multiple times with small remixes, resubmitting the same rejected paper over and over again with no changes, conveniently trying to leave out some baselines etc.) will eventually catch up with you and you will not be successful.&lt;/p&gt; &lt;p&gt;So at the end of the day it’s quite simple. Do good work, communicate it properly, people will notice and good things will happen. Have a fun ride!&lt;/p&gt; &lt;/article&gt;&lt;/div&gt;&lt;a href="https://karpathy.github.io/2016/09/07/phd/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Fri, 12 Jun 2020 12:17:21 UT
      </pubDate>
      <guid>
        https://karpathy.github.io/2016/09/07/phd/
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://www.cs.cmu.edu/~harchol/gradschooltalk.pdf
      </link>
      <description>
        &lt;a href="https://www.cs.cmu.edu/~harchol/gradschooltalk.pdf"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Fri, 12 Jun 2020 12:17:22 UT
      </pubDate>
      <guid>
        https://www.cs.cmu.edu/~harchol/gradschooltalk.pdf
      </guid>
    </item>
    <item>
      <title>
        Richard Socher - Home Page
      </title>
      <link>
        https://www.socher.org/index.php/Main/HomePage
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt; &lt;h3&gt; Research&lt;/h3&gt; &lt;h4&gt; 2020&lt;/h4&gt;&lt;p&gt;ProGen: Language Modeling for Protein Generation, Ali Madani, Bryan McCann, Nikhil Naik, Nitish Shirish Keskar, Namrata Anand, Raphael R Eguchi, Possu Huang and Richard Socher.&lt;br&gt;[ &lt;a rel="nofollow" href="https://www.biorxiv.org/content/10.1101/2020.03.07.982272v2"&gt;bioRxiv link&lt;/a&gt;, &lt;a rel="nofollow" href="https://blog.einstein.ai/progen/"&gt;blog&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;The AI Economist: Improving Equality and Productivity with AI-Driven Tax Policies, Stephan Zheng, Alexander Trott, Sunil Srinivasa, Nikhil Naik, Melvin Gruesbeck, David C. Parkes, Richard Socher.&lt;br&gt;[ &lt;a rel="nofollow" href="https://arxiv.org/abs/2004.13332"&gt;arxiv link&lt;/a&gt;, &lt;a rel="nofollow" href="https://blog.einstein.ai/the-ai-economist/"&gt;blog&lt;/a&gt;, &lt;a rel="nofollow" href="https://www.youtube.com/watch?v=4iQUcGyQhdA"&gt;short video&lt;/a&gt;, &lt;a rel="nofollow" href="https://salesforce.com/company/news-press/stories/2020/4/salesforce-ai-economist/"&gt;Q&amp;amp;A&lt;/a&gt;, Press: &lt;a rel="nofollow" href="https://venturebeat.com/2020/04/29/salesforces-ai-economist-taps-reinforcement-learning-to-generate-optimal-tax-policies/"&gt;VentureBeat&lt;/a&gt;, &lt;a rel="nofollow" href="https://techcrunch.com/2020/04/29/salesforce-researchers-are-working-on-an-ai-economist-for-more-equitable-tax-policy/"&gt;TechCrunch&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;Deep Learning-enabled Breast Cancer Hormonal Receptor Status Determination from Base-level H&amp;amp;E Stains, Nikhil Naik, Ali Madani, Andre Esteva, Nitish Keskar, Michael Press, Dan Ruderman, David Agus, Richard Socher &lt;br&gt;(&lt;strong&gt;Nature Communications 2020&lt;/strong&gt;) [ &lt;a rel="nofollow" href="https://www.nature.com/articles/s41467-020-19334-3"&gt;paper&lt;/a&gt;, &lt;a rel="nofollow" href="https://blog.einstein.ai/receptornet/"&gt;blog&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;Dye-sensitized solar cells under ambient light powering machine learning: towards autonomous smart sensors for the internet of things, Hannes Michaels, Michael Rinderle, Richard Freitag, Lacopo Benesperi, Tomas Edvinsson, Richard Socher, Alessio Gagliardib and Marina Freitag&lt;br&gt;Issue11, (&lt;strong&gt;Chemical Science 2020&lt;/strong&gt;). [ &lt;a rel="nofollow" href="https://pubs.rsc.org/en/content/articlelanding/2020/sc/c9sc06145b#!divAbstract"&gt;paper link&lt;/a&gt; ] &lt;/p&gt; &lt;h4&gt; 2019&lt;/h4&gt;&lt;p&gt;CTRL: A Conditional Transformer Language Model for Controllable Generation, Nitish Shirish Keskar, Bryan McCann, Lav R. Varshney, Caiming Xiong, Richard Socher.&lt;br&gt;[ &lt;a rel="nofollow" href="https://arxiv.org/abs/1909.05858"&gt;arxiv link&lt;/a&gt;, &lt;a rel="nofollow" href="https://github.com/salesforce/ctrl"&gt;code (pre-trained and fine-tuning)&lt;/a&gt;, &lt;a rel="nofollow" href="https://blog.einstein.ai/introducing-a-conditional-transformer-language-model-for-controllable-generation/"&gt;blog&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;Genie: a generator of natural language semantic parsers for virtual assistant commands, Giovanni Campagna, Silei Xu, Mehrad Moradshahi, Richard Socher, Monica S. Lam&lt;br&gt;PLDI 2019 [ &lt;a rel="nofollow" href="https://almond-static.stanford.edu/papers/genie-pldi19.pdf"&gt;pdf link&lt;/a&gt;, &lt;a rel="nofollow" href="https://almond.stanford.edu/"&gt;https://almond.stanford.edu/&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;Keeping Your Distance: Solving Sparse Reward Tasks Using Self-Balancing Shaped Rewards, Alex Trott, Stephan Zheng, Caiming Xiong, Richard Socher.&lt;br&gt;Thirty-third Conference on Neural Information Processing Systems (&lt;strong&gt;NeurIPS 2019&lt;/strong&gt;). &lt;/p&gt; &lt;p&gt;The State of Text Summarization: A Critical Evaluation, Wojciech Kryściński, Nitish Shirish Keskar, Bryan McCann, Caiming Xiong, Richard Socher.&lt;br&gt;2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing (&lt;strong&gt;EMNLP-IJCNLP 2019&lt;/strong&gt;). [ &lt;a rel="nofollow" href="https://arxiv.org/abs/1908.08960"&gt;arxiv link&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;WSLLN: Weakly Supervised Natural Language Localization Networks, Mingfei Gao, Larry Davis, Richard Socher, Caiming Xiong.&lt;br&gt;2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing (&lt;strong&gt;EMNLP-IJCNLP 2019&lt;/strong&gt;). [ &lt;a rel="nofollow" href="https://arxiv.org/abs/1909.00239"&gt;arxiv link&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;Editing-based SQL Query Generation for Cross-Domain Context-Dependent Questions, Rui Zhang, Tao Yu, Heyang Er, Sungrok Shim, Eric Xue, Xi Victoria Lin, Tianze Shi, Caiming Xiong, Richard Socher and Dragomir Radev&lt;br&gt;2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing (&lt;strong&gt;EMNLP-IJCNLP 2019&lt;/strong&gt;). [ &lt;a rel="nofollow" href="https://arxiv.org/abs/1909.00786"&gt;arxiv link&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;CoSQL: A Conversational Text-to-SQL Challenge Towards Cross-Domain Natural Language Interfaces to Databases, Tao Yu, Rui Zhang, Heyang Er, Suyi Li, Eric Xue, Bo Pang, Xi Victoria Lin, Yi Chern Tan, Tianze Shi, Zihan Li, Youxuan Jiang, Michihiro Yasunaga, Sungrok Shim, Tao Chen, Alexander Fabbri, Zifan Li, Luyao Chen, Yuwen Zhang, Shreya Dixit, Vincent Zhang, Caiming Xiong, Richard Socher, Walter Lasecki, Dragomir Radev.&lt;br&gt;2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing (&lt;strong&gt;EMNLP-IJCNLP 2019&lt;/strong&gt;). [ &lt;a rel="nofollow" href="https://arxiv.org/abs/1909.05378"&gt;arxiv link&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;Transferable Multi-Domain State Generator for Task-Oriented Dialogue Systems, Chien-Sheng Wu, Andrea Madotto, Ehsan Hosseini-Asl, Caiming Xiong, Richard Socher, Pascale Fung&lt;br&gt;The 57th Annual Meeting of the Association for Computational Linguistics (&lt;strong&gt;ACL 2019&lt;/strong&gt;). &lt;strong&gt;&lt;span&gt;Outstanding Paper Award&lt;/span&gt;&lt;/strong&gt;. [ &lt;a rel="nofollow" href="https://arxiv.org/abs/1905.08743"&gt;arxiv pdf&lt;/a&gt;, &lt;a rel="nofollow" href="https://github.com/jasonwu0731/trade-dst"&gt;code&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;Explain Yourself! Leveraging Language Models for Commonsense Reasoning, Nazneen Fatema Rajani, Bryan McCann, Caiming Xiong and Richard Socher&lt;br&gt;The 57th Annual Meeting of the Association for Computational Linguistics (&lt;strong&gt;ACL 2019&lt;/strong&gt;). [ &lt;a rel="nofollow" href="https://arxiv.org/abs/1906.02361"&gt;arxiv pdf&lt;/a&gt;, &lt;a rel="nofollow" href="https://blog.einstein.ai/leveraging-language-models-for-commonsense/"&gt;Blog Post&lt;/a&gt;, &lt;a rel="nofollow" href="https://github.com/salesforce/cos-e"&gt;Github&lt;/a&gt;, Press: &lt;a rel="nofollow" href="https://venturebeat.com/2019/06/27/salesforces-ai-grasps-commonsense-reasoning/"&gt;VentureBeat&lt;/a&gt;, &lt;a rel="nofollow" href="https://siliconangle.com/2019/06/27/salesforce-aims-bring-common-sense-ai/"&gt;Silicon Angle&lt;/a&gt;, &lt;a rel="nofollow" href="https://www.zdnet.com/article/salesforce-open-sources-research-to-advance-state-of-the-art-in-ai-for-common-sense-reasoning/"&gt;ZDNet&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;SParC: Cross-Domain Semantic Parsing in Context, Tao Yu, Rui Zhang, Michihiro Yasunaga, Yi Chern Tan, Xi Victoria Lin, Suyi Li, Heyang Er, Irene Li, Bo Pang, Tao Chen, Emily Ji, Shreya Dixit, David Proctor, Sungrok Shim, Jonathan Kraft, Vincent Zhang, Caiming Xiong, Richard Socher and Dragomir Radev&lt;br&gt;The 57th Annual Meeting of the Association for Computational Linguistics (&lt;strong&gt;ACL 2019&lt;/strong&gt;). [ &lt;a rel="nofollow" href="https://arxiv.org/pdf/1901.04713.pdf"&gt;arxiv pdf&lt;/a&gt;, &lt;a rel="nofollow" href="https://yale-lily.github.io/sparc"&gt;Challenge and Leaderboard&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;Global-to-local Memory Pointer Networks for Task-Oriented Dialogue, Chien-Sheng Wu, Richard Socher, Caiming Xiong&lt;br&gt;International Conference on Learning Representations (&lt;strong&gt;ICLR 2019&lt;/strong&gt;). [ &lt;a rel="nofollow" href="https://arxiv.org/pdf/1901.04713.pdf"&gt;arxiv pdf&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;Self-Monitoring Navigation Agent via Auxiliary Progress Estimation, Chih-Yao Ma, Jiasen Lu, Zuxuan Wu, Ghassan AlRegib, Zsolt Kira, Richard Socher, Caiming Xiong&lt;br&gt;International Conference on Learning Representations (&lt;strong&gt;ICLR 2019&lt;/strong&gt;). [ &lt;a rel="nofollow" href="https://arxiv.org/pdf/1901.03035.pdf"&gt;arxiv pdf&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;Coarse-grain Fine-grain Coattention Network for Multi-evidence Question Answering, Victor Zhong, Caiming Xiong, Nitish Shirish Keskar, Richard Socher. &lt;br&gt;International Conference on Learning Representations (&lt;strong&gt;ICLR 2019&lt;/strong&gt;). [ &lt;a rel="nofollow" href="https://arxiv.org/pdf/1901.00603.pdf"&gt;arxiv pdf&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;Competitive experience replay, Hao Liu, Alexander Trott, Richard Socher, Caiming Xiong.&lt;br&gt;International Conference on Learning Representations (&lt;strong&gt;ICLR 2019&lt;/strong&gt;). [ &lt;a rel="nofollow" href="https://arxiv.org/pdf/1902.00528.pdf"&gt;arxiv pdf&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;Augmented Cyclic Adversarial Learning for Low Resource Domain Adaptation, Ehsan Hosseini-Asl, Yingbo Zhou, Caiming Xiong, Richard Socher. &lt;br&gt;International Conference on Learning Representations (&lt;strong&gt;ICLR 2019&lt;/strong&gt;). [ &lt;a rel="nofollow" href="https://arxiv.org/abs/1807.00374"&gt;arxiv pdf&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;A Closer Look at Deep Learning Heuristics: Learning rate restarts, Warmup and Distillation, Akhilesh Gotmare, Nitish Shirish Keskar, Caiming Xiong, Richard Socher. &lt;br&gt;International Conference on Learning Representations (&lt;strong&gt;ICLR 2019&lt;/strong&gt;). [ &lt;a rel="nofollow" href="https://arxiv.org/pdf/1810.13243.pdf"&gt;arxiv pdf&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;AdaFrame: Adaptive Frame Selection for Fast Video Recognition, Zuxuan Wu, Caiming Xiong, Chih-Yao Ma, Richard Socher, Larry S Davis.&lt;br&gt;Conference on Computer Vision and Pattern Recognition (&lt;strong&gt;CVPR 2019&lt;/strong&gt;). [ &lt;a rel="nofollow" href="https://arxiv.org/pdf/1811.12432.pdf"&gt;arxiv pdf&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;Unifying Question Answering and Text Classification via Span Extraction, Nitish Shirish Keskar, Bryan McCann, Caiming Xiong, Richard Socher&lt;br&gt;[ &lt;a rel="nofollow" href="https://arxiv.org/abs/1904.09286"&gt;arxiv pdf&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;Learn to Grow: A Continual Structure Learning Framework for Catastrophic Forgetting, Xilai, Yingbo Zhou, Caiming Xiong, Richard Socher&lt;br&gt;The 36th International Conference on Machine Learning (&lt;strong&gt;ICML 2019&lt;/strong&gt;). [ &lt;a rel="nofollow" href="https://arxiv.org/abs/TODO"&gt;arxiv pdf&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;Taming MAML: Control variates for unbiased meta-reinforcement learning gradient estimation, Hao Liu, Caiming Xiong, Richard Socher&lt;br&gt;The 36th International Conference on Machine Learning (&lt;strong&gt;ICML 2019&lt;/strong&gt;). [ &lt;a rel="nofollow" href="https://arxiv.org/abs/TODO"&gt;arxiv pdf&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;On the Generalization Gap in Reparameterizable Reinforcement Learning (Huan Wang, Stephan Zheng, Caiming Xiong, Richard Socher&lt;br&gt;The 36th International Conference on Machine Learning (&lt;strong&gt;ICML 2019&lt;/strong&gt;). [ &lt;a rel="nofollow" href="https://arxiv.org/abs/TODO"&gt;arxiv pdf&lt;/a&gt; ] &lt;/p&gt; &lt;h4&gt; 2018 &lt;/h4&gt;&lt;div&gt; &lt;p&gt;The Natural Language Decathlon: Multitask Learning as Question Answering, Bryan McCann, Nitish Shirish Keskar, Caiming Xiong, Richard Socher&lt;br&gt;[ &lt;a rel="nofollow" href="https://arxiv.org/abs/1806.08730"&gt;arxiv pdf&lt;/a&gt;, &lt;a rel="nofollow" href="https://github.com/salesforce/decaNLP"&gt;code and leaderboard&lt;/a&gt;, &lt;a rel="nofollow" href="https://einstein.ai/research/the-natural-language-decathlon"&gt;blog post&lt;/a&gt;, &lt;a rel="nofollow" href="https://www.salesforce.com/company/news-press/stories/2018/6/062018-a/"&gt;Q&amp;amp;A&lt;/a&gt;, Press: &lt;a rel="nofollow" href="https://venturebeat.com/2018/06/20/salesforce-develops-natural-language-processing-model-that-performs-10-tasks-at-once/"&gt;VentureBeat&lt;/a&gt;, &lt;a rel="nofollow" href="https://www.zdnet.com/article/salesforce-research-creates-swiss-army-knife-for-natural-language-processing/"&gt;zdnet&lt;/a&gt;, &lt;a rel="nofollow" href="http://www.faz.net/aktuell/wirtschaft/kuenstliche-intelligenz/richard-socher-wenn-der-computer-multitasking-kann-15650122.html"&gt;FAZ (German)&lt;/a&gt;, &lt;a rel="nofollow" href="https://siliconangle.com/blog/2018/06/20/salesforce-claims-big-advance-natural-language-processing/"&gt;SiliconAngle&lt;/a&gt; ] &lt;/p&gt;&lt;/div&gt; &lt;p&gt;Multi-Hop Knowledge Graph Reasoning with Reward Shaping, Xi Victoria Lin, Richard Socher, Caiming Xiong&lt;br&gt;Conference on Empirical Methods in Natural Language Processing (&lt;strong&gt;EMNLP 2018&lt;/strong&gt;). [ &lt;a rel="nofollow" href="https://arxiv.org/abs/1808.10568"&gt;arxiv pdf&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;Improving Abstraction in Text Summarization, Wojciech Kryściński, Romain Paulus, Caiming Xiong, Richard Socher&lt;br&gt;Conference on Empirical Methods in Natural Language Processing (&lt;strong&gt;EMNLP 2018&lt;/strong&gt;). [ &lt;a rel="nofollow" href="https://arxiv.org/pdf/1808.07913.pdf"&gt;arxiv pdf&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;A Multi-Discriminator CycleGAN for Unsupervised Non-Parallel Speech Domain Adaptation, Ehsan Hosseini-Asl, Yingbo Zhou, Caiming Xiong, Richard Socher&lt;br&gt;&lt;strong&gt;Interspeech 2018&lt;/strong&gt;. [ &lt;a rel="nofollow" href="https://arxiv.org/abs/1804.00522"&gt;arxiv pdf&lt;/a&gt;, &lt;a rel="nofollow" href="https://einstein.ai/research/a-multi-discriminator-cyclegan-for-unsupervised-non-parallel-speech-domain-adaptation"&gt;blog&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;Global-Locally Self-Attentive Encoder for Dialogue State Tracking, Victor Zhong, Caiming Xiong, Richard Socher. &lt;br&gt;Association for Computational Linguistics 2018 Conference (&lt;strong&gt;ACL 2018&lt;/strong&gt;). [ &lt;a rel="nofollow" href="https://arxiv.org/abs/1805.09655"&gt;arxiv pdf&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;Efficient and Robust Question Answering from Minimal Context over Documents, Sewon Min, Victor Zhong, Richard Socher, Caiming Xiong. &lt;br&gt;Association for Computational Linguistics 2018 Conference (&lt;strong&gt;ACL 2018&lt;/strong&gt;). [ &lt;a rel="nofollow" href="https://arxiv.org/abs/1805.08092"&gt;arxiv pdf&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;End-to-End Dense Video Captioning with Masked Transformer, Luowei Zhou, Yingbo Zhou, Jason J. Corso, Richard Socher, Caiming Xiong&lt;br&gt;IEEE Conference on Computer Vision and Pattern Recognition (&lt;strong&gt;CVPR 2018&lt;/strong&gt;). &lt;span&gt; (Spotlight)&lt;/span&gt; [ &lt;a rel="nofollow" href="https://arxiv.org/abs/1804.00819"&gt;arxiv pdf&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;An Analysis of Neural Language Modeling at Multiple Scales, Stephen Merity, Nitish Shirish Keskar, Richard Socher&lt;br&gt;[ &lt;a rel="nofollow" href="https://arxiv.org/abs/1803.08240"&gt;arxiv pdf&lt;/a&gt;, &lt;a rel="nofollow" href="https://github.com/salesforce/awd-lstm-lm"&gt;github code&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;Interpretable Counting for Visual Question Answering, Alexander Trott, Caiming Xiong, Richard Socher&lt;br&gt;International Conference on Learning Representations (&lt;strong&gt;ICLR 2018&lt;/strong&gt;). [ &lt;a rel="nofollow" href="https://arxiv.org/abs/1712.08697"&gt;arxiv pdf&lt;/a&gt;, &lt;a rel="nofollow" href="https://einstein.ai/research/interpretable-counting-for-visual-question-answering"&gt;blog post&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;Hierarchical and Interpretable Skill Acquisition in Multi-task Reinforcement Learning, Tianmin Shu, Caiming Xiong, and Richard Socher&lt;br&gt;International Conference on Learning Representations (&lt;strong&gt;ICLR 2018&lt;/strong&gt;). [ &lt;a rel="nofollow" href="https://arxiv.org/abs/1712.07294"&gt;arxiv pdf&lt;/a&gt;, &lt;a rel="nofollow" href="https://einstein.ai/research/hierarchical-reinforcement-learning"&gt;blog post&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;A Deep Reinforced Model for Abstractive Summarization, Romain Paulus, Caiming Xiong, Richard Socher&lt;br&gt;International Conference on Learning Representations (&lt;strong&gt;ICLR 2018&lt;/strong&gt;). [ &lt;a rel="nofollow" href="https://arxiv.org/abs/1705.04304"&gt;pdf&lt;/a&gt;, &lt;a rel="nofollow" href="https://blog.einstein.ai/your-tldr-by-an-ai-a-deep-reinforced-model-for-abstractive-summarization/"&gt;blog post&lt;/a&gt;, Press: &lt;a rel="nofollow" href="https://www.forbes.com/sites/gilpress/2017/05/11/salesforce-announces-ai-breakthrough-reducing-information-overload"&gt;Forbes&lt;/a&gt;, &lt;a rel="nofollow" href="https://www.technologyreview.com/s/607828/an-algorithm-summarizes-lengthy-text-surprisingly-well/"&gt;MIT Tech Review&lt;/a&gt;, &lt;a rel="nofollow" href="https://techcrunch.com/2017/05/11/salesforce-aims-to-save-you-time-by-summarizing-emails-and-docs-with-machine-intelligence/"&gt;TechCrunch&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;Non-Autoregressive Neural Machine Translation, Jiatao Gu, James Bradbury, Caiming Xiong, Victor O.K. Li, Richard Socher&lt;br&gt;International Conference on Learning Representations (&lt;strong&gt;ICLR 2018&lt;/strong&gt;). [ &lt;a rel="nofollow" href="https://arxiv.org/abs/1711.02281"&gt;arxiv pdf&lt;/a&gt;, &lt;a rel="nofollow" href="https://einstein.ai/research/non-autoregressive-neural-machine-translation"&gt;blog post&lt;/a&gt;, Press: &lt;a rel="nofollow" href="https://www.cnbc.com/2017/11/06/salesforce-a-i-researchers-develop-faster-machine-translation-model.html"&gt;CNBC&lt;/a&gt;, &lt;a rel="nofollow" href="https://venturebeat.com/2017/11/07/salesforce-shows-how-to-bypass-a-key-bottleneck-in-ai-translation/"&gt;Venturebeat&lt;/a&gt;, &lt;a rel="nofollow" href="https://slator.com/technology/salesforce-joins-neural-machine-translation-race/"&gt;Slator&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;DCN+: Mixed Objective and Deep Residual Coattention for Question Answering, Caiming Xiong, Victor Zhong and Richard Socher&lt;br&gt;International Conference on Learning Representations (&lt;strong&gt;ICLR 2018&lt;/strong&gt;). [ &lt;a rel="nofollow" href="https://arxiv.org/abs/1711.00106"&gt;arxiv pdf&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;Regularizing and Optimizing LSTM Language Models, Stephen Merity, Nitish Shirish Keskar, Richard Socher&lt;br&gt;International Conference on Learning Representations (&lt;strong&gt;ICLR 2018&lt;/strong&gt;). [ &lt;a rel="nofollow" href="https://arxiv.org/abs/1708.02182"&gt;pdf&lt;/a&gt;, &lt;a rel="nofollow" href="https://github.com/salesforce/awd-lstm-lm"&gt;code&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;A Flexible Approach to Automated RNN Architecture Generation, Stephen Merity, Martin Schrimpf, James Bradbury, Richard Socher&lt;br&gt;International Conference on Learning Representations (ICLR 2018 Workshop Track). [ arxiv pdf, &lt;a rel="nofollow" href="https://einstein.ai/research/domain-specific-language-for-automated-rnn-architecture-search"&gt;blog post&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;Improving End-to-End Speech Recognition with Policy Learning, Yingbo Zhou, Caiming Xiong, Richard Socher&lt;br&gt;IEEE International Conference on Acoustics, Speech and Signal Processing (&lt;strong&gt;ICASSP 2018&lt;/strong&gt;). [ &lt;a rel="nofollow" href="https://einstein.ai/static/images/pages/research/improving-end-to-end-speech-models/policy-learning.pdf"&gt;pdf&lt;/a&gt;, &lt;a rel="nofollow" href="https://einstein.ai/research/improving-end-to-end-speech-models"&gt;blog post&lt;/a&gt; ] &lt;/p&gt; &lt;h4&gt; 2017 &lt;/h4&gt;&lt;p&gt;Improving Generalization Performance by Switching from Adam to SGD, Nitish Shirish Keskar, Richard Socher&lt;br&gt;[ &lt;a rel="nofollow" href="https://arxiv.org/abs/1712.07628"&gt;arxiv pdf&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;Improved Regularization Techniques for End-to-End Speech Recognition, Yingbo Zhou, Caiming Xiong, Richard Socher&lt;br&gt;[ &lt;a rel="nofollow" href="https://einstein.ai/static/images/pages/research/improving-end-to-end-speech-models/improved-regularization-techniques.pdf"&gt;pdf&lt;/a&gt;, &lt;a rel="nofollow" href="https://einstein.ai/research/improving-end-to-end-speech-models"&gt;blog post&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;Weighted Transformer Network for Machine Translation, Karim Ahmed, Nitish Shirish Keskar, Richard Socher&lt;br&gt;[ &lt;a rel="nofollow" href="https://arxiv.org/pdf/1711.02132"&gt;arxiv pdf&lt;/a&gt;, &lt;a rel="nofollow" href="https://einstein.ai/research/weighted-transformer"&gt;blog post&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;Seq2SQL: Generating Structured Queries from Natural Language using Reinforcement Learning, Victor Zhong, Caiming Xiong, Richard Socher&lt;br&gt;[ &lt;a rel="nofollow" href="https://arxiv.org/abs/1709.00103"&gt;arxiv pdf&lt;/a&gt;, &lt;a rel="nofollow" href="https://einstein.ai/research/how-to-talk-to-your-database"&gt;blog post&lt;/a&gt;, &lt;a rel="nofollow" href="https://github.com/salesforce/WikiSQL"&gt;dataset&lt;/a&gt;, Press: &lt;a rel="nofollow" href="https://techcrunch.com/2017/08/29/salesforce-is-using-ai-to-democratize-sql-so-anyone-can-query-databases-in-natural-language/"&gt;TechCrunch&lt;/a&gt;, &lt;a rel="nofollow" href="https://venturebeat.com/2017/08/29/salesforce-creates-ai-tool-for-talking-to-databases/"&gt;Venturebeat&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;Learned in Translation: Contextualized Word Vectors, Bryan McCann, James Bradbury, Caiming Xiong, Richard Socher&lt;br&gt;Advances in Neural Information Processing Systems (&lt;strong&gt;NIPS 2017&lt;/strong&gt;). [ &lt;a rel="nofollow" href="https://einstein.ai/static/images/layouts/research/cove/McCann2017LearnedIT.pdf"&gt;pdf&lt;/a&gt;, &lt;a rel="nofollow" href="https://einstein.ai/research/learned-in-translation-contextualized-word-vectors"&gt;blog post&lt;/a&gt;, &lt;a rel="nofollow" href="https://github.com/salesforce/cove"&gt;code&lt;/a&gt;, Press: &lt;a rel="nofollow" href="https://www.technologyreview.com/s/608382/to-build-a-smarter-chatbot-first-teach-it-a-second-language/"&gt;MIT Tech Review&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;Revisiting Activation Regularization for Language RNNs, Stephen Merity, Bryan McCann, Richard Socher&lt;br&gt;1st Workshop on Learning to Generate Natural Language at ICML 2017. [ &lt;a rel="nofollow" href="https://arxiv.org/abs/1708.01009"&gt;pdf&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;A Joint Many-Task Model: Growing a Neural Network for Multiple NLP Tasks, Kazuma Hashimoto,&amp;nbsp;Caiming Xiong,&amp;nbsp;Yoshimasa Tsuruoka,&amp;nbsp;Richard Socher&lt;br&gt;Conference on Empirical Methods in Natural Language Processing (&lt;strong&gt;EMNLP 2017&lt;/strong&gt;). Also appeared in NIPS 2016 Continual Learning and Deep Networks Workshop. [ &lt;a rel="nofollow" href="https://arxiv.org/abs/1611.01587"&gt;pdf&lt;/a&gt;, &lt;a rel="nofollow" href="http://metamind.io/research/multiple-different-natural-language-processing-tasks-in-a-single-deep-model"&gt;blog post&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;Knowing When to Look: Adaptive Attention via A Visual Sentinel for Image Captioning, Jiasen Lu, Caiming Xiong, Devi Parikh, Richard Socher&lt;br&gt;IEEE Computer Vision and Pattern Recognition (&lt;strong&gt;CVPR 2017&lt;/strong&gt;). [ &lt;a rel="nofollow" href="https://arxiv.org/abs/1612.01887"&gt;pdf&lt;/a&gt;, ] &lt;/p&gt; &lt;p&gt;Quasi-Recurrent Neural Networks, James Bradbury,&amp;nbsp;Stephen Merity,&amp;nbsp;Caiming Xiong,&amp;nbsp;Richard Socher&lt;br&gt;International Conference on Learning Representations (&lt;strong&gt;ICLR 2017&lt;/strong&gt;). [ &lt;a rel="nofollow" href="https://arxiv.org/abs/1611.01576"&gt;pdf&lt;/a&gt;, &lt;a rel="nofollow" href="http://metamind.io/research/new-neural-network-building-block-allows-faster-and-more-accurate-text-understanding/"&gt;blog post&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling, Hakan Inan,&amp;nbsp;Khashayar Khosravi,&amp;nbsp;Richard Socher&lt;br&gt;International Conference on Learning Representations (&lt;strong&gt;ICLR 2017&lt;/strong&gt;). [ &lt;a rel="nofollow" href="https://arxiv.org/abs/1611.01462"&gt;pdf&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;Pointer Sentinel Mixture Models, Stephen Merity, Caiming Xiong, James Bradbury, Richard Socher&lt;br&gt;International Conference on Learning Representations (&lt;strong&gt;ICLR 2017&lt;/strong&gt;) and NIPS 2016 Workshop on Multi-class and Multi-label Learning in Extremely Large Label Spaces. [ &lt;a rel="nofollow" href="http://arxiv.org/abs/1609.07843"&gt;pdf&lt;/a&gt;, &lt;a rel="nofollow" href="http://metamind.io/research/the-wikitext-long-term-dependency-language-modeling-dataset/"&gt;new dataset&lt;/a&gt; ] &lt;/p&gt; &lt;h4&gt; 2016&lt;/h4&gt;&lt;p&gt;A Way out of the Odyssey: Analyzing and Combining Recent Insights for LSTMs, Shayne Longpre, Sabeek Pradhan, Caiming Xiong, Richard Socher&lt;br&gt;[ &lt;a rel="nofollow" href="https://arxiv.org/abs/1611.05104"&gt;pdf&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;MetaMind Neural Machine Translation System for WMT 2016, James Bradbury, Richard Socher&lt;br&gt;Proceedings of the First Conference on Machine Translation. Association for Computational Linguistics.&lt;br&gt;[ &lt;a rel="nofollow" href="https://aclweb.org/anthology/W/W16/W16-2308.pdf"&gt;pdf&lt;/a&gt;, &lt;a rel="nofollow" href="http://matrix.statmt.org/matrix/systems_list/1840"&gt;2nd Place in the competition&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;Dynamic Memory Networks for Visual and Textual Question Answering, Caiming Xiong, Stephen Merity, Richard Socher&lt;br&gt;The 33rd International Conference on Machine Learning (&lt;strong&gt;ICML 2016&lt;/strong&gt;). [ &lt;a rel="nofollow" href="http://arxiv.org/abs/1603.01417"&gt;pdf&lt;/a&gt; , &lt;a rel="nofollow" href="http://www.nytimes.com/2016/03/07/technology/taking-baby-steps-toward-software-that-reasons-like-humans.html"&gt;New York Times&lt;/a&gt;, &lt;a rel="nofollow" href="https://www.technologyreview.com/s/600958/the-memory-trick-making-computers-seem-smarter"&gt;MIT Technology Review&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;Ask Me Anything: Dynamic Memory Networks for Natural Language Processing, Ankit Kumar, Ozan Irsoy, Peter Ondruska, Mohit Iyyer, James Bradbury, Ishaan Gulrajani, Victor Zhong, Romain Paulus, Richard Socher&lt;br&gt;The 33rd International Conference on Machine Learning (&lt;strong&gt;ICML 2016&lt;/strong&gt;). &lt;br&gt;Previous versions appeared at NIPS 2015 Deep Learning Symposium; NIPS 2015 workshop on Reasoning, Attention and Memory Workshop &lt;br&gt;[ &lt;a rel="nofollow" href="http://arxiv.org/abs/1506.07285"&gt;pdf&lt;/a&gt; , &lt;a rel="nofollow" href="http://www.wired.com/2015/06/ais-next-frontier-machines-understand-language/"&gt;Wired&lt;/a&gt;, &lt;a rel="nofollow" href="http://www.technologyreview.com/news/538821/computers-are-getting-a-dose-of-common-sense/"&gt;MIT Tech Review&lt;/a&gt;, &lt;a rel="nofollow" href="https://www.metamind.io/dmn"&gt;MetaMind announcement&lt;/a&gt; ] &lt;/p&gt; &lt;h4&gt; 2015&lt;/h4&gt;&lt;p&gt;Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks, Kai Sheng Tai, Richard Socher, and Christopher D. Manning&lt;br&gt;Association for Computational Linguistics 2015 Conference (&lt;strong&gt;ACL 2015&lt;/strong&gt;). [ &lt;a rel="nofollow" href="http://arxiv.org/abs/1503.00075"&gt;pdf&lt;/a&gt; , &lt;a rel="nofollow" href="https://github.com/stanfordnlp/treelstm"&gt;code&lt;/a&gt; ] &lt;/p&gt; &lt;h4&gt; 2014&lt;/h4&gt; &lt;p&gt;Global Belief Recursive Neural Networks, Romain Paulus, Richard Socher, Christopher D. Manning &lt;br&gt;Advances in Neural Information Processing Systems (&lt;strong&gt;NIPS 2014&lt;/strong&gt;). [ &lt;a rel="nofollow" href="https://www.socher.org/uploads/Main/PaulusSocherManning_NIPS2014.pdf"&gt;pdf&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;Aspect Specific Sentiment Analysis using Hierarchical Deep Learning, Himabindu Lakkaraju, Richard Socher, Chris Manning.&lt;br&gt;NIPS Workshop on Deep Learning and Representation Learning, 2014. [ &lt;a rel="nofollow" href="https://fb56552f-a-62cb3a1a-s-sites.googlegroups.com/site/deeplearningworkshopnips2014/58.pdf"&gt;pdf&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;Scaling Short-answer Grading by Combining Peer Assessment with Algorithmic Scoring, Chinmay Kulkarni, Richard Socher, Michael S. Bernstein, Scott R. Klemmer. &lt;br&gt;2014 ACM Conference on Learning at Scale [ &lt;a rel="nofollow" href="https://hci.stanford.edu/publications/2014/PeerStudio/las2008-kulkarni-ScalingShort-answerGrading.pdf"&gt;pdf&lt;/a&gt; ]. &lt;/p&gt; &lt;h4&gt; 2013&lt;/h4&gt; &lt;p&gt;Grounded Compositional Semantics for Finding and Describing Images with Sentences, Richard Socher, Quoc V. Le, Christopher D. Manning, Andrew Y. Ng. &lt;br&gt;Deep Learning Workshop at NIPS 2013 (see TACL 2014 version) &lt;/p&gt; &lt;div&gt; &lt;p&gt;&lt;a rel="nofollow" href="http://nlp.stanford.edu/sentiment/"&gt;Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank&lt;/a&gt;, Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Chris Manning, Andrew Ng and Chris Potts. &lt;br&gt;Conference on Empirical Methods in Natural Language Processing (&lt;strong&gt;EMNLP 2013, Oral&lt;/strong&gt;). [ &lt;a rel="nofollow" href="http://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf"&gt;pdf&lt;/a&gt;, &lt;a rel="nofollow" href="http://nlp.stanford.edu/~socherr/EMNLP2013_SemComp_SuppMat.pdf"&gt;Supplementary Material&lt;/a&gt;, &lt;span&gt;&lt;a rel="nofollow" href="http://nlp.stanford.edu/sentiment/"&gt;Website with Live Demo and Downloads&lt;/a&gt;;&lt;/span&gt; Press: &lt;a rel="nofollow" href="http://engineering.stanford.edu/news/stanford-algorithm-analyzes-sentence-sentiment-advances-machine-learning"&gt;Stanford release&lt;/a&gt;, &lt;a rel="nofollow" href="http://www.wired.com/wiredenterprise/2013/10/nasent-deep-learning/"&gt;Wired&lt;/a&gt;, &lt;a rel="nofollow" href="http://www.boston.com/bostonglobe/ideas/brainiac/2013/11/can_you_teach_a.html"&gt;Boston Globe&lt;/a&gt; &lt;a rel="nofollow" href="https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/"&gt;Related Kaggle Competition&lt;/a&gt; ]; &lt;/p&gt;&lt;/div&gt; &lt;p&gt;Bilingual Word Embeddings for Phrase-Based Machine Translation, Will Zou, Richard Socher, Daniel Cer and Christopher Manning. &lt;br&gt;Conference on Empirical Methods in Natural Language Processing (&lt;strong&gt;EMNLP 2013, Short&lt;/strong&gt;). [ &lt;a rel="nofollow" href="http://ai.stanford.edu/~wzou/emnlp2013_ZouSocherCerManning.pdf"&gt;pdf&lt;/a&gt; ] &lt;/p&gt; &lt;p&gt;Zero-Shot Learning Through Cross-Modal Transfer, Richard Socher, Milind Ganjoo, Hamsa Sridhar, Osbert Bastani, Christopher D. Manning, Andrew Y. Ng. &lt;br&gt;International Conference on Learning Representations (ICLR 2013, Workshop Track, Oral). [ &lt;a rel="nofollow" href="http://arxiv.org/pdf/1301.3666v2.pdf"&gt;pdf&lt;/a&gt;, &lt;a href="https://www.socher.org/index.php/Main/Zero-ShotLearningThroughCross-ModalTransfer"&gt;website&lt;/a&gt; ] &lt;/p&gt; &lt;h4&gt; 2012&lt;/h4&gt; &lt;p&gt;Stanford’s System for Parsing the English Web, David McClosky, Wanxiang Che, Marta Recasens, Mengqiu Wang, Richard Socher, and Christopher D. Manning &lt;br&gt;In Proceedings of First Workshop on Syntactic Analysis of Non-Canonical Language (SANCL at NAACL, 2012). [ &lt;a rel="nofollow" href="http://nlp.stanford.edu/pubs/mcclosky-sancl-12.pdf"&gt;pdf&lt;/a&gt;, &lt;a rel="nofollow" href="http://nlp.stanford.edu/pubs/mcclosky-sancl-12.bib"&gt;bib&lt;/a&gt; ] &lt;/p&gt; &lt;h4&gt; 2011&lt;/h4&gt; &lt;h4&gt; 2010&lt;/h4&gt; &lt;h4&gt; 2009&lt;/h4&gt;&lt;p&gt;&lt;a href="https://www.socher.org/index.php/Main/ABayesianAnalysisOfDynamicsInFreeRecall"&gt;A Bayesian analysis of dynamics in free recall&lt;/a&gt;, Richard Socher, Sam J. Gershman, Adler Perotte, Per Sederberg, Ken A. Norman, and David M. Blei. &lt;br&gt;Advances in Neural Information Processing Systems 22 (&lt;strong&gt;NIPS 2009&lt;/strong&gt;). [ &lt;a rel="nofollow" href="https://www.socher.org/uploads/Main/BayesianRecall-nips2009.pdf"&gt;pdf&lt;/a&gt; ] &lt;/p&gt; &lt;h4&gt; 2008&lt;/h4&gt; &lt;h4&gt; Former Students&lt;/h4&gt;&lt;div&gt; &lt;p&gt;Small subset of students or interns that I supervised at some point. &lt;/p&gt;&lt;ul&gt;&lt;li&gt;Jeffrey Pennington, Google Brain &lt;/li&gt;&lt;li&gt;Mohit Iyyer, professor in computer science at UMass Amherst &lt;/li&gt;&lt;li&gt;Tanay Tandon, Founder at Athelas &lt;/li&gt;&lt;li&gt;Ankit Kumar - Co-Founder &amp;amp; CTO - Ubiquity6 Inc. &lt;/li&gt;&lt;/ul&gt;&lt;/div&gt; &lt;h4&gt; Theses&lt;/h4&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://www.socher.org/index.php/Main/HomePage"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Fri, 12 Jun 2020 12:17:46 UT
      </pubDate>
      <guid>
        https://www.socher.org/index.php/Main/HomePage
      </guid>
    </item>
    <item>
      <title>
        Page not found | Center for the Study and Teaching of Writing
      </title>
      <link>
        https://cstw.osu.edu/writing-resources/dissertation-and-thesis-support
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div data-off-canvas-main-canvas=""&gt; &lt;header role="banner"&gt; &lt;div role="navigation" id="osu_navbar" aria-labelledby="osu_navbar_heading"&gt; &lt;h2 id="osu_navbar_heading"&gt;Ohio State nav bar&lt;/h2&gt; &lt;div&gt; &lt;div&gt; &lt;p&gt;&lt;a title="The Ohio State University" href="http://osu.edu/"&gt;The Ohio State University&lt;/a&gt;&lt;/p&gt; &lt;/div&gt; &lt;div&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="http://www.osu.edu/help.php"&gt;Help&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="http://buckeyelink.osu.edu/"&gt;BuckeyeLink&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="http://www.osu.edu/map/"&gt;Map&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="http://www.osu.edu/findpeople.php"&gt;Find People&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://email.osu.edu/"&gt;Webmail&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="http://www.osu.edu/search/"&gt;Search Ohio State&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div&gt; &lt;p&gt;&lt;a href="https://cstw.osu.edu/"&gt; &lt;img id="dep-logo-img" src="https://cstw.osu.edu/sites/default/files/logos/department-logo.svg" title="Center for the Study and Teaching of Writing" alt="Center for the Study and Teaching of Writing"&gt; &lt;/a&gt; &lt;a href="https://artsandsciences.osu.edu/"&gt; &lt;img id="asc-logo-img" src="https://cstw.osu.edu/themes/asc_bootstrap/images/logos/asc-logo.svg" title="College of Arts and Sciences logo" alt="College of Arts and Sciences logo"&gt; &lt;/a&gt; &lt;/p&gt; &lt;p&gt;&lt;a href="https://artsandsciences.osu.edu/"&gt; &lt;img id="asc-logo-img-mobile" src="https://cstw.osu.edu/themes/asc_bootstrap/images/logos/asc-logo-mobile.svg" title="College of Arts and Sciences logo" alt="College of Arts and Sciences logo"&gt; &lt;/a&gt; &lt;a href="https://cstw.osu.edu/"&gt; &lt;img id="dep-logo-img" src="https://cstw.osu.edu/sites/default/files/logos/department-logo-mobile.svg" title="Center for the Study and Teaching of Writing" alt="Center for the Study and Teaching of Writing"&gt; &lt;/a&gt; &lt;/p&gt; &lt;/div&gt; &lt;/header&gt; &lt;div id="main-nav"&gt; &lt;nav aria-label="Main"&gt; &lt;div&gt; &lt;section id="block-mainnavigation"&gt; &lt;span aria-label="Toggle Search" role="button"&gt; &lt;a title="Search" href="#"&gt; &lt;i&gt;&lt;/i&gt; &lt;/a&gt; &lt;/span&gt; &lt;ul id="superfish-main"&gt; &lt;li id="main-menu-link-content240e585f-733c-4816-9db6-1de38e706fca"&gt;&lt;a title="Our Mission here at CSTW" rel="" href="https://cstw.osu.edu/our-mission"&gt;Who We Are&lt;/a&gt;&lt;ul&gt;&lt;li id="main-menu-link-content73187732-1535-4f1b-8212-ba6ca301ec8f"&gt;&lt;a title="FAQs about the Writing Center" href="https://cstw.osu.edu/our-mission/faqs-facts-myths-about-cstw"&gt;FAQs, Facts, &amp;amp; Myths&lt;/a&gt;&lt;/li&gt;&lt;li id="main-menu-link-contentbc062670-3b72-4446-ae34-cd740e8a43c3"&gt;&lt;a title="CSTW Faculty, Staff and Consultants" href="https://cstw.osu.edu/our-mission/our-faculty-staff-tas"&gt;Faculty, Staff, &amp;amp; TAs&lt;/a&gt;&lt;/li&gt;&lt;li id="main-menu-link-content01b5ee97-d449-40c3-a9f2-599f7bd0f1ae"&gt;&lt;a title="List of Upcoming CSTW Events" href="https://cstw.osu.edu/our-mission/our-upcoming-events"&gt;Upcoming Events&lt;/a&gt;&lt;/li&gt;&lt;li id="main-menu-link-content445c6615-b451-43a0-940a-9a4b80d42c55"&gt;&lt;a title="Publications Written By CSTW Faculty, Staff, and Consultants" href="https://cstw.osu.edu/our-mission/selected-publications-cstw-faculty-staff-and-consultants"&gt;Publications&lt;/a&gt;&lt;/li&gt;&lt;li id="main-menu-link-content48db9602-4c54-4548-a90c-8a33f793d40d"&gt;&lt;a title="History of the Center for the Study and Teaching of Writing (CSTW)" href="https://cstw.osu.edu/our-mission/our-history"&gt;History&lt;/a&gt;&lt;/li&gt;&lt;li id="main-menu-link-content08e9aa34-60b2-466a-ad42-312cc3bce9e9"&gt;&lt;a title="CSTW Locations and Contact Information" href="https://cstw.osu.edu/our-mission/our-location-and-contact"&gt;Location and Contact&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li id="main-menu-link-content6c1bd44c-8688-40df-b755-f6eae5b1f6f8"&gt;&lt;a title="CSTW Programs and Services" href="https://cstw.osu.edu/our-programs"&gt;What We Do&lt;/a&gt;&lt;ul&gt;&lt;li id="main-menu-link-content9ea315ce-a775-4c9a-8bba-d040e549f712"&gt;&lt;a title="Writing Center Tutorial Services" href="https://cstw.osu.edu/our-programs/writing-center"&gt;Writing Center&lt;/a&gt;&lt;/li&gt;&lt;li id="main-menu-link-contentf859de76-baaf-41fd-9242-7097ab240917"&gt;&lt;a title="Faculty Development Help for Teaching Writing Across the Curriculum" href="https://cstw.osu.edu/our-programs/writing-across-curriculum"&gt;Writing Across the Curriculum&lt;/a&gt;&lt;/li&gt;&lt;li id="main-menu-link-content5e406027-ffc3-4b9f-95c5-8e0caedbb9e2"&gt;&lt;a title="Program that Places Tutors in Writing Courses at OSU" href="https://cstw.osu.edu/our-programs/writing-associates-program"&gt;Writing Associates Program&lt;/a&gt;&lt;/li&gt;&lt;li id="main-menu-link-contentf2d98520-673c-462d-af72-fff08e9e6dc5"&gt;&lt;a title="Collaboration with the Columbus Global Academy" href="https://cstw.osu.edu/our-programs/columbus-global-academy"&gt;Columbus Global Academy&lt;/a&gt;&lt;/li&gt;&lt;li id="main-menu-link-contenta9107449-8cb0-4012-8aa1-f55b02917b23"&gt;&lt;a title="Research Projects Undertaken by the CSTW Faculty and Staff" href="https://cstw.osu.edu/our-programs/research"&gt;Research&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li id="main-menu-link-content6c198ea8-3d22-4f51-b016-9cc5b593013f"&gt;&lt;a title="Writing Tips and Tools for Instructors and Students" href="https://cstw.osu.edu/tips-and-tools"&gt;Tips and Tools&lt;/a&gt;&lt;/li&gt;&lt;li id="main-menu-link-content2a0ff99c-9adc-42b9-9c64-740b259d1e6f"&gt;&lt;a title="Make an Appointment for Writing Center Tutoring" href="https://cstw.osu.edu/make-writing-center-appointment"&gt;Make an Appointment&lt;/a&gt;&lt;ul&gt;&lt;li id="main-menu-link-contenta6bdd499-4367-4424-b510-645edeaa9665"&gt;&lt;a title="Cancel an Individual Tutoring Appointment" href="https://cstw.osu.edu/make-writing-center-appointment/cancel-writing-center-appointment"&gt;Cancel a Writing Center Appointment&lt;/a&gt;&lt;/li&gt;&lt;li id="main-menu-link-content42d759b9-85b6-4f5a-a638-1c5294508429"&gt;&lt;a title="Instructors Schedule a Visit by Writing Center Staff to their Classrooms Here" href="https://cstw.osu.edu/make-writing-center-appointment/schedule-writing-center-classroom-visit"&gt;Schedule a Writing Center Classroom Visit&lt;/a&gt;&lt;/li&gt;&lt;li id="main-menu-link-contentbb1aed7a-3f80-4b17-af11-6363307e1d24"&gt;&lt;a title="Get Help with WCOnline Application for Scheduling Tutorials" href="https://cstw.osu.edu/make-writing-center-appointment/wconline-support"&gt;WCOnline Support&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li id="main-menu-link-contentb36d2a4c-8aa5-41f4-b6a3-dd803aba4965"&gt;&lt;a title="See and Apply for Positions at CSTW" href="https://cstw.osu.edu/work-for-us"&gt;Work for Us&lt;/a&gt;&lt;ul&gt;&lt;li id="main-menu-link-content78a1e690-26b5-4875-9943-8e75e356f649"&gt;&lt;a title="CSTW's Writing Center Positions" href="https://cstw.osu.edu/work-for-us/writing-center-positions"&gt;Writing Center Positions&lt;/a&gt;&lt;/li&gt;&lt;li id="main-menu-link-content11bbfd45-576a-4d47-b07c-4c2caae61609"&gt;&lt;a title="See and Apply for Positions in the WAC Program" href="https://cstw.osu.edu/wac-positions"&gt;WAC Positions&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li id="main-menu-link-content8a659e7d-41f9-4f60-8d14-fde195781953"&gt;&lt;a title="Find Information about Past CSTW Employees" href="https://cstw.osu.edu/alumni-and-friends"&gt;Alumni and Friends&lt;/a&gt;&lt;/li&gt;&lt;li id="main-menu-link-contentd2807631-96fb-48cd-b459-a406a5dfde57"&gt;&lt;a title="Make a donation to CSTW" href="https://cstw.osu.edu/donate"&gt;Donate&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;ul&gt; &lt;span aria-label="Toggle Search" role="button"&gt; &lt;a title="Search" href="#"&gt; &lt;i&gt;&lt;/i&gt; &lt;/a&gt; &lt;/span&gt; &lt;/ul&gt;&lt;/section&gt; &lt;div role="search" id="block-asc-bootstrap-search" data-drupal-selector="search-block-form"&gt; &lt;h2&gt;Search&lt;/h2&gt; &lt;form id="search-block-form" method="get" action="/search/node"&gt; &lt;div&gt; &lt;p&gt;&lt;label for="edit-keys"&gt;Search&lt;/label&gt;&lt;/p&gt; &lt;/div&gt; &lt;/form&gt; &lt;/div&gt; &lt;/div&gt; &lt;/nav&gt; &lt;/div&gt; &lt;div id="breadcrumb-container"&gt; &lt;nav aria-label="Breadcrumb"&gt; &lt;div&gt; &lt;ol&gt; &lt;li&gt; &lt;a href="https://cstw.osu.edu/"&gt;Home&lt;/a&gt; &lt;/li&gt; &lt;li&gt; Page not found &lt;/li&gt; &lt;/ol&gt; &lt;/div&gt; &lt;/nav&gt; &lt;/div&gt; &lt;section role="main"&gt; &lt;a id="main-content"&gt;&lt;/a&gt; &lt;div&gt; &lt;h2&gt;Page not found&lt;/h2&gt;&lt;p&gt; The requested page could not be found. &lt;/p&gt;&lt;/div&gt; &lt;/section&gt; &lt;div id="subfoot"&gt; &lt;div&gt; &lt;p&gt;&lt;a href="https://osu.edu/"&gt; &lt;img alt="The Ohio State University logo" src="https://cstw.osu.edu/themes/asc_bootstrap/images/osu-web-footer-wordmark-rev.png"&gt; &lt;/a&gt; &lt;/p&gt; &lt;div&gt; &lt;ul&gt; &lt;li id="access-area"&gt; If you have a disability and experience difficulty accessing this site, please contact us for assistance via email at &lt;a title="Email for accessibility assistance" href="mailto:asc-accessibility@osu.edu"&gt;asc-accessibility@osu.edu&lt;/a&gt;. &lt;/li&gt; &lt;li&gt; &lt;a href="https://go.osu.edu/privacy"&gt; Privacy Policy &lt;/a&gt; &lt;/li&gt; &lt;li&gt; &lt;a href="https://cstw.osu.edu/saml_login"&gt; LOGIN &lt;/a&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;div&gt; &lt;p&gt;&lt;small&gt;© 2021. The Ohio State University&lt;/small&gt;&lt;/p&gt; &lt;div&gt; &lt;p&gt;&lt;small&gt;&lt;i&gt;Designed and built by &lt;a href="https://asctech.osu.edu/services/web-services"&gt;ASCTech Web Services&lt;/a&gt;&lt;/i&gt;&lt;/small&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://cstw.osu.edu/writing-resources/dissertation-and-thesis-support"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Thu, 25 Jun 2020 07:52:27 UT
      </pubDate>
      <guid>
        https://cstw.osu.edu/writing-resources/dissertation-and-thesis-support
      </guid>
    </item>
    <item>
      <title>
        ETS Research: Automated Scoring of Writing Quality
      </title>
      <link>
        https://www.ets.org/research/topics/as_nlp/writing_quality/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt; &lt;p&gt;The &lt;span&gt;e-rater&lt;/span&gt;&lt;sup&gt;®&lt;/sup&gt; automated writing evaluation engine is ETS's patented capability for automated evaluation of expository, persuasive and summary essays. Multiple assessment programs use the engine. The engine is used in combination with human raters to score the writing sections of the &lt;span&gt;TOEFL iBT&lt;/span&gt;&lt;sup&gt;®&lt;/sup&gt; and &lt;span&gt;GRE&lt;/span&gt;&lt;sup&gt;®&lt;/sup&gt; tests.&lt;/p&gt; &lt;p&gt;The &lt;span&gt;e-rater&lt;/span&gt; engine is also used as the sole score in learning contexts, such as formative use in a classroom setting with ETS's &lt;span&gt;Criterion&lt;/span&gt;&lt;sup&gt;®&lt;/sup&gt; online essay evaluation system. In the &lt;span&gt;Criterion&lt;/span&gt; application, the engine is used to generate individualized feedback for students, addressing an increasingly important need for automated essay evaluation that is reliable, valid, fast and flexible.&lt;/p&gt; &lt;p&gt;The &lt;span&gt;e-rater&lt;/span&gt; engine features related to writing quality include:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;errors in grammar (e.g., subject-verb agreement)&lt;/li&gt; &lt;li&gt;usage (e.g., preposition selection)&lt;/li&gt; &lt;li&gt;mechanics (e.g., capitalization)&lt;/li&gt; &lt;li&gt;style (e.g., repetitious word use)&lt;/li&gt; &lt;li&gt;discourse structure (e.g., presence of a thesis statement, main points)&lt;/li&gt; &lt;li&gt;vocabulary usage (e.g., relative sophistication of vocabulary)&lt;/li&gt; &lt;li&gt;sentence variety&lt;/li&gt; &lt;li&gt;source use&lt;/li&gt; &lt;li&gt;discourse coherence quality&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The &lt;span&gt;e-rater&lt;/span&gt; engine can also automatically detect responses that are off-topic or otherwise anomalous and, therefore, should not be scored.&lt;/p&gt; &lt;p&gt;ETS has an active research agenda that investigates new automated scoring features for genres of writing beyond traditional essay genres, and now includes source-based and argumentative writing tasks found on assessments, as well as lab reports or social science papers.&lt;/p&gt; &lt;h2&gt;Featured Publications&lt;/h2&gt; &lt;p&gt;Below are some recent or significant publications that our researchers have authored that highlight research in automated writing evaluation.&lt;/p&gt; &lt;h3&gt;2017&lt;/h3&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.ets.org/research/policy_research_reports/publications/chapter/2017/jzbr"&gt;Exploring Relationships Between Writing &amp;amp; Broader Outcomes with Automated Writing Evaluation&lt;/a&gt;&lt;/strong&gt;&lt;br&gt;J. Burstein, D. McCaffrey, B. Beigman Klebanov, &amp;amp; G. Ling&lt;br&gt;Paper in &lt;em&gt;Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications&lt;/em&gt;, pp. 101–108&lt;/p&gt; &lt;p&gt;The exploratory study was conducted using test-taker essays from a standardized writing assessment of postsecondary student learning outcomes. Findings showed that for the essays, automated writing evaluation (AWE) features were found to be predictors of broader outcomes measures: college success indicators and learning outcomes measures. &lt;a href="https://www.ets.org/research/policy_research_reports/publications/chapter/2017/jzbr"&gt;Learn more about this publication &amp;gt; &lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.ets.org/research/policy_research_reports/publications/chapter/2017/jzbs"&gt;Detecting Good Arguments in a Non-Topic-Specific Way: An Oxymoron?&lt;/a&gt;&lt;/strong&gt;&lt;br&gt;B. Beigman Klebanov, B. Gyawali, &amp;amp; Y. Song&lt;br&gt;Paper in &lt;em&gt;Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, Volume 2: Short Papers&lt;/em&gt;, pp. 244–249&lt;/p&gt; &lt;p&gt;We investigate the extent to which it is possible to close the performance gap between topic-specific and across-topics models for identification of good arguments. &lt;a href="https://www.ets.org/research/policy_research_reports/publications/chapter/2017/jzbs"&gt;Learn more about this publication &amp;gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;2016&lt;/h3&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://journals.equinoxpub.com/index.php/CALICO/article/view/26374"&gt;&lt;span&gt;Informing Automated Writing Evaluation Using the Lens of Genre: Two Studies&lt;/span&gt;&lt;/a&gt;&lt;br&gt; J. Burstein, N. Elliott, &amp;amp; H. Molloy&lt;br&gt;&lt;em&gt;CALICO Journal, &lt;/em&gt;Vol. 33, No. 1&lt;/p&gt; &lt;p&gt;To construct-relevant systems used for writing instruction and assessment, researchers conducted two investigations of post-secondary writing requirements and faculty perceptions of student writing proficiency. Study results suggested ways that the role of automated writing evaluation might be expanded and aligned with instruction in higher education. &lt;a href="https://journals.equinoxpub.com/index.php/CALICO/article/view/26374"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;2015&lt;/h3&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://aclweb.org/anthology/W/W15/W15-1402.pdf"&gt;&lt;span&gt;Supervised Word-Level Metaphor Detection: Experiments with Concreteness and Reweighting of Examples&lt;/span&gt;&lt;/a&gt;&lt;br&gt; B. Beigman-Klebanov, C. W. Leong, &amp;amp; M. Flor&lt;br&gt; Paper in &lt;span&gt;Proceedings of the Third Workshop on Metaphor in NLP&lt;/span&gt;, pp. 11–20&lt;/p&gt; &lt;p&gt;The authors discuss a supervised machine learning system that classifies all content words in a running text as either metaphorical or nonmetaphorical. &lt;a href="http://aclweb.org/anthology/W/W15/W15-1402.pdf"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://www.aclweb.org/anthology/W15-0605"&gt;&lt;span&gt;Automated Scoring of Picture-based Story Narration&lt;/span&gt;&lt;/a&gt;&lt;br&gt; S. Somasundaran, C.-M. Lee, M. Chodorow, &amp;amp; X. Wang&lt;br&gt; Paper in &lt;span&gt;Proceedings of the Tenth Workshop on Innovative Use of NLP for Building Educational Applications&lt;/span&gt;, pp. 42–48&lt;/p&gt; &lt;p&gt;This paper describes an investigation of linguistically motivated features for automatically scoring a spoken picture-based narration task. &lt;a href="http://www.aclweb.org/anthology/W15-0605"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://www.aclweb.org/anthology/W15-0608"&gt;&lt;span&gt;Scoring Persuasive Essays Using Opinions and their Targets&lt;/span&gt;&lt;/a&gt;&lt;br&gt; N. Farra, S. Somasundaran, &amp;amp; J. Burstein&lt;br&gt; Paper in &lt;span&gt;Proceedings of the Tenth Workshop on Innovative Use of NLP for Building Educational Applications, pp&lt;/span&gt;. 64–74&lt;/p&gt; &lt;p&gt;In this work, researchers investigate whether the analysis of opinion expressions can help in scoring persuasive essays. Experiments on test taker essays show that essay scores produced using opinion features are indeed correlated with human scores. &lt;a href="http://www.aclweb.org/anthology/W15-0608"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://www.guilford.com/books/Handbook-of-Writing-Research/MacArthur-Graham-Fitzgerald/9781462522439/contents"&gt;&lt;span&gt;Automated Writing Evaluation: A Growing Body of Knowledge&lt;/span&gt;&lt;/a&gt;&lt;br&gt; M. Shermis, J. Burstein, N. Elliot, S. Miel, &amp;amp; P. Foltz. In C. MacArthur, S. Graham, &amp;amp; J. Fitzgerald (Eds.), &lt;span&gt;Handbook of Writing Research, 2nd Edition&lt;/span&gt; Guilford &lt;span&gt;Press&lt;/span&gt;&lt;/p&gt; &lt;p&gt;The authors present automated writing evaluation in terms of the categories of evidence that are used to demonstrate that these systems are useful in teaching and assessing writing. &lt;a href="http://www.guilford.com/books/Handbook-of-Writing-Research/MacArthur-Graham-Fitzgerald/9781462522439/contents"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://www.ets.org/research/policy_research_reports/publications/report/2015/junr"&gt;&lt;span&gt;Automated Analysis of Text in Graduate School Recommendations&lt;/span&gt;&lt;/a&gt;&lt;br&gt; M. Heilman, F. J. Breyer, F. Williams, D. Klieger, &amp;amp; M. Flor&lt;br&gt; ETS Research Report No. RR-15-23&lt;/p&gt; &lt;p&gt;This report explores evaluation of sentiment in letters of recommendation. Researchers developed and evaluated an approach to analyzing recommendations that involves (a) identifying which sentences are actually about the student; (b) measuring specificity; (c) measuring sentiment; and (d) predicting recommender ratings. &lt;a href="http://www.ets.org/research/policy_research_reports/publications/report/2015/junr"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://bells.uib.no/index.php/bells/article/view/811/751"&gt;&lt;span&gt;Patterns of Misspellings in L2 and L1 English: A View from the ETS Spelling Corpus&lt;/span&gt;&lt;/a&gt;&lt;br&gt; M. Flor, Y. Futagi, M. Lopez, &amp;amp; M. Mulholland&lt;br&gt; &lt;span&gt;Bergen Language and Linguistics Studies&lt;/span&gt;, Vol. 6&lt;/p&gt; &lt;p&gt;This paper presents a study of misspellings, based on annotated data from ETS's spelling corpus. Researchers examined data from the &lt;span&gt;TOEFL&lt;/span&gt;&lt;sup&gt;®&lt;/sup&gt; and GRE tests and found that the rate of misspellings decreased as writing proficiency (essay score) increased for test takers in both testing programs. &lt;a href="https://bells.uib.no/index.php/bells/article/view/811/751"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;2014&lt;/h3&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://acl2014.org/acl2014/P14-2/pdf/P14-2041.pdf"&gt;&lt;span&gt;Content Importance Models for Scoring Writing From Sources&lt;/span&gt;&lt;/a&gt;&lt;br&gt; B. Beigman Klebanov, N. Madnani, N., J. Burstein, &amp;amp; S. Somasundaran&lt;br&gt; Paper in &lt;span&gt;Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers)&lt;/span&gt;, pp. 247–252&lt;/p&gt; &lt;p&gt;This paper describes an integrative summarization task used in an assessment of English proficiency for nonnative speakers applying to higher education institutions in the United States. Researchers evaluate a variety of content importance models that help predict which parts of the source material the test taker would need to include in a successful response. &lt;a href="http://acl2014.org/acl2014/P14-2/pdf/P14-2041.pdf"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://www.ets.org/research/policy_research_reports/publications/report/2014/jsei"&gt;&lt;span&gt;Using Writing Process and Product Features to Assess Writing Quality and Explore How Those Features Relate to Other Literacy Tasks&lt;/span&gt;&lt;/a&gt;&lt;br&gt; P. Deane&lt;br&gt; ETS Research Report No. RR-14-03&lt;/p&gt; &lt;p&gt;This report explores automated methods for measuring features of student writing and determining its relationship to writing quality and other features of literacy, such as reading test scores. The &lt;span&gt;e-rater&lt;/span&gt; automated essay-scoring system and keystroke logging are a central focus. &lt;a href="http://www.ets.org/research/policy_research_reports/publications/report/2014/jsei"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://www.ets.org/research/policy_research_reports/publications/chapter/2014/jswe"&gt;&lt;span&gt;Predicting Grammaticality on an Ordinal Scale&lt;/span&gt;&lt;/a&gt;&lt;br&gt; M. Heilman, A. Cahill, N. Madnani, M. Lopez, M. Mulholland, &amp;amp; J. Tetreault&lt;br&gt; Paper in &lt;span&gt;Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics&lt;/span&gt;, (Short Papers), pp. 174–180&lt;/p&gt; &lt;p&gt;This paper describes a system for predicting the grammaticality of sentences on an ordinal scale. Such a system could be used in educational applications such as essay scoring. &lt;a href="http://www.ets.org/research/policy_research_reports/publications/chapter/2014/jswe"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://www.ets.org/research/policy_research_reports/publications/chapter/2014/jswf"&gt;&lt;span&gt;An Explicit Feedback System for Preposition Errors based on Wikipedia Revisions&lt;/span&gt;&lt;/a&gt;&lt;br&gt; N. Madnani &amp;amp; A. Cahill&lt;br&gt; Paper in &lt;span&gt;Proceedings of the Ninth Workshop on Innovative Use of NLP for Building Educational Applications&lt;/span&gt;, pp. 79–88&lt;/p&gt; &lt;p&gt;In this paper, the authors describe a novel tool they developed to provide automated explicit feedback to language learners based on data mined from Wikipedia revisions. They demonstrate how the tool works for the task of identifying preposition selection errors. &lt;a href="http://www.ets.org/research/policy_research_reports/publications/chapter/2014/jswf"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://www.ets.org/research/policy_research_reports/publications/chapter/2014/jswn"&gt;&lt;span&gt;Difficult Cases: From Data to Learning and Back&lt;/span&gt;&lt;/a&gt;&lt;br&gt; B. Beigman Klebanov &amp;amp; E. Beigman&lt;br&gt; Paper in Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, (Short Papers), pp. 390–396&lt;/p&gt; &lt;p&gt;This paper addresses cases in annotated datasets that are difficult to annotate reliably. Using a semantic annotation task, the authors provide empirical evidence that difficult cases can thwart supervised machine learning on the one hand and provide valuable insights into the characteristics of the data representation chosen for the task on the other. &lt;a href="http://www.ets.org/research/policy_research_reports/publications/chapter/2014/jswn"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://www.ets.org/research/policy_research_reports/publications/chapter/2014/jswm"&gt;&lt;span&gt;Different Texts, Same Metaphors: Unigrams and Beyond&lt;/span&gt;&lt;/a&gt;&lt;br&gt; B. Beigman Klebanov, C. Leong, M. Heilman, &amp;amp; M. Flor (2014)&lt;br&gt; Paper in &lt;span&gt;Proceedings of the Second Workshop on Metaphor in NLP&lt;/span&gt;, pp. 11–17&lt;/p&gt; &lt;p&gt;This paper describes the development of a supervised learning system to classify all content words in a running text as either being used metaphorically or not. &lt;a href="http://www.ets.org/research/policy_research_reports/publications/chapter/2014/jswm"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://www.aclweb.org/anthology/C14-1090"&gt;&lt;span&gt;Lexical Chaining for Measuring Discourse Coherence Quality in Test-taker Essays&lt;/span&gt;&lt;/a&gt;&lt;br&gt; S. Somasundaran, J. Burstein, &amp;amp; M. Chodorow&lt;br&gt; In The 25th International Conference on Computational Linguistics (COLING), Dublin, Ireland, August 23–29, 2014.&lt;br&gt; Paper in &lt;span&gt;Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers&lt;/span&gt;, pp. 950–961&lt;/p&gt; &lt;p&gt;Researchers investigated a technique known as lexical chaining for measuring discourse coherence quality in test-taker essays. In this paper, they describe the contexts in which they achieved the best system performance. &lt;a href="http://www.aclweb.org/anthology/C14-1090"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://www.ets.org/research/policy_research_reports/publications/chapter/2014/jswo"&gt;&lt;span&gt;Applying Argumentation Schemes for Essay Scoring&lt;/span&gt;&lt;/a&gt;&lt;br&gt; Y. Song, M. Heilman, B. Beigman Klebanov, &amp;amp; P. Deane&lt;br&gt; Paper in &lt;span&gt;Proceedings of the First Workshop on Argumentation Mining&lt;/span&gt;, pp. 69–78&lt;/p&gt; &lt;p&gt;In this paper, the authors develop an annotation approach based on the theory of argumentation schemes to analyze the structure of arguments and implement an NLP system for automatically predicting where critical questions are raised in essays. &lt;a href="http://www.ets.org/research/policy_research_reports/publications/chapter/2014/jswo"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;2013&lt;/h3&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://www.taylorandfrancis.com/books/details/9780415810968/"&gt;&lt;span&gt;Handbook of Automated Essay Evaluation: Current Applications and New Directions&lt;/span&gt;&lt;/a&gt;&lt;br&gt; M. D. Shermis &amp;amp; J. Burstein&lt;/p&gt; &lt;p&gt;This comprehensive, interdisciplinary handbook reviews the latest methods and technologies used in automated essay evaluation (AEE) methods and technologies. New York: Routledge. &lt;a href="http://search.ets.org/researcher/cs.html?url=http%3A//www.ets.org/research/policy_research_reports/publications/book/2013/jqej&amp;amp;qt=TI%3A%E2%80%A2+TI%3AHandbook+TI%3Aof+TI%3AAutomated+TI%3AEssay+TI%3AEvaluation%3A+TI%3ACurrent+TI%3AApplications+TI%3Aand+TI%253"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://www.aclweb.org/anthology/P13-1113.pdf"&gt;&lt;span&gt;Word Association Profiles and their Use for Automated Scoring of Essays&lt;/span&gt;&lt;/a&gt;&lt;br&gt; B. Beigman Klebanov &amp;amp; M. Flor&lt;br&gt; Paper in &lt;span&gt;Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics&lt;/span&gt; (Volume 1: Long Papers). pp. 1148–1158&lt;/p&gt; &lt;p&gt;The authors describe a new representation of the content vocabulary in a text, which they refer to as "word association profile." The paper presents a study of the relationship between quality of writing and word association profiles. &lt;a href="http://www.aclweb.org/anthology/P13-1113.pdf"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://search.ets.org/researcher/cs.html?url=http%3A//www.ets.org/research/policy_research_reports/publications/chapter/2013/jrhc&amp;amp;qt=TI%3ARobust+TI%3ASystems+TI%3Afor+TI%3APreposition+TI%3AError+TI%3ACorrection+TI%3AUsing+TI%3AWikipedia+TI%3ARevisions&amp;amp;col="&gt;&lt;span&gt;Robust Systems for Preposition Error Correction Using Wikipedia Revisions&lt;/span&gt;&lt;/a&gt;&lt;br&gt; A. Cahill, N. Madnani, J. Tetreault, &amp;amp; D. Napolitano&lt;br&gt; In &lt;span&gt;Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies&lt;/span&gt;, pp. 507–517, Atlanta, Ga.&lt;/p&gt; &lt;p&gt;This paper addresses the lack of generalizability in preposition error correction systems across different test sets. The authors then present a large new annotated corpus to be used in training such systems, and illustrate the use of the corpus in training systems across three separate test sets. &lt;a href="http://search.ets.org/researcher/cs.html?url=http%3A//www.ets.org/research/policy_research_reports/publications/chapter/2013/jrhc&amp;amp;qt=TI%3ARobust+TI%3ASystems+TI%3Afor+TI%3APreposition+TI%3AError+TI%3ACorrection+TI%3AUsing+TI%3AWikipedia+TI%3ARevisions&amp;amp;col="&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.ets.org/research/policy_research_reports/publications/chapter/2013/jrhm"&gt;&lt;span&gt;Detecting Missing Hyphens in Learner Text&lt;/span&gt;&lt;/a&gt;&lt;br&gt; A. Cahill, M. Chodorow, S. Wolff &amp;amp; N. Madnani&lt;br&gt; In &lt;span&gt;Proceedings of the Eighth Workshop on Innovative Use of NLP for Building Educational Applications&lt;/span&gt;, pp. 300–305, Atlanta, Ga.&lt;/p&gt; &lt;p&gt;This paper presents a method for automatically detecting missing hyphens in English text. &lt;a href="https://www.ets.org/research/policy_research_reports/publications/chapter/2013/jrhm"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://search.ets.org/researcher/cs.html?url=http%3A//www.ets.org/research/policy_research_reports/publications/chapter/2013/jqez&amp;amp;qt=TI%3A%E2%80%A2+TI%3AThe+TI%3AE-rater%C2%AE+TI%3AAutomated+TI%3AEssay+TI%3AScoring+TI%3ASystem&amp;amp;col=rsrchr&amp;amp;n=1"&gt;&lt;span&gt;The &lt;span&gt;e-rater&lt;/span&gt;&lt;sup&gt;®&lt;/sup&gt; Automated Essay Scoring System&lt;/span&gt;&lt;/a&gt;&lt;br&gt; J. Burstein, J. Tetreault, &amp;amp; N. Madnani. In M. D. Shermis &amp;amp; J. Burstein (Eds.), &lt;span&gt;Handbook of Automated Essay Scoring: Current Applications and Future Directions.&lt;/span&gt; New York: Routledge.&lt;/p&gt; &lt;p&gt;This handbook chapter includes a description of the &lt;span&gt;e-rater&lt;/span&gt; automated essay scoring system and its NLP-centered approach, and a discussion of the system's applications and development efforts for current and future educational settings. &lt;a href="http://search.ets.org/researcher/cs.html?url=http%3A//www.ets.org/research/policy_research_reports/publications/chapter/2013/jqez&amp;amp;qt=TI%3A%E2%80%A2+TI%3AThe+TI%3AE-rater%C2%AE+TI%3AAutomated+TI%3AEssay+TI%3AScoring+TI%3ASystem&amp;amp;col=rsrchr&amp;amp;n=1"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;2012&lt;/h3&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.ets.org/research/policy_research_reports/publications/article/2012/jewi"&gt;&lt;span&gt;A Fast and Flexible Architecture for Very Large Word n-gram Datasets&lt;/span&gt;&lt;/a&gt;&lt;br&gt; M. Flor&lt;br&gt; &lt;span&gt;Natural Language Engineering, FirstView&lt;/span&gt; online publication, pp. 1–33&lt;/p&gt; &lt;p&gt;This paper presents a versatile architecture that uses a novel architecture, features lossless compression, and optimizes both speed and memory use. &lt;a href="https://www.ets.org/research/policy_research_reports/publications/article/2012/jewi"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.ets.org/research/policy_research_reports/publications/chapter/2012/jfoj"&gt;&lt;span&gt;Correcting Comma Errors in Learner Essays, and Restoring Commas in Newswire Text&lt;/span&gt;&lt;/a&gt;&lt;br&gt; R. Israel, J. Tetreault, &amp;amp; M. Chodorow (2012)&lt;br&gt; &lt;span&gt;Proceedings of the 2012 Meeting of the North American Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)&lt;/span&gt;, pp. 284–294&lt;br&gt; Association for Computational Linguistics&lt;/p&gt; &lt;p&gt;The authors present a system for detection and correction of the placement of commas in English-language sentences. The system likewise can restore commas in well-crafted sentences. &lt;a href="https://www.ets.org/research/policy_research_reports/publications/chapter/2012/jfoj"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.ets.org/research/policy_research_reports/publications/chapter/2012/jfon"&gt;&lt;span&gt;On Using Context for Automatic Correction of Non-Word Misspellings in Student Essays&lt;/span&gt;&lt;/a&gt;&lt;br&gt; M. Flor &amp;amp; Y. Futagi&lt;br&gt; &lt;span&gt;Proceedings of the 7th Workshop on Innovative Use of Natural Language Processing for Building Educational Applications (BEA)&lt;/span&gt; pp. 105–115&lt;/p&gt; &lt;p&gt;The authors discuss a new system for spell-checking that uses contextual information to perform automatic correction of non-word misspellings. The article relates how the system has been evaluated against a large body of &lt;span&gt;TOEFL&lt;/span&gt;&lt;sup&gt;®&lt;/sup&gt; and &lt;span&gt;GRE&lt;/span&gt;&lt;sup&gt;®&lt;/sup&gt; essays, which were written by both native and nonnative English speakers. &lt;a href="https://www.ets.org/research/policy_research_reports/publications/chapter/2012/jfon"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;2010&lt;/h3&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.ets.org/research/policy_research_reports/publications/chapter/2010/imrx"&gt;&lt;span&gt;Using Parse Features for Preposition Selection and Error Detection&lt;/span&gt;&lt;/a&gt;&lt;br&gt; J. Tetreault, J. Foster, &amp;amp; M. Chodorow&lt;br&gt; &lt;span&gt;Proceedings of the 2010 Association for Computational Linguistics (ACL 2010)&lt;/span&gt;&lt;br&gt; Association for Computational Linguistics&lt;/p&gt; &lt;p&gt;This paper evaluates the effect of adding features that aim to improve the detection of preposition errors in writing from speakers of English as a second language. &lt;a href="https://www.ets.org/research/policy_research_reports/publications/chapter/2010/imrx"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://www.ets.org/research/policy_research_reports/publications/chapter/2010/iltf"&gt;&lt;span&gt;Progress and New Directions in Technology for Automated Essay Evaluation&lt;/span&gt;&lt;/a&gt;&lt;br&gt; J. Burstein &amp;amp; M. Chodorow&lt;br&gt; &lt;span&gt;The Oxford Handbook of Applied Linguistics, 2nd Edition&lt;/span&gt;, pp. 487–497&lt;br&gt; Oxford University Press&lt;/p&gt; &lt;p&gt;This ETS-authored work is part of a 39-chapter volume that covers topics in applied linguistics with the goal of providing a survey of the field, showing the many connections among its subdisciplines, and exploring likely directions of its future development. &lt;a href="http://www.ets.org/research/policy_research_reports/publications/chapter/2010/iltf"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.ets.org/research/policy_research_reports/publications/chapter/2010/imsf"&gt;&lt;span&gt;Using Entity-Based Features to Model Coherence in Student Essays&lt;/span&gt;&lt;/a&gt;&lt;br&gt; J. Burstein, J. Tetreault, &amp;amp; S. Andreyev&lt;br&gt; &lt;span&gt;Human language technologies: The 2010 Annual Conference of the North American Chapter of the ACL&lt;/span&gt;, pp. 681–684&lt;br&gt; Association for Computational Linguistics&lt;/p&gt; &lt;p&gt;This paper describes a study in which researchers combined an algorithm for observing what computational linguists refer to as entities — nouns and pronouns — with natural language processing features related to grammar errors and word usage with the aim of creating applications that can evaluate evidence of coherence in essays. &lt;a href="https://www.ets.org/research/policy_research_reports/publications/chapter/2010/imsf"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;2008&lt;/h3&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.ets.org/research/policy_research_reports/publications/report/2008/hyfi"&gt;&lt;span&gt;A Developmental Writing Scale&lt;/span&gt;&lt;/a&gt;&lt;br&gt; Y. Attali &amp;amp; D. Powers&lt;br&gt; ETS Research Report No. RR-08-19&lt;/p&gt; &lt;p&gt;This report describes the development of grade norms for timed-writing performance in two modes of writing: persuasive and descriptive. &lt;a href="https://www.ets.org/research/policy_research_reports/publications/report/2008/hyfi"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;2006&lt;/h3&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.ets.org/research/policy_research_reports/publications/article/2006/hsjv"&gt;&lt;span&gt;Automated Essay Scoring With &lt;span&gt;e-rater&lt;/span&gt; v.2.0&lt;/span&gt;&lt;/a&gt;&lt;br&gt; Y. Attali &amp;amp; J. Burstein&lt;br&gt; &lt;span&gt;Journal of Technology, Learning, and Assessment&lt;/span&gt;, Vol. 4, No. 3&lt;/p&gt; &lt;p&gt;This article describes Version 2 of ETS's &lt;span&gt;e-rater&lt;/span&gt; essay scoring engine. The authors present evidence on the validity and reliability of the scores that the system generates. &lt;a href="https://www.ets.org/research/policy_research_reports/publications/article/2006/hsjv"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;2003&lt;/h3&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.ets.org/research/policy_research_reports/publications/article/2003/hyhm"&gt;&lt;span&gt;Finding the WRITE Stuff: Automatic Identification of Discourse Structure in Student Essays&lt;/span&gt;&lt;/a&gt;&lt;br&gt; J. Burstein, D. Marcu, &amp;amp; K. Knight&lt;br&gt; &lt;span&gt;IEEE Intelligent Systems: Special Issue on Advances in Natural Language Processing&lt;/span&gt;, Vol. 18, No. 1, pp. 32–39&lt;/p&gt; &lt;p&gt;In this article, the authors discuss the use of automated essay-scoring applications in the elementary through university levels for large-scale assessment and classroom instruction. &lt;a href="https://www.ets.org/research/policy_research_reports/publications/article/2003/hyhm"&gt;Learn more about this publication &lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Find More Articles&lt;/h2&gt; &lt;p&gt;View more research publications related to &lt;a href="http://search.ets.org/researcher/query.html?fl0=KW%3A&amp;amp;ty0=p&amp;amp;op0=&amp;amp;tx0=Automated%20Scoring%20of%20Writing%20Quality"&gt;automated scoring of writing quality&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://www.ets.org/research/topics/as_nlp/writing_quality/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Thu, 25 Jun 2020 07:54:45 UT
      </pubDate>
      <guid>
        https://www.ets.org/research/topics/as_nlp/writing_quality/
      </guid>
    </item>
    <item>
      <title>
        types
      </title>
      <link>
        https://cs.lmu.edu/~ray/notes/types/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt; &lt;h2&gt;Types&lt;/h2&gt; &lt;p&gt;Programs manipulate values according to their type. There is more to the study of types than you might think.&lt;/p&gt; &lt;h2&gt;Why Types?&lt;/h2&gt; &lt;p&gt;Our very intuition makes the concept of types inescapable.&lt;/p&gt; &lt;p&gt;We have an intuition that integers are different from strings which are different from people which are different from books which are different from planets which are, you get the idea. These differences arise from behavior: You can &lt;em&gt;open&lt;/em&gt; a socket, but not an integer; you can request the &lt;em&gt;parents&lt;/em&gt; of a person, but not a dictionary; you can &lt;em&gt;push&lt;/em&gt; an object onto a stack, but not onto character. Therefore:&lt;/p&gt; &lt;blockquote&gt;A value’s type constrains the way it may be used in a program.&lt;/blockquote&gt; &lt;p&gt;More philosophically:&lt;/p&gt; &lt;blockquote&gt;Types impose constraints on what we can and cannot say.&lt;/blockquote&gt; &lt;p&gt;More formally:&lt;/p&gt; &lt;blockquote&gt;A type consists of a set of values and a set of allowable operations.&lt;/blockquote&gt; &lt;h2&gt;Examples&lt;/h2&gt; &lt;p&gt;What are some types you know about from previous programming practice? Here are some you might have seen, Keep in mind, as you go through this list, that types are characterized by their operations (more so than their “values”):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;span&gt;void&lt;/span&gt;, the empty type; the type of no values at all.&lt;/li&gt; &lt;li&gt;&lt;span&gt;boolean&lt;/span&gt;, the type containing the values &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;false&lt;/code&gt;, with operations such as &lt;code&gt;and&lt;/code&gt;, &lt;code&gt;or&lt;/code&gt;, &lt;code&gt;xor&lt;/code&gt;, and &lt;code&gt;not&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;span&gt;atom&lt;/span&gt;: The type of named symbols. Atoms just have name, and that’s it. You don’t really operate on them (other than testing them for equality perhaps); you just pass them around. They just exist.&lt;/li&gt; &lt;li&gt;&lt;dfn&gt;Numeric types&lt;/dfn&gt;, with operations such as plus, minus, multiply, divide, remainder, modulo, abs, sign, sin, cos, tan, and on and on and on. Numeric types can be integral, fixed-point, floating point, or complex; bounded or unbounded; signed or unsigned. Examples include: &lt;span&gt;number&lt;/span&gt;, &lt;span&gt;int8&lt;/span&gt;, &lt;span&gt;int16&lt;/span&gt;, &lt;span&gt;int32&lt;/span&gt;, &lt;span&gt;int64&lt;/span&gt;, &lt;span&gt;int128&lt;/span&gt;, &lt;span&gt;int&lt;/span&gt;, &lt;span&gt;uint8&lt;/span&gt;, &lt;span&gt;uint16&lt;/span&gt;, &lt;span&gt;uint32&lt;/span&gt;, &lt;span&gt;uint64&lt;/span&gt;, &lt;span&gt;uint128&lt;/span&gt;, &lt;span&gt;uint&lt;/span&gt;, &lt;span&gt;bigint&lt;/span&gt;, &lt;span&gt;fixed&lt;/span&gt;, &lt;span&gt;float32&lt;/span&gt;, &lt;span&gt;float64&lt;/span&gt;, &lt;span&gt;float128&lt;/span&gt;, &lt;span&gt;complex64&lt;/span&gt;, &lt;span&gt;complex128&lt;/span&gt;, &lt;span&gt;ratio&lt;/span&gt;, &lt;span&gt;decimal&lt;/span&gt;, &lt;span&gt;bigdecimal&lt;/span&gt;. &lt;/li&gt; &lt;li&gt;&lt;span&gt;char&lt;/span&gt;: The type of “characters”, i.e., units of textual information. Exactly what a character is might differ from language to language.&lt;/li&gt; &lt;li&gt;&lt;dfn&gt;Collection Types&lt;/dfn&gt;, with operations such as &lt;em&gt;size&lt;/em&gt;, &lt;em&gt;is_empty&lt;/em&gt;, &lt;em&gt;contains&lt;/em&gt;, &lt;em&gt;add&lt;/em&gt;, &lt;em&gt;remove&lt;/em&gt;, &lt;em&gt;retain&lt;/em&gt;, &lt;em&gt;clear&lt;/em&gt;.&lt;/li&gt; &lt;li&gt;&lt;dfn&gt;Set Types&lt;/dfn&gt;, which are unordered collections of unique elements.&lt;/li&gt; &lt;li&gt;&lt;dfn&gt;Sequence Types&lt;/dfn&gt;. So many of these. Lists, stacks, queues, dequeues, priority queues, blocking queues. Even the famous &lt;dfn&gt;string&lt;/dfn&gt; is a kind of sequence, but there’s not a lot of agreement about what exactly strings are sequences of. Are they sequences of bytes? character codes? code points? unicode scalars? graphemes? String types are generally broken. You don't need them.&lt;/li&gt; &lt;li&gt;&lt;dfn&gt;Mapping Types&lt;/dfn&gt;, types that maps keys to values. If the keys are unique we call them &lt;dfn&gt;maps&lt;/dfn&gt; or &lt;dfn&gt;dictionaries&lt;/dfn&gt;; if keys do not have to be unique we call them &lt;dfn&gt;multimaps&lt;/dfn&gt;. Normally the keys are unordered, but &lt;dfn&gt;orderedmaps&lt;/dfn&gt; or those that are automatically iterated by in key-order (assuming keys are comparable).&lt;/li&gt; &lt;li&gt;&lt;dfn&gt;Singleton types&lt;/dfn&gt;, which are types that only have one value in them. The operations on that individual value vary, of course.&lt;/li&gt; &lt;li&gt;&lt;dfn&gt;Sum Types&lt;/dfn&gt;. The type $T_1 + T_2$ consists of all the values of $T_1$ plus all the values of $T_2$. Sums are often called &lt;dfn&gt;unions&lt;/dfn&gt;. If the alternatives are labeled (named), we get &lt;dfn&gt;tagged unions&lt;/dfn&gt;.&lt;/li&gt; &lt;li&gt;&lt;dfn&gt;Product Types&lt;/dfn&gt;, The type $T_1 \times T_2$ consists of all pairs $(x, y)$ where $x$ has type $T_1$ and $y$ has type $T_2$. In general you can have products of any size: $T_1 \times T_2 \times \ldots \times T_n$. If $n=0$ you have what’s sometimes called the unit type: the type of only one value. In general, product types are called &lt;dfn&gt;tuple types&lt;/dfn&gt;. If the components are labeled (named), we get &lt;dfn&gt;records&lt;/dfn&gt;.&lt;/li&gt; &lt;li&gt;&lt;dfn&gt;Routines&lt;/dfn&gt;, which can be &lt;dfn&gt;subroutines&lt;/dfn&gt; or &lt;dfn&gt;coroutines&lt;/dfn&gt;. Operations on routines include &lt;em&gt;invoke&lt;/em&gt; and &lt;em&gt;invokeLater&lt;/em&gt;. Other terms for &lt;em&gt;invoke&lt;/em&gt; include &lt;em&gt;call&lt;/em&gt; and &lt;em&gt;apply&lt;/em&gt; (from the idea of function “application” — “applying” a function to its argument(s)).&lt;/li&gt; &lt;li&gt;&lt;dfn&gt;Function types&lt;/dfn&gt;, computational mappings from arguments to results. We can classify functions in many ways: there are &lt;dfn&gt;predicates&lt;/dfn&gt;, which return booleans, &lt;dfn&gt;consumers&lt;/dfn&gt;, that accept arguments but do not return results, &lt;dfn&gt;suppliers&lt;/dfn&gt;, which take no arguments but return results.&lt;/li&gt; &lt;li&gt;&lt;dfn&gt;Processes&lt;/dfn&gt;, &lt;dfn&gt;Threads&lt;/dfn&gt;, and &lt;dfn&gt;Tasks&lt;/dfn&gt;, which are things that run asynchronously. Generally these things send messages to each other, but shared memory is sometimes used. They are generally created with a &lt;em&gt;spwan&lt;/em&gt; operation. Internally they use &lt;em&gt;send&lt;/em&gt; and &lt;em&gt;receive&lt;/em&gt; to communicate.&lt;/li&gt; &lt;li&gt;The type &lt;span&gt;type&lt;/span&gt;, whose members are...types!&lt;/li&gt; &lt;li&gt;The type &lt;span&gt;any&lt;/span&gt;, which is the type of all values.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;b&gt;Exercise&lt;/b&gt;: Spend some time thinking about the behaviors of each of the types above. &lt;/p&gt; &lt;h2&gt;Classifying Types&lt;/h2&gt; &lt;p&gt;It is tempting to try to put types into a hierarchy, or at least a directed acyclic graph:&lt;/p&gt; &lt;p&gt;&lt;img alt="typehierarchy.png" src="https://cs.lmu.edu/~ray/images/typehierarchy.png"&gt;&lt;/p&gt; &lt;p&gt;But it’s actually difficult to this because there are so many other ways to classify type that defy hierarchy. In fact, there’s this whole idea of classifying types into something called &lt;dfn&gt;typeclasses&lt;/dfn&gt;, which are things like this:&lt;/p&gt; &lt;p&gt;A type is &lt;dfn&gt;equatable&lt;/dfn&gt;, or is an &lt;dfn&gt;eqtype&lt;/dfn&gt;, if values of the type can be tested for equality (&lt;code&gt;==&lt;/code&gt;).&lt;/p&gt; &lt;ul&gt;&lt;li&gt;In some languages, all types are equatable because most of the types have reference semantics. In Haskell, however, functions, for example, are not equatable.&lt;/li&gt;&lt;/ul&gt; &lt;p&gt;A type is &lt;dfn&gt;comparable&lt;/dfn&gt; (a.k.a. &lt;dfn&gt;ordered&lt;/dfn&gt;) if values of the type can be compared with &lt;code&gt;&amp;lt;&lt;/code&gt; (and often also with &lt;code&gt;&amp;lt;=&lt;/code&gt;, &lt;code&gt;&amp;gt;&lt;/code&gt;, and &lt;code&gt;&amp;gt;=&lt;/code&gt;, and often &lt;code&gt;&amp;lt;=&amp;gt;&lt;/code&gt;).&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Generally (at least in the vast majority of languages), if you make your own class, it won’t be comparable be default.&lt;/li&gt;&lt;/ul&gt; &lt;p&gt;A type is &lt;dfn&gt;bounded&lt;/dfn&gt; if there is a minimum value of the type and a maximum value of the type.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Fixed-size integers and simple enumerations are bounded.&lt;/li&gt;&lt;/ul&gt; &lt;p&gt;A type is &lt;dfn&gt;showable&lt;/dfn&gt;, or is a &lt;dfn&gt;showtype&lt;/dfn&gt; if values of the type can be converted to strings.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Functions and binary streams are generally not showable.&lt;/li&gt;&lt;/ul&gt; &lt;p&gt;A type is &lt;dfn&gt;callable&lt;/dfn&gt; if values of its type can be called on, or applied to, other values.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Functions are callable. In Python, so are types!&lt;/li&gt;&lt;/ul&gt; &lt;p&gt;A type is &lt;dfn&gt;enumerable&lt;/dfn&gt; if it has successor and predecessor operations on its values.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Integers are enumerable, as are characters (enumerated via their code points). Note this definition does not apply to languages with very complex &lt;code&gt;enum&lt;/code&gt; things, like Swift. Those concepts are completely different.&lt;/li&gt;&lt;/ul&gt; &lt;p&gt;A type is &lt;dfn&gt;monoidal&lt;/dfn&gt;, or is a &lt;dfn&gt;monoid&lt;/dfn&gt;, if it has an associative composition operator, and an identity operator for the composition.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Concrete example: Functions! They have function composition and the identity &lt;code&gt;x =&amp;gt; x&lt;/code&gt; (JS notation).&lt;/li&gt; &lt;li&gt;Abstractly: $\exists e, \bullet:\; \forall a, b, c: a \bullet (b \bullet c) = (a \bullet b) \bullet c \wedge a \bullet e = e \bullet a$&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;A type is &lt;dfn&gt;monadic&lt;/dfn&gt;, or is a &lt;dfn&gt;monad&lt;/dfn&gt;, if values of the type “wrap” underlying values in some way (e.g. optional, list), and there is an operator to wrap a value, and an associative composition operator on functions that unwrap a value and do something to it to produce a new wrapped value, such that the wrapper is an identity for the composition.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://wiki.haskell.org/Monad_tutorials_timeline"&gt;Need a tutorial?&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt; &lt;blockquote&gt;&lt;b&gt;Typeclasses in Practice&lt;/b&gt;&lt;p&gt;Languages vary greatly in their treatment of typeclasses. Haskell has a distinguished typeclass concept (called a &lt;code&gt;class&lt;/code&gt;. Swift implements them via protocols, and other languages just use their own interface or mixin construct.&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;&lt;b&gt;Exercise&lt;/b&gt;: Find the built-in Swift protocols for equatables and comparables. How do they work? Craft an example that uses them. &lt;/p&gt; &lt;h2&gt;A Type Algebra&lt;/h2&gt; &lt;p&gt;We can arrange types by building them up algebraically, similar to how sets are built up, for example:&lt;/p&gt; &lt;table&gt; &lt;tbody&gt;&lt;tr&gt;&lt;th&gt;Kind of Type&lt;/th&gt;&lt;th&gt;Notation&lt;/th&gt;&lt;th&gt;Notes&lt;/th&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Empty&lt;/td&gt;&lt;td&gt;$\perp$&lt;/td&gt;&lt;td&gt;Type with no members at all. A &lt;dfn&gt;bottom type&lt;/dfn&gt; (meaning it is a subtype of all types). Sometimes called &lt;code&gt;Void&lt;/code&gt;.&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Singleton&lt;/td&gt;&lt;td&gt;$x$&lt;/td&gt;&lt;td&gt;Type with only a single member. Examples:&lt;table&gt; &lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;null&lt;/code&gt;&lt;/td&gt;&lt;td&gt;type containing only the value &lt;code&gt;null&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt;&lt;td&gt;type containing only the value &lt;code&gt;true&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;&lt;code&gt;"hello"&lt;/code&gt;&lt;/td&gt;&lt;td&gt;ttype containing only the value &lt;code&gt;"hello"&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;&lt;code&gt;5&lt;/code&gt;&lt;/td&gt;&lt;td&gt;type containing only the value &lt;code&gt;5&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;&lt;code&gt;blue&lt;/code&gt;&lt;/td&gt;&lt;td&gt;type containing only the value &lt;code&gt;blue&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt;&lt;/table&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Sum&lt;/td&gt;&lt;td&gt;$T_1\;|\;T_2\;|\,...|\;T_n$&lt;br&gt;&lt;i&gt;or&lt;/i&gt;&lt;br&gt;$x_1: T_1\;|\,...|\;x_n: T_n$&lt;/td&gt;&lt;td&gt;Also written $T_1 \cup T_2$ or $T_1 + T_2$. If unlabeled, generally called a &lt;dfn&gt;Union&lt;/dfn&gt;. If labeled, generally called a &lt;dfn&gt;Tagged Union&lt;/dfn&gt;. Examples:&lt;table&gt; &lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;true | false&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;&lt;code&gt;red | green | blue&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;&lt;code&gt;string | null&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;&lt;code&gt;int | bool | float&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;&lt;code&gt;1 | 2 | 3 | 4 | 5 | 6&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;&lt;code&gt;circle: float | rectangle: float × float&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;&lt;code&gt;enum { circle: Float; rectangle: (Float, Float) }&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt;&lt;/table&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Product&lt;/td&gt;&lt;td&gt;$(T_1, T_2, ... T_n)$&lt;br&gt;&lt;i&gt;or&lt;/i&gt;&lt;br&gt;$(x_1: T_1,..., x_n: T_n)$&lt;/td&gt;&lt;td&gt;Also written $T_1 \times T_2$. If unlabled, generally called a &lt;dfn&gt;Tuple&lt;/dfn&gt;. If labeled, generally called a &lt;dfn&gt;Record&lt;/dfn&gt; or &lt;dfn&gt;Struct&lt;/dfn&gt;. Examples: &lt;table&gt; &lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;bool × int&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;&lt;code&gt;(Bool, Int)&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;&lt;code&gt;()&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;&lt;code&gt;x: int × y: int&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;&lt;code&gt;struct { x: int; y: int; }&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt;&lt;/table&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Sequence&lt;/td&gt;&lt;td&gt;$T*$&lt;/td&gt;&lt;td&gt;a.k.a. Array or List. Examples:&lt;table&gt; &lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;[Int]&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Swift&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;&lt;code&gt;[]float64&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Go&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;&lt;code&gt;bool list&lt;/code&gt;&lt;/td&gt;&lt;td&gt;SML&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;&lt;code&gt;List&amp;lt;String&amp;gt;&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Java&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt;&lt;/table&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Function&lt;/td&gt;&lt;td&gt;$T_1 \rightarrow T_2$&lt;/td&gt;&lt;td&gt;A function from $T_1$ to $T_2$. Use $\perp$ or a product type for $T_1$ to simulate zero or multiple arguments, and $\perp$ or a product type for $T_2$ to simulate zero or multiple return values. Examples:&lt;table&gt; &lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;Int -&amp;gt; Int&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;&lt;code&gt;Bool* -&amp;gt; Int × String&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;&lt;code&gt;Int × Int × String -&amp;gt; Int&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;&lt;code&gt;Float → Void&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt;&lt;/table&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Any&lt;/td&gt;&lt;td&gt;$\top$&lt;/td&gt;&lt;td&gt;All values are a member of this type. The “type of everything.” A &lt;dfn&gt;top type&lt;/dfn&gt; (meaning all types are a subtype of it). Examples:&lt;table&gt; &lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;any&lt;/code&gt;&lt;/td&gt;&lt;td&gt;TypeScript&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;&lt;code&gt;interface{}&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Go&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;&lt;code&gt;BasicObject&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Ruby&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;&lt;code&gt;object&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Python&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt;&lt;/table&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt;&lt;/table&gt; &lt;p&gt;This arrangement actually works pretty well, as it covers most everything we need:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The &lt;dfn&gt;boolean type&lt;/dfn&gt; is really just &lt;code&gt;true | false&lt;/code&gt; for singleton types &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;A &lt;dfn&gt;string type&lt;/dfn&gt; is just a sequence of some underlying elements, maybe bytes, maybe character codes, maybe graphemes.&lt;/li&gt; &lt;li&gt;An &lt;dfn&gt;optional type&lt;/dfn&gt; is just &lt;code&gt;T | null&lt;/code&gt; for any type &lt;code&gt;T&lt;/code&gt; and singleton type &lt;code&gt;null&lt;/code&gt;. This is often abbreviated &lt;code&gt;T?&lt;/code&gt; or &lt;code&gt;Optional&amp;lt;T&amp;gt;&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;Are sequence types really primitive? Seems like we can just write $T* = T \cup (T \times T) \cup (T \times T \times T) \cup \ldots$, but the abbreviation is simpler, of course. Be pragmatic.&lt;/li&gt; &lt;li&gt;Many statically typed languages have a generic &lt;dfn&gt;Either&lt;/dfn&gt; type, a tagged union with labels such as &lt;code&gt;left&lt;/code&gt; and &lt;code&gt;right&lt;/code&gt;, or a similarly structured tagged union called &lt;dfn&gt;Result&lt;/dfn&gt; with labels &lt;code&gt;success&lt;/code&gt; and &lt;code&gt;failure&lt;/code&gt;. The latter is commonly used for returning, rather than throwing errors.&lt;/li&gt; &lt;li&gt;There is a type called &lt;code&gt;Never&lt;/code&gt;, which isn’t really a type, but used in place of a return type in a function that does not return, either because it enters an infinite loop or throws an error.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;b&gt;Exercise&lt;/b&gt;: In your own words, describe the difference between a sum type and a product type. &lt;/p&gt; &lt;p&gt;In case you haven’t seen singleton or union types before, you might not have seen TypeScript.&lt;/p&gt; &lt;p&gt;&lt;img alt="typescripterror.png" src="https://cs.lmu.edu/~ray/images/typescripterror.png"&gt;&lt;/p&gt; &lt;h2&gt;Type Systems&lt;/h2&gt; &lt;p&gt;In programming language theory, a language’s &lt;dfn&gt;type system&lt;/dfn&gt; answers questions such as: &lt;/p&gt;&lt;ol&gt; &lt;li&gt;Is the set of types fixed, or can you create new ones? &lt;/li&gt;&lt;li&gt;Are types extra-lingual, or are they themselves values? If values, are they first-class? Also if values, do they themselves belong to one of possibly many types or is there just one type? If not, can they be categorized into different, um, say, typeclasses? &lt;/li&gt;&lt;li&gt;What exactly &lt;em&gt;are&lt;/em&gt; the types of the language, and how are new types built? &lt;/li&gt;&lt;li&gt;How do we infer the type of an expression (gets tricky with variables) &lt;/li&gt;&lt;li&gt;How do we know when two types are exactly the same? &lt;/li&gt;&lt;li&gt;How do we know when two types are compatible? &lt;/li&gt;&lt;li&gt;What do we do when expressions are used in a way inconsistent with their type? &lt;/li&gt;&lt;/ol&gt; &lt;h2&gt;Fixed Type Systems&lt;/h2&gt; &lt;p&gt;Some languages predefine the set of types and do &lt;em&gt;not&lt;/em&gt; let you define new ones. These include: &lt;/p&gt;&lt;ul&gt; &lt;li&gt;&lt;b&gt;JavaScript&lt;/b&gt;: The only types are these eight: Undefined, Null, Boolean, String, Number, BigInt, Symbol, Object &lt;/li&gt;&lt;li&gt;&lt;b&gt;Lua&lt;/b&gt;: The only types are these eight: nil, boolean, number, string, function, thread, userdata, table. &lt;/li&gt;&lt;li&gt;&lt;b&gt;Erlang&lt;/b&gt;: The only types are: atom, integer, float, binary, ref, pid, port, function, list, tuple, map. &lt;/li&gt;&lt;/ul&gt; &lt;p&gt;JavaScript really does have only eight types, but it kind of &lt;em&gt;feels&lt;/em&gt; like it has more. For example: &lt;/p&gt;&lt;pre&gt;class Dog { bark() { return 'woof'; } } class Rat { squeak() { return 'peep'; } } const d = new Dog(); const r = new Rat(); d.constructor // Dog r.constructor // Rat typeof d // 'object' typeof r // 'object' &lt;img src="https://cs.lmu.edu/~ray/images/js-logo32.png"&gt;&lt;/pre&gt; &lt;p&gt;So in JavaScript you can make lots of different kinds of objects (even arrays, functions, dates, and regular expressions are objects), but all of these objects have the same type. They have different constructors, but constructors aren’t types. &lt;/p&gt;&lt;h2&gt;Are Types Values?&lt;/h2&gt; &lt;p&gt;In JavaScript, the value 100 has the type “number”, but this “number type” itself is not a JavaScript value. Types in JavaScript are &lt;dfn&gt;extra-lingual&lt;/dfn&gt;. You can ask for an expression’s type, but you’ll just get back a string: &lt;/p&gt;&lt;pre&gt;typeof 3 === 'number' typeof 'hello' === 'string' typeof { x: 1, y: 2 } === 'object' typeof typeof 3 === 'string' &lt;img src="https://cs.lmu.edu/~ray/images/js-logo32.png"&gt;&lt;/pre&gt; &lt;p&gt;Ditto for Lua: &lt;/p&gt;&lt;pre&gt;type(3) == 'number' type('hello') == 'string' type({ x=1, y=2 }) == 'table' type(type(3)) == 'string' &lt;img src="https://cs.lmu.edu/~ray/images/lua-logo32.png"&gt;&lt;/pre&gt;&lt;p&gt; In Erlang, you can’t even ask for the type, but there are built-in functions to tell you whether or not an expression has a type: &lt;/p&gt;&lt;pre&gt;is_atom(ten). is_integer($a). is_float(-3.55e-8). is_function(fun (X) -&amp;gt; X*X end). is_reference(make_ref()). is_tuple({dog, "Nika", 5, 'G-SHEP'}). is_list("a string"). &lt;img src="https://cs.lmu.edu/~ray/images/erlang-logo32.png"&gt;&lt;/pre&gt; &lt;blockquote&gt;This is probably a good thing, because as we’ll see, values can have multiple types at the same time. So asking for &lt;strong&gt;the&lt;/strong&gt; type of an expression might be an indication of a type system that is less sophisticated than it could be.&lt;/blockquote&gt; &lt;p&gt;In C, you can't even ask or check for a type, but you can see them! The types exist in the code, but they are not values that can be assigned to variables or passed as arguments or returned from functions. &lt;/p&gt;&lt;p&gt;&lt;b&gt;Exercise&lt;/b&gt;: Try writing C code that uses &lt;code&gt;int&lt;/code&gt; as a value. What problems do you run into? &lt;/p&gt; &lt;p&gt;In Python, on the other hand, the value 100 has the type &lt;code&gt;int&lt;/code&gt;, and &lt;code&gt;int&lt;/code&gt; itself is a value in Python. In fact it has the type &lt;code&gt;type&lt;/code&gt;. And, you guessed it, &lt;code&gt;type&lt;/code&gt; is a value whose type is... yes, &lt;code&gt;type&lt;/code&gt;! &lt;/p&gt;&lt;pre&gt;type(3) == int type('hello') == str type({ 'x':1, 'y':2 }) == dict type(int) == type type(type) == type type(type(type(type(3)))) == type &lt;img src="https://cs.lmu.edu/~ray/images/python-logo32.png"&gt;&lt;/pre&gt; &lt;p&gt;Same with Ruby, though in Ruby you tend to see classes more than types: &lt;/p&gt;&lt;pre&gt;3.class == Integer 'hello'.class == String {x: 1, y: 2}.class == Hash Integer.class == Class Class.class == Class &lt;img src="https://cs.lmu.edu/~ray/images/ruby-logo32.png"&gt;&lt;/pre&gt; &lt;p&gt;Java, too, has objects representing classes: &lt;/p&gt;&lt;pre&gt;System.out.println(new Integer(3).getClass()); // class java.lang.Integer System.out.println(int.class); // int System.out.println("hello".getClass()); // class java.lang.String System.out.println(new int[]{1, 2, 3}.getClass()); // class [I System.out.println(String.class); // class java.lang.String System.out.println("hi".getClass().getClass()); // class java.lang.Class &lt;/pre&gt; &lt;p&gt;Augh, wait, WTF...we have types and now &lt;em&gt;classes&lt;/em&gt;? &lt;/p&gt;&lt;h2&gt;Types vs. Classes&lt;/h2&gt; &lt;p&gt;So what is this thing we call a &lt;dfn&gt;class&lt;/dfn&gt;? A little hard to define, maybe.... Some languages conflate the notion of type and class, but most people agree there is a difference. &lt;/p&gt;&lt;table&gt; &lt;tbody&gt;&lt;tr&gt;&lt;th&gt;TYPE&lt;/th&gt;&lt;th&gt;CLASS &lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Is all about behavior&lt;/td&gt;&lt;td&gt;Is about both structure and behavior &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;An object can have many types&lt;/td&gt;&lt;td&gt;An object belongs to exactly one class &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Is about interfacing and usage&lt;/td&gt;&lt;td&gt;Is about construction, and things like fields/properties and methods &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt; &lt;p&gt;&lt;b&gt;Example&lt;/b&gt;: A string object in Java has multiple types, including &lt;code&gt;String&lt;/code&gt;, &lt;code&gt;Comparable&lt;/code&gt;, and &lt;code&gt;Object&lt;/code&gt;. But only &lt;em&gt;one&lt;/em&gt; class: &lt;code&gt;String&lt;/code&gt;. &lt;/p&gt; &lt;pre&gt;String s = "hello"; // "hello" ∈ type String Comparable c = s; // "hello" ∈ type Comparable Object o = s; // "hello" ∈ type Object System.out.println(o.getClass().getName()); // THE class of "hello" is String &lt;img src="https://cs.lmu.edu/~ray/images/java-logo32.png"&gt;&lt;/pre&gt; &lt;p&gt;In most languages, declaring a class gives rise to a type. The exceptions to this rule are JavaScript and CoffeeScript, where the word &lt;code&gt;class&lt;/code&gt; does not make a type: instead it is a funny way of declaring a function and a prototype. &lt;/p&gt;&lt;p&gt;Other languages are similar to Java in having a &lt;code&gt;class&lt;/code&gt; construct that makes a type, but they also have ways to make types that “mixin” behaviors, for example Ruby has &lt;code&gt;module&lt;/code&gt;s and Swift has &lt;code&gt;protocol&lt;/code&gt;s. Go has &lt;code&gt;struct&lt;/code&gt;s for the class-concept and &lt;code&gt;interface&lt;/code&gt;s for the pure behavior-only types. &lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;Oversimplying just a bit...&lt;/b&gt;&lt;p&gt;A class is an object factory; a type is a behavioral specification.&lt;/p&gt;&lt;/blockquote&gt; &lt;h2&gt;Type Expressions&lt;/h2&gt; &lt;p&gt;In many languages, you get a set of basic types and mechanisms for making new types. Some examples: &lt;/p&gt;&lt;table&gt; &lt;tbody&gt;&lt;tr&gt; &lt;th&gt;Language &lt;/th&gt;&lt;th&gt;Basic Types &lt;/th&gt;&lt;th&gt;Type formers &lt;/th&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;C &lt;/td&gt;&lt;td&gt;char, signed char, unsigned char, short, unsigned short, int, unsigned, long, unsigned long, long long, unsigned long long, float, double, long double, _Bool, float _Complex, double _Complex, long double _Complex, float _Imaginary, double _Imaginary, long double _Imaginary &lt;/td&gt;&lt;td&gt;enum, *, [], (), union, struct &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;Java &lt;/td&gt;&lt;td&gt;boolean, byte, char, short, int, long, float, double &lt;/td&gt;&lt;td&gt;interface, class, enum, [] &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;Standard ML &lt;/td&gt;&lt;td&gt;unit, bool, int, word, real, char, string &lt;/td&gt;&lt;td&gt;-&amp;gt;, *, list, option, exn, ref, frag, datatype, {} &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;Python &lt;/td&gt;&lt;td&gt;NoneType, NotImplementedType, ellipsis, int, bool, float, complex, str, bytes, tuple, list, bytearray, set, frozenset, dict, function, generator, method, classmethod, staticmethod, module, slice, range, type &lt;/td&gt;&lt;td&gt;class &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;Go &lt;/td&gt;&lt;td&gt;bool, int8 (byte), int16, int32 (rune), int64, int, uint8, uint16, uint32, uint64, uintptr, float32, float64, complex64, complex128, string, error &lt;/td&gt;&lt;td&gt;[], map, *, func, struct, interface, chan &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;Rust &lt;/td&gt;&lt;td&gt;bool, i8, i16, i32, i64, i128, isize, u8, u16, u32, u64, u128, usize, f32, f64, char, str, ! &lt;/td&gt;&lt;td&gt;(T1, T2), [T ; N], [T], struct, enum, union, &lt;code&gt;-&amp;gt;&lt;/code&gt;, &amp;amp;, &amp;amp;mut, *const, *mut, trait, impl &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;Swift &lt;/td&gt;&lt;td&gt;Bool, Int8, Int16, Int32, Int64, Int, UInt8, UInt16, UInt32 UInt64, UInt, Float, Double, Character, String, &lt;/td&gt;&lt;td&gt;(T1, T2), T?, [T], Set&amp;lt;T&amp;gt;, [K:V], T-&amp;gt;U, struct, class &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;Haskell &lt;/td&gt;&lt;td&gt;Bool, Int, Integer, Float, Double, Char &lt;/td&gt;&lt;td&gt;[a], (a,b), a-&amp;gt;b, data &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt; &lt;p&gt;So it looks like one of the most common ways to introduce a new type is to use that &lt;code&gt;class&lt;/code&gt; notion we saw above. As in Python, for example: &lt;/p&gt;&lt;pre&gt;&amp;gt;&amp;gt;&amp;gt; &lt;kbd&gt;class C: pass&lt;/kbd&gt; ... &amp;gt;&amp;gt;&amp;gt; &lt;kbd&gt;class D: pass&lt;/kbd&gt; ... &amp;gt;&amp;gt;&amp;gt; &lt;kbd&gt;c, d = C(), D()&lt;/kbd&gt; &amp;gt;&amp;gt;&amp;gt; &lt;kbd&gt;type(c), type(d), type(c) == type(d)&lt;/kbd&gt; (&amp;lt;class '__main__.C'&amp;gt;, &amp;lt;class '__main__.D'&amp;gt;, False) &lt;img src="https://cs.lmu.edu/~ray/images/python-logo32.png"&gt;&lt;/pre&gt; &lt;p&gt;But something cooler and more computer sciencey are the &lt;dfn&gt;type operators&lt;/dfn&gt; of the ML-family of languages, like &lt;code&gt;list&lt;/code&gt; (for lists), &lt;code&gt;*&lt;/code&gt; (for tuples), and &lt;code&gt;-&amp;gt;&lt;/code&gt; (for functions): &lt;/p&gt;&lt;pre&gt;7 (* int *) (4, "dog") (* int * string *) [5, 3, 2, 7] (* int list *) [ [], [3,3,3], [], [1] ] (* int list list *) [(3, 4.0),(1, 5.5)] (* (int * real) list *) (5, [2.2, 1.0E~4]) (* int * real list *) fn x =&amp;gt; x + 8 (* int -&amp;gt; int *) fn x =&amp;gt; fn y =&amp;gt; x ^ Int.toString(y) (* string -&amp;gt; int -&amp;gt; string *) &lt;img src="https://cs.lmu.edu/~ray/images/sml-logo32.png"&gt;&lt;/pre&gt; &lt;p&gt;Mmmm, so here’s something interesting. SML has type called &lt;code&gt;int list&lt;/code&gt;. Does Python? No, in Python, the type is just called &lt;code&gt;list&lt;/code&gt;. So &lt;code&gt;[1, "hello"]&lt;/code&gt; is legal in Python but illegal in SML. SML has &lt;dfn&gt;parameterized types&lt;/dfn&gt;. &lt;/p&gt;&lt;h2&gt;Parameterized Types&lt;/h2&gt; &lt;p&gt;In Standard ML, the types &lt;code&gt;int list&lt;/code&gt; and &lt;code&gt;string list&lt;/code&gt; and &lt;code&gt;((int * string) -&amp;gt; bool) list&lt;/code&gt; are all different, but they are all instances of the parameterized type &lt;code&gt;'a&amp;nbsp;list&lt;/code&gt;. Lots of languages are like this. Here are some simple examples: &lt;/p&gt;&lt;table&gt; &lt;tbody&gt;&lt;tr&gt;&lt;th&gt;Language&lt;/th&gt;&lt;th&gt;Example Parameterized Type&lt;/th&gt;&lt;th&gt;Example Instantiated Type&lt;/th&gt;&lt;th&gt;Notes &lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan="3"&gt;Standard&amp;nbsp;ML&lt;/td&gt;&lt;td&gt;&lt;code&gt;'a list&lt;/code&gt;&lt;/td&gt;&lt;td&gt;&lt;code&gt;string list&lt;/code&gt;&lt;/td&gt;&lt;td rowspan="3"&gt;Type variables are &lt;code&gt;'a&lt;/code&gt;, &lt;code&gt;'b&lt;/code&gt;, &lt;code&gt;'c&lt;/code&gt; and so on. If the instantiating type must admit equality, then we write &lt;code&gt;''a&lt;/code&gt;, &lt;code&gt;''b&lt;/code&gt;, &lt;code&gt;''c&lt;/code&gt;, and so on. &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;'a * 'b&lt;/code&gt;&lt;/td&gt;&lt;td&gt;&lt;code&gt;string * bool&lt;/code&gt; &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;nobr&gt;&lt;code&gt;'a -&amp;gt; 'b -&amp;gt; 'a&lt;/code&gt;&lt;/nobr&gt;&lt;/td&gt;&lt;td&gt;&lt;nobr&gt;&lt;code&gt;int-&amp;gt;(bool*int)-&amp;gt;int&lt;/code&gt;&lt;/nobr&gt; &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Haskell&lt;/td&gt;&lt;td&gt;&lt;code&gt;[a]&lt;/code&gt;&lt;br&gt;&lt;code&gt;a-&amp;gt;b&lt;/code&gt;&lt;/td&gt;&lt;td&gt;&lt;code&gt;List Int&lt;/code&gt;&lt;br&gt;&lt;code&gt;Int-&amp;gt;String&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Types begin with a capital letter and type variables with a lowercase letter. &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Java&lt;/td&gt;&lt;td&gt;&lt;code&gt;List&amp;lt;T&amp;gt;&lt;/code&gt;&lt;/td&gt;&lt;td&gt;&lt;code&gt;List&amp;lt;String&amp;gt;&lt;/code&gt;&lt;/td&gt;&lt;td&gt; &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Swift&lt;/td&gt;&lt;td&gt;&lt;code&gt;Set&amp;lt;T&amp;gt;&lt;/code&gt;&lt;/td&gt;&lt;td&gt;&lt;code&gt;Set&amp;lt;String&amp;gt;&lt;/code&gt;&lt;/td&gt;&lt;td&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt; &lt;p&gt;By the way, &lt;strong&gt;type parameters do not have to be just a simple type variable&lt;/strong&gt;.&lt;/p&gt; &lt;h2&gt;Type Equivalence&lt;/h2&gt; &lt;p&gt;When are two types the same? &lt;/p&gt;&lt;pre&gt;typedef struct { int a; int b; } Point; typedef struct { int a; int b; } Pair; Point x; Pair y; &lt;img src="https://cs.lmu.edu/~ray/images/c-logo32.png"&gt;&lt;/pre&gt; &lt;p&gt;Do &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; have the same type? Should we say “yes” (because they have the same structure), or “no” (because their types have different names, and furthermore appear in different declarations)? These two approaches to determining whether types are the same are &lt;b&gt;structural&lt;/b&gt; and &lt;b&gt;named&lt;/b&gt; equivalence: &lt;/p&gt;&lt;table&gt; &lt;tbody&gt;&lt;tr&gt; &lt;th&gt;Structural Equivalence &lt;/th&gt;&lt;th&gt;Name Equivalence &lt;/th&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td rowspan="2"&gt;Check equivalence by expanding structures all the way down to basic types &lt;/td&gt;&lt;td&gt;&lt;strong&gt;Strict&lt;/strong&gt;: Every type declaration defines a new type &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;&lt;strong&gt;Loose&lt;/strong&gt;: Factor out aliases &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt; &lt;p&gt;Here is an example from Michael L. Scott: &lt;/p&gt;&lt;pre&gt;type alink = pointer to cell; subtype blink = alink; p, q : pointer to cell; r : alink; s : blink; t : pointer to cell; u : alink; -- If structural: [p q r s t u] -- If strict name: [p q] [r u] [s] [t] -- If loose name: [p q] [r s u] [t] &lt;/pre&gt; &lt;p&gt;Loose name equivalence is pretty common: we like to distinguish things like &lt;code&gt;Point&lt;/code&gt; and &lt;code&gt;Pair&lt;/code&gt; above but want the flexibility of aliasing. In Ada we can do both explicitly: &lt;/p&gt;&lt;pre&gt;type Height is new Integer; type Weight is new Integer; -- Can’t add heights and weights subtype Height is Integer; subtype Weight is Integer; -- Now you can freely mix them &lt;img src="https://cs.lmu.edu/~ray/images/ada-logo32.png"&gt;&lt;/pre&gt; &lt;p&gt;ML seems to use structural equivalence: &lt;/p&gt;&lt;pre&gt;type pair = int * int; type point = int * int; val x: point = (1, 4); val y: pair = x; type person = {name: string, age: int}; type school = {name: string, age: int}; val p: person = {name="Alice", age=22}; val s: school = p; &lt;img src="https://cs.lmu.edu/~ray/images/sml-logo32.png"&gt;&lt;/pre&gt; &lt;p&gt;But that’s because &lt;code&gt;type&lt;/code&gt; does not define a new type! Only a datatype or abstype declaration creates a new type. &lt;/p&gt;&lt;pre&gt;abstype person = P of string * int with fun new_person (s, i) = P(s, i) fun name (P(s, i)) = s fun age (P(s, i)) = i end; &lt;img src="https://cs.lmu.edu/~ray/images/sml-logo32.png"&gt;&lt;/pre&gt; &lt;h2&gt;Type Compatibility&lt;/h2&gt; &lt;p&gt;&lt;em&gt;When can a value of type A be used in a context that expects type B?&lt;/em&gt; &lt;/p&gt;&lt;p&gt;Possible answers: &lt;/p&gt;&lt;ul&gt; &lt;li&gt;When A and B are equivalent (the same type) &lt;/li&gt;&lt;li&gt;When A is a subtype of B &lt;/li&gt;&lt;li&gt;When an A can be &lt;em&gt;coerced&lt;/em&gt; to a B &lt;/li&gt;&lt;/ul&gt; &lt;p&gt;So.... In: &lt;/p&gt;&lt;pre&gt;int a; float b; float c; c = a + b; &lt;/pre&gt; &lt;p&gt;Is this &lt;/p&gt;&lt;ul&gt; &lt;li&gt;An error, fixable by writing &lt;code&gt;c = int_to_float(a) + b&lt;/code&gt;? &lt;/li&gt;&lt;li&gt;Allowable? &lt;/li&gt;&lt;/ul&gt; &lt;p&gt;A language that allows this is said to &lt;b&gt;coerce&lt;/b&gt; ints to floats, and we say "int is compatible with float". &lt;/p&gt;&lt;ul&gt; &lt;li&gt;Ada, Modula, ML: no coercion &lt;/li&gt;&lt;li&gt;Fortran: lots of coercion &lt;/li&gt;&lt;li&gt;C: lots of coercion in numeric types &lt;/li&gt;&lt;li&gt;C++: user can define coercions, even accidentally! &lt;/li&gt;&lt;/ul&gt; &lt;p&gt;Important definitions: &lt;/p&gt;&lt;dl&gt; &lt;dt&gt;Type Conversion &lt;/dt&gt;&lt;dd&gt;Explicit operation that takes in an object of one type and returns an object of a different type that has the "same value" (not necessarily the same bit pattern). &lt;/dd&gt;&lt;dt&gt;Type Coercion &lt;/dt&gt;&lt;dd&gt;Implicit &lt;/dd&gt;&lt;dt&gt;Non-converting Type Cast &lt;/dt&gt;&lt;dd&gt;"Reinterpret" an object as an object of another type by preserving its bit pattern, regardless of value. &lt;/dd&gt;&lt;/dl&gt; &lt;h2&gt;Type Inference&lt;/h2&gt; &lt;p&gt;&lt;em&gt;How do we determine the type of an expression?&lt;/em&gt; &lt;/p&gt;&lt;p&gt;ML seems to do it the most general way possible. It looks at all the types of the primitive expressions, then at the types of arguments that the subroutines and operators expect, and work your way out to the whole expression. &lt;/p&gt;&lt;pre&gt;1 fun fib (n) = 2 let fun fib_helper (f1, f2, i) = 3 if i = n then f2 4 else fib_helper (f2, f1+f2, i+1) 5 in 6 fib_helper (0, 1, 0) 7 end; &lt;/pre&gt; &lt;ul&gt; &lt;li&gt;i is int, because it is added to 1 at line 4 &lt;/li&gt;&lt;li&gt;n is int, because it is compared to i at line 3 &lt;/li&gt;&lt;li&gt;all three args at line 6 are int consts, and that’s the only use of fib_helper (given scope of let), so f1 and f2 are int &lt;/li&gt;&lt;li&gt;also 3rd arg is consistent with known int type of i (good!) &lt;/li&gt;&lt;li&gt;and the types of the arguments to the recursive call at line 4 are similarly consistent &lt;/li&gt;&lt;li&gt;since fib_helper returns f2 (known to be int) at line 3, the result of the call at line 6 will be int &lt;/li&gt;&lt;li&gt;Since fib immediately returns this result as its own result, the return type of fib is int &lt;/li&gt;&lt;/ul&gt; &lt;p&gt;If there’s not enough information to resolve to a known type, ML’s inferencer will bring in &lt;b&gt;type variables&lt;/b&gt;. Note how clever it is: &lt;/p&gt;&lt;pre&gt;fun I x = x; 'a -&amp;gt; 'a fun p x y = y 'a -&amp;gt; 'b -&amp;gt; 'b fun first (x, y) = x; 'a * 'b -&amp;gt; 'a fun q x = (hd o hd) x; 'a list list -&amp;gt; 'a fun c x y = if x = y then "y" else "n"; ''a -&amp;gt; ''a -&amp;gt; string &lt;/pre&gt; &lt;p&gt;In ML, a type variable beginning with two primes can only be instantiated with a type that admits equality. &lt;/p&gt;&lt;p&gt;ML’s inferencing is more powerful than that of other languages, Go, Rust, and Scala require that you put types on parameters. &lt;/p&gt;&lt;pre&gt;scala&amp;gt; &lt;kbd&gt;var x = 3;&lt;/kbd&gt; x: Int = 3 scala&amp;gt; &lt;kbd&gt;var y = x + 3;&lt;/kbd&gt; y: Int = 6 scala&amp;gt; &lt;kbd&gt;def f(x) = x + 3;&lt;/kbd&gt; &lt;span&gt;&amp;lt;console&amp;gt;:1: error: ':' expected but ')' found. def f(x) = x + 3; ^&lt;/span&gt; scala&amp;gt; &lt;kbd&gt;def f(x:Int) = x + 3;&lt;/kbd&gt; f: (x: Int)Int &lt;/pre&gt; &lt;p&gt;&lt;a href="http://play.golang.org/p/IVfzp9-OWZ"&gt;Go example&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;&lt;a href="http://is.gd/MkoeCA"&gt;Rust example&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;&lt;b&gt;Exercise&lt;/b&gt;: Two things complicate type inference are overloading and coercion. Give concrete examples of complications that arise for each. &lt;/p&gt; &lt;h2&gt;Type Checking&lt;/h2&gt; &lt;p&gt;&lt;em&gt;What if you use an expression in a manner inconsistent with its type, like trying to compute the age of a string (instead of a person). Should the evaluation result in an error, or return a "best guess"?&lt;/em&gt; &lt;/p&gt;&lt;h3&gt;Strong Typing vs. Weak Typing&lt;/h3&gt; &lt;table&gt; &lt;tbody&gt;&lt;tr&gt;&lt;th&gt;Strong Typing&lt;/th&gt;&lt;th&gt;Weak Typing &lt;/th&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;Type clashes among unrelated types result in errors. they may be compile time, or even run time (e.g. NoSuchMethodError, or ClassCastException) but they are errors. &lt;/td&gt;&lt;td&gt;Type clashes don’t really exist... the language implementation will try to cast the argument into some reasonable (!) type and carry out the operation. &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;Alternate definition: you can’t really circumvent the type system. Example: In Java, even if you explicitly add a cast to cast a string to an int, you get an error. &lt;/td&gt;&lt;td&gt;Alternate definition: you can easily circumvent the type system. Example: In C++, you can cast a pointer to an int to a void*, then to a string*, and you get away with it. &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt; &lt;p&gt;Some people would argue strong vs. weak typing isn’t a terribly useful thing to worry about. the static/dynamic dimension is a bigger deal. &lt;/p&gt;&lt;h3&gt;Static Typing vs. Dynamic Typing&lt;/h3&gt; &lt;table&gt; &lt;tbody&gt;&lt;tr&gt;&lt;th&gt;Static Typing&lt;/th&gt;&lt;th&gt;Dynamic Typing &lt;/th&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;Type checking done at compile time &lt;p&gt;Once a variable’s type is known, it can only be assigned expressions of that type (including related types that can be coerced to it, of course). &lt;/p&gt;&lt;/td&gt;&lt;td&gt;Type checking done at run time &lt;p&gt;Because checking is deferred until run-time a variable can be assigned an expression of one type and then later an expression of another type. &lt;/p&gt;&lt;pre&gt;var x; x = 2; print x + 5; x = "dog"; print concat(x, "house"); &lt;/pre&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt; &lt;p&gt;It is common for languages to have some static typing and some dynamic typing. &lt;/p&gt;&lt;h3&gt;Manifest Typing vs. Implicit Typing&lt;/h3&gt; &lt;table&gt; &lt;tbody&gt;&lt;tr&gt;&lt;th&gt;Manifest Typing&lt;/th&gt;&lt;th&gt;Implicit Typing &lt;/th&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;Types of variables must be given in their declarations. &lt;pre&gt;void f(int x, list&amp;lt;int&amp;gt; z) { int y = x * x; z.push_back(y); } &lt;/pre&gt; &lt;/td&gt;&lt;td&gt;the types of variables will be inferred from context &lt;pre&gt;fun f x z = let y = x * x in z @ [y] end &lt;/pre&gt; x must be an int because of the "*" operator, so y must be an int as well, and then z must be an int list, and finally f must be int -&amp;gt; int list -&amp;gt; int list. &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt; &lt;h3&gt;What about some popular languages?&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Common Lisp: strong, dynamic, implicit &lt;/li&gt;&lt;li&gt;Ada: strong, static, manifest &lt;/li&gt;&lt;li&gt;Pascal: strong, almost static, manifest &lt;/li&gt;&lt;li&gt;Java: strong, some static and some dynamic, manifest &lt;/li&gt;&lt;li&gt;ML: strong, static, implicit &lt;/li&gt;&lt;li&gt;JavaScript and Perl: weak, dynamic &lt;/li&gt;&lt;li&gt;Ruby and Python: strong, dynamic &lt;/li&gt;&lt;/ul&gt; &lt;p&gt;&lt;b&gt;Exercise&lt;/b&gt;: Classify Classic Lisp, Smalltalk, Go, and Rust &lt;/p&gt; &lt;h3&gt;Declarations and Static Typing&lt;/h3&gt; &lt;p&gt;In order to do static typing, you must sometimes specify types when declaring variables, functions, parameters, etc. How is this done? &lt;/p&gt;&lt;ul&gt; &lt;li&gt;&lt;a href="http://blog.golang.org/gos-declaration-syntax"&gt;A comparison of C and Go&lt;/a&gt; &lt;/li&gt;&lt;/ul&gt; &lt;p&gt;&lt;b&gt;Exercise&lt;/b&gt;: Rewrite the examples in the C and Go comparision article in Rust. &lt;/p&gt; &lt;h3&gt;Type Checking with Type Variables&lt;/h3&gt; &lt;p&gt;Suppose f has type &lt;code&gt;'a * int -&amp;gt; 'b * 'b -&amp;gt; string&lt;/code&gt;. then the following expressions are legal &lt;/p&gt;&lt;pre&gt; f(4, 5)("sd","de") f(1,1)(2,2) f([],5)([],[4,4]) &lt;/pre&gt; &lt;p&gt;but these are not &lt;/p&gt;&lt;pre&gt; f(3,2)(4,"p") f((3,2),5)([5.5,2.2],[1,6]) &lt;/pre&gt; &lt;h3&gt;Further Reading&lt;/h3&gt; &lt;p&gt;the literature on strong/weak, static/dynamic, and manifest/implicit typing is enormous, as are the debates and flame wars. Some good reading: &lt;/p&gt;&lt;ul&gt; &lt;li&gt;&lt;a href="http://perl.plover.com/yak/typing/"&gt;Mark Jason Dominus on Strong Typing in Perl (awesome presentation)&lt;/a&gt; &lt;/li&gt;&lt;li&gt;Wikipedia articles on &lt;a href="http://en.wikipedia.org/wiki/Datatype"&gt;data types&lt;/a&gt; and &lt;a href="http://en.wikipedia.org/wiki/Type_system"&gt;type systems&lt;/a&gt; &lt;/li&gt;&lt;/ul&gt; &lt;h2&gt;Dependent Types&lt;/h2&gt;&lt;p&gt; A &lt;dfn&gt;dependent type&lt;/dfn&gt; is a type whose definition depends on a value. Examples: &lt;/p&gt;&lt;ul&gt; &lt;li&gt;Arrays of length n&lt;/li&gt; &lt;li&gt;Integers less than 8&lt;/li&gt; &lt;li&gt;Pairs of integers that sum to 21&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Does C++ have dependent types? I mean, you can do:&lt;/p&gt; &lt;pre&gt;template &amp;lt;int n&amp;gt; class BoundedList { public: int contents[n]; } &lt;img src="https://cs.lmu.edu/~ray/images/cpp-logo32.png"&gt;&lt;/pre&gt; &lt;p&gt;but all types that instantiate this template are created at compile time.&lt;/p&gt; &lt;p&gt;Languages that fully support dynamic dependent types can eliminate many logic errors at compile time! (The type system essentially lets you formulate compile-time proofs that a program will have a certain run time behavior, in terms of the values it will produce.)&lt;/p&gt; &lt;p&gt;Start your study of dependent types at &lt;a href="https://stackoverflow.com/q/9338709/831878"&gt;this Stack Overflow question&lt;/a&gt; then go to &lt;a href="https://en.wikipedia.org/wiki/Dependent_type"&gt;Wikipedia&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Overview of Common Types&lt;/h2&gt; &lt;h3&gt;Numeric Types&lt;/h3&gt; &lt;p&gt;Lots of variety here:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Integer or Floating point or fixed point or ratios &lt;/li&gt;&lt;li&gt;Integer: Signed or unsigned &lt;/li&gt;&lt;li&gt;Integer: Saturated or unsaturated &lt;/li&gt;&lt;li&gt;Integer: Fixed size (8, 16, 32, 64, 128) or unbounded ("BigInt") &lt;/li&gt;&lt;li&gt;Ratios are also called Rationals&lt;/li&gt; &lt;li&gt;Some languages have a particular kind of ratio type called &lt;code&gt;Decimal&lt;/code&gt;&lt;/li&gt; &lt;li&gt;Floats: by size (32, 64, 80, 128) &lt;/li&gt;&lt;/ul&gt; &lt;h3&gt;Enumerations&lt;/h3&gt; &lt;p&gt;In type theory, an enumeration is a type with a fixed number of distinct values, ordered from smallest to largest. Typical examples are:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;type TrafficLight is (RED, AMBER, GREEN)&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;type Direction is (NORTH, EAST, SOUTH, WEST)&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The Boolean type is an enum of the values False and True.&lt;/p&gt; &lt;p&gt;Many languages have a character type which is essentially an enumeration. Each character’s "value" is its code point.&lt;/p&gt; &lt;h3&gt;Ranges&lt;/h3&gt; &lt;p&gt;Some languages allow you to make types such as:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;range(1, 100) &lt;/li&gt;&lt;li&gt;range(3, 900, 5)&lt;/li&gt; &lt;li&gt;1..100 &lt;/li&gt;&lt;li&gt;1...100&lt;/li&gt; &lt;li&gt;1..&amp;lt;100 &lt;/li&gt;&lt;/ul&gt; &lt;h3&gt;Sum Types and Product Types&lt;/h3&gt; &lt;p&gt;Suppose we have two types, Boolean and Byte, where: &lt;/p&gt;&lt;ul&gt; &lt;li&gt;Boolean has the values {false, true}&lt;/li&gt; &lt;li&gt;Byte has the values {-128, -127, ... 126, 127}&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Now we form new types:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Boolean + Byte = {false, true, -128, -127, -126, ..., 126, 127}&lt;/li&gt; &lt;li&gt;Boolean × Byte = {(false, -128), (false, -127), ... (false, 127), (true, -128), (true, -127), ..., true(true, 127}&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Note Boolean has 2 values, Byte has 256 values. Boolean + Byte has 2+256 = 258 values, and Boolean × Byte has 2 * 256 = 512 values. Boolean + Byte is a &lt;dfn&gt;sum type&lt;/dfn&gt; and Boolean × Byte is a &lt;dfn&gt;product type&lt;/dfn&gt;.&lt;/p&gt; &lt;p&gt;Product types are very common; Python calls them &lt;dfn&gt;tuples&lt;/dfn&gt;. Haskell and ML just let you write the product type name directly, e.g. &lt;code&gt;Int * String&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Often sums and products can be &lt;dfn&gt;tagged&lt;/dfn&gt;.&lt;/p&gt; &lt;h3&gt;Option Types&lt;/h3&gt; &lt;p&gt;Option types are one solution to the billion dollar mistake. Basically an object of type &lt;code&gt;T?&lt;/code&gt; is pretty much the sum type of &lt;code&gt;T&lt;/code&gt; and the type containing a single value representing null.&lt;/p&gt; &lt;h3&gt;Records, a.k.a. Structs&lt;/h3&gt; &lt;p&gt;Tagged product types go by many names: record, struct, object, hash, etc. Values of such types are thought of as key-value pairs.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Named fields, order may or may not matter &lt;/li&gt;&lt;li&gt;Memory layout often contiguous, but may have holes for alignment reasons, with some languages giving you explicit control over this (Ada has pragmas for it) &lt;/li&gt;&lt;li&gt;Compilers may rearrange fields &lt;/li&gt;&lt;li&gt;Usually you can copy but not compare &lt;/li&gt;&lt;li&gt;Copy can be bitwise, shallow, or deep &lt;/li&gt;&lt;/ul&gt; &lt;h3&gt;Unions&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Cheap way to make a type whose instances can have different forms &lt;/li&gt;&lt;li&gt;Also known as variant records &lt;/li&gt;&lt;li&gt;Generally implemented with overlaying (Fortran uses &lt;code&gt;EQUIVALENCE&lt;/code&gt;) &lt;/li&gt;&lt;li&gt;Not needed in languages with subclassing (or with a flexible datatype declaration like ML’s) &lt;/li&gt;&lt;li&gt;Language design choice: is the variant part "tagged"? &lt;/li&gt;&lt;li&gt;If not (C is a good example of this), the whole idea of strong typing goes out the window &lt;/li&gt;&lt;li&gt;If it is tagged, several design choices... &lt;ul&gt; &lt;li&gt;the tag could be permanent once set &lt;/li&gt;&lt;li&gt;Changing the tag could invalidate the object &lt;/li&gt;&lt;li&gt;We could prohibit changing just the tag and require a full reassignment (Ada, Algol68) &lt;/li&gt;&lt;/ul&gt; &lt;/li&gt;&lt;/ul&gt; &lt;pre&gt; datatype primary_color = Red | Blue | Green Red primary_color (Red, 4) primary_color * int &lt;/pre&gt; &lt;h3&gt;Arrays&lt;/h3&gt; &lt;p&gt;Usually by &lt;em&gt;array&lt;/em&gt; we mean a collection of elements indexed by integers or some other enumerated type, that has constant time access of any element given its index. Contrast this with a &lt;em&gt;list&lt;/em&gt;, which needn’t have constant time access, and with a &lt;em&gt;map&lt;/em&gt; (a.k.a dictionary or associative array), which can be indexed by anything, not just integers or related enumerated types. &lt;/p&gt;&lt;h4&gt;Array Bounds&lt;/h4&gt; &lt;ul&gt; &lt;li&gt;Normally, array "types" are unbounded, but array instances have bounds. &lt;/li&gt;&lt;li&gt;Is accessing an array outside of its bounds an error? Or does the array object expand to accommodate? &lt;/li&gt;&lt;li&gt;C doesn’t really have arrays! C "arrays" are just pointers and don’t know about bounds or not. Use at your own risk, and be careful! &lt;/li&gt;&lt;li&gt;If the bounds are not known at compile time, we generally make use of a dope vector. (Note that with dope vectors, like any other indirect storage mechanism, watch out for shallow vs. deep copy and equality testing.) &lt;/li&gt;&lt;li&gt;If the bounds are known at compile time, compilers can generate code for element access that uses simple algebraic transforms to compute as much up-front (at compile time) as possible &lt;/li&gt;&lt;/ul&gt; &lt;h4&gt;Lifetime and Shape&lt;/h4&gt; &lt;table&gt; &lt;tbody&gt;&lt;tr&gt; &lt;th&gt;&amp;nbsp;&lt;/th&gt; &lt;th&gt;Static Bounds&lt;/th&gt; &lt;th&gt;Bounds Set at Elaboration&lt;/th&gt; &lt;th&gt;Bounds Can be Changed&lt;br&gt;(Dynamic Shape)&lt;/th&gt; &lt;/tr&gt;&lt;tr&gt; &lt;th&gt;Global&lt;br&gt;Lifetime&lt;/th&gt; &lt;td&gt;C globals &lt;/td&gt;&lt;td&gt; &lt;/td&gt;&lt;td&gt; &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;th&gt;Local&lt;br&gt;Lifetime&lt;/th&gt; &lt;td&gt;C locals &lt;/td&gt;&lt;td&gt;Ada locals &lt;/td&gt;&lt;td&gt; &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;th&gt;Arbitrary&lt;br&gt;Lifetime&lt;/th&gt; &lt;td&gt; &lt;/td&gt;&lt;td&gt;Java &lt;/td&gt;&lt;td&gt;Perl, APL &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt; &lt;ul&gt; &lt;li&gt;Local lifetime / Bounds set at elaboration category is interesting: one can use the &lt;code&gt;alloca&lt;/code&gt; syscall to implement these, giving you automatic dealloaction on block exit. &lt;/li&gt;&lt;/ul&gt; &lt;h4&gt;Implementation&lt;/h4&gt; &lt;ul&gt; &lt;li&gt;Column Major &lt;/li&gt;&lt;li&gt;Row Major (allows 2-D arrays to be the same as arrays of arrays) &lt;/li&gt;&lt;li&gt;Row Pointers — necessary for ragged arrays, good on machines with small segments. &lt;/li&gt;&lt;/ul&gt; &lt;h4&gt;Slices&lt;/h4&gt; &lt;p&gt;Several languages (Perl, APL, Fortran 90) have nice syntax for slices. Fortran 90 allows (these examples are from Scott): &lt;/p&gt;&lt;pre&gt;matrix(3:6, 4:7) columns 3-6, rows 4-7 matrix(6:, 5) columns 6-end, row 5 matrix(:4, 2:8:2) columns 1-4, every other row from 2-8 matrix(:, /2, 5, 9/) all columns, rows 2, 5, and 9 &lt;/pre&gt; &lt;p&gt;&lt;b&gt;Exercise&lt;/b&gt;: Give the equivalent expressions in Julia. &lt;/p&gt; &lt;p&gt;&lt;b&gt;Exercise&lt;/b&gt;: How are these represented in Python’s numpy library? &lt;/p&gt; &lt;p&gt;Good to know: Go uses the term “slice“ to mean something else.&lt;/p&gt; &lt;h3&gt;Strings&lt;/h3&gt; &lt;p&gt;Most (all?) languages have them, but care is needed:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Are often built-in&lt;/li&gt; &lt;li&gt;Usually have easy to use literal forms, with escape characters&lt;/li&gt; &lt;li&gt;May be immutable&lt;/li&gt; &lt;li&gt;May be interchangeable with character arrays&lt;/li&gt; &lt;li&gt;If mutable, are usually resizable (except in old Pascal&lt;/li&gt; &lt;li&gt;May or may not allow newlines or control characters&lt;/li&gt; &lt;li&gt;Interpolation may or may not be supported&lt;/li&gt; &lt;li&gt;Length is ill-defined! (Number of bytes? number of characters? number of code points? number of graphemes?&lt;/li&gt; &lt;li&gt;Indexing may also be difficult&lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;Sets&lt;/h3&gt; &lt;p&gt;Mathematically, a &lt;dfn&gt;set&lt;/dfn&gt; is an unordered collection of unique elements.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Usually aren’t built-in but most libraries have them&lt;/li&gt; &lt;li&gt;May be mutable or immutable (Python has &lt;code&gt;set&lt;/code&gt; and &lt;code&gt;frozenset&lt;/code&gt;&lt;/li&gt; &lt;li&gt;Implemented with search trees, tries, hashtables or bitsets&lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;Pointers&lt;/h3&gt; &lt;p&gt;A pointer is, more or less, an object through which you reference some other object. They appear in system languages and low level languages. &lt;/p&gt;&lt;pre&gt;int x = 5; int* p = &amp;amp;x; int* q = NULL; int* r = new int; int* s = new int[100]; cout &amp;lt;&amp;lt; *p &amp;lt;&amp;lt; *r &amp;lt;&amp;lt; s[20]; cout &amp;lt;&amp;lt; *q; // crash &lt;/pre&gt; &lt;h4&gt;Basics&lt;/h4&gt; &lt;ul&gt; &lt;li&gt;Pointers are used for dynamic, linked data structures. &lt;/li&gt;&lt;li&gt;Pointers are at a higher level of abstraction than addresses since address computation and error checks can be done on the fly, and in some languages you can overload the dereference operators. &lt;/li&gt;&lt;li&gt;In some languages, pointers can refer &lt;em&gt;only&lt;/em&gt; to heap-allocated objects. &lt;/li&gt;&lt;li&gt;In many languages (Java, LISP, ML) pointers are implicit. Example from Lisp: &lt;pre&gt;(R (X () ()) (Y (Z ()()) (W ()()))) &lt;/pre&gt; And from ML: &lt;pre&gt;datatype tree = empty | node of 'a * 'a tree * 'a tree; val x_zw = node ('R', node ('X', empty, empty), node ('Y', node ('Z', empty, empty), node ('W', empty, empty))); &lt;/pre&gt; &lt;/li&gt;&lt;/ul&gt; &lt;h4&gt;Reference and Dereference Syntax&lt;/h4&gt; &lt;p&gt;Can be always explicit, always implicit, or sometimes-implicit (like in Ada). &lt;/p&gt;&lt;p&gt;&lt;img alt="pointer.png" src="https://cs.lmu.edu/~ray/images/pointer.png"&gt;&lt;/p&gt; &lt;p&gt;If the pointer is called p (or $p in Perl), then &lt;/p&gt;&lt;table&gt; &lt;tbody&gt;&lt;tr&gt;&lt;th&gt;In&lt;/th&gt;&lt;th&gt;the referent is called&lt;/th&gt;&lt;th&gt;and the field is called&lt;/th&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;C&lt;/td&gt;&lt;td&gt;&lt;code&gt;*p&lt;/code&gt;&lt;/td&gt;&lt;td&gt;&lt;code&gt;(*p).x&lt;/code&gt; or &lt;code&gt;p-&amp;gt;x&lt;/code&gt; &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Ada&lt;/td&gt;&lt;td&gt;&lt;code&gt;p.all&lt;/code&gt;&lt;/td&gt;&lt;td&gt;&lt;code&gt;p.all.x&lt;/code&gt; or &lt;code&gt;p.x&lt;/code&gt; &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Modula-2&lt;/td&gt;&lt;td&gt;&lt;code&gt;p^&lt;/code&gt;&lt;/td&gt;&lt;td&gt;&lt;code&gt;p^.x&lt;/code&gt; &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Java&lt;/td&gt;&lt;td&gt;&lt;code&gt;p&lt;/code&gt;&lt;/td&gt;&lt;td&gt;&lt;code&gt;p.x&lt;/code&gt; &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Perl&lt;/td&gt;&lt;td&gt;&lt;code&gt;%$p&lt;/code&gt;&lt;/td&gt;&lt;td&gt;&lt;code&gt;$$p{x} or $p-&amp;gt;{x}&lt;/code&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt; &lt;p&gt;If the referent is called p (or %p in Perl), then &lt;/p&gt;&lt;table&gt; &lt;tbody&gt;&lt;tr&gt;&lt;th&gt;In&lt;/th&gt;&lt;th&gt;the pointer is called&lt;/th&gt;&lt;th&gt;and the field is called&lt;/th&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;C&lt;/td&gt;&lt;td&gt;&lt;code&gt;&amp;amp;p&lt;/code&gt;&lt;/td&gt;&lt;td&gt;&lt;code&gt;p.x&lt;/code&gt; &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Ada&lt;/td&gt;&lt;td&gt;&lt;code&gt;p'access&lt;/code&gt;&lt;/td&gt;&lt;td&gt;&lt;code&gt;p.x&lt;/code&gt; &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Perl&lt;/td&gt;&lt;td&gt;&lt;code&gt;\%p&lt;/code&gt;&lt;/td&gt;&lt;td&gt;&lt;code&gt;$p{x}&lt;/code&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt; &lt;h4&gt;Memory Leaks and Dangling Pointers&lt;/h4&gt; &lt;p&gt;In languages like C requiring explicit allocation and explicit deallocation, it is possible to: &lt;/p&gt;&lt;ul&gt; &lt;li&gt;detach references to heap-allocated objects (&lt;b&gt;memory leak&lt;/b&gt;) &lt;/li&gt;&lt;li&gt;deallocate an objected through a shared pointer (&lt;b&gt;dangling pointer&lt;/b&gt;) &lt;/li&gt;&lt;/ul&gt; &lt;p&gt;How can we prevent such things? &lt;/p&gt;&lt;ul&gt; &lt;li&gt;Prohibit explicit deallocation and use a garbage collector (yeah but this is a cop out sometimes) &lt;/li&gt;&lt;li&gt;Give programmers some nice tools and conventions, like C++ (this does NOT solve the problem) &lt;/li&gt;&lt;li&gt;Put in run-time checks to ensure pointers cannot outlive referenced objects (expensive?) &lt;/li&gt;&lt;li&gt;Put in compile-time checks to ensure pointers cannot outlive referenced objects (a la Rust) &lt;/li&gt;&lt;/ul&gt; &lt;h4&gt;Garbage Collection&lt;/h4&gt; &lt;p&gt;Covered separately. For now, you can read &lt;a href="http://en.wikipedia.org/wiki/Garbage_collection_%28computer_science%29"&gt;Wikipedia’s article on garbage collection&lt;/a&gt;, and an interesting developerworks article on &lt;a href="http://www-128.ibm.com/developerworks/java/library/j-jtp09275.html"&gt;Java performance and garbage collection&lt;/a&gt;. &lt;/p&gt;&lt;h4&gt;Pointers and Arrays in C&lt;/h4&gt; &lt;p&gt;Sometimes, these ideas get conflated in C. After all: &lt;/p&gt;&lt;blockquote&gt; &lt;code&gt;e1[e2]&lt;/code&gt; is the same as *(e1 + e2) &lt;/blockquote&gt; &lt;p&gt;For &lt;em&gt;definitions&lt;/em&gt; these are completely different things: &lt;/p&gt;&lt;pre&gt; int *x; /* is totally different from: */ int x[100]; int *a[n]; /* is totally different from: */ int a[n][100]; &lt;/pre&gt; &lt;p&gt;But for declarations, at least in parameter declarations, you can blur the distinction: &lt;/p&gt;&lt;pre&gt; void f(int* a) { ... } void g(int b[]) { ... } &lt;/pre&gt; &lt;p&gt;An array of ints, or pointer to an int, can be passed to either. &lt;/p&gt;&lt;h3&gt;Streams&lt;/h3&gt; &lt;p&gt;The term &lt;dfn&gt;stream&lt;/dfn&gt; is a bit overloaded. Abstractly, a stream: &lt;/p&gt;&lt;ul&gt; &lt;li&gt;is an object that can be read from and written to, usually sequentially, but sometimes with "random access" &lt;/li&gt;&lt;li&gt;is called, if read-only, called a "source"; if write-only, a "sink" &lt;/li&gt;&lt;li&gt;is an excellent abstraction; in practice streams are attached to memory buffers, network connections, database connections, files, pipes, whatever.... &lt;/li&gt;&lt;li&gt;can be made by pasting two streams together. &lt;/li&gt;&lt;/ul&gt; &lt;p&gt;Sometimes we use the term stream to refer to files.&lt;/p&gt; &lt;p&gt;In Java, streams are their own thing. They work like the streams described above (they are processed sequentially), but are in a pretty large subsystem of their own.&lt;/p&gt; &lt;h3&gt;Regular Expressions&lt;/h3&gt; &lt;p&gt;Covered separately. &lt;/p&gt;&lt;h3&gt;Subroutines&lt;/h3&gt; &lt;p&gt;Subroutines are often objects with their own types. We’ll see these later when we discuss subroutines. &lt;/p&gt;&lt;h3&gt;Processes and threads&lt;/h3&gt; &lt;p&gt;Will be covered later when we discuss concurrency. &lt;/p&gt;&lt;h2&gt;Orthogonality&lt;/h2&gt; &lt;p&gt;If a type system is &lt;dfn&gt;orthogonal&lt;/dfn&gt;, then no type is more special and capable than others. The questions you want to ask to see whether a system is orthogonal or not are: Can an object of &lt;em&gt;any&lt;/em&gt; type: &lt;/p&gt;&lt;ul&gt; &lt;li&gt;be represented as a literal? &lt;/li&gt;&lt;li&gt;be declared at all? &lt;/li&gt;&lt;li&gt;have an initializer? &lt;/li&gt;&lt;li&gt;be assigned to? &lt;/li&gt;&lt;li&gt;be passed as a parameter? &lt;/li&gt;&lt;li&gt;be returned from a function? &lt;/li&gt;&lt;/ul&gt; &lt;p&gt;You might be surprised at how un-orthogonal some language’s type systems are.&lt;/p&gt; &lt;p&gt;A related question is: Are types themselves objects?&lt;/p&gt; &lt;ul&gt; &lt;li&gt;they aren’t in JavaScript, C, C++, Erlang, or Elixir.&lt;/li&gt; &lt;li&gt;Python has a type called &lt;code&gt;type&lt;/code&gt;, so yes there.&lt;/li&gt; &lt;li&gt;Java, Ruby, and many other languages have a class called &lt;code&gt;Class&lt;/code&gt;, so yes there too.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;It’s sometimes undesirable, or maybe even impossible, to get true orthogonality, since: &lt;/p&gt;&lt;ul&gt; &lt;li&gt;Expression oriented languages need an empty type and other languages want to ignore them. &lt;/li&gt;&lt;li&gt;First class subroutines might be difficult to implement or too slow in languages that claim to be fast. &lt;/li&gt;&lt;li&gt;Some languages allow arrays of anything; others can store only scalars? &lt;/li&gt;&lt;li&gt;Array indexing really can only be done by discrete types. &lt;/li&gt;&lt;li&gt;Member, Local, and Anonymous classes in Java don’t act like top-level ones. &lt;/li&gt;&lt;li&gt;Should blocks of code be values? &lt;/li&gt;&lt;li&gt;Simple languages just take short cuts: did you know, in Pascal, you can’t return complex objects from functions?&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://cs.lmu.edu/~ray/notes/types/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Fri, 17 Jul 2020 22:20:24 UT
      </pubDate>
      <guid>
        https://cs.lmu.edu/~ray/notes/types/
      </guid>
    </item>
    <item>
      <title>
        Tutorial #2: few-shot learning and meta-learning I
      </title>
      <link>
        https://www.borealisai.com/en/blog/tutorial-2-few-shot-learning-and-meta-learning-i/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt; &lt;h2&gt;Introduction&lt;/h2&gt; &lt;p&gt;Humans can recognize new object classes from very few instances. However, most machine learning techniques require thousands of examples to achieve similar performance. The goal of &lt;em&gt;few-shot learning&lt;/em&gt;&amp;nbsp;is to classify new data having seen only a few training examples. In the extreme, there might only be a single example of each class (&lt;em&gt;one shot learning&lt;/em&gt;). In practice, few-shot learning is useful when training examples are hard to find (e.g., cases of a rare disease), or where the cost of labelling data is high.&lt;/p&gt; &lt;p&gt;Few-shot learning is usually studied using &lt;em&gt;N-way-K-shot classification&lt;/em&gt;. Here, we aim to discriminate between $N$ classes with $K$ examples of each. A typical problem size might be to discriminate between $N=10$ classes with only $K=5$ samples from each to train from. We cannot train a classifier using conventional methods here; any modern classification algorithm will depend on far more parameters than there are training examples, and will generalize poorly.&lt;/p&gt; &lt;p&gt;If the data is insufficient to constrain the problem, then one possible solution is to gain experience from other similar problems. To this end, most approaches characterize few-shot learning as a &lt;em&gt;meta-learning&lt;/em&gt;&amp;nbsp;problem.&lt;/p&gt; &lt;h2&gt;The meta learning framework&lt;/h2&gt; &lt;p&gt;In the classical learning framework, we learn a how to classify from training data and evaluate the results using test data. In the meta-learning framework, we &lt;em&gt;learn how to learn&lt;/em&gt;&amp;nbsp;to classify given a set of &lt;em&gt;training tasks&lt;/em&gt;&amp;nbsp;and evaluate using a set of t&lt;em&gt;est tasks&lt;/em&gt;&amp;nbsp;(figure 1); In other words, we use one set of classification problems to help solve other unrelated sets.&lt;/p&gt; &lt;p&gt; &lt;img src="https://www.borealisai.com/media/filer_public_thumbnails/filer_public/50/6a/506a0057-93f9-4d7a-9f91-14c4f0c8339f/t2_figure1.png__3000x1372_q85_subject_location-1500%2C686_subsampling-2.png"&gt; &lt;span&gt;Figure 1. Meta-learning framework. An algorithm is trained using a series of training tasks. Here, each task is a 3-way-2-shot classification problem because each training task contains a support set with three different classes and two examples of each. During training the cost function assesses performance on the query set for each task in turn given the respective support set. At test time, we use a completely different set of tasks, and evaluate performance on the query set, given the support set.&amp;nbsp;Note that there is no overlap between the classes in the two training tasks {cat, lamb, pig}, {dog, shark, lion} and between those in the test task {duck, dolphin, hen}, so the algorithm must learn to classify image classes in general rather than any particular set.&lt;/span&gt; &lt;/p&gt; &lt;p&gt;Here, each task mimics the few-shot scenario, so for N-way-K-shot classification, each task includes $N$ classes with $K$ examples of each. These are known as the&amp;nbsp;&lt;i&gt;support set&lt;/i&gt;&amp;nbsp;for the task and are used for learning how to solve this task. In addition, there are further examples of the same&amp;nbsp;classes, known as a&amp;nbsp;&lt;i&gt;query set&lt;/i&gt;, which are used to evaluating the performance on this task. Each task can be completely non-overlapping; we may never see the classes from one task in any of the others. The idea is that the system repeatedly sees instances (tasks) during training that match the structure of the final few-shot task, but contain different classes.&lt;/p&gt; &lt;p&gt;At each step of meta-learning, we update the model parameters based on a randomly selected training task. The loss function is determined by the classification performance on the query set of this training task, based on knowledge gained from its support set. Since the network is presented with a different task at each time step, it must learn how to discriminate data classes in general, rather than a particular subset of classes.&lt;/p&gt; &lt;p&gt;To evaluate few-shot performance, we use a set of test tasks. Each contains only unseen classes that were not in any of the training tasks. For each, we measure performance on the query set based on knowledge of their support set.&lt;/p&gt; &lt;h2&gt;&lt;small&gt;Approaches to meta-learning&lt;/small&gt;&lt;/h2&gt; &lt;p&gt;Approaches to meta-learning are diverse and there is no consensus on the best approach.&amp;nbsp;However, there are three distinct families, each of which exploits a different type of prior knowledge:&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Prior knowledge about similarity:&amp;nbsp;&lt;/strong&gt;We learn embeddings in training tasks that tend to separate different classes even when they are unseen.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Prior knowledge about learning:&lt;/strong&gt;&amp;nbsp;We use prior knowledge to constrain the learning algorithm to choose parameters that generalize well from few examples.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Prior knowledge of data:&lt;/strong&gt;&amp;nbsp;We exploit prior knowledge about the structure and variability of the data and this allows us to learn viable models from few examples.&lt;/p&gt; &lt;p&gt;An overview these methods can be seen in figure 2. In this review, we will consider each family of methods in turn.&amp;nbsp;&lt;/p&gt; &lt;p&gt; &lt;img src="https://www.borealisai.com/media/filer_public_thumbnails/filer_public/44/d3/44d348ed-41e4-45c3-8286-2d98b01eec9a/t2_figure2.png__3000x1625_q85_subject_location-1500%2C814_subsampling-2.png"&gt; &lt;span&gt;Figure 2. Few-shot learning methods can be divided into three families. The first family learns prior knowledge about the similarity and dissimilarity of classes (in the form of embeddings) from training tasks. The second family exploits prior knowledge about how to learn that it has garnered from training tasks. The third family exploits prior knowledge about the data and its likely variation that is has learned from training tasks.&lt;/span&gt; &lt;/p&gt; &lt;h2&gt;Prior knowledge of similarity&lt;/h2&gt; &lt;p&gt;This family of algorithms aims to learn compact representations (embeddings) in which the data vector is mostly unaffected by intra-class variations but retains information about class membership. Early work focused on pairwise comparators which aim to judge whether two data examples are from the same or different classes, even though the system may not have seen these classes before. Subsequent research focused on multi-class comparators which allow assignment of new examples to one of several classes.&lt;/p&gt; &lt;h2&gt;&lt;small&gt;Pairwise comparators&lt;/small&gt;&lt;/h2&gt; &lt;p&gt;Pairwise comparators take two examples and classify them as either belonging to the same or different classes. This differs from the standard N-way-K-shot configuration and does not obviously map onto the above description of meta-learning although as we will see later there is in fact a close relationship.&lt;/p&gt; &lt;h4&gt;&lt;strong&gt;Siamese networks&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;a href="https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf"&gt;Koch&amp;nbsp;&lt;em&gt;et al.&lt;/em&gt; (2015)&lt;/a&gt; trained a model that outputs the probability $Pr(y_a=y_{b})$ that two data examples $\mathbf{x}_{a}$ and $\mathbf{x}_{b}$ belong to the same class (figure 3a). The two examples are passed through identical multi-layer neural networks (hence Siamese) to create two embeddings. The component-wise absolute distance between the embeddings is computed and passed to a subsequent comparison network that reduces this distance vector to a single number. This is passed though a sigmoidal output for classification as being the same or different with a cross-entropy loss.&lt;/p&gt; &lt;p&gt; &lt;img src="https://www.borealisai.com/media/filer_public_thumbnails/filer_public/76/e2/76e24938-4b43-4cde-9b12-4be2d067561b/t2_figure3.png__3000x1185_q85_subject_location-1500%2C593_subsampling-2.png"&gt; &lt;span&gt;Figure 3. Pairwise comparators. a) Siamese networks take two examples $\mathbf{x}_{a}$ and $\mathbf{x}_{b}$ and return the probability $Pr(y_{a}=y_{b})$ that they are the same class. They do this by passing each example through an identical network (hence Siamese) and then using the pairwise difference between the embeddings as the basis of the decision.&amp;nbsp;b) Triplet networks take two examples of the same class $\mathbf{x}_{a}$ and $\mathbf{x}_{+}$ and one of a different class $\mathbf{x}_{-}$ and pass all three through identical networks to create three embeddings. The triplet loss encourages the embeddings of examples from the same class to be closer together than those from different classes. c) In the test phase for triplet networks, we pass two examples $\mathbf{x}_{a}$ and $\mathbf{x}_{b}$ through the same network and judge whether they come from the same class or not based on the distance.&lt;/span&gt; &lt;/p&gt; &lt;p&gt;During training, each pair of examples are randomly drawn from a super-set of training classes. Hence, the system learns to discriminate between classes is general, rather than two classes in particular. In testing, completely different classes are used. Although this does not have the formal structure of the N-way-K-shot task, the spirit is similar.&lt;/p&gt; &lt;h4&gt;Triplet networks&lt;/h4&gt; &lt;p&gt;Triplet networks (&lt;a href="https://arxiv.org/abs/1412.6622"&gt;Hoffer &amp;amp; Ailon 2015&lt;/a&gt;) consist of three identical networks that are trained by triplets $\{\mathbf{x}_{+},\mathbf{x}_{a},\mathbf{x}_{-}\}$ of the form (positive, anchor, negative). The positive and anchor samples are from the same class, whereas the negative sample is from a different class. The learning criterion is &lt;em&gt;triplet loss&lt;/em&gt;&amp;nbsp;which encourages the anchor to be closer to the positive example than it is to the negative example in the embedding space (figure 3b).&amp;nbsp;Hence it is based on two pairwise comparisons.&lt;/p&gt; &lt;p&gt;After training, the system can take two examples and establish whether they are from the same or different classes, by thresholding the distance in the learned embedding space.&amp;nbsp;This was employed in the context of face verification by &lt;a href="https://arxiv.org/abs/1503.03832"&gt;Schroff &lt;em&gt;et al.&lt;/em&gt; (2015)&lt;/a&gt;. This line of work is part of a greater literature on learning distance metrics (see &lt;a href="https://arxiv.org/abs/1812.05944"&gt;Suarez &lt;em&gt;et al.&lt;/em&gt;&amp;nbsp;2018&lt;/a&gt; for overview).&lt;/p&gt; &lt;h2&gt;&lt;small&gt;Multi-class comparators&lt;/small&gt;&lt;/h2&gt; &lt;p&gt;Pairwise comparators can be adapted to the N-way-K-shot setting by assigning the class for an example in the query set based on its maximum similarity to one of the examples in the support set.&amp;nbsp;However, multi-class comparators attempt to do the same thing in a more principled way; here the representation and final classification are learned in an end-to-end fashion.&lt;/p&gt; &lt;p&gt;In this section, we'll use the notation $\mathbf{x}_{nk}$ to denote the $k$th support example from the $n$th class in the N-Way-K-Shot classification task, and $y_{nk}$ to denote the corresponding label. For simplicity, we'll assume there is a single query example $\hat{\mathbf{x}}$ and the goal is to predict the associated label $\hat{y}$.&lt;/p&gt; &lt;h4&gt;Matching Networks&lt;/h4&gt; &lt;p&gt;Matching networks&amp;nbsp;(&lt;a href="https://arxiv.org/abs/1606.04080"&gt;Vinyals &lt;em&gt;et al.&lt;/em&gt;&amp;nbsp;2016&lt;/a&gt;) predict the one-hot encoded query-set label $\hat{\mathbf{y}}$ as a weighted sum of all of the one-hot encoded support-set labels $\{\mathbf{y}_{nk}\}_{n,k=1}^{NK}$. The weight is based on a computed similarity $a[\hat{\mathbf{x}},\mathbf{x}_{nk}]$ between the query-set data $\hat{\mathbf{x}}$ and each training example $\{\mathbf{x}_{nk}\}_{n,k=1}^{N,K}$.&lt;/p&gt; &lt;p&gt;\begin{equation}&lt;br&gt; &amp;nbsp; &amp;nbsp; \hat{\mathbf{y}} = \sum_{n=1}^{N}\sum_{k=1}^{K} a[\mathbf{x}_{nk},\hat{\mathbf{x}}]\mathbf{y}_{nk}&amp;nbsp;\tag{1.1}&lt;br&gt; \end{equation}&lt;/p&gt; &lt;p&gt;where the similarities have been constrained to be positive and sum to one.&amp;nbsp;&lt;/p&gt; &lt;p&gt;To compute the similarity $a[\hat{\mathbf{x}},\mathbf{x}_{nk}]$, they pass each support example $\mathbf{x}_{nk}$ through a network $\mbox{ f}[\bullet]$ to produce an embedding and pass the query example $\hat{\mathbf{x}}$ through a different network $\mbox{ g}[\bullet]$ to produce a different embedding. They then compute the cosine similarity between these embeddings (figure 5a)&lt;/p&gt; &lt;p&gt;\begin{equation}&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp;d[\mathbf{x}_{nk}, \hat{\mathbf{x}}] = \frac{\mbox{ f}[\mathbf{x}_{nk}]^{T}\mbox{ g}[\hat{\mathbf{x}}]} {||\mbox{ f}[\mathbf{x}_{nk}]||\cdot||\mbox{ g}[\hat{\mathbf{x}}]||},&amp;nbsp;\tag{1.2}&lt;br&gt; \end{equation}&lt;/p&gt; &lt;p&gt;and normalise using a softmax function:&lt;/p&gt; &lt;p&gt;\begin{equation}&lt;br&gt; &amp;nbsp; &amp;nbsp; a[\hat{\mathbf{x}}_{nk},\mathbf{x}] = \frac{\exp[d[\mathbf{x}_{nk},\hat{\mathbf{x}}]]}{\sum_{n=1}^{N}\sum_{k=1}^{K}\exp[d[\mathbf{x}_{nk},\hat{\mathbf{x}}]]}.&amp;nbsp;\tag{1.3}&lt;br&gt; \end{equation}&lt;/p&gt; &lt;p&gt;to produce positive similarities that sum to one. This system can be trained end to end for the N-way-K-shot learning task.&lt;sup&gt;1&amp;nbsp;&lt;/sup&gt;At each learning iteration, the system is presented with a training task; the predicted labels are computed for the query set (the calculation is based on the support set) and the loss function is the cross entropy of the ground truth and predicted labels.&lt;/p&gt; &lt;p&gt;Matching networks compute similarities between the embeddings of each support example and the query example. This has the disadvantage that the algorithm is not robust to data imbalance; if there are more support examples for some classes than others (i.e., we have departed from the N-way-K-shot scenario), the ones with more frequent training data may dominate.&lt;/p&gt; &lt;h4&gt;Prototypical Networks&lt;/h4&gt; &lt;p&gt;Prototypical networks&amp;nbsp;(&lt;a href="https://arxiv.org/abs/1703.05175"&gt;Snell et al.&amp;nbsp;2017&lt;/a&gt;) are robust to data imbalance by construction; they average the embeddings $\{\mathbf{z}_{nk}\}_{k=1}^{K}$ of the examples for class $n$ to compute their mean embedding or &lt;em&gt;prototype&lt;/em&gt;&amp;nbsp;$\mathbf{p}_{n}$. They then use the similarity between each prototype and the query embedding (figures 4 and 5 b) as a basis for classification.&lt;/p&gt; &lt;p&gt; &lt;img src="https://www.borealisai.com/media/filer_public_thumbnails/filer_public/97/02/970270e1-d976-49c1-ba8c-a9310c00d2c0/t2_figure4.png__3000x1215_q85_subject_location-1500%2C607_subsampling-2.png"&gt; &lt;span&gt;Figure 4. Prototypical networks. The support examples $\mathbf{x}_{nk}$ are all mapped to the embedding space to create embedding $\mathbf{z}_{nk}$ (coloured circles). All of the embeddings for class $k$ are averaged to create a prototype $\mathbf{p}_{n}$. To classify query examples $\hat{\mathbf{x}}$, we first compute its embedding $\hat{\mathbf{z}}$ and then base the decision on the relative distance to the prototypes.&lt;/span&gt; &lt;/p&gt; &lt;p&gt;The similarity is computed as a negative multiple of the Euclidean distance (so that larger distances now give smaller numbers). They pass these similarities to a softmax function to give a probability over classes. This model effectively learns a metric space where the average of a few examples of a class is a good representation of that class and class membership can be assigned based on distance.&lt;/p&gt; &lt;p&gt;They noted that (i) the choice of distance function is vital as squared Euclidean distance outperformed cosine distance, (ii) having a higher number of classes in the support set helps to achieve better performance, and that (iii) the system works best when the support size of each class is matched in the training and test tasks.&lt;/p&gt; &lt;p&gt;&lt;a href="https://arxiv.org/abs/1803.00676"&gt;Ren et al. (2018)&lt;/a&gt; extended this system to take advantage of additional unlabeled data which might be from the test task classes or from other distractor classes. &lt;a href="https://arxiv.org/abs/1805.10123"&gt;Oreshkin et al. (2018)&lt;/a&gt; extended this approach by learning a task-dependent metric on the feature space, so that the distance metric changes from place to place in the embedding space.&lt;/p&gt; &lt;h4&gt;Relation Networks&lt;/h4&gt; &lt;p&gt;Matching networks and prototypical networks both focus on learning the embedding and compare examples using a pre-defined metric (cosine and Euclidean distance, respectively).&amp;nbsp;Relation networks (&lt;a href="https://dl.acm.org/citation.cfm?id=3045585"&gt;Santoro et al.&amp;nbsp;2016&lt;/a&gt;) also learn a metric for comparison of the embeddings (figure 5c). Similarly to prototypical networks, the relation network averages the embeddings of each class in the support set together to form a single prototype. Each prototype is then concatenated with the query embedding and passed to a &lt;em&gt;relation module&lt;/em&gt;. This is a learnable non-linear operator that produces a similarity score between 0 and 1 where 1&amp;nbsp;indicates that the query example belongs to this class prototype. This approach is clean and elegant and can be trained end-to-end.&lt;/p&gt; &lt;h2&gt;&lt;small&gt;Comparison between models&lt;/small&gt;&lt;/h2&gt; &lt;p&gt;All of the pairwise and multi-class comparators are closely related to one another. Each learns an embedding space for data examples. In matching networks, there are different embeddings for support and query examples, but in the other models, they are the same. For prototypical networks and relation networks, multiple embeddings from the same class are averaged to form prototypes. Distances between support set embeddings/prototypes and query set embeddings are computed using either pre-determined distance functions such as Euclidean or cosine distance (triplet networks, matching networks, prototypical networks) or by learning a distance metric (Siamese networks and relation networks).&lt;/p&gt; &lt;p&gt; &lt;img src="https://www.borealisai.com/media/filer_public_thumbnails/filer_public/d6/16/d616cbd2-189e-4d7a-b724-290ee8d9b821/t2_figure5.png__3000x1438_q85_subject_location-1500%2C721_subsampling-2.png"&gt; &lt;span&gt;Figure 5. Multi-class comparators. a) Matching networks compute separate embeddings for support examples (here $\mathbf{x}_{11},\mathbf{x}_{12},\mathbf{x}_{21},\mathbf{x}_{22}$) and the query example $\hat{\mathbf{x}}$. Here $\mathbf{x}_{nk}$ is the $k$th example from the $n$th class. They compute the cosine similarity between each support embedding and the the query embedding, and then use these similarities to choose the class. This has the disadvantage that if there are many more examples of one class than the others, the relatively abundant class may be chosen too frequently.&amp;nbsp;b) Prototypical networks embed the query and support examples using the same network, but average together support embeddings to make prototypes for each class, and so it doesn't matter if the numbers are unbalanced. The Euclidean distance between query embeddings and prototypes is used to support classification. c) Relation networks replace this Euclidean distance with a learned non-linear distance metric.&lt;/span&gt; &lt;/p&gt; &lt;p&gt;The multi-class networks have the advantage that they can be trained end-to-end for the N-way-K-shot classification task. This is not true for the pairwise comparators which are trained to produce a similarity or distance between pairs of data examples (which could itself subsequently be used to support multi-class classification).&lt;/p&gt; &lt;p&gt;Although it is not obvious how the pairwise comparators map to the meta-learning framework, it is possible to consider their data as consisting of minimal training and test tasks. For Siamese networks, each pair of examples is a training task, consisting of one support example and one query example, where their classes may not necessarily match. For triplet networks, there are two support examples (from different classes) and one query example (from one of the classes).&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;In part I of this tutorial we have described the few-shot and meta-learning problems and introduced a taxonomy of methods. We have also discussed methods that use a series of training tasks to learn prior knowledge about the similarity and dissimilarity of classes that can be exploited for future few-shot tasks.&amp;nbsp;This knowledge takes the form of data embeddings that reduce within-class variance relative to between-class variance, and hence make it easier to learn from just a few data points.&lt;/p&gt; &lt;p&gt;In &lt;a href="https://www.borealisai.com/en/blog/tutorial-3-few-shot-learning-and-meta-learning-ii/"&gt;part II&lt;/a&gt; of this tutorial, we'll discuss methods that incorporate prior knowledge about how to learn models, and that incorporate prior knowledge about the data itself.&lt;/p&gt; &lt;p&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;cite&gt;&lt;a href="https://arxiv.org/abs/1606.04080"&gt;Vinyals et al. (2016)&lt;/a&gt;. also introduced a novel &lt;em&gt;context embedding&lt;/em&gt;&amp;nbsp;method which took the full context of the support set $\mathcal{S}$ into account so that $\mbox{ g}[\bullet] = \mbox{ g}[\mathbf{x}, \mathcal{S}]$. Here, the support set was considered as a sequence and encoded by a bi-directional LSTM. &lt;a href="https://arxiv.org/abs/1703.05175"&gt;Snell et al. (2017)&lt;/a&gt; later argued that this context embedding was problematic and redundant.&lt;/cite&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://www.borealisai.com/en/blog/tutorial-2-few-shot-learning-and-meta-learning-i/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sat, 18 Jul 2020 15:47:40 UT
      </pubDate>
      <guid>
        https://www.borealisai.com/en/blog/tutorial-2-few-shot-learning-and-meta-learning-i/
      </guid>
    </item>
    <item>
      <title>
        Percy Liang
      </title>
      <link>
        https://cs.stanford.edu/~pliang/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt; &lt;p&gt; My goal is to develop trustworthy systems that can communicate effectively with people and improve over time through interaction. I broadly identify with the machine learning (ICML, NeurIPS) and natural language processing (ACL, NAACL, EMNLP) communities. &lt;/p&gt; &lt;p&gt; Computers can do a lot, but tapping into their full power requires the rather non-trivial ability to program. I'm interested in building systems that learn to translate natural language descriptions (e.g., in English or Chinese) into programs (e.g., in Python or C++). Such systems would unlock the full power of computing to a much wider audience. A while back, I wrote a friendly introduction to natural language interfaces (&lt;a href="https://cs.stanford.edu/~pliang/papers/talking-xrds2014.pdf"&gt;XRDS magazine 2014&lt;/a&gt;) and a slightly more technical survey article on executable semantic parsing (&lt;a href="https://cs.stanford.edu/~pliang/papers/executable-cacm2016.pdf"&gt;CACM 2016&lt;/a&gt;). One idea we've explored is to "naturalize" a programming language gradually into a natural language (&lt;a href="https://arxiv.org/pdf/1704.06956.pdf"&gt;ACL 2017&lt;/a&gt;). One can also use natural language to describe classifiers directly rather than requiring labeled data (&lt;a href="https://arxiv.org/pdf/1805.03818.pdf"&gt;ACL 2018&lt;/a&gt;). The tension between the fuzziness of machine learning and the crispness of logic also fascinates me. On this note, we showed that neural networks can solve SAT problems with surprising accuracy despite not being told explicitly what a SAT problem is (&lt;a href="https://arxiv.org/pdf/1802.03685.pdf"&gt;ICLR 2019&lt;/a&gt;). &lt;/p&gt; &lt;p&gt; Despite the successes of machine learning, otherwise high-performing models are still difficult to debug and fail catastrophically in the presence of changing data distributions and adversaries. For example, on the &lt;a href="http://stanford-qa.com/"&gt;SQuAD&lt;/a&gt; reading comprehension dataset we created (&lt;a href="https://arxiv.org/pdf/1606.05250.pdf"&gt;EMNLP 2016&lt;/a&gt;), we showed that state-of-the-art systems, despite reaching human-level benchmark performance, are easily fooled by distracting sentences in a way that no human would be (&lt;a href="http://arxiv.org/pdf/1707.07328.pdf"&gt;EMNLP 2017&lt;/a&gt;). Given society's increasing reliance on machine learning, it is critical to build tools to make machine learning more reliable in the wild. We've worked on using influence functions to understand black-box models (&lt;a href="http://arxiv.org/pdf/1703.04730.pdf"&gt;ICML 2017&lt;/a&gt;), semidefinite programming to provide certificates a neural network is safe from a class of adversaries (&lt;a href="https://arxiv.org/pdf/1811.01057.pdf"&gt;NeurIPS 2018&lt;/a&gt;), and distributionally robust optimization to ensure the fairness of machine learning models over time (&lt;a href="https://arxiv.org/pdf/1806.08010.pdf"&gt;ICML 2018&lt;/a&gt;). &lt;/p&gt; &lt;p&gt; Finally, I am a strong proponent of efficient and reproducible research. We have been developing &lt;b&gt;&lt;a href="https://worksheets.codalab.org/"&gt;CodaLab Worksheets&lt;/a&gt;&lt;/b&gt;, a platform that allows researchers to run and manage their experiments by maintaining the full provenance of an experiment from raw data to final results. Most of our recent papers have been published on CodaLab as &lt;a href="https://worksheets.codalab.org/worksheets/0x9b6bb6fdd4aa4bf1b120300fd95f944a"&gt;executable papers&lt;/a&gt;. We are actively looking for contributors, so please contact me if you're interested! &lt;/p&gt; &lt;p&gt;Here is some &lt;a href="https://cs.stanford.edu/~pliang/software"&gt;code for older projects&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://cs.stanford.edu/~pliang/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sun, 29 Nov 2020 11:11:44 UT
      </pubDate>
      <guid>
        https://cs.stanford.edu/~pliang/
      </guid>
    </item>
    <item>
      <title>
        He He - NYU
      </title>
      <link>
        https://hhexiy.github.io/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt; &lt;div&gt; &lt;p&gt;&lt;img height="250px" src="https://hhexiy.github.io/figures/me2016-lo.jpg"&gt; &lt;/p&gt; &lt;div&gt; &lt;div&gt; &lt;ul&gt; &lt;li&gt;&lt;h2&gt;He He&lt;/h2&gt;&lt;/li&gt; &lt;li&gt;&lt;img height="40" src="https://hhexiy.github.io/figures/name.png"&gt;&lt;/li&gt; &lt;li&gt;&lt;small&gt;(&lt;a&gt;How to pronounce?&lt;/a&gt;)&lt;/small&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div&gt; &lt;ul&gt; &lt;li&gt;Assistant Professor of &lt;a href="https://cs.nyu.edu/home/index.html"&gt;Computer Science&lt;/a&gt; and &lt;a href="https://cds.nyu.edu/"&gt;Data Science&lt;/a&gt; &lt;/li&gt; &lt;li&gt;&lt;a href="https://wp.nyu.edu/cilvr/"&gt;CILVR&lt;/a&gt; / &lt;a href="https://wp.nyu.edu/ml2/"&gt;ML&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div&gt; &lt;ul&gt; &lt;li&gt;60 Fifth Ave 605&lt;/li&gt; &lt;li&gt;hehe@cs.nyu.edu&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div&gt; &lt;ul&gt; &lt;li&gt; [&lt;a href="https://hhexiy.github.io/docs/cv/cv.pdf"&gt;CV&lt;/a&gt;] [&lt;a href="https://scholar.google.com/citations?hl=en&amp;amp;user=K-isjagAAAAJ&amp;amp;view_op=list_works&amp;amp;sortby=pubdate"&gt;&lt;span size="3"&gt;Google Scholar&lt;/span&gt;&lt;/a&gt;] &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;p&gt; My goal is to enable reliable communication in natural langauge between machines and humans. Recent research directions include: (1) &lt;strong&gt;Text generation&lt;/strong&gt;: How do we ensure that the generated text are not just coheret, but also &lt;a href="https://arxiv.org/abs/2005.03754"&gt;factually correct&lt;/a&gt;? Beyond factuality, how do we generate &lt;a href="https://arxiv.org/abs/1804.06437"&gt;novel&lt;/a&gt;, &lt;a href="https://arxiv.org/abs/1904.06828"&gt;creative&lt;/a&gt; text in a controllable way? (2) &lt;strong&gt;Robust language understanding&lt;/strong&gt;: Statistical machine learning systems suffer from spurious correlations in the data, resulting in biased prediction and catastrophic errors. How can we &lt;a href="https://arxiv.org/abs/1908.10763"&gt;learn&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2007.06778"&gt;models&lt;/a&gt; that are robust to dataset biases? (3) &lt;strong&gt;Dialogue systems&lt;/strong&gt;: Building an effective dialogue agent requires understanding in a broad sense, e.g., how to &lt;a href="https://arxiv.org/abs/1704.07130"&gt;reason&lt;/a&gt; about structured knowledge and learn efficient &lt;a href="https://arxiv.org/abs/1808.09637"&gt;strategies&lt;/a&gt; for a specific task? &lt;/p&gt; &lt;p&gt; &lt;strong&gt;Prospective students:&lt;/strong&gt; If you are interested in working with me, please apply to either the &lt;a href="https://cs.nyu.edu/home/phd/admission.html"&gt;PhD program in Computer Science&lt;/a&gt; or &lt;a href="https://cds.nyu.edu/academics/phd-in-data-science/"&gt;PhD program in Data Science&lt;/a&gt; and mention my name in your application. If you are a student at NYU, please drop me an email. &lt;/p&gt; &lt;hr&gt; &lt;p&gt; &lt;h4&gt;PhD students&lt;/h4&gt; &lt;/p&gt; &lt;div&gt; &lt;ul&gt; &lt;li&gt; &lt;a href="https://joshinh.github.io/"&gt;Nitish Joshi&lt;/a&gt; &lt;/li&gt; &lt;li&gt; &lt;a href="https://vishakhpk.github.io/"&gt;Vishakh Padmakumar&lt;/a&gt; &lt;/li&gt; &lt;li&gt; &lt;a href="https://yzpang.github.io/"&gt;Richard Pang&lt;/a&gt; (co-advised with Kyunghyun Cho) &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;p&gt; &lt;h4&gt;Visitors and MS students&lt;/h4&gt; &lt;/p&gt; &lt;div&gt; &lt;ul&gt; &lt;li&gt; &lt;a href="https://uditarora.com/"&gt;Udit Arora&lt;/a&gt; &lt;/li&gt; &lt;li&gt; Aniket Bhatnagar &lt;/li&gt; &lt;li&gt; &lt;a href="http://johnnyma.info/"&gt;Johnny Ma&lt;/a&gt; &lt;/li&gt; &lt;li&gt; Zhiliang Tian &lt;/li&gt; &lt;li&gt; Saranya Venkatraman &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;p&gt; &lt;h4&gt;Teaching&lt;/h4&gt; &lt;/p&gt; &lt;div&gt; &lt;ul&gt; &lt;li&gt; &lt;a href="https://hhexiy.github.io/nlp/index.html"&gt;CSCI-GA.2590 Natural Language Processing&lt;/a&gt; [&lt;a href="https://cs.nyu.edu/courses/fall20/CSCI-GA.2590-001/"&gt;fall20&lt;/a&gt;] &lt;/li&gt; &lt;li&gt; &lt;a href="https://nyu-ds1003.github.io/spring2021/#home"&gt;DS-GA.1003 Machine Learning&lt;/a&gt; [spring19] [&lt;a href="https://nyu-ds1003.github.io/spring2021/#home"&gt;spring20&lt;/a&gt;] &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;p&gt; &lt;h4&gt;Publications&lt;/h4&gt; &lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://hhexiy.github.io/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sun, 29 Nov 2020 11:11:50 UT
      </pubDate>
      <guid>
        https://hhexiy.github.io/
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://users.umiacs.umd.edu/~resnik/writing_advice.html
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt; My former grad student Chris Dyer wrote to me recently to ask if I could remind him of some of the useful editorial advice I'd given him while he was writing his dissertation. Made me feel all warm and fuzzy to think it was valuable enough that he wants to pass it on to his own students. A lot of my process for helping students improve their writing happens in the moment, very much on a case by case basis. But here are a few principles that I think are worth noting. &lt;h2&gt;Strong writing&lt;/h2&gt; &lt;ul&gt; &lt;li&gt; &lt;strong&gt;Feeling/thinking verbs.&lt;/strong&gt; Avoid "we think", "we believe", etc. If you're putting it in your paper, it's because you believe it or think it's true, and these do nothing but weaken or hedge. &lt;/li&gt;&lt;li&gt; &lt;strong&gt;"Present" verbs.&lt;/strong&gt; If I &lt;em&gt;present&lt;/em&gt; an algorithm to you, am I presenting someone else's work that existed before, or my own novel contribution? Avoid wording that is ambiguous and aim for strong verbs that emphasize your particular contribution. &lt;/li&gt;&lt;li&gt; &lt;strong&gt;Using strong verbs.&lt;/strong&gt; For algorithms, models, etc., it's must stronger to &lt;em&gt;introduce&lt;/em&gt; something new than simply to &lt;em&gt;propose&lt;/em&gt; it, although &lt;em&gt;propose&lt;/em&gt; is good early in the paper for a hypothesis that you then &lt;em&gt;support&lt;/em&gt; with results, allowing you to claim that you have &lt;em&gt;validated&lt;/em&gt;, &lt;em&gt;verified&lt;/em&gt;, or &lt;em&gt;demonstrated&lt;/em&gt;. In general for results, it's strong to &lt;em&gt;demonstrate&lt;/em&gt; and &lt;em&gt;show&lt;/em&gt;, although there are also appropriate places for, say, having &lt;em&gt;found&lt;/em&gt; something to be true or, in the context of something more exploratory or inductive, having &lt;em&gt;seen&lt;/em&gt; some behavior or pattern. Unless it's an actual proof, avoid &lt;em&gt;prove&lt;/em&gt;, and unless you're Columbus, avoid transitive &lt;em&gt;discover&lt;/em&gt; &lt;em&gt;NP&lt;/em&gt;, although with a sentential complement &lt;em&gt;discovered that [clause]&lt;/em&gt; is similar to &lt;em&gt;having seen&lt;/em&gt;. &lt;/li&gt;&lt;li&gt; &lt;strong&gt;Passive voice.&lt;/strong&gt; There is nothing the least bit wrong with passive voice when it is used appropriately. (For example, there is no reason whatsoever for me to modify the previous sentence to say "when one uses it appropriately".) For chapter and verse on this, see Pullum, &lt;a href="http://www.lel.ed.ac.uk/grammar/passives.html"&gt;"Confusion over avoiding the passive"&lt;/a&gt;, http://www.lel.ed.ac.uk/grammar/passives.html; it's a must-read. &lt;/li&gt;&lt;li&gt; &lt;strong&gt;Academic "we".&lt;/strong&gt; This is somewhere between a matter of taste and a religious issue, so your mileage may vary. However, if you're doing a practice presentation or defense (or sometimes even the real thing) and a certain colleague of mine is in the audience, and you use "we", you can expect a question about which pieces of the contribution are yours and which should be attributed to your advisor. Personally, I prefer "I" for dissertations and in single-authored papers I tend to avoid the issue when possible by using alternative phrasing, e.g. passive ("a corpus of 200M words was obtained by..."), non-animate subjects ("The results of Experiment 1 demonstrate..."), nominalizations ("After sentence-breaking and tokenization..."), etc. That said, I do think it's fine to use an inclusive "we" to provide an informal tone that brings together author and audience, e.g. "When we take a look at the output of Algorithm 1, ...". (Notice that if past tense &lt;em&gt;took&lt;/em&gt; had been used instead of present tense &lt;em&gt;take&lt;/em&gt;, this would have been an academic rather than inclusive "we".) &lt;/li&gt;&lt;li&gt; &lt;strong&gt;The "story" in a paper should be organized logically, not chronologically.&lt;/strong&gt; Nobody needs to know that you actually executed Experiment 1 a month after Experiment 3. The logic of the argument in the paper should dictate the structure. There are exceptions, e.g. perhaps analysis of Experiment 2 led to some new or expanded ideas that were then tested in Experiment 3, but notice that in this case the logical progression and the chronological progression coincide. &lt;/li&gt;&lt;li&gt; &lt;strong&gt;Nobody cares about debugging or implementation.&lt;/strong&gt; Implementation details belong in documentation or, if they're really salient for the paper, in an appendix. Unless the paper is about data structures, programming language choice, etc., go with &lt;a href="http://en.wikipedia.org/wiki/David_Marr_(neuroscientist)#Levels_of_analysis"&gt;Marr&lt;/a&gt;'s computational or algorithmic levels in your description, not the physical/implementation level. &lt;/li&gt;&lt;li&gt; &lt;strong&gt;Be generous in your citations.&lt;/strong&gt; People who have done related work might well be your reviewers. Plus it's the right thing to do. 'Nuff said. &lt;/li&gt;&lt;li&gt; &lt;strong&gt;Eschew obfuscation.&lt;/strong&gt; Yes, you can save a whole lot of space by condensing a ton in between \begin{algorithm} and \end{algorithm}. But not everyone (read: not every reviewer) enjoys having to work through the line-by-line details of an algorithm. Make sure the text has plenty of plain language and be generous with your prose explanation of what's going on. And try to avoid any Greek letters that people might not know how to pronounce. &lt;/li&gt;&lt;li&gt; &lt;strong&gt;Be explicit about having separated training and test data.&lt;/strong&gt; This is a pet peeve of mine. Yes, everyone is supposed to remember this. But make sure your description makes it clear that you did. &lt;/li&gt;&lt;li&gt; &lt;strong&gt;Explain why you chose the parameters you chose.&lt;/strong&gt; You used 50 topics for LDA? Why not 20 or 100? Oh, and if the answer is not that you either decided a priori or tuned on held-out data, but rather that it gave you the best results on your test data, you'd better see the previous point: you are reporting a tainted experiment. You can un-taint it somewhat by reporting the results for the other values you tried also -- but then you should be prepared for a reviewer to ask why we should believe 50 will be the best value on the next, previously unseen dataset. (Better yet, do the next experiment fixing 50 in advance and show that the choice generalized to another case.) If all else fails, appeal to previous literature and choose parameter values that can be described as typical in prior work. &lt;/li&gt;&lt;/ul&gt; At this point I realized I was veering into "grumpy old man" territory and decided to stop... &lt;/div&gt;&lt;a href="https://users.umiacs.umd.edu/~resnik/writing_advice.html"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sun, 29 Nov 2020 11:11:54 UT
      </pubDate>
      <guid>
        https://users.umiacs.umd.edu/~resnik/writing_advice.html
      </guid>
    </item>
    <item>
      <title>
        better geometry through graph theory
      </title>
      <link>
        https://ideolalia.com/2018/08/28/artifex.html
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt; &lt;article&gt; &lt;p&gt;&lt;img alt="" src="https://ideolalia.com/images/artifex-set-operations.png"&gt;&lt;/p&gt; &lt;h3 id="how-i-spent-my-summer"&gt;how I spent my summer&lt;/h3&gt; &lt;p&gt;A few months ago, I decided to implement set operations on curved regions. I had the &lt;a href="https://www.springer.com/us/book/9783540779735"&gt;the canonical textbook on computational geometry&lt;/a&gt;, which described approaches for polygons comprised of straight lines, and it seemed like &lt;a href="http://paperjs.org/"&gt;other projects&lt;/a&gt; had extended these techniques to &lt;a href="https://en.wikipedia.org/wiki/B%C3%A9zier_curve"&gt;parametric curves&lt;/a&gt;. I figured it would take a couple of weeks.&lt;/p&gt; &lt;p&gt;Unfortunately, the field of computational geometry embodies a fundamental contradiction. In geometry, the angles of a triangle add up to exactly π radians, and if &lt;em&gt;u&lt;/em&gt; is clockwise from &lt;em&gt;v&lt;/em&gt; then &lt;em&gt;v&lt;/em&gt; must be counter-clockwise from &lt;em&gt;u&lt;/em&gt;. Computers, on the other hand, use floating point representations which make a mockery of these simple Euclidean truths.&lt;/p&gt; &lt;p&gt;The academic literature largely ignores this. Algorithms are proven to be geometrically sound, and robust implementations are left as an exercise for the reader. This is akin to a world in which hash collisions caused unavoidable data loss, and the academic response was to implicitly assume the existence of a perfect hash function. If a paper is predicated on unrealistic assumptions, we cannot evaluate it on its own terms; we must understand, empirically, how well it functions when these assumptions are broken.&lt;/p&gt; &lt;p&gt;With this in mind, we can now look at the existing algorithms for &lt;a href="https://en.wikipedia.org/wiki/Clipping_(computer_graphics)"&gt;polygon clipping&lt;/a&gt;, which is the term of art for polygon set operations. Every technique is a variation on a common theme:&lt;/p&gt; &lt;p&gt;&lt;img alt="" src="https://ideolalia.com/images/artifex-clipping.png"&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Given two or more rings, find every point of intersection&lt;/li&gt; &lt;li&gt;Segment the rings at the points of intersection&lt;/li&gt; &lt;li&gt;Decide whether each segment should be included, based on the operation being performed&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The dozen or so papers on this subject differ only in the third step. Since our decision to include a segment typically inverts at an intersection point, they describe a variety of approaches for using our decision to about one segment to inform our decision about adjacent segments.&lt;/p&gt; &lt;p&gt;My textbook described a method using &lt;a href="https://en.wikipedia.org/wiki/Doubly_connected_edge_list"&gt;doubly-connected edge lists&lt;/a&gt;, which is a generic geometric data structure. I assumed that meant it could be reused for other problems, so I started my implementation.&lt;/p&gt; &lt;p&gt;A month went by.&lt;/p&gt; &lt;p&gt;I had finished the implementation my first week, but it wasn’t reliable. A DCEL is a collection of linked loops, which can be incrementally updated. When performing a set operation, we incrementally bisect the original set of loops, and then determine which should and shouldn’t be included. Despite my best efforts, I kept finding new shapes that caused adjacent faces to get tangled together, creating a Möbius strip that is simultaneously inside and outside the expected result.&lt;/p&gt; &lt;p&gt;Slowly, I realized the problem wasn’t the data structure, it was the first step that every paper glossed over: finding all the intersections. The DCEL assumes the edges at a vertex have a total ordering: the previous edge is directly clockwise, and the next one is directly counter-clockwise. If we miss an intersection, we might conclude two curves are both clockwise relative to the other, causing everything to fall apart.&lt;/p&gt; &lt;p&gt;I began to look for better ways to find intersections, hoping that if I found an approach that was sufficiently accurate, my work on the DCEL could be salvaged. Unfortunately, the approaches I found in the literature and implemented in the wild were no better than what I had been using. My data structure demanded precise inputs, without internal contradictions, and I couldn’t deliver.&lt;/p&gt; &lt;p&gt;At that point, I began to wonder if I had missed something fundamental. I thought maybe if I dissected how other, more mature, libraries handled my pathological shapes, I could work backwards to see where I had gone wrong. But when I began to feed these shapes into well-established projects like paper.js, I found they failed just as badly.&lt;/p&gt; &lt;p&gt;To find my pathological inputs, I had been using property-based testing. Given a random combination of shapes, I would perform a point-in-region test and compare it to a reference result, generated by querying each shape individually and combining the results according to the operation. Most inputs worked fine, but after a few hundred thousand inputs it would inevitably find some failure.&lt;/p&gt; &lt;p&gt;Other projects, it turned out, had been a little less eager to find their own failure modes. Some only had a handful of example-based tests, others had a static suite of a few thousand inputs they used to validate their changes. If I had missed something, it appeared to be that no one else expected these operations to be particularly robust.&lt;/p&gt; &lt;hr&gt; &lt;h3 id="why-is-this-so-hard"&gt;why is this so hard?&lt;/h3&gt; &lt;p&gt;Floating point arithmetic is best understood through a simple, maddening fact: &lt;code&gt;a + (b - a)&lt;/code&gt; does not necessarily equal &lt;code&gt;b&lt;/code&gt;. It might be equal, or it might be off by just a little, where “little” is relative to the larger of the two numbers. This means that when we compare two floating point numbers, we cannot do a precise comparison, we have to ask whether they differ by less than some &lt;em&gt;epsilon&lt;/em&gt; value.&lt;/p&gt; &lt;p&gt;This epsilon represents the level of numerical uncertainty to which we’ve resigned ourselves. There is vast folk wisdom around how to minimize this uncertainty, but the fact remains that every arithmetic operation injects a bit of uncertainty, and it grows cumulatively with each successive operation. When dealing with small numbers, this uncertainty may dwarf the values themselves.&lt;/p&gt; &lt;p&gt;An intersection, in a precise mathematical sense, occurs wherever the distance between the curves is exactly zero:&lt;/p&gt; &lt;p&gt;&lt;img alt="" src="https://ideolalia.com/images/artifex-precise-intersection.png"&gt;&lt;/p&gt; &lt;p&gt;But in a practical sense, it is wherever the distance between the curves is close enough to zero:&lt;/p&gt; &lt;p&gt;&lt;img alt="" src="https://ideolalia.com/images/artifex-fuzzy-intersection.png"&gt;&lt;/p&gt; &lt;p&gt;This has at least one intersection, but we could just as easily return three or ten within that overlapping range. This uncertainty is anathema to the published techniques, which rely on counting these intersections to determine whether we’re inside or outside the other shape. A single spurious intersection may cause the entire result to vanish. If two objects with similar curvature move across each other, the result will tend to flicker in and out of existence.&lt;/p&gt; &lt;p&gt;These techniques may suffice for straight lines, which require smaller epsilons, but they are wholly unsuited to the relative imprecision of parametric curves.&lt;/p&gt; &lt;hr&gt; &lt;h3 id="embracing-the-uncertainty"&gt;embracing the uncertainty&lt;/h3&gt; &lt;p&gt;As the weeks passed, the errors uncovered by my tests went from feeling random to feeling malicious. Floating point arithmetic may be deterministic, but as I watched my screen, waiting for the tests to fail, I imagined a demon in the FPU nudging the values as they flowed past, trying to move them beyond the threshold of self-consistency.&lt;/p&gt; &lt;p&gt;One day, I realized this was exactly the narrative behind &lt;a href="https://en.wikipedia.org/wiki/Error_detection_and_correction"&gt;error-correcting codes&lt;/a&gt;; we assume our data has been randomly altered en route, and we want to return it to a consistent state. It didn’t seem like I could get it right the first time, so why not just fix it afterwards?&lt;/p&gt; &lt;p&gt;Consider the union of two ellipses:&lt;/p&gt; &lt;p&gt;&lt;img alt="" src="https://ideolalia.com/images/artifex-two-ellipses.png"&gt;&lt;/p&gt; &lt;p&gt;Ostensibly, there should only be three points of intersection, one on the left and two on the right. But for the reasons described above, any intersection routine will likely find multiple points of intersection on the left as the curves converge on each other:&lt;/p&gt; &lt;p&gt;&lt;img alt="" src="https://ideolalia.com/images/artifex-ellipses-intersections.png"&gt;&lt;/p&gt; &lt;p&gt;The segments on the left are small enough, and thus imprecise enough, that our spatial intuition for the problem will just mislead us. For this reason, it’s better to think of it as a graph:&lt;/p&gt; &lt;p&gt;&lt;img alt="" src="https://ideolalia.com/images/artifex-ellipses-graph.png"&gt;&lt;/p&gt; &lt;p&gt;Now we have to decide which edges to include, and which to exclude. Since we’re trying to find the union, we want to keep any segments that are outside the other shape:&lt;/p&gt; &lt;p&gt;&lt;img alt="" src="https://ideolalia.com/images/artifex-ellipses-valid-result.png"&gt;&lt;/p&gt; &lt;p&gt;This is a well-formed result; there is a single cycle, and once we remove that cycle there are no leftover edges. But we can’t rely on getting this lucky; the edges on the left might have succumbed to floating point error and believed they were both inside the other:&lt;/p&gt; &lt;p&gt;&lt;img alt="" src="https://ideolalia.com/images/artifex-ellipses-incomplete.png"&gt;&lt;/p&gt; &lt;p&gt;This is not a well-formed result; there are no cycles, and a bunch of leftover edges. To make this consistent, we need to either close the loop, or remove the leftovers. The cost of these changes is measured by the aggregate length of the edges we are adding or removing.&lt;/p&gt; &lt;p&gt;The minimal set of changes is equivalent to the shortest path between the dangling vertices. Having found the path, we then invert the inclusion of every edge it passes through. In this case, it passes through one of the edges we originally excluded, so we add that edge back in, and return the cycle we just created.&lt;/p&gt; &lt;p&gt;Alternately, both edges might think they are outside the other:&lt;/p&gt; &lt;p&gt;&lt;img alt="" src="https://ideolalia.com/images/artifex-ellipses-redundant.png"&gt;&lt;/p&gt; &lt;p&gt;In this case, we have a complete cycle, but once we’ve extracted it there’s a single leftover edge:&lt;/p&gt; &lt;p&gt;&lt;img alt="" src="https://ideolalia.com/images/artifex-ellipses-leftover.png"&gt;&lt;/p&gt; &lt;p&gt;Here again, we search through all the remaining edges for the shortest path between the two dangling vertices. Since it passes through our leftover edge, we remove it.&lt;/p&gt; &lt;p&gt;Every floating point inconsistency will surface as one of these two cases, or some combination thereof. By searching for the shortest path between the dangling edges, we find the smallest possible edit that will yield a consistent result. Of course, a consistent result is not necessarily the &lt;em&gt;correct&lt;/em&gt; one, but the fact that floating point errors tend to cluster around the smallest edges makes this a reasonable heuristic. More importantly, it has weathered tens of millions of generative test cases without any issues.&lt;/p&gt; &lt;p&gt;A complete implementation of this algorithm can be found &lt;a href="https://github.com/lacuna/artifex/blob/master/src/io/lacuna/artifex/utils/regions/Clip.java"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;hr&gt; &lt;p&gt;I’m not sure if this is a novel approach, but at the very least it represents a meaningful improvement on the state of the art in open source. Intuitively, it feels like this might be a means to avoid epsilon hell in a wide range of geometric and numerical algorithms. If anyone is aware of prior art in this vein, I’d be very interested to see it.&lt;/p&gt; &lt;p&gt;My work on the &lt;a href="https://github.com/lacuna/artifex"&gt;Artifex&lt;/a&gt; library is ongoing, but I hope it proves useful to others, and look forward to sharing my own projects that it will enable in the near future.&lt;/p&gt; &lt;hr&gt; &lt;p&gt;&lt;em&gt;Thanks to Alex Engelberg, Elana Hashman, Angus Fletcher, Reid McKenzie, and Zack Maril for feedback on early drafts of this post.&lt;/em&gt;&lt;/p&gt; &lt;/article&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://ideolalia.com/2018/08/28/artifex.html"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sun, 6 Dec 2020 18:48:40 UT
      </pubDate>
      <guid>
        https://ideolalia.com/2018/08/28/artifex.html
      </guid>
    </item>
    <item>
      <title>
        Amazon.com : Anthony Thomas, Award Winning Peanut Butter &amp;amp; Milk Chocolate Buckeyes in Ohio State Buckeyes Box, Deliciously Delightful Snacks (24 Count) : Grocery &amp;amp; Gourmet Food
      </title>
      <link>
        https://www.amazon.com/Anthony-Thomas-Chocolate-Deliciously-Delightful/dp/B076B15VRJ/ref=sr_1_2?crid=1V9DVYCKTSDNI&amp;dchild=1&amp;keywords=ohio+state+buckeyes+chocolate&amp;qid=1607894720&amp;sprefix=ohio+state+buckeyes+choc%2Caps%2C176&amp;sr=8-2
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;&lt;p&gt;&lt;span data-hook="cr-widget-MedleyCustomerImages"&gt; &lt;div data-hook="customer-images-widget" data-asin="B076B15VRJ" id="reviews-image-gallery-container"&gt;&lt;p&gt;&lt;h3&gt;Customer images&lt;/h3&gt;&lt;/p&gt; &lt;/div&gt;&lt;/span&gt; &lt;span data-widget-name="cr-summarization-lighthut"&gt; &lt;/span&gt;&lt;span data-hook="cr-widget-FocalReviews"&gt; &lt;div&gt; &lt;p id="cm-cr-local-reviews-title"&gt;&lt;h3 data-hook="dp-local-reviews-header"&gt; Top reviews from the United States &lt;/h3&gt;&lt;/p&gt;&lt;div&gt;&lt;div role="alert" aria-live="assertive"&gt;&lt;h4&gt;There was a problem filtering reviews right now. Please try again later.&lt;/h4&gt;&lt;/div&gt;&lt;div data-hook="top-customer-reviews-widget" id="cm-cr-dp-review-list"&gt;&lt;div id="R1KQRQ84NDKDQQ" data-hook="review"&gt;&lt;p&gt;&lt;span data-hook="review-date"&gt;Reviewed in the United States on April 2, 2020&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-hook="format-strip-linkless"&gt;Size: 7.23 Ounce (Pack of 12)&lt;/span&gt;&lt;i aria-label="|" role="img"&gt;&lt;/i&gt;&lt;span data-hook="avp-badge-linkless"&gt;Verified Purchase&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-hook="review-body"&gt;&lt;div data-a-expander-collapsed-height="300" data-a-expander-name="review_text_read_more" aria-live="polite"&gt;&lt;p&gt;&lt;span&gt; I remember having buckeye candy as a kid and loving it. So when my mom and I saw these featured on the Kelly Clarkson show, we decided to give them a try. Price was a bit steep, but worth it if delicious. They aren’t bad by any means, they just were not great or special in our opinion. To each their own though. &lt;/span&gt; &lt;/p&gt;&lt;/div&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;div id="RDUFFO40YZ3LG" data-hook="review"&gt;&lt;p&gt;&lt;span data-hook="review-date"&gt;Reviewed in the United States on November 17, 2018&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-hook="format-strip-linkless"&gt;Size: 7.23 Ounce (Pack of 12)&lt;/span&gt;&lt;i aria-label="|" role="img"&gt;&lt;/i&gt;&lt;span data-hook="avp-badge-linkless"&gt;Verified Purchase&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-hook="review-body"&gt;&lt;div data-a-expander-collapsed-height="300" data-a-expander-name="review_text_read_more" aria-live="polite"&gt;&lt;p&gt;&lt;span&gt; Sent as a gift out of state to a buckeye fan. Was told they had a film of white/grey on them and she bit into one and it crumbled it was so stale. The box had no exp date. Very disappointed and embarrassed. They were expensive and I thought I could count on the brand alone. &lt;/span&gt; &lt;/p&gt;&lt;/div&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;div id="RIRLHGMGYC33Q" data-hook="review"&gt;&lt;p&gt;&lt;span data-hook="review-date"&gt;Reviewed in the United States on July 12, 2020&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-hook="format-strip-linkless"&gt;Size: 60 Count (Pack of 1)&lt;/span&gt;&lt;i aria-label="|" role="img"&gt;&lt;/i&gt;&lt;span data-hook="avp-badge-linkless"&gt;Verified Purchase&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-hook="review-body"&gt;&lt;div data-a-expander-collapsed-height="300" data-a-expander-name="review_text_read_more" aria-live="polite"&gt;&lt;p&gt;&lt;span&gt; Not the real versions of chocolate Buckeyes, but WAY better! Package comes plastic wrapped and inside the display box are the 60 individually wrapped chocolates... PLUS the chocolatier is based out of the home of the Buckeyes, Columbus Ohio. A great gift for anyone who’s an alumnus not able to get a taste of “home”. &lt;/span&gt; &lt;/p&gt;&lt;/div&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;div id="RZZQJ8C3PYG2K" data-hook="review"&gt;&lt;p&gt;&lt;span data-hook="review-date"&gt;Reviewed in the United States on February 9, 2020&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-hook="format-strip-linkless"&gt;Size: 7.23 Ounce (Pack of 12)&lt;/span&gt;&lt;i aria-label="|" role="img"&gt;&lt;/i&gt;&lt;span data-hook="avp-badge-linkless"&gt;Verified Purchase&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-hook="review-body"&gt;&lt;div data-a-expander-collapsed-height="300" data-a-expander-name="review_text_read_more" aria-live="polite"&gt;&lt;p&gt;&lt;span&gt; I purchased these for our OSU/Clemson football party. The candies arrived quickly. But I was very disappointed in their "flavor". Maybe next time I'll make my own. &lt;/span&gt; &lt;/p&gt;&lt;/div&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;div id="RXY3HQCLBNTDM" data-hook="review"&gt;&lt;p&gt;&lt;span data-hook="review-date"&gt;Reviewed in the United States on October 14, 2018&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-hook="format-strip-linkless"&gt;Size: 60 Count (Pack of 1)&lt;/span&gt;&lt;i aria-label="|" role="img"&gt;&lt;/i&gt;&lt;span data-hook="avp-badge-linkless"&gt;Verified Purchase&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-hook="review-body"&gt;&lt;div data-a-expander-collapsed-height="300" data-a-expander-name="review_text_read_more" aria-live="polite"&gt;&lt;p&gt;&lt;span&gt; Unfortunately they arrived totally melted, which would look bad to use in our wedding welcome bags. The listing says “Ships in insulated packaging and cold packs to keep from melting,” but that was apparently not the case. &lt;/span&gt; &lt;/p&gt;&lt;/div&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;div id="R2AXSFPVY6OWJZ" data-hook="review"&gt;&lt;p&gt;&lt;span data-hook="review-date"&gt;Reviewed in the United States on January 20, 2021&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-hook="format-strip-linkless"&gt;Size: 7.23 Ounce (Pack of 12)&lt;/span&gt;&lt;i aria-label="|" role="img"&gt;&lt;/i&gt;&lt;span data-hook="avp-badge-linkless"&gt;Verified Purchase&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-hook="review-body"&gt;&lt;div data-a-expander-collapsed-height="300" data-a-expander-name="review_text_read_more" aria-live="polite"&gt;&lt;p&gt;&lt;span&gt; I was really hopeful for these based on the reviews but the ones I got were just not that good. I'd say they were average quality, definitely not something I'd buy again. &lt;/span&gt; &lt;/p&gt;&lt;/div&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;div id="R1KMEZXQJQK18Q" data-hook="review"&gt;&lt;p&gt;&lt;span data-hook="review-date"&gt;Reviewed in the United States on January 21, 2020&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-hook="format-strip-linkless"&gt;Size: 14.5 Ounce (Pack of 1)&lt;/span&gt;&lt;i aria-label="|" role="img"&gt;&lt;/i&gt;&lt;span data-hook="avp-badge-linkless"&gt;Verified Purchase&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-hook="review-body"&gt;&lt;div data-a-expander-collapsed-height="300" data-a-expander-name="review_text_read_more" aria-live="polite"&gt;&lt;p&gt;&lt;span&gt; These buckeyes do no justice to homemade. Tasted like wax. Never again. &lt;/span&gt; &lt;/p&gt;&lt;/div&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;div id="R1XKAB454JAXA7" data-hook="review"&gt;&lt;p&gt;&lt;span data-hook="review-date"&gt;Reviewed in the United States on November 17, 2019&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-hook="format-strip-linkless"&gt;Size: 14.5 Ounce (Pack of 1)&lt;/span&gt;&lt;i aria-label="|" role="img"&gt;&lt;/i&gt;&lt;span data-hook="avp-badge-linkless"&gt;Verified Purchase&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-hook="review-body"&gt;&lt;div data-a-expander-collapsed-height="300" data-a-expander-name="review_text_read_more" aria-live="polite"&gt;&lt;p&gt;&lt;span&gt; This is my third purchase. 2 boxes for us, and a box that I am taking over to a family gathering. Great conversation as well as great tasting candy. I am originally from Ohio, moved to NC, so I am so delighted that I can buy once again!!! &lt;/span&gt; &lt;/p&gt;&lt;/div&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/span&gt; &lt;span data-hook="cr-widget-DesktopGlobalReviews"&gt;&lt;/span&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;a href="https://www.amazon.com/Anthony-Thomas-Chocolate-Deliciously-Delightful/dp/B076B15VRJ/ref=sr_1_2?crid=1V9DVYCKTSDNI&amp;dchild=1&amp;keywords=ohio+state+buckeyes+chocolate&amp;qid=1607894720&amp;sprefix=ohio+state+buckeyes+choc%2Caps%2C176&amp;sr=8-2"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sun, 13 Dec 2020 16:45:59 UT
      </pubDate>
      <guid>
        https://www.amazon.com/Anthony-Thomas-Chocolate-Deliciously-Delightful/dp/B076B15VRJ/ref=sr_1_2?crid=1V9DVYCKTSDNI&amp;dchild=1&amp;keywords=ohio+state+buckeyes+chocolate&amp;qid=1607894720&amp;sprefix=ohio+state+buckeyes+choc%2Caps%2C176&amp;sr=8-2
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://wiki.nikitavoloboev.xyz/macos
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div data-gramm="false" spellcheck="true" data-key="74520e045e1c4985ba637c4d8cb5e84f" data-slate-editor="true" data-editioncontainer="true"&gt;&lt;p data-key="a9fd87d6e18540c08b644cf399524002"&gt;&lt;span&gt;&lt;span data-key="6d8cf8178e2243ef990ae9428acdef48"&gt;&lt;span data-offset-key="6d8cf8178e2243ef990ae9428acdef48:0"&gt;macOS is my &lt;/span&gt;&lt;/span&gt;&lt;a data-key="0d0b56a4916e4c2081ae27bd726928f3" rel="noopener noreferrer" href="https://github.com/nikitavoloboev/my-mac-os"&gt;&lt;span data-key="ac444296e8214e2986576dffe4d3e328"&gt;&lt;span data-offset-key="ac444296e8214e2986576dffe4d3e328:0"&gt;favorite desktop operating system&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="b79faa4de8a8440f8f4b7b3c5f254a64"&gt;&lt;span data-offset-key="b79faa4de8a8440f8f4b7b3c5f254a64:0"&gt;.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-key="37fc7cb50ac44db6996bb60981606227"&gt;&lt;span&gt;&lt;span data-key="e90f8efc12444e00b02fee26cabf88e0"&gt;&lt;span data-offset-key="e90f8efc12444e00b02fee26cabf88e0:0"&gt;I do wish to expand my horizons and try out Linux more. I doubt I will ever be able to move to another operating system as I have too much invested in optimizing and using macOS but I do want to take the best of all worlds. Linux is open source, has an increasingly large community of users and developers and one thing that I love about UNIX systems is that by using these systems you effectively become a developer. Because otherwise you are simply missing out on the &lt;/span&gt;&lt;span data-offset-key="e90f8efc12444e00b02fee26cabf88e0:1"&gt;&lt;em data-slate-leaf="true"&gt;full experience&lt;/em&gt;&lt;/span&gt;&lt;span data-offset-key="e90f8efc12444e00b02fee26cabf88e0:2"&gt;.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2 data-key="b0289f4fc3ef4b87b723fa10b639af64" id="clean-install"&gt;&lt;p&gt;&lt;span&gt;&lt;span data-key="edd2211540a948c3b578d36ca77cecda"&gt;&lt;span data-offset-key="edd2211540a948c3b578d36ca77cecda:0"&gt;Clean install&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href="#clean-install"&gt;&lt;span&gt;&lt;svg stroke="currentColor" stroke-linejoin="round" stroke-linecap="round" stroke-width="2" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" fill="none" width="1em" height="1em" preserveAspectRatio="xMidYMid meet"&gt;&lt;g&gt;&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"&gt;&lt;/path&gt;&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"&gt;&lt;/path&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/h2&gt;&lt;p data-key="e15f280d78cf486ab331c3a387becae5"&gt;&lt;span&gt;&lt;span data-key="d8e0b386b848478f80b8f60ecd429327"&gt;&lt;span data-offset-key="d8e0b386b848478f80b8f60ecd429327:0"&gt;You can clean install by going to Recovery mode (restart with &lt;/span&gt;&lt;span data-offset-key="d8e0b386b848478f80b8f60ecd429327:1"&gt;&lt;code data-slate-leaf="true" spellcheck="false"&gt;cmd+r&lt;/code&gt;&lt;/span&gt;&lt;span data-offset-key="d8e0b386b848478f80b8f60ecd429327:2"&gt; pressed). Then Disk Utility &amp;gt; Select disk &amp;gt; Erase (Format it) &amp;gt; Close Disk Utility &amp;gt; Select option Reinstall MacOS (Choose macOS ver. to install).&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2 data-key="4c33aac6089049278ee168a947a0a0ee" id="notes"&gt;&lt;p&gt;&lt;span&gt;&lt;span data-key="b89fc866f4794e2f860b4298af7dc9db"&gt;&lt;span data-offset-key="b89fc866f4794e2f860b4298af7dc9db:0"&gt;Notes&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href="#notes"&gt;&lt;span&gt;&lt;svg stroke="currentColor" stroke-linejoin="round" stroke-linecap="round" stroke-width="2" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" fill="none" width="1em" height="1em" preserveAspectRatio="xMidYMid meet"&gt;&lt;g&gt;&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"&gt;&lt;/path&gt;&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"&gt;&lt;/path&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/h2&gt;&lt;ul data-key="021f10557fed48ac84932ffd12713d41"&gt;&lt;li&gt;&lt;div data-key="6e4b2f2cc1b04094884a583da0645500"&gt;&lt;p data-key="cd062a6b431341ecbb49b53274995e9a"&gt;&lt;span&gt;&lt;span data-key="9ce8514337c54d4f91f01d8e6c337ae8"&gt;&lt;span data-offset-key="9ce8514337c54d4f91f01d8e6c337ae8:0"&gt;In save dialogues I can press these keys:&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul data-key="54ede13d5c4b4741b5a47c7de4e744b8"&gt;&lt;li&gt;&lt;p data-key="57edbebe38644b6081fde4517f0d438f"&gt;&lt;span&gt;&lt;span data-key="38bbd6632b4d4310979af2c051aee676"&gt;&lt;span data-offset-key="38bbd6632b4d4310979af2c051aee676:0"&gt;&lt;code data-slate-leaf="true" spellcheck="false"&gt;Return&lt;/code&gt;&lt;/span&gt;&lt;span data-offset-key="38bbd6632b4d4310979af2c051aee676:1"&gt; or &lt;/span&gt;&lt;span data-offset-key="38bbd6632b4d4310979af2c051aee676:2"&gt;&lt;code data-slate-leaf="true" spellcheck="false"&gt;⌘ + S&lt;/code&gt;&lt;/span&gt;&lt;span data-offset-key="38bbd6632b4d4310979af2c051aee676:3"&gt; = Save&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="b1edbe39b7b14590b999f317978c88b0"&gt;&lt;span&gt;&lt;span data-key="028ba4bdf054482bb598c9d8a24cc307"&gt;&lt;span data-offset-key="028ba4bdf054482bb598c9d8a24cc307:0"&gt;&lt;code data-slate-leaf="true" spellcheck="false"&gt;ESC&lt;/code&gt;&lt;/span&gt;&lt;span data-offset-key="028ba4bdf054482bb598c9d8a24cc307:1"&gt; = Cancel&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="e5c85ecc735e46e69d17ff1cc472ed6b"&gt;&lt;span&gt;&lt;span data-key="a295b173fdcf46b4a6989a56a7a40e31"&gt;&lt;span data-offset-key="a295b173fdcf46b4a6989a56a7a40e31:0"&gt;I can also press &lt;/span&gt;&lt;span data-offset-key="a295b173fdcf46b4a6989a56a7a40e31:1"&gt;&lt;code data-slate-leaf="true" spellcheck="false"&gt;/&lt;/code&gt;&lt;/span&gt;&lt;span data-offset-key="a295b173fdcf46b4a6989a56a7a40e31:2"&gt; or &lt;/span&gt;&lt;span data-offset-key="a295b173fdcf46b4a6989a56a7a40e31:3"&gt;&lt;code data-slate-leaf="true" spellcheck="false"&gt;~&lt;/code&gt;&lt;/span&gt;&lt;span data-offset-key="a295b173fdcf46b4a6989a56a7a40e31:4"&gt; to quickly go to some directory from a save dialogue. And I can press &lt;/span&gt;&lt;span data-offset-key="a295b173fdcf46b4a6989a56a7a40e31:5"&gt;&lt;code data-slate-leaf="true" spellcheck="false"&gt;⌘ + ↑&lt;/code&gt;&lt;/span&gt;&lt;span data-offset-key="a295b173fdcf46b4a6989a56a7a40e31:6"&gt; to go to &lt;/span&gt;&lt;span data-offset-key="a295b173fdcf46b4a6989a56a7a40e31:7"&gt;&lt;code data-slate-leaf="true" spellcheck="false"&gt;parent directory&lt;/code&gt;&lt;/span&gt;&lt;span data-offset-key="a295b173fdcf46b4a6989a56a7a40e31:8"&gt;.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="b6fcd8fd4c8c49d6a06a22d6d9c9beac"&gt;&lt;span&gt;&lt;span data-key="39f9dca6ecfa4aa4b44fa23497b3a505"&gt;&lt;span data-offset-key="39f9dca6ecfa4aa4b44fa23497b3a505:0"&gt;Recovery mode: Power off the machine, press the power button and immediately hold Cmd-R.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;div data-key="3547d39b3204492c8adec7ef22b370fd"&gt;&lt;p data-key="d21179c39e964cd895b7e405ba3c9ba9"&gt;&lt;span&gt;&lt;span data-key="060a01ce1d55414c86945cad81642628"&gt;&lt;span data-offset-key="060a01ce1d55414c86945cad81642628:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="e66eef379f8e4bffbe0b274e2793fd15" rel="noopener noreferrer" href="https://www.reddit.com/r/MacOS/comments/90g4h9/is_it_worth_the_effort_to_do_a_clean_install_of/"&gt;&lt;span data-key="23b9f12c3e44441685693b8041d2d5e4"&gt;&lt;span data-offset-key="23b9f12c3e44441685693b8041d2d5e4:0"&gt;Both Windows and MacOS are at a point where clean installs are unnecessary.&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="db8ffb180cfa421d882cf742a76bb245"&gt;&lt;span data-offset-key="db8ffb180cfa421d882cf742a76bb245:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul data-key="9541f764d08f42299b208873dbc692ed"&gt;&lt;li&gt;&lt;p data-key="35a52e4b4b554349967b6375b8b4464c"&gt;&lt;span&gt;&lt;span data-key="25e21f2a0ebb4ba39dd130401569f00b"&gt;&lt;span data-offset-key="25e21f2a0ebb4ba39dd130401569f00b:0"&gt;I can appreciate someone wanting to do a clean install if they've installed and removed many apps and just want to clear out everything spread around all the system and hidden folders, even if it doesn't really affect performance and won't save a ton of disk space. There is something cathartic about a clean install.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="8a5522899a1f42b3a4df489c59348010"&gt;&lt;span&gt;&lt;span data-key="9a3fe888eb0f44929c24f47b70ded087"&gt;&lt;span data-offset-key="9a3fe888eb0f44929c24f47b70ded087:0"&gt;&lt;code data-slate-leaf="true" spellcheck="false"&gt;/usr/local/bin&lt;/code&gt;&lt;/span&gt;&lt;span data-offset-key="9a3fe888eb0f44929c24f47b70ded087:1"&gt; is a good place to put raw binaries available in the path, that are not installed with Nix.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;div data-key="834a401315ad4596a2efca5e7beb824c"&gt;&lt;p data-key="9faa511475114a8e901ee67234f422f9"&gt;&lt;span&gt;&lt;span data-key="0d1252a8524c4326818428ba59e8bc47"&gt;&lt;span data-offset-key="0d1252a8524c4326818428ba59e8bc47:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="974d92f7ddf24bc6a41da0f4e4563329" rel="noopener noreferrer" href="https://github.com/golang/go/issues/42684"&gt;&lt;span data-key="3c04f4df216a4a16963c1c46f88cb070"&gt;&lt;span data-offset-key="3c04f4df216a4a16963c1c46f88cb070:0"&gt;To code sign binaries ad hoc, run &lt;/span&gt;&lt;span data-offset-key="3c04f4df216a4a16963c1c46f88cb070:1"&gt;&lt;code data-slate-leaf="true" spellcheck="false"&gt;codesign -s - &amp;lt;path_to_binary&amp;gt;&lt;/code&gt;&lt;/span&gt;&lt;span data-offset-key="3c04f4df216a4a16963c1c46f88cb070:2"&gt;.&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="39d2547b8660458bb4d2c4d302a01cfa"&gt;&lt;span data-offset-key="39d2547b8660458bb4d2c4d302a01cfa:0"&gt; This will give users a gatekeeper warning but they could still run the binary. To sign so users can run binary without warning, you need Apple developer account.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-key="c8dfc7e7260b4464aedd5d1bac0f8d61"&gt;&lt;p&gt;&lt;span&gt;&lt;span data-key="b09aa76dc73c4edba0ff4cacc39dbbf5"&gt;&lt;span data-offset-key="b09aa76dc73c4edba0ff4cacc39dbbf5:0"&gt;Links&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href="#links"&gt;&lt;span&gt;&lt;svg stroke="currentColor" stroke-linejoin="round" stroke-linecap="round" stroke-width="2" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" fill="none" width="1em" height="1em" preserveAspectRatio="xMidYMid meet"&gt;&lt;g&gt;&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"&gt;&lt;/path&gt;&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"&gt;&lt;/path&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/h2&gt;&lt;ul data-key="99c13fd3c22a4843a23d8d0466d4d3a7"&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;div data-key="02abfe5491204256b2e571743b898d40"&gt;&lt;p data-key="692da1de9d20456ea732a5191291e24b"&gt;&lt;span&gt;&lt;span data-key="b9259bdb3c2e41f48335c7b2cc6efbcf"&gt;&lt;span data-offset-key="b9259bdb3c2e41f48335c7b2cc6efbcf:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="cc892b8bba084b79bbc4716bebbe38e1" rel="noopener noreferrer" href="https://github.com/pirate/mac-keyboard-brightness"&gt;&lt;span data-key="842a182d87484d3dbd2b9cdce0fb3a48"&gt;&lt;span data-offset-key="842a182d87484d3dbd2b9cdce0fb3a48:0"&gt;Control Mac Keyboard Brightness&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="4c13dc7c573f4924a88e9bc95876e921"&gt;&lt;span data-offset-key="4c13dc7c573f4924a88e9bc95876e921:0"&gt; - Programmatically flash the keyboard lights and control display brightness on Macs.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li&gt;&lt;div data-key="d06f8943223b47378e052669127dd54e"&gt;&lt;p data-key="f7a315c3473d4d46a77629cd31f7deae"&gt;&lt;span&gt;&lt;span data-key="4971f1bdcc4c4fc6a2fe3d3c0a525471"&gt;&lt;span data-offset-key="4971f1bdcc4c4fc6a2fe3d3c0a525471:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="ded916c5e5154a43a48f967f2983ab9e" rel="noopener noreferrer" href="https://github.com/HazCod/maclaunch"&gt;&lt;span data-key="0c2ce51a1d23431486f3494b2ba73eaf"&gt;&lt;span data-offset-key="0c2ce51a1d23431486f3494b2ba73eaf:0"&gt;maclaunchmaclaunch&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="61d1b19e31b3493c873aabea83eca3cf"&gt;&lt;span data-offset-key="61d1b19e31b3493c873aabea83eca3cf:0"&gt; - Manage your macOS startup items.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="c63bb28971e14641a73576a4ddb7b41f"&gt;&lt;span&gt;&lt;span data-key="ddcd4e6cf7474988b8a299bf0a0bcb4f"&gt;&lt;span data-offset-key="ddcd4e6cf7474988b8a299bf0a0bcb4f:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="a51b9bf978e94f31a7a6ad8198e609df" rel="noopener noreferrer" href="https://www.objective-see.com/"&gt;&lt;span data-key="32fc0c99b4ff414fbb594b9da41f9a9b"&gt;&lt;span data-offset-key="32fc0c99b4ff414fbb594b9da41f9a9b:0"&gt;Objective-See&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="8fca8892369e445c940989af24da481e"&gt;&lt;span data-offset-key="8fca8892369e445c940989af24da481e:0"&gt; - Simple, yet effective macOS security tools.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="e2aab131bc324c5b88a9c452c55c1ab4"&gt;&lt;span&gt;&lt;span data-key="f5e2e4c8b21241acad306a89355a1ca4"&gt;&lt;span data-offset-key="f5e2e4c8b21241acad306a89355a1ca4:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="cb7572fc965d466989bceec25b47cea9" rel="noopener noreferrer" href="https://github.com/mxcl/AppUpdater"&gt;&lt;span data-key="2cd286b316ca4d66af67584971327f60"&gt;&lt;span data-offset-key="2cd286b316ca4d66af67584971327f60:0"&gt;AppUpdater&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="f2cf510ea7ac4faf9cd08923928840fb"&gt;&lt;span data-offset-key="f2cf510ea7ac4faf9cd08923928840fb:0"&gt; - Simple app-updater for macOS, checks your GitHub releases for a binary asset once a day and silently updates your app.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="22fbbf80716e4c46bbd6075caf429681"&gt;&lt;span&gt;&lt;span data-key="26da0464218a4731b0f67e3f06812504"&gt;&lt;span data-offset-key="26da0464218a4731b0f67e3f06812504:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="419dbd420f514b0ea509a418cac735e9" rel="noopener noreferrer" href="https://github.com/pedrommcarrasco/Brooklyn"&gt;&lt;span data-key="73d0b6c573b540b5b27da8c37a9ff775"&gt;&lt;span data-offset-key="73d0b6c573b540b5b27da8c37a9ff775:0"&gt;Brooklyn&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="d003484eb5654515a278a2fa361b17bf"&gt;&lt;span data-offset-key="d003484eb5654515a278a2fa361b17bf:0"&gt; - Screensaver inspired by Apple's Event on October 30, 2018.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="e057f977b9894ed88fee79fed240cbc1"&gt;&lt;span&gt;&lt;span data-key="3690c93daecd4ab88d6a9559aad8e83f"&gt;&lt;span data-offset-key="3690c93daecd4ab88d6a9559aad8e83f:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="8619c74820864ff594dce42192ed9073" rel="noopener noreferrer" href="https://github.com/PureDarwin/PureDarwin"&gt;&lt;span data-key="85c622b479d14098b8fe0b66a0f38ae4"&gt;&lt;span data-offset-key="85c622b479d14098b8fe0b66a0f38ae4:0"&gt;PureDarwin&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="782e4bf268014a4ab3b5cc34f9cac34c"&gt;&lt;span data-offset-key="782e4bf268014a4ab3b5cc34f9cac34c:0"&gt; - Community project to make Darwin more usable. (&lt;/span&gt;&lt;/span&gt;&lt;a data-key="030e4c3e4d904ccbac8bae36d402d219" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=23799331"&gt;&lt;span data-key="e0bfd49b1b784ceaad9ac82530e69932"&gt;&lt;span data-offset-key="e0bfd49b1b784ceaad9ac82530e69932:0"&gt;HN&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="1ba8042a738045a69b898508e6baf22d"&gt;&lt;span data-offset-key="1ba8042a738045a69b898508e6baf22d:0"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="c5ff45193afd43b58f538e62a3f27a43"&gt;&lt;span&gt;&lt;span data-key="98155080e2584f34bdf73fdad5491b52"&gt;&lt;span data-offset-key="98155080e2584f34bdf73fdad5491b52:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="6bd6b4c4b8cc418e9a12f3c91c5ac248" rel="noopener noreferrer" href="https://www.objective-see.com/products/blockblock.html"&gt;&lt;span data-key="6b2f02a5e7584a15991bf7e77da6ecff"&gt;&lt;span data-offset-key="6b2f02a5e7584a15991bf7e77da6ecff:0"&gt;BlockBlock&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="f27febd1239a4ac6bf9cbc1dd5760da1"&gt;&lt;span data-offset-key="f27febd1239a4ac6bf9cbc1dd5760da1:0"&gt; - Continually monitors common persistence locations and displays an alert whenever a persistent component is added to the OS.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="ba0551715886474c875fbaee72c3a432"&gt;&lt;span&gt;&lt;span data-key="016ad8d8a4ba43c19b47cb29c492cf1f"&gt;&lt;span data-offset-key="016ad8d8a4ba43c19b47cb29c492cf1f:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="b426528369db4b52b679e6aac674f9b2" rel="noopener noreferrer" href="https://github.com/ChimeHQ/Impact"&gt;&lt;span data-key="386c5d18319f49fd9c174ae814421774"&gt;&lt;span data-offset-key="386c5d18319f49fd9c174ae814421774:0"&gt;Impact&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="783640fcae3c4be999445423ea7397ac"&gt;&lt;span data-offset-key="783640fcae3c4be999445423ea7397ac:0"&gt; - Crash detection and recording library for Apple platforms.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="b97c8cd5596741f5ab0408668c02ccfd"&gt;&lt;span&gt;&lt;span data-key="f07f608a8cdc4eed971ab51c04d68ae2"&gt;&lt;span data-offset-key="f07f608a8cdc4eed971ab51c04d68ae2:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="7985d575aa704a00b9e41bdf2c7bac5d" rel="noopener noreferrer" href="https://github.com/mitchellh/gon"&gt;&lt;span data-key="ddc65a49de3a402fbaa49e4984216d3d"&gt;&lt;span data-offset-key="ddc65a49de3a402fbaa49e4984216d3d:0"&gt;gon&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="119e504be5914255971748c481a9b969"&gt;&lt;span data-offset-key="119e504be5914255971748c481a9b969:0"&gt; - CLI and Go Library for macOS Notarization.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="d30be566c1b14ad6ba53b5f38960a979"&gt;&lt;span&gt;&lt;span data-key="8ecb732ad6f242c1a11d7946d5db289e"&gt;&lt;span data-offset-key="8ecb732ad6f242c1a11d7946d5db289e:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="e8152e79265b4d90ae15fccdf3e0c28f" rel="noopener noreferrer" href="https://github.com/w0lfschild/macOS_headers"&gt;&lt;span data-key="e1df6c80df7e4d79a96e9ae31cacbefc"&gt;&lt;span data-offset-key="e1df6c80df7e4d79a96e9ae31cacbefc:0"&gt;macOS Headers&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="100474f9ecda49098bf8d49fbf18f3b9"&gt;&lt;span data-offset-key="100474f9ecda49098bf8d49fbf18f3b9:0"&gt; - Consistently maintained dump of most macOS Headers.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="61fc025bf58c4e64a90135dda8e7d67d"&gt;&lt;span&gt;&lt;span data-key="85efd93a4a294fc2b82e0346e3482200"&gt;&lt;span data-offset-key="85efd93a4a294fc2b82e0346e3482200:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="dbdf39fe216a45ae9761f55ea8bd9639" rel="noopener noreferrer" href="https://github.com/OskarGroth/AppMover"&gt;&lt;span data-key="ac4e22542fa14d75acdb96af9bff3f71"&gt;&lt;span data-offset-key="ac4e22542fa14d75acdb96af9bff3f71:0"&gt;AppMover&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="9ebd36d04a8f4e7db680984b579e63f7"&gt;&lt;span data-offset-key="9ebd36d04a8f4e7db680984b579e63f7:0"&gt; - Framework for moving your application bundle to Applications folder on launch.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="8286a3a03607438b9d668a0c1f8bec4b"&gt;&lt;span&gt;&lt;span data-key="72b9cf33c00f4091bde848feda0fbffb"&gt;&lt;span data-offset-key="72b9cf33c00f4091bde848feda0fbffb:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="a24eeea77c74412ca090f8fcd4b703b3" rel="noopener noreferrer" href="https://github.com/acidanthera/Lilu"&gt;&lt;span data-key="a2b214239f684a1d9ac536b378d5ed06"&gt;&lt;span data-offset-key="a2b214239f684a1d9ac536b378d5ed06:0"&gt;Lilu&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="b976144ac4f24d68b30104968109c48c"&gt;&lt;span data-offset-key="b976144ac4f24d68b30104968109c48c:0"&gt; - Arbitrary kext and process patching on macOS.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="2dd1ba124e574ea8a5e611cfcf8dd377"&gt;&lt;span&gt;&lt;span data-key="3ecd18c07cf645d69b5e39f84ed0e7ec"&gt;&lt;span data-offset-key="3ecd18c07cf645d69b5e39f84ed0e7ec:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="43a9579142b140038d7a073cb54d0777" rel="noopener noreferrer" href="https://github.com/pqrs-org/osx-hid-inspector"&gt;&lt;span data-key="42ad0e2db86b4f4784e496bff904d77f"&gt;&lt;span data-offset-key="42ad0e2db86b4f4784e496bff904d77f:0"&gt;osx-hid-inspector&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="983bbd8f8dda438ba771d38fc2517f7c"&gt;&lt;span data-offset-key="983bbd8f8dda438ba771d38fc2517f7c:0"&gt; - Command line tool for macOS for inspecting human input devices (HID).&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="f3eb841887c04ec0a327c55e995d6c27"&gt;&lt;span&gt;&lt;span data-key="7f3bc4f65e63496a977b3990d7ba2496"&gt;&lt;span data-offset-key="7f3bc4f65e63496a977b3990d7ba2496:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="ee1c2774da3d4ee98f86eca74d0d9264" rel="noopener noreferrer" href="https://github.com/mas-cli/mas"&gt;&lt;span data-key="2ee8e49299f444449f615a6ac90d488d"&gt;&lt;span data-offset-key="2ee8e49299f444449f615a6ac90d488d:0"&gt;mas-cli&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="1019a6a686be43649a3f8bd9153422bc"&gt;&lt;span data-offset-key="1019a6a686be43649a3f8bd9153422bc:0"&gt; - Simple command line interface for the Mac App Store. Designed for scripting and automation.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="918ba8d3b5654ee09e0f722bec4a8dda"&gt;&lt;span&gt;&lt;span data-key="8e8f197aaa0b4becb21e8fccfdb0b67b"&gt;&lt;span data-offset-key="8e8f197aaa0b4becb21e8fccfdb0b67b:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="e8ee67202d99455386dc87d9bd49b720" rel="noopener noreferrer" href="https://github.com/zero-sh/apply-user-defaults"&gt;&lt;span data-key="e5066504e59d4f52ae5fe82fb791b621"&gt;&lt;span data-offset-key="e5066504e59d4f52ae5fe82fb791b621:0"&gt;apply-user-defaults&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="4c078a173e8844e094fa6a4bb4815bf6"&gt;&lt;span data-offset-key="4c078a173e8844e094fa6a4bb4815bf6:0"&gt; - Small utility to set macOS user defaults declaratively from a YAML file.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="c941046094d64d139e2e49dade732bee"&gt;&lt;span&gt;&lt;span data-key="8c15d8bdf4fe4eb7899ef244301208f5"&gt;&lt;span data-offset-key="8c15d8bdf4fe4eb7899ef244301208f5:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="19180b2f00ee4b44a2e95178a9b68470" rel="noopener noreferrer" href="https://github.com/zero-sh/zero.sh"&gt;&lt;span data-key="57895f7f25fa40c5b03c617f8e372023"&gt;&lt;span data-offset-key="57895f7f25fa40c5b03c617f8e372023:0"&gt;Zero.sh&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="35b69b66824849a6a49140e0ad6aef89"&gt;&lt;span data-offset-key="35b69b66824849a6a49140e0ad6aef89:0"&gt; - Radically simple personal bootstrapping tool for macOS.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;div data-key="eb8fbba2781444e294cf6c0e79671d83"&gt;&lt;p data-key="8094c0771f8843afb18a1b67ab30634c"&gt;&lt;span&gt;&lt;span data-key="54e41f723acf450ba2ac4f137406a3a5"&gt;&lt;span data-offset-key="54e41f723acf450ba2ac4f137406a3a5:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="2308e90966c347658cdb84da56ab6acb" rel="noopener noreferrer" href="https://tyler.io/default-app-for-mac-ios/"&gt;&lt;span data-key="cd6ef22b965741239e86895257cd2471"&gt;&lt;span data-offset-key="cd6ef22b965741239e86895257cd2471:0"&gt;DefaultApp&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="a91d991ae8ad48508b85d39fd88bfdf0"&gt;&lt;span data-offset-key="a91d991ae8ad48508b85d39fd88bfdf0:0"&gt; - Template for starting macOS projects. (&lt;/span&gt;&lt;/span&gt;&lt;a data-key="6a58cf489eb04765990d74a820e1a6bb" rel="noopener noreferrer" href="https://github.com/tylerhall/DefaultApp"&gt;&lt;span data-key="b9d69ca85e4d486d8ae0cee8e2508413"&gt;&lt;span data-offset-key="b9d69ca85e4d486d8ae0cee8e2508413:0"&gt;Code&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="f48bd55bda04492595cf00123c4c651b"&gt;&lt;span data-offset-key="f48bd55bda04492595cf00123c4c651b:0"&gt;) (&lt;/span&gt;&lt;/span&gt;&lt;a data-key="45e860e512a542ff8c8315665407df3d" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=22582456"&gt;&lt;span data-key="b02714688ed74ab68dc129c7ce25d12e"&gt;&lt;span data-offset-key="b02714688ed74ab68dc129c7ce25d12e:0"&gt;HN&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="74237959dd4a48bb8cb41884ea4c0bff"&gt;&lt;span data-offset-key="74237959dd4a48bb8cb41884ea4c0bff:0"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="60aa76897f544f0e8dda034aef9e7ea0"&gt;&lt;span&gt;&lt;span data-key="6e382b35bfdc4cf9adac4c3edfde953c"&gt;&lt;span data-offset-key="6e382b35bfdc4cf9adac4c3edfde953c:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="8e8e9f9486ae43babd3d52c090d66bfc" rel="noopener noreferrer" href="https://github.com/ExistentialAudio/BlackHole"&gt;&lt;span data-key="66757c2b52a847bdbcd475897fd36e69"&gt;&lt;span data-offset-key="66757c2b52a847bdbcd475897fd36e69:0"&gt;BlackHole&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="e96cb0368601464c8c6b160a5b266ab1"&gt;&lt;span data-offset-key="e96cb0368601464c8c6b160a5b266ab1:0"&gt; - Modern MacOS virtual audio driver that allows applications to pass audio to other applications with zero additional latency.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="a5d7d36df4c5451e879f0fad38527d40"&gt;&lt;span&gt;&lt;span data-key="72431b950d494bf38b7da15d52d0c94a"&gt;&lt;span data-offset-key="72431b950d494bf38b7da15d52d0c94a:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="3fc38e00f7a347849078eeb989507ba3" rel="noopener noreferrer" href="https://github.com/akeru-inc/xcnotary"&gt;&lt;span data-key="510aab83d3954e0b828165e8fb7a9fc0"&gt;&lt;span data-offset-key="510aab83d3954e0b828165e8fb7a9fc0:0"&gt;xcnotary&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="e4fedcf563e44507b919e403f995fd13"&gt;&lt;span data-offset-key="e4fedcf563e44507b919e403f995fd13:0"&gt; - Missing macOS app notarization helper, built with Rust. (&lt;/span&gt;&lt;/span&gt;&lt;a data-key="2da3bc5df71849c2b0394f0769b708b9" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=22743659"&gt;&lt;span data-key="b065498ca15445e086420c5160faba12"&gt;&lt;span data-offset-key="b065498ca15445e086420c5160faba12:0"&gt;HN&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="10274606229b4248a518e457fd827acb"&gt;&lt;span data-offset-key="10274606229b4248a518e457fd827acb:0"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="1f7c59b8bec6477a866b97ca0381d555"&gt;&lt;span&gt;&lt;span data-key="6ede299043e84784b6ef9e2a38bd11a9"&gt;&lt;span data-offset-key="6ede299043e84784b6ef9e2a38bd11a9:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="68347ef735004c45a6a34917d41f76ab" rel="noopener noreferrer" href="https://github.com/koekeishiya/skhd"&gt;&lt;span data-key="929dbe8834e944c489216d381670c267"&gt;&lt;span data-offset-key="929dbe8834e944c489216d381670c267:0"&gt;skhd&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="26119172ce294d019beb2abe67b927d7"&gt;&lt;span data-offset-key="26119172ce294d019beb2abe67b927d7:0"&gt; - Simple hotkey daemon for macOS.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="03ad31db7e9f4ccf93c10daee3ecfe6d"&gt;&lt;span&gt;&lt;span data-key="48839197e029440daeb133fe0fea9659"&gt;&lt;span data-offset-key="48839197e029440daeb133fe0fea9659:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="4bc3b88c4f7740928fc1e95e2ffe7cf4" rel="noopener noreferrer" href="https://github.com/briankendall/proxy-audio-device"&gt;&lt;span data-key="c28a8a6108ad45d483efefa2f1bdae8e"&gt;&lt;span data-offset-key="c28a8a6108ad45d483efefa2f1bdae8e:0"&gt;Proxy Audio Driver&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="ecdda68223e647298e567bffdaaaab5f"&gt;&lt;span data-offset-key="ecdda68223e647298e567bffdaaaab5f:0"&gt; - Virtual audio driver for macOS to sends all audio to another output.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="73e9a43370a3405f82069f008825a264"&gt;&lt;span&gt;&lt;span data-key="05db82d9beff467096c33c489171e816"&gt;&lt;span data-offset-key="05db82d9beff467096c33c489171e816:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="fff15348d1984645bee7d7234d05bb76" rel="noopener noreferrer" href="https://github.com/SAP/macOS-icon-generator"&gt;&lt;span data-key="99f589b050544f8a990ad24f6cdb1f4f"&gt;&lt;span data-offset-key="99f589b050544f8a990ad24f6cdb1f4f:0"&gt;Icons.app&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="ba1bc0ccc75e44b08f6434d33095aefb"&gt;&lt;span data-offset-key="ba1bc0ccc75e44b08f6434d33095aefb:0"&gt; - App for macOS which is designed to generate consistent sized icons of an existing application in various states, jiggling (shaking) etc.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="ef494804f7ed49d2aafdd162efd0b309"&gt;&lt;span&gt;&lt;span data-key="2a840b8202364cff84389b93df8e6fcc"&gt;&lt;span data-offset-key="2a840b8202364cff84389b93df8e6fcc:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="15a3079742794124aa2d7bd44d75835f" rel="noopener noreferrer" href="https://dortania.github.io/OpenCore-Desktop-Guide/"&gt;&lt;span data-key="2df4ef4c765b4addb4b4a09aba15fd31"&gt;&lt;span data-offset-key="2df4ef4c765b4addb4b4a09aba15fd31:0"&gt;OpenCore&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="9a2a5a6689414ef787eac57b15fd37c1"&gt;&lt;span data-offset-key="9a2a5a6689414ef787eac57b15fd37c1:0"&gt; - Open-source, unconventional, first-in-class piece of software designed to intercept kernel loading to insert a highly advanced rootkit, designed to be an alternative to Clover. (&lt;/span&gt;&lt;/span&gt;&lt;a data-key="115eb5f6f67c44119edcbb6967af83e1" rel="noopener noreferrer" href="https://github.com/dortania/OpenCore-Desktop-Guide"&gt;&lt;span data-key="090f11b4b88e46a1bf70a54348c3b860"&gt;&lt;span data-offset-key="090f11b4b88e46a1bf70a54348c3b860:0"&gt;Code&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="f1d1d21873ce4681863f30f70e8c4bcd"&gt;&lt;span data-offset-key="f1d1d21873ce4681863f30f70e8c4bcd:0"&gt;) (&lt;/span&gt;&lt;/span&gt;&lt;a data-key="a9258f410553489d89458f65d4bc37d7" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=22916281"&gt;&lt;span data-key="91c07e406d2c48dd88db38085f7e2716"&gt;&lt;span data-offset-key="91c07e406d2c48dd88db38085f7e2716:0"&gt;HN&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="79e7dde9fcbb4bff846a18e6f924f646"&gt;&lt;span data-offset-key="79e7dde9fcbb4bff846a18e6f924f646:0"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="396f313e03f24066a8df42afbb2435d7"&gt;&lt;span&gt;&lt;span data-key="6efff378514041f488a2ef4f01029b38"&gt;&lt;span data-offset-key="6efff378514041f488a2ef4f01029b38:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="ba228e618ef14e86a8dfd6c5d8375c8f" rel="noopener noreferrer" href="https://github.com/Syphon/Syphon-Framework"&gt;&lt;span data-key="b793789b8a41498091b34a5d825936d2"&gt;&lt;span data-offset-key="b793789b8a41498091b34a5d825936d2:0"&gt;Syphon&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="575044ff203d48e193c21c262206e0a0"&gt;&lt;span data-offset-key="575044ff203d48e193c21c262206e0a0:0"&gt; - macOS technology to allow applications to share video and still images with one another in realtime, instantly.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;div data-key="9bd15a37282e42878738313d24fb1299"&gt;&lt;p data-key="48526906dd8f4bb0a4565b8a62d61aae"&gt;&lt;span&gt;&lt;span data-key="bead5fcc2a5941b5935413d9cc014da5"&gt;&lt;span data-offset-key="bead5fcc2a5941b5935413d9cc014da5:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="53aec6c6620840c6a3dae183ec51a251" rel="noopener noreferrer" href="https://flow.swiss/mac-bare-metal"&gt;&lt;span data-key="8d994f932fe042b0a76f56fa32a8e747"&gt;&lt;span data-offset-key="8d994f932fe042b0a76f56fa32a8e747:0"&gt;Mac Bare Metal&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="7caa15abb35947d48ee347b8e0665345"&gt;&lt;span data-offset-key="7caa15abb35947d48ee347b8e0665345:0"&gt; - Enterprise-class IaaS for macOS.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li&gt;&lt;div data-key="75a2ed345ccc4292b9a89b5790503b35"&gt;&lt;p data-key="7b687f2129064c688fe32ae59cb3ceb8"&gt;&lt;span&gt;&lt;span data-key="bdf6d0b8d0d343aea48d0606c98741de"&gt;&lt;span data-offset-key="bdf6d0b8d0d343aea48d0606c98741de:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="c9c5e4a8d8a746f29a186c8dcd08a609" rel="noopener noreferrer" href="https://github.com/microsoft/react-native-macos"&gt;&lt;span data-key="0d5dfa136d474e75a0402a68b7829753"&gt;&lt;span data-offset-key="0d5dfa136d474e75a0402a68b7829753:0"&gt;React Native for macOS&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="f258e6b0f25e470898373b3a95704d54"&gt;&lt;span data-offset-key="f258e6b0f25e470898373b3a95704d54:0"&gt; - Build native macOS apps with React. (&lt;/span&gt;&lt;/span&gt;&lt;a data-key="679551907d514e6dbcacc0e17e7c59a3" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=23160075"&gt;&lt;span data-key="47163a283dd24dc48a249a33293c603c"&gt;&lt;span data-offset-key="47163a283dd24dc48a249a33293c603c:0"&gt;HN&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="360b841a5e9f4551be37b6fdd7111617"&gt;&lt;span data-offset-key="360b841a5e9f4551be37b6fdd7111617:0"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="cbf6dff980a7433e9265b5313f93144d"&gt;&lt;span&gt;&lt;span data-key="f80738050dba4e16b86362acab507f87"&gt;&lt;span data-offset-key="f80738050dba4e16b86362acab507f87:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="ce1c51cb7611425885672c9d89d8596f" rel="noopener noreferrer" href="https://github.com/grahamc/netboot.nix"&gt;&lt;span data-key="268251c50e064d5f802ec6f04e49ec65"&gt;&lt;span data-offset-key="268251c50e064d5f802ec6f04e49ec65:0"&gt;netboot.nix&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="e31fc9afa01e4b6c953d0a1a24d3be4b"&gt;&lt;span data-offset-key="e31fc9afa01e4b6c953d0a1a24d3be4b:0"&gt; - Create full netboot images in 15 seconds.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="58f54b2eb54449e9bb193b876e75b00e"&gt;&lt;span&gt;&lt;span data-key="97b77afc444e4ab689b6fe35065a042a"&gt;&lt;span data-offset-key="97b77afc444e4ab689b6fe35065a042a:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="cbfc02309fc54bf2b34d28691d864b98" rel="noopener noreferrer" href="https://github.com/NSExceptional/Swizzle"&gt;&lt;span data-key="e0f31e9ee48b41faa4932f606d632c7f"&gt;&lt;span data-offset-key="e0f31e9ee48b41faa4932f606d632c7f:0"&gt;Swizzle&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="718fae20bb1c40d8bed737961507cd60"&gt;&lt;span data-offset-key="718fae20bb1c40d8bed737961507cd60:0"&gt; - Extensible tweak to create simple tweaks for any app, from within any app.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="c5d1705cd6cb43acbd06502d793d75b0"&gt;&lt;span&gt;&lt;span data-key="f9f279791fdf4a0b902b68a53c7f33c7"&gt;&lt;span data-offset-key="f9f279791fdf4a0b902b68a53c7f33c7:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="40aded1b6c854214b645e23d3b24e455" rel="noopener noreferrer" href="https://github.com/bdrister/AquaticPrime"&gt;&lt;span data-key="892161661243401488d14631f70d4af2"&gt;&lt;span data-offset-key="892161661243401488d14631f70d4af2:0"&gt;AquaticPrime&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="2c6dcf1597784abfbab84682220840ed"&gt;&lt;span data-offset-key="2c6dcf1597784abfbab84682220840ed:0"&gt; - Mac software licensing code using cryptographically signed license files.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="1d0ced250e4346b5b3a91db3c2a92a2b"&gt;&lt;span&gt;&lt;span data-key="a15c756e188f47b9b2717546e0d619ea"&gt;&lt;span data-offset-key="a15c756e188f47b9b2717546e0d619ea:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="3089286e1e6b469da8301d6f7ab71801" rel="noopener noreferrer" href="https://github.com/KhaosT/SimpleVM"&gt;&lt;span data-key="6fbeb7489c9a47bdae3ff6bdb70ef1bd"&gt;&lt;span data-offset-key="6fbeb7489c9a47bdae3ff6bdb70ef1bd:0"&gt;SimpleVM&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="a7301b9f411448c198b0848a4d89ec17"&gt;&lt;span data-offset-key="a7301b9f411448c198b0848a4d89ec17:0"&gt; - Sample code for Virtualization framework. (&lt;/span&gt;&lt;/span&gt;&lt;a data-key="e0262380710e49139299d47b2149f76a" rel="noopener noreferrer" href="https://github.com/danczar/SimpleVM"&gt;&lt;span data-key="999afb56cd35405384bed440f173ab0c"&gt;&lt;span data-offset-key="999afb56cd35405384bed440f173ab0c:0"&gt;Fork&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="19e24260b6584110bd331cb65d7d8908"&gt;&lt;span data-offset-key="19e24260b6584110bd331cb65d7d8908:0"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="f11c54df6df34f63ab605baac2e341e0"&gt;&lt;span&gt;&lt;span data-key="784fd6462aca43c4871ef9fe543bb739"&gt;&lt;span data-offset-key="784fd6462aca43c4871ef9fe543bb739:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="18ea3808191a444593aa1f78b46686dd" rel="noopener noreferrer" href="https://github.com/trailofbits/sinter"&gt;&lt;span data-key="fea8a4d24026401283d02e405af95572"&gt;&lt;span data-offset-key="fea8a4d24026401283d02e405af95572:0"&gt;Sinter&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="71dc8f6d91884f0ca07568fbf0a16456"&gt;&lt;span data-offset-key="71dc8f6d91884f0ca07568fbf0a16456:0"&gt; - User-mode application authorization system for MacOS written in Swift. (&lt;/span&gt;&lt;/span&gt;&lt;a data-key="b66b36d1c449428686a13b36a4684362" rel="noopener noreferrer" href="https://blog.trailofbits.com/2020/08/12/sinter-new-user-mode-security-enforcement-for-macos/"&gt;&lt;span data-key="abacd620887447ffa1ced7cb1717a451"&gt;&lt;span data-offset-key="abacd620887447ffa1ced7cb1717a451:0"&gt;Article&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="86513430a52944eabab44e5b0c49fb07"&gt;&lt;span data-offset-key="86513430a52944eabab44e5b0c49fb07:0"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;div data-key="1eee72d12e7b4435a5826afd38f15982"&gt;&lt;p data-key="49c51636a5464b248a01e07500dfdc5f"&gt;&lt;span&gt;&lt;span data-key="7079b8e4d7d74a0ab12720ba7481fb81"&gt;&lt;span data-offset-key="7079b8e4d7d74a0ab12720ba7481fb81:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="180cabf7c56843178d747db6ee04a35c" rel="noopener noreferrer" href="https://macosicons.com/"&gt;&lt;span data-key="cb67fd47c8fc48d19f93c89905e3b3f0"&gt;&lt;span data-offset-key="cb67fd47c8fc48d19f93c89905e3b3f0:0"&gt;macOS icon pack&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="5ffd9e677ce04ea89c7decf6ba39f477"&gt;&lt;span data-offset-key="5ffd9e677ce04ea89c7decf6ba39f477:0"&gt; - Beautiful open source icons for Big Sur. (&lt;/span&gt;&lt;/span&gt;&lt;a data-key="043afc0ff7b24dbf87f5faa8c43cbc1d" rel="noopener noreferrer" href="https://github.com/elrumo/macOS_Big_Sur_icons_replacements"&gt;&lt;span data-key="145b507b4b3f492fa9aa3286f5e267db"&gt;&lt;span data-offset-key="145b507b4b3f492fa9aa3286f5e267db:0"&gt;Code&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="370bdabbea9f4286824da789c942e731"&gt;&lt;span data-offset-key="370bdabbea9f4286824da789c942e731:0"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="02f999842ecf49afa21ed5162606bc6e"&gt;&lt;span&gt;&lt;span data-key="c1085f8fc1f64a21ae6963fa2afd554f"&gt;&lt;span data-offset-key="c1085f8fc1f64a21ae6963fa2afd554f:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="3295125698f04abeb2c6261656fef517" rel="noopener noreferrer" href="https://github.com/sparkle-project/Sparkle"&gt;&lt;span data-key="aad9f2cf73754651a0bd153eeefb4f78"&gt;&lt;span data-offset-key="aad9f2cf73754651a0bd153eeefb4f78:0"&gt;Sparkle&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="a63e52e60f1d41258ad566a72a096a7e"&gt;&lt;span data-offset-key="a63e52e60f1d41258ad566a72a096a7e:0"&gt; - Software update framework for macOS. (&lt;/span&gt;&lt;/span&gt;&lt;a data-key="18601a69fd6948d987684d86d6d77875" rel="noopener noreferrer" href="https://sparkle-project.org/"&gt;&lt;span data-key="508152a52525426cb531c2ba565073f5"&gt;&lt;span data-offset-key="508152a52525426cb531c2ba565073f5:0"&gt;Web&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="a7bc64787f0d49be86fcebcc234d29cd"&gt;&lt;span data-offset-key="a7bc64787f0d49be86fcebcc234d29cd:0"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="6e1e1d9a9996473cb2b5bf630917e5ed"&gt;&lt;span&gt;&lt;span data-key="49ac5832421f48e2b811be686e13a76e"&gt;&lt;span data-offset-key="49ac5832421f48e2b811be686e13a76e:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="1bad941e148e4f2ca0bfc522f24b5c5f" rel="noopener noreferrer" href="https://github.com/fastai/fastmac/"&gt;&lt;span data-key="2f3052d8fd1641ec9e2cd9b60dc2de8c"&gt;&lt;span data-offset-key="2f3052d8fd1641ec9e2cd9b60dc2de8c:0"&gt;fastmac&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="89a06b4fced14d95933045d1cbbe28bc"&gt;&lt;span data-offset-key="89a06b4fced14d95933045d1cbbe28bc:0"&gt; - MacOS instance or Linux shell. (&lt;/span&gt;&lt;/span&gt;&lt;a data-key="0c2005047e9d400f89bf392ce7938fb1" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=24452384"&gt;&lt;span data-key="a9ec49500d604e3daa80c90112934eac"&gt;&lt;span data-offset-key="a9ec49500d604e3daa80c90112934eac:0"&gt;HN&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="a9594d87be9d45dcb6ff7c3e3ec563ef"&gt;&lt;span data-offset-key="a9594d87be9d45dcb6ff7c3e3ec563ef:0"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="7938c130136e43f2be1d5d6125066411"&gt;&lt;span&gt;&lt;span data-key="7c69fee297a945adb584f562d619f37c"&gt;&lt;span data-offset-key="7c69fee297a945adb584f562d619f37c:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="9174fb5af0bd487a8594640e14a77baa" rel="noopener noreferrer" href="https://github.com/foxlet/macOS-Simple-KVM"&gt;&lt;span data-key="8e1c762122254502959ca39e33069a46"&gt;&lt;span data-offset-key="8e1c762122254502959ca39e33069a46:0"&gt;macOS Simple KVM&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="e6e82eaa2cdc4e159bb7345745742b19"&gt;&lt;span data-offset-key="e6e82eaa2cdc4e159bb7345745742b19:0"&gt; - Tools to set up a quick macOS VM in QEMU, accelerated by KVM.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="4484e3d41b0f487fb9feb0bab0aa2dc0"&gt;&lt;span&gt;&lt;span data-key="f2d85977873549bca6fe0bdc71e57353"&gt;&lt;span data-offset-key="f2d85977873549bca6fe0bdc71e57353:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="d7d0035665244e51919bef4f97fe3f59" rel="noopener noreferrer" href="https://github.com/phatblat/ApplePlatformVersions"&gt;&lt;span data-key="76e0ad555eae4398abcaf6b9440f950f"&gt;&lt;span data-offset-key="76e0ad555eae4398abcaf6b9440f950f:0"&gt;Apple Platform Versions&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="da6423b882c74f01aa5c815980078692"&gt;&lt;span data-offset-key="da6423b882c74f01aa5c815980078692:0"&gt; - Recent history of platforms developed by Apple, including Apple-managed build tools for these platforms.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;div data-key="2ef90e941d764527bf72234a9c76f0d0"&gt;&lt;p data-key="e213028dcf0640e6bed2d14981f6e421"&gt;&lt;span&gt;&lt;span data-key="085a8e88fa044ae29e8f78c4ee388156"&gt;&lt;span data-offset-key="085a8e88fa044ae29e8f78c4ee388156:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="679c0a41a5604a65afeda5e155e3854a" rel="noopener noreferrer" href="https://macos-defaults.com/"&gt;&lt;span data-key="4368802fb34e49e8b13cb4d0f90a1c90"&gt;&lt;span data-offset-key="4368802fb34e49e8b13cb4d0f90a1c90:0"&gt;macOS defaults&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="ae13b883d9414bf39c3ccd51291a9b68"&gt;&lt;span data-offset-key="ae13b883d9414bf39c3ccd51291a9b68:0"&gt; - List of macOS defaults commands with demos. (&lt;/span&gt;&lt;/span&gt;&lt;a data-key="03e689c48e0c4726865431819bad1035" rel="noopener noreferrer" href="https://github.com/yannbertrand/macos-defaults"&gt;&lt;span data-key="77b45f3a4f5d4cdaad218a23c233b2ad"&gt;&lt;span data-offset-key="77b45f3a4f5d4cdaad218a23c233b2ad:0"&gt;Code&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="9be20696278c48ada85fddd33bec1ca3"&gt;&lt;span data-offset-key="9be20696278c48ada85fddd33bec1ca3:0"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="f502ffe6f6a24e119fabbcf113a6499f"&gt;&lt;span&gt;&lt;span data-key="ca8b2760a4034d438e1817f14390311a"&gt;&lt;span data-offset-key="ca8b2760a4034d438e1817f14390311a:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="279f151f3d7d4c938488f8a17fd4de82" rel="noopener noreferrer" href="https://doesitarm.com/"&gt;&lt;span data-key="774c5b390379448f8a4a12c7141d71ee"&gt;&lt;span data-offset-key="774c5b390379448f8a4a12c7141d71ee:0"&gt;Does it ARM&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="9fd684c0faf54f5986a3c2fc74735fe3"&gt;&lt;span data-offset-key="9fd684c0faf54f5986a3c2fc74735fe3:0"&gt; - Apps that are reported to support Apple Silicon. (&lt;/span&gt;&lt;/span&gt;&lt;a data-key="de49887850104aa3a67ec3f5131c23ab" rel="noopener noreferrer" href="https://github.com/ThatGuySam/doesitarm"&gt;&lt;span data-key="0ecaf04e9e9d40f69f90354e5b6e7632"&gt;&lt;span data-offset-key="0ecaf04e9e9d40f69f90354e5b6e7632:0"&gt;Code&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="689ccc8687654d37834deb9f1726a8ed"&gt;&lt;span data-offset-key="689ccc8687654d37834deb9f1726a8ed:0"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="c8f3e63fa61c4485aea4c6bcd4b693b8"&gt;&lt;span&gt;&lt;span data-key="58523a05b1134d958ba897c849923be5"&gt;&lt;span data-offset-key="58523a05b1134d958ba897c849923be5:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="c05cc465238e49e4ac79e99cfe2c9c34" rel="noopener noreferrer" href="https://github.com/create-dmg/create-dmg"&gt;&lt;span data-key="b98a4e6431d944f18d653ff3d7a1b555"&gt;&lt;span data-offset-key="b98a4e6431d944f18d653ff3d7a1b555:0"&gt;create-dmg&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="20698504ac61418ba42a078128a22ac1"&gt;&lt;span data-offset-key="20698504ac61418ba42a078128a22ac1:0"&gt; - Shell script to build fancy DMGs.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;div data-key="e1f2a544da0e481f973e3128ec96594d"&gt;&lt;p data-key="50078222501d400fbd4ed3807cf0c5ec"&gt;&lt;span&gt;&lt;span data-key="fb4d1409d681490a905b49e4c6942fd2"&gt;&lt;span data-offset-key="fb4d1409d681490a905b49e4c6942fd2:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="be8de43765b447f885c92520b7cb2399" rel="noopener noreferrer" href="https://github.com/nico/lssym"&gt;&lt;span data-key="1b9fd08fd1444ffabff7ca9abab3b967"&gt;&lt;span data-offset-key="1b9fd08fd1444ffabff7ca9abab3b967:0"&gt;Mach-O learning tool&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="ee5491c3166649c0aca806291771d317"&gt;&lt;span data-offset-key="ee5491c3166649c0aca806291771d317:0"&gt; - Toy program to learn more about the mach-o file format.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="692bf723d3554578a20c1d6594d4ac0c"&gt;&lt;span&gt;&lt;span data-key="b46c27302fed42baa3a35c2f7905dc8d"&gt;&lt;span data-offset-key="b46c27302fed42baa3a35c2f7905dc8d:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="e1d4ddf3e67a440a8d64bfb0b17098d4" rel="noopener noreferrer" href="https://github.com/iSapozhnik/Popover"&gt;&lt;span data-key="dd6e39aa901d4571aba0555d0dcc6b7c"&gt;&lt;span data-offset-key="dd6e39aa901d4571aba0555d0dcc6b7c:0"&gt;Popover&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="260532a2b787492e968277d1f2b84b13"&gt;&lt;span data-offset-key="260532a2b787492e968277d1f2b84b13:0"&gt; - Custom macOS Popover.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;div data-key="8d095a8151dc41f4a3f2b0600ba46d20"&gt;&lt;p data-key="efb019385ce448119a06dfd4694be1b3"&gt;&lt;span&gt;&lt;span data-key="210823a931f445b6a8aa63fc58c51aec"&gt;&lt;span data-offset-key="210823a931f445b6a8aa63fc58c51aec:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="f19286c3bb784c20a8e9b4d2c623c89a" rel="noopener noreferrer" href="https://github.com/evansm7/vftool"&gt;&lt;span data-key="6acc67a91c9b4c99b10ce275ed2ac82f"&gt;&lt;span data-offset-key="6acc67a91c9b4c99b10ce275ed2ac82f:0"&gt;Virtualization.framework tool (vftool)&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="3147b2ff429e4c8b813178d79143ce6b"&gt;&lt;span data-offset-key="3147b2ff429e4c8b813178d79143ce6b:0"&gt; - Runs Linux virtual machines in macOS. (&lt;/span&gt;&lt;/span&gt;&lt;a data-key="8031cc5f2364415ba2398c93b5277dd5" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=25382529"&gt;&lt;span data-key="932ab0a858c64813a0204ded8892e83e"&gt;&lt;span data-offset-key="932ab0a858c64813a0204ded8892e83e:0"&gt;HN&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="887474ec609447a09d7f6b412f249586"&gt;&lt;span data-offset-key="887474ec609447a09d7f6b412f249586:0"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="a5327f73bb044bc18539f365f72daee9"&gt;&lt;span&gt;&lt;span data-key="031113b6c8c141b290f57c6e9409c38a"&gt;&lt;span data-offset-key="031113b6c8c141b290f57c6e9409c38a:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="ea64ec65d1ea467dacef195ff6ba11e0" rel="noopener noreferrer" href="https://github.com/PraneetNeuro/Project-Mendacius"&gt;&lt;span data-key="752ef7ec69384772a78d3a25f3ed358e"&gt;&lt;span data-offset-key="752ef7ec69384772a78d3a25f3ed358e:0"&gt;Project Mendacius&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="44481f80cf75407c9b9c4ce9a835751b"&gt;&lt;span data-offset-key="44481f80cf75407c9b9c4ce9a835751b:0"&gt; - GUI based virtualization tool for running Linux on macOS Big Sur.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="5cea379135504a6fa29e1e66232b211e"&gt;&lt;span&gt;&lt;span data-key="2bec2ae63cbd4d458b90d4d1b8745f2d"&gt;&lt;span data-offset-key="2bec2ae63cbd4d458b90d4d1b8745f2d:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="dfe4192ecf90481490b3788ba4115812" rel="noopener noreferrer" href="https://github.com/insidegui/dmgdist"&gt;&lt;span data-key="6b79b95459bd487cbd2c7ce765e41b04"&gt;&lt;span data-offset-key="6b79b95459bd487cbd2c7ce765e41b04:0"&gt;dmgdist&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="fd53a99412744bffa5f01607aa54e90f"&gt;&lt;span data-offset-key="fd53a99412744bffa5f01607aa54e90f:0"&gt; - Automate the process of creating, uploading and notarizing the DMG of a Mac app.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="4eab7a1f381f4a47ab390bb8497aa727"&gt;&lt;span&gt;&lt;span data-key="f861ccdf0fe2485089e8fccc6fc7c3a7"&gt;&lt;span data-offset-key="f861ccdf0fe2485089e8fccc6fc7c3a7:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="4c6b33932dec4ff0a316f60609bdf944" rel="noopener noreferrer" href="https://github.com/kendfinger/MacHack"&gt;&lt;span data-key="47caa9686d3d47ee909a32e915ea9017"&gt;&lt;span data-offset-key="47caa9686d3d47ee909a32e915ea9017:0"&gt;MacHack&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="d2d104a94e9a44b7a0c40f4cfdfb2919"&gt;&lt;span data-offset-key="d2d104a94e9a44b7a0c40f4cfdfb2919:0"&gt; - List of built-in tools in macOS that you probably didn't know about.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="b9bc362debaf4774a5b4f79426c99784"&gt;&lt;span&gt;&lt;span data-key="8d906785311149d892993ed049ad9149"&gt;&lt;span data-offset-key="8d906785311149d892993ed049ad9149:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="14fa655d1a7f40a49d76b398dc8a7517" rel="noopener noreferrer" href="https://github.com/theevilbit/Shield"&gt;&lt;span data-key="bada073f2b684c94b73a2797183efc6f"&gt;&lt;span data-offset-key="bada073f2b684c94b73a2797183efc6f:0"&gt;Shield&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="7743957193b442d9b448412e08a2434f"&gt;&lt;span data-offset-key="7743957193b442d9b448412e08a2434f:0"&gt; - App to protect against process injection on macOS. (&lt;/span&gt;&lt;/span&gt;&lt;a data-key="5ec9b87681594d3c9da0346dea69ff8f" rel="noopener noreferrer" href="https://theevilbit.github.io/shield/"&gt;&lt;span data-key="52631424139646c38ab5a0299afa18b2"&gt;&lt;span data-offset-key="52631424139646c38ab5a0299afa18b2:0"&gt;Article&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="791708e2624b454993ad6ead06dd6211"&gt;&lt;span data-offset-key="791708e2624b454993ad6ead06dd6211:0"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="8c410d3fa9004882881a8b4ed6251dba"&gt;&lt;span&gt;&lt;span data-key="7ed78bb010de4f5eb280fe11a67fcff1"&gt;&lt;span data-offset-key="7ed78bb010de4f5eb280fe11a67fcff1:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="7543f1784d4f4e9a8af9c5f6ff67a2ef" rel="noopener noreferrer" href="https://github.com/gyf304/vmcli"&gt;&lt;span data-key="1475656a23d647878974a0fa97ede356"&gt;&lt;span data-offset-key="1475656a23d647878974a0fa97ede356:0"&gt;VMCLI&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="e46c55d7266a454abab982c68593c5d4"&gt;&lt;span data-offset-key="e46c55d7266a454abab982c68593c5d4:0"&gt; - Set of utilities to help you manage VMs with Virtualization.framework. (&lt;/span&gt;&lt;/span&gt;&lt;a data-key="085c82eafe334787b3de5db0e994d155" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=25786640"&gt;&lt;span data-key="e8be8726eac1475488293f6c20ee4a57"&gt;&lt;span data-offset-key="e8be8726eac1475488293f6c20ee4a57:0"&gt;HN&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="ce445a5bcb344663bc51ad71cf01d818"&gt;&lt;span data-offset-key="ce445a5bcb344663bc51ad71cf01d818:0"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="fe8ed9c167df466d9d16073f67a84067"&gt;&lt;span&gt;&lt;span data-key="1d8eb391a1b247ab88e1613c6a6665fb"&gt;&lt;span data-offset-key="1d8eb391a1b247ab88e1613c6a6665fb:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="758b8502877e47248ef23044b70f4737" rel="noopener noreferrer" href="https://github.com/KevinGutowski/SplitConfigurations"&gt;&lt;span data-key="cb1563be889341b58620fadd23d2dd2c"&gt;&lt;span data-offset-key="cb1563be889341b58620fadd23d2dd2c:0"&gt;SplitConfigurations&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="252af045a37a4a30b7f034033c8b9763"&gt;&lt;span data-offset-key="252af045a37a4a30b7f034033c8b9763:0"&gt; - Up the basics of a Big Sur app layout. Includes splitview and toolbarItems.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="ad50f7f901ab498ba40a00c0701690c4"&gt;&lt;span&gt;&lt;span data-key="73c76aa6368649508d3970474d7ee4ad"&gt;&lt;span data-offset-key="73c76aa6368649508d3970474d7ee4ad:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="2b0644f83888462d95c27b5398a3d296" rel="noopener noreferrer" href="https://github.com/niw/TinyLinux"&gt;&lt;span data-key="dc8adf68b49a4396b35c034f767412bc"&gt;&lt;span data-offset-key="dc8adf68b49a4396b35c034f767412bc:0"&gt;TinyLinux&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="aadc92ff44c74412978c9c1df07ba725"&gt;&lt;span data-offset-key="aadc92ff44c74412978c9c1df07ba725:0"&gt; - Tiny minimum implementation of Virtualization framework to boot Linux.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-key="23c39c5c508a4f05ac6434aeb90946ea"&gt;&lt;span&gt;&lt;span data-key="962949bf244c4f79908a3277239eec7b"&gt;&lt;span data-offset-key="962949bf244c4f79908a3277239eec7b:0"&gt;&lt;span data-slate-zero-width="z"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a data-key="485c389d685642518294aa1247c8fb77" rel="noopener noreferrer" href="https://github.com/arandomdev/DyldExtractor"&gt;&lt;span data-key="bcf0db0d55ea46b5b9369481f865b183"&gt;&lt;span data-offset-key="bcf0db0d55ea46b5b9369481f865b183:0"&gt;DyldExtractor&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-key="83eb6b4e572944a9ac1ccb0a01537c05"&gt;&lt;span data-offset-key="83eb6b4e572944a9ac1ccb0a01537c05:0"&gt; - Extract Binaries from Apple's Dyld Shared Cache.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;a href="https://wiki.nikitavoloboev.xyz/macos"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Mon, 25 Jan 2021 13:47:29 UT
      </pubDate>
      <guid>
        https://wiki.nikitavoloboev.xyz/macos
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://arxiv.org/pdf/2012.02943.pdf
      </link>
      <description>
        &lt;a href="https://arxiv.org/pdf/2012.02943.pdf"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Mon, 25 Jan 2021 13:57:02 UT
      </pubDate>
      <guid>
        https://arxiv.org/pdf/2012.02943.pdf
      </guid>
    </item>
    <item>
      <title>
        Null References: The Billion Dollar Mistake
      </title>
      <link>
        https://www.infoq.com/presentations/Null-References-The-Billion-Dollar-Mistake-Tony-Hoare/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt; &lt;article data-type="presentation"&gt; &lt;p&gt; &lt;span&gt;&lt;a title="InfoQ Homepage" href="https://www.infoq.com/?itm_source=infoq&amp;amp;itm_medium=breadcrumbs_feature&amp;amp;itm_campaign=breadcrumbs"&gt;InfoQ Homepage&lt;/a&gt;&lt;/span&gt; &lt;span&gt;&lt;a title="Presentations" href="https://www.infoq.com/presentations?itm_source=infoq&amp;amp;itm_medium=breadcrumbs_feature&amp;amp;itm_campaign=breadcrumbs"&gt;Presentations&lt;/a&gt;&lt;/span&gt; &lt;span&gt;Null References: The Billion Dollar Mistake&lt;/span&gt; &lt;/p&gt; &lt;div&gt; &lt;h2&gt;Summary&lt;/h2&gt; &lt;p&gt;Tony Hoare introduced Null references in ALGOL W back in 1965 "simply because it was so easy to implement", says Mr. Hoare. He talks about that decision considering it "my billion-dollar mistake".&lt;/p&gt; &lt;/div&gt; &lt;div&gt; &lt;h2&gt;Bio&lt;/h2&gt; &lt;p&gt;Sir Charles Antony Richard Hoare, commonly known as Tony Hoare, is a British computer scientist, probably best known for the development in 1960, at age 26, of Quicksort. He also developed Hoare logic, the formal language Communicating Sequential Processes (CSP), and inspired the Occam programming language.&lt;/p&gt; &lt;/div&gt; &lt;div&gt; &lt;h2&gt;About the conference&lt;/h2&gt; &lt;p&gt;QCon is a conference that is organized by the community, for the community.The result is a high quality conference experience where a tremendous amount of attention and investment has gone into having the best content on the most important topics presented by the leaders in our community. QCon is designed with the technical depth and enterprise focus of interest to technical team leads, architects, and project managers.&lt;/p&gt; &lt;/div&gt; &lt;div&gt; &lt;h3&gt;INFOQ EVENTS&lt;/h3&gt; &lt;ul&gt; &lt;li data-col="1/1" data-type="webinar" data-id="infoqLive_transcripts_box"&gt;&lt;a href="https://live.infoq.com/conference/2021/february/?utm_source=infoq&amp;amp;utm_medium=boxwithtranscripts&amp;amp;utm_campaign=infoqlivefebboxtranscripts"&gt;&lt;img alt="Deep-dive into practical ways you can use and integrate observability into your distributed system architecture." src="https://cdn.infoq.com/statics_s2_20210201062919/images/enhancements/eventNotice/infoqlive-btr.jpg"&gt;&lt;/a&gt; &lt;span&gt;Feb 16th, 9AM EDT / 3PM CET&lt;/span&gt; &lt;h4&gt;&lt;a href="https://live.infoq.com/conference/2021/february/?utm_source=infoq&amp;amp;utm_medium=boxwithtranscripts&amp;amp;utm_campaign=infoqlivefebboxtranscripts"&gt;Deep-dive into practical ways you can use and integrate observability into your distributed system architecture.&lt;/a&gt;&lt;/h4&gt; &lt;/li&gt; &lt;/ul&gt; &lt;ul&gt; &lt;li data-col="1/1" data-type="webinar"&gt; &lt;a href="https://infoq.link/LD-Webinar-Box-Transcripts"&gt; &lt;img alt="InfoQ Webinar Image" src="https://cdn.infoq.com/statics_s2_20210201062919/images/enhancements/eventNotice/LaunchD-transcripts.jpg"&gt; &lt;/a&gt; &lt;span&gt;February 11th, 2021, 10:00AM PST&lt;/span&gt; &lt;h4&gt;&lt;a href="https://infoq.link/LD-Webinar-Box-Transcripts"&gt;Safe and Sane: Deployment and Launch with Reduced Risks.&lt;/a&gt;&lt;/h4&gt; &lt;p&gt;&lt;a href="https://infoq.link/LD-Webinar-Box-Transcripts"&gt;Presented by: Heidi Waterhouse - Principal Developer Advocate&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div id="presentationNotes"&gt; &lt;h2&gt;Key Takeaways&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Null references have historically been a bad idea&lt;/li&gt; &lt;li&gt;Early compilers provided opt-out switches for run-time checks, at the expense of correctness&lt;/li&gt; &lt;li&gt;Programming language designers should be responsible for the errors in programs written in that language&lt;/li&gt; &lt;li&gt;Customer requests and markets may not ask for what's good for them; they may need regulation to build the market&lt;/li&gt; &lt;li&gt;If the billion dollar mistake was the null pointer, the C gets function is a multi-billion dollar mistake that created the opportunity for malware and viruses to thrive&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Show notes&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a&gt;00:45&lt;/a&gt; Thesis: historically, null references have been a bad idea.&lt;/li&gt; &lt;li&gt;&lt;a&gt;02:15&lt;/a&gt; Null references were created in 1964 - how much have they cost? Less or more than a billion dollars?&lt;/li&gt; &lt;li&gt;&lt;a&gt;03:20&lt;/a&gt; Whilst we don't know, the amount is probably in the order of an (American) billion - more than a tenth of a billon, less than ten billion.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;History of programming languages&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a&gt;03:35&lt;/a&gt; A little on the history of the idea. Tony started as a programmer with Elliot's [Ed: Elliot Brothers, London Ltd] in 1960, and was asked to design a new programming language.&lt;/li&gt; &lt;li&gt;&lt;a&gt;04:10&lt;/a&gt; In the library was a 23-page booklet entitled "Report on the international language ALGOL60";, edited by Peter Naur.&lt;/li&gt; &lt;li&gt;&lt;a&gt;04:30&lt;/a&gt; Used as a basis for the new language, but left out the complicated parts such as "if"; and "then";.&lt;/li&gt; &lt;li&gt;&lt;a&gt;05:00&lt;/a&gt; Most software was still written in machine code (including the complier).&lt;/li&gt; &lt;li&gt;&lt;a&gt;05:25&lt;/a&gt; Most assembly was simple enough to understand that when it went wrong, it could be diagnosed by following through to find out what the fault was.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Towards a high level language&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a&gt;05:40&lt;/a&gt; Using a high level language meant you couldn't step through the machine code.&lt;/li&gt; &lt;li&gt;&lt;a&gt;05:50&lt;/a&gt; The Elliot's machine had 4096 locations, with a length of 4 7/8 bytes long (39 bits), although other machines had different sizes (IBM's had 36 bits.&lt;/li&gt; &lt;li&gt;&lt;a&gt;06:30&lt;/a&gt; To shield customers from implementation details, customers were told the errors in terms of the high level programming language, instead of a hexadecimal core dump.&lt;/li&gt; &lt;li&gt;&lt;a&gt;07:10&lt;/a&gt; In order to implement error messages, an array had a check to verify whether its reference was in the bounds.&lt;/li&gt; &lt;li&gt;&lt;a&gt;08:00&lt;/a&gt; Adding checks to arrays added space and time to the program; on Tony's first machine it ran at less than 2k operations per second (500 micro seconds per operation, and two such tests for each array bounds).&lt;/li&gt; &lt;li&gt;&lt;a&gt;08:40&lt;/a&gt; No undetected array errors, and customers didn't know they could trade off safety for speed.&lt;/li&gt; &lt;li&gt;&lt;a&gt;09:30&lt;/a&gt; The Java language has, after 30 years, decided to replicate the decision to bounds checking arrays. [Ed: other languages, like Python, handle this as well].&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Record oriented programming&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a&gt;10:20&lt;/a&gt; Introduced the concept of an object, which could be referred to with a pointer.&lt;/li&gt; &lt;li&gt;&lt;a&gt;10:30&lt;/a&gt; With pointers, it is possible to wreak havoc with the program you are trying to test [Ed: this is the single biggest cause of security failures in modern day code].&lt;/li&gt; &lt;li&gt;&lt;a&gt;10:55&lt;/a&gt; If a floating point value or integer is used as a pointer accidentally, and the value it is pointing to is updated, then it will just as likely update the program which may then crash or cause problems now or in the future. [Ed: these days, virtual memory and page mapping takes away some of the problems about editing program code, but these weren't present in the computers of that era.]&lt;/li&gt; &lt;li&gt;&lt;a&gt;12:00&lt;/a&gt; As a given, when invoking a function with a pointer required the type of the pointer to be declared.&lt;/li&gt; &lt;li&gt;&lt;a&gt;13:30&lt;/a&gt; The type of the program can be compile time checked from the static types.&lt;/li&gt; &lt;li&gt;&lt;a&gt;13:45&lt;/a&gt; Many years later Tony discovered that some of these ideas had been integrated for the first time, although previous examples came from both Doug Rossier's Plex and Simula.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Records avoid subscript errors&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a&gt;14:35&lt;/a&gt; The great thing about record handling is that you don't need to have a subscript error, because you cannot construct a pointer that points to something that doesn't exist, and a whole set of errors cannot occur and do not need to be checked at run-time.&lt;/li&gt; &lt;li&gt;&lt;a&gt;15:50&lt;/a&gt; Later, we asked the customers whether they wanted the option to be able turn off the type checking in production. It's a bit like wearing a life jacket when you are practicing drills, but then taking it off the ship was sinking. The customers decided to not switch off the type checking.&lt;/li&gt; &lt;li&gt;&lt;a&gt;17:00&lt;/a&gt; We produced a compiler that would translate Fortran programs to Algol programs. It was a disaster, and no Fortran user would use it.&lt;/li&gt; &lt;li&gt;&lt;a&gt;18:00&lt;/a&gt; The reason that they couldn't use it was because they couldn't use any of their programs. Within a few milliseconds of running it would come up with a subscript error. The error wasn't wanted as they just wanted the code to run.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Type checking as standard&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a&gt;19:00&lt;/a&gt; Things have changed a bit - mainstream programming languages like Java now have subscript checking as standard, type-checked object oriented programming.&lt;/li&gt; &lt;li&gt;&lt;a&gt;19:30&lt;/a&gt; And then I went and invented the null pointer. You either have to check every reference, or you risk disaster.&lt;/li&gt; &lt;li&gt;&lt;a&gt;19:45&lt;/a&gt; Fortran programmers preferred to risk disaster; in fact, experience disaster, rather than check subscripts.&lt;/li&gt; &lt;li&gt;&lt;a&gt;20:00&lt;/a&gt; I didn't know it a the time, but my friend Edsger Dijkstra thought the null reference was a bad idea. He said:&lt;/li&gt; &lt;li&gt;&lt;a&gt;20:20&lt;/a&gt; "If you have a null reference, then every bachelor who you represent in your object structure will seem to be married polyamocursly to the same person Null".&lt;/li&gt; &lt;li&gt;&lt;a&gt;20:55&lt;/a&gt; It brings back the same question whether you want to run your code quickly (without checks) or safely (with checks).&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Disjoint unions and discrimination test&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a&gt;21:10&lt;/a&gt; I did know there was a solution based on the idea of discrimination of objects belong to a disjoint union class; that is, two sets in which there are no members in common. For example a Vehicle class that has subtypes Car and Bus; the Car may have a luggage carrying capacity property while the Bus has a person carrying capacity. You would then have a discrimination test and do different operations based on whether it was a Bus or a Car.&lt;/li&gt; &lt;li&gt;&lt;a&gt;23:40&lt;/a&gt; The size of the program grows with the number of discrimination clauses and number of types. This allows null to be represented as a different class, which can then be passed in to functions.&lt;/li&gt; &lt;li&gt;&lt;a&gt;24:30&lt;/a&gt; The types of the pointer could then be implemented as a union of either a pointer to the null type, or a pointer to the type.&lt;/li&gt; &lt;li&gt;&lt;a&gt;25:20&lt;/a&gt; This leads to implementation problems; what happens if you assume that a pointer is a Bus but change that pointer to a Car instead?&lt;/li&gt; &lt;li&gt;&lt;a&gt;25:55&lt;/a&gt; One of the things you want is to be able to know in a high level language is that when it is created, all of its data structure is initialised. In this case, a null reference can be used to indicate that the data is missing or not known at this time. In fact, it's the only thing that can be assigned if you have a pointer to a particular type.&lt;/li&gt; &lt;li&gt;&lt;a&gt;26:35&lt;/a&gt; If you don't want to use null, you have to implement a sublanguage for representing how to initialise objects of the right type. If the data structure is a tree-based representation, this is achievable if you create the leaves first because they can be fully created.&lt;/li&gt; &lt;li&gt;&lt;a&gt;27:10&lt;/a&gt; It isn't possible to create a cyclic structure using this technique; if there's a cycle in the data structure you can start with a null pointer and then assign it once the rest of the cycle has been completed.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Introducing null&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a&gt;27:40&lt;/a&gt; This led me to suggest that the null value is a member of every type, and a null check is required on every use of that reference variable, and it may be perhaps a billion dollar mistake.&lt;/li&gt; &lt;li&gt;&lt;a&gt;28:00&lt;/a&gt; Modern languages such as C# or Spec# and even Java are introducing the idea of non-null reference parameters, and compile time checking which verifies that they cannot possibly have null values.&lt;/li&gt; &lt;li&gt;&lt;a&gt;28:50&lt;/a&gt; The issues of overloading and inheritance make it a lot more difficult to do these when null references were originally created.&lt;/li&gt; &lt;li&gt;&lt;a&gt;29:20&lt;/a&gt; The movement must have been made based on the fact that null references were an expensive mistake.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Programming languages should be responsible for their users&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a&gt;30:20&lt;/a&gt; A programming language designer should be responsible for the mistakes made by programmers using the language. It is a serious activity; not one that should be given to programmers with 9 months experience with assembly; they should have a strong scientific basis, a good deal of ingenuity and invention and control of detail, and a clear objective that the programs written by people using the language would be correct. free of obvious errors and free of syntactical traps.&lt;/li&gt; &lt;li&gt;&lt;a&gt;31:40&lt;/a&gt; This was the idea that led me to the idea of using proof and formal verification of programs as logical and mathematical models, is a method of conducting research into the design of good programming languages. I wasn't too optimistic in 1969 would actually be using proofs to guarantee correctness of programs.&lt;/li&gt; &lt;li&gt;&lt;a&gt;32:20&lt;/a&gt; By looking at the programming language and whether programs written would be possible to prove the programs written in the language gives an objective measure of how easy it would be to verify the program later. If the understanding of applying a rule locally has to depend on global knowledge of the program then you haven't done a good job in creating the programming language, and you don't need your customers to tell you that.&lt;/li&gt; &lt;li&gt;&lt;a&gt;33:30&lt;/a&gt; In fact customers don't tell you - it's very easy to persuade your customers that anything that goes wrong is their fault rather than yours.&lt;/li&gt; &lt;li&gt;&lt;a&gt;33:40&lt;/a&gt; I rejected that - programming language design is a serious scientific engineering activity, and we should begin to take responsibility for the mistakes that our users make.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Designing for safety&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a&gt;33:55&lt;/a&gt; It's beginning to happen again - the Java programming language and its successors have all used avoidance of error as one of the criteria in the detail ed design of new features of the language, and I'm delighted to give them a great deal of credit for that - but it is only one criteria, and it is only one.&lt;/li&gt; &lt;li&gt;&lt;a&gt;34:35&lt;/a&gt; The most important criteria is backwards compatibility of everything that has gone before, with the millions or billions lines of code that have been written.&lt;/li&gt; &lt;li&gt;&lt;a&gt;34:55&lt;/a&gt; Every commercial language has to make concessions for commercial and historical reasons; but gradually, ideas change, programmers get more interested in provable correctness; production techniques, languages, checkers, analytic tools, test case generators and so on that are going to help them get their programs correct.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Safe at any speed?&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a&gt;35:40&lt;/a&gt; The analogy that I draw is with agricultural pollution and vehicle security. When Ralph Nader first started publishing "Unsafe at any speed", what he was saying had no connection with the marketplace - customers were not asking for reliability or safety as one of their vehicles.&lt;/li&gt; &lt;li&gt;&lt;a&gt;36:20&lt;/a&gt; But gradually, customers started to demand reliability and safety, with the aid of law making and legal constraints requiring basic levels of safety to be included in every vehicle sold.&lt;/li&gt; &lt;li&gt;&lt;a&gt;36:50&lt;/a&gt; There is a possibility that the marketplace will move the reliability of programs and the language in which they&amp;amp;'re expressed.&lt;/li&gt; &lt;li&gt;&lt;a&gt;37:15 &lt;/a&gt;For many professional engineers, they do have ideals and do pursue them in preference to not pursuing them whenever the opportunity arises. The commercial imperative that requires greater attention paid to the formal correctness of the programs is the virus.&lt;/li&gt; &lt;li&gt;&lt;a&gt;37:50&lt;/a&gt; The virus (or malware, or worm) does dreadful things by reaching the parts of the program that it doesn't usually reach. It is no longer applicable to test the cases that are likely to arise, the virus will attack the places that are not likely to arise, and so need just the same level of testing.&lt;/li&gt; &lt;li&gt;&lt;a&gt;38:35&lt;/a&gt; It forces you to get the while program correct, not just the ones that will be used by customers, the code that will be used by viruses needs to be checked too.&lt;/li&gt; &lt;li&gt;&lt;a&gt;38:45&lt;/a&gt; And that can't be done by testing, it has to be done by analysis.&lt;/li&gt; &lt;li&gt;&lt;a&gt;38:55&lt;/a&gt; Analysis of the source code, type-checking techniques are the simplest, but more sophisticated reasoning techniques are being used to high volume code to check that it doesn't contain any naughty things like null reference dereferencing.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Introduction of the virus&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a&gt;39:30&lt;/a&gt; So if I am responsible for a billion dollar mistake; and I bring it up because other designers are much more responsible.&lt;/li&gt; &lt;li&gt;&lt;a&gt;39:40&lt;/a&gt; The designers of C - one can definitely quantify. The buffer overflow is a direct result of the C language gets fnction that doesn't check the bounds of the string input. That allowed the early viruses to get in by overwriting the return values of the code.&lt;/li&gt; &lt;li&gt;&lt;a&gt;40:10&lt;/a&gt; These simple viruses taught the world how to write malware. Without this very simple entry point, it is quite possible that nobody would ever have thought to look for the more subtle kind of thing which are now being exploited every day by people who are now motivated, skilled, and whose profession and income it is to write botware, malware.&lt;/li&gt; &lt;li&gt;&lt;a&gt;40:45&lt;/a&gt; If it hadn't been for the gets routine in C, we might have had no malware.&lt;/li&gt; &lt;li&gt;&lt;a&gt;40:55&lt;/a&gt; Now one virus - the CodeRed virus - was estimated to have cost the world economy 4 billion dollars, because it brought down all the networks, and the interruption to business and all the ordinary banking, other business was estimated to cost that amount. There was another one later as well.&lt;/li&gt; &lt;li&gt;&lt;a&gt;41:30&lt;/a&gt; And that was more than the Millennium bug, which was estimated a little less than 4 billion dollars.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Companies mentioned&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Elliot Brothers (London) Ltd&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;People mentioned&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Peter Naur&lt;/li&gt; &lt;li&gt;Doug Rossier&lt;/li&gt; &lt;li&gt;Edsger Dijkstra&lt;/li&gt; &lt;li&gt;Ralph Nader&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Languages mentioned&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Algol60&lt;/li&gt; &lt;li&gt;Occam&lt;/li&gt; &lt;li&gt;Plex&lt;/li&gt; &lt;li&gt;Simula&lt;/li&gt; &lt;li&gt;Fortran&lt;/li&gt; &lt;li&gt;C#&lt;/li&gt; &lt;li&gt;Spec#&lt;/li&gt; &lt;li&gt;C&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Products mentioned&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="http://www.webcitation.org/65BW96PjQ"&gt;ACM Turing Award speech&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;See more presentations with show notes&lt;/h2&gt; &lt;/div&gt; &lt;div&gt; &lt;div&gt; &lt;p&gt;Recorded at:&lt;/p&gt; &lt;p&gt;&lt;a href="http://qconsf.com/sf2009/?utm_source=infoq&amp;amp;utm_medium=listing&amp;amp;utm_campaign=listingpresentations"&gt; &lt;img src="https://res.infoq.com/presentations/Null-References-The-Billion-Dollar-Mistake-Tony-Hoare/en/promoimage/qcon_logo3.jpg" alt=""&gt; &lt;/a&gt; &lt;/p&gt;&lt;/div&gt; &lt;p&gt;Aug 25, 2009&lt;/p&gt; &lt;/div&gt; &lt;ul&gt; &lt;li&gt; &lt;/li&gt; &lt;li&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/article&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://www.infoq.com/presentations/Null-References-The-Billion-Dollar-Mistake-Tony-Hoare/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 26 Jan 2021 15:36:46 UT
      </pubDate>
      <guid>
        https://www.infoq.com/presentations/Null-References-The-Billion-Dollar-Mistake-Tony-Hoare/
      </guid>
    </item>
    <item>
      <title>
        Patio11's Greatest Hits
      </title>
      <link>
        https://www.kalzumeus.com/greatest-hits/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt; &lt;p&gt;I’ve written for 16 years, 570 essays, and 2.9 million words and &lt;a href="https://www.kalzumeus.com/wc/"&gt;counting&lt;/a&gt;. You can read a &lt;a href="https://www.kalzumeus.com/start-here-if-youre-new/"&gt;quick intro&lt;/a&gt; or my best work, which I curate below.&lt;/p&gt; &lt;h2 id="most-popular"&gt;Most Popular&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2012/01/23/salary-negotiation/"&gt;Salary Negotiation&lt;/a&gt; Instrumentally probably the most useful thing I have ever written. Salary negotiation advice, originally written for engineers in a good market but I’m told broadly applicable. According to reports from people this is responsible for ~$9 million a year in marginal improvement to compensation. &lt;strong&gt;Personal favorite.&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2011/10/28/dont-call-yourself-a-programmer/"&gt;Don’t Call Yourself A Programmer, And Other Career Advice&lt;/a&gt;. &amp;nbsp;Career advice for engineers, but widely applicable, or so I’m told. &amp;nbsp;&lt;strong&gt;Personal favorite.&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2011/03/13/some-perspective-on-the-japan-earthquake/"&gt;Some Perspective On The Japanese Earthquake&lt;/a&gt;. &amp;nbsp;My (very personal) take on Japan’s response to disaster management after the Touhoku earthquake in 2011. &amp;nbsp;Got covered in the NYT, Australian ABC, BBC, etc.&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2010/06/17/falsehoods-programmers-believe-about-names/"&gt;Falsehoods Programmers Believe About Names&lt;/a&gt;.&amp;nbsp;I identified a common class of bugs in the design of applications. This spawned something of a &lt;a href="https://github.com/kdeldycke/awesome-falsehood"&gt;genre&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2010/03/20/running-a-software-business-on-5-hours-a-week/"&gt;Running A Software Business on 5 Hours A Week&lt;/a&gt;. &amp;nbsp;Time management and productivity tips. &amp;nbsp;&lt;strong&gt;Personal favorite.&lt;/strong&gt; See also about using &lt;a href="https://www.kalzumeus.com/2009/10/04/work-smarter-not-harder/"&gt;metrics for personal productivity&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2009/09/05/desktop-aps-versus-web-apps/"&gt;Why I’m Done Making Desktop Applications&lt;/a&gt;. &amp;nbsp;&lt;strong&gt;Personal favorite.&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2009/03/07/how-to-successfully-compete-with-open-source-software/"&gt;How To Compete With Open Source&lt;/a&gt;. &amp;nbsp;(&lt;a href="https://www.kalzumeus.com/2009/03/18/competing-with-oss-japanese/"&gt;日本語版&lt;/a&gt;もあります！）&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2009/10/23/the-ie-css-bug-which-cost-me-a-months-salary/"&gt;The IE7 CSS Bug Which Cost Me A Month’s Salary&lt;/a&gt;. &amp;nbsp;It was a learning experience… a very expensive learning experience.&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2010/01/24/startup-seo/"&gt;Strategic SEO for Startups&lt;/a&gt;. &amp;nbsp;&lt;strong&gt;Personal favorite&lt;/strong&gt;, and probably my best “high level” take on SEO strategy for businesses which are not mine. &amp;nbsp;See also &lt;a href="https://www.kalzumeus.com/2010/01/25/followup-questions-for-strategic-seo-for-startups/"&gt;follow-up discussion&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2010/08/25/the-hardest-adjustment-to-self-employment/"&gt;The Hardest Adjustment To Self Employment&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2010/04/20/building-highly-reliable-websites-for-small-companies/"&gt;Building Highly Reliable Websites&lt;/a&gt;. &amp;nbsp;&lt;strong&gt;Personal favorite&lt;/strong&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;h2 id="marketing"&gt;Marketing&lt;/h2&gt; &lt;p&gt;&lt;strong&gt;In a nutshell:&lt;/strong&gt; Every software company should assign full-time engineers to working on their marketing funnel. Virtually no one does. Most of my largest career wins are shipping relatively simple engineering artifacts (like e.g. automated drip email campaigns) which directly affect funnel math by 3~15%.&lt;/p&gt; &lt;h3 id="drip-email-campaigns"&gt;Drip email campaigns:&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;My most common consulting engagement was delivering a lifecycle email campaign, often for first-time users of the software. This was because it routinely increased conversion by ~15%. Due to &lt;a href="https://stripe.com/atlas/guides/business-of-saas"&gt;SaaS math&lt;/a&gt; that rounds to a 15% increase in enterprise value for one to two weeks of work. (I have a &lt;a href="https://training.kalzumeus.com/lifecycle-emails/"&gt;video course&lt;/a&gt; on this.)&lt;/li&gt; &lt;li&gt;Only enough time to write one email? Send all customers on a month-to-month SaaS plan an email offering to upgrade them to the annual plan for a modest discount (10% off or one month free). You can do this in an hour; it routinely gets 20%+ uptake and is great for your cash flow and churn rate. Here’s one &lt;a href="https://gist.github.com/patio11/479cb824173e5458b91b"&gt;annotated example&lt;/a&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;h3 id="conversion-optimization"&gt;Conversion Optimization:&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;I wrote the book on A/B testing in Rails (if by book one means OSS software). It &lt;a href="https://bjk5.com/post/10171483254/abingo-split-testing-now-on-app-engine-built-for"&gt;was adapted&lt;/a&gt; for Khan Academy’s metrics infrastructure. I used this extensively for testing marketing copy, landing pages, design tweaks, the purchasing page, and in-app funnels.&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2006/07/29/10-minute-tweaks-to-boost-your-conversion/"&gt;Minor tactical conversion tweaks with big results&lt;/a&gt;. &amp;nbsp;Four years later I’m paid to consult with companies you’ve heard of and it is &lt;em&gt;disgusting&lt;/em&gt; how many need to be told some of them. &amp;nbsp;(Big buttons!)&lt;/li&gt; &lt;li&gt;How to&amp;nbsp;&lt;a href="https://www.kalzumeus.com/2007/05/14/increase-your-software-sales/"&gt;sell more software&lt;/a&gt;. &amp;nbsp;&lt;strong&gt;Personal favorite&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2009/07/26/practical-conversion-tips-for-selling-software/"&gt;Practical Conversion Tips for Selling Software&lt;/a&gt;. &amp;nbsp;&lt;strong&gt;Personal favorite&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;The importance of always giving the user &lt;a href="https://www.kalzumeus.com/2009/08/01/keeping-the-user-moving-towards-conversion/"&gt;prominent options which advance them towards conversion&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Tips for &lt;a href="https://www.kalzumeus.com/2009/08/06/landing-page-design-tips/"&gt;landing page design&lt;/a&gt;. &amp;nbsp;They worked &lt;a href="https://www.kalzumeus.com/2009/08/09/update-landing-page-redesign-successful/"&gt;pretty decently&lt;/a&gt; for me.&lt;/li&gt; &lt;/ul&gt; &lt;h3 id="adwords"&gt;AdWords:&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Early impressions on &lt;a href="https://www.kalzumeus.com/2006/07/19/making-adwords-work-for-you/"&gt;how to be successful with AdWords&lt;/a&gt;. &amp;nbsp;Hilariously, at the time I was very opposed to the Content Network, which is now 90% of my AdWords business.&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2006/07/24/its-ok-to-be-second-best/"&gt;Using Placement Preference to decrease costs&lt;/a&gt;. &amp;nbsp;I don’t do it anymore — Conversion Optimizer is far superior for cost performance.&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2006/08/05/fie-upon-you-ysm/"&gt;Why I don’t use Yahoo Search Marketing&lt;/a&gt;, or whatever it is called these days. &amp;nbsp;Fool me once, bad on you, fool me twice…&lt;/li&gt; &lt;li&gt;After being an &lt;a href="https://www.kalzumeus.com/2007/09/25/new-adwords-feature/"&gt;early adopter&lt;/a&gt; of Conversion Optimizer with &lt;a href="https://www.kalzumeus.com/2007/09/28/googles-conversion-optimizer-rocks/"&gt;significant success&lt;/a&gt; I was &lt;a href="https://www.kalzumeus.com/2007/11/24/exploiting-new-niches/"&gt;ranking #3 for it&lt;/a&gt; (under Google itself), which might have been why they &lt;a href="https://www.kalzumeus.com/2008/01/24/google-features-bingo-card-creator/"&gt;did&lt;/a&gt; a &lt;a href="http://www.google.com/adwords/conversionoptimizer/bingocard.html"&gt;case study&lt;/a&gt; with me. &amp;nbsp;It remains my &lt;a href="https://www.kalzumeus.com/2007/11/10/conversion-optimizer-adwords-done-right/"&gt;favorite AdWords feature&lt;/a&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;h3 id="measurement"&gt;Measurement:&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2006/08/05/peeking-over-your-customers-shoulders/"&gt;Instrumenting a downloadable free trial&lt;/a&gt; to tell what is causing conversions.&lt;/li&gt; &lt;li&gt;Using Google Analytics to &lt;a href="https://www.kalzumeus.com/2006/11/16/using-analytics-to-improve-your-web-design/"&gt;see what people are clicking on&lt;/a&gt;. &amp;nbsp;(&lt;a href="http://www.crazyegg.com/"&gt;CrazyEgg &lt;/a&gt;is a &lt;a href="https://www.kalzumeus.com/2007/04/20/crazyegg-vs-google-analytics/"&gt;much better option&lt;/a&gt; in every way.)&lt;/li&gt; &lt;/ul&gt; &lt;h3 id="miscellaneous"&gt;Miscellaneous:&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2009/12/31/engineering-your-way-to-marketing-success/"&gt;Engineering Your Way To Marketing Success&lt;/a&gt;. &amp;nbsp;Partially practical tips, partially part of my ongoing campaign to convince programmers that marketing is a worthwhile skill they can’t afford to reflexively dismiss or be terrible at.&lt;/li&gt; &lt;li&gt;Why posting on forums to move product at retail is probably a &lt;a href="https://www.kalzumeus.com/2007/05/26/community-oriented-marketing-forums-usenet-mailing-lists-etc/"&gt;waste of your time&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2008/02/06/blogging-as-personal-marketing/"&gt;Blogging as personal marketing&lt;/a&gt;. &amp;nbsp;(I was starting to be the go-to guy for SEO a year and change into my business, when I was 25.)&lt;/li&gt; &lt;li&gt;Using &lt;a href="https://www.kalzumeus.com/2010/01/17/wufoo-free-incentivization-cheap-effective-user-surveys/"&gt;incentivized surveys&lt;/a&gt; to get customer feedback. &amp;nbsp;&lt;strong&gt;Personal favorite&lt;/strong&gt;. &amp;nbsp;It taught me &lt;a href="https://www.kalzumeus.com/2010/02/07/what-my-user-survey-taught-me/"&gt;some interesting things&lt;/a&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;h2 id="career-advice"&gt;Career Advice&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2011/10/28/dont-call-yourself-a-programmer/"&gt;Don’t Call Yourself A Programmer&lt;/a&gt;. &amp;nbsp;&lt;strong&gt;Personal favorite. &amp;nbsp;&lt;/strong&gt;My advice to young engineers on positioning themselves for current and future career growth.&lt;/li&gt; &lt;li&gt;My thoughts on &lt;a href="https://www.kalzumeus.com/2012/01/23/salary-negotiation/"&gt;salary negotiation&lt;/a&gt;, particularly useful for engineers. &lt;strong&gt;Personal favorite.&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;For freelancers/consultants: &lt;a href="https://www.kalzumeus.com/2012/09/17/ramit-sethi-and-patrick-mckenzie-on-getting-your-first-consulting-client/"&gt;how to get your first client&lt;/a&gt; and &lt;a href="https://www.kalzumeus.com/2012/09/21/ramit-sethi-and-patrick-mckenzie-on-why-your-customers-would-be-happier-if-you-charged-more/"&gt;how to set prices&lt;/a&gt; (interviews conducted with Ramit Sethi).&lt;/li&gt; &lt;/ul&gt; &lt;h2 id="weird-hobbies"&gt;Weird Hobbies&lt;/h2&gt; &lt;p&gt;I have some weird hobbies. Some people have, probably justly, accused me of having a hobby of having weird hobbies. Occasionally I write what I learn from them:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;I used to ghostwrite letters to banks to resolve consumer credit problems, which prepared me very well for when Equifax had their data security breach. Writeup: &lt;a href="https://www.kalzumeus.com/2017/09/09/identity-theft-credit-reports/"&gt;Identity, Credit Reports, and You&lt;/a&gt;&lt;/li&gt; &lt;li&gt;I researched and wrote about the economics of the discount brokerage industry. &lt;a href="https://www.kalzumeus.com/2019/6/26/how-brokerages-make-money/"&gt;How Discount Brokerages Make Money&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h2 id="conference-talks"&gt;Conference Talks&lt;/h2&gt; &lt;p&gt;I present at conferences about 4~5 times a year, and generally request that the talk be made available after the conference.&lt;/p&gt; &lt;p&gt;I’ve spoken at &lt;a href="https://www.microconf.com/"&gt;Microconf&lt;/a&gt; almost every year and consider that community my home-away-from-home. You should absolutely attend if you are at all interested in running a software business.&lt;/p&gt; &lt;p&gt;MicroConf recommends my talks in &lt;a href="https://www.youtube.com/watch?v=acVvumkWVLU&amp;amp;list=PLwcQbu9cKWclhn8JCryvm3GHpK8w7fb2q"&gt;this order&lt;/a&gt;, but chronologically works best for some people so:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;2011: A Software Business on 5 Hours a Week (not recorded, but I have &lt;a href="https://speakerdeck.com/patio11/a-software-business-on-5-hours-a-week"&gt;the slides&lt;/a&gt;)&lt;/li&gt; &lt;li&gt;2012: &lt;a href="https://www.youtube.com/watch?v=N6V-cytrvvQ"&gt;How to Engineer Marketing Success&lt;/a&gt;. Explains some of my common tactics, and broader mindset, on building engineering artifacts to influence marketing / sales outcomes.&lt;/li&gt; &lt;li&gt;2013: &lt;a href="https://www.youtube.com/watch?v=acVvumkWVLU"&gt;Building Things to Help You Sell the Things You Build&lt;/a&gt;, again on the mechanics of engineering sales and marketing.&lt;/li&gt; &lt;li&gt;2014: I’ve always said that the only thing that could keep me away from Microconf was the birth of a child. In 2014, we were blessed by the birth of our daughter Lillian.&lt;/li&gt; &lt;li&gt;2015: &lt;a href="https://www.youtube.com/watch?v=-Tg48MVnBeQ"&gt;Leveling Up&lt;/a&gt;, on how entrepreneurship effectively has a career ladder, where what you learn doing one company can be used to help jumpstart the next. &lt;a href="https://speakerdeck.com/patio11/leveling-up"&gt;Slides&lt;/a&gt;&lt;/li&gt; &lt;li&gt;2016: I attended Microconf but was hip-deep in Starfighter and didn’t present.&lt;/li&gt; &lt;li&gt;2017: &lt;a href="https://www.youtube.com/watch?v=_h8IhbR2Iqk"&gt;Paint by Numbers: From Productized Consulting to SaaS&lt;/a&gt;. This is the glide path for bootstrapping a software business off of a consulting/infoproduct sort of offering, and helps you avoid the long slow SaaS ramp of death. &lt;a href="https://speakerdeck.com/patio11/paint-by-numbers-from-productized-service-to-saas"&gt;Slides&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;2018: &lt;a href="https://www.youtube.com/watch?v=PtmUJye7t4c"&gt;Your First 60 Days&lt;/a&gt;, on booting up a new Internet business. Covers marketing from a cold start, how to prioritize product development and other tasks, and what the minimum viable backoffice work is. &lt;a href="https://speakerdeck.com/patio11/your-first-60-days"&gt;Slides&lt;/a&gt;&lt;/li&gt; &lt;li&gt;2019: &lt;a href="https://www.youtube.com/watch?v=cIoC97CJGtw"&gt;The Ethos of MicroConf&lt;/a&gt;, a bit of a personal reflection on life and business. &lt;a href=""&gt;Slides&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;I also periodically speak at other conferences, on a potpurri of topics. You can find many of my presentations on &lt;a href="https://www.slideshare.com/patio11"&gt;Slideshare&lt;/a&gt; or &lt;a href="https://speakerdeck.com/patio11"&gt;SpeakerDeck&lt;/a&gt;.&lt;/p&gt; &lt;h2 id="podcast"&gt;Podcast&lt;/h2&gt; &lt;p&gt;I am a frequent &lt;a href="https://www.listennotes.com/search/?q=%22patrick%20mckenzie%22&amp;amp;sort_by_date=0&amp;amp;scope=episode&amp;amp;offset=0&amp;amp;language=Any%20language&amp;amp;len_min=0"&gt;guest&lt;/a&gt; on podcasts.&lt;/p&gt; &lt;p&gt;I also occasionally host &lt;a href="https://www.kalzumeus.com/podcast/"&gt;my own podcast&lt;/a&gt;. Some recent episodes:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2017/05/10/kalzumeus-podcast-episode-14-running-a-business-portfolio-with-jonathan-siegel/"&gt;Kalzumeus Podcast Episode 14: Running A Business Portfolio with Jonathan Siegel&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2016/08/26/kalzumeus-podcast-episode-13-selling-online-businesses-with-thomas-smale/"&gt;Kalzumeus Podcast Episode 13: Selling Online Businesses With Thomas Smale&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2016/06/03/kalzumeus-podcast-episode-12-salary-negotiation-with-josh-doody/"&gt;Kalzumeus Podcast Episode 12: Salary Negotiation with Josh Doody&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h2 id="videos"&gt;Videos&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Andrew Warner &lt;a href="http://mixergy.com/patrick-mckenzie-interview/"&gt;interviewed me&lt;/a&gt; on &lt;a href="http://www.mixergy.com/"&gt;Mixergy&lt;/a&gt;. &amp;nbsp;(About one hour, comes with transcript half-written by me.) &amp;nbsp;Andrew is, by the way, the best interviewer in technology today. &amp;nbsp;You cannot do better than some of the insights he teases out of guests, and he has a wonderful way of making people so comfortable they forget to not answer the tough questions he slides in there.&lt;/li&gt; &lt;li&gt;Gabriel Weinberg &lt;a href="http://www.gabrielweinberg.com/blog/2010/04/patrick-mckenzie-on-seo-adwords-for-bingo-card-creator.html"&gt;interviewed me&lt;/a&gt; with specific regards to SEO, mini-sites, and conversion optimization. &amp;nbsp;(About one hour, comes with transcript written by me.)&lt;/li&gt; &lt;li&gt;I did a 7.5 minute lightning talk on &lt;a href="https://www.kalzumeus.com/2011/03/26/software-for-underserved-markets/"&gt;selling software to underserved markets&lt;/a&gt; at Business of Software 2010.&lt;/li&gt; &lt;li&gt;I spoke on &lt;a href="https://www.kalzumeus.com/2011/12/19/productizing-twilio-applications/"&gt;Productizing Twilio Applications&lt;/a&gt; at TwilioConf 2011.&lt;/li&gt; &lt;li&gt;Google brought me in to do a tech talk about &lt;a href="http://www.youtube.com/watch?v=sFWlmEO6eg0"&gt;What Engineers Don’t Know We Know About Marketing&lt;/a&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;h2 id="seo"&gt;SEO&lt;/h2&gt; &lt;h3 id="content-creation"&gt;Content Creation:&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Before launch (July 1, 2006) I had a &lt;a href="https://www.kalzumeus.com/2006/06/29/from-visitor-to-downloader-to-purchaser/"&gt;rough cut&lt;/a&gt; of my content creation strategy and figured out there would be &lt;a href="https://www.kalzumeus.com/2006/06/30/unexpected-expenditure-great-marketing-idea/"&gt;seasonal elements to it&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Right after launch, I stumbled on what turned into my &lt;a href="https://www.kalzumeus.com/2006/07/04/optimized-landing-page-1/"&gt;first major SEO opportunity&lt;/a&gt;: Dolch Sight Words. &amp;nbsp;This &lt;a href="https://www.kalzumeus.com/2006/08/31/how-much-content-does-your-website-have/"&gt;started working&lt;/a&gt; rather quickly (was my main source of sales for almost a year), both for traffic and for &lt;a href="https://www.kalzumeus.com/2007/02/07/google-finally-lets-you-see-backlinks/"&gt;backlinks&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Optimizing your website for &lt;a href="https://www.kalzumeus.com/2007/05/30/ranking-for-an-arbitrary-organic-search-query/"&gt;snowflake queries&lt;/a&gt;: the ones Google only sees once. &amp;nbsp;This eventually formed the core of my content creation strategy: as many pages as possible, each targeted at one specific, narrow interest.&lt;/li&gt; &lt;li&gt;&lt;span&gt;&lt;strong&gt;Most recommended series&lt;/strong&gt;&lt;/span&gt;: After seeing the results of doing content creation by hand in notepad, I started trying to &lt;a href="https://www.kalzumeus.com/2007/10/21/developing-linkbait-for-a-non-technical-audience/"&gt;scale it up&lt;/a&gt; using Rails and get the content &lt;a href="https://www.kalzumeus.com/2007/10/03/before-i-try-rentacoder/"&gt;written by freelancers&lt;/a&gt;. &amp;nbsp;This ended up getting &lt;a href="https://www.kalzumeus.com/2007/11/05/october-2007-stats-2000-in-sales/"&gt;early positive results&lt;/a&gt; and eventually virtually taking over the business (now accounting for some 50% of sales and 75% of profits, give or take). &amp;nbsp;I eventually distilled this strategy into a &lt;a href="https://www.kalzumeus.com/2010/07/17/seo-for-software-companies/"&gt;presentation on SEO for software companies&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2007/11/18/putting-the-green-in-evergreen/"&gt;Using evergreen content&lt;/a&gt; (that which is perpetually useful to consistent, unchanging needs of your customers) to make sales. &amp;nbsp;(Note: anti-pattern of a 10 year old blog post outranking product site happens frequently in consulting!) &amp;nbsp;My little brother busy trying to break into &lt;a href="http://www.superheronation.com/"&gt;comic book writing advice&lt;/a&gt; also has &lt;a href="https://www.kalzumeus.com/2008/03/20/insights-on-blog-optimization/"&gt;thoughts&lt;/a&gt; on this &lt;a href="http://www.superheronation.com/2008/03/20/new-years-resolution-madness-assessing-bounce-rates-in-online-novels/#more-574"&gt;here&lt;/a&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;h3 id="mini-sites"&gt;Mini-sites:&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;I had a variety of &lt;a href="https://www.kalzumeus.com/2008/12/13/learning-from-a-specific-example-of-failure/"&gt;mini-sites&lt;/a&gt; focused on my best performing single pieces of content, beginning with an &lt;a href="https://www.kalzumeus.com/2008/11/24/christmas-bingo-boards/"&gt;experimental one&lt;/a&gt; for Christmas back in 2008. They tended to work &lt;em&gt;exceptionally well&lt;/em&gt; in their second and third years. This is &lt;strong&gt;probably not&lt;/strong&gt; worth doing anymore since SEO changes over time.&lt;/li&gt; &lt;li&gt;Relatedly, I wrote up some tips on &lt;a href="https://www.kalzumeus.com/2009/10/14/holiday-promotion/"&gt;how to do holiday promotions&lt;/a&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;h3 id="link-building"&gt;Link Building:&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;See everything I write about content creation, as they’re deeply entwined for me.&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2008/04/08/linkbuilding-for-small-businesses/"&gt;Tactics and strategy&lt;/a&gt; for more effective link building.&lt;/li&gt; &lt;/ul&gt; &lt;h3 id="on-page-seo"&gt;On Page SEO:&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;An early take on &lt;a href="https://www.kalzumeus.com/2006/07/29/on-page-seo-for-small-companies/"&gt;on-page optimizations&lt;/a&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;h2 id="miscellaneous-1"&gt;Miscellaneous&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;It took &lt;a href="https://www.kalzumeus.com/2006/07/04/day-11-first-page-of-google/"&gt;11 days&lt;/a&gt; to rank for my product name and &lt;a href="https://www.kalzumeus.com/2006/07/29/legitimate-organic-searches-eclipse-ppc/"&gt;a month&lt;/a&gt; until organic SEO eclipsed PPC as a source of traffic for me.&lt;/li&gt; &lt;li&gt;Coding for &lt;a href="http://www.bingocardcreator.com/articles/rails-seo-tips.htm"&gt;SEO on Rails&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;I tried &lt;a href="https://www.kalzumeus.com/2006/09/23/text-link-ads/"&gt;buying links&lt;/a&gt; when I was young and stupid (slightly before Google came down hard on the practice). &amp;nbsp;It didn’t work out well.&lt;/li&gt; &lt;li&gt;Put your blog in a &lt;a href="https://www.kalzumeus.com/2006/10/02/object-lesson-on-blogging-for-your-business/"&gt;subdirectory of the product domain&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;The right way to do a &lt;a href="https://www.kalzumeus.com/2007/05/27/how-to-rename-a-web-page/"&gt;301 redirect&lt;/a&gt; in Apache.&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2008/01/28/why-you-shouldnt-pay-any-seo-you-can-afford/"&gt;Why I don’t recommend hiring SEO consultants&lt;/a&gt;. &amp;nbsp;&lt;strong&gt;Personal favorite&lt;/strong&gt;. &amp;nbsp;(Ironic, since I have worked as one.)&lt;/li&gt; &lt;/ul&gt; &lt;h2 id="tough-to-categorize-but-still-useful"&gt;Tough To Categorize But Still Useful&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Why I don’t write any &lt;a href="https://www.kalzumeus.com/2006/08/13/ten-reasons-why-most-internet-writing-is-terrible/"&gt;Top Ten Ways To Sell A Widget&lt;/a&gt; articles. &amp;nbsp;&lt;strong&gt;Personal favorite.&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.kalzumeus.com/2010/08/19/dealing-with-market-seasonality/"&gt;Dealing with market seasonality&lt;/a&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;ul&gt; &lt;li&gt;Year in Review Posts: &lt;a href="https://www.kalzumeus.com/2006/12/26/merry-christmas-part-2/"&gt;2006&lt;/a&gt;, &lt;a href="https://www.kalzumeus.com/2008/01/13/year-2007-stats-and-year-2008-goals/"&gt;2007&lt;/a&gt;, &lt;a href="https://www.kalzumeus.com/2008/12/21/bingo-card-creator-year-2008-in-review/"&gt;2008&lt;/a&gt;, &lt;a href="https://www.kalzumeus.com/2009/12/18/bingo-card-creator-year-in-review-2009/"&gt;2009&lt;/a&gt;, &lt;a href="https://www.kalzumeus.com/2010/12/17/bingo-card-creator-etc-year-in-review-2010/"&gt;2010&lt;/a&gt;, &lt;a href="https://www.kalzumeus.com/2011/12/21/bingo-card-creator-etc-year-in-review-2011/"&gt;2011&lt;/a&gt;, &lt;a href="https://www.kalzumeus.com/2012/12/29/bingo-card-creator-and-other-stuff-year-in-review-2012/"&gt;2012&lt;/a&gt;, &lt;a href="https://www.kalzumeus.com/2014/01/06/kalzumeus-software-year-in-review-2013/"&gt;2013&lt;/a&gt;, &lt;a href="https://www.kalzumeus.com/2014/12/22/kalzumeus-software-year-in-review-2014/"&gt;2014&lt;/a&gt;, 2015 (skipped), and &lt;a href="https://www.kalzumeus.com/2016/12/30/kalzumeus-software-year-in-review-2016/"&gt;2016&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Since late 2016 I’ve been &lt;a href="https://www.kalzumeus.com/2019/3/18/two-years-at-stripe/"&gt;working at Stripe&lt;/a&gt;. (I can’t show you our stats unless you &lt;a href="https://stripe.com/jobs"&gt;come work with us on growing the GDP of the Internet.&lt;/a&gt;)&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://www.kalzumeus.com/greatest-hits/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Mon, 1 Feb 2021 12:19:32 UT
      </pubDate>
      <guid>
        https://www.kalzumeus.com/greatest-hits/
      </guid>
    </item>
    <item>
      <title>
        mtlynch.io
      </title>
      <link>
        https://mtlynch.io/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt; &lt;p&gt;I'm Michael Lynch, software developer and blogger. I used to work as a software engineer at large companies, but now I run small software businesses of my own and blog about the process.&lt;/p&gt; &lt;div&gt; &lt;div&gt; &lt;h2&gt;Most Popular Articles&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://mtlynch.io/why-i-quit-google/"&gt;Why I Quit Google to Work for Myself&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://mtlynch.io/tinypilot/"&gt;TinyPilot: Build a KVM Over IP for Under $100&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://mtlynch.io/stole-siacoins/"&gt;How I Stole Your Siacoin&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://mtlynch.io/solo-developer-year-2/"&gt;My Second Year as a Solo Developer&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div&gt; &lt;h2&gt;Articles about Software Development&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://mtlynch.io/code-review-love/"&gt;How to Make Your Code Reviewer Fall in Love with You&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://mtlynch.io/human-code-reviews-1/"&gt;How to Do Code Reviews Like a Human&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://mtlynch.io/good-developers-bad-tests/"&gt;Why Good Developers Write Bad Unit Tests&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://mtlynch.io/painless-web-app-testing/"&gt;End-to-End Testing Web Apps: The Painless Way&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div&gt; &lt;h2&gt;Articles about Blogging&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://mtlynch.io/editor/"&gt;How I Hired a Freelance Editor for My Blog&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://mtlynch.io/how-to-hire-a-cartoonist/"&gt;How to Hire a Cartoonist to Make Your Blog Less Boring&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://mtlynch.io/hiring-content-writers/"&gt;Hiring Content Writers: A Guide for Small Businesses&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://mtlynch.io/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Mon, 1 Feb 2021 12:22:45 UT
      </pubDate>
      <guid>
        https://mtlynch.io/
      </guid>
    </item>
    <item>
      <title>
        Structured Procrastination
      </title>
      <link>
        https://jblevins.org/log/structured-procrastination
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div id="content"&gt; &lt;article&gt; &lt;header&gt; &lt;h2&gt;&lt;a title="Permanent link to 'Structured Procrastination'" href="https://jblevins.org/log/structured-procrastination"&gt;Structured Procrastination&lt;/a&gt;&lt;/h2&gt; &lt;p&gt;February 10, 2007&lt;/p&gt; &lt;/header&gt; &lt;p&gt;Every professional procrastinator knows that when a big project deadline looms in the near future, the time is ripe to work on some &lt;em&gt;other&lt;/em&gt; project instead. It usually involves something at least marginally productive, such as cleaning the house, or it might involve starting some entirely new project. My bouts of procrastination usually result in the latter and then I have yet another open project that lingers unfinished.&lt;/p&gt; &lt;p&gt;I used to try to fight the urge to procrastinate directly, but I am beginning to believe that the key is not to combat it outright, but to harness it. I know many very bright and productive people who procrastinate just as much as anyone else. In fact, academia is rife with procrastinators yet still manages to plod along somehow. For example, a 1980 article by Gary W. Yohe figures the average time to publication of an article submitted to &lt;em&gt;Econometrica&lt;/em&gt;, a top Economics journal, to be 25.9 months. One explanation is that top journals simply examine submitted articles more carefully. Another perhaps more likely reason is that journal referees and editors are procrastinators.&lt;/p&gt; &lt;p&gt;The key to harnessing one’s procrastination is to recognize it and channel it away from the marginally productive activities into more highly productive ones. This is the essence of &lt;a href="http://www.structuredprocrastination.com/"&gt;Structured Procrastination&lt;/a&gt;, as described in an essay by by John Perry. His first paragraph is an excellent summary:&lt;/p&gt; &lt;blockquote title="John Perry, Structured Procrastination" cite="http://www.structuredprocrastination.com"&gt; &lt;p&gt;I have been intending to write this essay for months. Why am I finally doing it? Because I finally found some uncommitted time? Wrong. I have papers to grade, textbook orders to fill out, an NSF proposal to referee, dissertation drafts to read. I am working on this essay as a way of not doing all of those things. This is the essence of what I call structured procrastination, an amazing strategy I have discovered that converts procrastinators into effective human beings, respected and admired for all that they can accomplish and the good use they make of time.&lt;/p&gt; &lt;/blockquote&gt; &lt;h3&gt;References&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;Perry, John. “Structured Procrastination”, &lt;code&gt;&lt;a href="http://www.structuredprocrastination.com/"&gt; http://www.structuredprocrastination.com&lt;/a&gt;&lt;/code&gt;, April 25 1995, retrieved on February 10, 2007.&lt;/li&gt; &lt;li&gt;Yohe, Gary W. (1980): “Current Publication Lags in Economics Journals”, &lt;em&gt;Journal of Economic Literature&lt;/em&gt;, 18, 1050–1055.&lt;/li&gt; &lt;/ul&gt; &lt;/article&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://jblevins.org/log/structured-procrastination"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 2 Feb 2021 13:33:33 UT
      </pubDate>
      <guid>
        https://jblevins.org/log/structured-procrastination
      </guid>
    </item>
    <item>
      <title>
        In Praise of Low-Fidelity
      </title>
      <link>
        https://jblevins.org/log/lofi
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div id="content"&gt; &lt;article&gt; &lt;header&gt; &lt;h2&gt;&lt;a title="Permanent link to 'In Praise of Low-Fidelity'" href="https://jblevins.org/log/lofi"&gt;In Praise of Low-Fidelity&lt;/a&gt;&lt;/h2&gt; &lt;p&gt;February 5, 2006&lt;/p&gt; &lt;/header&gt; &lt;p&gt;I believe in simplification. I strongly support technology and innovation, but I believe more strongly in choosing the best tool for any task. Simplicity can of course result from the application of technology but many times, the best tool happens to be the “low-fidelity” one. Expensive high-tech gadgets that promise to make you more efficient will probably do the opposite. Most of the time a notebook and pen will do. For example, those nifty special effects in PowerPoint that took an hour of tweaking only serve to detract your audience from your content in the end. On the other hand, my razor, my iPod, and my compact, lightweight titanium-frame umbrella, all very simple, elegant, and useful, were all possible only because of technology.&lt;/p&gt; &lt;p&gt;I think that technology has a tendency to overstimulate and overextend us, but I am by no means a Luddite. Innovation is essential, even if only to help us realize that some previous solution worked better. Word processors with lots of bells and whistles are great for certain tasks, but despite 40 years of advances in computer technology, the plain text file has survived. It is used for its own purposes, it constitutes the source code of complicated computer programs, and supports the publication of the most thought-provoking new books. Windows was a major catalyst to the computer revolution, but it’s complexity, bulkiness, and closed nature was in turn a catalyst to a Unix revolution in favor of openness, flexibility, and simplicity.&lt;/p&gt; &lt;p&gt;I believe that if you’re not pushing your limits, you’re wasting time, but if you push through the present without enjoying what you’ve done, there will be no time left to waste. This is where the low-fidelity approach is useful. There is a certain pleasure in listening to the radio instead of watching television, in writing a letter instead of an email, or in taking a walk instead of driving, and it helps keep you grounded in the present while keeping your mind clear for looking ahead. There are also possible efficiency gains. I can listen to NPR while driving or making breakfast, and I spare myself from an onslaught of advertisements in the process.&lt;/p&gt; &lt;p&gt;Thus, the low-fidelity approach is the selective application of the simplest, most efficient tool available, whether it involves the newest technology on the market or just some old-fashioned practicality.&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;I wasted time, and now doth time waste me.&lt;/p&gt; &lt;p&gt;&lt;cite&gt;William Shakespeare, Richard II&lt;/cite&gt;&lt;/p&gt; &lt;/blockquote&gt; &lt;/article&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://jblevins.org/log/lofi"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 2 Feb 2021 13:33:39 UT
      </pubDate>
      <guid>
        https://jblevins.org/log/lofi
      </guid>
    </item>
    <item>
      <title>
        cron is dead, long live launchd! - Selected Thoughts
      </title>
      <link>
        https://blog.jan-ahrens.eu/2017/01/13/cron-is-dead-long-live-launchd.html
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div role="main" id="main"&gt; &lt;article class="page"&gt; &lt;div&gt; &lt;header&gt; &lt;p&gt; &lt;span&gt; 1 minute read &lt;/span&gt; &lt;/p&gt; &lt;/header&gt; &lt;section&gt; &lt;p&gt;Now that I finally created my &lt;a href="https://tarsnap.com/"&gt;tarsnap&lt;/a&gt; backup script, how do I execute it regularly? Oh, I know: My Mac is just an Unix system, I’ll use cron!&lt;/p&gt; &lt;p&gt;At least that’s what I thought I’ll do. After a few attempts to get cron to do the job, I learned that there’s a better way on macOS: &lt;a href="https://en.wikipedia.org/wiki/Launchd"&gt;launchd&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;launchd does a lot more than executing scripts cron-style. Like &lt;a href="https://en.wikipedia.org/wiki/Systemd"&gt;systemd&lt;/a&gt; on Linux, launchd is a replacement for a lot of old school Unix tools, like cron, inetd, init, &lt;a href="https://en.wikipedia.org/wiki/Launchd#History"&gt;etc&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;At it’s core, launchd distincts daemons and agents. Dameons are processes that always run in the background, while agents describe regular jobs that are to be executed on certain events. There are a lot of different events to choose from. For example you can trigger an agent, when a device gets mounted, when a file gets created, or when a certain time arrives.&lt;/p&gt; &lt;p&gt;What really helped me in learning how to write my first launchd agent was &lt;a href="http://www.launchd.info/"&gt;launchd.info&lt;/a&gt;. Unlike the &lt;a href="https://developer.apple.com/library/content/documentation/MacOSX/Conceptual/BPSystemStartup/Chapters/CreatingLaunchdJobs.html"&gt;Apple documentation&lt;/a&gt;, it contains useful snippets and concise explanations. I highly recommend that you also have a look at the launchd agents that some of your applications put into &lt;code&gt;~/Library/LaunchAgents&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Below you can see the agent that I ended up creating. You can learn how to load/unload agents and about the meaning of the different options at &lt;a href="http://www.launchd.info/"&gt;launchd.info&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;If you’re testing your script and you don’t want to wait for the next hour to arrive, you can start it immediately with &lt;code&gt;launchctl start eu.jan-ahrens.tarsnap&lt;/code&gt;.&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;?xml version="1.0" encoding="UTF-8"?&amp;gt; &amp;lt;!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd"&amp;gt; &amp;lt;plist version="1.0"&amp;gt; &amp;lt;dict&amp;gt; &amp;lt;key&amp;gt;Label&amp;lt;/key&amp;gt; &amp;lt;string&amp;gt;eu.jan-ahrens.tarsnap&amp;lt;/string&amp;gt; &amp;lt;key&amp;gt;EnvironmentVariables&amp;lt;/key&amp;gt; &amp;lt;dict&amp;gt; &amp;lt;key&amp;gt;PATH&amp;lt;/key&amp;gt; &amp;lt;string&amp;gt;/bin:/usr/bin:/usr/local/bin&amp;lt;/string&amp;gt; &amp;lt;/dict&amp;gt; &amp;lt;key&amp;gt;ProgramArguments&amp;lt;/key&amp;gt; &amp;lt;array&amp;gt; &amp;lt;string&amp;gt;/bin/bash&amp;lt;/string&amp;gt; &amp;lt;string&amp;gt;/Users/jan/bin/run-tarsnap-backup&amp;lt;/string&amp;gt; &amp;lt;/array&amp;gt; &amp;lt;key&amp;gt;StartInterval&amp;lt;/key&amp;gt; &amp;lt;integer&amp;gt;3600&amp;lt;/integer&amp;gt; &amp;lt;key&amp;gt;StandardOutPath&amp;lt;/key&amp;gt; &amp;lt;string&amp;gt;/Users/jan/.tarsnap.log&amp;lt;/string&amp;gt; &amp;lt;key&amp;gt;StandardErrorPath&amp;lt;/key&amp;gt; &amp;lt;string&amp;gt;/Users/jan/.tarsnap.log&amp;lt;/string&amp;gt; &amp;lt;key&amp;gt;KeepAlive&amp;lt;/key&amp;gt; &amp;lt;dict&amp;gt; &amp;lt;key&amp;gt;NetworkState&amp;lt;/key&amp;gt; &amp;lt;true/&amp;gt; &amp;lt;/dict&amp;gt; &amp;lt;key&amp;gt;ExitTimeout&amp;lt;/key&amp;gt; &amp;lt;integer&amp;gt;900&amp;lt;/integer&amp;gt; &amp;lt;key&amp;gt;Nice&amp;lt;/key&amp;gt; &amp;lt;integer&amp;gt;10&amp;lt;/integer&amp;gt; &amp;lt;/dict&amp;gt; &amp;lt;/plist&amp;gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;P.S.: cron itself is implemented as a launchd daemon. You can find it at &lt;code&gt;/System/Library/LaunchDaemons/com.vix.cron.plist&lt;/code&gt;.&lt;/p&gt; &lt;/section&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://blog.jan-ahrens.eu/2017/01/13/cron-is-dead-long-live-launchd.html"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Wed, 3 Feb 2021 10:12:31 UT
      </pubDate>
      <guid>
        https://blog.jan-ahrens.eu/2017/01/13/cron-is-dead-long-live-launchd.html
      </guid>
    </item>
    <item>
      <title>
        Hammerspoon: A Better, Better Hyper Key
      </title>
      <link>
        http://evantravers.com/articles/2020/06/08/hammerspoon-a-better-better-hyper-key/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt; &lt;p&gt;This &lt;em&gt;all&lt;/em&gt; started with Hyper. I &lt;a href="http://evantravers.com/articles/2020/06/08/hammerspoon-history/"&gt;talked in the last post&lt;/a&gt; about my history with the concept, how I learned from &lt;a href="https://stevelosh.com/blog/2012/10/a-modern-space-cadet/"&gt;Steve Losh’s post on the topic&lt;/a&gt; and borrowed from &lt;a href="https://brettterpstra.com/2016/09/29/a-better-hyper-key-hack-for-sierra/"&gt;Brett Terpstra&lt;/a&gt;…&amp;nbsp;and I’ve expanded the idea a bit. At the moment, my hyper implementation is contained in a lua module called &lt;a href="https://github.com/evantravers/hammerspoon-config/blob/38a7d8c0ad2190d1563d681725628e4399dcbe6c/hyper.lua"&gt;hyper.lua&lt;/a&gt;, with some dependencies on Karabiner-Elements.app.&lt;/p&gt; &lt;p&gt;I’m using hs.hotkey.modal to capture an &lt;code&gt;F19&lt;/code&gt; keystroke, and only sending the “hyper chord” of &lt;code&gt;⌘⌥⇧⌃&lt;/code&gt; if absolutely required. The &lt;a href="https://github.com/evantravers/hammerspoon-config/blob/38a7d8c0ad2190d1563d681725628e4399dcbe6c/hyper.lua"&gt;code isn’t that complex&lt;/a&gt; so this post will be focused on the advantages of this approach.&lt;/p&gt; &lt;h2 id="before-hyper-chord"&gt;Before: hyper chord&lt;/h2&gt; &lt;p&gt;Traditionally, a Hyper key is implemented by sending to the Operating System “hyper chord” of &lt;code&gt;⌘⌥⇧⌃&lt;/code&gt; by modifying the keyboard firmware or using &lt;a href="https://karabiner-elements.pqrs.org/"&gt;Karabiner-elements.app&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;img alt="" src="http://evantravers.com/images/articles/2020/06/traditional.png"&gt;&lt;/p&gt; &lt;p&gt;The user would then use some kind of automation software like Alfred or Keyboard Maestro to listen for the “hyper chord” and fire different automations. You can &lt;em&gt;absolutely&lt;/em&gt; do this in Hammerspoon if you want.&lt;/p&gt; &lt;p&gt;While it works well, it has its limitations. Using the “hyper chord” as the entire “hyper key”, you can’t add any more modifiers, because it is already &lt;em&gt;all&lt;/em&gt; the modifiers. Because of this a lot of hyper key setups are limited to “leader key” style interactions.&lt;/p&gt; &lt;h2 id="after-hs-hotkey-modal"&gt;After: hs.hotkey.modal&lt;/h2&gt; &lt;p&gt;Using a single keycode as your “hyper” key, and handling the translation at the automation layer is much more expressive. In my case, Hammerspoon becomes a single “router” to all the automation and UI customization on my Mac.&lt;/p&gt; &lt;p&gt;&lt;img alt="" src="http://evantravers.com/images/articles/2020/06/hammerspoon.png"&gt;&lt;/p&gt; &lt;p&gt;I use a single often-unused key (in my case, &lt;code&gt;F19&lt;/code&gt;) to trigger a &lt;code&gt;hs.hotkey.modal&lt;/code&gt; in Hammerspoon. Instead of having every single application listening to all the keystrokes, I can control it &lt;em&gt;one place&lt;/em&gt;. In this as in all things, I am not the first. Brett Terpstra &lt;a href="https://brettterpstra.com/2012/12/08/a-useful-caps-lock-key/"&gt;first wrote about this in “A Useful Caps Lock Key”&lt;/a&gt; in 2012.&lt;/p&gt; &lt;h3 id="hyper-shifted"&gt;Hyper… shifted?&lt;/h3&gt; &lt;p&gt;One big advantage to using Hammerspoon as a “man-in-the-middle” is using modifiers with your hyper key. Because your “hyper key” &lt;strong&gt;is not&lt;/strong&gt; a cluster of modifier keys, you can actually use it in conjunction with any normal modifiers.&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;-- Press `HYPER+r`, get the Hammerspoon console.&lt;/span&gt; &lt;span&gt;hyper&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;bind&lt;/span&gt;&lt;span&gt;({},&lt;/span&gt; &lt;span&gt;'r'&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;function&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;hs&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;console&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;hswindow&lt;/span&gt;&lt;span&gt;():&lt;/span&gt;&lt;span&gt;focus&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;end&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-- Because my `HYPER` is actually F19,&lt;/span&gt; &lt;span&gt;-- I can press `HYPER+SHIFT+R`&lt;/span&gt; &lt;span&gt;--&lt;/span&gt; &lt;span&gt;-- Press `HYPER+⇧+R`, reload Hammerspoon configuration.&lt;/span&gt; &lt;span&gt;hyper&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;bind&lt;/span&gt;&lt;span&gt;({&lt;/span&gt;&lt;span&gt;'shift'&lt;/span&gt;&lt;span&gt;},&lt;/span&gt; &lt;span&gt;'r'&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;function&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;hs&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;reload&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;end&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;(from &lt;a href="https://github.com/evantravers/hammerspoon-config/blob/38a7d8c0ad2190d1563d681725628e4399dcbe6c/init.lua#L167-L168"&gt;init.lua&lt;/a&gt;)&lt;/p&gt; &lt;p&gt;I presently only use this in a few bindings, but I’m excited about all kinds of interesting ways to use it: quitting instead of launching an app, automatically choosing a window layout, the options are endless!&lt;/p&gt; &lt;h3 id="truly-global-hotkeys-local-bindings"&gt;Truly Global Hotkeys: Local Bindings&lt;/h3&gt; &lt;p&gt;There is one problem… if you want to use your hyper key to bind to an in-app Preference…&amp;nbsp;&lt;code&gt;F19&lt;/code&gt; is not supported by all applications.&lt;/p&gt; &lt;figure&gt; &lt;img alt="Preference pane for Things 3, showing the Quick Capture." src="http://evantravers.com/images/articles/2020/06/things-prefs.png"&gt; &lt;figcaption&gt; &lt;p&gt;Things will not recognize &lt;code&gt;F19&lt;/code&gt; as a keycode, or a modifier.&lt;/p&gt; &lt;p&gt;To handle this, when I press &lt;code&gt;F19+.&lt;/code&gt; Hammerspoon translates &lt;a href="https://github.com/evantravers/hammerspoon-config/blob/38a7d8c0ad2190d1563d681725628e4399dcbe6c/init.lua#L69"&gt;that local binding&lt;/a&gt; as if I’m pressing &lt;code&gt;⌘⇧⌥⌃+.&lt;/code&gt;.&lt;/p&gt; &lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;Many apps give you the ability to set a hotkey in their preference panes for certain “global” tasks.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Create to-do’s in Things 3.&lt;/li&gt; &lt;li&gt;Open the Quick Capture in Drafts.app.&lt;/li&gt; &lt;li&gt;Open the clipboard history, file manager, and main search window of Alfred.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;To answer this, I have developed a concept of “local bindings.” If you set any &lt;code&gt;local_binding&lt;/code&gt; key for the configuration, hyper.lua will intercept the &lt;code&gt;F19+&amp;lt;key&amp;gt;&lt;/code&gt; keypress and instead send the traditional &lt;code&gt;⌘⇧⌥⌃+&amp;lt;key&amp;gt;&lt;/code&gt; to the operating system…&amp;nbsp;just like the Traditional model. First, set up the local bindings to the app in Hammerspoon. Then, use your new local bindings in the preference pane of the app of your choice.&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;if&lt;/span&gt; &lt;span&gt;app&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;local_bindings&lt;/span&gt; &lt;span&gt;then&lt;/span&gt; &lt;span&gt;-- for key in app.local_bindings&lt;/span&gt; &lt;span&gt;for&lt;/span&gt; &lt;span&gt;_&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;key&lt;/span&gt; &lt;span&gt;in&lt;/span&gt; &lt;span&gt;pairs&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;app&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;local_bindings&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;do&lt;/span&gt; &lt;span&gt;hyper&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;bind&lt;/span&gt;&lt;span&gt;({},&lt;/span&gt; &lt;span&gt;key&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;function&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;..&lt;/span&gt;&lt;span&gt;]&lt;/span&gt; &lt;span&gt;-- send hyper chord + key&lt;/span&gt; &lt;span&gt;hs&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;eventtap&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;keyStroke&lt;/span&gt;&lt;span&gt;({&lt;/span&gt;&lt;span&gt;'cmd'&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;'alt'&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;'shift'&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;'ctrl'&lt;/span&gt;&lt;span&gt;},&lt;/span&gt; &lt;span&gt;key&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;..&lt;/span&gt;&lt;span&gt;]&lt;/span&gt; &lt;span&gt;end&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;end&lt;/span&gt; &lt;span&gt;end&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;(from &lt;a href="https://github.com/evantravers/hammerspoon-config/blob/38a7d8c0ad2190d1563d681725628e4399dcbe6c/hyper.lua#L79-L94"&gt;hyper.lua&lt;/a&gt;)&lt;/p&gt; &lt;h3 id="even-when-the-app-is-closed"&gt;Even when the app is closed&lt;/h3&gt; &lt;p&gt;In addition, I have incorporated an idea from &lt;a href="https://thesweetsetup.com/oopsiethings-applescript-for-things-on-mac/"&gt;Shawn Blanc’s OopsieThings applescript&lt;/a&gt;. If the you trigger a local binding and Hammerspoon sees that app isn’t open, it’ll open it for you and &lt;em&gt;then&lt;/em&gt; send the binding.&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;-- if the app is open&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;hs&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;application&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;find&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;app&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;bundleID&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;then&lt;/span&gt; &lt;span&gt;-- send hyper chord&lt;/span&gt; &lt;span&gt;hs&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;eventtap&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;keyStroke&lt;/span&gt;&lt;span&gt;({&lt;/span&gt;&lt;span&gt;'cmd'&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;'alt'&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;'shift'&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;'ctrl'&lt;/span&gt;&lt;span&gt;},&lt;/span&gt; &lt;span&gt;key&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;else&lt;/span&gt; &lt;span&gt;-- launch the app&lt;/span&gt; &lt;span&gt;hyper&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;launch&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;app&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;-- wait for it to launch&lt;/span&gt; &lt;span&gt;hs&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;timer&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;waitWhile&lt;/span&gt;&lt;span&gt;(&lt;/span&gt; &lt;span&gt;function&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;hs&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;application&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;find&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;app&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;bundleID&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt; &lt;span&gt;end&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;function&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;-- then send hyper chord + key&lt;/span&gt; &lt;span&gt;hs&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;eventtap&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;keyStroke&lt;/span&gt;&lt;span&gt;({&lt;/span&gt;&lt;span&gt;'cmd'&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;'alt'&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;'shift'&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;'ctrl'&lt;/span&gt;&lt;span&gt;},&lt;/span&gt; &lt;span&gt;key&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;end&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;end&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;That way my “send a tweet using Tweetbot” or “make a Draft” or especially “make a to-do in Things” buttons &lt;strong&gt;always&lt;/strong&gt; work, regardless of whether the app is accidentally closed. 👍&lt;/p&gt; &lt;h2 id="configuration"&gt;Configuration&lt;/h2&gt; &lt;p&gt;Hammerspoon loads an &lt;code&gt;init.lua&lt;/code&gt; file by default…&amp;nbsp;so I have a couple of configuration tables declared in there that I pass into the other modules.&lt;/p&gt; &lt;p&gt;I used to declare &lt;code&gt;config&lt;/code&gt; as a global and just let all the other modules use it, but I wanted to make sure the modules can use whatever anyone wants to use,&lt;sup id="fnref1"&gt;&lt;a href="#fn1"&gt;1&lt;/a&gt;&lt;/sup&gt; so now each module has a &lt;code&gt;.start()&lt;/code&gt; method that takes as an argument a config table. Since lua stores nearly everything as a reference, I’m not worried about blowing out memory.&lt;/p&gt; &lt;p&gt;Here is a minimalist example of a config for hyper.lua. I’ve removed some of the other keys and values for some of the other modules for the sake of discussion… just the config to launch Things 3, create local bindings for the capture options, and a quick function to reload the Hammerspoon config file.&lt;/p&gt; &lt;div&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;config&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;{}&lt;/span&gt; &lt;span&gt;config&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;applications&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;'Things'&lt;/span&gt;&lt;span&gt;]&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;bundleID&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'com.culturedcode.ThingsMac'&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;hyper_key&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'t'&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;local_bindings&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;','&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;'.'&lt;/span&gt;&lt;span&gt;}&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;span&gt;-- load as global, it's going to be used&lt;/span&gt; &lt;span&gt;hyper&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;require&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;'hyper'&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;hyper&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;start&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;config&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;hyper&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;bind&lt;/span&gt;&lt;span&gt;({&lt;/span&gt;&lt;span&gt;'shift'&lt;/span&gt;&lt;span&gt;},&lt;/span&gt; &lt;span&gt;'r'&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;function&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;hs&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;reload&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;end&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;It’s very straightforward. My most common use of Hyper.lua is to launch an application, so I have a table of applications that I can define a “hyper key” for, and optionally some local bindings that I bind inside that application to use globally.&lt;/p&gt; &lt;p&gt;I use hyper.lua as the “entry point” for nearly all my Hammerspoon based automation… it’s great. All my keybindings are declared in one place, and I &lt;strong&gt;know&lt;/strong&gt; they will never conflict with any new applications that I download. No more discovering that weird app behavior is due to a double-bound keybinding.&lt;/p&gt; &lt;p&gt;As this series continues, I’ll list the examples of how I connect hyper.lua to other automations here.&lt;/p&gt; &lt;p&gt;If you want to &lt;a href="https://github.com/evantravers/hammerspoon-config/blob/abc945264a4ec1830083c53079b2bfd5c4a4d23d/hyper.lua"&gt;read Hyper.lua at the time of this blog post, it’s available on my GitHub&lt;/a&gt;. It’s possible it’s gone through new versions since this post. There’s a few features in there now that I am not covering in this post, but we’ll get to them later in this series.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="http://evantravers.com/articles/2020/06/08/hammerspoon-a-better-better-hyper-key/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sun, 7 Feb 2021 15:00:18 UT
      </pubDate>
      <guid>
        http://evantravers.com/articles/2020/06/08/hammerspoon-a-better-better-hyper-key/
      </guid>
    </item>
    <item>
      <title>
        Silly job interview questions in Haskell
      </title>
      <link>
        https://chrispenner.ca/posts/interview
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;article&gt; &lt;p&gt;Today I thought it'd be fun to take a look at a few common &amp;amp; simple "interview questions" in Haskell. These sorts of questions are often used to establish whether someone has programming and problem solving skills, and I thought it might be useful for folks to see how they play out in Haskell since our beloved language's solutions tend to follow a different paradigm than most other languages do. I'll withhold any judgement on whether these questions are in any way helpful in determining programming skill whatsoever 😅; please don't @ me about it.&lt;/p&gt; &lt;h2 id="palindromes"&gt;Palindromes&lt;/h2&gt; &lt;p&gt;Let's start off nice and easy with the standard "is it a palindrome" question! The task is to write a function which determines whether a given string is a palindrome (i.e. whether it reads the same in both reverse and forwards)&lt;/p&gt; &lt;div id="cb1"&gt;&lt;pre&gt;&lt;code&gt;&lt;span id="cb1-1"&gt;&lt;a href="#cb1-1"&gt;&lt;/a&gt;&lt;span&gt;isPalindrome ::&lt;/span&gt; &lt;span&gt;String&lt;/span&gt; &lt;span&gt;-&amp;gt;&lt;/span&gt; &lt;span&gt;Bool&lt;/span&gt;&lt;/span&gt; &lt;span id="cb1-2"&gt;&lt;a href="#cb1-2"&gt;&lt;/a&gt;isPalindrome str &lt;span&gt;=&lt;/span&gt; str &lt;span&gt;==&lt;/span&gt; &lt;span&gt;reverse&lt;/span&gt; str&lt;/span&gt; &lt;span id="cb1-3"&gt;&lt;a href="#cb1-3"&gt;&lt;/a&gt;&lt;/span&gt; &lt;span id="cb1-4"&gt;&lt;a href="#cb1-4"&gt;&lt;/a&gt;&lt;span&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; isPalindrome &lt;span&gt;"racecar"&lt;/span&gt;&lt;/span&gt; &lt;span id="cb1-5"&gt;&lt;a href="#cb1-5"&gt;&lt;/a&gt;&lt;span&gt;True&lt;/span&gt;&lt;/span&gt; &lt;span id="cb1-6"&gt;&lt;a href="#cb1-6"&gt;&lt;/a&gt;&lt;/span&gt; &lt;span id="cb1-7"&gt;&lt;a href="#cb1-7"&gt;&lt;/a&gt;&lt;span&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; isPalindrome &lt;span&gt;"hello world!"&lt;/span&gt;&lt;/span&gt; &lt;span id="cb1-8"&gt;&lt;a href="#cb1-8"&gt;&lt;/a&gt;&lt;span&gt;False&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;That'll do it! Not much to say about this one, it's nice that our definition roughly matches an English sentence describing the problem "does a given string equal itself in reverse". I'll leave it as an exercise for the reader to expand it to handle differences in capitalization however you like.&lt;/p&gt; &lt;h2 id="fizz-buzz"&gt;Fizz Buzz&lt;/h2&gt; &lt;p&gt;Next up is the infamous Fizz Buzz! For the 3 of you who are unfamiliar, for each number from 1 to 100 we need to print out "Fizz" if it's divisible by 3, "Buzz" if it's divisible by 5, and "Fizz Buzz" if it's divisible by both 3 AND 5! Otherwise we print the number itself.&lt;/p&gt; &lt;p&gt;Let's see it!&lt;/p&gt; &lt;div id="cb2"&gt;&lt;pre&gt;&lt;code&gt;&lt;span id="cb2-1"&gt;&lt;a href="#cb2-1"&gt;&lt;/a&gt;&lt;span&gt;import&lt;/span&gt; &lt;span&gt;Data.Foldable&lt;/span&gt;&lt;/span&gt; &lt;span id="cb2-2"&gt;&lt;a href="#cb2-2"&gt;&lt;/a&gt;&lt;/span&gt; &lt;span id="cb2-3"&gt;&lt;a href="#cb2-3"&gt;&lt;/a&gt;&lt;span&gt;fizzle ::&lt;/span&gt; &lt;span&gt;Int&lt;/span&gt; &lt;span&gt;-&amp;gt;&lt;/span&gt; &lt;span&gt;String&lt;/span&gt;&lt;/span&gt; &lt;span id="cb2-4"&gt;&lt;a href="#cb2-4"&gt;&lt;/a&gt;fizzle n&lt;/span&gt; &lt;span id="cb2-5"&gt;&lt;a href="#cb2-5"&gt;&lt;/a&gt; &lt;span&gt;|&lt;/span&gt; n &lt;span&gt;`mod`&lt;/span&gt; &lt;span&gt;3&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;0&lt;/span&gt; &lt;span&gt;&amp;amp;&amp;amp;&lt;/span&gt; n &lt;span&gt;`mod`&lt;/span&gt; &lt;span&gt;5&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;0&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;"Fizz Buzz!"&lt;/span&gt;&lt;/span&gt; &lt;span id="cb2-6"&gt;&lt;a href="#cb2-6"&gt;&lt;/a&gt; &lt;span&gt;|&lt;/span&gt; n &lt;span&gt;`mod`&lt;/span&gt; &lt;span&gt;3&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;0&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;"Fizz!"&lt;/span&gt;&lt;/span&gt; &lt;span id="cb2-7"&gt;&lt;a href="#cb2-7"&gt;&lt;/a&gt; &lt;span&gt;|&lt;/span&gt; n &lt;span&gt;`mod`&lt;/span&gt; &lt;span&gt;5&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;0&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;"Buzz!"&lt;/span&gt;&lt;/span&gt; &lt;span id="cb2-8"&gt;&lt;a href="#cb2-8"&gt;&lt;/a&gt; &lt;span&gt;|&lt;/span&gt; &lt;span&gt;otherwise&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;show&lt;/span&gt; n&lt;/span&gt; &lt;span id="cb2-9"&gt;&lt;a href="#cb2-9"&gt;&lt;/a&gt;&lt;/span&gt; &lt;span id="cb2-10"&gt;&lt;a href="#cb2-10"&gt;&lt;/a&gt;&lt;span&gt;main ::&lt;/span&gt; &lt;span&gt;IO&lt;/span&gt; ()&lt;/span&gt; &lt;span id="cb2-11"&gt;&lt;a href="#cb2-11"&gt;&lt;/a&gt;main &lt;span&gt;=&lt;/span&gt; &lt;span&gt;do&lt;/span&gt;&lt;/span&gt; &lt;span id="cb2-12"&gt;&lt;a href="#cb2-12"&gt;&lt;/a&gt; for_ [&lt;span&gt;1&lt;/span&gt;&lt;span&gt;..&lt;/span&gt;&lt;span&gt;100&lt;/span&gt;] (&lt;span&gt;putStrLn&lt;/span&gt; &lt;span&gt;.&lt;/span&gt; fizzle)&lt;/span&gt; &lt;span id="cb2-13"&gt;&lt;a href="#cb2-13"&gt;&lt;/a&gt;&lt;/span&gt; &lt;span id="cb2-14"&gt;&lt;a href="#cb2-14"&gt;&lt;/a&gt;&lt;/span&gt; &lt;span id="cb2-15"&gt;&lt;a href="#cb2-15"&gt;&lt;/a&gt;&lt;span&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; main&lt;/span&gt; &lt;span id="cb2-16"&gt;&lt;a href="#cb2-16"&gt;&lt;/a&gt;&lt;span&gt;1&lt;/span&gt;&lt;/span&gt; &lt;span id="cb2-17"&gt;&lt;a href="#cb2-17"&gt;&lt;/a&gt;&lt;span&gt;2&lt;/span&gt;&lt;/span&gt; &lt;span id="cb2-18"&gt;&lt;a href="#cb2-18"&gt;&lt;/a&gt;&lt;span&gt;Fizz&lt;/span&gt;&lt;span&gt;!&lt;/span&gt;&lt;/span&gt; &lt;span id="cb2-19"&gt;&lt;a href="#cb2-19"&gt;&lt;/a&gt;&lt;span&gt;4&lt;/span&gt;&lt;/span&gt; &lt;span id="cb2-20"&gt;&lt;a href="#cb2-20"&gt;&lt;/a&gt;&lt;span&gt;Buzz&lt;/span&gt;&lt;span&gt;!&lt;/span&gt;&lt;/span&gt; &lt;span id="cb2-21"&gt;&lt;a href="#cb2-21"&gt;&lt;/a&gt;&lt;span&gt;Fizz&lt;/span&gt;&lt;span&gt;!&lt;/span&gt;&lt;/span&gt; &lt;span id="cb2-22"&gt;&lt;a href="#cb2-22"&gt;&lt;/a&gt;&lt;span&gt;7&lt;/span&gt;&lt;/span&gt; &lt;span id="cb2-23"&gt;&lt;a href="#cb2-23"&gt;&lt;/a&gt;&lt;span&gt;8&lt;/span&gt;&lt;/span&gt; &lt;span id="cb2-24"&gt;&lt;a href="#cb2-24"&gt;&lt;/a&gt;&lt;span&gt;Fizz&lt;/span&gt;&lt;span&gt;!&lt;/span&gt;&lt;/span&gt; &lt;span id="cb2-25"&gt;&lt;a href="#cb2-25"&gt;&lt;/a&gt;&lt;span&gt;Buzz&lt;/span&gt;&lt;span&gt;!&lt;/span&gt;&lt;/span&gt; &lt;span id="cb2-26"&gt;&lt;a href="#cb2-26"&gt;&lt;/a&gt;&lt;span&gt;11&lt;/span&gt;&lt;/span&gt; &lt;span id="cb2-27"&gt;&lt;a href="#cb2-27"&gt;&lt;/a&gt;&lt;span&gt;Fizz&lt;/span&gt;&lt;span&gt;!&lt;/span&gt;&lt;/span&gt; &lt;span id="cb2-28"&gt;&lt;a href="#cb2-28"&gt;&lt;/a&gt;&lt;span&gt;13&lt;/span&gt;&lt;/span&gt; &lt;span id="cb2-29"&gt;&lt;a href="#cb2-29"&gt;&lt;/a&gt;&lt;span&gt;14&lt;/span&gt;&lt;/span&gt; &lt;span id="cb2-30"&gt;&lt;a href="#cb2-30"&gt;&lt;/a&gt;&lt;span&gt;Fizz&lt;/span&gt; &lt;span&gt;Buzz&lt;/span&gt;&lt;span&gt;!&lt;/span&gt;&lt;/span&gt; &lt;span id="cb2-31"&gt;&lt;a href="#cb2-31"&gt;&lt;/a&gt;&lt;span&gt;16&lt;/span&gt;&lt;/span&gt; &lt;span id="cb2-32"&gt;&lt;a href="#cb2-32"&gt;&lt;/a&gt;&lt;span&gt;-- ...you get the idea&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;I write a helper function "fizzle" here which converts a number into its appropriate string so I can keep the "printing" logic separate, which is good programming style in Haskell as it makes things easier to both test and reason about.&lt;/p&gt; &lt;p&gt;We can see that "case analysis" is very helpful for these sorts of problems, I'm using "pattern guards" to do a sort of multi-way if statement. Since "divisible by both 3 &amp;amp; 5" overlaps with the other conditions and also is the most restrictive, we check for that one first, then check the other two cases falling back on returning the string version of the number itself. It all works beautifully!&lt;/p&gt; &lt;p&gt;I really enjoy looking at this problem as an example of how Haskell is different from other languages. Most things in Haskell are &lt;em&gt;functions&lt;/em&gt;, even our loops are just higher-order functions! The nice thing about that is that functions are &lt;em&gt;composable&lt;/em&gt; and have very clean boundaries, which means we don't need to intermingle the &lt;strong&gt;syntax&lt;/strong&gt; of a &lt;strong&gt;for-loop&lt;/strong&gt; with our logic. It's these same principles which allow us to easily separate our &lt;em&gt;effectful&lt;/em&gt; printing logic from our function which computes the output string.&lt;/p&gt; &lt;p&gt;The next difference we can see is that we use pattern-matching, specifically "pattern guards", which allow us to select which definition of a function we want to use. It looks a bit like a glorified if-statement, but I find it's less syntactic noise once you get used to it, and there are many more things pattern guards can do!&lt;/p&gt; &lt;p&gt;All that's left is to loop over all the numbers and print them out one by one, which is a snap thanks to the &lt;code&gt;for_&lt;/code&gt; function!&lt;/p&gt; &lt;p&gt;Next!&lt;/p&gt; &lt;h3 id="sum-up-to-n-problem"&gt;Sum up to N problem&lt;/h3&gt; &lt;p&gt;Here's a less-common problem that nonetheless I've still heard a few times! I think it was in one of my algorithms assignments back in the day...&lt;/p&gt; &lt;p&gt;The task is to take a &lt;strong&gt;list of numbers&lt;/strong&gt; and find any &lt;strong&gt;combinations of &lt;em&gt;3&lt;/em&gt; numbers&lt;/strong&gt; which add up to a specified total. For instance, if we want to determine all combinations of &lt;strong&gt;3&lt;/strong&gt; numbers which add up to &lt;strong&gt;15&lt;/strong&gt;, we'd expect our result to look something like this:&lt;/p&gt; &lt;div id="cb3"&gt;&lt;pre&gt;&lt;code&gt;&lt;span id="cb3-1"&gt;&lt;a href="#cb3-1"&gt;&lt;/a&gt;&lt;span&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; sumToN &lt;span&gt;15&lt;/span&gt; [&lt;span&gt;2&lt;/span&gt;, &lt;span&gt;5&lt;/span&gt;, &lt;span&gt;3&lt;/span&gt;, &lt;span&gt;10&lt;/span&gt;, &lt;span&gt;4&lt;/span&gt;, &lt;span&gt;1&lt;/span&gt;, &lt;span&gt;0&lt;/span&gt;]&lt;/span&gt; &lt;span id="cb3-2"&gt;&lt;a href="#cb3-2"&gt;&lt;/a&gt;[[&lt;span&gt;2&lt;/span&gt;,&lt;span&gt;3&lt;/span&gt;,&lt;span&gt;10&lt;/span&gt;],[&lt;span&gt;5&lt;/span&gt;,&lt;span&gt;10&lt;/span&gt;,&lt;span&gt;0&lt;/span&gt;],[&lt;span&gt;10&lt;/span&gt;,&lt;span&gt;4&lt;/span&gt;,&lt;span&gt;1&lt;/span&gt;]]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;Notice how each inner list sums to 15? We only care about &lt;em&gt;combinations&lt;/em&gt; here, not &lt;em&gt;permutations&lt;/em&gt;, so we have &lt;code&gt;[2, 3, 10]&lt;/code&gt;, but don't bother with &lt;code&gt;[3, 2, 10]&lt;/code&gt;!&lt;/p&gt; &lt;p&gt;So how will we set about implementing an algorithm for this? Well, the first thing to come to mind here is that we're finding &lt;em&gt;combinations&lt;/em&gt;, then we're filtering them down to match a predicate!&lt;/p&gt; &lt;p&gt;In Haskell we like to split problems into smaller composable pieces, the filter part should be pretty easy, so let's tackle the combinations problem first.&lt;/p&gt; &lt;p&gt;After a quick look through hackage it looks like there &lt;em&gt;is&lt;/em&gt; a &lt;a href="https://hackage.haskell.org/package/base-4.14.0.0/docs/Data-List.html#v:permutations"&gt;&lt;code&gt;permutations&lt;/code&gt;&lt;/a&gt; function, but strangely there's no &lt;code&gt;combinations&lt;/code&gt; function! I suppose we could somehow try to de-duplicate the output of &lt;code&gt;permutations&lt;/code&gt;, but it'll be fun to write our own version! &lt;code&gt;combinations&lt;/code&gt; are quite nice to compute recursively, so let's try it that way!&lt;/p&gt; &lt;div id="cb4"&gt;&lt;pre&gt;&lt;code&gt;&lt;span id="cb4-1"&gt;&lt;a href="#cb4-1"&gt;&lt;/a&gt;&lt;span&gt;combinations ::&lt;/span&gt; &lt;span&gt;Int&lt;/span&gt; &lt;span&gt;-&amp;gt;&lt;/span&gt; [a] &lt;span&gt;-&amp;gt;&lt;/span&gt; [[a]]&lt;/span&gt; &lt;span id="cb4-2"&gt;&lt;a href="#cb4-2"&gt;&lt;/a&gt;&lt;span&gt;-- Only one way to get zero things&lt;/span&gt;&lt;/span&gt; &lt;span id="cb4-3"&gt;&lt;a href="#cb4-3"&gt;&lt;/a&gt;combinations &lt;span&gt;0&lt;/span&gt; _ &lt;span&gt;=&lt;/span&gt; [[]]&lt;/span&gt; &lt;span id="cb4-4"&gt;&lt;a href="#cb4-4"&gt;&lt;/a&gt;combinations n (x&lt;span&gt;:&lt;/span&gt;xs) &lt;span&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span id="cb4-5"&gt;&lt;a href="#cb4-5"&gt;&lt;/a&gt; &lt;span&gt;-- Get all combinations containing x by appending x to all (n-1)&lt;/span&gt;&lt;/span&gt; &lt;span id="cb4-6"&gt;&lt;a href="#cb4-6"&gt;&lt;/a&gt; &lt;span&gt;-- combinations of the rest of the list&lt;/span&gt;&lt;/span&gt; &lt;span id="cb4-7"&gt;&lt;a href="#cb4-7"&gt;&lt;/a&gt; &lt;span&gt;fmap&lt;/span&gt; (x&lt;span&gt;:&lt;/span&gt;) (combinations (n&lt;span&gt;-&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;) xs)&lt;/span&gt; &lt;span id="cb4-8"&gt;&lt;a href="#cb4-8"&gt;&lt;/a&gt; &lt;span&gt;-- Combine it with all combinations from the rest of the list&lt;/span&gt;&lt;/span&gt; &lt;span id="cb4-9"&gt;&lt;a href="#cb4-9"&gt;&lt;/a&gt; &lt;span&gt;&amp;lt;&amp;gt;&lt;/span&gt; combinations n xs&lt;/span&gt; &lt;span id="cb4-10"&gt;&lt;a href="#cb4-10"&gt;&lt;/a&gt;&lt;span&gt;-- No elements means no combinations!&lt;/span&gt;&lt;/span&gt; &lt;span id="cb4-11"&gt;&lt;a href="#cb4-11"&gt;&lt;/a&gt;combinations _ [] &lt;span&gt;=&lt;/span&gt; []&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;Here we're using pattern matching and recursion to do our dirty work. First we can confidently say that there's only ONE way to get 0 elements from &lt;strong&gt;any&lt;/strong&gt; list of elements, so we can fill that in. Next we'll handle a single step, if we have at least one element left in the list, we can compute all the combinations which contain that element by prepending it to all the combinations of size &lt;code&gt;n-1&lt;/code&gt; from the remainder of the list; and we'll concatenate that with all the combinations of the &lt;strong&gt;rest&lt;/strong&gt; of the list.&lt;/p&gt; &lt;p&gt;Lastly we add one more pattern match which handles all invalid inputs (either negative numbers or empty lists) and simply assert that they have no valid combinations.&lt;/p&gt; &lt;p&gt;Let's try out our implementation before we move on to the next part.&lt;/p&gt; &lt;div id="cb5"&gt;&lt;pre&gt;&lt;code&gt;&lt;span id="cb5-1"&gt;&lt;a href="#cb5-1"&gt;&lt;/a&gt;&lt;span&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; combinations &lt;span&gt;3&lt;/span&gt; [&lt;span&gt;1&lt;/span&gt;&lt;span&gt;..&lt;/span&gt;&lt;span&gt;5&lt;/span&gt;]&lt;/span&gt; &lt;span id="cb5-2"&gt;&lt;a href="#cb5-2"&gt;&lt;/a&gt;[[&lt;span&gt;1&lt;/span&gt;,&lt;span&gt;2&lt;/span&gt;,&lt;span&gt;3&lt;/span&gt;],[&lt;span&gt;1&lt;/span&gt;,&lt;span&gt;2&lt;/span&gt;,&lt;span&gt;4&lt;/span&gt;],[&lt;span&gt;1&lt;/span&gt;,&lt;span&gt;2&lt;/span&gt;,&lt;span&gt;5&lt;/span&gt;],[&lt;span&gt;1&lt;/span&gt;,&lt;span&gt;3&lt;/span&gt;,&lt;span&gt;4&lt;/span&gt;],[&lt;span&gt;1&lt;/span&gt;,&lt;span&gt;3&lt;/span&gt;,&lt;span&gt;5&lt;/span&gt;],[&lt;span&gt;1&lt;/span&gt;,&lt;span&gt;4&lt;/span&gt;,&lt;span&gt;5&lt;/span&gt;],[&lt;span&gt;2&lt;/span&gt;,&lt;span&gt;3&lt;/span&gt;,&lt;span&gt;4&lt;/span&gt;],[&lt;span&gt;2&lt;/span&gt;,&lt;span&gt;3&lt;/span&gt;,&lt;span&gt;5&lt;/span&gt;],[&lt;span&gt;2&lt;/span&gt;,&lt;span&gt;4&lt;/span&gt;,&lt;span&gt;5&lt;/span&gt;],[&lt;span&gt;3&lt;/span&gt;,&lt;span&gt;4&lt;/span&gt;,&lt;span&gt;5&lt;/span&gt;]]&lt;/span&gt; &lt;span id="cb5-3"&gt;&lt;a href="#cb5-3"&gt;&lt;/a&gt;&lt;span&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; combinations &lt;span&gt;2&lt;/span&gt; [&lt;span&gt;1&lt;/span&gt;&lt;span&gt;..&lt;/span&gt;&lt;span&gt;4&lt;/span&gt;]&lt;/span&gt; &lt;span id="cb5-4"&gt;&lt;a href="#cb5-4"&gt;&lt;/a&gt;[[&lt;span&gt;1&lt;/span&gt;,&lt;span&gt;2&lt;/span&gt;],[&lt;span&gt;1&lt;/span&gt;,&lt;span&gt;3&lt;/span&gt;],[&lt;span&gt;1&lt;/span&gt;,&lt;span&gt;4&lt;/span&gt;],[&lt;span&gt;2&lt;/span&gt;,&lt;span&gt;3&lt;/span&gt;],[&lt;span&gt;2&lt;/span&gt;,&lt;span&gt;4&lt;/span&gt;],[&lt;span&gt;3&lt;/span&gt;,&lt;span&gt;4&lt;/span&gt;]]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;Feel free to take the time to convince yourself that these are correct 😀&lt;/p&gt; &lt;p&gt;To finish it off we need to find any of these combinations which add up to our target number.&lt;/p&gt; &lt;div id="cb6"&gt;&lt;pre&gt;&lt;code&gt;&lt;span id="cb6-1"&gt;&lt;a href="#cb6-1"&gt;&lt;/a&gt;&lt;span&gt;sumNToTotal ::&lt;/span&gt; &lt;span&gt;Int&lt;/span&gt; &lt;span&gt;-&amp;gt;&lt;/span&gt; &lt;span&gt;Int&lt;/span&gt; &lt;span&gt;-&amp;gt;&lt;/span&gt; [&lt;span&gt;Int&lt;/span&gt;] &lt;span&gt;-&amp;gt;&lt;/span&gt; [[&lt;span&gt;Int&lt;/span&gt;]]&lt;/span&gt; &lt;span id="cb6-2"&gt;&lt;a href="#cb6-2"&gt;&lt;/a&gt;sumNToTotal n totalNeeded xs &lt;span&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span id="cb6-3"&gt;&lt;a href="#cb6-3"&gt;&lt;/a&gt; &lt;span&gt;filter&lt;/span&gt; matchesSum (combinations n xs)&lt;/span&gt; &lt;span id="cb6-4"&gt;&lt;a href="#cb6-4"&gt;&lt;/a&gt; &lt;span&gt;where&lt;/span&gt;&lt;/span&gt; &lt;span id="cb6-5"&gt;&lt;a href="#cb6-5"&gt;&lt;/a&gt; matchesSum ys &lt;span&gt;=&lt;/span&gt; &lt;span&gt;sum&lt;/span&gt; ys &lt;span&gt;==&lt;/span&gt; totalNeeded&lt;/span&gt; &lt;span id="cb6-6"&gt;&lt;a href="#cb6-6"&gt;&lt;/a&gt;&lt;/span&gt; &lt;span id="cb6-7"&gt;&lt;a href="#cb6-7"&gt;&lt;/a&gt;&lt;/span&gt; &lt;span id="cb6-8"&gt;&lt;a href="#cb6-8"&gt;&lt;/a&gt;&lt;span&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; sumNToTotal &lt;span&gt;3&lt;/span&gt; &lt;span&gt;15&lt;/span&gt; [&lt;span&gt;2&lt;/span&gt;, &lt;span&gt;5&lt;/span&gt;, &lt;span&gt;3&lt;/span&gt;, &lt;span&gt;10&lt;/span&gt;, &lt;span&gt;4&lt;/span&gt;, &lt;span&gt;1&lt;/span&gt;, &lt;span&gt;0&lt;/span&gt;]&lt;/span&gt; &lt;span id="cb6-9"&gt;&lt;a href="#cb6-9"&gt;&lt;/a&gt;[[&lt;span&gt;2&lt;/span&gt;,&lt;span&gt;3&lt;/span&gt;,&lt;span&gt;10&lt;/span&gt;],[&lt;span&gt;5&lt;/span&gt;,&lt;span&gt;10&lt;/span&gt;,&lt;span&gt;0&lt;/span&gt;],[&lt;span&gt;10&lt;/span&gt;,&lt;span&gt;4&lt;/span&gt;,&lt;span&gt;1&lt;/span&gt;]]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;Great! We can simply get all possible combinations and filter out the results which don't properly sum to the expected number. One other nifty thing here is that, because Haskell is &lt;strong&gt;lazy&lt;/strong&gt;, if we only need to find the &lt;strong&gt;first&lt;/strong&gt; valid combination, we could just grab the first result of the list and Haskell won't do any more work than absolutely necessary.&lt;/p&gt; &lt;p&gt;But wait! There's a surprise &lt;strong&gt;part two&lt;/strong&gt; of this problem:&lt;/p&gt; &lt;p&gt;We now have to find all combinations of ANY length which sum to a target number, lucky for us, that's pretty easy for us to adapt for!&lt;/p&gt; &lt;div id="cb7"&gt;&lt;pre&gt;&lt;code&gt;&lt;span id="cb7-1"&gt;&lt;a href="#cb7-1"&gt;&lt;/a&gt;&lt;span&gt;sumAnyToTarget ::&lt;/span&gt; &lt;span&gt;Int&lt;/span&gt; &lt;span&gt;-&amp;gt;&lt;/span&gt; [&lt;span&gt;Int&lt;/span&gt;] &lt;span&gt;-&amp;gt;&lt;/span&gt; [[&lt;span&gt;Int&lt;/span&gt;]]&lt;/span&gt; &lt;span id="cb7-2"&gt;&lt;a href="#cb7-2"&gt;&lt;/a&gt;sumAnyToTarget totalNeeded xs&lt;/span&gt; &lt;span id="cb7-3"&gt;&lt;a href="#cb7-3"&gt;&lt;/a&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;foldMap&lt;/span&gt; (\n &lt;span&gt;-&amp;gt;&lt;/span&gt; sumNToTotal n totalNeeded xs) [&lt;span&gt;0&lt;/span&gt;&lt;span&gt;..&lt;/span&gt;&lt;span&gt;length&lt;/span&gt; xs]&lt;/span&gt; &lt;span id="cb7-4"&gt;&lt;a href="#cb7-4"&gt;&lt;/a&gt;&lt;/span&gt; &lt;span id="cb7-5"&gt;&lt;a href="#cb7-5"&gt;&lt;/a&gt;&lt;span&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; sumAnyToTarget &lt;span&gt;15&lt;/span&gt; [&lt;span&gt;2&lt;/span&gt;, &lt;span&gt;5&lt;/span&gt;, &lt;span&gt;3&lt;/span&gt;, &lt;span&gt;10&lt;/span&gt;, &lt;span&gt;4&lt;/span&gt;, &lt;span&gt;1&lt;/span&gt;, &lt;span&gt;0&lt;/span&gt;]&lt;/span&gt; &lt;span id="cb7-6"&gt;&lt;a href="#cb7-6"&gt;&lt;/a&gt;[ [&lt;span&gt;5&lt;/span&gt;,&lt;span&gt;10&lt;/span&gt;]&lt;/span&gt; &lt;span id="cb7-7"&gt;&lt;a href="#cb7-7"&gt;&lt;/a&gt;, [&lt;span&gt;2&lt;/span&gt;,&lt;span&gt;3&lt;/span&gt;,&lt;span&gt;10&lt;/span&gt;]&lt;/span&gt; &lt;span id="cb7-8"&gt;&lt;a href="#cb7-8"&gt;&lt;/a&gt;, [&lt;span&gt;5&lt;/span&gt;,&lt;span&gt;10&lt;/span&gt;,&lt;span&gt;0&lt;/span&gt;]&lt;/span&gt; &lt;span id="cb7-9"&gt;&lt;a href="#cb7-9"&gt;&lt;/a&gt;, [&lt;span&gt;10&lt;/span&gt;,&lt;span&gt;4&lt;/span&gt;,&lt;span&gt;1&lt;/span&gt;]&lt;/span&gt; &lt;span id="cb7-10"&gt;&lt;a href="#cb7-10"&gt;&lt;/a&gt;, [&lt;span&gt;2&lt;/span&gt;,&lt;span&gt;3&lt;/span&gt;,&lt;span&gt;10&lt;/span&gt;,&lt;span&gt;0&lt;/span&gt;]&lt;/span&gt; &lt;span id="cb7-11"&gt;&lt;a href="#cb7-11"&gt;&lt;/a&gt;, [&lt;span&gt;10&lt;/span&gt;,&lt;span&gt;4&lt;/span&gt;,&lt;span&gt;1&lt;/span&gt;,&lt;span&gt;0&lt;/span&gt;]&lt;/span&gt; &lt;span id="cb7-12"&gt;&lt;a href="#cb7-12"&gt;&lt;/a&gt;, [&lt;span&gt;2&lt;/span&gt;,&lt;span&gt;5&lt;/span&gt;,&lt;span&gt;3&lt;/span&gt;,&lt;span&gt;4&lt;/span&gt;,&lt;span&gt;1&lt;/span&gt;]&lt;/span&gt; &lt;span id="cb7-13"&gt;&lt;a href="#cb7-13"&gt;&lt;/a&gt;, [&lt;span&gt;2&lt;/span&gt;,&lt;span&gt;5&lt;/span&gt;,&lt;span&gt;3&lt;/span&gt;,&lt;span&gt;4&lt;/span&gt;,&lt;span&gt;1&lt;/span&gt;,&lt;span&gt;0&lt;/span&gt;]&lt;/span&gt; &lt;span id="cb7-14"&gt;&lt;a href="#cb7-14"&gt;&lt;/a&gt;]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;This new version re-uses the &lt;code&gt;sumNToTotal&lt;/code&gt; function we wrote in the previous step! It iterates over each possible length of combination and finds all the winning combinations using &lt;code&gt;sumNToTotal&lt;/code&gt;, then concatenates them using &lt;code&gt;foldMap&lt;/code&gt;! Works out pretty cleanly if I do say so myself!&lt;/p&gt; &lt;h2 id="check-if-two-strings-are-anagrams"&gt;Check if two strings are anagrams&lt;/h2&gt; &lt;p&gt;For whatever reason, interviewers LOVE string manipulation questions; so let's try another one!&lt;/p&gt; &lt;p&gt;Here our task is to determine whether two strings are anagrams of each other. I'd say the difficulty for this one comes from thinking up your &lt;em&gt;strategy&lt;/em&gt; rather than the implementation itself. Here's how I'd give this a go in Haskell!&lt;/p&gt; &lt;div id="cb8"&gt;&lt;pre&gt;&lt;code&gt;&lt;span id="cb8-1"&gt;&lt;a href="#cb8-1"&gt;&lt;/a&gt;&lt;span&gt;import&lt;/span&gt; &lt;span&gt;Data.Function&lt;/span&gt; (on)&lt;/span&gt; &lt;span id="cb8-2"&gt;&lt;a href="#cb8-2"&gt;&lt;/a&gt;&lt;span&gt;isAnagram ::&lt;/span&gt; &lt;span&gt;String&lt;/span&gt; &lt;span&gt;-&amp;gt;&lt;/span&gt; &lt;span&gt;String&lt;/span&gt; &lt;span&gt;-&amp;gt;&lt;/span&gt; &lt;span&gt;Bool&lt;/span&gt;&lt;/span&gt; &lt;span id="cb8-3"&gt;&lt;a href="#cb8-3"&gt;&lt;/a&gt;isAnagram &lt;span&gt;=&lt;/span&gt; (&lt;span&gt;==&lt;/span&gt;) &lt;span&gt;`on`&lt;/span&gt; &lt;span&gt;sort&lt;/span&gt;&lt;/span&gt; &lt;span id="cb8-4"&gt;&lt;a href="#cb8-4"&gt;&lt;/a&gt;&lt;/span&gt; &lt;span id="cb8-5"&gt;&lt;a href="#cb8-5"&gt;&lt;/a&gt;&lt;span&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; isAnagram &lt;span&gt;"elbow"&lt;/span&gt; &lt;span&gt;"below"&lt;/span&gt;&lt;/span&gt; &lt;span id="cb8-6"&gt;&lt;a href="#cb8-6"&gt;&lt;/a&gt;&lt;span&gt;True&lt;/span&gt;&lt;/span&gt; &lt;span id="cb8-7"&gt;&lt;a href="#cb8-7"&gt;&lt;/a&gt;&lt;span&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; isAnagram &lt;span&gt;"bored"&lt;/span&gt; &lt;span&gt;"road"&lt;/span&gt;&lt;/span&gt; &lt;span id="cb8-8"&gt;&lt;a href="#cb8-8"&gt;&lt;/a&gt;&lt;span&gt;False&lt;/span&gt;&lt;/span&gt; &lt;span id="cb8-9"&gt;&lt;a href="#cb8-9"&gt;&lt;/a&gt;&lt;span&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; isAnagram &lt;span&gt;"stressed"&lt;/span&gt; &lt;span&gt;"desserts"&lt;/span&gt;&lt;/span&gt; &lt;span id="cb8-10"&gt;&lt;a href="#cb8-10"&gt;&lt;/a&gt;&lt;span&gt;True&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;Here we're using a funky higher-order function called &lt;code&gt;on&lt;/code&gt;; &lt;code&gt;on&lt;/code&gt; takes two functions, AND THEN takes two arguments! In this case it calls "sort" on both arguments, then checks if the sorted results are equal! It turns out this is sufficient to know if two strings are anagrams!&lt;/p&gt; &lt;p&gt;But wait! What's that? What if they're in differing cases! Okay fine!&lt;/p&gt; &lt;div id="cb9"&gt;&lt;pre&gt;&lt;code&gt;&lt;span id="cb9-1"&gt;&lt;a href="#cb9-1"&gt;&lt;/a&gt;&lt;span&gt;import&lt;/span&gt; &lt;span&gt;Data.Char&lt;/span&gt; (toLower)&lt;/span&gt; &lt;span id="cb9-2"&gt;&lt;a href="#cb9-2"&gt;&lt;/a&gt;&lt;/span&gt; &lt;span id="cb9-3"&gt;&lt;a href="#cb9-3"&gt;&lt;/a&gt;&lt;span&gt;isAnagram ::&lt;/span&gt; &lt;span&gt;String&lt;/span&gt; &lt;span&gt;-&amp;gt;&lt;/span&gt; &lt;span&gt;String&lt;/span&gt; &lt;span&gt;-&amp;gt;&lt;/span&gt; &lt;span&gt;Bool&lt;/span&gt;&lt;/span&gt; &lt;span id="cb9-4"&gt;&lt;a href="#cb9-4"&gt;&lt;/a&gt;isAnagram a b &lt;span&gt;=&lt;/span&gt; (&lt;span&gt;==&lt;/span&gt;) &lt;span&gt;`on`&lt;/span&gt; (&lt;span&gt;sort&lt;/span&gt; &lt;span&gt;.&lt;/span&gt; &lt;span&gt;map&lt;/span&gt; &lt;span&gt;toLower&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;Happy now? No? What's that? It seems non-performant? Well yes, but actually no!&lt;/p&gt; &lt;p&gt;While it's true that sort has an &lt;code&gt;O(nlogn)&lt;/code&gt; performance profile, one interesting thing here is that sorting is &lt;strong&gt;lazy&lt;/strong&gt; in Haskell! This means that if our two strings are unequal, they will only be sorted far enough to determine inequality! In fact, if the first elements of each sorted string aren't equal to each other, then we won't bother sorting any more.&lt;/p&gt; &lt;p&gt;Sure, our function isn't perfect, but it's not bad, especially since this is the first approach that came to mind. Compare our 2 line solution with the &lt;a href="https://javarevisited.blogspot.com/2013/03/Anagram-how-to-check-if-two-string-are-anagrams-example-tutorial.html"&gt;Java Solution&lt;/a&gt; provided in the post which gave me the idea for this problem. It might be more performant (though to be honest I haven't benchmarked them), but if I'm going to be reading this code often in the future, I'd much prefer the clearest version which performs at an adequate level.&lt;/p&gt; &lt;h2 id="min-and-max"&gt;Min and Max&lt;/h2&gt; &lt;p&gt;Here's a problem! Given a list of elements, find the smallest and largest element of that list!&lt;/p&gt; &lt;p&gt;I'll show and discuss three different strategies for this one.&lt;/p&gt; &lt;p&gt;Here's the first:&lt;/p&gt; &lt;div id="cb10"&gt;&lt;pre&gt;&lt;code&gt;&lt;span id="cb10-1"&gt;&lt;a href="#cb10-1"&gt;&lt;/a&gt;&lt;span&gt;simpleMinMax ::&lt;/span&gt; &lt;span&gt;Ord&lt;/span&gt; a &lt;span&gt;=&amp;gt;&lt;/span&gt; [a] &lt;span&gt;-&amp;gt;&lt;/span&gt; (a, a)&lt;/span&gt; &lt;span id="cb10-2"&gt;&lt;a href="#cb10-2"&gt;&lt;/a&gt;simpleMinMax xs &lt;span&gt;=&lt;/span&gt; (&lt;span&gt;minimum&lt;/span&gt; xs, &lt;span&gt;maximum&lt;/span&gt; xs)&lt;/span&gt; &lt;span id="cb10-3"&gt;&lt;a href="#cb10-3"&gt;&lt;/a&gt;&lt;/span&gt; &lt;span id="cb10-4"&gt;&lt;a href="#cb10-4"&gt;&lt;/a&gt;&lt;span&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; simpleMinMax [&lt;span&gt;3&lt;/span&gt;, &lt;span&gt;1&lt;/span&gt;, &lt;span&gt;10&lt;/span&gt;, &lt;span&gt;5&lt;/span&gt;]&lt;/span&gt; &lt;span id="cb10-5"&gt;&lt;a href="#cb10-5"&gt;&lt;/a&gt;(&lt;span&gt;1&lt;/span&gt;,&lt;span&gt;10&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;This is the simplest way we could imagine doing this sort of thing; and indeed it does work! Unfortunately, there are few skeletons from "legacy" haskell that are hidden in this closet. Look what happens if we try it on an empty list!&lt;/p&gt; &lt;div id="cb11"&gt;&lt;pre&gt;&lt;code&gt;&lt;span id="cb11-1"&gt;&lt;a href="#cb11-1"&gt;&lt;/a&gt;&lt;span&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; simpleMinMax []&lt;/span&gt; &lt;span id="cb11-2"&gt;&lt;a href="#cb11-2"&gt;&lt;/a&gt;(&lt;span&gt;***&lt;/span&gt; &lt;span&gt;Exception&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; Prelude.minimum&lt;span&gt;:&lt;/span&gt; empty list&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;Oops... Haskell isn't supposed to throw exceptions! That's okay though, there are some other good ways to accomplish this which won't blow up in our faces!&lt;/p&gt; &lt;p&gt;Time for the next one!&lt;/p&gt; &lt;div id="cb12"&gt;&lt;pre&gt;&lt;code&gt;&lt;span id="cb12-1"&gt;&lt;a href="#cb12-1"&gt;&lt;/a&gt;&lt;span&gt;boundedMinMax ::&lt;/span&gt; (&lt;span&gt;Bounded&lt;/span&gt; a, &lt;span&gt;Ord&lt;/span&gt; a) &lt;span&gt;=&amp;gt;&lt;/span&gt; [a] &lt;span&gt;-&amp;gt;&lt;/span&gt; (a, a)&lt;/span&gt; &lt;span id="cb12-2"&gt;&lt;a href="#cb12-2"&gt;&lt;/a&gt;boundedMinMax xs &lt;span&gt;=&lt;/span&gt; coerce &lt;span&gt;$&lt;/span&gt; &lt;span&gt;foldMap&lt;/span&gt; (\x &lt;span&gt;-&amp;gt;&lt;/span&gt; (&lt;span&gt;Min&lt;/span&gt; x, &lt;span&gt;Max&lt;/span&gt; x)) xs&lt;/span&gt; &lt;span id="cb12-3"&gt;&lt;a href="#cb12-3"&gt;&lt;/a&gt;&lt;/span&gt; &lt;span id="cb12-4"&gt;&lt;a href="#cb12-4"&gt;&lt;/a&gt;&lt;span&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; boundedMinMax [&lt;span&gt;4&lt;/span&gt;, &lt;span&gt;1&lt;/span&gt;, &lt;span&gt;23&lt;/span&gt;, &lt;span&gt;7&lt;/span&gt;]&lt;span&gt; ::&lt;/span&gt; (&lt;span&gt;Int&lt;/span&gt;, &lt;span&gt;Int&lt;/span&gt;)&lt;/span&gt; &lt;span id="cb12-5"&gt;&lt;a href="#cb12-5"&gt;&lt;/a&gt;(&lt;span&gt;1&lt;/span&gt;,&lt;span&gt;23&lt;/span&gt;)&lt;/span&gt; &lt;span id="cb12-6"&gt;&lt;a href="#cb12-6"&gt;&lt;/a&gt;&lt;span&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; boundedMinMax []&lt;span&gt; ::&lt;/span&gt; (&lt;span&gt;Int&lt;/span&gt;, &lt;span&gt;Int&lt;/span&gt;)&lt;/span&gt; &lt;span id="cb12-7"&gt;&lt;a href="#cb12-7"&gt;&lt;/a&gt;(&lt;span&gt;9223372036854775807&lt;/span&gt;,&lt;span&gt;-&lt;/span&gt;&lt;span&gt;9223372036854775808&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;This implementation might be a bit confusing if you haven't learned enough about Semigroups and Monoids, but don't let that scare you! These are both very common abstractions in Haskell and are used very often and to great effect!&lt;/p&gt; &lt;p&gt;A Semigroup is a type of interface which provides an implementation which lets us combine multiple elements together. Haskell has two semigroup type-wrappers which provide specific behaviour to whichever type we wrap: &lt;code&gt;Min&lt;/code&gt; and &lt;code&gt;Max&lt;/code&gt;!&lt;/p&gt; &lt;p&gt;These types define a combining operation which, any time we combine two elements, will keep only the smallest or largest value respectively! I'm using &lt;code&gt;foldMap&lt;/code&gt; here to project each list element into a tuple of these two types which, when the list is collapsed by &lt;code&gt;foldMap&lt;/code&gt;, will all combine together and will include the lowest and highest elements, all in a single pass!&lt;/p&gt; &lt;p&gt;So what's up with the second example? Well, it's a bit unexpected, but not necessarily &lt;em&gt;wrong&lt;/em&gt;. When we're missing any elements to compare foldMap will use the default value for each of our type wrappers, which it can do if they're monoids. For &lt;code&gt;Min&lt;/code&gt; and &lt;code&gt;Max&lt;/code&gt; the default value is the "smallest" and "largest" value of the wrapped type, which is defined by the &lt;code&gt;Bounded&lt;/code&gt; interface that we require in the type signature. This works okay, and behaves as expected under &lt;em&gt;most&lt;/em&gt; circumstances, but maybe we can try one more time:&lt;/p&gt; &lt;div id="cb13"&gt;&lt;pre&gt;&lt;code&gt;&lt;span id="cb13-1"&gt;&lt;a href="#cb13-1"&gt;&lt;/a&gt;&lt;span&gt;import&lt;/span&gt; &lt;span&gt;Data.Semigroup&lt;/span&gt;&lt;/span&gt; &lt;span id="cb13-2"&gt;&lt;a href="#cb13-2"&gt;&lt;/a&gt;&lt;/span&gt; &lt;span id="cb13-3"&gt;&lt;a href="#cb13-3"&gt;&lt;/a&gt;&lt;span&gt;minMax ::&lt;/span&gt; &lt;span&gt;Ord&lt;/span&gt; a &lt;span&gt;=&amp;gt;&lt;/span&gt; [a] &lt;span&gt;-&amp;gt;&lt;/span&gt; &lt;span&gt;Maybe&lt;/span&gt; (a, a)&lt;/span&gt; &lt;span id="cb13-4"&gt;&lt;a href="#cb13-4"&gt;&lt;/a&gt;minMax xs &lt;span&gt;=&lt;/span&gt; &lt;span&gt;case&lt;/span&gt; &lt;span&gt;foldMap&lt;/span&gt; (\a &lt;span&gt;-&amp;gt;&lt;/span&gt; &lt;span&gt;Just&lt;/span&gt; (&lt;span&gt;Min&lt;/span&gt; a, &lt;span&gt;Max&lt;/span&gt; a)) xs &lt;span&gt;of&lt;/span&gt;&lt;/span&gt; &lt;span id="cb13-5"&gt;&lt;a href="#cb13-5"&gt;&lt;/a&gt; &lt;span&gt;Just&lt;/span&gt; (&lt;span&gt;Min&lt;/span&gt; x, &lt;span&gt;Max&lt;/span&gt; y) &lt;span&gt;-&amp;gt;&lt;/span&gt; &lt;span&gt;Just&lt;/span&gt; (x, y)&lt;/span&gt; &lt;span id="cb13-6"&gt;&lt;a href="#cb13-6"&gt;&lt;/a&gt; _ &lt;span&gt;-&amp;gt;&lt;/span&gt; &lt;span&gt;Nothing&lt;/span&gt;&lt;/span&gt; &lt;span id="cb13-7"&gt;&lt;a href="#cb13-7"&gt;&lt;/a&gt;&lt;/span&gt; &lt;span id="cb13-8"&gt;&lt;a href="#cb13-8"&gt;&lt;/a&gt;&lt;span&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; minMax [&lt;span&gt;4&lt;/span&gt;, &lt;span&gt;1&lt;/span&gt;, &lt;span&gt;9&lt;/span&gt;, &lt;span&gt;5&lt;/span&gt;]&lt;/span&gt; &lt;span id="cb13-9"&gt;&lt;a href="#cb13-9"&gt;&lt;/a&gt;&lt;span&gt;Just&lt;/span&gt; (&lt;span&gt;1&lt;/span&gt;,&lt;span&gt;9&lt;/span&gt;)&lt;/span&gt; &lt;span id="cb13-10"&gt;&lt;a href="#cb13-10"&gt;&lt;/a&gt;&lt;span&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; minMax []&lt;/span&gt; &lt;span id="cb13-11"&gt;&lt;a href="#cb13-11"&gt;&lt;/a&gt;&lt;span&gt;Nothing&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;Okay! This is pretty much the same, but we needed an &lt;strong&gt;explicit&lt;/strong&gt; way to correctly handle an empty list of values. In this case, by wrapping our tuple in &lt;code&gt;Just&lt;/code&gt; we invoke the &lt;code&gt;Maybe&lt;/code&gt; monoid, and remember that &lt;code&gt;foldMap&lt;/code&gt; is smart enough to return the "empty" element of that monoid if our list is empty! That means we get &lt;code&gt;Nothing&lt;/code&gt; back if there are no elements.&lt;/p&gt; &lt;p&gt;This may seem like "magic" at first, but all of these &lt;em&gt;typeclasses&lt;/em&gt; have &lt;strong&gt;laws&lt;/strong&gt; which dictate their behaviour and make them predictable. I suggest learning more about monoids if you have time, they're fascinating and useful!&lt;/p&gt; &lt;p&gt;This is a very "safe" implementation, in fact much safer than most languages would offer. We explicitly return &lt;code&gt;Nothing&lt;/code&gt; in the case that the list is empty, and the &lt;code&gt;Maybe&lt;/code&gt; return type requires the caller to handle that case. I mentioned earlier how functions are composable, and it turns out that data-types are too! If we pair two objects with a semigroup together in a tuple, that tuple has a semigroup instance too, which combines respective element together when we combine tuples!&lt;/p&gt; &lt;h2 id="word-frequency"&gt;Word Frequency&lt;/h2&gt; &lt;p&gt;This is a pretty popular one too!&lt;/p&gt; &lt;p&gt;The challenge this time is, given a block of text, find the most common word!&lt;/p&gt; &lt;p&gt;Ultimately, this comes down to an understanding of data-structures.&lt;/p&gt; &lt;div id="cb14"&gt;&lt;pre&gt;&lt;code&gt;&lt;span id="cb14-1"&gt;&lt;a href="#cb14-1"&gt;&lt;/a&gt;&lt;span&gt;import&lt;/span&gt; &lt;span&gt;Data.List&lt;/span&gt; (maximumBy)&lt;/span&gt; &lt;span id="cb14-2"&gt;&lt;a href="#cb14-2"&gt;&lt;/a&gt;&lt;span&gt;import&lt;/span&gt; &lt;span&gt;Data.Function&lt;/span&gt; (on)&lt;/span&gt; &lt;span id="cb14-3"&gt;&lt;a href="#cb14-3"&gt;&lt;/a&gt;&lt;span&gt;import&lt;/span&gt; &lt;span&gt;qualified&lt;/span&gt; &lt;span&gt;Data.Map&lt;/span&gt; &lt;span&gt;as&lt;/span&gt; &lt;span&gt;M&lt;/span&gt;&lt;/span&gt; &lt;span id="cb14-4"&gt;&lt;a href="#cb14-4"&gt;&lt;/a&gt;&lt;/span&gt; &lt;span id="cb14-5"&gt;&lt;a href="#cb14-5"&gt;&lt;/a&gt;&lt;span&gt;mostCommonWord ::&lt;/span&gt; &lt;span&gt;String&lt;/span&gt; &lt;span&gt;-&amp;gt;&lt;/span&gt; &lt;span&gt;Maybe&lt;/span&gt; &lt;span&gt;String&lt;/span&gt;&lt;/span&gt; &lt;span id="cb14-6"&gt;&lt;a href="#cb14-6"&gt;&lt;/a&gt;mostCommonWord str &lt;span&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span id="cb14-7"&gt;&lt;a href="#cb14-7"&gt;&lt;/a&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;null&lt;/span&gt; wordCounts&lt;/span&gt; &lt;span id="cb14-8"&gt;&lt;a href="#cb14-8"&gt;&lt;/a&gt; &lt;span&gt;then&lt;/span&gt; &lt;span&gt;Nothing&lt;/span&gt;&lt;/span&gt; &lt;span id="cb14-9"&gt;&lt;a href="#cb14-9"&gt;&lt;/a&gt; &lt;span&gt;else&lt;/span&gt; &lt;span&gt;Just&lt;/span&gt; &lt;span&gt;.&lt;/span&gt; &lt;span&gt;fst&lt;/span&gt; &lt;span&gt;.&lt;/span&gt; maximumBy (&lt;span&gt;compare&lt;/span&gt; &lt;span&gt;`on`&lt;/span&gt; &lt;span&gt;snd&lt;/span&gt;) &lt;span&gt;.&lt;/span&gt; M.toList &lt;span&gt;$&lt;/span&gt; wordCounts&lt;/span&gt; &lt;span id="cb14-10"&gt;&lt;a href="#cb14-10"&gt;&lt;/a&gt; &lt;span&gt;where&lt;/span&gt;&lt;/span&gt; &lt;span id="cb14-11"&gt;&lt;a href="#cb14-11"&gt;&lt;/a&gt; wordCounts &lt;span&gt;=&lt;/span&gt; M.unionsWith (&lt;span&gt;+&lt;/span&gt;) &lt;span&gt;.&lt;/span&gt; &lt;span&gt;fmap&lt;/span&gt; (\w &lt;span&gt;-&amp;gt;&lt;/span&gt; M.singleton w &lt;span&gt;1&lt;/span&gt;) &lt;span&gt;.&lt;/span&gt; &lt;span&gt;words&lt;/span&gt; &lt;span&gt;$&lt;/span&gt; str&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt; &lt;p&gt;There's a bit more going on this time, so let's break it down a bit!&lt;/p&gt; &lt;p&gt;In Haskell, we use "math-style" function composition using &lt;code&gt;.&lt;/code&gt;, so we read most expressions from right-to-left.&lt;/p&gt; &lt;p&gt;Let's look at the &lt;code&gt;wordCounts&lt;/code&gt; binding down in the &lt;code&gt;where&lt;/code&gt; clause first. Reading from right to left, first we use the &lt;code&gt;words&lt;/code&gt; function from the built-in Prelude to split the incoming stream into a list of words, then we create a key-value map out of each one, consisting of the word as the key with a value of &lt;code&gt;1&lt;/code&gt; to start.&lt;/p&gt; &lt;p&gt;Now we have a list of key-value maps, and can add them up all up key-wise using &lt;code&gt;unionsWith&lt;/code&gt; from the &lt;code&gt;Data.Map&lt;/code&gt; library, this will count up the number of elements of each key and will result in a key-value mapping where the values represent occurrences.&lt;/p&gt; &lt;p&gt;We've got a mapping now, so let's find the largest count!&lt;/p&gt; &lt;p&gt;First things first, to be safe we'll check whether the map has any values at all, if it doesn't then we'll return &lt;code&gt;Nothing&lt;/code&gt;. Otherwise, we can convert the map into a list of key-value pairs by calling &lt;code&gt;M.toList&lt;/code&gt;, then we can use &lt;code&gt;maximumBy&lt;/code&gt; to return the biggest element according to a comparison function that we specify! &lt;code&gt;on&lt;/code&gt; comes in handy here and we can tell it to compare on the second element, which is the count. That will return us the key-value pair with the largest value, then we just need to grab the key as a result using &lt;code&gt;fst&lt;/code&gt;!&lt;/p&gt; &lt;p&gt;Ultimately this is a bit of a naive implementation which won't work well on huge texts, but it should be enough to get you through the whiteboard portion of the interview 😄.&lt;/p&gt; &lt;h2 id="summary"&gt;Summary&lt;/h2&gt; &lt;p&gt;That's all I've got for you today, nothing to revolutionary I'm sure, but hopefully you had a bit of fun, or maybe learned a thing or two about what code looks like in Haskell compared to your favourite language 😄&lt;/p&gt; &lt;p&gt; Hopefully you learned something 🤞! If you did, please consider checking out my book: It teaches the principles of using optics in Haskell and other functional programming languages and takes you all the way from an beginner to wizard in all types of optics! You can get it &lt;a href="https://leanpub.com/optics-by-example/"&gt;here&lt;/a&gt;. Every sale helps me justify more time writing blog posts like this one and helps me to continue writing educational functional programming content. Cheers! &lt;/p&gt; &lt;/article&gt;&lt;/div&gt;&lt;a href="https://chrispenner.ca/posts/interview"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sun, 7 Feb 2021 15:01:44 UT
      </pubDate>
      <guid>
        https://chrispenner.ca/posts/interview
      </guid>
    </item>
    <item>
      <title>
        How to Write Technical Posts (so people will read them) :: Reasonably Polymorphic
      </title>
      <link>
        https://reasonablypolymorphic.com/blog/writing-technical-posts/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt; &lt;p&gt;One of today’s best bloggers in the functional programming space is &lt;a href="https://chrispenner.ca/"&gt;Chris Penner&lt;/a&gt;. Despite this, Chris is criminally underrated—nobody I talk to seems to know of his work. Go check him out as soon as you finish reading this post!&lt;/p&gt; &lt;p&gt;This is reasonably pervasive phenomenon in our subculture; there’s lots of fantastic work being produced, but for one reason or another, it falls between the cracks. I’d propose the biggest obstacle is that most FP writing &lt;em&gt;isn’t optimized to be read.&lt;/em&gt;&lt;/p&gt; &lt;p&gt;So I’d like to take some time today and talk about common failure modes in technical writing. If you don’t have a checklist you run through before publishing a post, you’ll probably get a lot of benefit from internalizing this advice.&lt;/p&gt; &lt;p&gt;The value? You’ll make it easier for people to understand what you’re trying to tell them. Which is why you’re writing in the first place, right? The good news is that none of this is magic—just some simple guidelines for structuring your content.&lt;/p&gt; &lt;h2 id="the-guiding-principle"&gt;The Guiding Principle&lt;/h2&gt; &lt;p&gt;Here’s the biggest thing to keep in mind: your reader doesn’t really care what you have to say. You get maybe four sentences to convince them that your essay is worth their time. If you haven’t made your case by then, you’ve probably lost them to the next tab they binge-opened.&lt;/p&gt; &lt;p&gt;Even after you’ve convinced them that it’s a valuable read, you need to continue assuring them that you’re not wasting their time. If you take too long to get to the point, or if you make the information too hard to find on a quick skim, you’ve lost them again.&lt;/p&gt; &lt;p&gt;As a result, alongside your technical content, you have two primary goals to focus on:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Provide strong, concise motivations for everything you want to talk about.&lt;/li&gt; &lt;li&gt;Make it easy to skim.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;If you can do these two things, you’re already most of the way to better engagement.&lt;/p&gt; &lt;h2 id="writing-strong-motivations"&gt;Writing Strong Motivations&lt;/h2&gt; &lt;p&gt;People care about solutions to problems they have, or expect to have one day. They care about other things too, but it’s not really relevant to us today.&lt;/p&gt; &lt;p&gt;With this in mind, you want to tailor your motivations in terms of &lt;em&gt;solutions to problems.&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Here are some good examples of problems that you’ve probably run into (and links to their solutions for you to read later):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://chrispenner.ca/posts/adjunction-battleship"&gt;Ed Kmett writes shitty documentation&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://reasonablypolymorphic.com/blog/higher-kinded-data/"&gt;I have lots of types that need to evolve at the same time&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="http://thinkingwithtypes.com/"&gt;There is no good place to learn type-level programming&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Bad examples of motivating documents are things that assume you care &lt;em&gt;simply because they exist.&lt;/em&gt; This is &lt;a href="http://hackage.haskell.org/package/pipes-4.3.9/docs/Pipes-Tutorial.html"&gt;pretty&lt;/a&gt; &lt;a href="http://yannesposito.com/Scratch/en/blog/Yesod-tutorial-for-newbies/"&gt;common&lt;/a&gt; of libraries’ tutorials. The same document that convinces you to use a technology should also show you how.&lt;/p&gt; &lt;p&gt;As a more general rule, focusing on &lt;em&gt;why&lt;/em&gt; is going to be more valuable than on &lt;em&gt;how.&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Why should someone care, and why your solution is a good one.&lt;/p&gt; &lt;p&gt;“How” without a “why” suggests a contrived solution to a made-up problem. In other words, it’s easily read as “who cares?”&lt;/p&gt; &lt;h2 id="understanding-how-people-read"&gt;Understanding How People Read&lt;/h2&gt; &lt;p&gt;People who spend lots of time reading have good heuristics for skipping lots of text. If you understand these heuristics, you can make it easy for people to find what they’re looking for. And remember: they’re looking for reasons to continue reading.&lt;/p&gt; &lt;p&gt;There are two behaviors here. The first is what I call “skimming for concepts”—which is that people will attempt to determine what text is about at a high-level. They’re looking for &lt;em&gt;what you’re trying to tell them&lt;/em&gt;, as opposed to &lt;em&gt;what you’re actually saying.&lt;/em&gt;&lt;/p&gt; &lt;p&gt;When skimming, people are likely to read only the headings and the first two sentences of a paragraph. If they’re convinced they know what you have to say, they’ll skip to the next paragraph. If several paragraphs in a row don’t seem relevant, they’ll skip to the next heading.&lt;/p&gt; &lt;p&gt;If the next heading also fails to grab their attention, they’ll probably give up.&lt;/p&gt; &lt;p&gt;The solution is to structure your argument as a tree. Headings must provide enough information to let someone know whether or not they care about the following prose.&lt;/p&gt; &lt;p&gt;This also means that the first sentence of each paragraph should be sufficient to understand the rest of the paragraph. The remaining sentences are only allowed to reinforce or give details of the first sentence. One paragraph equals one idea.&lt;/p&gt; &lt;p&gt;Roughly speaking, the hierarchy of your document should look like this:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Document &lt;ul&gt; &lt;li&gt;Heading &lt;ul&gt; &lt;li&gt;First sentence &lt;ul&gt; &lt;li&gt;Rest of paragraph&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Maybe you feel like it’s hard to know how much knowledge to assume your readership knows. Understanding how people read makes this a non-issue. Present as much information as is necessary to understand your point, but make it easy to skip if people already know it. Those who don’t yet know will learn, those who do can skip past, and both camps will appreciate it.&lt;/p&gt; &lt;p&gt;After you’ve convinced your reader that they care what you have to say, they’re more willing to read what you &lt;em&gt;actually have to say.&lt;/em&gt; When the reader is ready to dive in, that’s when you can make the finer points of your argument.&lt;/p&gt; &lt;p&gt;It’s unlikely that anyone is going to read every word of your essay. It’s even less likely that they’ll read them all in order.&lt;/p&gt; &lt;h2 id="stumbling-blocks"&gt;Stumbling Blocks&lt;/h2&gt; &lt;p&gt;Now that you’ve got people ready to listen to you, it’s important to keep them on the same page as you. You really need to stay on top of anything that might break their focus.&lt;/p&gt; &lt;p&gt;Use short sentences. If it’s too hard to parse, people won’t.&lt;/p&gt; &lt;p&gt;Make sure your spelling and grammar have no egregious problems. You don’t need to have perfect command of the language, but you need to be able to signal that you’re trustworthy-enough to listen to. Don’t underestimate how much credibility you’ll lose from blatantly bad spelling and grammar.&lt;/p&gt; &lt;p&gt;This stuff is relatively common-sense.&lt;/p&gt; &lt;p&gt;What might be less so is that you also need to stay on top of conceptual stumbling blocks. If your argument makes a jump that feels poorly motivated or references something potentially unfamiliar, expect that your reader will experience vertigo.&lt;/p&gt; &lt;p&gt;Most of the ideas we talk about in functional programming &lt;em&gt;are not easy,&lt;/em&gt; and it doesn’t do anyone any favors to pretend this isn’t so. Expect that your readers will be pretty similar to you; if you had a problem understanding a piece of your topic, &lt;em&gt;call that out.&lt;/em&gt; Point out the obstacle. Point out what they might be thinking, and then very explicitly show them what they should be thinking instead.&lt;/p&gt; &lt;p&gt;For example, if your code sample uses a &lt;a href="https://en.wikipedia.org/wiki/Functional_dependency"&gt;functional dependency&lt;/a&gt;, it might be worth a short sentence saying “that funny bar thing is a functional dependency.” Give a tiny summary of its purpose, and provide a link for them to learn more if they need to.&lt;/p&gt; &lt;p&gt;Another illustration: if &lt;em&gt;you&lt;/em&gt; originally got confused that an “algebra in recursion schemes” is not the same thing as the algebra you learned in high-school, your readers probably will too. The first time you say “algebra” in the new context, say “this is a misleading term. This has nothing to do with solving equations like you did in high-school.”&lt;/p&gt; &lt;p&gt;More important than what you’re saying is what you’re &lt;em&gt;not saying.&lt;/em&gt; If you’re giving examples of something that fits a pattern, make sure you give examples of things that &lt;em&gt;do not&lt;/em&gt; fit the pattern. A concept that is applicable everywhere is useful nowhere.&lt;/p&gt; &lt;p&gt;Give lots of examples. Nobody I know learns via mathematical statements, nor do they learn via long, wordy, abstract prose. People learn by seeing lots of examples, and being told explicitly how these examples relate to one another. The mathematical statements are only useful &lt;em&gt;after&lt;/em&gt; you have the intuition, so save them for an appropriate time.&lt;/p&gt; &lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt; &lt;p&gt;The takeaway advice from this essay is that &lt;em&gt;if you want lots of readers, you must make it easy for them to read.&lt;/em&gt;&lt;/p&gt; &lt;p&gt;To that end, pay lots of attention to motivation. Why should people care what you have to say? What value does it give &lt;em&gt;them?&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Focus your energy on the beginnings—both of the essay as a whole, and of each paragraph. People who are unconvinced by your essay’s value will skim their way through it, and they will do that by reading only the beginnings of things.&lt;/p&gt; &lt;p&gt;Make your information easy to find. Structure your argument in a tree, and make sure it supports random-access. Nobody is going to read the whole thing from start to finish. Instead they’re going to jump around, ignoring the pieces they already know, and looking for the bits they don’t.&lt;/p&gt; &lt;p&gt;Use lots of short paragraphs. A paragraph should correspond to a single idea.&lt;/p&gt; &lt;p&gt;Anticipate which parts of your argument will be difficult for your readers, and be proactive in trying to assuage those difficulties. Give lots of examples of what you’re talking about, and more importantly, what you’re not talking about.&lt;/p&gt; &lt;p&gt;Point out where you went into the weeds while learning this stuff. Steer readers away from common mistakes and misconceptions.&lt;/p&gt; &lt;p&gt;And finally, end on a high note. Leave people with a good feeling, and it will incentivize them to get to the bottom of your next piece. Inspirational calls to action are a good way to go out.&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;Tell them what you’re going to tell them. Then tell them. Finally, tell them what you told them.&lt;/p&gt; &lt;p&gt;-Unknown&lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt;Funny and poignant quotes are too.&lt;/p&gt; &lt;p&gt; &lt;span&gt; &lt;a href="https://reasonablypolymorphic.com/blog/thinking-with-types"&gt;←&lt;/a&gt; &lt;/span&gt; &lt;span&gt; &lt;a href="https://reasonablypolymorphic.com/blog/freer-monads"&gt;→&lt;/a&gt; &lt;/span&gt; &lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://reasonablypolymorphic.com/blog/writing-technical-posts/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sun, 7 Feb 2021 15:12:58 UT
      </pubDate>
      <guid>
        https://reasonablypolymorphic.com/blog/writing-technical-posts/
      </guid>
    </item>
    <item>
      <title>
        Advanced Hackery With The Hammerspoon Window Manager - Tristan Hume
      </title>
      <link>
        https://thume.ca/2016/07/16/advanced-hackery-with-the-hammerspoon-window-manager/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div id="post"&gt; &lt;h2&gt;Advanced Hackery With The Hammerspoon Window Manager&lt;/h2&gt; &lt;p&gt;Along with &lt;a href="https://kapeli.com/dash"&gt;Dash&lt;/a&gt;, &lt;a href="https://www.sketchapp.com/"&gt;Sketch&lt;/a&gt; and &lt;a href="http://papersapp.com/"&gt;Papers&lt;/a&gt;, one of the main reasons I haven’t yet switched to Linux is &lt;a href="http://www.hammerspoon.org/"&gt;Hammerspoon&lt;/a&gt;. Hammerspoon gives me most of the power that a fancy Linux tiling window manager and configurable desktop would give me, without having to switch operating systems. It’s fully configurable with Lua, has &lt;a href="http://www.hammerspoon.org/docs/index.html"&gt;tons of built in modules&lt;/a&gt; and it is simple to write your own modules. I think of it more as a general-purpose tool for modifying OSX’s user interface than just a window manager. This post explores some of the ways I’ve used Hammerspoon to greatly enhance my general OSX-using experience.&lt;/p&gt; &lt;p&gt;&lt;img alt="Hints Screenshot" src="https://thume.ca/assets/postassets/hammerspoon/hammerspoon.png"&gt;&lt;/p&gt; &lt;h2 id="window-hints"&gt;Window Hints&lt;/h2&gt; &lt;p&gt;The first Hammerspoon module I wrote was a port of &lt;a href="https://thume.ca/howto/2012/11/19/using-slate/#switching-windows"&gt;Slate’s window hints&lt;/a&gt;, which if you’ve ever used Vimium or Vimperator, are like link hints for windows. They allow you to switch to any window with only two keystrokes: One shortcut to bring up icons and letters for every window, and then simply hitting the key corresponding to the window you want.&lt;/p&gt; &lt;p&gt;&lt;a href="https://github.com/trishume/mjolnir.th.hints"&gt;The module&lt;/a&gt; was written mostly in a single evening as a native Lua module (originally for Mjolnir, the precursor to Hammerspoon). It didn’t take much time, and is very enjoyable to use, and because the module was added to the core Hammerspoon distribution, lots of other people can also benefit from it.&lt;/p&gt; &lt;h2 id="window-tabs"&gt;Window Tabs&lt;/h2&gt; &lt;p&gt;The second Hammerspoon module I wrote was one that allows you to add tabs to any OSX Application. The tabs sit in the top right of the title bar and allow you to easily switch between windows of an app with keyboard shortcuts (e.g &lt;code&gt;ctrl+tab number&lt;/code&gt;) and later by clicking. This was originally motivated by my switching to &lt;a href="http://spacemacs.org/"&gt;Spacemacs&lt;/a&gt; and it not having a good solution for working on many different projects like Vim tabs. This module allowed me to wrangle Emacs windows to more easily switch between different projects. I later repurposed it to switch between Sublime Windows for the same reason when I switched back to Sublime Text.&lt;/p&gt; &lt;p&gt;This module was very different to write since it was pure Lua. It uses Hammerspoon’s various powerful built-in modules including the drawing module, the app watcher module, and the window listener module.&lt;/p&gt; &lt;p&gt;&lt;img alt="Tabs Screenshot" src="https://thume.ca/assets/postassets/hammerspoon/tabs.png"&gt;&lt;/p&gt; &lt;h2 id="mouth-noises"&gt;Mouth Noises&lt;/h2&gt; &lt;p&gt;Most recently I &lt;a href="https://github.com/Hammerspoon/hammerspoon/pull/936"&gt;contributed&lt;/a&gt; a &lt;a href="https://github.com/trishume/thume.popclick"&gt;module for recognizing mouth noises&lt;/a&gt;. It is based off some low-latency high-accuracy mouth noise recognizers I wrote during my research term at the UWaterloo HCI lab. Personally I use this module to scroll pages hands-free while lying down on the couch with my laptop. Previously I had to contort my hand into a cramped position on my chest to scroll with the trackpad while lying on my back. It’s one of my zanier uses of Hammerspoon but it is nice to use nonetheless. Just goes to show the variety of user interface scripting tasks Hammerspoon can do.&lt;/p&gt; &lt;h2 id="custom-window-management-hotkeys"&gt;Custom Window Management Hotkeys&lt;/h2&gt; &lt;p&gt;I love being able to customize my window management shortcuts perfectly for the kind of things I normally do. I have a custom modifier key on &lt;a href="https://thume.ca/2014/09/08/creating-a-keyboard-1-hardware/"&gt;my keyboard&lt;/a&gt; that is dedicated to window management I call &lt;code&gt;hyper&lt;/code&gt;. Pressing &lt;code&gt;hyper&lt;/code&gt; in combination with the left home row jumps directly between my most frequently used apps (Chrome, Sublime, iTerm2, Mail, Path Finder) and a pair of keys that mark a certain window and focus it, for all the other apps I use occasionally like PDF readers when writing LaTeX. Pressing &lt;code&gt;hyper&lt;/code&gt; with the right home row moves a window between full screen, halves of the monitor, and between screens. Various other hyper shortcuts do things like toggling mouth noise recognition. I also have a hotkey I can hit when I plug in my external monitor that arranges all my apps between monitors in the way I like them instantly.&lt;/p&gt; &lt;h2 id="miscellaneous-hackery"&gt;Miscellaneous Hackery&lt;/h2&gt; &lt;p&gt;I’ve used Hammerspoon for some one-off tasks, especially when I want to bind things to global keyboard shortcuts. An example of this is a weekend project I did to make a mouse controlled by head movements detected by an accelerometer on a microphone headset. I used Hammerspoon to send serial commands to the microcontroller when I pressed a shortcut to toggle the mousing on and off.&lt;/p&gt; &lt;p&gt;&lt;img alt="Lookmouse" src="https://thume.ca/assets/postassets/hammerspoon/lookmouse.jpg"&gt;&lt;/p&gt; &lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt; &lt;p&gt;I hope this has given you some ideas about how you can use Hammerspoon to make your computing experience more pleasant. Check out &lt;a href="https://github.com/trishume/dotfiles/blob/master/hammerspoon/hammerspoon.symlink/init.lua"&gt;my Hammerspoon config&lt;/a&gt; to see how I configure everything and tie it all together. For more inspiration check out the amazing things &lt;a href="https://github.com/asmagill/hammerspoon-config"&gt;asmagill does in his config&lt;/a&gt;. He has experimental modules for all sorts of things like drawing calendars, custom app menus, fonts and speech control.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://thume.ca/2016/07/16/advanced-hackery-with-the-hammerspoon-window-manager/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sun, 7 Feb 2021 15:16:44 UT
      </pubDate>
      <guid>
        https://thume.ca/2016/07/16/advanced-hackery-with-the-hammerspoon-window-manager/
      </guid>
    </item>
    <item>
      <title>
        Blame It on the Phones - Temporary heresy
      </title>
      <link>
        https://blog.nukemberg.com/post/blame-it-on-the-phones/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div role="main"&gt;&lt;article role="main"&gt;&lt;p&gt;Since I’ve abandoned Facebook my primary source of tech news has become Twitter and this week my feed is raging with two seemingly unrelated security/privacy incidents: &lt;a href="https://medium.com/bugbountywriteup/zoom-zero-day-4-million-webcams-maybe-an-rce-just-get-them-to-visit-your-website-ac75c83f4ef5"&gt;Zoom’s zero day&lt;/a&gt; and &lt;a href="https://mikeindustries.com/blog/archive/2019/06/superhuman-is-spying-on-you"&gt;Superhuman’s email tracking scandal&lt;/a&gt;. I write “seemingly”, because despite these being two very different companies operating in two different markets (Zoom in video conference calls and Superhuman in emails), building very different products (Zoom is all about jump in, jump out - Superhuman is a workspace) these incidents stem from the same fundamental fault: The telephone experience.&lt;/p&gt;&lt;div&gt;&lt;figure&gt;&lt;p&gt;&lt;img alt="/img/let-me-sum-it-up.gif" src="https://blog.nukemberg.com/img/let-me-sum-it-up.gif"&gt;&lt;/p&gt;&lt;a href="https://blog.nukemberg.com/img/let-me-sum-it-up.gif"&gt;&lt;/a&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;Not so long ago, when people still used to call each other and conduct phone calls all you had to do to talk to someone was click on the contact (or punch in the phone number), wait a few moments for the other side to answer and violla, start talking. On the receiver end, you got a notification and connected with one click (or picked up the phone). Privacy expectations were pretty clear - either side could record the conversation, mute their side or disconnect and had reasonable expectation that 3rd parties were not involved (other than trusted carriers). Each side knows that they are connected and can reasonably detect the other side is still engaged.&lt;/p&gt;&lt;p&gt;This model is so pervasive that almost every digital communication platform tries to mimic it - just pop open your video chat app and look at the controls, have they changed much conceptually? But the click-once-to-connect model, while being &lt;em&gt;easy&lt;/em&gt; from a &lt;em&gt;local&lt;/em&gt; usability viewpoint, is also fundamentally flawed on a more broad level. Let’s analyze what would happen on a public network where any two parties can connect to each other using this model, remembering how humans &lt;em&gt;actually&lt;/em&gt; behave in the real world. One click connection means minimal attention, which on a public system immediately clashes with an &lt;em&gt;identity&lt;/em&gt; problem: How do we know who’s on the other side? Not surprisingly, the phone system is plagued with fraud and unsolicited calls. We’ve tried, and failed, to resolve these issues with Caller id and smartphone’s contact management - because such identity mapping system has obvious problems like name take-over, typosquatting etc (DNS anyone?). But still, you have control over &lt;em&gt;when&lt;/em&gt; and &lt;em&gt;if&lt;/em&gt; a 2nd party was connected, right? turns out it isn’t so good - as pocket calls often remind us. What about trusted carriers and freedom from 3rd parties? also turns out to be problematic as this model doesn’t say anything about ownership - think corporate phones and switchboards. If a 3rd party pays for communication, do you trust it? do you trust the providers it chose to work with? what happens when multiple such parties communicate? who owns the call? the participants or the client who paid?&lt;/p&gt;&lt;p&gt;Note that I haven’t wrote a word about the underlying technology - because these “bugs” are in the &lt;em&gt;product experience&lt;/em&gt; model, not the code. Thus they will inevitably appear in some form on any system which tries to recreate that experience. What is happening today is a modern version of all the things we hated telephones for. And this was &lt;em&gt;before&lt;/em&gt; attention and focus became the scarcest of resources.&lt;/p&gt;&lt;p&gt;It’s quite clear how video chats got here. But what does email tracking got to do with it? you see, the original “mail” experience never had this “tracking” feature. You sent a mail, and the only way you knew the recipient got your message was if they chose to respond; mail was strictly asynchronous. But as the one-click model prevailed, various companies tried to make email more phone like - where you knew the other side picked up. The email protocol doesn’t support this of course, and so they hacked it, exploiting email clients along the way - not unlike how Zoom hacked browser security policies to shave user clicks off. And what a surprise, it was abused… much the same way people used call-and-immediately-hangup over phones to detect if you were home.&lt;/p&gt;&lt;p&gt;Make no mistake: Zoom and Superhuman incidents are not a code bug; they are product bug.&lt;/p&gt;&lt;hr&gt;&lt;/article&gt;&lt;/div&gt;&lt;/div&gt;&lt;a href="https://blog.nukemberg.com/post/blame-it-on-the-phones/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sun, 7 Feb 2021 17:12:26 UT
      </pubDate>
      <guid>
        https://blog.nukemberg.com/post/blame-it-on-the-phones/
      </guid>
    </item>
    <item>
      <title>
        Level up keyboard shortcuts - Part 2. Hammerspoon and the Home Row
      </title>
      <link>
        https://mattorb.com/level-up-shortcuts-hammerspoon-home-row/
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div id="site-main"&gt; &lt;article&gt; &lt;figure&gt; &lt;img alt="Level up keyboard shortcuts - Part 2. Hammerspoon and the Home Row" src="https://mattorb.com/content/images/size/w2000/2019/09/amauri-acosta-montiel-@amauriam-RMttILfqOi4-unsplash.jpg" sizes="(max-width: 800px) 400px, (max-width: 1170px) 1170px, 2000px" srcset="https://mattorb.com/content/images/size/w300/2019/09/amauri-acosta-montiel-@amauriam-RMttILfqOi4-unsplash.jpg 300w, https://mattorb.com/content/images/size/w600/2019/09/amauri-acosta-montiel-@amauriam-RMttILfqOi4-unsplash.jpg 600w, https://mattorb.com/content/images/size/w1000/2019/09/amauri-acosta-montiel-@amauriam-RMttILfqOi4-unsplash.jpg 1000w, https://mattorb.com/content/images/size/w2000/2019/09/amauri-acosta-montiel-@amauriam-RMttILfqOi4-unsplash.jpg 2000w"&gt; &lt;/figure&gt; &lt;div&gt; &lt;p&gt;After my &lt;a href="https://mattorb.com/level-up-shortcuts-and-the-hyper-key/"&gt;initial experiments&lt;/a&gt; using Karabiner to bind a keyboard shortcut to an image-based cheatsheet and leverage a hyper key to avoid application level key binding conflicts and finger twister, I was super excited. &amp;nbsp;I had combed through&lt;em&gt; many blogs and git repositories&lt;/em&gt;.&lt;/p&gt;&lt;p&gt;Having an extra meta key with a whole slew of nonconflicting keybinding slots seemed awesome. &amp;nbsp; I like keyboard shortcuts bound to keys based on a pnemonic, so binding my global spectacle keyboard shortcut cheatsheet to hyper+k ['k' for keys] seemed like a good, quick win that would help me memorize those Spectacle shortcuts.&lt;/p&gt;&lt;p&gt;Incremental and Safe . . . time to test it out! &amp;nbsp;👍&lt;/p&gt;&lt;h2 id="the-home-row"&gt;The Home Row&lt;/h2&gt;&lt;p&gt;Then, mid-way through patting myself on the back, I discovered &lt;a href="https://brettterpstra.com/2012/12/08/a-useful-caps-lock-key/"&gt;global vi mode with a hyper key and Karabiner&lt;/a&gt;. &amp;nbsp;With this Karabiner recipe enabled, you press a hyper key and then h/j/k/l to move the cursor left/down/up/right. &amp;nbsp;Additionally, tab can be rigged up to act as a modifier in conjunction with the hyper key to enable quick access to home/end/pgdn/pgup – which is especially awesome when you are on a laptop keyboard. &amp;nbsp; &lt;/p&gt;&lt;p&gt;In order to to try out global vi mode w/Karabiner, I had to sacrifice hyper+k from &amp;nbsp;the Spectacle cheatsheet and switch that to be right-option+k. &amp;nbsp;&lt;/p&gt;&lt;blockquote&gt;Hey, another key I never use. &amp;nbsp;right-option. &amp;nbsp;hyper2? &lt;/blockquote&gt;&lt;p&gt;Fast forward a bit. &amp;nbsp;I dug deeper and deeper into the &lt;a href="http://www.hammerspoon.org/"&gt;Hammerspoon&lt;/a&gt; ecosystem, looked at more custom Karabiner and Hammerspoon settings, and heard some feedback from my first post.&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.hammerspoon.org/"&gt;Hammerspoon&lt;/a&gt; is an application you run in the background that loads custom &lt;a href="https://www.lua.org/"&gt;Lua&lt;/a&gt; scripts to interact with your system, allowing you to script behaviors to react to system events. &amp;nbsp; One kind of system event is a key press. &amp;nbsp;For our purposes here, we're exploring Hammerspoon primarily in the context of using it to react to keyboard shortcuts and trigger something in response. &amp;nbsp;It has &lt;a href="https://www.hammerspoon.org/docs/"&gt;many&lt;/a&gt; &lt;a href="https://www.hammerspoon.org/Spoons/"&gt;other&lt;/a&gt; &lt;a href="http://www.hammerspoon.org/go/"&gt;uses&lt;/a&gt; though. &amp;nbsp; Keep in mind we're talking about system-wide key bindings here – not something isolated to a single application. &amp;nbsp;🤯&lt;/p&gt;&lt;p&gt;A unit of re-usable scripting in Hammerspoon is called a 'spoon'. &amp;nbsp; &lt;/p&gt;&lt;p&gt;After trying out many different spoons and customizations, two projects really caught my eye:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;FryJay's &lt;a href="https://github.com/FryJay/MenuHammer"&gt;MenuHammer&lt;/a&gt; - "A Spacemacs inspired menu system". &amp;nbsp; A quick, customizable, nestable, menu system you can access via a system-wide keyboard shortcut.&lt;/li&gt;&lt;li&gt;Jason Rudolph's &lt;a href="https://github.com/jasonrudolph/keyboard"&gt;Karabiner+Hammerspoon setup&lt;/a&gt; which focuses on home-row centric shortcuts for cursor navigation and window managment (ht: &lt;a href="https://twitter.com/gregvaughn"&gt;@gregvaughn&lt;/a&gt;)&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Thinking about these in terms of the capabilities they enable relative to the caps-lock hyper key and Spectacle cheat sheet via a shortcut that we put together in the &lt;a href="https://mattorb.com/level-up-shortcuts-and-the-hyper-key/"&gt;previous post&lt;/a&gt;, it seems there is a lot of potential. &lt;/p&gt;&lt;p&gt;Let's explore. &lt;/p&gt;&lt;h2 id="key-chords"&gt;Key Chords&lt;/h2&gt;&lt;p&gt;Hammerspoon can enable key chords*.&lt;/p&gt;&lt;blockquote&gt;Karabiner can enable key chords too, but I found the nuances of getting it implemented well in Karabiner, for alpha keys, with the current version, to be painful. ** &amp;nbsp;&lt;/blockquote&gt;&lt;p&gt;Wait wait . . . What is a key chord you say? &amp;nbsp;&lt;/p&gt;&lt;p&gt;So, the aforementioned &lt;a href="https://github.com/jasonrudolph/keyboard"&gt;JR's setup&lt;/a&gt; has a 'super duper' behavior where pressing the 's' and 'd' keys at the same time acts almost like another new modifier key. &amp;nbsp;&lt;em&gt;waaaaaaaat? &lt;/em&gt; &amp;nbsp;That new modifier is then leveraged for some home row centric key bindings that can substitute for moving your right hand or stretching the right pinky down to the arrow keys.&lt;/p&gt;&lt;p&gt;Here's how it works: while 's' and 'd' are pressed and held with the left hand, you use the right hand to press h to move the cursor left. &amp;nbsp; 'h' for left, 'j' for down, 'k' for up, 'l' for right. &amp;nbsp; You may recognize these commonly used &lt;em&gt;vi&lt;/em&gt; cursor movement keys. &amp;nbsp;With hand in place, pressing down the 's' and 'd', you can press 'a' to add the option/alt modifier, 'f' to add cmd modifier, or spacebar to add shift modifier. &amp;nbsp;Those keys are all lying right under the fingertips of where the left hand is already positioned, minimizing the needed movement. &lt;/p&gt;&lt;p&gt;I thought it would be nice to form the muscle memory for those h/j/k/l &lt;em&gt;vi&lt;/em&gt; cursor movement keys as a side benefit for when I might occasionally run &lt;em&gt;vi&lt;/em&gt; on a remote server. &amp;nbsp;Mostly though, I'm thinking about not having to pinky stretch down to those tiny cursor keys or reposition the whole right hand each time I want to navigate the cursor from a laptop keyboard.&lt;/p&gt;&lt;p&gt;What really pushed me over the line of &lt;strong&gt;I have to try this now&lt;/strong&gt; was seeing those same home-row keys used for cursor movement -and- window positioning in a consistent way.&lt;/p&gt;&lt;h2 id="modes-and-menus"&gt;Modes and Menus&lt;/h2&gt;&lt;p&gt;Where key chords are generally more temporary states, enabling a behavior only if all the right keys are pressed in close proximity spatially and temporally, a 'mode' let's you toggle into a state where keys react differently until it is dismissed. &amp;nbsp; Menus are similar and dismiss automatically upon the selection of an action.&lt;/p&gt;&lt;p&gt;So in the context of JR's setup, when you hit control-S, you enable window layout mode. &amp;nbsp;Then, you press one of the h/j/k/l/i/o/,/. keys while focused on a particular window, and it will resize&amp;amp;move the window to left/down/up/right/top-left/top-right/bottom-left/bottom-right. &amp;nbsp;This re-uses some familar home row mappings (i.e. - 'h' = left whether it is for cursor movement or shifting a window to the left side of the screen). &amp;nbsp;A few other window resize/move keys are added (i/o/,/.) in a place that makes sense spatially for shifting windows to corners. &amp;nbsp;For example, out of the i/o/,/. keys, the 'i' is the top left key on the keyboard and it arranges the window to the top left position. &amp;nbsp;After you make a selection the window layout mode dismisses itself. &amp;nbsp;&lt;/p&gt;&lt;p&gt;There is a 'showHelp' flag built in to the lua script that drives window layout mode. &amp;nbsp;When you set that flag to true, a built in cheatsheet displays when in window layout mode. &amp;nbsp; &lt;em&gt;Note: I re-bound this mode to hyper-W to preserve ctrl-S for application-level bindings. &amp;nbsp;&lt;/em&gt;&lt;/p&gt;&lt;figure&gt;&lt;img src="https://mattorb.com/content/images/2019/09/Screen-Shot-2019-09-03-at-9.20.20-AM-1.png"&gt;&lt;figcaption&gt;The built-in 'cheatsheet' for window layout mode via JR's hammerspoon setup (set showHelp=true)&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;It's worth noting that since I have had this working, I've been using Spectacle less and less. &amp;nbsp;At the moment, it does not have feature parity with Spectacle, but it does &lt;a href="https://github.com/scottwhudson/Lunette"&gt;seem possible&lt;/a&gt; to get there. 🤔&lt;/p&gt;&lt;p&gt;Another variation of the idea of a 'mode' is a shortcut driven menu. &amp;nbsp; Once activated, you get a list of options, along with the keys to quickly navigate and select from those options. &amp;nbsp;&lt;/p&gt;&lt;p&gt;This is where the &lt;a href="https://github.com/FryJay/MenuHammer"&gt;Menuhammer&lt;/a&gt; project comes in. &amp;nbsp;Menuhammer allows you to set up a totally customizable menu you can access system-wide via shortcut. &amp;nbsp;From that menu, you can trigger any action hammerspoon can initiate – launching applications, macros, running scripts, laying out multiple windows, etc. &amp;nbsp; &lt;/p&gt;&lt;figure&gt;&lt;img src="https://mattorb.com/content/images/2019/09/Screen-Shot-2019-09-03-at-9.24.56-AM.png"&gt;&lt;figcaption&gt;My current Menuhammer system-wide menu (bound to Hyper-Space)&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;It looks like a great place to house things that are launched less frequently like occasional use macros, or toggling Wi-fi on and off. &amp;nbsp;I'm thinking this a good landing spot for things which either (1) are not used frequently enough to give up an immediate action keybinding slot or (2) are not used frequently enough that it is worth memorizing. &amp;nbsp;I bound it to hyper-space to try it out. &amp;nbsp;&lt;/p&gt;&lt;p&gt;After using it for a while, I found it useful to bind the application submenu to Hyper-A and the Finder submenu to Hyper-F to jump directly to those as needed. &amp;nbsp; &lt;/p&gt;&lt;figure&gt;&lt;img src="https://mattorb.com/content/images/2019/09/Screen-Shot-2019-09-03-at-9.25.05-AM.png"&gt;&lt;figcaption&gt;Application submenu, bound to hyper-A&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;img src="https://mattorb.com/content/images/2019/09/Screen-Shot-2019-09-03-at-9.25.13-AM.png"&gt;&lt;figcaption&gt;Finder submenu, bound to hyper-F&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Note the really cool feature of those hyper-F menu items: &amp;nbsp;Several of them launch Finder -and- send specific key to it, immediately selecting the 'Download's directory for instance.&lt;/p&gt;&lt;p&gt;I'm still experimenting with what feels most comfortable for applications I use regularly vs less often . . . especially in regards to putting applications on the shortlist in MenuHammer vs binding a key to launch them directly via hammerspoon. &lt;/p&gt;&lt;h2 id="hyper-key-and-super-duper-key-chord"&gt;Hyper key -and- Super Duper key chord?&lt;/h2&gt;&lt;p&gt;Given what we did in &lt;a href="https://mattorb.com/level-up-shortcuts-and-the-hyper-key/"&gt;part 1 of this series&lt;/a&gt;, where caps lock became a hyper key, with tab acting as a modifier when held, how does &lt;em&gt;how does super duper mode compare to that &lt;/em&gt;and can these two worlds live together? &amp;nbsp;If not, which one is more comfortable and effective?&lt;/p&gt;&lt;p&gt;With very few changes, I was able to fully enable Super Duper mode, and keep in place many of the caps-lock based hyper key things I already had. &amp;nbsp;This is for both cursor movement and window management (Spectacle vs Hammerspoon scripted). &amp;nbsp;This allowed me to compare the comfort level of each to see which one feels right. &amp;nbsp;After using super duper mode for a bit, I'm finding it a lot more comfortable, and have swapped out caps lock to be a ctrl key on hold instead of being my hyper key which maps to ctrl-alt-shift-cmd. &amp;nbsp; I have moved that hyper key down to the right-command key position, which I'm finding convenient. &amp;nbsp; &lt;/p&gt;&lt;p&gt;I'm also experimenting with an 'a'h 'f'udge 😜 &amp;nbsp;mode which maps &amp;nbsp;home/pgdn/pgup/end keys to h/j/k/l when the a+f keychord is held. &amp;nbsp;As always, all my curent setup can be found in my &lt;a href="https://github.com/mattorb/dotfiles"&gt;dotfiles repo&lt;/a&gt;. &amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;em&gt;* This is what I like to call them at the moment.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;** Karabiners key chord pains: dupe keys, missed key presses, missed dropping and enabling of chord state, tried many solutions including stuff currently marked as 'working' in Karabiner recipes. &amp;nbsp;All had problems with either messing up my normal typing of words or not working consistently enough.&lt;/em&gt;&lt;/p&gt; &lt;/div&gt; &lt;section&gt; &lt;h3&gt;Subscribe to mattorb&lt;/h3&gt; &lt;p&gt;Get the latest posts delivered right to your inbox&lt;/p&gt; &lt;form data-members-form="subscribe"&gt; &lt;p&gt;&lt;strong&gt;Great!&lt;/strong&gt; Check your inbox and click the link to confirm your subscription. &lt;/p&gt; &lt;p&gt; Please enter a valid email address! &lt;/p&gt; &lt;/form&gt; &lt;/section&gt; &lt;/article&gt; &lt;/div&gt;&lt;/div&gt;&lt;a href="https://mattorb.com/level-up-shortcuts-hammerspoon-home-row/"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sun, 7 Feb 2021 17:12:55 UT
      </pubDate>
      <guid>
        https://mattorb.com/level-up-shortcuts-hammerspoon-home-row/
      </guid>
    </item>
    <item>
      <title>
        Why you should migrate everything from Linux to BSD
      </title>
      <link>
        https://www.unixsheikh.com/articles/why-you-should-migrate-everything-from-linux-to-bsd.html
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;article&gt; &lt;p&gt;Published on &lt;span id="pubdate"&gt;2020-01-18&lt;/span&gt;. Modified on &lt;span id="moddate"&gt;2021-02-03&lt;/span&gt;.&lt;/p&gt; &lt;p&gt;As an operating system GNU/Linux has become a mess because of the fragmented nature of the project, the bloatware in the kernel, and because of the manipulation by corporate interests. There exist &lt;a href="https://unixsheikh.com/articles/technical-reasons-to-choose-freebsd-over-linux.html"&gt;several technical reasons&lt;/a&gt; for when a migration from GNU/Linux to BSD make sense, but this article isn't about that, it's an opinionated rant, more than anything else.&lt;/p&gt; &lt;h3&gt;Table of Contents&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="#introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#fragmented"&gt;Linux is fragmented&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#hijacked"&gt;Linux is being heavily influenced by corporate interests&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#bsd"&gt;BSD is the place to be&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#license"&gt;License problems&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#migrate"&gt;Time to migrate everything to BSD&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#links"&gt;Relevant links&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h2 id="introduction"&gt;Introduction&lt;/h2&gt; &lt;p&gt;In the past I have always been a favorite of choosing operating system and tools based upon technical merit. However, in today's world of companies like Microsoft, Apple, Google, and many others, compromising user privacy, and conducting controversial activities, I don't believe that to be the right cause of action.&lt;/p&gt; &lt;p&gt;Proprietary operating systems like &lt;a href="https://en.wikipedia.org/wiki/Windows_10#Privacy_and_data_collection"&gt;Microsoft Windows 10&lt;/a&gt;, &lt;a href="https://gist.github.com/iosecure/357e724811fe04167332ef54e736670d"&gt;Apple MacOS&lt;/a&gt;, and &lt;a href="https://en.wikipedia.org/wiki/Android_%28operating_system%29#Security_and_privacy"&gt;Google Android&lt;/a&gt; have become famous for their ill conduct, and even companies like Lenovo is using UEFI boot to inject custom Windows components, so that the system can phone home to Lenovo.&lt;/p&gt; &lt;p&gt;As a result of all this I have been a proponent for the open source alternatives, like GNU/Linux and BSD, for a very long time. Not only that, I also believe that the open source alternatives are much better in many technical areas.&lt;/p&gt; &lt;p&gt;I have also always been very much against &lt;a href="https://www.unixsheikh.com/articles/the-typical-discussions-about-bsd-vs-linux.html"&gt;The typical discussions about BSD vs Linux&lt;/a&gt;, and as I wrote in my article back then, I have always believed that the different open source projects can help each other and cooperate, and that end-users should only debate such issues from a technical stand point rather than personal preference.&lt;/p&gt; &lt;p&gt;Whenever it has been possible, I have proposed people, both private and in the industry, to change the operating systems they use to open source alternatives, and when people have been receptive to my advocacy I have helped them migrate from Microsoft Windows on their workstations to BSD or Linux. And likewise on the server side. This has been a truly successful endeavor and I have honestly never experienced a dissatisfied person or company.&lt;/p&gt; &lt;p&gt;However, things are beginning to change in the GNU/Linux world as more and more corporations want to control the direction of the Linux communities. Due to the structure and organization of GNU/Linux as an operating system, it is unfortunately susceptible to these influences, and while it is still open source, and still not anywhere near the bad things that is going on with the proprietary alternatives, some opt-out features have slowly been introduced into both the kernel and systemd.&lt;/p&gt; &lt;p&gt;You can still choose to opt-out of these features and go your merry way, but as an open source enthusiast and proponent, and as a privacy concerned individual, perhaps the better approach is to migrate systems to something where you don't have to concern yourself with "creepware".&lt;/p&gt; &lt;p&gt;As a system administrator I don't want to worry about whether I am going to be surprised the next time I upgrade a system, and I don't want to keep a list of spyware I have to remember to opt-out of whenever I run one of these systems.&lt;/p&gt; &lt;p&gt;Several Linux distributions have decided (not only because of privacy opt-out issues, but other issues as well) to implement &lt;a href="https://en.wikipedia.org/wiki/Category:Linux_distributions_without_systemd"&gt;other init solutions than systemd&lt;/a&gt;, but with the situation going on in the kernel development, and with many third party applications becoming more and dependent upon systemd, the problems are spreading to other parts of the operating system and I believe this is becoming an uphill battle.&lt;/p&gt; &lt;p&gt;I don't believe the future of GNU/Linux looks as bright as it used to, and as a possible alternative solution I suggest migrating everything (when possible) to something a bit more sane, like the BSD projects.&lt;/p&gt; &lt;h2 id="fragmented"&gt;Linux is fragmented&lt;/h2&gt; &lt;p&gt;In 1983 Richard Stallman announced his intent to start coding the GNU Project in a Usenet message. By June 1987, the project had accumulated and developed free and open source software for an assembler, an almost finished portable optimizing C compiler (GCC), an editor (GNU Emacs), and various Unix utilities, such as ls, grep, awk, make and ld.&lt;/p&gt; &lt;p&gt;In 1991, the Linux kernel appeared, developed outside the GNU project by Linus Torvalds, and in December 1992 it was made available under version 2 of the GNU General Public License. Combined with the operating system utilities already developed by the GNU project, it became the GNU/Linux operating system, better known as just "Linux".&lt;/p&gt; &lt;p&gt;Then came the Linux distributions. Different projects took the Linux kernel, the GNU tools and libraries, additional third party software, documentation, the X Window System, a window manager, and a desktop environment, and combined those components into the distributions. Different distributions focused on different goals, some put focus on the desktop while others put their main focus on servers, and again others tried to provide a multi-purpose operating system.&lt;/p&gt; &lt;p&gt;In the past all these different components and projects where developed by open source enthusiasts and communities and the passion for programming and open source was the driving force.&lt;/p&gt; &lt;p&gt;This is no longer the case! Please see &lt;a href="https://unixsheikh.com/articles/the-real-motivation-behind-systemd.html"&gt;The real motivation behind systemd&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Linus Torvalds has many times made it very clear that he doesn't care about what goes on in the "Linux world", all he cares about is the kernel development, and on January 6, 2020 in the "Moderated Discussions" forum at &lt;a href="https://www.realworldtech.com/forum/?threadid=189711&amp;amp;curpostid=189841"&gt;realworldtech.com&lt;/a&gt;, Linus Torvalds answered a user's question, with an absolute jaw-dropping comment, about a year-old kernel maintenance controversy that heavily impacted the ZFS on Linux project.&lt;/p&gt; &lt;p&gt;After answering the user's actual question, Torvalds went on to make very wrong and damaging claims about the ZFS filesystem. Torvalds said:&lt;/p&gt; &lt;blockquote&gt; It (ZFS) was always more of a buzzword than anything else. &lt;/blockquote&gt; &lt;p&gt;By that statements Linus Torvalds has just reduced more that 15 years of development of one of the most robust and popular filesystems in the world into a "buzzword"!&lt;/p&gt; &lt;p&gt;ZFS is described as "The last word in filesystems". It is a combined filesystem and logical volume manager originally designed by Sun Microsystems. ZFS is a stable, fast, secure, and future-proof filesystem. It is scalable, and includes extensive protection against data corruption, support for high storage capacities, a maximum 16 Exabyte file size, and a maximum 256 Quadrillion Zettabytes storage with no limit on number of filesystems (datasets) or files, efficient data compression, snapshots and copy-on-write clones, continuous integrity checking and automatic repair, RAID-Z, native NFSv4 ACLs, and can be very precisely configured.&lt;/p&gt; &lt;p&gt;The two main implementations, by Oracle and by the &lt;a href="https://en.wikipedia.org/wiki/OpenZFS"&gt;OpenZFS&lt;/a&gt; project, are extremely similar, making ZFS widely available within Unix-like systems.&lt;/p&gt; &lt;p&gt;As mentioned in the Wikipedia article, OpenZFS is an umbrella project aimed at bringing together individuals and companies that use the ZFS file system and work on its improvements, aiming as well at making ZFS more widely used and developed in an open-source manner. OpenZFS brings together developers from the illumos, Linux, FreeBSD, and macOS platforms, and a wide range of companies. High-level goals of the project include raising awareness of the quality, utility and availability of open-source implementations of ZFS, encouraging open communication about ongoing efforts toward improving open-source variants of ZFS, and ensuring consistent reliability, functionality and performance of all distributions of ZFS.&lt;/p&gt; &lt;p&gt;&lt;a href="https://github.com/zfsonlinux/zfs/commits/master"&gt;OpenZFS on Linux&lt;/a&gt;, which is the Linux part of the project, has currently 345 active contributors with more that 5.600 commits, and commits are being made on an almost daily basis!&lt;/p&gt; &lt;p&gt;Some of the worlds biggest CDN and data storage services runs ZFS on either FreeBSD or Linux!&lt;/p&gt; &lt;p&gt;In another situation Linus Torvalds gave an interview on &lt;a href="https://www.youtube.com/watch?v=mysM-V5h9z8"&gt;TFiR: open source and Emerging Tech YouTube channel&lt;/a&gt; about Linux on the desktop in which he makes another amazing statement saying that Linux still isn't ready for the desktop and that perhaps &lt;a href="https://en.wikipedia.org/wiki/Chrome_OS"&gt;Chrome OS&lt;/a&gt; is the solution to that problem.&lt;/p&gt; &lt;p&gt;These and many other statements by Linus Torvalds shows that Torvalds should avoid authoritative statements about projects he's unfamiliar with, but more importantly they also show that Linux as an operating system has no real direction and no clear management because the kernel development is performed in isolation from the rest of the Linux world.&lt;/p&gt; &lt;p&gt;Linus Torvalds is generally also very open to the rapid influence by corporate interests and his perspective on security is also worrying.&lt;/p&gt; &lt;p&gt;In 2009 Linus Torvalds admitted that the kernel development is getting out of control.&lt;/p&gt; &lt;blockquote&gt; We're getting bloated and huge. Yes, it's a problem ... Uh, I'd love to say we have a plan ... I mean, sometimes it's a bit sad that we are definitely not the streamlined, small, hyper-efficient kernel that I envisioned 15 years ago ... The kernel is huge and bloated, and our icache footprint is scary. I mean, there is no question about that. And whenever we add a new feature, it only gets worse. &lt;/blockquote&gt; &lt;p&gt;At LinuxCon 2014, he said that he thinks the bloat situation is better because modern PCs are a lot faster!&lt;/p&gt; &lt;blockquote&gt; We've been bloating the kernel over the last 20 years, but hardware has grown faster. &lt;/blockquote&gt; &lt;p&gt;This is a very problematic attitude.&lt;/p&gt; &lt;p&gt;When software gets bloated it not only becomes more insecure and more error prone, but it also becomes much slower. Thinking that the problem goes away because hardware becomes faster is an immature attitude. In this day and age we need to optimize software so that less power is required, we need to save power and limit pollution.&lt;/p&gt; &lt;p&gt;In a 2007 interview "Why I quit": kernel developer Con Kolivas he stated:&lt;/p&gt; &lt;blockquote&gt; If there is any one big problem with kernel development and Linux it is the complete disconnection of the development process from normal users. You know, the ones who constitute 99.9% of the Linux user base. The Linux kernel mailing list is the way to communicate with the kernel developers. To put it mildly, the Linux kernel mailing list (lkml) is about as scary a communication forum as they come. Most people are absolutely terrified of mailing the list lest they get flamed for their inexperience, an inappropriate bug report, being stupid or whatever. ... I think the kernel developers at large haven't got the faintest idea just how big the problems in userspace are. &lt;/blockquote&gt; &lt;p&gt;Besides from the above mentioned problems, the fact of the matter is that Linux as an operating system is put together by many different applications from different projects that has absolutely nothing to do with each other. If you don't know anything about this you should take a look at how you build &lt;a href="http://www.linuxfromscratch.org/lfs/view/stable/"&gt;Linux From Scratch&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Another good read that demonstrates some of these problems is the article &lt;a href="https://web.archive.org/web/20200813101037/https://blog.farhan.codes/2018/06/25/linux-maintains-bugs-the-real-reason-ifconfig-on-linux-is-deprecated/"&gt;Linux maintains bugs: The real reason ifconfig on Linux is deprecated&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;This is very different from the BSDs as those projects, meaning FreeBSD, OpenBSD, NetBSD and DragonFly BSD, each are independent projects that put together their systems "in-house", so to speak. The kernel, the standard C library, the user land tools, etc., are all part of the base system of the operating system, not something put together from a bunch of different outside sources.&lt;/p&gt; &lt;h2 id="hijacked"&gt;Linux is being heavily influenced by corporate interests&lt;/h2&gt; &lt;p&gt;A Linux distribution is a collection of tools written by different groups of people, often with conflicting interests and priorities, and because of this fragmented structure of the GNU/Linux operating system, the project as a whole is rapidly spinning out of control as it gets pushed around by commercial interests.&lt;/p&gt; &lt;p&gt;Even the best GNU/Linux distributions, such as Debian GNU/Linux and Arch Linux, that are still mainly driven by open source communities, are not immune to this problem because they not only still depend heavily on the fragmented tools, but many developers also directly work for some of these major commercial companies.&lt;/p&gt; &lt;p&gt;In my article &lt;a href="https://www.unixsheikh.com/articles/the-real-motivation-behind-systemd.html"&gt;The real motivation behind systemd&lt;/a&gt; I have written about how the primary reason for developing systemd is Red Hats financial interests in embedded devices, primarily at the U.S. Military and the automobile industry. Initially systemd was released as a new init system, but it has slowly grown into what Poettering describes as "a suite of software that provides fundamental building blocks for a Linux operating system."&lt;/p&gt; &lt;p&gt;In an &lt;a href="https://linux.slashdot.org/story/17/10/30/0237219/interviews-red-hat-ceo-jim-whitehurst-answers-your-questions"&gt;interview&lt;/a&gt; with Red Had CEO Jim Whitehurst he states:&lt;/p&gt; &lt;blockquote&gt; We partner with the largest embedded vendors in the world, particularly in the telecom and automotive industries where stability and reliability is the number one concern. They easily adapted to systemd. &lt;/blockquote&gt; &lt;p&gt;I have nothing against the init part of systemd, or systemd as an administration tool, on the contrary I really like it, and I even like some of the other tools that come with it, but the main problem with systemd is that its continued development is motivated by a company's financial interests and not the open source community interests. As such, the adoption of systemd by the major Linux distributions, such as Debian GNU/Linux and Arch Linux, was a big mistake in my humble opinion. They have made themselves heavily dependent upon systemd and Red Hat.&lt;/p&gt; &lt;p&gt;Another heavy influence on the Linux world is Google. Google has developed both Android and Chrome OS, both Linux kernel-based operating systems. Chrome OS is derived from Chromium OS and uses the Google Chrome web browser as its principal user interface.&lt;/p&gt; &lt;p&gt;Chrome OS is viewed as a competitor to Microsoft, both directly to Microsoft Windows and indirectly the company's word processing and spreadsheet applications, the latter through Chrome OS's reliance on cloud computing. And this is one of the core problems with Chrome OS, it is built with great reliance of Googles cloud infrastructure.&lt;/p&gt; &lt;p&gt;Google has become one of the most &lt;a href="https://en.wikipedia.org/wiki/Google#Criticism_and_controversy"&gt;controversial companies&lt;/a&gt;. Google is in its essence an advertisement company and it has become famous for their manipulation of search results and extreme user tracking capabilities, mainly thanks to the stupidity of web developers adding Google Analytics to their websites.&lt;/p&gt; &lt;p&gt;In a YouTube video from August 2019 by &lt;a href="https://www.youtube.com/watch?v=YNp4OqdxHWI"&gt;Linus Tech Tips&lt;/a&gt;, Linus Sebastian demonstrates how tracking on the Internet works and how it affects the prices you get offered when you search for products. &lt;b&gt;Please note&lt;/b&gt;: The video was sponsored by Private Internet Access, a company that has since been bought by Kape Technologies which is known for sending malware through their software and for being really scummy in general. &lt;strong&gt;Don't use Private Internet Access!&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Cloudflare is another American web infrastructure and website company that is affecting different areas of the development. The company provides services that actually sit between a website's visitor and the Cloudflare user's hosting provider, acting as a reverse proxy for websites. As such Cloudflare has become one of the greatest cancers of the Internet.&lt;/p&gt; &lt;p&gt;Both systemd and Mozilla has managed to integrate Cloudflare into the core of their products. systemd has integrated both Cloudflare's and Google's DNS servers as opt-out in systemd-resolved and Mozilla is defaulting their &lt;a href="https://en.wikipedia.org/wiki/DNS_over_HTTPS"&gt;DNS over HTTPS&lt;/a&gt; in Firefox to Cloudflare.&lt;/p&gt; &lt;p&gt;Even though Mozilla Firefox isn't a Linux project, it is still one of the most widely used browsers on the different Linux distributions and when Mozilla makes the big mistake of integrating DNS over HTTPS in Firefox, let alone using Cloudflare, they are setting a very bad precedence. DNS over HTTPS is by itself &lt;a href="https://www.youtube.com/watch?v=ZxTdEEuyxHU"&gt;bad enough&lt;/a&gt;, and &lt;a href="https://en.wikipedia.org/wiki/DNS_over_HTTPS#Criticism"&gt;highly criticized&lt;/a&gt; with good reason, but by combining it with a controversial company like Cloudflare it makes it even worse. OpenBSD has &lt;a href="https://undeadly.org/cgi?action=article;sid=20190911113856"&gt;disabled DNS over HTTPS&lt;/a&gt; by default in their builds of Firefox due to use of Cloudflare services for this feature.&lt;/p&gt; &lt;p&gt;With the growing influence of Red Hat through systemd, they have managed to steer the direction of GNU/Linux as an operating system in a direction that contradicts what many system administrators and users would like to see.&lt;/p&gt; &lt;h2 id="bsd"&gt;BSD is the place to be&lt;/h2&gt; &lt;p&gt;Contrary to the Linux distributions the &lt;a href="https://en.wikipedia.org/wiki/BSD_(operating_system)"&gt;Berkeley Software Distribution (BSD)&lt;/a&gt; is not a fragmented project. The BSD projects maintain the entire operating system, not only the kernel.&lt;/p&gt; &lt;p&gt;BSD was an operating system based on Research Unix, developed and distributed by the Computer Systems Research Group (CSRG) at the University of California, Berkeley. Today, "BSD" refers to its descendants, such as &lt;a href="https://www.freebsd.org/"&gt;FreeBSD&lt;/a&gt;, &lt;a href="https://www.openbsd.org/"&gt;OpenBSD&lt;/a&gt;, &lt;a href="https://www.netbsd.org/"&gt;NetBSD&lt;/a&gt; and &lt;a href="https://www.dragonflybsd.org/"&gt;DragonFly BSD&lt;/a&gt;. These projects are real operating systems not just kernels and they are not "distributions".&lt;/p&gt; &lt;p&gt;Linux distributions, such as Debian GNU/Linux and Arch Linux have to do the work of bringing together all the software required to create a complete Linux operating system. They need the &lt;a href="https://www.kernel.org/"&gt;Linux kernel&lt;/a&gt;, the &lt;a href="https://www.gnu.org/gnu/linux-and-gnu.html"&gt;GNU tools and libraries&lt;/a&gt;, an &lt;a href="https://en.wikipedia.org/wiki/Init"&gt;init system&lt;/a&gt;, and some amount of third party applications in order to end up with a functioning operating system.&lt;/p&gt; &lt;p&gt;In contrast the BSDs are both a kernel and a complete operating system. For example, FreeBSD provides both the FreeBSD kernel and the FreeBSD operating system. It is maintained as a single project.&lt;/p&gt; &lt;p&gt;No one person or corporation owns BSD. It is created and distributed by a community of highly technical and committed contributors all over the world.&lt;/p&gt; &lt;p&gt;Companies also &lt;a href="https://en.wikipedia.org/wiki/List_of_products_based_on_FreeBSD"&gt;use and contribute to BSD&lt;/a&gt;, but contrary to Linux, a company cannot "hijack" BSD. A company can make their own version of BSD, such as Sony Computer Entertainment has done for their PlayStation 3, PlayStation 4 and PlayStation Vita gaming consoles, but because the BSDs are complete operating systems, and because each BSD project is maintained and developed by open source enthusiasts and communities, not companies such as Red Hat, the BSD projects are really and truly independent.&lt;/p&gt; &lt;p&gt;The result of this organization of the BSDs you wont find crazy opt-out spyware settings in your basic installation, no matter what BSD project you choose, and you don't find privacy compromising solutions integrated into the operating system core components.&lt;/p&gt; &lt;p&gt;On the contrary, because the BSD projects are developed and driven by skillful and enthusiastic people who care much about operating system design, security, and privacy, you will often find that even the third party software that are available for installation using a package manager gets patched so that these problems are removed, such as the &lt;a href="https://undeadly.org/cgi?action=article;sid=20190911113856"&gt;disabling of DNS over HTTPS by OpenBSD&lt;/a&gt; in Firefox.&lt;/p&gt; &lt;p&gt;Another great benefit from all of this is that the communities that surround the BSD projects consist of experienced, helpful, and (for the most part) kind people.&lt;/p&gt; &lt;h2 id="license"&gt;License problems&lt;/h2&gt; &lt;p&gt;The GPL license is more strict on developers and it is an &lt;a href="https://www.youtube.com/watch?v=Pm8P4oCIY3g&amp;amp;t=37m05s"&gt;open source anti-pattern&lt;/a&gt; as it forces a release of all modified source code and prevents other open source projects from being integrated, for example, the GPLv2 is preventing the integration of &lt;a href="https://en.wikipedia.org/wiki/DTrace"&gt;DTrace&lt;/a&gt; and &lt;a href="https://en.wikipedia.org/wiki/ZFS"&gt;ZFS&lt;/a&gt; in Linux.&lt;/p&gt; &lt;p&gt;BSD developers on the other hand have no such restrictions. Manufacturers may opt for BSD as their operating system of choice when creating new devices instead of Linux. This would allow them to keep the code modifications to themselves if they wanted to. With Linux the license force the release of the source code to the public.&lt;/p&gt; &lt;p&gt;The GPL license may sound better, because why should we allow companies to simply "steal" our open source code and produce proprietary products without even giving anything back. But it's not that simple. By forcing companies to release source code to the public via the GPL license, companies quickly become more manipulative.&lt;/p&gt; &lt;p&gt;The tactics deployed by Red Hat with the release of systemd was to try to get as many "important" third party projects to cooperate very tightly with systemd, or even depend upon systemd. This way other Linux distributions are more easily persuaded into adopting systemd because of the easy integration of these third party projects. The systemd developers addressed several third party projects and tried to convince them to make their projects either depend upon systemd, such as the attempts made by Lennart Poettering on &lt;a href="https://mail.gnome.org/archives/desktop-devel-list/2011-May/msg00427.html"&gt;the Gnome mailing list&lt;/a&gt;, and the attempt made by Red Hat developer "keszybz" on &lt;a href="https://github.com/tmux/tmux/issues/428"&gt;the tmux project&lt;/a&gt;. Most of these attempts were originally "disguised" as technical issues, however when you read the long email correspondence on the Gnome mailing list and elsewhere, the real intent becomes quite clear.&lt;/p&gt; &lt;p&gt;Such manipulation isn't needed in BSD. Companies are free to do whatever they want with BSD and as such they don't need to try to affect the way things are going. If that wasn't the case we would possible see, for example, Sony trying very hard to influence the development of FreeBSD because they use that in their PlayStation products.&lt;/p&gt; &lt;p&gt;The different GNU/Linux distributions, such as Debian GNU/Linux, Arch Linux, and even Red Hat Linux back in the days, were really great projects. When projects are driven by passion and not profit they tend to become much better quality. However, when projects are no longer driven by passion, but rather by profit, they often decline in quality. This is natural because motivation by profit is very different from motivation by passion. This is one of the reasons why Microsoft Windows has always been such a crappy OS.&lt;/p&gt; &lt;p&gt;The reason for the success of Microsoft Windows on the desktop isn't because people believe that Windows is a great operating system, no sane and experienced system administrator or IT supporter believes that, rather it is because of the aggressive marketing strategy deployed by Microsoft.&lt;/p&gt; &lt;p&gt;While the BSD projects do get both code and occasional financial support from companies, they are driven by passion and not by profit. This mainly means well thought out decisions. There are no compromises with privacy or security for the benefit of profit such as what we may find in Linux.&lt;/p&gt; &lt;h2 id="migrate"&gt;Time to migrate everything to BSD&lt;/h2&gt; &lt;p&gt;Back in about 1998-2000 I started migrating every server and desktop operating system from Microsoft Windows, both at home and at my company, to GNU/Linux, initially Red Hat Linux and then later Debian GNU/Linux. I did that because I had spent about a decade doing Microsoft Windows support and wasted so much time on this absolutely horrible operating system.&lt;/p&gt; &lt;p&gt;When I was recommended GNU/Linux by a good friend of mine I was amazed at how well it performed, how amazing the open source communities were, and how all the usual problems related to Windows just vanished. Whenever I replaced a Windows setup with a Linux setup at a customer, a family member, or a friend, the support hours rapidly declined. Of course this meant less customer support work, but this was great because now we could concentrate our time on more important matters.&lt;/p&gt; &lt;p&gt;A little later I discovered the BSD world and eventually also began deploying both FreeBSD and OpenBSD on servers and on desktops too.&lt;/p&gt; &lt;p&gt;Back in the days Linux often had better hardware support than BSD and as a result I generally used Linux more than BSD. Hardware was expensive and it was not always possible to purchase hardware based upon which operating system you wanted to run on the system. This is different today where the BSDs generally have great support for modern hardware.&lt;/p&gt; &lt;p&gt;I still like GNU/Linux, but I don't want to worry about possibly privacy breaking crap in systemd, or whatever creepware Lennart Poettering comes up with next, I also don't want to worry about all the bloatware that goes into the kernel, such as the kernel &lt;a href="https://patchwork.kernel.org/patch/10084131/"&gt;forcing adaption of DRM&lt;/a&gt;. I generally don't want to worry about whatever the next problematic thing is going to be. Everything needs to be sane options and decisions by default! Not opt-out!&lt;/p&gt; &lt;p&gt;You can read about FreeBSD in my article &lt;a href="https://www.unixsheikh.com/articles/freebsd-is-an-amazing-operating-system.html"&gt;FreeBSD is an amazing operating system&lt;/a&gt; and about OpenBSD in my article &lt;a href="https://www.unixsheikh.com/articles/openbsd-is-fantastic.html"&gt;OpenBSD is fantastic&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;i&gt;If you have any comments or corrections please feel free to email them to me. Also, if you found this content useful consider supporting me on &lt;a href="https://patreon.com/unixsheikh"&gt;Patreon&lt;/a&gt;&lt;/i&gt;&lt;/p&gt; &lt;h2&gt;Other relevant links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://blog.farhan.codes/2018/06/25/linux-maintains-bugs-the-real-reason-ifconfig-on-linux-is-deprecated/"&gt;Linux maintains bugs: The real reason ifconfig on Linux is deprecated&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.hostingadvice.com/blog/freebsd-project-under-the-hood/"&gt;FreeBSD Committer Allan Jude Discusses the Advantages of FreeBSD and His Role in Keeping Millions of Servers Running&lt;/a&gt;. &lt;b&gt;Note:&lt;/b&gt; FreeBSD has grown considerably since the interview with Allan Jude back in 2016.&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.freebsd.org/advocacy/whyusefreebsd.html"&gt;Why choose FreeBSD?&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=ps67ECyh0sM"&gt;FreeBSD is not a Linux distribution&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.freebsd.org/"&gt;FreeBSD&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.freebsdfoundation.org/journal/browser-based-edition/"&gt;The FreeBSD Journal&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.openbsd.org/"&gt;OpenBSD&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://undeadly.org/"&gt;The OpenBSD Journal&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://svnweb.freebsd.org/base/head/share/misc/bsd-family-tree?view=co"&gt;The BSD family tree&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.youtube.com/user/EuroBSDcon/playlists"&gt;EuroBSDcon playlists on YouTube&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/article&gt;&lt;/div&gt;&lt;a href="https://www.unixsheikh.com/articles/why-you-should-migrate-everything-from-linux-to-bsd.html"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sun, 7 Feb 2021 23:22:59 UT
      </pubDate>
      <guid>
        https://www.unixsheikh.com/articles/why-you-should-migrate-everything-from-linux-to-bsd.html
      </guid>
    </item>
    <item>
      <title>
        
      </title>
      <link>
        https://monetize.substack.com/p/open-source-eras
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div&gt;&lt;p&gt;Open source is the current norm for developer collaboration and customer adoption in software. It is the foundation that enabled unicorns and cloud providers to build their services from the ground up. But that wasn’t always the case with open source, and it is changing and evolving again.&amp;nbsp;&lt;/p&gt;&lt;div&gt;&lt;figure&gt;&lt;a href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F183f2e91-d9bb-4dfe-8259-94637f245189_2400x938.png"&gt;&lt;img alt="" data-attrs="{&amp;quot;src&amp;quot;:&amp;quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/183f2e91-d9bb-4dfe-8259-94637f245189_2400x938.png&amp;quot;,&amp;quot;height&amp;quot;:569,&amp;quot;width&amp;quot;:1456,&amp;quot;resizeWidth&amp;quot;:null,&amp;quot;bytes&amp;quot;:139222,&amp;quot;alt&amp;quot;:null,&amp;quot;title&amp;quot;:null,&amp;quot;type&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;href&amp;quot;:null}" src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F183f2e91-d9bb-4dfe-8259-94637f245189_2400x938.png"&gt;&lt;/a&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;&lt;em&gt;Open Source Eras and relative adoption trend lines&lt;/em&gt;&lt;/p&gt;&lt;p&gt;In this post, I will look at open source evolution broadly, try to analyze what are some of the triggers and enablers for the change, and where it might be heading next. Let’s start with the main open software development eras by summarizing the main trends and then focus on the big picture with an attempt to predict the future.&lt;/p&gt;&lt;h2&gt;Free Software (1980)&lt;/h2&gt;&lt;p&gt;The term “free software” is attributed to Richard Stallman around the 1980s for using it for the &lt;a href="https://en.wikipedia.org/wiki/Free-software_movement"&gt;free-software movement&lt;/a&gt;. During these early days of computing, Richard started the GNU project in an effort to cultivate collaboration among the early hacker community and create a freedom-respecting operating system. He campaigns for software to be distributed in a manner such that its users receive the freedoms to use, study, distribute, and modify that software. This era set the origins of open source and more importantly the free software licenses (such as GPL) that flourish later.&lt;/p&gt;&lt;p&gt;At the time, the main software creators in the open were the individual hackers and in their view of the world, the software had to be free as speech and remain so. Free software grew because personal computers became more widely available to these hackers and they used CDs, floppy disks, and the early internet to distribute software and spread their ideology.&lt;/p&gt;&lt;p&gt;In this pre-internet era, manual distributions of software, supporting documentation, consulting services (installation, development), &lt;a href="https://www.gnu.org/philosophy/selling-exceptions.en.html"&gt;selling-exceptions&lt;/a&gt; were some of the popular monetization methods.&lt;/p&gt;&lt;h2&gt;Open Source Software (2000)&lt;/h2&gt;&lt;p&gt;The term "open source" was used by a group of people from the free-software movement around 2000. The motivation for this new term was to free itself from the ideological and confrontational connotations of the term "free software" and make it more appealing for the business world. The supporters of the open source movement stress the subtle difference from free software where free software requires any changes to be submitted to the original maker for redistribution, and any derivative software must also be distributed as free software. This new term set the beginning of a new movement and the forming of &lt;a href="https://en.wikipedia.org/wiki/Open_Source_Initiative"&gt;Open Source Initiative&lt;/a&gt; to educate and advance open source culture. The open source movement allowed smaller companies to play a more significant role in the software economy by giving them access to the software needed to compete in the global market. Before that, it was the larger corporations, the producers of the networks and hardware who had the power.&lt;/p&gt;&lt;p&gt;Open source sparked from the early hackers community but grew rapidly into open source businesses, enabled by software foundations, the internet, and the wider adoption of open source by companies of all sizes. The primary monetization mechanism for the open source software is through support and the open core models where additional accompanying value is created around the core open source project. While this open core (enabled by permissive licenses such as MIT, Apache) allows everybody to benefit from it, it is also its Achilles' heel as we will see next.&lt;/p&gt;&lt;h2&gt;Shared Source Software (2020)&lt;/h2&gt;&lt;p&gt;Open source licenses give more freedom to the users, but they don’t give many advantages to the producers of the software. Many small projects with a handful of maintainers create huge economic value which ends up captured by other companies with better operational capabilities to monetize. This leads the maintainers of these projects to remain below the poverty line. Other companies hire open source maintainers as full-time employers and bet their company existence and brand into the success of their open source project. Yet they got disrupted and threatened by even larger hyperscale SaaS providers who have the scale to capture the economical value more efficiently and faster from the same projects.&lt;/p&gt;&lt;p&gt;This new economic reality started forcing individual maintainers and small companies to move their software away from business-friendly open source to other free software inspired derivative licenses and pursue dual-licensing models. This new family of licenses is not proprietary, but they don’t fit the open source definition either as they protect the trademark owner from the competition by discriminating against certain ways of software distributions such as SaaS. This transition of new and existing open source projects to non-open source licenses indicates the start of a new era. Keeping the source partially open is primarily for marketing and user adoption purposes rather than collaborative development and keeping software useful for everybody. This shared source software era is triggered by the existential threat of not being able to offer the software in a way demanded by consumers (as a SaaS) and efficiently capture economical value by the creators whether they are individual contributors or large companies with an open source business model.&lt;/p&gt;&lt;div&gt;&lt;figure&gt;&lt;a href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F062fa2cc-b9c0-4e06-80a8-be4b861c123e_1636x1252.png"&gt;&lt;img alt="" data-attrs="{&amp;quot;src&amp;quot;:&amp;quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/062fa2cc-b9c0-4e06-80a8-be4b861c123e_1636x1252.png&amp;quot;,&amp;quot;height&amp;quot;:1114,&amp;quot;width&amp;quot;:1456,&amp;quot;resizeWidth&amp;quot;:null,&amp;quot;bytes&amp;quot;:330468,&amp;quot;alt&amp;quot;:null,&amp;quot;title&amp;quot;:null,&amp;quot;type&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;href&amp;quot;:null}" src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F062fa2cc-b9c0-4e06-80a8-be4b861c123e_1636x1252.png"&gt;&lt;/a&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;&lt;em&gt;Open source software eras and main characteristics&lt;/em&gt;&lt;/p&gt;&lt;p&gt;Protected by these new licenses, the enablers for the modern-day independent hackers are the powerful online services that allow them to offer good quality software through globally available automation tools based on git, build tools, software scanning, and distribution services, etc. These hackers can build enough critical mass of supporters through social media and are able to capture economical value through services such as Github sponsors, Patreon, Tidelift, and &lt;a href="https://www.oss.fund/"&gt;many others&lt;/a&gt;. The other group, the disrupted open source companies are transitioning to the SaaS based distribution of software as vertical cloud services on top of the hybrid cloud infrastructure to compete with cloud providers. This allows the creators of the software to offer their service on multiple clouds and at the same time align with the way users prefer to consume software, which is as a service.&lt;/p&gt;&lt;h2&gt;What Will Software After Open Source Look Like?&lt;/h2&gt;&lt;p&gt;The start of a new trend doesn’t indicate the end of the existing eras, but a new addition to the mix. Free and open source software will continue growing at a huge pace. At the same time, I believe we will see an acceleration of the trend towards the so-called shared source and source available licenses too. This will double down on the dual-licensing of smaller library projects by individual developers and the SaaS-based distribution of bigger projects. The open core and open source models will remain here, but the open core of the projects will get smaller and smaller, practically useless for the competitors. We will see projects starting as open source during bootstrapping and initial adoption phases, and then transition to source available licenses when threatened by more operationally mature competitors. Unfortunately, this initial phase of uncertainty and adaptation in the shared source era will limit collaboration among competitors and demonstrate the importance of open governance and open funding through neutral software foundations or decentralized technologies.&lt;/p&gt;&lt;p&gt;Then we will see cycles repeating and independent hackers flourish again, innovating as in the free software era. But this time they will be better equipped with better infrastructure to support their livelihood as independent small businesses of one. They will start projects in the open to scratch their itch, but quickly turn them into businesses or let them die. They will be less ideological, and more practical. These independent hackers will not need to be part of the traditional horizontal software companies that bundle engineering, marketing, sales, support, education, etc to be successful in the software business. Instead, they will be able to consume unbundled vertical online services and deliver enterprise-grade software. We will see a rise in the tools and platforms that offer reliable project governance without joining a foundation or consortium. Independent software builders can use decentralized &lt;a href="http://bit.ly/rdcle"&gt;infrastructure&lt;/a&gt;, &lt;a href="http://bit.ly/devprtcl"&gt;tokenize&lt;/a&gt; their projects, and customize the &lt;a href="http://bit.ly/srcred"&gt;governance&lt;/a&gt; through on-chain community voting. The economical and governance aspects of the projects will be merged with the source code and licenses into a holistic entity enabled by blockchain technology and create opportunities for individual hackers to create million-dollar companies.&lt;/p&gt;&lt;p&gt;The infrastructure for independent techies will not be only for the software builders but for the whole ecosystem. Creating software is not enough, it has to go through the full pipeline of budgeting, building, marketing, hosting, sales, support in order to grow and remain sustainable. Speculators will put money into project tokens to help bootstrap projects and gain returns. Developers will build. Indies will create niche services complementing larger projects. Subject matter experts will provide consulting services and online training, and bounty hackers will hunt for ad-hoc work. Sometimes all of it will be driven by a single person, and sometimes a whole decentralized ecosystem forming around a project without the dominance of a central business entity. This will take a generation of software builders...&lt;/p&gt;&lt;h2&gt;Conclusion&lt;/h2&gt;&lt;p&gt;At the beginning of the open source era, Eric S. Raymond described a decentralized software development process called &lt;a href="https://opensource.com/article/18/9/barter-currency-system"&gt;The Cathedral and The Bazaar&lt;/a&gt;. This era proved that the bazaar is the superior software development model. But at the same time, this era also showed us the limitations and the narrow mindedness of this model when it is not accompanied by a &lt;a href="https://monetize.substack.com/p/a0cf19a6-62d2-47f7-9771-82dec3d01094"&gt;holistic governance and monetization view&lt;/a&gt;. The next era will improve on the same decentralized development principles by incorporating decentralized monetization and governance too. This will take us the full cycle of Decentralized and Sustainable Open Software nirvana.&lt;/p&gt;&lt;p&gt;&lt;em&gt;If you like my explorations of opensource, blockchain, &lt;/em&gt;monetization&lt;em&gt;, sing up to the &lt;a href="https://monetize.substack.com/"&gt;newsletter&lt;/a&gt; or follow me on &lt;a href="https://twitter.com/bibryam"&gt;twitter&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;a href="https://monetize.substack.com/p/open-source-eras"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sun, 7 Feb 2021 23:24:47 UT
      </pubDate>
      <guid>
        https://monetize.substack.com/p/open-source-eras
      </guid>
    </item>
    <item>
      <title>
        Why You Should Stop Caring What Other People Think (Taming the Mammoth) - Wait But Why
      </title>
      <link>
        https://waitbutwhy.com/2014/06/taming-mammoth-let-peoples-opinions-run-life.html
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;article id="post-1861"&gt; &lt;div id="pico"&gt;&lt;div id=""&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;We made a fancy PDF of this post for printing and offline viewing. &lt;a rel="noopener" href="https://gum.co/wbw-mammoth"&gt;Buy it here.&lt;/a&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt; &lt;p&gt;&lt;span&gt;&lt;strong&gt;Part 1: Meet Your Mammoth&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;The first day I was in second grade, I came to school and noticed that there was a new, very pretty girl in the class—someone who hadn’t been there the previous two years. Her name was Alana and within an hour, she was everything to me.&lt;/p&gt; &lt;p&gt;When you’re seven, there aren’t really any actionable steps you can take when you’re in love with someone. You’re not even sure what you want from the situation. There’s just this amorphous yearning that’s a part of your life, and that’s that.&lt;/p&gt; &lt;p&gt;But for me, it became suddenly relevant a few months later, when during recess one day, one of the girls in the class started asking each of the boys, “Who do &lt;em&gt;youuu &lt;/em&gt;want to marry?” When she asked me, it was a no-brainer. “Alana.”&lt;/p&gt; &lt;p&gt;Disaster.&lt;/p&gt; &lt;p&gt;I was still new to being a human and didn’t realize that the &lt;em&gt;only &lt;/em&gt;socially acceptable answer was, &lt;em&gt;“No one.”&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The second I answered, the heinous girl ran toward other students, telling each one, “Tim said he wants to marry &lt;em&gt;Alana!&lt;/em&gt;” Each person she told covered their mouth with uncontrollable laughter. I was finished. Life was over.&lt;/p&gt; &lt;p&gt;The news quickly got back to Alana herself, who stayed as far away from me as possible for days after. If she knew what a restraining order was, she’d have taken one out.&lt;/p&gt; &lt;p&gt;This horrifying experience taught me a critical life lesson—it can be mortally dangerous to be yourself, and you should exercise extreme social caution at all times.&lt;/p&gt; &lt;p&gt;Now this sounds like something only a traumatized second grader would think, but the weird thing, and the topic of this post, is that this lesson isn’t just limited to me and my debacle of a childhood—&lt;em&gt;it’s a defining paranoia of the human species. &lt;/em&gt;We share a collective insanity that pervades human cultures throughout the world:&lt;/p&gt; &lt;p&gt;&lt;span&gt;&lt;b&gt;An irrational and unproductive obsession with what other people think of us.&lt;/b&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;Evolution does everything for a reason, and to understand the origin of this particular insanity, let’s back up for a minute to 50,000BC in Ethiopia, where your &lt;a rel="noopener" href="https://waitbutwhy.com/2013/12/your-ancestor-is-jellyfish.html"&gt;Great&lt;sup&gt;2,000&lt;/sup&gt; Grandfather&lt;/a&gt; lived as part of a small tribe.&lt;/p&gt; &lt;p&gt;Back then, being part of a tribe was critical to survival. A tribe meant food and protection in a time when neither was easy to come by. So for your Great&lt;sup&gt;2,000&lt;/sup&gt; Grandfather, almost nothing in the world was more important than being accepted by his fellow tribe members, especially those in positions of authority. Fitting in with those around him and pleasing those above him meant he could stay in the tribe, and about the worst nightmare he could imagine would be people in the tribe starting to whisper about how annoying or unproductive or weird he was—because if enough people disapproved of him, his ranking within the tribe would drop, and if it got really bad, he’d be kicked out altogether and left for dead. He also knew that if he ever embarrassed himself by pursuing a girl in the tribe and being rejected, she’d tell the other girls about it—not only would he have blown his chance with that girl, but he might never have a mate at all now because every girl that would ever be in his life knew about his lame, failed attempt. Being socially accepted was &lt;em&gt;everything&lt;/em&gt;.&lt;/p&gt; &lt;p&gt;Because of this, humans evolved an over-the-top obsession with what others thought of them—a craving for social approval and admiration, and a paralyzing fear of being disliked. Let’s call that obsession a human’s Social Survival Mammoth. It looks something like this:&lt;/p&gt; &lt;p&gt;&lt;a rel="noopener" href="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/Mammoth1.png"&gt;&lt;img sizes="(max-width: 521px) 100vw, 521px" srcset="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/Mammoth1.png 800w, https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/Mammoth1-300x263.png 300w, https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/Mammoth1-600x525.png 600w" height="456" width="521" alt="Mammoth" src="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/Mammoth1.png" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Your Great&lt;sup&gt;2,000&lt;/sup&gt; Grandfather’s Social Survival Mammoth was central to his ability to endure and thrive. It was simple—keep the mammoth well fed with social approval and pay close attention to its overwhelming fears of nonacceptance, and you’ll be fine.&lt;/p&gt; &lt;p&gt;And that was all well and fine in 50,000BC. And 30,000BC. And 10,000BC. But something funny has happened for humans in the last 10,000 years—their civilization has &lt;em&gt;dramatically&lt;/em&gt; changed. Sudden, quick change is something civilization has the ability to do, and the reason that can be awkward is that our evolutionary biology can’t move nearly as fast. So while for most of history, both our social structure and our biology evolved and adjusted at a snail’s pace together, civilization has recently developed the speed capabilities of a hare while our biology has continued snailing along.&lt;/p&gt; &lt;p&gt;Our bodies and minds are built to live in a tribe in 50,000BC, which leaves modern humans with a number of unfortunate traits, one of which is a fixation with tribal-style social survival in a world where social survival is no longer a real concept. We’re all here in 2014, accompanied by a large, hungry, and easily freaked-out woolly mammoth who still thinks it’s 50,000BC.&lt;/p&gt; &lt;p&gt;Why else would you try on four outfits and still not be sure what to wear before going out?&lt;/p&gt; &lt;p&gt;&lt;a href="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/4-shirts-1.png"&gt;&lt;img height="367" width="533" alt="Trying on Shirts" src="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/4-shirts-1-1024x705.png" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/4-shirts-2.png"&gt;&lt;img height="366" width="533" alt="Trying on Shirts" src="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/4-shirts-2-1024x703.png" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/4-shirts-3.png"&gt;&lt;img height="361" width="533" alt="Trying on Shirts" src="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/4-shirts-3-1024x694.png" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/4-shirts-4.png"&gt;&lt;img height="382" width="533" alt="Trying on Shirts" src="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/4-shirts-4-1024x733.png" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;The mammoth’s nightmares about romantic rejection made your ancestors cautious and savvy, but in today’s world, it just makes you a coward:&lt;/p&gt; &lt;p&gt;&lt;a href="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/ask-girl-1.png"&gt;&lt;img height="314" width="460" alt="Pursuing a Girl" src="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/ask-girl-1-1024x699.png" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/ask-girl-2.png"&gt;&lt;img height="356" width="460" alt="Pursuing a Girl" src="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/ask-girl-2-1024x791.png" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/ask-girl-3.png"&gt;&lt;img height="353" width="460" alt="Pursuing a Girl" src="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/ask-girl-3-1024x785.png" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/ask-girl-4.png"&gt;&lt;img height="353" width="460" alt="Pursuing a Girl" src="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/ask-girl-4-1024x785.png" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/ask-girl-5.png"&gt;&lt;img height="343" width="460" alt="Pursuing a Girl" src="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/ask-girl-5-1024x763.png" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;And don’t even get the mammoth started on the terror of artistic risks:&lt;/p&gt; &lt;p&gt;&lt;a href="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/singing-1.png"&gt;&lt;img height="370" width="483" alt="Karaoke" src="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/singing-1-1024x785.png" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/singing-21.png"&gt;&lt;img height="386" width="483" alt="singing 2" src="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/singing-21-1024x819.png" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;The mammoth’s hurricane of fear of social disapproval plays a factor in most parts of most people’s lives. It’s what makes you feel weird about going to a restaurant or a movie alone; it’s what makes parents care a little &lt;em&gt;too &lt;/em&gt;much about where their child goes to college; it’s what makes you pass up a career you’d love in favor of a more lucrative career you’re lukewarm about; it’s what makes you get married before you’re ready to a person you’re not in love with.&lt;/p&gt; &lt;p&gt;And while keeping your highly insecure Social Survival Mammoth feeling calm and safe takes a lot of work, that’s only one half of your responsibilities. The mammoth also needs to be fed regularly and robustly—with praise, approval, and the feeling of being on the right side of any social or moral dichotomy.&lt;/p&gt; &lt;p&gt;Why else would you be such an &lt;a rel="noopener" href="https://waitbutwhy.com/2013/07/7-ways-to-be-insufferable-on-facebook.html"&gt;image-crafting douchebag&lt;/a&gt; on Facebook?&lt;/p&gt; &lt;p&gt;Or brag when you’re out with friends even though you always regret it later?&lt;/p&gt; &lt;p&gt;&lt;a href="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/brag.png"&gt;&lt;img height="456" width="311" alt="Brag" src="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/brag-700x1024.png" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Society has evolved to accommodate this mammoth-feeding frenzy, inventing things like accolades and titles and the concept of prestige in order to keep our mammoths satisfied—and often to incentivize people to do meaningless jobs and live unfulfilling lives they wouldn’t otherwise consider taking part in.&lt;/p&gt; &lt;p&gt;Above all, mammoths want to fit in—that’s what tribespeople had always needed to do so that’s how they’re programmed. Mammoths look around at society to figure out what they’re supposed to do, and when it becomes clear, they jump right in. Just look at any two college fraternity pictures taken ten years apart:&lt;/p&gt; &lt;p&gt;&lt;a href="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/frat1.png"&gt;&lt;img height="275" width="636" alt="frat" src="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/frat1-1024x443.png" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Or all those subcultures where &lt;em&gt;every single person&lt;/em&gt; has one of the same three socially-acceptable advanced degrees:&lt;/p&gt; &lt;p&gt;&lt;a href="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/diploma-1.png"&gt;&lt;img height="279" width="397" alt="Diploma" src="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/diploma-1-1024x720.png" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/diploma-2.png"&gt;&lt;img height="303" width="397" alt="Diploma" src="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/diploma-2-1024x780.png" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Sometimes, a mammoth’s focus isn’t on wider society as much as it’s on winning the approval of a Puppet Master in your life. A Puppet Master is a person or group of people whose opinion matters &lt;em&gt;so &lt;/em&gt;much to you that they’re essentially running your life. A Puppet Master is often a parent, or maybe your significant other, or sometimes an alpha member of your group of friends. A Puppet Master can be a person you look up to who you don’t know very well—maybe even a celebrity you’ve never met—or a group of people you hold in especially high regard.&lt;/p&gt; &lt;p&gt;We crave the Puppet Master’s approval more than anyone’s, and we’re so horrified at the thought of upsetting the Puppet Master or feeling their nonacceptance or ridicule that we’ll do anything to avoid it. When we get to this toxic state in our relationship with a Puppet Master, that person’s presence hangs over our entire decision-making process and pulls the strings of our opinions and our moral voice.&lt;/p&gt; &lt;p&gt;&lt;a href="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/puppet-master.png"&gt;&lt;img height="390" width="509" alt="puppet master" src="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/puppet-master-1024x785.png" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;With so much thought and energy dedicated to the mammoth’s needs, you often end up neglecting someone else in your brain, someone all the way at the center—your Authentic Voice.&lt;/p&gt; &lt;p&gt;&lt;a href="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/AV.png"&gt;&lt;img height="347" width="570" alt="AV" src="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/AV-1024x623.png" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Your Authentic Voice, somewhere in there, knows all about you. In contrast to the black-and-white simplicity of the Social Survival Mammoth, your Authentic Voice is complex, sometimes hazy, constantly evolving, and unafraid. Your AV has its own, nuanced moral code, formed by experience, reflection, and its own personal take on compassion and integrity. It knows how you feel deep down about things like money and family and marriage, and it knows which kinds of people, topics of interest, and types of activities you truly enjoy, and which you don’t. Your AV knows that it &lt;em&gt;doesn’t&lt;/em&gt; know how your life will or should play out, but it tends to have a strong hunch about the right step to take next.&lt;/p&gt; &lt;p&gt;And while the mammoth looks only to the outside world in its decision-making process, your Authentic Voice uses the outside world to learn and gather information, but when it’s time for a decision, it has all the tools it needs right there in the core of your brain.&lt;/p&gt; &lt;p&gt;Your AV is also someone the mammoth tends to ignore entirely. A strong opinion from a confident person in the outside world? The mammoth is all ears. But a passionate plea from your AV is largely dismissed until someone else validates it.&lt;/p&gt; &lt;p&gt;And since our 50,000-year-old brains are wired to give the mammoth a whole lot of sway in things, your Authentic Voice starts to feel like it’s irrelevant. Which makes it shrink and fade and lose motivation.&lt;/p&gt; &lt;p&gt;&lt;a href="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/AV-small.png"&gt;&lt;img height="347" width="570" alt="AV" src="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/AV-small-1024x623.png" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Eventually, a mammoth-run person can lose touch with their AV entirely.&lt;/p&gt; &lt;p&gt;In tribal times, AVs often spent their lives in quiet obscurity, and this was largely okay. Life was simple, and conformity was the goal—and the mammoth had conformity covered just fine.&lt;/p&gt; &lt;p&gt;But in today’s large, complex world of varying cultures and personalities and opportunities and options, losing touch with your AV is dangerous. When you don’t know who you are, the only decision-making mechanism you’re left with is the crude and outdated needs and emotions of your mammoth. When it comes to the most personal questions, instead of digging deep into the foggy center of what you really believe in to find clarity, you’ll look to others for the answers. Who you are becomes some blend of the strongest opinions around you.&lt;/p&gt; &lt;p&gt;Losing touch with your AV also makes you fragile, because when your identity is built on the approval of others, being criticized or rejected by others &lt;em&gt;really &lt;/em&gt;hurts. A bad break-up is painful for everyone, but it stings in a much deeper place for a mammoth-run person than for a person with a strong AV. A strong AV makes a stable core, and after a break-up, that core is still holding firm—but since the acceptance of others is all a mammoth-run person has, being dumped by a person who knows you well is a far more shattering experience.&lt;/p&gt; &lt;p&gt;Likewise, you know those people who react to being criticized by coming back with a nasty low-blow? Those tend to be severely mammoth-run people, and criticism makes them so mad because mammoths cannot handle criticism.&lt;/p&gt; &lt;p&gt;&lt;a href="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/low-blow-1.png"&gt;&lt;img height="356" width="464" alt="Low Blow" src="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/low-blow-1-1024x785.png" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/low-blow-2.png"&gt;&lt;img height="302" width="464" alt="Low Blow" src="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/low-blow-2-1024x666.png" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/low-blow-3.png"&gt;&lt;img height="302" width="464" alt="Low Blow" src="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/low-blow-3-1024x666.png" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/low-blow-4.png"&gt;&lt;img height="281" width="464" alt="Low Blow" src="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/low-blow-4-1024x620.png" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;At this point, the mission should be clear—we need to figure out a way to override the wiring of our brain and tame the mammoth. That’s the only way to take our lives back.&lt;/p&gt; &lt;p&gt;&lt;span&gt;&lt;strong&gt;Part 2: Taming the Mammoth&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;Some people are born with a reasonably tame mammoth or raised with parenting that helps keep the mammoth in check. Others die without ever reining their mammoth in at all, spending their whole lives at its whim. Most of us are somewhere in the middle—we’ve got control of our mammoth in certain areas of our lives while it wreaks havoc in others. Being run by your mammoth doesn’t make you a bad or weak person—it just means you haven’t yet figured out how to get a grip on it. You might not even be aware that you have a mammoth at all or of the extent to which your Authentic Voice has been silenced.&lt;/p&gt; &lt;p&gt;Whatever your situation, there are three steps to getting your mammoth under your control:&lt;/p&gt; &lt;p&gt;&lt;span&gt;&lt;strong&gt;Step 1: Examine Yourself&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;The first step to improving things is a clear and honest assessment of what’s going on in your head, and there are three parts of this:&lt;/p&gt; &lt;p&gt;&lt;span&gt;&lt;strong&gt;1) Get to know your Authentic Voice&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/meet-AV1.png"&gt;&lt;img sizes="(max-width: 235px) 100vw, 235px" srcset="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/meet-AV1.png 368w, https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/meet-AV1-249x300.png 249w" height="284" width="235" alt="meet AV" src="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/meet-AV1.png" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;This doesn’t sound that hard, but it is. It takes some serious reflection to sift through the webs of other people’s thoughts and opinions and figure out who the real you actually is. You spend time with a lot of people—which of them do you actually like the most? How do you spend your leisure time, and do you truly enjoy all parts of it? Is there anything you regularly spend money on that you don’t feel that comfortable with? How does your gut really feel about your job and relationship status? What’s your true political opinion? Do you even care? Do you pretend to care about things you don’t just to have an opinion? Do you secretly have an opinion on a political or moral issue you don’t ever voice because people you know will be outraged?&lt;/p&gt; &lt;p&gt;There are cliché phrases for this process—”soul-searching” or “finding yourself”—but that’s exactly what needs to happen. Maybe you can reflect on this from whatever chair you’re sitting in right now or from some other part of your normal life—or maybe you need to go somewhere far away, by yourself, and step out of your life in order to effectively examine it. Either way, you’ve got to figure out what &lt;em&gt;actually&lt;/em&gt; matters to you and start being proud of whoever your Authentic Voice is.&lt;/p&gt; &lt;p&gt;&lt;span&gt;&lt;strong&gt;2) Figure out where the mammoth is hiding&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/mammoth-hiding.png"&gt;&lt;img height="375" width="489" alt="mammoth hiding" src="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/mammoth-hiding-1024x785.png" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Most of the time a mammoth is in control of a person, the person’s not really aware of it. But you can’t make progress if you’re not crystal clear about where the biggest problem areas are.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;The most obvious way to find the mammoth is to figure out where your fear is&lt;/strong&gt;—where are you most susceptible to shame or embarrassment? What parts of your life do you think about and a dreadful, sinking feeling washes over you? Where does the prospect of failure seem like a nightmare? What are you too timid to publicly try even though you know you’re good at it? If you were giving advice to yourself, which parts of your life would clearly need a change that you’re avoiding acting on right now?&lt;/p&gt; &lt;p&gt;&lt;strong&gt;The second place a mammoth hides is in the way-too-good feelings you get from feeling accepted or on a pedestal over other people.&lt;/strong&gt; Are you a serious &lt;em&gt;pleaser &lt;/em&gt;at work or in your relationship? Are you terrified of disappointing your parents and do you choose making them proud over aiming to gratify yourself? Do you get too excited about being associated with prestigious things or care too much about status? Do you brag more than you should?&lt;/p&gt; &lt;p&gt;&lt;strong&gt;A third area the mammoth is present is anywhere you don’t feel comfortable making a decision without “permission” or approval from others.&lt;/strong&gt; Do you have opinions you’re regurgitating from someone else’s mouth, which you’re comfortable having now that you know that person has them? When you introduce your new girlfriend or boyfriend to your friends or family for the first time, can those people’s reaction to your new person fundamentally change your feelings for him/her? Is there a Puppet Master in your life? If so, who, and why?&lt;/p&gt; &lt;p&gt;&lt;span&gt;&lt;strong&gt;3) Decide where the mammoth needs to be ousted&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/ousted1.png"&gt;&lt;img height="536" width="504" alt="ousted" src="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/ousted1-962x1024.png" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;It’s not realistic to kick the mammoth entirely out of your head—you’re a human and humans have mammoths in their head, period. The thing we all need to do is carve out certain sacred areas of our lives that &lt;em&gt;must &lt;/em&gt;be in the hands of the AV and free of mammoth influence. There are obvious areas that need to be made part of the AV’s domain like your choice of life partner, your career path, and the way you raise your kids. Others are personal—it comes down to the question, “In which parts of your life must you be entirely true to yourself?”&lt;/p&gt; &lt;p&gt;&lt;span&gt;&lt;strong&gt;Step 2: Gather Courage by Internalizing That the Mammoth Has a Low IQ&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;Real Woolly Mammoths were unimpressive enough to go extinct, and Social Survival Mammoths aren’t any better. Despite the fact that they haunt us so, our mammoths are dumb, primitive creatures who have no understanding of the modern world. Deeply understanding this—and &lt;em&gt;internalizing&lt;/em&gt; it—is a key step to taming yours. There are two major reasons not to take your mammoth seriously:&lt;/p&gt; &lt;p&gt;&lt;span&gt;&lt;b&gt;1) The mammoth’s fears are totally irrational.&lt;/b&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;5 things the Mammoth is incorrect about:&lt;/p&gt; &lt;p&gt;&lt;span&gt;→ &lt;/span&gt;&lt;span&gt;&lt;b&gt;Everyone is talking about me and my life and just think how much everyone will be talking about it if I do this risky or weird thing.&lt;/b&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;Here’s how the mammoth thinks things are:&lt;/p&gt; &lt;p&gt;&lt;a href="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/circles.png"&gt;&lt;img sizes="(max-width: 482px) 100vw, 482px" srcset="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/circles.png 935w, https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/circles-300x288.png 300w, https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/circles-600x576.png 600w" height="463" width="482" alt="circles" src="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/circles.png" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Here’s how things actually are:&lt;/p&gt; &lt;p&gt;&lt;a href="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/circles-2.png"&gt;&lt;img height="370" width="482" alt="Circle" src="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/circles-2-1024x785.png" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;No one really cares that much about what you’re doing. People are highly self-absorbed.&lt;/p&gt; &lt;p&gt;&lt;span&gt;→ &lt;/span&gt;&lt;span&gt;&lt;b&gt;If I try really hard, I can please everyone.&lt;/b&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;Yes, maybe in a 40-person tribe with a unified culture. But in today’s world, no matter who you are, a bunch of people will like you and a bunch of other people won’t. Being approved of by one type of person means turning another off. So obsessing over fitting in with any one group is illogical, especially if that group isn’t really who you are. You’ll do all that work, and meanwhile, your actual favorite people are off being friends with each other somewhere else.&lt;/p&gt; &lt;p&gt;&lt;span&gt;→ &lt;/span&gt;&lt;span&gt;&lt;b&gt;Being disapproved of or looked down upon or shit-talked about has real consequences in my life.&lt;/b&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;Anyone who disapproves of who you’re being or what you’re doing isn’t even in the same room with you 99.7% of the time. It’s a classic mammoth mistake to fabricate a vision of future social consequences that is &lt;em&gt;way &lt;/em&gt;worse than what actually ends up happening—which is usually nothing at all.&lt;/p&gt; &lt;p&gt;&lt;span&gt;→ &lt;/span&gt;&lt;span&gt;&lt;b&gt;Really judgy people matter.&lt;/b&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;Here’s how judgy people function: They’re highly mammoth-controlled and become good friends with and date other judgy people who are also highly mammoth-controlled. One of the primary activities they do together is talk shit about whoever’s not with them—maybe they feel some jealousy, and eye-rolling disapproval helps them flip the script and feel less jealous, or maybe they’re not jealous and use someone as a vehicle for bathing in &lt;a rel="noopener" href="http://en.wikipedia.org/wiki/Schadenfreude"&gt;schadenfreude&lt;/a&gt;—but whatever the underlying feeling, the judging serves to feed their hungry mammoth.&lt;/p&gt; &lt;p&gt;&lt;a href="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/eating-words-1.png"&gt;&lt;img height="422" width="550" alt="eating words 1" src="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/eating-words-1-1024x785.png" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/eating-words-2.png"&gt;&lt;img height="422" width="550" alt="eating words 2" src="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/eating-words-2-1024x785.png" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/eating-words-3.png"&gt;&lt;img height="382" width="550" alt="eating words 3" src="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/eating-words-3-1024x710.png" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;When people shit-talk, they set up a category division of which they’re always on the right side. They do this to prop themselves up on a pedestal that their mammoth can chomp away on.&lt;/p&gt; &lt;p&gt;Being the material a judgy person uses to feel good about themselves is a fairly infuriating thought—but it has no actual consequences and it’s clearly all much more about the judgy person and their mammoth problem than it is about you. If you find yourself making decisions partially based on not being talked badly about by a judgy person, think hard about what’s actually going on and stop.&lt;/p&gt; &lt;p&gt;&lt;span&gt;→ &lt;/span&gt;&lt;span&gt;&lt;b&gt;I’m a bad person if I disappoint or offend the person/people who love me and have invested so much in me.&lt;/b&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;No. You’re not a bad person for being whoever your Authentic Voice is in your one life. This is one of those simple things—if they truly selflessly love you, they will for sure come around and accept everything once they see that you’re happy. If you’re happy and they still don’t come around, here’s what’s happening: their strong feelings about who you should be or what you should do are &lt;em&gt;their mammoth talking&lt;/em&gt;, and their main motivation is worrying about how it’ll “look” to other people who know them. They’re allowing their mammoth to override their love for you, and they should be adamantly ignored.&lt;/p&gt; &lt;p&gt;Two other reasons why the mammoth’s fearful obsession with social approval makes no sense:&lt;/p&gt; &lt;p&gt;&lt;span&gt;&lt;b&gt;A) You live here:&lt;/b&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/Earth.png"&gt;&lt;img height="436" width="569" alt="Earth" src="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/Earth-1024x785.png" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;So who gives a fuck about anything?&lt;/p&gt; &lt;p&gt;&lt;span&gt;&lt;b&gt;B) You and everyone you know are going to die. Kind of soon.&lt;/b&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/die.png"&gt;&lt;img height="312" width="570" alt="die" src="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/die-1024x561.png" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;So like…yeah.&lt;/p&gt; &lt;p&gt;The mammoth’s fears being irrational is one reason the mammoth has a low IQ. Here’s the second:&lt;/p&gt; &lt;p&gt;&lt;span&gt;&lt;b&gt;2) The mammoth’s efforts are counterproductive. &lt;/b&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;The irony of the whole thing is that the obsessive lumbering mammoth isn’t even good at his job. His methods of winning approval may have been effective in simpler times, but today, they’re transparent and off-putting. The modern world is an AV’s world, and if the mammoth wants to thrive socially, he should do the thing that scares him most—let the AV take over. Here’s why:&lt;/p&gt; &lt;p&gt;&lt;strong&gt;AVs are interesting. Mammoths are boring. &lt;/strong&gt;Every AV is unique and complex, which is inherently interesting. Mammoths are all the same—they copy and conform, and their motives aren’t based on anything authentic or real, just on doing what they think they’re supposed to do. That’s supremely boring.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;AVs lead. Mammoths follow. &lt;/strong&gt;Leadership is natural for most AVs, because they draw their thoughts and opinions from an original place, which gives them an original angle. And if they’re smart and innovative enough, they can change things in the world and invent things that disrupt the status quo. If you give someone a paintbrush and an empty canvas, they might not paint something good—but they’ll change the canvas in one way or another.&lt;/p&gt; &lt;p&gt;Mammoths, on the other hand, follow—by definition. That’s what they were built to do—blend in and follow the leader. The last thing a mammoth is going to do is change the status quo because it’s trying so hard to &lt;em&gt;be &lt;/em&gt;the status quo. When you give someone a paintbrush and canvas, but the paint is the same exact color as the canvas, they can paint all they want, but they won’t change anything.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;People gravitate toward AVs, not mammoths. &lt;/strong&gt;The only time a mammoth-crazed person is appealing on a first date is when they’re on the date with another mammoth-crazed person. People with a strong AV see through mammoth-controlled people and aren’t attracted to them. A friend of mine was dating a great on-paper guy awhile back but broke things off because she couldn’t quite fall for him. She tried to articulate why, saying he wasn’t weird or special enough—he seemed like “just one of the guys.” In other words, he was being run too much by a mammoth.&lt;/p&gt; &lt;p&gt;This also holds among friends or colleagues, where AV-run people are more respected and more magnetic—not because there’s necessarily anything extraordinary about them, but because &lt;em&gt;people respect someone with the strength of character to have tamed their mammoth. &lt;/em&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;&lt;strong&gt;Step 3: Start Being Yourself&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;This post was all fun and games until “start being yourself” came into the picture. Up to now, this has been an interesting reflection into why humans care so much what other people think, why that’s bad, how it’s a problem in your life, and why there’s no good reason it should continue to plague you. But actually &lt;em&gt;doing &lt;/em&gt;something after you finish reading this article is a whole different thing. That takes more than reflection—it takes some courage.&lt;/p&gt; &lt;p&gt;&lt;a href="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/toe-in-water.png"&gt;&lt;img height="357" width="610" alt="toe in water" src="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/toe-in-water-1024x599.png" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;But courage against &lt;em&gt;what, &lt;/em&gt;exactly? As we’ve discussed, there’s no actual danger involved in being yourself—more than anything, it just takes an Emperor Has No Clothes epiphany, which is as simple as this:&lt;/p&gt; &lt;p&gt;&lt;span&gt;&lt;strong&gt;Almost nothing you’re socially scared of is actually scary.&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;Absorbing this thought will diminish the fear that you feel, and without fear, the mammoth loses some power.&lt;/p&gt; &lt;p&gt;&lt;a href="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/medium-mammoth1.png"&gt;&lt;img sizes="(max-width: 467px) 100vw, 467px" srcset="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/medium-mammoth1.png 1022w, https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/medium-mammoth1-300x241.png 300w, https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/medium-mammoth1-600x483.png 600w" height="376" width="467" alt="medium mammoth" src="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/medium-mammoth1.png" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;With a weakened mammoth, it becomes possible to begin standing up for who you are and even making some bold changes—and when you watch those changes turn out well for you with few negative consequences and no regrets, it reinforces the epiphany and an empowered AV becomes a habit. Your mammoth has now lost its ability to pull the strings, and it’s tamed.&lt;/p&gt; &lt;p&gt;&lt;a href="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/small-mammoth.png"&gt;&lt;img sizes="(max-width: 290px) 100vw, 290px" srcset="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/small-mammoth.png 349w, https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/small-mammoth-189x300.png 189w" height="460" width="290" alt="small mammoth" src="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/small-mammoth.png" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;The mammoth is still with you—it’ll always be with you—but you’ll have an easier time ignoring or overruling it when it speaks up or acts out, because the AV is the alpha dog now. You can start to relish the feeling of being viewed as weird or inappropriate or confusing to people, and society becomes your playground and blank canvas, not something to grovel before and hope for acceptance from.&lt;/p&gt; &lt;p&gt;Making this shift isn’t easy for anyone, but it’s worth obsessing over. Your Authentic Voice has been given one life—and it’s your job to make sure it gets the opportunity to live it.&lt;/p&gt; &lt;p&gt;_________&lt;/p&gt; &lt;p&gt;If you’re into Wait But Why, sign up for the &lt;strong&gt;&lt;a rel="noopener" href="http://eepurl.com/Ffj9D"&gt;Wait But Why email list&lt;/a&gt;&lt;/strong&gt; and we’ll send you the new posts right when they come out. It’s a very unannoying list, don’t worry.&lt;/p&gt; &lt;p&gt;If you’d like to support Wait But Why, &lt;strong&gt;&lt;a rel="noopener" href="https://www.patreon.com/waitbutwhy"&gt;here’s our Patreon&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;You can &lt;strong&gt;&lt;a href="https://gum.co/wbw-mammoth"&gt;buy the PDF of this post&lt;/a&gt; &lt;/strong&gt;for offline sharing, or get your own Social Survival Mammoth &lt;strong&gt;&lt;a href="https://store.waitbutwhy.com/collections/plush-toys/products/the-mammoth-plush-toy?variant=19704079361"&gt;here&lt;/a&gt;&lt;/strong&gt;:&lt;/p&gt; &lt;p&gt;&lt;a href="https://store.waitbutwhy.com/collections/plush-toys/products/the-mammoth-plush-toy?variant=19704079361"&gt;&lt;img sizes="(max-width: 300px) 100vw, 300px" srcset="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/wbw-mammoth-plushie-01-300x300.jpg 300w, https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/wbw-mammoth-plushie-01-150x150.jpg 150w, https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/wbw-mammoth-plushie-01-600x600.jpg 600w, https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/wbw-mammoth-plushie-01.jpg 651w" height="300" width="300" alt="WBW mammoth plush toy" src="https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2014/06/wbw-mammoth-plushie-01-300x300.jpg" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;_________&lt;/p&gt; &lt;p&gt;&lt;strong&gt;&lt;span&gt;More on life and happiness from Wait But Why&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;A different struggle going on in another part of your brain – &lt;a href="https://waitbutwhy.com/2013/10/why-procrastinators-procrastinate.html"&gt;Why Procrastinators Procrastinate&lt;/a&gt;&lt;/p&gt; &lt;p&gt;The thing I learned from Elon Musk that changed the way I think about my life: &lt;a href="https://waitbutwhy.com/2015/11/the-cook-and-the-chef-musks-secret-sauce.html"&gt;The Cook and the Chef: Musk’s Secret Sauce&lt;/a&gt;&lt;/p&gt; &lt;p&gt;A deeper look at the deal with the mammoth and the other animals in your brain. A post that ties it all together – &lt;a href="https://waitbutwhy.com/2014/10/religion-for-the-nonreligious.html"&gt;A Religion for the Nonreligious&lt;/a&gt;&lt;/p&gt; &lt;p&gt;To be happy, you have to know where happiness lives – &lt;a href="https://waitbutwhy.com/2013/11/life-is-picture-but-you-live-in-pixel.html"&gt;Life is a Picture but You Live in a Pixel&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Mammoths are not good at picking life partners – &lt;a href="https://waitbutwhy.com/2014/02/pick-life-partner.html"&gt;How to Pick Your Life Partner&lt;/a&gt;&lt;/p&gt; &lt;p&gt;You don’t have that many weeks, unfortunately. Make them count. &lt;a href="https://waitbutwhy.com/2014/05/life-weeks.html"&gt;Your Life in Weeks&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;/article&gt;&lt;/div&gt;&lt;a href="https://waitbutwhy.com/2014/06/taming-mammoth-let-peoples-opinions-run-life.html"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Sun, 7 Feb 2021 23:42:01 UT
      </pubDate>
      <guid>
        https://waitbutwhy.com/2014/06/taming-mammoth-let-peoples-opinions-run-life.html
      </guid>
    </item>
    <item>
      <title>
        The days are long but the decades are short - Sam Altman
      </title>
      <link>
        https://blog.samaltman.com/the-days-are-long-but-the-decades-are-short
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt;&lt;div id="post_body_848362"&gt;&lt;p&gt;&lt;i&gt;﻿I turned 30 last week and a friend asked me if I'd figured out any life advice in the past decade worth passing on. &amp;nbsp;I'm somewhat hesitant to publish this because I think these lists usually seem hollow, but here is a cleaned up&amp;nbsp;version of my answer:&lt;/i&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;1)&amp;nbsp;Never put your family, friends, or significant other low on your priority list.&amp;nbsp; Prefer a handful of truly close friends to a hundred acquaintances.&amp;nbsp; Don’t lose touch with old friends.&amp;nbsp; Occasionally stay up until the sun rises talking to people.&amp;nbsp; Have parties.&lt;br&gt;&lt;/p&gt;&lt;p&gt;2)&amp;nbsp;Life is not a dress rehearsal—this is probably it.&amp;nbsp; Make it count.&amp;nbsp; Time is extremely limited and goes by fast.&amp;nbsp; Do what makes you happy and fulfilled—few people get remembered hundreds of years after they die anyway.&amp;nbsp; Don’t do stuff that doesn’t make you happy (this happens most often when other people want you to do something).&amp;nbsp; Don’t spend time trying to maintain relationships with people you don’t like, and cut negative people out of your life.&amp;nbsp; Negativity is really bad.&amp;nbsp; Don’t let yourself make excuses for not doing the things you want to do.&lt;/p&gt;&lt;p&gt;3)&amp;nbsp;How to succeed: pick the right thing to do (this is critical and usually ignored), focus, believe in yourself (especially when others tell you it’s not going to work), develop personal connections with people that will help you, learn to identify talented people, and work hard.&amp;nbsp; It’s hard to identify what to work on because original thought is hard.&lt;/p&gt;&lt;p&gt;4)&amp;nbsp;On work: it’s difficult to do a great job on work you don’t care about.&amp;nbsp; And it’s hard to be totally happy/fulfilled in life if you don’t like what you do for your work.&amp;nbsp; Work very hard—a surprising number of people will be offended that you choose to work hard—but not so hard that the rest of your life passes you by.&amp;nbsp; Aim to be the best in the world at whatever you do professionally.&amp;nbsp; Even if you miss, you’ll probably end up in a pretty good place.&amp;nbsp; Figure out your own productivity system—don’t waste time being unorganized, working at suboptimal times, etc.&amp;nbsp; Don’t be afraid to take some career risks, especially early on.&amp;nbsp; Most people pick their career fairly randomly—really think hard about what you like, what fields are going to be successful, and try to talk to people in those fields.&lt;/p&gt;&lt;p&gt;5)&amp;nbsp;On money: Whether or not money can buy happiness, it can buy freedom, and that’s a big deal.&amp;nbsp; Also, lack of money is very stressful.&amp;nbsp; In almost all ways, having enough money so that you don’t stress about paying rent does more to change your wellbeing than having enough money to buy your own jet.&amp;nbsp; Making money is often more fun than spending it, though I personally have never regretted money I’ve spent on friends, new experiences, saving time, travel, and causes I believe in.&lt;/p&gt;&lt;p&gt;6)&amp;nbsp;Talk to people more.&amp;nbsp; Read more long content and less tweets.&amp;nbsp; Watch less TV.&amp;nbsp; Spend less time on the Internet.&lt;/p&gt;&lt;p&gt;7)&amp;nbsp;Don’t waste time.&amp;nbsp; Most people waste most of their time, especially in business.&lt;/p&gt;&lt;p&gt;8)&amp;nbsp;Don’t let yourself get pushed around.&amp;nbsp; As Paul Graham once said to me, “People can become formidable, but it’s hard to predict who”.&amp;nbsp; (There is a big difference between confident and arrogant.&amp;nbsp; Aim for the former, obviously.)&lt;/p&gt;&lt;p&gt;9)&amp;nbsp;Have clear goals for yourself every day, every year, and every decade.&amp;nbsp;&lt;/p&gt;&lt;p&gt;10)&amp;nbsp;However, as valuable as planning is, if a great opportunity comes along you should take it.&amp;nbsp; Don’t be afraid to do something slightly reckless.&amp;nbsp; One of the benefits of working hard is that good opportunities will come along, but it’s still up to you to jump on them when they do.&lt;/p&gt;&lt;p&gt;11)&amp;nbsp;Go out of your way to be around smart, interesting, ambitious people.&amp;nbsp; Work for them and hire them (in fact, one of the most satisfying parts of work is forging deep relationships with really good people).&amp;nbsp; Try to spend time with people who are either among the best in the world at what they do or extremely promising but totally unknown.&amp;nbsp; It really is true that you become an average of the people you spend the most time with.&lt;/p&gt;&lt;p&gt;12)&amp;nbsp;Minimize your own cognitive load from distracting things that don’t really matter.&amp;nbsp; It’s hard to overstate how important this is, and how bad most people are at it.&amp;nbsp; Get rid of distractions in your life.&amp;nbsp; Develop very strong ways to avoid letting crap you don’t like doing pile up and take your mental cycles, especially in your work life.&lt;/p&gt;&lt;p&gt;13)&amp;nbsp;Keep your personal burn rate low.&amp;nbsp; This alone will give you a lot of opportunities in life.&lt;/p&gt;&lt;p&gt;14)&amp;nbsp;Summers are the best.&lt;/p&gt;&lt;p&gt;15)&amp;nbsp;Don’t worry so much.&amp;nbsp; Things in life are rarely as risky as they seem. &amp;nbsp;Most people are too risk-averse, and so most advice is biased too much towards conservative paths.&lt;/p&gt;&lt;p&gt;16)&amp;nbsp;Ask for what you want.&amp;nbsp;&amp;nbsp;&lt;/p&gt;&lt;p&gt;17)&amp;nbsp;If you think you’re going to regret not doing something, you should probably do it.&amp;nbsp; Regret is the worst, and most people regret far more things they didn’t do than things they did do.&amp;nbsp; When in doubt, kiss the boy/girl.&lt;/p&gt;&lt;p&gt;18)&amp;nbsp;Exercise.&amp;nbsp; Eat well.&amp;nbsp; Sleep.&amp;nbsp; Get out into nature with some regularity.&lt;/p&gt;&lt;p&gt;19)&amp;nbsp;Go out of your way to help people.&amp;nbsp; Few things in life are as satisfying.&amp;nbsp; Be nice to strangers.&amp;nbsp; Be nice even when it doesn’t matter.&lt;/p&gt;&lt;p&gt;20) Youth&amp;nbsp;is a really great thing.&amp;nbsp; Don’t waste it.&amp;nbsp; In fact, in your 20s, I think it’s ok to take a “Give me financial discipline, but not just yet” attitude.&amp;nbsp; All the money in the world will never get back time that passed you by.&lt;/p&gt;&lt;p&gt;21)&amp;nbsp;Tell your parents you love them more often.&amp;nbsp; Go home and visit as often as you can.&lt;/p&gt;&lt;p&gt;22)&amp;nbsp;This too shall pass.&lt;/p&gt;&lt;p&gt;23)&amp;nbsp;Learn voraciously.&amp;nbsp;&lt;/p&gt;&lt;p&gt;24)&amp;nbsp;Do new things often.&amp;nbsp; This seems to be really important.&amp;nbsp; Not only does doing new things seem to slow down the perception of time, increase happiness, and keep life interesting, but it seems to prevent people from calcifying in the ways that they think.&amp;nbsp; Aim to do something big, new, and risky every year in your personal and professional life.&lt;/p&gt;&lt;p&gt;25)&amp;nbsp;Remember how intensely you loved your boyfriend/girlfriend when you were a teenager?&amp;nbsp; Love him/her that intensely now.&amp;nbsp; Remember how excited and happy you got about stuff as a kid?&amp;nbsp; Get that excited and happy now.&lt;/p&gt;&lt;p&gt;26)&amp;nbsp;Don’t screw people and don’t burn bridges.&amp;nbsp; Pick your battles carefully.&lt;/p&gt;&lt;p&gt;27)&amp;nbsp;Forgive people.&amp;nbsp;&lt;/p&gt;&lt;p&gt;28)&amp;nbsp;Don’t chase status.&amp;nbsp; Status without substance doesn’t work for long and is unfulfilling.&lt;/p&gt;&lt;p&gt;29)&amp;nbsp;Most things are ok in moderation.&amp;nbsp; Almost nothing is ok in extreme amounts.&lt;/p&gt;&lt;p&gt;30)&amp;nbsp;Existential angst is part of life.&amp;nbsp; It is particularly noticeable around major life events or just after major career milestones.&amp;nbsp; It seems to particularly affect smart, ambitious people.&amp;nbsp; I think one of the reasons some people work so hard is so they don’t have to spend too much time thinking about this.&amp;nbsp; Nothing is wrong with you for feeling this way; you are not alone.&lt;/p&gt;&lt;p&gt;31)&amp;nbsp;Be grateful and keep problems in perspective.&amp;nbsp; Don’t complain too much.&amp;nbsp; Don’t hate other people’s success (but remember that some people will hate your success, and you have to learn to ignore it).&amp;nbsp;&lt;/p&gt;&lt;p&gt;32)&amp;nbsp;Be a doer, not a talker.&lt;/p&gt;&lt;p&gt;33)&amp;nbsp;Given enough time, it is possible to adjust to almost anything, good or bad.&amp;nbsp; Humans are remarkable at this.&lt;/p&gt;&lt;p&gt;34)&amp;nbsp;Think for a few seconds before you act.&amp;nbsp; Think for a few minutes if you’re angry.&lt;/p&gt;&lt;p&gt;35)&amp;nbsp;Don’t judge other people too quickly.&amp;nbsp; You never know their whole story and why they did or didn’t do something.&amp;nbsp; Be empathetic.&lt;/p&gt;&lt;p&gt;36)&amp;nbsp;The days are long but the decades are short.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;a href="https://blog.samaltman.com/the-days-are-long-but-the-decades-are-short"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Mon, 8 Feb 2021 12:13:42 UT
      </pubDate>
      <guid>
        https://blog.samaltman.com/the-days-are-long-but-the-decades-are-short
      </guid>
    </item>
    <item>
      <title>
        Lightweight Static Guarantees
      </title>
      <link>
        http://okmij.org/ftp/Computation/lightweight-static-guarantees.html
      </link>
      <description>
        &lt;div id="readability-page-1" class="page"&gt; &lt;h2&gt;Safe and Efficient, Now&lt;/h2&gt; &lt;div&gt;&lt;p&gt;We have identified (more than a decade ago, in fact) a disciplined programming style that uses &lt;em&gt;existing&lt;/em&gt; type systems in practical, mature languages (such as OCaml, Scala, Haskell, etc., and to an extent, Java and C++) to &lt;em&gt;statically&lt;/em&gt; assure a wide range of safety properties: &lt;/p&gt;&lt;ul&gt; &lt;li&gt;never dereferencing a null pointer or taking the head of an empty list; &lt;/li&gt; &lt;li&gt;always sanitizing user input; &lt;/li&gt; &lt;li&gt;using only in-bounds indices to access (dynamically allocated) arrays of the statically unknown size. &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The technique is compatible with modular development, separate compilation, imperative code, native mutable arrays, indirect indexing, and general recursion. The resulting program is not just more reliable but also more efficient, because fewer run-time checks are needed. The technique does not obviate the foundational, formal methods approach; rather, it complements and structures it. Formal methods may still be used to prove the (typically small and simple) security kernel correct. Our technique extends the static guarantees from the kernel through the whole program. &lt;/p&gt;&lt;p&gt;There are two surprises: (i) what we enumerate is even possible; (ii) that it is so old (tracing back to Morris' 1973 paper), so simple and yet so rarely used. &lt;/p&gt;&lt;/div&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="#introduction"&gt;Introduction&lt;/a&gt; &lt;/li&gt; &lt;li&gt;&lt;a href="#dirty-string"&gt;User-input sanitation and SQL injection&lt;/a&gt; &lt;/li&gt; &lt;li&gt;&lt;a href="#ADT"&gt;Abstract Types -- the language protection layer&lt;/a&gt; &lt;/li&gt; &lt;li&gt;&lt;a href="#safe-array-access"&gt;Eliminating array bound checks&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#multiple"&gt;Eliminating array bound checking in multiple arrays&lt;/a&gt; &lt;/li&gt; &lt;li&gt;&lt;a href="#KMP"&gt;Knuth-Morris-Pratt string search with safe array access&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#lsc"&gt;Lightweight static capabilities&lt;/a&gt; &lt;/li&gt; &lt;li&gt;&lt;a href="#formalization"&gt;Formalization of the abstract type protection&lt;/a&gt; &lt;/li&gt; &lt;li&gt;&lt;a href="#verification"&gt;The question of verification&lt;/a&gt; &lt;/li&gt; &lt;li&gt;&lt;a href="#range-analysis"&gt;Lightweight guarantees and static analyses&lt;/a&gt; &lt;/li&gt; &lt;li&gt;&lt;a href="#deptype"&gt;Lightweight guarantees and dependent types&lt;/a&gt; &lt;/li&gt; &lt;li&gt;&lt;a href="#conclusion"&gt;Conclusions&lt;/a&gt; &lt;/li&gt;&lt;/ul&gt; &lt;hr&gt; &lt;h2&gt;&lt;a name="introduction"&gt;Introduction&lt;/a&gt;&lt;/h2&gt; &lt;dl&gt; &lt;dd&gt;The memory of Heartbleed, a flaw in the OpenSSL library, is beginning to fade. After all, exploitable security flaws are regular occurrence. Heartbleed is still remarkable in how much effort was spent to patch it, and how trivial it was. &lt;p&gt;We should also remember how trivially it was introduced (like many other flaws of that nature). As the developer of the Heartbeat SSL feature explained, ``I was working on improving OpenSSL and submitted numerous bug fixes and added new features. In one of the new features, unfortunately, I missed validating a variable containing a length.'' A reviewer ``apparently also didn’t notice the missing validation,'' the developer said, ``so the error made its way from the development branch into the released version.'' The error remained (publicly) undetected for two years. &lt;/p&gt;&lt;p&gt;The OpenSSL patch that finally fixes the error shows how indeed trivial it was: just one statement &lt;/p&gt;&lt;pre&gt; memcpy(bp, pl, payload); &lt;/pre&gt;that copies the payload data of the size &lt;code&gt;payload&lt;/code&gt; from the input packet (starting at the pointer &lt;code&gt;pl&lt;/code&gt;) to the output packet buffer, starting at the location &lt;code&gt;bp&lt;/code&gt;. The value of &lt;code&gt;payload&lt;/code&gt; has been previously read from the input packet. The problem comes when the attacker sends a packet with the maximum value of the payload size, but with no actual payload data. In that case &lt;code&gt;memcpy&lt;/code&gt;, instead of the data from the received packet (which is already ended), copies the large amount of garbage from the openSSL input buffer. That `garbage' is actually left-over data, with often sensitive information including passwords. &lt;p&gt;What is also disturbing about Heartbleed is how trivially the error could have been avoided, if the low-level functions like &lt;code&gt;memcpy&lt;/code&gt; could not be invoked directly, but only through wrappers, which, for example, sanity check that &lt;code&gt;pl + payload&lt;/code&gt; is still within the input packet (the boundaries of input packet are readily available). The invocation restriction could be effected in any language with module/namespace abstraction facilities (C++ and beyond)&amp;nbsp;-- or even in C, when test-compiling against appropriately set up &lt;code&gt;.h&lt;/code&gt; files that omit restricted functions. The performance need not be sacrificed: the wrapper could be an inline function (or a C macro), and the length sanity check has to be done anyway. &lt;/p&gt;&lt;p&gt;Abstraction is the key word: Abstraction over internal data and functions forces the end programmer to use public APIs with safety checks. By preventing tampering with the internal state, abstraction also ensures that whatever invariant was verified by the safety checks remains valid. Therefore, the safety checks do not have to be done over and over again -- or even at all, if the needed invariant follows from the checks the algorithm had to do anyway. Hence our slogan: &lt;strong&gt;Safe and Efficient, Now&lt;/strong&gt;. &lt;/p&gt;&lt;p&gt;The basic idea behind our programming style is ubiquitous, going back to the dawn of computing: hardware protection layer, the hardware-enforced access restriction to memory and devices. The layer separates the computing system into the (trusted) kernel (which operates in the privileged mode and may execute low-level operations) and `user-level' programs, which may access devices only through public kernel APIs (system calls), which do sanity and access checks. A user program may not write onto a disk at will. Rather, it has to do an `open' system call, which, after authorization and other checks, returns an opaque token, the file descriptor. The descriptor acts as a &lt;em&gt;capability&lt;/em&gt; to do the prescribed set of operations. It also represents the fact of the successful authorization, so further operations do not have to repeat it. James Morris' 1973 paper `Protection in Programming Languages' was the first to apply to software the ideas from operating systems such as memory protection, authentication, capabilities, scope control. The paper demonstrated how the software/language protection layer helps us reason about programs locally, modularly. The abstraction facilities of programming languages became more extensive since 1973. It is high time we took the full advantage of Morris' insights. &lt;/p&gt;&lt;p&gt;We can do it right now, in existing, mature programming languages. Making sure that we: &lt;/p&gt;&lt;ul&gt; &lt;li&gt;dereference only non-null pointers; &lt;/li&gt; &lt;li&gt;divide by only non-zero denominators; &lt;/li&gt; &lt;li&gt;take the head or tail of only non-empty linked lists; &lt;/li&gt; &lt;li&gt;index into a static buffer with only in-range indices; and &lt;/li&gt; &lt;li&gt;execute SQL commands containing no unsanitized strings from external input. &lt;/li&gt;&lt;/ul&gt;can be done already in C++ and Java. We show examples below. &lt;p&gt;We can also do more. The facilities for generic programming (parametric polymorphism) or advanced module systems in modern languages let us assure more safety properties, such as safe indexing into an array whose size is known only at run-rime -- without imposing a bound check on each access. We even show assuredly buffer-overflow--free KMP string search, which is a rather complex imperative algorithm with indirect indexing. &lt;/p&gt;&lt;p&gt;Morris' old ideas do indeed work. Why don't we use them?&lt;/p&gt;&lt;/dd&gt; &lt;dt&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/dt&gt; &lt;dd&gt;``Costly error -- Heartbleed developer explains OpenSSL mistake that put Web at risk. `Trivial' coding error in open source project wasn't intentional, report says''&lt;br&gt; Jon Brodkin. Ars Technica, Apr 11, 2014 2:45 pm UTC&lt;br&gt; &amp;lt;&lt;a href="http://arstechnica.com/information-technology/2014/04/heartbleed-developer-explains-openssl-mistake-that-put-web-at-risk/"&gt;http://arstechnica.com/information-technology/2014/04/heartbleed-developer-explains-openssl-mistake-that-put-web-at-risk/&lt;/a&gt;&amp;gt; (Surprisingly many of the `explanations' of the problem one may find on the internet are wrong, falsely blaming &lt;code&gt;OPENSSL_malloc&lt;/code&gt;) &lt;p&gt;The openSSL patch that fixes the Heartbleed (moving from OpenSSL revision 1.0.1f to 1.0.1g)&lt;br&gt; &amp;lt;&lt;a href="https://github.com/openssl/openssl/commit/96db9023b881d7cd9f379b0c154650d6c108e9a3#diff-2"&gt;https://github.com/openssl/openssl/commit/96db9023b881d7cd9f379b0c154650d6c108e9a3#diff-2&lt;/a&gt;&amp;gt; &lt;/p&gt;&lt;p&gt;&amp;lt;&lt;a href="https://xkcd.com/1354/"&gt;https://xkcd.com/1354/&lt;/a&gt;&amp;gt; How the Heartbleed Bug Works &lt;/p&gt;&lt;/dd&gt;&lt;/dl&gt; &lt;h2&gt;&lt;a name="dirty-string"&gt;User-input sanitation and SQL injection&lt;/a&gt;&lt;/h2&gt; &lt;dl&gt; &lt;dd&gt;Heartbleed was just one instance of neglecting to validate/sanitize data received from the user or network. Another, unfortunately all-too-common instance is the input injection attacks&amp;nbsp;-- in particular, SQL injection, `Bobby Tables'--like attacks. I have implemented the static SQL injection prevention in a web application server used in production. The implementation turned out straightforward and instructive. &lt;p&gt;I have written a web application server, which has been constantly running in production for at least eight years. The server makes SQL queries using the data from user-submitted requests. SQL injection and input validation had to be taken seriously. About half-way through the development I decided to try the `software protection layer': make the type-checker alert me to a missing input validation. &lt;/p&gt;&lt;p&gt;The idea was easy to try: the simple library below is essentially it. (The shown code is OCaml; it could have been C++, Java, Scala, or many other languages.) &lt;/p&gt;&lt;pre&gt; module DirtyString : sig (* interface *) type dirty_string (* abstract *) val dirty : string -&amp;gt; dirty_string val escape : dirty_string -&amp;gt; string val read_int : dirty_string -&amp;gt; int option val read_ncname : dirty_string -&amp;gt; (string * dirty_string) option end = struct (* implementation *) type dirty_string = string let dirty = %identity let read_int = int_of_string_opt ... end &lt;/pre&gt;The method &lt;code&gt;dirty&lt;/code&gt; taints a given string, turning it into a value of the &lt;em&gt;abstract&lt;/em&gt; &lt;code&gt;dirty_string&lt;/code&gt; type. Once the string is dirty, there is not much one can do with it: only apply &lt;code&gt;escape&lt;/code&gt;, &lt;code&gt;read_int&lt;/code&gt;, and &lt;code&gt;read_ncname&lt;/code&gt; methods. The latter attempts to read a sequence of alphanumeric, `safe' characters, returning them as a string, paired with the remainder of the input dirty string. An &lt;code&gt;ncname&lt;/code&gt; string can be used in building SQL queries worry-free, and hence is returned as the ordinary, `clean' string. &lt;p&gt;In the &lt;code&gt;DirtyString&lt;/code&gt; implementation, within the `kernel', &lt;code&gt;dirty_string&lt;/code&gt; is just the ordinary string. Likewise, the &lt;code&gt;read_int&lt;/code&gt; method is nothing but the corresponding function from the standard library. When the module is inlined, there is really no overhead. There is still protection: to the users of the library, &lt;code&gt;dirty_string&lt;/code&gt; and &lt;code&gt;string&lt;/code&gt; are different, not interchangeable types. &lt;/p&gt;&lt;p&gt;After I wrote the &lt;code&gt;DirtyString&lt;/code&gt; library, I &lt;code&gt;dirty&lt;/code&gt;-ed the result of network reading functions, and started the recompilation watching for type errors. Every place in the code that was using user input was flagged by the type checker: a &lt;code&gt;dirty_string&lt;/code&gt; cannot be used as an ordinary string. Indeed, some sort of validation/sanitation is required. Fixing the errors was simple, because some sort of validation was already in place. I merely had to rename the extant &lt;code&gt;read_ncname&lt;/code&gt; into &lt;code&gt;DirtyString.read_ncname&lt;/code&gt;, etc. I clearly remember one place, however, which was flagged by the type checker but did not have any validation checking. After thinking for about ten minutes, I decided that there should have been a validation check at that place after all. &lt;/p&gt;&lt;p&gt;The experience proved quite encouraging. I spent in total less than an hour implementing the &lt;code&gt;DirtyString&lt;/code&gt; and adjusting the code correspondingly, and I found a genuine problem. There was also no run-time overhead as I could see.&lt;/p&gt;&lt;/dd&gt; &lt;dt&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/dt&gt; &lt;dd&gt;&amp;lt;&lt;a href="https://www.xkcd.com/327/"&gt;https://www.xkcd.com/327/&lt;/a&gt;&amp;gt; Exploits of a Mom (aka, `Bobby Tables') &lt;p&gt;&lt;a href="http://okmij.org/ftp/Haskell/dependent-types.html#non-empty-list"&gt;Non-empty lists&lt;/a&gt;&lt;br&gt; The similar `tainting' technique ensures the absence of `head/tail of empty list' errors (the equivalent of `NullPointerException') &lt;/p&gt;&lt;p&gt;&lt;a href="http://okmij.org/ftp/ML/reverse.ml"&gt;reverse.ml&lt;/a&gt;&amp;nbsp;[2K]&lt;br&gt; List reversal with safe list access: The OCaml version of the Non-empty list code &lt;/p&gt;&lt;/dd&gt;&lt;/dl&gt; &lt;h2&gt;&lt;a name="ADT"&gt;Abstract Types -- the language protection layer&lt;/a&gt;&lt;/h2&gt; &lt;dl&gt; &lt;dd&gt;Let us explain, on a series of simple but already useful examples, how exactly abstraction acts as a protection layer, which invariants it enforces, and what good it does us. &lt;p&gt;Suppose we have several (assumed constant) integer arrays &lt;code&gt;a1...an&lt;/code&gt;, to be repeatedly searched for occurrences of some elements. It may make sense to create the sorted versions of the arrays &lt;code&gt;a1'...an'&lt;/code&gt; and search those, with the efficient binary search. There are a couple of problems however. First of all, how to ensure that &lt;code&gt;ai'&lt;/code&gt; is still the sorted version of the original &lt;code&gt;ai&lt;/code&gt;? Arrays are mutable by nature. Therefore, whenever we pass &lt;code&gt;ai'&lt;/code&gt; as an argument to some function, we cannot be sure it remains unmodified (unless we carefully examine the code of that function, if it is even available). Mainly, how does the binary search function guarantees that its argument array is actually sorted? Examining the array for sortedness is out of the question since it takes more time than the actual search. &lt;/p&gt;&lt;p&gt;Protection&amp;nbsp;-- access restriction&amp;nbsp;-- provides the sortedness guarantee. Consider the following simple library realized as an OCaml module. &lt;/p&gt;&lt;pre&gt; module ArraySearch : sig (* the interface *) type t (* abstract *) val sort : int array -&amp;gt; t val search : int -&amp;gt; t -&amp;gt; bool end = struct (* the implementation: the `kernel' *) type t = int array let sort : int array -&amp;gt; t = fun a -&amp;gt; let a' = Array.copy a in Array.sort compare a'; a' (* binary search in the sorted array arr *) let search x arr = ... end &lt;/pre&gt;One can write such code in almost any language with a module system. (Later on we show another implementation, using closures/objects.) The library provides only two operations: &lt;code&gt;sort&lt;/code&gt; and &lt;code&gt;search&lt;/code&gt;. The former takes an integer array and returns the value of type &lt;code&gt;t&lt;/code&gt;. Nothing is known about the type &lt;code&gt;t&lt;/code&gt; to the users of library. In particular, none of the array access and mutation operations apply to &lt;code&gt;t&lt;/code&gt; values: if we try, the type checker will complain that &lt;code&gt;t&lt;/code&gt; is not an array. In fact, &lt;code&gt;t&lt;/code&gt; is not equal to any other type known to the type checker. Hence we may give a &lt;code&gt;t&lt;/code&gt; value only to polymorphic functions (which merely pass it around), or to the operation &lt;code&gt;search&lt;/code&gt; of the library. Here is a usage example (for the case of two arrays &lt;code&gt;a1&lt;/code&gt; and &lt;code&gt;a2&lt;/code&gt; in our original set-up): &lt;pre&gt; let a1' = ArraySearch.sort a1 (* First, sort the arrays *) let a2' = ArraySearch.sort a2 ... (* some code *) let v1 = ArraySearch.search 1 a1' &amp;amp;&amp;amp; ArraySearch.search 2 a2' ... (* more code *) let f x = ArraySearch.search x a1' in f 1 &amp;amp;&amp;amp; f 2 &lt;/pre&gt;The prefix &lt;code&gt;ArraySearch&lt;/code&gt; may be omitted if we &lt;code&gt;open ArraySearch&lt;/code&gt; first. &lt;p&gt;Looking into the implementation of the library (the &lt;code&gt;ArraySearch&lt;/code&gt; structure) shows that the type &lt;code&gt;t&lt;/code&gt; is actually &lt;code&gt;int array&lt;/code&gt;&amp;nbsp;-- but this is known only within the implementation. The implementation may, therefore, treat &lt;code&gt;t&lt;/code&gt; values as arrays, with no complaints from the type checker. The operation &lt;code&gt;sort&lt;/code&gt; makes the copy of its input array and sorts the result; &lt;code&gt;search&lt;/code&gt; does not modify the argument array. We thus may conclude that a value of type &lt;code&gt;t&lt;/code&gt; represents a sorted array. It is made sorted by &lt;code&gt;sort&lt;/code&gt;, it is not aliased to outside, and the operations on &lt;code&gt;t&lt;/code&gt; preserve sortedness. We made this determination by looking &lt;em&gt;only&lt;/em&gt; at the implementation of the module, rather than through any of the code that may use it. The users of the library cannot know what &lt;code&gt;t&lt;/code&gt; is, and cannot apply any operations to it except for &lt;code&gt;ArraySearch.search&lt;/code&gt;. Hence the sortedness&amp;nbsp;-- the property, or the invariant that may be associated with the type &lt;code&gt;t&lt;/code&gt;&amp;nbsp;-- indeed holds. Thus the merit of type abstraction, of type-checker--reinforced access restrictions: invariants established by &lt;em&gt;local&lt;/em&gt; reasoning are preserved &lt;em&gt;globally&lt;/em&gt;. In our case, the sortedness invariant entails that the &lt;code&gt;search&lt;/code&gt; operation does not need to check if its argument is a sorted array. It always is. The type abstraction hence let us use the faster algorithm and be sure it is correctly applied. &lt;/p&gt;&lt;p&gt;Before we turn to the second example, let us see another realization of the sorted-array--search library, using a different language protection mechanism. &lt;/p&gt;&lt;pre&gt; let sort : int array -&amp;gt; (int -&amp;gt; bool) = fun a -&amp;gt; let a' = Array.copy a in let () = Array.sort compare a' in (* binary search in the sorted array arr *) let search x arr = ... in fun x -&amp;gt; search x a' &lt;/pre&gt;Here, &lt;code&gt;sort&lt;/code&gt; takes an &lt;code&gt;int array&lt;/code&gt; and returns an operation to (efficiently) search in that array. The abstraction mechanism now is first-class functions: returning functions as results. Crucially, the returned function is actually a &lt;em&gt;closure&lt;/em&gt; &lt;code&gt;fun x -&amp;gt; search x a'&lt;/code&gt; that contains a reference to the internal array &lt;code&gt;a'&lt;/code&gt;. Since closures are opaque and cannot be deconstructed, the embedded &lt;code&gt;a'&lt;/code&gt; reference cannot be used, or seen, outside the closure. We notice no other reference to &lt;code&gt;a'&lt;/code&gt; available to library users; therefore, once sorted, &lt;code&gt;a'&lt;/code&gt; remains constant and sorted. Again we see local reasoning (examining only the implementation but not the uses of the library) and the guarantee due to the protection that local invariants remain valid globally. &lt;p&gt;Incidentally, the closure implementation is similar to the one presented already in Morris 1973 paper (in the context of a different example -- although Morris has also mentioned the array sortedness and the binary search). With closures, there is an overhead of creating and using them. With the &lt;code&gt;ArraySearch&lt;/code&gt; module, there is no run-time overhead at all: internally a value of the type &lt;code&gt;t&lt;/code&gt; is an &lt;code&gt;int array&lt;/code&gt;, with no wrappers or indirections. &lt;/p&gt;&lt;p&gt;As the next example, to be used later, consider the following module (library) with four operations: &lt;/p&gt;&lt;pre&gt; module Interv : sig (* the interface *) type t (* abstract *) val lwb : t val upb : t val mid : t -&amp;gt; t -&amp;gt; t val to_int : t -&amp;gt; int end = struct (* the implementation: the `kernel' *) type t = int let lwb = 0 let upb = 5 let mid x y = (x + y) / 2 (* no overflow, for our range *) let to_int x = x end &lt;/pre&gt;The library is presented in the form of an OCaml module. The similar code can also be easily written in any Object-Oriented language, as a class with a protected field. &lt;p&gt;Examining the implementation lets us conclude that we may attribute to the abstract type &lt;code&gt;Interv.t&lt;/code&gt; the invariant that it represents an integer from 0 through 5, inclusive. Indeed, &lt;code&gt;lwb&lt;/code&gt; returns 0, which respects the invariant. Likewise, &lt;code&gt;upb&lt;/code&gt; returns 5, the number within the range. The operation &lt;code&gt;mid&lt;/code&gt; is both the consumer of &lt;code&gt;t&lt;/code&gt; values and the producer of them. As a consumer, it can assume &lt;code&gt;t&lt;/code&gt;'s invariant: it is a number from 0 through 5. Upon this assumption, the result of &lt;code&gt;mid&lt;/code&gt; is also a number within the same range. Hence the invariant is established. As the consequence, the result of &lt;code&gt;to_int&lt;/code&gt; operation will surely be an integer from 0 though 5, incl. Such an assurance is behind safe array indexing, described next. &lt;/p&gt;&lt;p&gt;To conclude, the language protection layer helps ensure that the invariants established by &lt;em&gt;local&lt;/em&gt; reasoning are preserved &lt;em&gt;globally&lt;/em&gt;. Specifically, type abstraction lets us attribute an invariant (a proposition) to the values of an abstract type: e.g., the value represents a number within certain range, or a sorted array. The idea of abstract data type's statically representing and enforcing sophisticated properties of run-time values was Robin Milner's main insight behind the design of the Edinburgh LCF theorem prover back in the early 1970s. &lt;/p&gt;&lt;p&gt;The local reasoning we have conducted so far has been informal. It could be made formal, to any desired degree. In fact, the protection layer helps formal reasoning by making it local and modular. It is much easier to formally analyze the implementation of the, say, &lt;code&gt;Interv&lt;/code&gt; interface, than the whole program using that interface. &lt;/p&gt;&lt;p&gt;It should be pointed out that guarantees of abstract types come from the lack of reflection, extension, and introspection of abstract data types. OCaml, incidentally, is weaker in this respect because polymorphic equality can break some of the invariants. So, reflection, extension and introspection facilities of a language can be viewed as vices rather than virtues.&lt;/p&gt;&lt;/dd&gt; &lt;dt&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/dt&gt; &lt;dd&gt;James H. Morris Jr.: Protection in Programming Languages&lt;br&gt; Comm. of the ACM, 1973, V16, N1, pp. 15-21&lt;br&gt; Abstract: Linguistic mechanisms which can be used to protect one subprogram from another's malfunctioning are described. Function-producing functions and various type-tagging schemes are considered. An attempt is made to distinguish between access limitation and authentication. &lt;p&gt;&lt;a href="#formalization"&gt;Formalization of the abstract type protection&lt;/a&gt; &lt;/p&gt;&lt;p&gt;&lt;a href="#lsc"&gt;Lightweight static capabilities&lt;/a&gt; &lt;/p&gt;&lt;/dd&gt;&lt;/dl&gt; &lt;h2&gt;&lt;a name="safe-array-access"&gt;Eliminating array bound checks&lt;/a&gt;&lt;/h2&gt; &lt;dl&gt; &lt;dd&gt;We now describe in detail how the language protection layer helps ensure that all array indexing operations are within array bounds. Not only do we get the confidence that an out-of-bound access (aka, buffer overflow) never occurs in any run of the program. We also eliminate dynamic array bound checks and hence improve the program performance. Let us see how the slogan&amp;nbsp;-- safe and efficient, now&amp;nbsp;-- works for realistic, interesting programs. This article describes binary search in a sorted array&amp;nbsp;-- the example in the famous Xi and Pfenning's PLDI 1998 paper. More involved examples appear later on this web page. This article uses OCaml, although our binary search code was first presented (in 2004) in Haskell. It is easy to reimplement it in Scala or even Java; the simpler versions have been coded in C++ (see the references at the end). &lt;p&gt;Let's consider an extended version of the &lt;code&gt;Interv&lt;/code&gt; interface from our earlier example: &lt;/p&gt;&lt;pre&gt; module type Index = sig type index = private int (* i:index implies lwb &amp;lt;= i &amp;lt;= upb *) type indexL = private int (* i:indexL implies lwb &amp;lt;= i *) type indexH = private int (* i:indexH implies i &amp;lt;= upb *) val lwb : indexL val upb : indexH val bsucc : index -&amp;gt; indexL val bpred : index -&amp;gt; indexH val bmid : index -&amp;gt; index -&amp;gt; index val bcmp : indexL -&amp;gt; indexH -&amp;gt; (index * index) option end &lt;/pre&gt;The &lt;code&gt;Index&lt;/code&gt; interface shows off another abstraction facility of OCaml: so-called private types. A value of the type &lt;code&gt;private int&lt;/code&gt; can always be cast into &lt;code&gt;int&lt;/code&gt; and later used as an ordinary integer. In fact, at run-time a &lt;code&gt;private int&lt;/code&gt; is an &lt;code&gt;int&lt;/code&gt;&amp;nbsp;-- moreover, the optimizer can see that and optimize accordingly. On the other hand, &lt;code&gt;int&lt;/code&gt; &lt;em&gt;cannot&lt;/em&gt; be cast to &lt;code&gt;private int&lt;/code&gt;; using an &lt;code&gt;int&lt;/code&gt; value where a &lt;code&gt;private int&lt;/code&gt; is expected is a type error. The only way to create &lt;code&gt;private int&lt;/code&gt; values is to use the operations of the interface. &lt;p&gt;&lt;code&gt;Index&lt;/code&gt; has three abstract types, all distinct: for example, &lt;code&gt;bsucc lwb&lt;/code&gt; is a type error. The code comments show the propositions we would like to attribute to the values of these types. That is, if &lt;code&gt;i&lt;/code&gt; is a value of the type &lt;code&gt;index&lt;/code&gt;, it is an integer within the closed range &lt;code&gt;[lwb,upb]&lt;/code&gt; (the value of the type &lt;code&gt;index&lt;/code&gt; hence also witnesses the fact that &lt;code&gt;lwb &amp;lt;= upb&lt;/code&gt;). In contrast, an &lt;code&gt;indexL&lt;/code&gt; value is only bounded from below, by &lt;code&gt;lwb&lt;/code&gt;, and an &lt;code&gt;indexH&lt;/code&gt; value is only bounded from above. The operation &lt;code&gt;bsucc&lt;/code&gt; is meant to be the index increment. Its result may exceed &lt;code&gt;upb&lt;/code&gt; but surely stays above the lower bound; therefore the result type is &lt;code&gt;indexL&lt;/code&gt; rather than &lt;code&gt;index&lt;/code&gt;. The operation &lt;code&gt;pred&lt;/code&gt; is the predecessor (which certainly preserves the upper bound); &lt;code&gt;bmid&lt;/code&gt; averages two indices, leaving the result in range&amp;nbsp;-- which is reflected in its type. Finally, &lt;code&gt;bcmp&lt;/code&gt; compares an integer &lt;code&gt;i:indexL&lt;/code&gt; bounded from below by &lt;code&gt;lwb&lt;/code&gt;, with an integer &lt;code&gt;j:indexH&lt;/code&gt; bounded from above by &lt;code&gt;upb&lt;/code&gt;. If &lt;code&gt;i&amp;lt;=j&lt;/code&gt;, then both &lt;code&gt;i&lt;/code&gt; and &lt;code&gt;j&lt;/code&gt; are in fact within &lt;code&gt;[lwb,upb]&lt;/code&gt;; they should be returned as the values of the type &lt;code&gt;index&lt;/code&gt; this time. The comparison result is hence not just a mere &lt;code&gt;true&lt;/code&gt; or &lt;code&gt;false&lt;/code&gt;: a successful comparison improves our knowledge of values and, correspondingly, entitles to use more precise types. &lt;/p&gt;&lt;p&gt;The following is the straightforward implementation, parameterized by &lt;code&gt;upb&lt;/code&gt;, which could be an arbitrary integer. The lower bound is assumed zero. It is easy to see the implementation respects the invariants of the interface we have just described. &lt;/p&gt;&lt;pre&gt; module IndexF(S:sig val upb:int end) : Index = struct type index = int type indexL = int type indexH = int let lwb : indexL = 0 let upb : indexH = S.upb let bsucc : index -&amp;gt; indexL = Stdlib.succ let bpred : index -&amp;gt; indexH = Stdlib.pred let bmid : index -&amp;gt; index -&amp;gt; index = fun x y -&amp;gt; x + (y - x)/2 let[@inline] bcmp : indexL -&amp;gt; indexH -&amp;gt; (index * index) option = fun i j -&amp;gt; if i &amp;lt;= j then Some (i,j) else None end &lt;/pre&gt;Within the implementation, &lt;code&gt;index&lt;/code&gt;, &lt;code&gt;indexL&lt;/code&gt; and &lt;code&gt;indexH&lt;/code&gt; types are no longer private, so we may create their values. Ascribing the signature &lt;code&gt;Index&lt;/code&gt; adds the private qualification, and the corresponding access restrictions. The curious &lt;code&gt;[@inline]&lt;/code&gt; is an inlining annotation similar to the &lt;code&gt;inline&lt;/code&gt; keyword in C/C++. &lt;p&gt;The invariant that a value of the &lt;code&gt;index&lt;/code&gt; type is an integer within &lt;code&gt;[lwb,upb]&lt;/code&gt; guarantees safe access to an array whose index range is the same &lt;code&gt;[lwb,upb]&lt;/code&gt;. Because the safety is assured, the run-time bounds check can be elided: &lt;/p&gt;&lt;pre&gt; module BArray(S: sig type el val arr : el array end) = struct include IndexF(struct let upb = Array.length S.arr - 1 end) let[@inline] bget : index -&amp;gt; S.el = fun i -&amp;gt; Array.unsafe_get S.arr (i :&amp;gt; int) end &lt;/pre&gt;If &lt;code&gt;a1&lt;/code&gt; is an integer array then &lt;code&gt;BArray(struct type el = int let arr = a1 end)&lt;/code&gt; is a module that implements the &lt;code&gt;Index&lt;/code&gt; interface with one extra operation: &lt;code&gt;bget&lt;/code&gt; for indexing within the array &lt;code&gt;a1&lt;/code&gt;. (The operation &lt;code&gt;(i :&amp;gt; int)&lt;/code&gt; is the coercion of an &lt;code&gt;index&lt;/code&gt; to an &lt;code&gt;int&lt;/code&gt;, which is always possible and is, operationally, the identity.) The instantiation of &lt;code&gt;IndexF&lt;/code&gt; makes &lt;code&gt;lwb&lt;/code&gt; be zero and &lt;code&gt;upb&lt;/code&gt; be the length of &lt;code&gt;a1&lt;/code&gt; minus one&amp;nbsp;-- which is the index range of &lt;code&gt;a1&lt;/code&gt;, if it is not empty, thus justifying the use of &lt;code&gt;unsafe_get&lt;/code&gt;. (If &lt;code&gt;a1&lt;/code&gt; is an empty array, &lt;code&gt;unsafe_get&lt;/code&gt; is still justified, because the &lt;code&gt;index&lt;/code&gt; type has no values.) &lt;p&gt;We have implemented the trusted `security kernel', providing the &lt;code&gt;Index&lt;/code&gt; API with the extra &lt;code&gt;bget&lt;/code&gt; method. We can now write the binary search itself. It takes the comparison operation &lt;code&gt;cmp&lt;/code&gt;, a &lt;code&gt;key&lt;/code&gt; and an array and returns either &lt;code&gt;None&lt;/code&gt; if the &lt;code&gt;key&lt;/code&gt; does not occur in the array, or &lt;code&gt;Some (i,key)&lt;/code&gt; where &lt;code&gt;i&lt;/code&gt; is the index at which the &lt;code&gt;key&lt;/code&gt; does occur. The array is assumed sorted, according to &lt;code&gt;cmp&lt;/code&gt;. We took this &lt;code&gt;bsearch&lt;/code&gt; interface from Xi and Pfenning's PLDI 1998 paper. &lt;/p&gt;&lt;pre&gt; let bsearch (type a) : (a*a -&amp;gt; int) -&amp;gt; a -&amp;gt; a array -&amp;gt; (int * a) option = fun cmp key arr -&amp;gt; let module M = BArray(struct type el = a let arr = arr end) in let open M in let rec look (lo:indexL) (hi:indexH) = (* type annotations are for clarity*) match bcmp lo hi with | None -&amp;gt; None | Some (lo',hi') -&amp;gt; (* lo' and hi' are of the type index now *) let m = bmid lo' hi' in let x = bget m in let cmp_r = cmp (key,x) in if cmp_r &amp;lt; 0 then look lo (bpred m) else if cmp_r = 0 then Some ((m :&amp;gt; int), x) else look (bsucc m) hi in look lwb upb &lt;/pre&gt;The implementation is textbook, and also closely matches Xi and Pfenning's code: only theirs was in Dependent ML and ours is ordinary OCaml. The key part is &lt;code&gt;bcmp lo hi&lt;/code&gt; that compares &lt;code&gt;lo&lt;/code&gt; (bounded from below by zero) with &lt;code&gt;hi&lt;/code&gt; (bounded from above by &lt;code&gt;upb&lt;/code&gt;, the largest index value within the array). If &lt;code&gt;lo&lt;/code&gt; does not exceed &lt;code&gt;hi&lt;/code&gt;, then &lt;code&gt;[lo,hi]&lt;/code&gt; interval is non-empty, and is contained within &lt;code&gt;[0,upb]&lt;/code&gt;, the safe index range. &lt;p&gt;The &lt;code&gt;bsearch&lt;/code&gt; code is not part of a trusted security kernel: rather, it is `user-level', so to speak. It is written using the interface of the (instantiated) &lt;code&gt;BArray&lt;/code&gt; module and benefits from its invariants: the guaranteed safe indexing within the input array. If we compile the &lt;code&gt;bsearch&lt;/code&gt; code with &lt;code&gt;ocamlopt -O3&lt;/code&gt; and look at the generated assembly, we see all array access and index calculations inlined, with no bounds checks and no calls to error functions. Safe and efficient, indeed. &lt;/p&gt;&lt;p&gt;There are many variations of the &lt;code&gt;bsearch&lt;/code&gt; code; the references below show several. It is worth noting one variation point, related to the feature of the &lt;code&gt;BArray&lt;/code&gt; module that we did not stress. &lt;/p&gt;&lt;p&gt;&lt;code&gt;BArray&lt;/code&gt; assures safe indexing within an array whose length is not known until run-time. The more one thinks about it, the harder it gets to believe. How is it possible to use types&amp;nbsp;-- which are checked statically, before the program runs&amp;nbsp;-- to ensure in-bounds indexing when the bounds are not known until the run-time? The following example explains. After the set-up: &lt;/p&gt;&lt;pre&gt; let a1 = [|1;3|] and a2 = [|1;3|] module M1 = BArray(struct type el=int let arr=a1 end) module M2 = BArray(struct type el=int let arr=a2 end) &lt;/pre&gt;Evaluating &lt;pre&gt; (M1.lwb :&amp;gt;int);; - : M1.indexL = 0 M1.bget M1.lwb;; ^^^^^^ Error: This expression has type M1.indexL but an expression was expected of type M1.index &lt;/pre&gt;gives a type error. One may be puzzled: how come we cannot index an array at index 0? Because it is not always safe: the array may be empty. Therefore, in the &lt;code&gt;Index&lt;/code&gt; interface, &lt;code&gt;M1.lwb&lt;/code&gt; has the type &lt;code&gt;indexL&lt;/code&gt;, rather than &lt;code&gt;index&lt;/code&gt; expected by &lt;code&gt;bget&lt;/code&gt;. The only way to get the &lt;code&gt;index&lt;/code&gt; zero value is through the comparison &lt;code&gt;lwb&lt;/code&gt; with &lt;code&gt;upb&lt;/code&gt;, which amounts to the non-emptiness check. The types force us to do this check: &lt;pre&gt; match (M1.bcmp M1.lwb M1.upb, M2.bcmp M2.lwb M2.upb) with (Some (l1,u1), Some (l2,u2)) -&amp;gt; (M1.bget l1, M2.bget l2);; - : int * int = (1, 1) &lt;/pre&gt;However, evaluating &lt;pre&gt; match (M1.bcmp M1.lwb M1.upb, M2.bcmp M2.lwb M2.upb) with (Some (l1,u1), Some (l2,u2)) -&amp;gt; ((l1:&amp;gt;int),(l2:&amp;gt;int));; - : int * int = (0, 0) match (M1.bcmp M1.lwb M1.upb, M2.bcmp M2.lwb M2.upb) with (Some (l1,u1), Some (l2,u2)) -&amp;gt; M1.bget l2;; ^^ Error: This expression has type M2.index but an expression was expected of type M1.index &lt;/pre&gt;is again the type error&amp;nbsp;-- even though we checked that both arrays are non-empty and &lt;code&gt;l1&lt;/code&gt; may indeed index within M1's array. Although both &lt;code&gt;l1&lt;/code&gt; and &lt;code&gt;l2&lt;/code&gt; are of the type &lt;code&gt;index&lt;/code&gt; and both represent the integer 0, only &lt;code&gt;l1&lt;/code&gt; may index within M1's array. This is because the types of &lt;code&gt;l1&lt;/code&gt; and &lt;code&gt;l2&lt;/code&gt; are actually different: &lt;code&gt;M1.index&lt;/code&gt; and &lt;code&gt;M2.index&lt;/code&gt;, resp. Each instantiation of &lt;code&gt;BArray&lt;/code&gt; with a different array creates a new, fresh `version' of the &lt;code&gt;index&lt;/code&gt; type&amp;nbsp;-- to be used for indexing only within that instance of &lt;code&gt;BArray&lt;/code&gt;. One may say, a &lt;code&gt;BArray&lt;/code&gt; instance makes a distinct `brand' of its abstract types, usable only with the operations of the same brand. (The code of the operations need not be duplicated since the optimizer knows that &lt;code&gt;index&lt;/code&gt; of any brand is a mere integer.) Technically, &lt;code&gt;M1.index&lt;/code&gt; and &lt;code&gt;M2.index&lt;/code&gt; are considered distinct by the type checker because they have different `paths', or the provenance, which can be easily checked statically. This facility of OCaml is akin to path-dependent types in Scala. &lt;p&gt;The branding, albeit not a `simple type' facility, is not exotic: it can be accomplished in any language with existential (or, `abstract package' types), or universal types. OCaml has both existential and universal types, which gives two other ways to write the safe &lt;code&gt;bsearch&lt;/code&gt;. The code referenced below shows one such alternative, using universal types, in OCaml and Haskell.&lt;/p&gt;&lt;/dd&gt; &lt;dt&gt;&lt;strong&gt;Version&lt;/strong&gt;&lt;/dt&gt; &lt;dd&gt;The current version is -- original (Haskell): August 2004; improved and explained OCaml: August 2019&lt;/dd&gt; &lt;dt&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/dt&gt; &lt;dd&gt;Hongwei Xi and Frank Pfenning: Eliminating Array Bound Checking Through Dependent Types. PLDI'98&lt;br&gt; The famous paper introducing a practical dependent type system as a dialect of SML. We faithfully re-implement the &lt;code&gt;bsearch&lt;/code&gt; example from that paper, in several languages. &lt;p&gt;&lt;a href="http://okmij.org/ftp/Computation/lightweight-guarantees/eliminating-array-bound-checks.ml"&gt;eliminating-array-bound-checks.ml&lt;/a&gt;&amp;nbsp;[15K]&lt;br&gt; OCaml code explained in this message, plus the older implementation of branding based on universal types &lt;/p&gt;&lt;p&gt;&lt;a href="http://okmij.org/ftp/Computation/lightweight-guarantees/eliminating-array-bound-check-literally.hs"&gt;eliminating-array-bound-check-literally.hs&lt;/a&gt;&amp;nbsp;[8K]&lt;br&gt; The Haskell version of &lt;code&gt;bsearch&lt;/code&gt;. The code is written in Haskell98 with the sole extension for higher-ranked types. &lt;/p&gt;&lt;p&gt;&lt;a href="http://okmij.org/ftp/Computation/lightweight-guarantees/eliminating-array-bound-check.lhs"&gt;eliminating-array-bound-check.lhs&lt;/a&gt;&amp;nbsp;[9K]&lt;br&gt; The literate Haskell code with explanations and the examples&lt;br&gt; The first version of the code was originally posted as &lt;cite&gt;Eliminating Array Bound Checking through Non-dependent types&lt;/cite&gt; on the Haskell mailing list on Thu, 5 Aug 2004 19:31:36 -0700. The current version corrects the problem pointed out by Conor T. McBride in the discussion thread. &lt;/p&gt;&lt;p&gt;&lt;a href="http://okmij.org/ftp/Computation/lightweight-guarantees/bsearch-static.cc"&gt;bsearch-static.cc&lt;/a&gt;&amp;nbsp;[2K]&lt;br&gt; &lt;a href="http://okmij.org/ftp/Computation/lightweight-guarantees/bsearch-template.cc"&gt;bsearch-template.cc&lt;/a&gt;&amp;nbsp;[2K]&lt;br&gt; &lt;a href="http://okmij.org/ftp/Computation/lightweight-guarantees/bsearch-static.s"&gt;bsearch-static.s&lt;/a&gt;&amp;nbsp;[3K]&lt;br&gt; &lt;a href="http://okmij.org/ftp/Computation/lightweight-guarantees/bsearch-template.s"&gt;bsearch-template.s&lt;/a&gt;&amp;nbsp;[2K]&lt;br&gt; Binary search in an array with the statically known bounds: C++ code (with and without templates) and the generated assembly code (gcc -O2). The assembly code shows no run-time overhead of the abstractions used to ensure the safety of array access. &lt;/p&gt;&lt;p&gt;&lt;a href="#range-analysis"&gt;Lightweight guarantees and static analyses&lt;/a&gt;&lt;br&gt; Another explanation of the branding technique, on a simpler example &lt;/p&gt;&lt;/dd&gt;&lt;/dl&gt; &lt;h2&gt;&lt;a name="lsc"&gt;Lightweight static capabilities&lt;/a&gt;&lt;/h2&gt; &lt;dl&gt; &lt;dd&gt;We describe a modular programming style that harnesses modern type systems to verify safety conditions in practical systems. This style has three ingredients: (i) A compact kernel of trust that is specific to the problem domain; (ii) Unique names, &lt;em&gt;capabilities&lt;/em&gt;, that confer rights and certify properties, so as to extend the trust from the kernel to the rest of the application; (iii) Static (type) proxies for dynamic values. We illustrate our approach using examples from the dependent-type literature, but our programs are written in Haskell and OCaml today, so our techniques are compatible with imperative code, native mutable arrays, and general recursion. The three ingredients of this programming style call for (1) an expressive core language, (2) higher-rank polymorphism, and (3) phantom types. &lt;p&gt;This paper demonstrates a lightweight notion of &lt;em&gt;static capabilities&lt;/em&gt; that brings together increasingly expressive type systems and increasingly accessible program verification. Like many programmers, we want to assure safety conditions: array indices remain within bounds; modular arithmetic operates on numbers with the same modulus; a file or database handle is used only while open; and so on. The safety conditions protect objects such as arrays, modular numbers, and files. Our overarching view is that a static capability authorizes access to a protected object and simultaneously certifies that a safety condition holds. Rather than proposing a new language or system, our contribution is to substantiate the slogan that types are capabilities, today: we use concrete and straightforward code in Haskell and OCaml to illustrate that a programming language with an appropriately expressive type system is a static capability language. &lt;/p&gt;&lt;p&gt;This is a joint work with Chung-chieh Shan. &lt;/p&gt;&lt;/dd&gt; &lt;dt&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/dt&gt; &lt;dd&gt;&lt;a href="http://okmij.org/ftp/Computation/lightweight-guarantees/lightweight-static-capabilities.pdf"&gt;lightweight-static-capabilities.pdf&lt;/a&gt;&amp;nbsp;[334K]&lt;br&gt; The paper published in Electr. Notes Theor. Comput. Sci, 174(7), pp. 79-104, 2007 &lt;p&gt;&lt;a href="http://okmij.org/ftp/Computation/lightweight-guarantees/lightweight-guarantees-u07-poster.pdf"&gt;lightweight-guarantees-u07-poster.pdf&lt;/a&gt;&amp;nbsp;[81K]&lt;br&gt; Poster `Lightweight Static Guarantees' presented at the Poster Session of the 2007 USENIX Annual Technical Conference. June 20, 2007. Santa Clara, CA &lt;/p&gt;&lt;p&gt;&lt;a href="http://okmij.org/ftp/Haskell/number-parameterized-types.html#ls-resources"&gt;Lightweight static resources,&lt;/a&gt; for safe embedded and systems programming&lt;br&gt; This follow-up paper describes further applications, for safe embedded and systems programming, ensuring, among other properties, proper alignment when accessing raw memory areas. The paper also introduces kind-level static capabilities to enforce invariants of type-level programming. &lt;/p&gt;&lt;/dd&gt;&lt;/dl&gt; &lt;h2&gt;&lt;a name="formalization"&gt;Formalization of the abstract type protection&lt;/a&gt;&lt;/h2&gt; &lt;dl&gt; &lt;dd&gt;How do we hope to prove that the protection layer indeed enforces invariants and extends locally established properties through the whole program? &lt;p&gt;The &lt;a href="#lsc"&gt;Lightweight static capabilities&lt;/a&gt; paper (joint work with Chung-chieh Shan) introduced the so-called `strict' type system with the dependent-type flavor. The safety invariants are enforced and propagated because they are part of types. The paper then introduced a relaxation of the strict system to the Hindley-Milner system with type abstraction (higher-ranked types), and demonstrated how the safety invariants are still maintained. &lt;/p&gt;&lt;p&gt;&lt;a href="http://okmij.org/ftp/formalizations/safety.elf"&gt;safety.elf&lt;/a&gt;&amp;nbsp;[17K]&lt;br&gt; Twelf code with proofs of soundness of the `strict' type system for the language based on System F with lists and non-empty lists. The progress theorem assures that a well-typed program shall not attempt to take the head or tail of an empty list. &lt;/p&gt;&lt;p&gt;&lt;a href="http://okmij.org/ftp/formalizations/safety-array.elf"&gt;safety-array.elf&lt;/a&gt;&amp;nbsp;[32K]&lt;br&gt; Twelf code verifying manual proofs of soundness of the `strict' type system for the language made of System F plus `arrays' whose type reflects their size. The progress theorem states the safety property: in a well-typed program array access is always in-bounds.&lt;/p&gt;&lt;/dd&gt;&lt;/dl&gt; &lt;h2&gt;&lt;a name="multiple"&gt;Eliminating array bound checking in multiple arrays&lt;/a&gt;&lt;/h2&gt; &lt;dl&gt; &lt;dd&gt;This message gives another non-trivial example of writing code with non-trivial static guarantees in present-day functional languages. The example involves native Haskell arrays, index computations, and general recursion. All array indexing operations are statically guaranteed to be safe -- hence we can safely use the efficient &lt;code&gt;unsafeAt&lt;/code&gt; primitive. Furthermore, the static assurances in the main loop cost us no run-time overhead. The example uses only Haskell98 + higher-ranked types. No new type classes are introduced. The safety is based on: Haskell type system, quantified type variables, and a compact general-purpose trusted kernel. I thank Daniel Yokomizo for the challenge. &lt;p&gt;Our example is folding over multiple, &lt;em&gt;variously-sized&lt;/em&gt; arrays. This is like a fold over an array -- generalized to an arbitrary number of arrays, whose index ranges do not have to be the same (and do not have to overlap). Typing this example in a genuinely dependent type system is probably going to be quite challenging. &lt;/p&gt;&lt;p&gt;Our goal is to implement a function &lt;/p&gt;&lt;pre&gt; marray_fold :: (Ix i, Integral i) =&amp;gt; (seed -&amp;gt; [e] -&amp;gt; seed) -&amp;gt; seed -&amp;gt; [Array i e] -&amp;gt; seed &lt;/pre&gt;Its third argument is a list of arrays; the arrays have all the same element and index types; the actual sizes (that is, the lower and upper bounds) may differ. Some arrays in the list may even be empty (with the lower bound higher than the upper one). The function &lt;code&gt;marray_fold&lt;/code&gt;, like left fold, applies its left argument to the values extracted from the corresponding arrays. Because arrays may have different sizes and bounds, &lt;code&gt;marray_fold&lt;/code&gt; operates over the range of indices that is the intersection of the ranges of the argument arrays. &lt;p&gt;For example: &lt;/p&gt;&lt;pre&gt; dot a1 a2 = marray_fold (\seed l -&amp;gt; product l + seed) 0 [a1,a2] &lt;/pre&gt;computes the dot products of two arrays. &lt;/dd&gt; &lt;dt&gt;&lt;strong&gt;Version&lt;/strong&gt;&lt;/dt&gt; &lt;dd&gt;The current version is February 2006&lt;/dd&gt; &lt;dt&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/dt&gt; &lt;dd&gt;&lt;a href="http://okmij.org/ftp/Computation/lightweight-guarantees/eliminating-mult-array-bound-check.lhs"&gt;eliminating-mult-array-bound-check.lhs&lt;/a&gt;&amp;nbsp;[13K]&lt;br&gt; The literate Haskell98 plus higher-order types&lt;br&gt; The code was posted as &lt;cite&gt;Eliminating Multiple-Array Bound Checking through Non-dependent types&lt;/cite&gt; on the Haskell mailing list on Fri, 10 Feb 2006 22:05:04 -0800 (PST) &lt;/dd&gt;&lt;/dl&gt; &lt;h2&gt;&lt;a name="KMP"&gt;Knuth-Morris-Pratt string search with safe array access&lt;/a&gt;&lt;/h2&gt; &lt;dl&gt; &lt;dd&gt;The largest example in the Xi and Pfenning's PLDI'98 paper is Knuth-Morris-Pratt (KMP) string search. It is an imperative algorithm with complicated control flow, mutable arrays and indirect indexing within the pattern string. It also uses a deliberately out-of-bounds index value (-1) as a special indicator in the indirect indexing. The goal is to statically assure safety of all array and string access operations, and so to eliminate run-time array-bound check without introducing other overhead into the main loops of the algorithm. &lt;p&gt;We re-implement Xi's KMP code in Haskell and OCaml, maintaining the same safety guarantees and efficiency.&lt;/p&gt;&lt;/dd&gt; &lt;dt&gt;&lt;strong&gt;Version&lt;/strong&gt;&lt;/dt&gt; &lt;dd&gt;The current version is May 2006&lt;/dd&gt; &lt;dt&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/dt&gt; &lt;dd&gt;&lt;a href="http://okmij.org/ftp/Computation/lightweight-guarantees/KMP-DML.ml"&gt;KMP-DML.ml&lt;/a&gt;&amp;nbsp;[4K]&lt;br&gt; The KMP code in Dependent ML, written by Hongwei Xi and published in Xi and Pfenning, PLDI'98 &lt;p&gt;&lt;a href="http://okmij.org/ftp/Computation/lightweight-guarantees/KMP-deptype.hs"&gt;KMP-deptype.hs&lt;/a&gt;&amp;nbsp;[14K]&lt;br&gt; The complete Haskell code: Haskell98 with higher-ranked types &lt;/p&gt;&lt;p&gt;&lt;a href="http://okmij.org/ftp/Computation/lightweight-guarantees/KMP.ml"&gt;KMP.ml&lt;/a&gt;&amp;nbsp;[11K]&lt;br&gt; The corresponding OCaml code &lt;/p&gt;&lt;/dd&gt;&lt;/dl&gt; &lt;h2&gt;&lt;a name="verification"&gt;The question of verification&lt;/a&gt;&lt;/h2&gt; &lt;dl&gt; &lt;dd&gt;The lightweight approaches depend on a trusted kernel. How to make sure the trusted library deserves our trust? The same question exists for any other dependent-type system: how we make sure that our Oracle is correct, the typing rules are correct, and, mainly, that the implementation of those rules in a &lt;em&gt;compiler&lt;/em&gt; is correct? &lt;p&gt;I have heard a similar question asked of J. Strother Moore and J. Harrison. J. Strother Moore said that most of ACL2 is built by bootstrapping, from lemmas and strategies that ACL2 itself has proven. However, the core of ACL2 just has to be trusted. ACL2 has been used for quite a while and so there is a confidence in its soundness. NSA and NIST found this argument persuasive when they accepted proofs by ACL2 as evidence of high assurance, in awarding Orange book A1 and IFIPS 140-1 ratings -- the highest security ratings -- to some products. &lt;/p&gt;&lt;p&gt;In general, verification is a rather complex issue, far beyond the mere checking of the derivations of formal propositions: see the references below. Even in Mathematics, it is not at all resolved what exactly constitutes a mathematical proof and how much trust, including personal trust, is involved.&lt;/p&gt;&lt;/dd&gt; &lt;dt&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/dt&gt; &lt;dd&gt;Randy Pollack: How to believe a machine-checked proof &lt;p&gt;Toby Murray, P.C. van Oorschot. BP: Formal Proofs, the Fine Print and Side Effects&lt;br&gt; Awarded `the best paper' at IEEE SecDev 2018&lt;br&gt; ``We consider what value proofs about software systems deliver to end-users (e.g., in terms of net assurance benefits), and at what cost in terms of side effects (such as changes made to software to facilitate the proofs, and assumption-related deployment restrictions imposed on software if these proofs are to remain valid in operation).'' In short, this is the paper on how to believe in a formal (security) proof and what value it actually offers. &lt;/p&gt;&lt;p&gt;Arthur Jaffe, Frank Quinn: ``Theoretical mathematics'': Toward a cultural synthesis of mathematics and theoretical physics&lt;br&gt; Bull.Am.Math.Soc. 29 (1993) 1-13 &amp;lt;&lt;a href="http://arxiv.org/abs/math.HO/9307227"&gt;http://arxiv.org/abs/math.HO/9307227&lt;/a&gt;&amp;gt;&lt;br&gt; &lt;/p&gt;&lt;p&gt;William P. Thurston: On Proof And Progress In Mathematics&lt;br&gt; Bull.Am.Math.Soc. 30 (1994) 167-177 &amp;lt;&lt;a href="http://arxiv.org/abs/math.HO/9404236"&gt;http://arxiv.org/abs/math.HO/9404236&lt;/a&gt;&amp;gt;&lt;br&gt; &lt;/p&gt;&lt;p&gt;Michael Atiyah, Armand Borel, G. J. Chaitin, Daniel Friedan, James Glimm, Jeremy J. Gray, Morris W. Hirsch, Saunder MacLane, Benoit B. Mandelbrot, David Ruelle, Albert Schwarz, Karen Uhlenbeck, Rene' Thom, Edward Witten, Christopher Zeeman: Responses to ``Theoretical Mathematics: Toward a cultural synthesis of mathematics and theoretical physics'', by A. Jaffe and F. Quinn&lt;br&gt; Bull.Am.Math.Soc. 30 (1994) 178-207. &amp;lt;&lt;a href="http://arxiv.org/abs/math.HO/9404229"&gt;http://arxiv.org/abs/math.HO/9404229&lt;/a&gt;&amp;gt; &lt;/p&gt;&lt;p&gt;Arthur Jaffe, Frank Quinn: Response To Comments On ``Theoretical Mathematics''&lt;br&gt; Bull.Am.Math.Soc. 30 (1994) 208-211. &amp;lt;&lt;a href="http://arxiv.org/abs/math/9404231"&gt;http://arxiv.org/abs/math/9404231&lt;/a&gt;&amp;gt; &lt;/p&gt;&lt;/dd&gt;&lt;/dl&gt; &lt;h2&gt;&lt;a name="range-analysis"&gt;Lightweight guarantees and static analyses&lt;/a&gt;&lt;/h2&gt; &lt;dl&gt; &lt;dd&gt;When the code for the safe and efficient binary search was first posted on the Haskell mailing list in August 2004, a lively discussion followed. In particular, Bjoern Lisper asked about the relation to classical range analyses known for a long time for imperative languages. &lt;p&gt;First of all, within the divide ``making sense of already written programs v. writing only those programs that make sense'', range analysis, as other static verification, belongs to the first group&amp;nbsp;-- whereas types, model-driven development, refinement and lightweight guarantees belong to the second. &lt;/p&gt;&lt;p&gt;Mainly, lightweight guarantees, or language protection layer, lets us implement the classical range analyses in a program itself&amp;nbsp;-- and be sure of their outcome. In contrast, analyses in the compiler cannot be easily seen or controlled, and their outcome is often hard to detect and explain. &lt;/p&gt;&lt;p&gt;Let's take an example: locating the first element of an array satisfying a given predicate and returning its index. &lt;/p&gt;&lt;pre&gt; let findarr : type a. (a -&amp;gt; bool) -&amp;gt; a array -&amp;gt; int option = fun p arr -&amp;gt; let n = Array.length arr in let rec loop i = if i &amp;lt; n then if p (arr.(i)) then Some i else loop (succ i) else None in loop 0 &lt;/pre&gt;The classical range analysis will see that &lt;code&gt;i&lt;/code&gt; starts at the lower bound of &lt;code&gt;arr&lt;/code&gt;, i.e., zero, and is incremented afterwards. When the analysis sees the test &lt;code&gt;i&amp;lt;n&lt;/code&gt; it infers that in the `then' branch of that test &lt;code&gt;i&lt;/code&gt; does not exceed the upper bound of the array. Therefore, the indexing operation &lt;code&gt;arr.(i)&lt;/code&gt; is safe and the run-time range check may be elided. &lt;p&gt;In the lightweight guarantees framework the code looks as follows (see the reference to the complete code below): &lt;/p&gt;&lt;pre&gt; let findarr' : type a. (a -&amp;gt; bool) -&amp;gt; a array -&amp;gt; int option = fun p arr -&amp;gt; let module M = LenF(struct type el=a let arr=arr end) in let open M in let rec loop i = match cmp i length with | Some i' -&amp;gt; if p (get M.arr i') then Some (i' :&amp;gt; int) else loop (Nat.succ i) | _ -&amp;gt; None in loop Nat.zero &lt;/pre&gt;The programmer gives the array, array length and &lt;code&gt;i&lt;/code&gt; more precise types: &lt;code&gt;M.arr&lt;/code&gt; has the type &lt;code&gt;a array M.len&lt;/code&gt;, &lt;code&gt;length&lt;/code&gt; has the type &lt;code&gt;int M.len&lt;/code&gt;, and &lt;code&gt;i:nat&lt;/code&gt;. Here &lt;code&gt;M.len&lt;/code&gt; is an `annotation' (erased at run-time) that an object has the length &lt;code&gt;len&lt;/code&gt;. We should stress that the comparison of &lt;code&gt;i&lt;/code&gt; with the array length no longer returns a mere boolean. The type of &lt;code&gt;cmp&lt;/code&gt; is &lt;pre&gt; nat -&amp;gt; int M.len -&amp;gt; (nat M.len) option &lt;/pre&gt;If the comparison &lt;code&gt;cmp i length&lt;/code&gt; succeeds, the result is &lt;code&gt;M.len&lt;/code&gt;-annotated &lt;code&gt;i&lt;/code&gt;, which is in bounds of the array &lt;code&gt;M.arr&lt;/code&gt;. The successful comparison `improves &lt;code&gt;i&lt;/code&gt;'s type', so to speak, making it more precise. Thus the logical implication that was implicit in the range checker is made explicit to the type checker here. &lt;p&gt;Bjoern Lisper further wrote ``A program analysis like range analysis is not exact, of course: it must make safe approximations sometimes and will sometimes say that an array index might be out of bounds when it actually won't. In your framework, this seems to correspond to the fact that you must verify your propositions about index expressions.'' &lt;/p&gt;&lt;p&gt;True, just as the range analysis must verify the rules of the analysis. The difference is that the conventional range analyzer is part of a compiler, typically hidden from view (of a regular programmer). Here, the analyzer is part of a library. &lt;/p&gt;&lt;p&gt;The need for approximations may also arise in our framework. Suppose that in the original &lt;code&gt;findarr&lt;/code&gt; code, the line &lt;/p&gt;&lt;pre&gt; if p (arr.(i)) then Some i ... &lt;/pre&gt;had been replaced with &lt;pre&gt; let j = very_complex_function i in if p (arr.(j)) then Some j ... &lt;/pre&gt;Although the analysis may know that &lt;code&gt;i&lt;/code&gt; is within array bounds, it may be very difficult to ascertain if &lt;code&gt;j&lt;/code&gt; is. The classical analysis may give up and insert a run-time check (often without any indications it is done so). In our framework, we have to &lt;pre&gt; let j = very_complex_function (i':&amp;gt;int) in match range_check j with | Some j' -&amp;gt; if p (arr.(j')) then Some (j':&amp;gt;int) ... | None -&amp;gt; on_out_of_range &lt;/pre&gt;That is, we intentionally forget the more precise typing of &lt;code&gt;i'&lt;/code&gt;, do the complex index transformation, followed by a run-time witnessing to recover the precise typing. We now have to handle the situation if the result of &lt;code&gt;very_complex_function (i':&amp;gt;int)&lt;/code&gt; is out of range. If we somehow know that the &lt;code&gt;very_complex_function&lt;/code&gt; keeps the result within the range, but do not have the time to verify or prove it, we can replace &lt;code&gt;on_out_of_range&lt;/code&gt; with &lt;code&gt;assert false&lt;/code&gt;. In any case, the fact that we gave up on the precise analysis is very explicit, and so is the dynamic check we had to insert. &lt;p&gt;Incidentally, if we can prove that &lt;code&gt;very_complex_function&lt;/code&gt; leaves the index in range, then we can give the function a more precise type: &lt;code&gt;nat M.len -&amp;gt; nat M.len&lt;/code&gt; and put into the trusted kernel, after the appropriate rigorous verification.&lt;/p&gt;&lt;/dd&gt; &lt;dt&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/dt&gt; &lt;dd&gt;&lt;a href="http://okmij.org/ftp/Computation/lightweight-guarantees/range-check-expl.ml"&gt;range-check-expl.ml&lt;/a&gt;&amp;nbsp;[3K]&lt;br&gt; The complete OCaml code for the example &lt;p&gt;Thread &lt;cite&gt;Re: [Haskell] Eliminating Array Bound Checking through Non-dependent types&lt;/cite&gt; on the Haskell mailing, August 4-8 2004 &lt;/p&gt;&lt;/dd&gt;&lt;/dl&gt; &lt;h2&gt;&lt;a name="deptype"&gt;Lightweight guarantees and dependent types&lt;/a&gt;&lt;/h2&gt; &lt;dl&gt; &lt;dd&gt;We have seen that type abstraction lets attribute an invariant (a proposition) to the values of an abstract type&amp;nbsp;-- e.g., all values of the type represent integers within a certain range. There is a clear similarity with dependent types. &lt;p&gt;A dependent type expresses the proposition about the values of the type directly (using the language of logic), whereas an abstract type merely &lt;em&gt;refers&lt;/em&gt; to the proposition. The difference is akin to that between a golden coin and paper money. The coin has its worth in the gold it carries. It is relatively easy to compare and exchange coins of different coinages, based on the weight and purity of their gold. Paper money merely refers to worth, and requires trusted institutions (state, banks) to operate. Comparing paper money of different issuers is non-trivial. Still, we know from history that an economy based on paper money is viable. &lt;/p&gt;&lt;p&gt;In the discussion thread following the first presentation of the lightweight guarantees approach in August 2004, Conor McBride has made an excellent summary of this approach and its relation to genuine dependent types: ``The abstract &lt;code&gt;brand&lt;/code&gt; is just a type-level proxy for the bounding interval, and the library of operations provides interval-respecting operations on indices. This is a very neat solution in Haskell, but it goes round an extra corner which isn't necessary with dependent types, where you can just talk about the interval directly. The library-writer would develop and verify the same convenient operations for working with intervals and indices; the proofs would be independently recheckable terms in type theory.''&lt;/p&gt;&lt;/dd&gt; &lt;dt&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/dt&gt; &lt;dd&gt;Extensive discussion with Conor McBride, with his many insights and explanations of dependent-type programming. Haskell mailing list, August 6-9, 2004. Thread: &lt;cite&gt;Re: Eliminating Array Bound Checking through Non-dependent types&lt;/cite&gt; &lt;/dd&gt;&lt;/dl&gt; &lt;h2&gt;&lt;a name="conclusion"&gt;Conclusions&lt;/a&gt;&lt;/h2&gt; &lt;dl&gt; &lt;dd&gt;We have demonstrated the programming style that ensures safety without sacrificing efficiency. The key idea is a language protection layer (specifically, type abstraction), which lets us restrict access to some operations on data. Operations that preserve a desired invariant may be accessed `publicly'; the other, potentially invariant-destroying operations, may only be invoked within a (usually small) `trusted kernel', where the invariant is assured by careful code inspection or in some formal way. All in all, the invariants established by &lt;em&gt;local&lt;/em&gt; reasoning are preserved &lt;em&gt;globally&lt;/em&gt;. The globally-valid invariants (such as sortedness, range limit, etc) then guarantee safe execution of the program and let us elide run-time safety checks. &lt;p&gt;&lt;em&gt;Safe and Efficient&lt;/em&gt; can be practiced right now. In fact, the main idea was proposed by Milner and Morris in the mid-1970s, and was shown to work already then. I personally have been using it successfully, in production and in answering challenges. Further challenges and suggestions are welcome.&lt;/p&gt;&lt;/dd&gt;&lt;/dl&gt; &lt;/div&gt;&lt;a href="http://okmij.org/ftp/Computation/lightweight-static-guarantees.html"&gt;Source&lt;/a&gt;
      </description>
      <pubDate>
        Tue, 9 Feb 2021 09:27:20 UT
      </pubDate>
      <guid>
        http://okmij.org/ftp/Computation/lightweight-static-guarantees.html
      </guid>
    </item>
  </channel>
</rss>