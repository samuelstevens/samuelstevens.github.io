{"items":[{"id":"https://www.executeprogram.com/","content_text":null,"title":"Execute Program","date_published":"2020-03-24T12:18:12-00:00"},{"id":"https://setosa.io/blog/2014/07/26/markov-chains/index.html","content_text":"\nMarkov chains, named after Andrey Markov, are mathematical systems that hop from one \"state\" (a situation or set of values) to another. For example, if you made a Markov chain model of a baby's behavior, you might include \"playing,\" \"eating\", \"sleeping,\" and \"crying\" as states, which together with other behaviors could form a 'state space': a list of all possible states. In addition, on top of the state space, a Markov chain tells you the probabilitiy of hopping, or \"transitioning,\" from one state to any other state---e.g., the chance that a baby currently playing will fall asleep in the next five minutes without crying first.\n\nA simple, two-state Markov chain is shown below.\n\n\n\nWith two states (A and B) in our state space, there are 4 possible transitions (not 2, because a state can transition back into itself). If we're at 'A' we could transition to 'B' or stay at 'A'. If we're at 'B' we could transition to 'A' or stay at 'B'. In this two state diagram, the probability of\ntransitioning from any state to any other state is 0.5.\n\nOf course, real modelers don't always draw out Markov chain diagrams. Instead they use a \"transition matrix\" to tally the transition probabilities. Every state in the state space is included once as a row and again as a column, and each cell in the matrix tells you the probability of transitioning from its row's state to its column's state. So, in the matrix, the cells do the same job that the arrows do in the diagram.\n\n\n\nIf the state space adds one state, we add one row and one column, adding one cell to every existing column and row. This means the number of cells grows quadratically as we add states to our Markov chain. Thus, a transition matrix comes in handy pretty quickly, unless you want to draw a jungle gym Markov chain diagram.\n\nOne use of Markov chains is to include real-world phenomena in computer simulations. For example, we might want to check how frequently a new dam will overflow, which depends on the number of rainy days in a row. To build this model, we start out with the following pattern of rainy (R) and sunny (S) days:\n\n\n\nOne way to simulate this weather would be to just say \"Half of the days are rainy. Therefore, every day in our simulation will have a fifty percent chance of rain.\" This rule would generate the following sequence in simulation:\n\n\n\nDid you notice how the above sequence doesn't look quite like the original? The second sequence seems to jump around, while the first one (the real data) seems to have a \"stickyness\". In the real data, if it's sunny (S) one day, then the next day is also much more likely to be sunny.\n\nWe can minic this \"stickyness\" with a two-state Markov chain. When the Markov chain is in state \"R\", it has a 0.9 probability of staying put and a 0.1 chance of leaving for the \"S\" state. Likewise, \"S\" state has 0.9 probability of staying put and a 0.1 chance of transitioning to the \"R\" state.\n\n\n\nIn the hands of metereologists, ecologists, computer scientists, financial engineers and other people who need to model big phenomena, Markov chains can get to be quite large and powerful. For example, the algorithm Google uses to determine the order of search results, called PageRank, is a type of Markov chain.\n\n\n\nAbove, we've included a Markov chain \"playground\", where you can make your own Markov chains by messing around with a transition matrix. Here's a few to work from as an example: ex1, ex2, ex3 or generate one randomly. The transition matrix text will turn red if the provided matrix isn't a valid transition matrix. The rows of the transition matrix must total to 1. There also has to be the same number of rows as columns.\n\nYou can also access a fullscreen version at setosa.io/markov\n\n\n\n","title":"Markov Chains","date_published":"2020-03-24T12:18:48-00:00"},{"id":"https://www.lesswrong.com/posts/FCXCXigp7byv2dM8D/how-to-make-billions-of-dollars-reducing-loneliness","content_text":"Loneliness Is a Big Problem\nOn Facebook, my friend Tyler writes:\n\nLately, I've been having an alarming amount of conversations arise about the burdens of loneliness, alienation, rootlessness, and a lack of belonging that many of my peers feel, especially in the Bay Area. I feel it too. Everyone has a gazillion friends and events to attend. But there's a palpable lack of social fabric. I worry that this atomization is becoming a world-wide phenomenon – that we might be some of the first generations without the sort of community that it's in human nature to rely on.\n\n\nAnd that the result is a worsening epidemic of mental illness...\n\n\nWithout the framework of a uniting religion, ethnicity, or purpose, it's hard to get people to truly commit to a given community. Especially when it's so easy to swipe left and opt for things that offer the fleeting feeling of community without being the real thing: the parties, the once-a-month lecture series, the Facebook threads, the workshops, the New Age ceremonies. We often use these as \"community porn\" – they're easier than the real thing and they satisfy enough of the craving. But they don't make you whole.\n\n\nI've had some thoughts about experiments to try. But then I think about how hard it is (especially in this geographic area) to get people to show up to something on at least a weekly basis. Even if it's for something really great. I see many great attempts at community slowly peter out.\n\nYoung people are lonely.  Old people are lonely.\nLoneliness is bad for your health.  It's bad for society's health.\nHaving a smartphone that keeps you entertained all day, and enough money to live by yourself, might sound like first world problems.  But they are likely contributors to loneliness.  And as developing countries get richer, they'll start having first world problems too.  So I think addressing loneliness could be very high-leverage for the world.\nPeople are starting businesses to address loneliness: you can pay someone to call you periodically or take you for a walk.  But I'd argue these services are a band-aid in the same sense that parties, workshops, and ceremonies are.  They don't solve the underlying problem: You're still alone by default instead of together by default.\nRoommates Could Be a Great Solution\nSociologists think there are three conditions necessary for making friends: proximity; repeated, unplanned interactions; and a setting that encourages people to let their guard down and confide in each other.  These conditions tend to be present during college for many people, but not afterwards.\nWhy do people find it easier to make friends in college?  Maybe it's because college students don't usually live alone.\nGoing to events doesn't work because (a) you don't typically get repeated interactions with the same person and (b) events take place at a scheduled time.  Which may or may not be a time you're feeling lonely.\nIf you have a lot of roommates, all you have to do is step outside your room and find someone to chat with.  No transportation CO2 emissions needed.  But more important, you know your roommates are always gonna be around.\nBut I Already Have Roommates\nEven if you already have roommates, I think there's a good chance your roommate situation is under-optimized.  Given that you spend so much time with them, there's a lot of value in living with people you really connect with.  (Finding great coworkers makes sense for similar reasons.)\nThe layout of your house and the number of roommates you have can also make a big difference.  I used to have friends living in a 4-bedroom place where all the bedrooms opened directly into a single large common area.  If anyone else was outside their room, you'd immediately know it and have an opportunity for interaction.  Later I lived in an 8-bedroom place which felt far lonelier, even with every room occupied.  The house was laid out so it was easy to go about your day without ever running into a fellow roommate.  I also lived in a house with over 50 bedrooms for a while, which was wild & a lot of fun.\nBut I Don't Want Roommates\nOne reason you might not want roommates is because you're worried you might have conflicting preferences for what living together should be like.  For example, my philosophy towards dirty dishes is to let them pile up on the counter and periodically stuff them all in the dishwasher, to be as time-efficient as possible.  Surprisingly, some people dislike this approach.\nRoomieMatch.com is a website which tries to solve the roommate compatibility problem.  You create a profile by answering questions about dishes, food in the fridge, housecleaning, social events, noise, overnight guests, shared household items, walking around in your underwear, TV, etc.  In addition, there are questions to help predict how you well you will connect as people.\nYou Could Make a Lot of Money\nRoomieMatch has two search options: free and cheap.  Cheap costs $20/year.\nThe problem with RoomieMatch is they're leaving a massive amount of money on the table.\nA few years ago, a friend of mine was jobless & struggling financially.  He was living in a 4-bedroom house at the time, and he was the primary contact with the landlord.  My friend took responsibility for vetting folks from Craigslist in order to fill the remaining rooms in the house.  He found that folks from Craigslist were willing to pay enough rent for the remaining 3 rooms that he was able to live rent-free until he found a job.\nI acknowledge this is murky ethical territory, and I'm not condoning my friend's actions.  (I don't believe anyone ever found out or got upset, for whatever that's worth.)  The point I'm trying to make is that property management is way more lucrative than roommate matching.  RoomieMatch makes $20 per user per year at best.  My friend was making $100+ per user per month.\nWhat I'm suggesting is that you take the full-stack startup playbook which has been successful in Silicon Valley recently, and apply it to online roommate matching + property management.\nThe extreme full-stack approach is to own your own properties.  Apparently the US has a surplus of big houses right now.\nThere are already players in this space such as Roam which are proving that people will pay for community.  (As if people paying extra to live in hip cities like SF & NYC didn't prove that already.  BTW, I found that the awesome community at the Athena Hotel more than made up for the fact that it's in a non-hip city.)  Anyway, I think existing players are mostly pursuing the extreme full-stack option.  I actually think this is the wrong play.  You want to be a marketplace, like Airbnb (valued at over $30 billion).  The more people who are using your tool, the finer-grained roommate matching services you can provide.  It's hard to achieve massive scale if you have to own every property.  You want to be playing matchmaker for individuals with common interests who all happen to be looking for rooms around the same time, plus landlords with empty houses.  Maybe you'll want to undercut RoomieMatch, and provide free matching services for people who live in their properties, in order to achieve the necessary scale.  (RoomieMatch's existing scale is impressive by the way--I quickly got 100+ active, vetted matches in a midsize US city when I tried the tool.  If you have the money you might want to just buy it.)\nSo instead of buying properties, maybe you just want to contact people selling large homes & see if you can convince them to let you manage their property.\nNote that this is a good company to start if a recession happens, since people who currently live alone will be thinking about how to save on rent.\nThis Could Be Really Great\nMost roommate search tools, like Craigslist, don't make it easy to figure out if a future roommate is someone you'd actually want to live with.  Imagine reaching a scale where you could match people based on factors like:\n\n\nThey love to play board games, or pool, or Super Smash Bros.\n\n\nThey want a compost pile and a garden in their backyard.\n\n\nOne has a pet, and the other likes animals but isn't yet ready to make a lifetime commitment.\n\n\nThey want a squat rack in the basement to save time & money going to the gym.\n\n\nThey want to continue partying like college students after graduation.\n\n\nThey want to be part of an intentional community devoted to mutual improvement and life optimization, or spirituality, or whatever.\n\n\nThey want to share childcare responsibilities.\n\n\nThey're all fans of the same sports team.\n\n\nThey enjoy reading and discussing the same genre of novels, or watching the same movies.\n\n\nThey're musicians looking for people to jam with.\n\n\nThey want to live near hiking trails and go on group hikes together.\n\n\nThey want to do independent study of the same topic.\n\n\nThey're trying to eat a healthier diet.\n\n\nThey just moved to a new city and want friends they can explore the city with.\n\n\nThey have the same unusual work schedule.\n\n\nOne needs a caretaker, and the other wants to make extra money.\n\n\nThey like the idea of having a couch or two listed on CouchSurfing.\n\n\nOne knows a language the other wants to learn.\n\n\nThey work close together in the same expensive metropolitan area and want save on housing.  So they live in the outskirts of the city and commute together every day using the diamond lane.  One drives and the other pays for gas.\n\n\nI also see opportunities to reduce friction in the current roommate matching process:\n\n\nAutomatically find times when everyone is available for a meet & greet video call.\n\n\nLet people take virtual tours of the houses on offer to minimize driving.\n\n\nNo need to worry about breaking a lease if someone moves to a different house in your company's network.  Let people try out a few communities & see what works for them.  Use machine learning to improve your matching as you gather more data.\n\n\nProvide external mediation in the event of roommate disputes, and have a reputation system to encourage good behavior.\n\n\nYou aren't providing housing as a service (like Airbnb), or companionship as a service (like the people-walking startup).  You're providing community as a service.  You could even organize mixers across your houses.\nConclusion\nTechnology has been blamed for the loneliness epidemic, but I think we can use technology to cure the loneliness epidemic as well.\nI'm too busy being obsessed with machine learning to start any company which isn't mostly about that.  But I think this is a product the world needs, and I want you to build it.  I encourage you to sign the Founders Pledge and donate the money to effective charities in case you actually end up making billions of dollars as a result of reading this.\nI apologize if you found the tone of this post overly sales-y.  My goal was to light a spark in the right person.  (Feel free to steal phrases from this post when pitching investors!)\nSome folks in the rationalist community might be a little underwhelmed by this idea, since people in the rationalist community have been living together in group houses for a long time.  The thing is, finding roommates by connecting based on mutual interests via the internet is still kind of weird in the eyes of the general public.  As Paul Graham put it: \"Live in the future, then build what's missing.\"  The existence of so many lonely people proves that this option is still missing for most people.\nAnyway, if you're interested in building/investing in this, please comment below, or send me a private message via my user page with the country you're in and I'll put you in contact with others who message me.  (Edit: I might be slow to reply, sorry)\nCross-posted from the Effective Altruism Forum.  See also discussion on Hacker News.\n","title":"","date_published":"2020-03-24T12:22:01-00:00"},{"id":"https://sahandsaba.com/understanding-sat-by-implementing-a-simple-sat-solver-in-python.html","content_text":"\n    \n        \n            Understanding SAT by Implementing a Simple SAT Solver in Python\n        \n    \n\n    \n\n    \n      \nIntroduction\nSAT is short for \"satisfiability\". Chances are you have heard of it or one of\nits variants like 3-SAT in passing, especially in discussions of complexity and\nNP-completeness. In this post, we will go into details of what it is all about,\nwhy it is of such importance from both a theoretical and practical perspective,\nand how to approach solving it by developing a simple Python SAT solver.  By\nthe end of this post, we will have a working SAT solver with a command-line\ninterface. The code for it is on GitHub: https://github.com/sahands/simple-sat. Feel free to fork and contribute\nimprovements. Of course, our implementation will not be anywhere close to more\ncomplicated SAT solvers implemented in C or C++, such as miniSAT. The focus here is on simplicity since\nthe code is to be an introduction to SAT and SAT solvers.\nSections marked with * are more theoretical and not required for\nunderstanding the algorithm we will use. On the other hand, the rest of the\nintroduction section below can be skipped if you already know the problem\ndefinition and relevant technical terms.\n\nNon-Technical Definitions & Example\nBefore we start with the definitions, you might be asking why SAT is written in\nall capitals if it is not an acronym.  Well, great question. SAT happens to\nfall under what are called decision problems in computer science. What that\nmeans is that the answer to a particular instance of the problem is either\n\"yes\" or \"no\". Decision problems are often simply identified with the set of\ninputs for which the answer is \"yes\", and that set is given a capitalized name.\nFor example, SAT is the set of all satisfiable CNF expressions, and PRIMES is\nthe set of all prime numbers (the decision problem in the latter is that of\nprimality; i.e. given the binary representation of number nn\n\n, decide if\nit is a prime or not). To go on a bit of a tangent, this is also the reason\nthat the title of the paper that introduced the AKS primality test (\"PRIMES is\nin P\") is\nnot a silly grammar mistake; PRIMES is a set and the paper shows that it is in\nP, which is the set of decision problems solvable in polynomial-time. This\nnaming style, as far as I know, is mainly due to Garey and Johnson's classic\ntextbook on complexity theory.\nSo, back to SAT. So far we mentioned that SAT is a decision problem, and\nsomething about mysterious sounding \"CNF expressions\". Now, if you happen to\nknow your Boolean logic and already know all about satisfiability and CNF\nexpressions, then feel free to skip ahead to next section. The rest of this\nsection assumes no prior knowledge of logic. Like many other interesting\nproblems, there are a variety of ways of describing SAT, some more technical\nand some less. Here I will provide a very non-technical description of the\nproblem that nonetheless is an accurate description.\nAssume you are in charge of elections in a society. Elections in this society\nwork as follows: there are nn\n\n candidates, and any number of them, from\n00\n\n (nobody) to nn\n\n (everybody) can be elected as the result of the\nelections. Each voter provides a list of candidates they want elected and\ncandidates they want not elected. For example, if we call the candidates A, B\nand C, then one vote might be \"A, B, not C\". We say a voter will be satisfied\nwith the results of the election if at least one of his/her preferences is met.\nFor example, the voter with the \"A, B, not C\" vote will be satisfied if either\nA or B is elected, or if C is not elected. To be clear, that voter will be\nhappy even if nobody is elected (anarchy!) because one of the preferences is\n\"not C\" which is met if we do not pick anyone. It's also possible to receive an\nempty vote. We take this to mean that the voter will not be satisfied\nregardless of who is elected.\nYou are given all the votes, and your job is to determine if all the voters can\nbe satisfied or not, and if yes, provide at least one possible pick of\ncandidates that would satisfy everybody.\nWe assume that each candidate is represented by a unique identifier that will\nbe a string in the input. For the votes, we will write just the string\nrepresenting candidate xx\n\n to indicate the voter wants the candidate\nelected, and ∼x\\sim{}x\n\n to indicate the voter wants xx\n\n not elected.\nLet's look at an example. Assume the list of votes is given as follows, one per\nline:\n\nThen choosing to elect just candidates AA\n\n and CC\n\n but not\nBB\n\n will satisfy all the voters. Take a moment to convince yourself that\nno other choice of candidates (there are a total of 23=82^3 = 8\n\n\npossibilities) can satisfy everyone. It is easy to see that in general\nthe search-space is of size 2n2^n\n\n where nn\n\n is the number of\ncandidates.\n\n\nTechnical Terminology\nNow that the problem makes sense, let's define the technical\nvocabulary. First, what we called \"candidates\" are called variables. The\nvariables in the above example are AA\n\n, BB\n\n and CC\n\n. A\nvariable can be assigned true or false. A literal is a variable or its\nnegation. For example AA\n\n and ∼A\\sim A\n\n are literals.  Literals\nwithout the ∼\\sim\n\n are called positive, pure, or unnegated literals.\nLiterals with ∼\\sim\n\n are called negated literals. A set of literals is\ncalled a clause. An assignment is a mapping of variables to true or false.\nFor example, the assignment that satisfied the clauses in the previous example\nwas given by A=trueA = true\n\n, B=falseB = false\n\n and C=trueC = true\n\n. A clause\nis satisfied by an assignment if at least one of its unnegated literals is\nassigned true by the assignment, or one of its negated literals is assigned\nfalse in the assignment.  It is customary, in logic notation, to separate the\nliterals in a clause using the ∨\\vee\n\n symbol, read \"or\". For example, the\nfirst clause above is written as A∨B ∨∼CA \\vee B ~ \\vee \\sim C\n\n in mathematical\nnotation.\nSo SAT can be summarized as follows: given a list of clauses, determine if\nthere exists an assignment that satisfies all of them simultaneously.\nIt is also worthy of mention that there is a variation of SAT called 3-SAT with\nthe restriction that each clause consists of at most 3 (distinct) literals.\nIt can be shown with relative ease that SAT is in fact reducible to 3-SAT.\n\n\n\nA Simple SAT Solver In Python\nEven though SAT is NP-complete and therefore no known polynomial-time algorithm\nfor it is (yet) known, many improvements over the basic backtracking algorithms\nhave been made over the last few decades. However, here we will look at one of\nthe most basic yet relatively efficient algorithms for solving SAT. The encoding\nand the algorithm are based on Knuth's SAT0W program which you can download\nfrom his programs page.\nThe algorithm is a watch-list based backtracking algorithm. What makes the\nwatch-list based algorithms particularly simple, as we will see, is that very\nlittle (practically nothing) needs to be done to \"undo\" steps taken when we\nneed to backtrack.\n\nParsing & Encoding The Input\nBefore we can approach solving a SAT instance, we need to be able to represent\nthe instance in memory. Let's remember that a SAT instance is a set of clauses,\nand each clause is a set of literals. Finally, a literal is a variable that is\neither negated or not. Of course, we can just store the instance as a list of\nclauses, with each clause being a list of strings that are the literals. The\nproblem with this approach is that we will not be able to quickly look up\nvariables, and checking to see if a literal is negated or not, and negating it\nif not, would be rather slow string operations.\nInstead, we will first assign a unique number, starting from 00\n\n and\ncounting up, to each variable as we encounter them, using a dictionary to keep\ntrack of the mapping. So variables will be encoded as numbers 00\n\n to\nn−1n-1\n\n where nn\n\n is the number of variables.  Then for an unnegated\nliteral with variable encoded as number xx\n\n we will encode the literal as\n2x2x\n\n, and the negated one will be 2x+12x + 1\n\n. Then a clause will\nsimply be a list of numbers that are the encoded literals, and\nLet's look at an example first. For this, let's see how the code that we will\nlook at in a minute behaves:\n>>> from satinstance import SATInstance\n>>> s = SATInstance()\n>>> s.parse_and_add_clause('A B ~C')\n>>> s.variables\n['A', 'B', 'C']\n>>> s.variable_table\n{'A': 0, 'C': 2, 'B': 1}\n>>> s.clauses\n[(0, 2, 5)]\n\nSo as you see, the clause A∨B∨∼CA \\vee B \\vee \\sim C\n\n is encoded as the tuple\n(0, 2, 5) since variable AA\n\n is assigned number 00\n\n, and hence\nliteral AA\n\n is 2⋅0=02 \\cdot 0 =0\n\n. On the other hand, ∼C\\sim C\n\n is\nencoded as 55\n\n since CC\n\n is assigned 22\n\n and hence\n∼C\\sim C\n\n is encoded as 2⋅2+1=52 \\cdot 2 + 1 = 5\n\n.\nWhy the funny encoding, you ask? Because it has a few advantages:\n\nwe can keep track of variables by keeping a list of length nn\n\n, and of\nliterals by keeping a list of length 2n2n\n\n,\nchecking to see if a literal is negated or not is simple: just do a bit-wise\nAND with 11\n\n, that is x & 1 == 0,\nlooking up the variable in a literal is a matter of dividing by two, which is\nthe same as a bit-wise shift to the right, that is v = x >> 1,\nswitching a literal from negated to unnegated and back can be done by doing a\nbit-wise XOR with the number one, that is negate(x) = x ^ 1,\nand finally going from a variable to a literal can be done by doing a\nbit-wise shift to the right (and a bit-wise OR with 1 if negated), that is\nx = v << 1 or x = v << 1 | 1.\n\nNotice that all of the above can be done using bit-wise operations which are\ngenerally very fast to do. And since these operations will be happening an\nexponential number of times, we will take any performance boost we can get.\nWith this, we are ready to write the code that takes care of reading an input\nfile and encoding the clauses. Here it is:\nclass SATInstance(object):\n    def parse_and_add_clause(self, line):\n        clause = []\n        for literal in line.split():\n            negated = 1 if literal.startswith('~') else 0\n            variable = literal[negated:]\n            if variable not in self.variable_table:\n                self.variable_table[variable] = len(self.variables)\n                self.variables.append(variable)\n            encoded_literal = self.variable_table[variable] << 1 | negated\n            clause.append(encoded_literal)\n        self.clauses.append(tuple(set(clause)))\n\n    def __init__(self):\n        self.variables = []\n        self.variable_table = dict()\n        self.clauses = []\n\n    @classmethod\n    def from_file(cls, file):\n        instance = cls()\n        for line in file:\n            line = line.strip()\n            if len(line) > 0 and not line.startswith('#'):\n                instance.parse_and_add_clause(line)\n        return instance\n\n    def literal_to_string(self, literal):\n        s = '~' if literal & 1 else ''\n        return s + self.variables[literal >> 1]\n\n    def clause_to_string(self, clause):\n        return ' '.join(self.literal_to_string(l) for l in clause)\n\n    def assignment_to_string(self, assignment, brief=False, starting_with=''):\n        literals = []\n        for a, v in ((a, v) for a, v in zip(assignment, self.variables)\n                     if v.startswith(starting_with)):\n            if a == 0 and not brief:\n                literals.append('~' + v)\n            elif a:\n                literals.append(v)\n        return ' '.join(literals)\n\nAs you can see, we also include methods here to decode variables, literals,\nclauses, and assignments. These are used for outputting logging messages as\nwell as the final solutions.\n\n\nKeeping Track Of The Assignment\nOur algorithm will be a backtracking algorithm, in which we will assign true or\nfalse to all the variables, starting from variable 00\n\n and going in order to\nvariable n−1n-1\n\n. Of course, the basic search space is of size 2n2^n\n\n but by\npruning, we will not explore the whole space (usually anyway). The assignment\nwill be kept as a list of length nn\n\n, with item at index ii\n\n being\nNone if neither true or false has been assigned variable ii\n\n, and\n00\n\n (false) or 11\n\n (true) otherwise, depending on the assignment.\nWhen we backtrack, we set the corresponding item in the assignment list back to\nNone to indicate it is no longer assigned.\n\n\nWatch-lists\nNow that we have the encoding in place, and know how to keep track of the\nassignment, let's look at the key idea of our algorithm. For each clause to be\nsatisfied, it needs to have at least one of its literals satisfied. As such, we\ncan make each clause watch one of its literals, and ensure that the following\ninvariant is maintained throughout our algorithm:\n\nInvariant\nAll watched literals are either not assigned yet, or they have been\nassigned true.\n\nWe then proceed to assign true or false to variables, starting from 00\n\n to\nn−1n-1\n\n. If we successfully assign true or false to every variable while\nmaintaining the above variant, then we have an assignment that satisfies every\nclause.\nTo maintain this invariant, any time we assign true or false to a variable, we\nensure to update the watch-list accordingly. To do this efficiently, we need to\nkeep a list of clauses that are currently watching a given literal. This is\ndone in the code below using a list of length 2n2n\n\n of double-ended queue\n(collections.deque), with each clause initially watching the first literal in\nit. The function below takes care of this setting up of the watch-list:\ndef setup_watchlist(instance):\n    watchlist = [deque() for __ in range(2 * len(instance.variables))]\n    for clause in instance.clauses:\n        # Make the clause watch its first literal\n        watchlist[clause[0]].append(clause)\n    return watchlist\n\nWhy double-ended queues instead of just a list? Short answer is that after\nexperimenting, I found out that double-ended queues provided the best\nperformance.\nBack to the algorithm, whenever we assign true to a variable xx\n\n we must\nmake clauses watching ∼x\\sim x\n\n watch something else. And\nsimilarly, whenever we assign false to a variable xx\n\n we make clauses watching\nxx\n\n watch something else. If we can not make a clause watch something, which\nhappens when all the other literals in a clause have already been assigned\nfalse, then we know that the current assignment contradicts the clause, and we\nstop and backtrack. We only need one clause to be contradicted to know not to\ngo any further. As such, the heart of our algorithm will be where we update the\nwatch-list after an assignment has been made. The Python function below, which\nis in (watchlist.py), implements this part of the algorithm:\ndef update_watchlist(instance,\n                     watchlist,\n                     false_literal,\n                     assignment,\n                     verbose):\n    \"\"\"\n    Updates the watch list after literal 'false_literal' was just assigned\n    False, by making any clause watching false_literal watch something else.\n    Returns False it is impossible to do so, meaning a clause is contradicted\n    by the current assignment.\n    \"\"\"\n    while watchlist[false_literal]:\n        clause = watchlist[false_literal][0]\n        found_alternative = False\n        for alternative in clause:\n            v = alternative >> 1\n            a = alternative & 1\n            if assignment[v] is None or assignment[v] == a ^ 1:\n                found_alternative = True\n                del watchlist[false_literal][0]\n                watchlist[alternative].append(clause)\n                break\n\n        if not found_alternative:\n            if verbose:\n                dump_watchlist(instance, watchlist)\n                print('Current assignment: {}'.format(\n                      instance.assignment_to_string(assignment)),\n                      file=stderr)\n                print('Clause {} contradicted.'.format(\n                      instance.clause_to_string(clause)),\n                      file=stderr)\n            return False\n    return True\n\nSo why the watch-list based approach? The main reason is the simplicity it\naffords us. Since during a backtracking step, assignments only go from 00\n\n or\n11\n\n to None, the watch-list does not need to be updated at all to maintain\nthe invariant. This means the backtracking step will simply be changing the\nassignment of a variable back to None and that's it.\n\n\nPutting It All Together\nWe are now ready to put it all together to get a simple recursive algorithm for\nsolving SAT. The steps are simple: try assigning 00\n\n to variable\ndd\n\n, update the watch-list, if successful, move on to variable\nd+1d+1\n\n. If not successful, try assigning 11\n\n to variable dd\n\n\nand update the watch-list and continue to variable d+1d+1\n\n. If neither\nsucceed, assign None to variable dd\n\n and backtrack. Here is the code:\ndef solve(instance, watchlist, assignment, d, verbose):\n    \"\"\"\n    Recursively solve SAT by assigning to variables d, d+1, ..., n-1. Assumes\n    variables 0, ..., d-1 are assigned so far. A generator for all the\n    satisfying assignments is returned.\n    \"\"\"\n    if d == len(instance.variables):\n        yield assignment\n        return\n\n    for a in [0, 1]:\n        if verbose:\n            print('Trying {} = {}'.format(instance.variables[d], a),\n                  file=stderr)\n        assignment[d] = a\n        if update_watchlist(instance,\n                            watchlist,\n                            (d << 1) | a,\n                            assignment,\n                            verbose):\n            for a in solve(instance, watchlist, assignment, d + 1, verbose):\n                yield a\n\n    assignment[d] = None\n\n\n\nMaking It Iterative *\nFor fun, let's see if we can implement the above algorithm without recursion.\nThis is in fact how Knuth implements the algorithm. (He seems to dislike\nrecursion, see for example this story on Quora.)\nThe basic idea here is to manually keep track of the current state of the\nbacktrack tree. When we use recursion, the state is kept implicitly using the\nstack and which instruction is executing in each of the function calls. In the\niterative case, we will store the state using d which is the current depth\nof the backtrack tree we are currently in, and also the variable we are to\nassign to currently, and the state list which keeps track of which\nassignments for each variable have been tried so far. Here is the code:\ndef solve(instance, watchlist, assignment, d, verbose):\n    \"\"\"\n    Iteratively solve SAT by assigning to variables d, d+1, ..., n-1. Assumes\n    variables 0, ..., d-1 are assigned so far. A generator for all the\n    satisfying assignments is returned.\n    \"\"\"\n\n    # The state list wil keep track of what values for which variables\n    # we have tried so far. A value of 0 means nothing has been tried yet,\n    # a value of 1 means False has been tried but not True, 2 means True but\n    # not False, and 3 means both have been tried.\n    n = len(instance.variables)\n    state = [0] * n\n\n    while True:\n        if d == n:\n            yield assignment\n            d -= 1\n            continue\n        # Let's try assigning a value to v. Here would be the place to insert\n        # heuristics of which value to try first.\n        tried_something = False\n        for a in [0, 1]:\n            if (state[d] >> a) & 1 == 0:\n                if verbose:\n                    print('Trying {} = {}'.format(instance.variables[d], a),\n                          file=stderr)\n                tried_something = True\n                # Set the bit indicating a has been tried for d\n                state[d] |= 1 << a\n                assignment[d] = a\n                if not update_watchlist(instance, watchlist,\n                                        d << 1 | a,\n                                        assignment,\n                                        verbose):\n                    assignment[d] = None\n                else:\n                    d += 1\n                    break\n\n        if not tried_something:\n            if d == 0:\n                # Can't backtrack further. No solutions.\n                return\n            else:\n                # Backtrack\n                state[d] = 0\n                assignment[d] = None\n                d -= 1\n\n\n\n\nTheoretical and Practical Significance *\nAll right, so SAT is a cool problem, sure; possibly even useful. But why is\nit given so much importance? The short answer is that many other problems,\noften \"difficult\" problems, can be reduced to SAT. Let's consider an example\nfirst, and then look at Stephen Cook's result that established SAT as the first\nNP-complete problem, to get a sense of both practical applications of SAT, and\nits theoretical importance.\n\nFour Colouring *\nYou might have heard of the \"four colour theorem\". In simplest terms, it states\nthat the regions in any map can be coloured using at most four colours\nsuch that no two neighbouring regions are coloured the same. See the Wikipedia\npage on it for more\ndetails.\nThis lends itself to a simple decision problem: given a map, is it possible to\ncolour it using 4 or less colours such that no two neighbouring regions are\nthe same colour? The four colour theorem is then true if and only if the answer\nto this decision problem is always true (provided the input map meets the\nrequirements of a planar graph, a detail we are not too concerned with here).\nAs input, we will take the number of regions nn\n\n, and assume the regions\nare labelled using numbers 11\n\n to nn\n\n, and a list of neighbouring\nregions of the form {i,j}\\{i, j\\}\n\n with i̸=ji \\ne j\n\n, indicating regions\nii\n\n and jj\n\n are neighbours. Let us use colours red (R), blue (B),\ngreen (G), and yellow (Y) to colour the regions. Our variables are going to be\nRiR_i\n\n, BiB_i\n\n, GiG_i\n\n and YiY_i\n\n, for 1≤i≤n1 \\le i \\le\nn\n\n, indicating that region ii\n\n is coloured red, blue, green, or yellow,\nrespectively.\nNext, we need to construct the right set of clauses such that if all of\nthem are satisfied, then we have a proper colouring of the map. Specifically, we\nneed every region to be coloured, and we need no two neighbouring regions to be\nthe same colour. First, let us construct the clauses that will make sure every\nregion has one and only one colour assigned to it. For this, we need to make sure\nonly one of RiR_i\n\n, BiB_i\n\n, GiG_i\n\n or YiY_i\n\n is picked for\nour assignment at a time. We can express this in terms of  KK\n\n clauses for\neach region ii\n\n. First, we add Ri∨Bi∨Gi∨YiR_i \\vee B_i \\vee G_i \\vee Y_i\n\n as\na clause, which ensures that region ii\n\n gets at least one colour assigned\nto it. Then for pair of colours, say RR\n\n and BB\n\n, we add the clause\n∼Ri∨∼Bi\\sim R_i \\vee \\sim B_i\n\n which basically says \"not both of RiR_i\n\n\nand BiB_i\n\n can be picked at the same time\", effectively making sure that\nexactly one colour is assigned to each region. Finally, for any two\nneighbouring regions, say ii\n\n and jj\n\n, and each colour, say\nRR\n\n, we add the clause ∼Ri∨∼Rj\\sim R_i \\vee \\sim R_j\n\n which says not both\nof ii\n\n and jj\n\n can be coloured red.\nLet's look at a very simple example. Suppose our map has only two regions,\nregions 11\n\n and 22\n\n and that they are neighbours. Then our SAT\ninput would be:\n# Assign at least one colour to region 1\nR1 B1 G1 Y1\n\n# But no more than one colour\n~R1 ~B1\n~R1 ~G1\n~R1 ~Y1\n~B1 ~G1\n~B1 ~Y1\n~G1 ~Y1\n\n# Similarly for region 2\nR2 B2 G2 Y2\n~R2 ~B2\n~R2 ~G2\n~R2 ~Y2\n~B2 ~G2\n~B2 ~Y2\n~G2 ~Y2\n\n# Make sure regions 1 and 2 are not coloured the same since they are neighbours\n~R1 ~R2\n~B1 ~B2\n~G1 ~G2\n~Y1 ~Y2\n\nRunning this through our SAT solver gives:\n$ python sat.py --brief --all < tests/colouring/01.in\nY1 G2\nY1 B2\nY1 R2\nG1 Y2\nG1 B2\nG1 R2\nB1 Y2\nB1 G2\nB1 R2\nR1 Y2\nR1 G2\nR1 B2\n\nAs you can see, there are many possible solutions, since in such a simple case\nwe have a valid colouring as long as we assign a different colour to each\nregion, which can be done in 4⋅3=124 \\cdot 3 = 12\n\n ways, corresponding\nprecisely to the 1212\n\n solutions given by our SAT solver.\nIn the next section, we see that a much broader set of problems can be reduced\nto SAT.\nIn general, the decision problem of the above example is known as graph\ncolouring, or GT4 in Garey-Johnson's naming, where given a graph and a number\nkk\n\n the decision problem is to determine if a kk\n\n-colouring for the\ngraph exists.  In the above, we had k=4.k=4.\n\n In this more general\ndefinition, with nn\n\n regions, our reduction to SAT involves introducing\nk⋅nk\\cdot n\n\n variables and\n1+n⋅(k2)+k⋅e\n1 + n \\cdot \\binom{k}{2} + k \\cdot e\nclauses, where ee\n\n is the number of edges.  Since e=O(n2)e = O(n^2)\n\n (in\nfact, e=O(n)e = O(n)\n\n for planar graphs), the number of variables and clauses\nin our construction above are polynomials in nn\n\n and kk\n\n.  Hence we\nhave a polynomial-time reduction to SAT.  The significance of this is discussed\nfurther in the next section.\n\n\nNP-Completeness Of SAT *\nIn previous section we saw how a problem regarding colouring of regions in a\nmap can be reduced to SAT. This can be further generalized to much larger class\nof problems: any decision problem that can be decided in polynomial time using\na non-deterministic Turing machine can be reduced in polynomial time to\nSAT. This was first proved in Stephen Cook's paper \"The Complexity of\nTheorem-Proving Procedures\", which is the paper\nthat introduced the famous P = NP question as well. Let's go over the basic\nidea in the paper very briefly here. If you are interested in more details,\nmake sure you have a look at the paper, as it is rather short and a pleasure to\nread.\nBut before we go into detail, let us take a moment to discuss why it is of such\nimportance. First, nobody has yet come up with an efficient (polynomial time)\nalgorithm to solve SAT in its generality. (SAT with some restrictions, e.g.\n2-SAT, can be solved efficiently though.) Showing that a problem can be reduced\nto SAT means that if we find an efficient algorithm for SAT then we have found\nan efficient algorithm for that problem as well. For example, if we find a\npolynomial-time algorithm for SAT then we immediately have a polynomial-time\nalgorithm for the graph colouring problem given above.\nNow, the class of decision problems that can be solved in polynomial-time using\na non-deterministic Turing machine is known as NP (which stands for\nNon-deterministic Polynomial). This is a very large class of problems, since\nTuring machines are one of the most general computational models we have, and\neven though we are limited to polynomial-time Turing machines, the fact that\nthe Turing machine does not have to be deterministic allows us much more\nfreedom. Some examples of problems that are in NP are:\n\nall problems in P, e.g. determining if a number is prime or not (PRIMES), and\ndecision versions of shortest path, network flow, etc.,\ninteger factorization,\ngraph colouring,\nSAT,\nand all NP-complete problems (see here for a rather\nlarge list of examples).\n\nA problem is said to be NP-complete if it, in addition to being in NP, also has\nthe property that any other problem in NP can be reduced to it in\npolynomial-time. Cook's paper proved SAT to be NP-complete. In fact, since that\npaper introduced the concept of NP-completeness, SAT was the first problem\nto be proved NP-complete. Since then, many other problems have been shown to be\nNP-complete, often by showing that SAT (or 3-SAT) can be reduced in\npolynomial-time to those problems (converse of what we proved earlier for\ngraph colouring).\nNow, as promised, let's briefly look at why SAT is NP-complete. For this, we\nneed to know more precisely what a Turing machine is. Unfortunately, this would\ninvolve a bit more detail than I want to include in this section. So instead, I\nam going to show that if a problem can be solved using a finite-state machine\n(FSM) then it be reduced in polynomial-time to SAT. The case for Turing\nmachines, which are a generalizations of finite-state machines (Turing machines\nare basically FSM's with the addition of a tape that they can read from and\nwrite to), is quite similar, just more complicated. I encourage you to read\nCook's original paper for details of the proof with Turing machines.\nFirst, let's define what an FSM is. In simplest terms, an FSM is a program that\nhas a finite number of states, and that when fed an input character, moves to\nanother state (or possibly stays in the same state) based on a fixed set of\nrules.  Also, some states are taken as \"accepting\" states. Given an input\nstring, we feed the string character by character into the FSM, and if at the\nend the FSM is in an accepting state, the answer to our decision problem is\nyes. If not, the answer is no.\nThe below code shows how an FSM could can be implemented in Python. Note that\nin this implementation, we are forced to have a deterministic FSM. Let's\nignore this detail for now though. This particular example implements an FSM\nthat accepts input strings that contain an even number of ones.\nfrom __future__ import print_function\n\n\ndef even_ones(s):\n    # Two states:\n    # - 0 (even number of ones seen so far)\n    # - 1 (odd number of ones seen so far)\n    rules = {(0, '0'): 0,\n             (0, '1'): 1,\n             (1, '0'): 1,\n             (1, '1'): 0}\n    # There are 0 (which is an even number) ones in the empty\n    # string so we start with state = 0.\n    state = 0\n    for c in s:\n        state = rules[state, c]\n    return state == 0\n\n\n# Example usage:\ns = \"001100110\"\nprint('Output for {} = {}'.format(s, even_ones(s)))\n\nSo the core of an FSM is a list of rules of the form (S,c)→T(S, c) \\rightarrow\nT\n\n which says if the FSM is in state SS\n\n and receives input character\ncc\n\n then it goes to state TT\n\n. If for any unique pair of (S,c)(S,\nc)\n\n there is only one rule (S,c)→T(S, c) \\rightarrow T\n\n then the FSM is said to\nbe deterministic. This is because the FSM will never need to make a \"choice\" as\nto which of the rules to apply. With non-deterministic FSM's, the definition of\nacceptance needs to be modified a bit: if any set of choices of rules would\nget us to an accepting state given an input then the input is said to be\naccepted. It is a well-established result in Automata theory that deterministic\nand non-deterministic FSM's are computationally equally powerful, because any\nnon-deterministic FSM can be translated to an equivalent deterministic one by\nthe \"powerset construction\" method. The equivalent\ndeterministic FSM might have an exponentially larger number of states compared\nto the non-deterministic one, however.\nIt is also well-known that FSM's can solve a class of problems known as\n\"regular\" problems. What this means, in very simple terms, is that if you can\nwrite a regular expression that would accept the \"yes\" instances of your\ndecision problem, then you can solve the problem using an FSM. In fact, regular\nexpressions are often implemented using FSM-like structures. The \"compile\"\nphase of using regular expression is precisely when the regular expression\nengine builds the FSM-like structure from your regular expression. (Exercise:\nFind a regular expression that accepts the above language, namely binary\nstrings with an even number of ones.)\nAll right, so let's say a decision problem can be solved using an FSM with states\nnumbered 11\n\n to nn\n\n. For simplicity, let's assume that our input\nwill be binary (character set is {0,1}\\{0, 1\\}\n\n). Suppose the FSM has\nkk\n\n rules given by (Si,ci)→Ti(S_i, c_i) \\rightarrow T_i\n\n, for 1≤i≤k1 \\le i\n\\le k\n\n. And assume the input characters are given by s1s_1\n\n to\nsms_m\n\n. So our input is of length mm\n\n. Finally, assume that the\ninitial state is 11\n\n and accepting states are a1a_1\n\n to aqa_q\n\n,\nwhere qq\n\n is the number of accepting states.\nFollowing Cook's footsteps, we will introduce the following variables for our\nSAT reduction:\n\nPtP_t\n\n which is true iff st=1s_t = 1\n\n,\nand QtiQ^i_t\n\n which is true iff the FSM is in state ii\n\n after input\ncharacter sts_t\n\n has been fed into the FSM, for 1≤i<j≤n1 \\le i < j \\le\nn\n\n and 0≤t≤m0 \\le t \\le m\n\n. We will take t=0t=0\n\n to be the starting step,\nbefore anything has been fed into the FSM.\n\nWith these definitions, we proceed to translate the question of whether the\ninput is accepted by the FSM into an instance of SAT. The goal is to produce a\nset of clauses that are satisfiable iff the FSM ends in an accepting state\ngiven the particular input. The clauses that will accomplish this are:\n\nPtP_t\n\n for 0≤t≤m0 \\le t \\le m\n\n such that st=1s_t = 1\n\n and\n∼Pt\\sim P_t\n\n for all other 1≤t≤m1 \\le t \\le m\n\n. These will be the first\nmm\n\n clauses, each consisting of a single literal.\nQmajQ^{a_j}_{m}\n\n for 1≤j≤q1 \\le j \\le q\n\n. This says that after the last\ncharacter is fed into the FSM, we want to be in one of the accepting states.\n∼Qti∨∼Qtj\\sim Q^i_t \\vee \\sim Q^j_t\n\n for any 1≤i<j≤n1 \\le i < j \\le n\n\n and\n1≤t≤m1 \\le t \\le m\n\n, which effectively says that the FSM can not be in both\nstates ii\n\n and jj\n\n at step tt\n\n.  Collectively, these\nclauses will ensure that the FSM is not in more than one state at a time.\nQt1∨…∨QtnQ^1_t \\vee \\ldots \\vee Q^n_t\n\n for 1≤t≤m1 \\le t \\le m\n\n. This says\nthat the FSM needs to be in at least one state at any step. Together with the\nlast set of clauses, we ensure that the FSM is in exactly one state at any\nstep.\n∼Qt−1Si∨Pt∨QtTi\\sim Q^{S_i}_{t-1} \\vee P_t \\vee Q^{T_i}_{t}\n\n for all rules (Si,0)→Ti(S_i,\n0) \\rightarrow T_i\n\n and ∼Qt−1Si∨∼Pt∨QtTi\\sim Q^{S_i}_{t-1} \\vee \\sim P_t \\vee\nQ^{T_i}_{t}\n\n for all rules (Si,1)→Ti(S_i, 1) \\rightarrow T_i\n\n, for\n1≤t≤m1 \\le t \\le m\n\n. These clauses are logically equivalent to\n\"Qt−1SiQ^{S_i}_{t-1}\n\n and PtP_t\n\n implies QtTiQ^{T_i}_{t}\n\n\" which is\nequivalent to (Si,1)→Ti(S_i, 1) \\rightarrow T_i\n\n.  In other words, they ensure\nproper transition between states based on the input.\nFinally, we want to start in the initial state so we add the\nclause Q01Q^1_0\n\n.\n\nLet's see this in action for the above FSM which accepts strings with an even\nnumber of ones in them. First, we have two states, so n=2n=2\n\n. Let's build the\nSAT instance to handle inputs of length tt\n\n. Also note that we can leave out the\nfirst set of clauses (the PtP_t\n\n and ∼Pt\\sim P_t\n\n ones), in which case any SAT\nassignment will give us some accepted input. Which means we can list all the\nstrings accepted by the FSM by looking at all the satisfying assignments of the\nabove set of clauses.\nHere is an example for t=3t=3\n\n. In this input QtiQ^i_t\n\n is written as\nQi-t.  The states are also labelled 00\n\n and 11\n\n instead of\n11\n\n to nn\n\n in the above.\n# No more than one state at each step\n~Q0-0 ~Q1-0\n~Q0-1 ~Q1-1\n~Q0-2 ~Q1-2\n~Q0-3 ~Q1-3\n\n# At least one state in each step\nQ0-0 Q1-0\nQ0-1 Q1-1\nQ0-2 Q1-2\nQ0-3 Q1-3\n\n# Add the rules\n# (EVEN, 1) -> ODD\n~Q0-0  ~P1   Q1-1\n~Q0-1  ~P2   Q1-2\n~Q0-2  ~P3   Q1-3\n\n# (ODD, 1) -> EVEN\n~Q1-0  ~P1   Q0-1\n~Q1-1  ~P2   Q0-2\n~Q1-2  ~P3   Q0-3\n\n# (EVEN, 0) -> EVEN\n~Q0-0   P1   Q0-1\n~Q0-1   P2   Q0-2\n~Q0-2   P3   Q0-3\n\n# (ODD, 0) -> ODD\n~Q1-0   P1   Q1-1\n~Q1-1   P2   Q1-2\n~Q1-2   P3   Q1-3\n\n# Start in state 0\nQ0-0\n# End in an accepting state\nQ0-3\n\nLet's see the output of running a SAT solver on this, and another file for\nt=3t=3\n\n and t=4t=4\n\n:\n$ python sat.py --all --starting_with P --brief < tests/fsm/even-ones-3.in\n\nP1 P3\nP1 P2\nP2 P3\n$ python sat.py --all --starting_with P --brief < tests/fsm/even-ones-4.in\n\nP1 P4\nP1 P3\nP1 P2 P3 P4\nP1 P2\nP2 P4\nP2 P3\nP3 P4\n\nAs expected, all the possible ways of picking a subset of {P1,P2,P3}\\{P1, P2, P3\n\\}\n\n with an even number of elements in them are listed above, and similarly for\n{P1,P2,P3,P4}\\{P1, P2, P3, P4 \\}\n\n, although not necessarily in any meaningful order.\n(Notice that the empty lines are the empty subsets, which also have even\nnumbers of ones.)\n\n\n\n\n    \n\n\n\n\n        \n\n\n\n\n\n\n\n\n","title":"Understanding SAT by Implementing a Simple SAT Solver in Python","date_published":"2020-03-24T12:22:09-00:00"},{"id":"https://ferd.ca/clever-functional-design.html","content_text":"\n        \n            2019/08/24\n        \n        Clever Functional Design\n        \n\nOne of the best bits of software design I recall participating in was something done a few years ago at Heroku. It's been long enough since then that I feel comfortable boasting about it here. It's one small piece of data-centred functional design, where thinking a bit harder about the problem at hand greatly simplified what would have been a more straightforward and obvious implementation choice in a mutable language.\n\nThe Feature\n\n\nHeroku's routing stack had one very interesting feature it provided to all users: a router log. The router log contains fields such as the overall request time, the time it took to send the request, the time it took to send the body, heroku-specific error codes and so on. They're broader categories of interesting time span.\n\nAt the same time, Heroku engineers had internal logs for all the requests for which users had public logs. These internal logs contained more detailed information that more often made sense to display during specific debugging activities. They included information such as time spent parsing headers from the client, time to first response packet (calculating what would essentially be the time after which the whole request was sent, but before which the back-end application would respond), POSIX statuses detected by the proxy on socket issues, and so on.\n\nDuring more intricate debugging, other values could be required from the logs, but adding them would need code changes. This information was maintained in what was essentially a monolithic proxy that contained both the business logic (what logs to create, which servers to route to, and so on) and the proxying logic (how to shuttle HTTP from point A to point B).\n\nAt some point during my Heroku days, we rewrote the entire routing stack to clearly divide the business concerns (routing and features for Heroku apps) and the proxying logic. The idea was to clean up deeply intertwined code, clarify and properly specify the proxying behaviour, and allow to reason about and change what we offered to customers without having to know all the innards of HTTP proxying logic to do so. This divide was successful, and eventually allowed us to open source the proxying logic: since it was no longer business related and was commodity infrastructure, vegur became public.\n\nThis division came with a few challenges though, and one of them was with the logs: how were we to take a Heroku feature, such as the router logs we had, with their own specific needs that could change according to business requirements, and bake them into a generic proxy library, where all the interesting measurements and samplings were to take place?\n\nThe Straightforward Design\n\n\nThe approach we took in the original router was to just take all the samples as we needed them, mostly as spans. You essentially just intersperse the logging and observational needs with the actual business end of the code, and do what you must.\n\nOne straightforward way to do this is with timestamps and might look something like this:\n\nT1 = stamp(),\ndo_something(),\nT2 = stamp(),\nreport_duration(\"some label\", T2-T1)\n\n\n\nYou take a timestamp, do the thing, take a second timestamp, and report the difference as the duration of the operation. Eventually you get tired of doing this, and you might wrap them up in a helper that takes a closure (or wraps some object in OO design) and hides the reporting:\n\nwith_timestamp(\"some label\", fun() -> do_something() end)\n\n\n\nBoth approaches work fine. The latter offers slightly more encapsulation, and also prevents having overlapping timestamps where two measurements intersect. The logic is always set at the call-site, and things can be a bit tricky with error handling, but that's generally how you do it. The same kind of approach is still rather broadly used in distributed tracing with the addition of a context, which lets you define some lineage or nesting of operations:\n\n%% approach 1\nCtx = new_span(\"some label\"),\nT1 = stamp(),\nNewCtx = do_something(Ctx),\nT2 = stamp(),\nclose_span(NewCtx)\n\n%% approach 2\nwith_span(\"some_label\", fun(Ctx) -> do_something(Ctx) end)\n\n\n\nOf course if you've got mutability going on and some global scope available, you'll cheat a bit and hide the span context within the program's state differently.\n\nIn any case, the old approach was based on these kinds of mechanism. When time came to split them up into their business and general parts, the tools used for logging needed to be decoupled as well. The general and straightforward approach to that is to do it through dependency injection. Our new approaches might now look something like this:\n\nf(Logger) ->\n    T1 = stamp(),\n    do_something(Logger),\n    T2 = stamp(),\n    Logger(\"some label\", T2-T1)\n\n\n\nKind of similarly to passing the context or a span in the distributed tracing approach, you now parametrize each contract of dependent functions to take some contextual cues that explain how to do things.  It would have become a bit cumbersome to do it through all involved components of a proxying library, but it would have been possible to do it, and even more easily with tool or IDE support.\n\nThis, however, was the road we decided not to take.\n\nThe Weakness of the Straightforward Approach\n\n\nThe problem with the dependency injection approach, aside from its cumbersomeness, is that it did not sufficiently decouple what was a business concern from what was a generic library. Sure, we would hide and abstract away the tools chosen—which logging or tracing library would be used—but in no way would it really de-couple the design.\n\nIt would be tricky, for example, to properly track the concerns of \"public user logs\" and \"internal engineer logs\". The biggest design issue was something we uncovered by simply asking ourselves this question: if some other project were to use this library, would their reporting need to change every time Heroku decided to log new metrics?\n\nSure, the implementation could be independent. But the straightforward design only de-coupled the technical dependencies and which code was used. It did not get rid of the logical coupling that still existed between Heroku's business logic and the proxy's need to just shuttle HTTP. If we went with that approach, there was still a very deep dependency between both code bases. Heroku would unsurprisingly rely on the proxy, but it felt weird that the proxy's instrumentation would have to be defined by the Heroku product requirements.\n\nAnother slightly less important issue came from implementation details. I mention it not because it was a huge blocker to logical decoupling, but because this implementation detail ended up providing the key to the nicer design. The Vegur proxy had been written to use passive TCP sockets used in a blocking mode, because those were faster back in the day (implementation changes and optimizations within the BEAM VM have since then made this unnecessary). This, and other earlier design choices, made it so the proxy itself had 3 major moving parts:\n\n\nan HTTP server parsing module, which would listen to incoming requests from the public Internet and parse them\nan HTTP client parsing module, which would forward the traffic to a customer's back-end and listen to the responses\nan inner loop that would use both the client and server bits and would handle the data transfer across both of them as a bridge.\n\nThis meant that some concerns we had in terms of metrics would sometimes reside all within one bit of code (i.e. the time it takes to parse headers is self-contained to any of the components), but sometimes it would cross boundaries. For example, knowing the time it took to parse the request body required taking measurements in the HTTP server, but which could be intertwined with operations taking place both in the inner loop and the HTTP client. It had no clear structural hierarchy.\n\nWorse, some debugging scenarios required taking some measurements that started in the HTTP server, and finished in the HTTP client. That made it particularly difficult to localize and isolate concerns well, and the overall requirements of Heroku's reporting risked having a huge impact on the structure of the proxy.\n\nDependency injection would not be enough to fix this, we needed to think about the problem differently.\n\nA Functional Design\n\n\nEven in today's modern distributed tracing ecosystem, the design of most tracing libraries is deeply centered on the concept of a span: a pre-defined point A to point B period of time, which is written and instrumented as such in the code.\n\nThe big Eureka! moment for our approach in Vegur was in realizing that what when debugging, what we care about is picking arbitrary points on a timeline. Spans let you represent things a bit like this:\n|------------------- Request --------------------|\n |--- Header Parsing ---|-- Body parsing --| ...\n     |-- Cookie --|\n        | ... |\n\nThose are contiguous subdivisions of the whole timeline. What we wanted, instead, was a flat timeline on which we could pick arbitrary intervals:\nrequest start                                          end of request\n|                                                       |\n| start header parsing                                  |\n| |                first packet sent           ...      |\n| |                |                             |      |\n|-x--x--x------x---x----x------------------x-----x---...|\n     |  |      |        |                  |\n     |  |     ...      start body parsing  |\n     | end cookie                     end body parsing\n start cookie\n\nAll these things happen in a continuum. The divisions of what we wanted to report were not structural to this timeline, they were views or selections of various points of interests, and a measurement between them. The \"first packet sent\" event is something that could be useful to multiple metrics:\n\n\ntime between the first packet received and the first packet sent (\"how long we took to process the headers\"\ntime between header parsing being done and sending the first packet (\"how long we took to make a routing decision\")\ntime between the first packet sent and the last header packet sent (\"time to send the request headers\")\ntime between the first packet sent and the last request packet sent (\"time to send the full request\")\n\nand so on. Being able to report on all of these was context-dependent for the consumer, meaning that's usually a business concern. But the proxying library itself only cared about specific arbitrary points we thought could be useful to its technical users.\n\nThat distinction and approach as a timeline was the pivotal point we needed in the design. What the proxying library needed to do was not provide all the metrics and spans Heroku expected. What it needed to provide was the list of all important points on a timeline, whether they represented a singular event, or a duration. It would then be up to the consumer to report things however they wanted, whenever they wanted.\n\nThe flat timeline was particularly interesting for this because it is easily representable as an immutable data structure. If all you have is a bunch of local monotonic timestamps, all you need to do is maintain a local data structure that maintains sequences of labelled points in time: [{Label1, T1}, {Label2, T2}, ...]\n\nSince timestamps are generally sortable locally—you need some fancy cheats to make it work in a distributed setting—then all the local timelines between the HTTP client, server, and inner loop modules could be maintained independently, but merged reliably: just sort by timestamp.\n|-x----------------x---------------------------------...|\n\n  |--x--x------x--------x------------------|\n\n                   |—---------------------------x---...|\n\n         |               |             |\n         v               v             v\n\n|-x--x--x------x---x----x------------------x----x----...|\n\nThis would let us write one generic well-defined data structure, use it wherever and whenever we needed it, and just merge them near the end of each timeline. No need to coordinate context-passing around, just a fetch and a merge once per item.\n\nThen, the business end of code in Heroku's router could ask for that timeline once the request was ready to be logged, get one well-known data structure, and do as many selections for as many debugging reports as it required. If you wanted to send 15 logs out of there, it did not matter to the proxy library. Just analyze the timeline, generate what you need, and that's it.\n\nInterestingly, since the final data structure could be represented easily in the base types of the language, Heroku's router was able to create its own compatible timeline that itself could be cast and merged with the proxy's timeline, without having them actually share the implementation (which would also have been fine). This would later let us augment the proxying logs with all the routing and business decisions for all kinds of debugging purposes (how much time would we spend queued to find an available back-end to route to?). This turned into app-specific routing flags that could allow to do deeper introspection of routing logic for specific applications, at nearly no overhead in code.\n\nLesson Learned\n\n\nThe approach itself here is mildly interesting. It has some intriguing implications in the context of designing implementations of distributed tracing libraries. The implementation is so straightforward in Vegur that I didn't spend the time to describe it here.\n\nThe true bigger lesson here is in systems design. It relates to functional, immutable, and declarative approaches to structuring communication flows.\n\nThe straightforward answer to our decoupling issue was to respond to the technical concern: just make it so the dependency does not know about the libraries used by its parent. I think it would have strictly speaking solved the most blocking problem in getting the code to build.  This would have been easy to do, and the only thing that made it annoying was the fact we were using a functional programming language with no mutable data structures nor global shared context. But satisfying the compiler is not enough to make for good design. This approach would have made it hard to get maintainable code given implementation details, and did not remove any logical coupling.\n\nRather than dismissing this challenge as \"a bad fit for functional programming\", it is what led to a better solution: re-think the data structure, gain better insights in the distinction between how the data is produced and how the data is consumed. Take that separation, and make it explicit. Build around it. Turn it into a data contract. This, in turn, lets you more transparently change either ends. You might need to add new measurement points in the producer-side when the consumer needs it, but the properly declared abstraction makes it so the other consumers will not be effected by the change.\n\nThe end result was a purely functional data structure that was mergeable, testable, and in line with functional design, but that's just a technical aspect of the result: it was the structural constraint of already being in an immutable context that prompted the cleaner design. Most challenges of working in a functional, declarative, or immutable language are not necessarily due to the language itself. They come from being thrown in a context where easier shortcuts are not as practical as we are used for them to be, and having to re-think both our problem and our solutions.\n\n    ","title":"Clever Functional Design","date_published":"2020-03-24T12:22:15-00:00"},{"id":"https://blog.scaleway.com/2019/building-a-machine-reading-comprehension-system-using-the-latest-advances-in-deep-learning-for-nlp/","content_text":"Found. Redirecting to /building-a-machine-reading-comprehension-system-using-the-latest-advances-in-deep-learning-for-nlp/\n","title":"","date_published":"2020-03-24T12:22:26-00:00"},{"id":"https://blog.regehr.org/archives/1687","content_text":"\n\t\t\n\n\t\t\t\n\n\t\t\n\t\n\t\n\t\tFuzzing is sort of a superpower for locating vulnerabilities and other software defects, but it is often used to find problems baked deeply into already-deployed code. Fuzzing should be done earlier, and moreover developers should spend some effort making their code more amenable to being fuzzed. \nThis post is a non-comprehensive, non-orthogonal list of ways that you can write code that fuzzes better. Throughout, I’ll use “fuzzer” to refer to basically any kind of randomized test-case generator, whether mutation-based (afl, libFuzzer, etc.) or generative (jsfunfuzz, Csmith, etc.). Not all advice will apply to every situation, but a lot of it is sound software engineering advice in general. I’ve bold-faced a few points that I think are particularly important.\nInvest in Oracles\nA test oracle decides whether a test case triggered a bug or not. By default, the only oracle available to a fuzzer like afl is provided by the OS’s page protection mechanism. In other words, it detects only crashes. We can do much better than this.\nAssertions and their compiler-inserted friends — sanitizer checks — are another excellent kind of oracle. You should fuzz using as many of these checks as possible. Beyond these easy oracles, many more possibilities exist, such as: \n\nfunction-inverse pairs: does a parse-print loop, compress-decompress loop, encrypt-decrypt loop, or similar, work as expected?\ndifferential: do two different implementations, or modes of the same implementation, show the same behavior?\nmetamorphic: does the system show the same behavior when a test case is modified in a semantics-preserving way, such as adding a layer of parentheses to an expression?\nresource: does the system consume a reasonable amount of time, memory, etc. when processing an input?\ndomain specific: for example, is a lossily-compressed image sufficiently visually similar to its uncompressed version?\n\nStrong oracles are worth their weight in gold, since they tend to find application-level logic errors rather than the lower-level bugs that are typically caught by looking for things like array bounds violations.\nI wrote a bit more about this topic a few years ago. Finally, a twitter user suggested “If you’re testing a parser, poke at the object it returns, don’t just check if it parses.” This is good advice.\nInterpose on I/O and State\nStateless code is easier to fuzz. Beyond that, you will want APIs for taking control of state and for interposing on I/O. For example, if your program asks the OS for the number of cores, the current date, or the amount of disk space remaining, you should provide a documented method for setting these values. It’s not that we necessarily want to randomly change the number of cores, but rather that we might want to fuzz our code when set to single-core mode and then separately fuzz it in 128-core mode. Important special cases of taking control of state and I/O include making it easy to reset the state (to support persistent-mode fuzzing) and avoiding hidden inputs that lead to non-deterministic execution. We want as much determinism as possible while fuzzing our code.\nAvoid or Control Fuzzer Blockers\nFuzzer blockers are things that make fuzzing gratuitously difficult. The canonical fuzzer blocker is a checksum included somewhere in the input: the random changes made to the input by a mutation-based fuzzer will tend to cause the checksum to not validate, resulting in very poor code coverage. There are basically two solutions. First, turn off checksum validation in builds intended for fuzzing. Second, have the fuzzer generate inputs with valid checksums. A generation-based fuzzer will have this built in; with a mutation-based fuzzer we would write a little utility to patch up the test case with a valid checksum after it is generated and before it is passed to the program being fuzzed. afl has support for this.\nBeyond checksums, hard-to-satisfy validity properties over the input can be a serious problem. For example, if you are fuzzing a compiler for a strongly typed programming language, blind mutation of compiler inputs may not result in valid compiler inputs very often. I like to think of validity constraints as being either soft (invalid inputs waste time, but are otherwise harmless) or hard (the system behaves arbitrarily when processing an invalid input, so they must be avoided for fuzzing to work at all). When we fuzz a C++ compiler to look for wrong code bugs, we face a hard validity constraint because compiler inputs that have UB will look like wrong code bugs. There is no simple, general-purpose solution to this kind of problem, but rather a family of techniques for explicitly taking validity properties into account. The most obvious solution — but often not the right one — is to write a new generational fuzzer. The problem is that if you do this, you cannot take advantage of modern coverage-driven fuzzing techniques, which are amazing. To fit into a coverage-driven fuzzing framework you have a couple of options. First, write a custom mutator that respects your validity constraints. Second, structure-aware fuzzing, which basically means taking the mutated data from the fuzzer and translating it into something like what the program being fuzzed expects to see. There’s a lot of research left to be done in making coverage-driven fuzzers work well in the presence of validity constraints without requiring a lot of manual effort. There are some significant subtleties here, maybe I’ll go into them another time. Putting something like a SAT solver into the fuzzer is not, generally speaking, the answer here, first because some validity constraints like checksums are specifically difficult for solvers, and second because some validity constraints (such as UB-freedom in a C++ program) are implicit and cannot be inferred, even in principle, by looking at the system being fuzzed.\nA lot of code in a typical system cannot be fuzzed effectively by feeding input to public APIs because access is blocked by other code in the system. For example, if you use a custom memory allocator or hash table implementation, then fuzzing at the application level probably does not result in especially effective fuzzing of the allocator or hash table. These kinds of APIs should be exposed to direct fuzzing. There is a strong synergy between unit testing and fuzzing: if one of these is possible and desirable, then the other one probably is too. You typically want to do both.\nSanitizers and fuzzers often require tweaks or even significant changes to the build process. To make this easier, keep the build process as clean and simple as possible. Make it easy to switch out the compiler and modify the compiler options. Depend on specific tools (and versions of tools) as little as possible. Routinely build and test your code with multiple compilers. Document special build system requirements.\nFinally, some fuzzer blockers are sort of silly and easy to avoid. If your code leaks memory or terminates its process with a deep call stack, it will be painful to test using a persistent-mode fuzzer, so don’t do these things. Avoid handling SIGSEGV or, if you really must do this, have a way to disable the handler for fuzzer builds. If your code is not compatible with ASan or UBSan, then these extremely useful oracles are harder to use. In particular, if your code uses a custom memory allocator you should consider turning it off for fuzzer builds, or else adapting it to work with ASan, or else you’ll miss important bugs.\nUnblock Coverage-Driven Fuzzers\nBecause coverage-driven fuzzers refocus their effort to try to hit uncovered branches, they can be blocked in certain specific ways. For example, if a coverage-driven fuzzer is presented with too many uncoverable branches, it can spend so much time on them that it becomes less likely to hit more interesting branches elsewhere in the program. For example, one time I compared afl’s coverage on a program compiled with and without UBSan, and found that (in whatever time limit I used) it covered quite a lot less of the sanitized program, compared to the unsanitized build. On the other hand, we definitely want our fuzzer to look for sanitizer failures.  My advice is to fuzz both sanitized and unsanitized builds of your program. I don’t know how to budget fuzzing resources for these different activities and don’t know of any principled work on that problem. It may not matter that much, since fuzzing is all about overkill.\nSometimes your program will call branchy, already-heavily-fuzzed code early in its execution. For example, you might decompress or decrypt input before processing it. This is likely to distract the coverage-driven fuzzer, causing it to spend a lot of time trying to fuzz the crypto or compression library. If you don’t want to do this, provide a way to disable crypto or compression during fuzzing.\nAny interpreter in your program is likely to make life difficult for a coverage-driven fuzzer, since the relevant program paths are now encoded in the data being interpreted, which is generally opaque to the fuzzer. If you want maximum mileage out of coverage-driven fuzzers, you may want to try to avoid writing interpreters, or at least keep them extremely simple. An obvious way to deal with embedded interpreters — which someone must have thought of and tried, but I don’t have any pointers — would be to have an API for teaching the fuzzer how to see coverage of the language being interpreted.\nEnable High Fuzzing Throughput\nFuzzing is most effective when throughput is very high; this seems particularly the case for feedback-driven fuzzers that may take a while to learn how to hit difficult coverage targets. An easy throughput hack is to make it possible to disable slow code (detailed logging, for example) when it is not germane to the fuzzing task. Similarly, interposing on I/O can help us avoid speed hacks such as running the fuzzer in a ramdisk.\n“But I Want Fuzzing My Code to be Harder, Not Easier”\nI don’t have a lot of sympathy for this point of view. Instead of aiming for security through obscurity, we would do better to:\n\nfuzz early and thoroughly, eliminating fuzzable defects before releasing code into the wild\nwrite code in a programming language with as strong of a type system as we are willing to tolerate — this will statically eliminate classes of bad program behaviors, for example by stopping us from putting the wrong kind of thing into a hashmap\naggressively use assertions and sanitizers to get dynamic checking for properties that the type system can’t enforce statically\n\nAnti-fuzzing techniques are a thing, but I don’t think it represents a useful kind of progress towards better software. \nConclusion\nRandomized testing is incredibly powerful and there’s no point avoiding it: if you don’t fuzz your code, someone else will. This piece has described some ways for you, the software developer, to make fuzzing work better. Of course there are plenty of other aspects, such as choosing a good corpus and writing a good fuzzer driver, that are not covered here.\nAcknowledgments: Pascal Cuoq and Alex Groce provided feedback on a draft of this piece, and it also benefited from suggestions I received on Twitter. You can read the conversation here; it contains some suggestions and nuances that I did not manage to capture.\n\t\n\n\t\n\n\t\t\t\t\n\n\n\t\n\n\n\t\t\n\t","title":"Write Fuzzable Code &#8211; Embedded in Academia","date_published":"2020-03-24T12:24:29-00:00"},{"id":"https://spectrum.ieee.org/the-institute/ieee-member-news/educational-resources-that-get-students-up-to-speed-on-advanced-manufacturing-and-programming-languages","content_text":"\n\t\t\n\t\t\t\t\n\t\t\t\t\tJoin IEEE\n\t\t\t\t\t|\n\t\t\t\t\tIEEE.org\n\t\t\t\t\t|\n\t\t\t\t\tIEEE Xplore Digital Library\n\t\t\t\t\t|\n\t\t\t\t\tIEEE Standards\n\t\t\t\t\t|\n\t\t\t\t\tIEEE Spectrum\n\t\t\t\t\t|\n\t\t\t\t\tMore Sites\n\t\t\t\t\t\n\t\t\t\t\n\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\tCreate\n\t\t\t\t\t\t\t\t\t\t\tAccount\n\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t|\n\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\tSign In\n\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\n\t\t\n\n             \n\n\n\n\n\t\t\t\n\n \n\t\n\n\t\n\n\n\n\n \n\n\n\n\n\n\t\n\t\n\t\n\t\n\n \n \n \n\n\n\n\t\n\n\n\n\n\n\n\t\t\t\n\n\n","title":"Full Page Reload","date_published":"2020-03-24T12:27:19-00:00"},{"id":"https://blog.plaid.com/how-we-reduced-deployment-times-by-95/","content_text":"301 Moved Permanently\nnginx\n\n\n\n","title":"301 Moved Permanently","date_published":"2020-03-24T12:27:27-00:00"},{"id":"https://www.reifyworks.com/writing/2019-08-26-a-most-software-companies","content_text":"\n\n      \n\n\n      \n        \n        \n                  One of the most important skills to build as a marketer is follow through. In marketing that means taking every opportunity to gather data in order to understand your users and improve your process.\n\n\n  Understanding your users doesn’t end when they purchase your product.\n\n\nOne deficiency we’ve consistently seen inside companies small and large alike is that they don’t have ready access to information about what users are doing with their product. Marketers are incentivized to instrument the hell of out lead generation and a section of the funnel, sales religiously updates CRMs to track prospects and potential revenue expansion opportunities, but noone is tying it all together by looking to information that you own about what users are doing with your product.\n\nThe reason why this is so important to get right early is that it will deeply inform decisions that you’ll need to make later on … if you’re around that long. Decisions about pricing and packaging, feature development, marketing spending, hiring, strategic investment of all sorts, etc., are more intelligently made when they’re backed by data that is enriched by how users are actually using your product.\n\nThere are myriad technical approaches to gathering the data necessary for this method, but an ideal setup should contain the following, regardless of how it is implemented:\n\n\n  A “User table” which rolls up all useful usage information into one easy to query data source. You likely have some version of this powering either a homegrown “admin dashboard” or feeding into one or more external systems.\n  A time-bounded data source which is amenable to more complex queries, including historical queries, and can be used to generate reports. Amazon Redshift is a popular solution for this component.\n\n\nHere’s an example row:\n\n\n  \n    ID\n    name\n    score\n    feature1\n    feature2\n    plan\n    monthly\n    seats\n    last_seen\n    user_since\n  \n  \n    1\n    Reify\n    87\n    1\n    0\n    small\n    99\n    3\n    019-08-29\n    019-01-02\n  \n\n\n\n\nMaintaining and curating this date over time will allow you to answer crucial questions about your trial users, customes, ex-customers, and so on. Recording and maintaining this data is so simple that it’s becoming table stakes for good marketers – don’t get left behind.\n\nBonus Implementation Tips\n\n\n  Track feature usage in your user table with columns denoting whether or not a user has or has not used this feature\n  Associate plan and payment information with your user table rows so that you can easily segment your user data by important revenue based facets\n  Create an “engagement metric” number which takes core features of your product into account and rolls them up into a 0-100 score that can be tracked over time.\n  Use the data in your users table to power all kinds of interesting customer communication. Want to communicate with users who have or haven’t used a specific feature and ask them why? Now you can. Want to segment trial users into those who haven’t used that one killer feature and those who have? Go for it.\n\n\n\n                  \n                  \n                \n\n      \n\n      \n    ","title":"Most software companies ignore user behavior","date_published":"2020-03-24T12:27:34-00:00"}],"title":"Reading List","version":"https://jsonfeed.org/version/1.1"}